commit 4364390adbf16b57c093a05217897831f48da7d3
Author: Ivan Bogatyy <bogatyy@google.com>
Date:   Mon Nov 13 16:06:54 2017 -0800

     Release DRAGNN bulk networks (#2785)
    
    * Release DRAGNN bulk networks

diff --git a/research/syntaxnet/Dockerfile b/research/syntaxnet/Dockerfile
index 47e8b9d5..d651c344 100644
--- a/research/syntaxnet/Dockerfile
+++ b/research/syntaxnet/Dockerfile
@@ -1,5 +1,4 @@
-# Java baseimage, for Bazel.
-FROM openjdk:8
+FROM ubuntu:16.10
 
 ENV SYNTAXNETDIR=/opt/tensorflow PATH=$PATH:/root/bin
 
@@ -21,13 +20,15 @@ RUN mkdir -p $SYNTAXNETDIR \
           libopenblas-dev \
           libpng-dev \
           libxft-dev \
-          patch \
+          openjdk-8-jdk \
           python-dev \
           python-mock \
           python-pip \
           python2.7 \
           swig \
+          unzip \
           vim \
+          wget \
           zlib1g-dev \
     && apt-get clean \
     && (rm -f /var/cache/apt/archives/*.deb \
@@ -55,7 +56,7 @@ RUN python -m pip install \
           --py --sys-prefix widgetsnbextension \
     && rm -rf /root/.cache/pip /tmp/pip*
 
-# Installs the latest version of Bazel.
+# Installs Bazel.
 RUN wget --quiet https://github.com/bazelbuild/bazel/releases/download/0.5.4/bazel-0.5.4-installer-linux-x86_64.sh \
     && chmod +x bazel-0.5.4-installer-linux-x86_64.sh \
     && ./bazel-0.5.4-installer-linux-x86_64.sh \
@@ -65,13 +66,11 @@ COPY WORKSPACE $SYNTAXNETDIR/syntaxnet/WORKSPACE
 COPY tools/bazel.rc $SYNTAXNETDIR/syntaxnet/tools/bazel.rc
 COPY tensorflow $SYNTAXNETDIR/syntaxnet/tensorflow
 
-# Workaround solving the PYTHON_BIN_PATH not found problem
-ENV PYTHON_BIN_PATH=/usr/bin/python
 # Compile common TensorFlow targets, which don't depend on DRAGNN / SyntaxNet
 # source. This makes it more convenient to re-compile DRAGNN / SyntaxNet for
 # development (though not as convenient as the docker-devel scripts).
 RUN cd $SYNTAXNETDIR/syntaxnet/tensorflow \
-    && ./configure CPU \
+    && tensorflow/tools/ci_build/builds/configured CPU \
     && cd $SYNTAXNETDIR/syntaxnet \
     && bazel build -c opt @org_tensorflow//tensorflow:tensorflow_py
 
@@ -92,4 +91,4 @@ EXPOSE 8888
 COPY examples $SYNTAXNETDIR/syntaxnet/examples
 # Todo: Move this earlier in the file (don't want to invalidate caches for now).
 
-CMD /bin/bash -c "bazel-bin/dragnn/tools/oss_notebook_launcher notebook --debug --notebook-dir=/opt/tensorflow/syntaxnet/examples --allow-root"
+CMD /bin/bash -c "bazel-bin/dragnn/tools/oss_notebook_launcher notebook --debug --notebook-dir=/opt/tensorflow/syntaxnet/examples"
diff --git a/research/syntaxnet/README.md b/research/syntaxnet/README.md
index 078c630a..f813895b 100644
--- a/research/syntaxnet/README.md
+++ b/research/syntaxnet/README.md
@@ -23,8 +23,8 @@ This repository is largely divided into two sub-packages:
     [documentation](g3doc/DRAGNN.md),
     [paper](https://arxiv.org/pdf/1703.04474.pdf)** implements Dynamic Recurrent
     Acyclic Graphical Neural Networks (DRAGNN), a framework for building
-    multi-task, fully dynamically constructed computation graphs. Practically, we
-    use DRAGNN to extend our prior work from [Andor et al.
+    multi-task, fully dynamically constructed computation graphs. Practically,
+    we use DRAGNN to extend our prior work from [Andor et al.
     (2016)](http://arxiv.org/abs/1603.06042) with end-to-end, deep recurrent
     models and to provide a much easier to use interface to SyntaxNet. *DRAGNN
     is designed first and foremost as a Python library, and therefore much
@@ -54,20 +54,47 @@ There are three ways to use SyntaxNet:
 
 ### Docker installation
 
+_This process takes ~10 minutes._
+
 The simplest way to get started with DRAGNN is by loading our Docker container.
 [Here](g3doc/CLOUD.md) is a tutorial for running the DRAGNN container on
 [GCP](https://cloud.google.com) (just as applicable to your own computer).
 
+### Ubuntu 16.10+ binary installation
+
+_This process takes ~5 minutes, but is only compatible with Linux using GNU libc
+3.4.22 and above (e.g. Ubuntu 16.10)._
+
+Binary wheel packages are provided for TensorFlow and SyntaxNet. If you do not
+need to write new binary TensorFlow ops, these should suffice.
+
+*   `apt-get install -y graphviz libgraphviz-dev libopenblas-base libpng16-16
+    libxft2 python-pip python-mock`
+*   `pip install pygraphviz
+    --install-option="--include-path=/usr/include/graphviz"
+    --install-option="--library-path=/usr/lib/graphviz/"`
+*   `pip install 'ipython<6.0' protobuf numpy scipy jupyter
+    syntaxnet-with-tensorflow`
+*   `python -m jupyter_core.command nbextension enable --py --sys-prefix
+    widgetsnbextension`
+
+You can test that binary modules can be successfully imported by running,
+
+*   `python -c 'import dragnn.python.load_dragnn_cc_impl,
+    syntaxnet.load_parser_ops'`
+
 ### Manual installation
 
+_This process takes 1-2 hours._
+
 Running and training SyntaxNet/DRAGNN models requires building this package from
 source. You'll need to install:
 
 *   python 2.7:
     *   Python 3 support is not available yet
-*   bazel:
+*   bazel 0.5.4:
     *   Follow the instructions [here](http://bazel.build/docs/install.html)
-    *   Alternately, Download bazel <.deb> from
+    *   Alternately, Download bazel 0.5.4 <.deb> from
         [https://github.com/bazelbuild/bazel/releases](https://github.com/bazelbuild/bazel/releases)
         for your system configuration.
     *   Install it using the command: sudo dpkg -i <.deb file>
@@ -103,9 +130,12 @@ following commands:
   bazel test --linkopt=-headerpad_max_install_names \
     dragnn/... syntaxnet/... util/utf8/...
 ```
+
 Bazel should complete reporting all tests passed.
 
-Now you can install the SyntaxNet and DRAGNN Python modules with the following commands:
+Now you can install the SyntaxNet and DRAGNN Python modules with the following
+commands:
+
 ```shell
   mkdir /tmp/syntaxnet_pkg
   bazel-bin/dragnn/tools/build_pip_package --output-dir=/tmp/syntaxnet_pkg
@@ -116,8 +146,6 @@ Now you can install the SyntaxNet and DRAGNN Python modules with the following c
 To build SyntaxNet with GPU support please refer to the instructions in
 [issues/248](https://github.com/tensorflow/models/issues/248).
 
-
-
 **Note:** If you are running Docker on OSX, make sure that you have enough
 memory allocated for your Docker VM.
 
diff --git a/research/syntaxnet/docker-devel/Dockerfile-test b/research/syntaxnet/docker-devel/Dockerfile-test
new file mode 100644
index 00000000..24b28b0f
--- /dev/null
+++ b/research/syntaxnet/docker-devel/Dockerfile-test
@@ -0,0 +1,11 @@
+FROM dragnn-oss-test-base:latest
+
+RUN rm -rf \
+  $SYNTAXNETDIR/syntaxnet/dragnn \
+  $SYNTAXNETDIR/syntaxnet/syntaxnet \
+  $SYNTAXNETDIR/syntaxnet/third_party \
+  $SYNTAXNETDIR/syntaxnet/util/utf8
+COPY dragnn $SYNTAXNETDIR/syntaxnet/dragnn
+COPY syntaxnet $SYNTAXNETDIR/syntaxnet/syntaxnet
+COPY third_party $SYNTAXNETDIR/syntaxnet/third_party
+COPY util/utf8 $SYNTAXNETDIR/syntaxnet/util/utf8
diff --git a/research/syntaxnet/docker-devel/Dockerfile-test-base b/research/syntaxnet/docker-devel/Dockerfile-test-base
new file mode 100644
index 00000000..96f6e084
--- /dev/null
+++ b/research/syntaxnet/docker-devel/Dockerfile-test-base
@@ -0,0 +1,91 @@
+FROM ubuntu:16.10
+
+ENV SYNTAXNETDIR=/opt/tensorflow PATH=$PATH:/root/bin
+
+# Install system packages. This doesn't include everything the TensorFlow
+# dockerfile specifies, so if anything goes awry, maybe install more packages
+# from there. Also, running apt-get clean before further commands will make the
+# Docker images smaller.
+RUN mkdir -p $SYNTAXNETDIR \
+    && cd $SYNTAXNETDIR \
+    && apt-get update \
+    && apt-get install -y \
+          file \
+          git \
+          graphviz \
+          libcurl3-dev \
+          libfreetype6-dev \
+          libgraphviz-dev \
+          liblapack-dev \
+          libopenblas-dev \
+          libpng-dev \
+          libxft-dev \
+          openjdk-8-jdk \
+          python-dev \
+          python-mock \
+          python-pip \
+          python2.7 \
+          swig \
+          unzip \
+          vim \
+          wget \
+          zlib1g-dev \
+    && apt-get clean \
+    && (rm -f /var/cache/apt/archives/*.deb \
+        /var/cache/apt/archives/partial/*.deb /var/cache/apt/*.bin || true)
+
+# Install common Python dependencies. Similar to above, remove caches
+# afterwards to help keep Docker images smaller.
+RUN pip install --ignore-installed pip \
+    && python -m pip install numpy \
+    && rm -rf /root/.cache/pip /tmp/pip*
+RUN python -m pip install \
+          asciitree \
+          ipykernel \
+          jupyter \
+          matplotlib \
+          pandas \
+          protobuf \
+          scipy \
+          sklearn \
+    && python -m ipykernel.kernelspec \
+    && python -m pip install pygraphviz \
+          --install-option="--include-path=/usr/include/graphviz" \
+          --install-option="--library-path=/usr/lib/graphviz/" \
+    && python -m jupyter_core.command nbextension enable \
+          --py --sys-prefix widgetsnbextension \
+    && rm -rf /root/.cache/pip /tmp/pip*
+
+# Installs Bazel.
+RUN wget --quiet https://github.com/bazelbuild/bazel/releases/download/0.5.3/bazel-0.5.3-installer-linux-x86_64.sh \
+    && chmod +x bazel-0.5.3-installer-linux-x86_64.sh \
+    && JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/ ./bazel-0.5.3-installer-linux-x86_64.sh \
+    && rm ./bazel-0.5.3-installer-linux-x86_64.sh
+
+COPY WORKSPACE $SYNTAXNETDIR/syntaxnet/WORKSPACE
+COPY tools/bazel.rc $SYNTAXNETDIR/syntaxnet/tools/bazel.rc
+
+# Compile common TensorFlow targets, which don't depend on DRAGNN / SyntaxNet
+# source. This makes it more convenient to re-compile DRAGNN / SyntaxNet for
+# development (though not as convenient as the docker-devel scripts).
+RUN cd $SYNTAXNETDIR/syntaxnet \
+    && git clone --branch r1.3 --recurse-submodules https://github.com/tensorflow/tensorflow \
+    && cd tensorflow \
+    # This line removes a bad archive target which causes Tensorflow install
+    # to fail.
+    && sed -i '\@https://github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz@d' tensorflow/workspace.bzl \
+    && tensorflow/tools/ci_build/builds/configured CPU \\
+    && cd $SYNTAXNETDIR/syntaxnet \
+    && bazel build -c opt @org_tensorflow//tensorflow:tensorflow_py
+
+# Just copy the code and run tests. The build and test flags differ enough that
+# doing a normal build of TensorFlow targets doesn't save much test time.
+WORKDIR $SYNTAXNETDIR/syntaxnet
+COPY dragnn $SYNTAXNETDIR/syntaxnet/dragnn
+COPY syntaxnet $SYNTAXNETDIR/syntaxnet/syntaxnet
+COPY third_party $SYNTAXNETDIR/syntaxnet/third_party
+COPY util/utf8 $SYNTAXNETDIR/syntaxnet/util/utf8
+
+# Doesn't matter if the tests pass or not, since we're going to re-copy over the
+# code.
+RUN bazel test -c opt ... || true
diff --git a/research/syntaxnet/docker-devel/Dockerfile.min b/research/syntaxnet/docker-devel/Dockerfile.min
index 876f69d9..1acfb691 100644
--- a/research/syntaxnet/docker-devel/Dockerfile.min
+++ b/research/syntaxnet/docker-devel/Dockerfile.min
@@ -1,11 +1,9 @@
 # You need to build wheels before building this image. Please consult
 # docker-devel/README.txt.
-
-# This is the base of the openjdk image.
 #
 # It might be more efficient to use a minimal distribution, like Alpine. But
 # the upside of this being popular is that people might already have it.
-FROM buildpack-deps:jessie-curl
+FROM ubuntu:16.10
 
 ENV SYNTAXNETDIR=/opt/tensorflow PATH=$PATH:/root/bin
 
@@ -19,7 +17,7 @@ RUN apt-get update \
           libgraphviz-dev \
           liblapack3 \
           libopenblas-base \
-          libpng12-0 \
+          libpng16-16 \
           libxft2 \
           python-dev \
           python-mock \
@@ -48,11 +46,13 @@ RUN python -m pip install \
     && python -m pip install pygraphviz \
           --install-option="--include-path=/usr/include/graphviz" \
           --install-option="--library-path=/usr/lib/graphviz/" \
+    && python -m jupyter_core.command nbextension enable \
+          --py --sys-prefix widgetsnbextension \
     && rm -rf /root/.cache/pip /tmp/pip*
 
-COPY syntaxnet_with_tensorflow-0.2-cp27-none-linux_x86_64.whl $SYNTAXNETDIR/
+COPY syntaxnet_with_tensorflow-0.2-cp27-cp27mu-linux_x86_64.whl $SYNTAXNETDIR/
 RUN python -m pip install \
-        $SYNTAXNETDIR/syntaxnet_with_tensorflow-0.2-cp27-none-linux_x86_64.whl \
+        $SYNTAXNETDIR/syntaxnet_with_tensorflow-0.2-cp27-cp27mu-linux_x86_64.whl \
     && rm -rf /root/.cache/pip /tmp/pip*
 
 # This makes the IP exposed actually "*"; we'll do host restrictions by passing
@@ -63,4 +63,4 @@ EXPOSE 8888
 # This does not need to be compiled, only copied.
 COPY examples $SYNTAXNETDIR/syntaxnet/examples
 # For some reason, this works if we run it in a bash shell :/ :/ :/
-CMD /bin/bash -c "python -m jupyter_core.command notebook --debug --notebook-dir=/opt/tensorflow/syntaxnet/examples"
+CMD /bin/bash -c "python -m jupyter_core.command notebook --debug --notebook-dir=/opt/tensorflow/syntaxnet/examples --allow-root"
diff --git a/research/syntaxnet/docker-devel/README.txt b/research/syntaxnet/docker-devel/README.txt
index e190d599..029242e7 100644
--- a/research/syntaxnet/docker-devel/README.txt
+++ b/research/syntaxnet/docker-devel/README.txt
@@ -43,11 +43,11 @@ Step 3: Building the development image
 
 First, ensure you have the file
 
-  syntaxnet_with_tensorflow-0.2-cp27-none-linux_x86_64.whl
+  syntaxnet_with_tensorflow-0.2-cp27-cp27mu-linux_x86_64.whl
 
 in your working directory, from step 2. Then run,
 
-  docker build -t dragnn-oss:latest-minimal -f docker-devel/Dockerfile.min
+  docker build -t dragnn-oss:latest-minimal -f docker-devel/Dockerfile.min .
 
 If the filename changes (e.g. you are on a different architecture), just update
 Dockerfile.min.
diff --git a/research/syntaxnet/dragnn/__init__.py b/research/syntaxnet/dragnn/__init__.py
new file mode 100644
index 00000000..e69de29b
diff --git a/research/syntaxnet/dragnn/components/stateless/BUILD b/research/syntaxnet/dragnn/components/stateless/BUILD
index dd8caf23..bdd86771 100644
--- a/research/syntaxnet/dragnn/components/stateless/BUILD
+++ b/research/syntaxnet/dragnn/components/stateless/BUILD
@@ -10,7 +10,6 @@ cc_library(
         "//dragnn/core:component_registry",
         "//dragnn/core/interfaces:component",
         "//dragnn/core/interfaces:transition_state",
-        "//dragnn/io:sentence_input_batch",
         "//dragnn/protos:data_proto",
         "//syntaxnet:base",
     ],
diff --git a/research/syntaxnet/dragnn/components/stateless/stateless_component.cc b/research/syntaxnet/dragnn/components/stateless/stateless_component.cc
index 47a7b70b..4820ff80 100644
--- a/research/syntaxnet/dragnn/components/stateless/stateless_component.cc
+++ b/research/syntaxnet/dragnn/components/stateless/stateless_component.cc
@@ -16,7 +16,6 @@
 #include "dragnn/core/component_registry.h"
 #include "dragnn/core/interfaces/component.h"
 #include "dragnn/core/interfaces/transition_state.h"
-#include "dragnn/io/sentence_input_batch.h"
 #include "dragnn/protos/data.pb.h"
 #include "syntaxnet/base.h"
 
@@ -25,7 +24,8 @@ namespace dragnn {
 namespace {
 
 // A component that does not create its own transition states; instead, it
-// simply forwards the states of the previous component.  Does not support all
+// simply forwards the states of the previous component.  Requires that some
+// previous component has converted the input batch.  Does not support all
 // methods.  Intended for "compute-only" bulk components that only use linked
 // features, which use only a small subset of DRAGNN functionality.
 class StatelessComponent : public Component {
@@ -38,8 +38,7 @@ class StatelessComponent : public Component {
   void InitializeData(
       const std::vector<std::vector<const TransitionState *>> &parent_states,
       int max_beam_size, InputBatchCache *input_data) override {
-    // Must use SentenceInputBatch to match SyntaxNetComponent.
-    batch_size_ = input_data->GetAs<SentenceInputBatch>()->data()->size();
+    batch_size_ = input_data->Size();
     beam_size_ = max_beam_size;
     parent_states_ = parent_states;
 
@@ -84,31 +83,34 @@ class StatelessComponent : public Component {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
     return nullptr;
   }
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int matrix_length) override {
-    LOG(FATAL) << "[" << name_ << "] Method not supported";
+  bool AdvanceFromPrediction(const float *transition_matrix, int num_items,
+                             int num_actions) override {
+    LOG(FATAL) << "[" << name_ << "] AdvanceFromPrediction not supported";
   }
   void AdvanceFromOracle() override {
-    LOG(FATAL) << "[" << name_ << "] Method not supported";
+    LOG(FATAL) << "[" << name_ << "] AdvanceFromOracle not supported";
   }
   std::vector<std::vector<int>> GetOracleLabels() const override {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
-    return {};
   }
   int GetFixedFeatures(std::function<int32 *(int)> allocate_indices,
                        std::function<int64 *(int)> allocate_ids,
                        std::function<float *(int)> allocate_weights,
                        int channel_id) const override {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
-    return 0;
   }
   int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
-    return 0;
   }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override {
+    LOG(FATAL) << "[" << name_ << "] Method not supported";
+  }
+
   std::vector<LinkFeatures> GetRawLinkFeatures(int channel_id) const override {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
-    return {};
   }
   void AddTranslatedLinkFeaturesToTrace(
       const std::vector<LinkFeatures> &features, int channel_id) override {
diff --git a/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc b/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc
index 4a7d4331..a0126466 100644
--- a/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc
+++ b/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc
@@ -18,6 +18,7 @@
 #include "dragnn/core/test/generic.h"
 #include "dragnn/core/test/mock_transition_state.h"
 #include "dragnn/io/sentence_input_batch.h"
+#include "dragnn/protos/data.pb.h"
 #include "syntaxnet/base.h"
 #include "syntaxnet/sentence.pb.h"
 #include "tensorflow/core/lib/core/errors.h"
@@ -119,6 +120,10 @@ class StatelessComponentTest : public ::testing::Test {
     CHECK(TextFormat::ParseFromString(kMasterSpec, &master_spec));
     data_.reset(new InputBatchCache(data));
 
+    // The stateless component does not use any particular input batch type, and
+    // relies on the preceding components to convert the input batch.
+    data_->GetAs<SentenceInputBatch>();
+
     // Create a parser component with the specified beam size.
     std::unique_ptr<Component> parser_component(
         Component::Create("StatelessComponent"));
@@ -167,5 +172,37 @@ TEST_F(StatelessComponentTest, ForwardsTransitionStates) {
   EXPECT_EQ(parent_states, forwarded_states);
 }
 
+TEST_F(StatelessComponentTest, UnimplementedMethodsDie) {
+  MockTransitionState mock_state_1, mock_state_2, mock_state_3;
+  const std::vector<std::vector<const TransitionState *>> parent_states;
+  std::vector<string> data;
+  for (const string &textproto : {kSentence0, kSentence1, kLongSentence}) {
+    Sentence sentence;
+    CHECK(TextFormat::ParseFromString(textproto, &sentence));
+    data.emplace_back();
+    CHECK(sentence.SerializeToString(&data.back()));
+  }
+
+  const int kBeamSize = 2;
+  auto test_parser = CreateParser(kBeamSize, parent_states, data);
+
+  EXPECT_TRUE(test_parser->IsReady());
+  EXPECT_DEATH(test_parser->AdvanceFromPrediction({}, 0, 0),
+               "AdvanceFromPrediction not supported");
+  EXPECT_DEATH(test_parser->AdvanceFromOracle(),
+               "AdvanceFromOracle not supported");
+  EXPECT_DEATH(test_parser->GetOracleLabels(), "Method not supported");
+  EXPECT_DEATH(test_parser->GetFixedFeatures(nullptr, nullptr, nullptr, 0),
+               "Method not supported");
+  BulkFeatureExtractor extractor(nullptr, nullptr, nullptr);
+  EXPECT_DEATH(test_parser->BulkEmbedFixedFeatures(0, 0, 0, {nullptr}, nullptr),
+               "Method not supported");
+  EXPECT_DEATH(test_parser->BulkGetFixedFeatures(extractor),
+               "Method not supported");
+  EXPECT_DEATH(test_parser->GetRawLinkFeatures(0), "Method not supported");
+  EXPECT_DEATH(test_parser->AddTranslatedLinkFeaturesToTrace({}, 0),
+               "Method not supported");
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc
index f5df9e6b..6ebef622 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc
@@ -28,6 +28,7 @@
 #include "syntaxnet/sparse.pb.h"
 #include "syntaxnet/task_spec.pb.h"
 #include "syntaxnet/utils.h"
+#include "tensorflow/core/lib/strings/str_util.h"
 #include "tensorflow/core/platform/logging.h"
 
 namespace syntaxnet {
@@ -105,7 +106,7 @@ void SyntaxNetComponent::InitializeComponent(const ComponentSpec &spec) {
     dims.push_back(StrCat(channel.embedding_dim()));
   }
 
-  context.SetParameter("neurosis_feature_syntax_version", "2");
+
   context.SetParameter("brain_parser_embedding_dims", utils::Join(dims, ";"));
   context.SetParameter("brain_parser_predicate_maps",
                        utils::Join(predicate_maps, ";"));
@@ -187,8 +188,9 @@ std::unique_ptr<Beam<SyntaxNetTransitionState>> SyntaxNetComponent::CreateBeam(
     return this->IsFinal(state);
   };
   auto oracle_function = [this](SyntaxNetTransitionState *state) {
-    VLOG(2) << "oracle_function action:" << this->GetOracleLabel(state);
-    return this->GetOracleLabel(state);
+    VLOG(2) << "oracle_function action:"
+            << tensorflow::str_util::Join(this->GetOracleVector(state), ", ");
+    return this->GetOracleVector(state);
   };
   auto beam_ptr = beam.get();
   auto advance_function = [this, beam_ptr](SyntaxNetTransitionState *state,
@@ -335,25 +337,32 @@ std::function<int(int, int, int)> SyntaxNetComponent::GetStepLookupFunction(
   }
 }
 
-void SyntaxNetComponent::AdvanceFromPrediction(const float transition_matrix[],
-                                               int transition_matrix_length) {
-  VLOG(2) << "Advancing from prediction.";
-  int matrix_index = 0;
-  int num_labels = transition_system_->NumActions(label_map_->Size());
+bool SyntaxNetComponent::AdvanceFromPrediction(const float *transition_matrix,
+                                               int num_items, int num_actions) {
+  VLOG(2) << "Advancing from prediction, component = " << spec_.name();
+  const int num_static_actions =
+      transition_system_->NumActions(label_map_->Size());
+  if (num_static_actions != ParserTransitionSystem::kDynamicNumActions) {
+    CHECK_EQ(num_static_actions, num_actions)
+        << "[" << spec_.name()
+        << "] static action set does not match transition matrix";
+  }
   for (int i = 0; i < batch_.size(); ++i) {
-    int max_beam_size = batch_.at(i)->max_size();
-    int matrix_size = num_labels * max_beam_size;
-    CHECK_LE(matrix_index + matrix_size, transition_matrix_length);
-    if (!batch_.at(i)->IsTerminal()) {
-      batch_.at(i)->AdvanceFromPrediction(&transition_matrix[matrix_index],
-                                          matrix_size, num_labels);
+    const int size = num_actions * batch_[i]->max_size();
+    if (!batch_[i]->IsTerminal()) {
+      bool success = batch_[i]->AdvanceFromPrediction(transition_matrix, size,
+                                                      num_actions);
+      if (!success) {
+        return false;
+      }
     }
-    matrix_index += num_labels * max_beam_size;
+    transition_matrix += size;
   }
+  return true;
 }
 
 void SyntaxNetComponent::AdvanceFromOracle() {
-  VLOG(2) << "Advancing from oracle.";
+  VLOG(2) << "Advancing from oracle, component = " << spec_.name();
   for (auto &beam : batch_) {
     beam->AdvanceFromOracle();
   }
@@ -404,8 +413,18 @@ int SyntaxNetComponent::GetFixedFeatures(
         features.emplace_back(f);
         if (do_tracing_) {
           FixedFeatures fixed_features;
-          for (const string &name : f.description()) {
-            fixed_features.add_value_name(name);
+          CHECK_EQ(f.description_size(), f.id_size());
+          CHECK(f.weight_size() == 0 || f.weight_size() == f.id_size());
+          const bool has_weights = f.weight_size() != 0;
+          for (int i = 0; i < f.description_size(); ++i) {
+            if (has_weights) {
+              fixed_features.add_value_name(StrCat("id: ", f.id(i),
+                                                   " name: ", f.description(i),
+                                                   " weight: ", f.weight(i)));
+            } else {
+              fixed_features.add_value_name(
+                  StrCat("id: ", f.id(i), " name: ", f.description(i)));
+            }
           }
           fixed_features.set_feature_name("");
           auto *trace = GetLastStepInTrace(state->mutable_trace());
@@ -522,8 +541,8 @@ int SyntaxNetComponent::BulkGetFixedFeatures(
   // This would be a good place to add threading.
   for (int channel_id = 0; channel_id < num_channels; ++channel_id) {
     int feature_count = feature_counts[channel_id];
-    LOG(INFO) << "Feature count is " << feature_count << " for channel "
-              << channel_id;
+    VLOG(2) << "Feature count is " << feature_count << " for channel "
+            << channel_id;
     int32 *indices_tensor =
         extractor.AllocateIndexMemory(channel_id, feature_count);
     int64 *ids_tensor = extractor.AllocateIdMemory(channel_id, feature_count);
@@ -603,7 +622,9 @@ std::vector<std::vector<int>> SyntaxNetComponent::GetOracleLabels() const {
     for (int beam_idx = 0; beam_idx < beam->size(); ++beam_idx) {
       // Get the raw link features from the linked feature extractor.
       auto state = beam->beam_state(beam_idx);
-      oracle_labels.back().push_back(GetOracleLabel(state));
+
+      // Arbitrarily choose the first vector element.
+      oracle_labels.back().push_back(GetOracleVector(state).front());
     }
   }
   return oracle_labels;
@@ -661,13 +682,17 @@ bool SyntaxNetComponent::IsFinal(SyntaxNetTransitionState *state) const {
   return transition_system_->IsFinalState(*(state->parser_state()));
 }
 
-int SyntaxNetComponent::GetOracleLabel(SyntaxNetTransitionState *state) const {
+std::vector<int> SyntaxNetComponent::GetOracleVector(
+    SyntaxNetTransitionState *state) const {
   if (IsFinal(state)) {
     // It is not permitted to request an oracle label from a sentence that is
     // in a final state.
-    return -1;
+    return {-1};
   } else {
-    return transition_system_->GetNextGoldAction(*(state->parser_state()));
+    // TODO(googleuser): This should use the 'ParserAction' typedef.
+    std::vector<int> golds;
+    transition_system_->GetAllNextGoldActions(*(state->parser_state()), &golds);
+    return golds;
   }
 }
 
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h
index 303fcf77..02b0b3dc 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
+#ifndef DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
+#define DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
 
 #include <vector>
 
@@ -81,9 +81,10 @@ class SyntaxNetComponent : public Component {
   std::function<int(int, int, int)> GetStepLookupFunction(
       const string &method) override;
 
-  // Advances this component from the given transition matrix.
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int transition_matrix_length) override;
+  // Advances this component from the given transition matrix.Returns false
+  // if the component could not be advanced.
+  bool AdvanceFromPrediction(const float *transition_matrix, int num_items,
+                             int num_actions) override;
 
   // Advances this component from the state oracles.
   void AdvanceFromOracle() override;
@@ -105,6 +106,13 @@ class SyntaxNetComponent : public Component {
   // component via the oracle until it is terminal.
   int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override;
 
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_matrix) override {
+    LOG(FATAL) << "Method not supported";
+  }
+
   // Extracts and returns the vector of LinkFeatures for the specified
   // channel. Note: these are NOT translated.
   std::vector<LinkFeatures> GetRawLinkFeatures(int channel_id) const override;
@@ -145,13 +153,13 @@ class SyntaxNetComponent : public Component {
   bool IsFinal(SyntaxNetTransitionState *state) const;
 
   // Oracle function for this component.
-  int GetOracleLabel(SyntaxNetTransitionState *state) const;
+  std::vector<int> GetOracleVector(SyntaxNetTransitionState *state) const;
 
   // State advance function for this component.
   void Advance(SyntaxNetTransitionState *state, int action,
                Beam<SyntaxNetTransitionState> *beam);
 
-  // Creates a new state for the given nlp_saft::SentenceExample.
+  // Creates a new state for the given example.
   std::unique_ptr<SyntaxNetTransitionState> CreateState(
       SyntaxNetSentence *example);
 
@@ -195,4 +203,4 @@ class SyntaxNetComponent : public Component {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
+#endif  // DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc
index 52441ad3..62571187 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc
@@ -15,6 +15,8 @@
 
 #include "dragnn/components/syntaxnet/syntaxnet_component.h"
 
+#include <limits>
+
 #include "dragnn/core/input_batch_cache.h"
 #include "dragnn/core/test/generic.h"
 #include "dragnn/core/test/mock_transition_state.h"
@@ -197,8 +199,8 @@ TEST_F(SyntaxNetComponentTest, AdvancesFromPredictionAndTerminates) {
   // Transition the expected number of times.
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(transition_matrix,
-                                       kNumPossibleTransitions * kBeamSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(transition_matrix, kBeamSize,
+                                                   kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -225,6 +227,29 @@ TEST_F(SyntaxNetComponentTest, AdvancesFromPredictionAndTerminates) {
   // TODO(googleuser): What should the finalized data look like?
 }
 
+TEST_F(SyntaxNetComponentTest, AdvancesFromPredictionFailsWithNanWeights) {
+  // Create an empty input batch and beam vector to initialize the parser.
+  Sentence sentence_0;
+  TextFormat::ParseFromString(kSentence0, &sentence_0);
+  string sentence_0_str;
+  sentence_0.SerializeToString(&sentence_0_str);
+
+  auto test_parser = CreateParser({}, {sentence_0_str});
+
+  // There are 93 possible transitions for any given state. Create a transition
+  // array with a score of 10.0 for each transition.
+  constexpr int kBeamSize = 2;
+  constexpr int kNumPossibleTransitions = 93;
+  float transition_matrix[kNumPossibleTransitions * kBeamSize];
+  for (int i = 0; i < kNumPossibleTransitions * kBeamSize; ++i) {
+    transition_matrix[i] = std::numeric_limits<double>::quiet_NaN();
+  }
+
+  EXPECT_FALSE(test_parser->IsTerminal());
+  EXPECT_FALSE(test_parser->AdvanceFromPrediction(transition_matrix, kBeamSize,
+                                                  kNumPossibleTransitions));
+}
+
 TEST_F(SyntaxNetComponentTest, RetainsPassedTransitionStateData) {
   // Create and initialize the state->
   MockTransitionState mock_state_one;
@@ -269,8 +294,8 @@ TEST_F(SyntaxNetComponentTest, RetainsPassedTransitionStateData) {
   // Transition the expected number of times
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(transition_matrix,
-                                       kNumPossibleTransitions * kBeamSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(transition_matrix, kBeamSize,
+                                                   kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -326,8 +351,8 @@ TEST_F(SyntaxNetComponentTest, AdvancesFromPredictionForMultiSentenceBatches) {
   // Transition the expected number of times.
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(
-        transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+        transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -382,8 +407,8 @@ TEST_F(SyntaxNetComponentTest,
   constexpr int kExpectedNumTransitions = kNumTokensInLongSentence * 2;
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(
-        transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+        transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -467,7 +492,7 @@ TEST_F(SyntaxNetComponentTest, ResetAllowsReductionInBatchSize) {
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(parser_component->IsTerminal());
     parser_component->AdvanceFromPrediction(
-        transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+        transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions);
   }
 
   // At this point, the test parser should be terminal.
@@ -553,7 +578,7 @@ TEST_F(SyntaxNetComponentTest, ResetAllowsIncreaseInBatchSize) {
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(parser_component->IsTerminal());
     parser_component->AdvanceFromPrediction(
-        transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+        transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions);
   }
 
   // At this point, the test parser should be terminal.
@@ -611,8 +636,8 @@ TEST_F(SyntaxNetComponentTest, ResetCausesBeamToReset) {
   // Transition the expected number of times.
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(transition_matrix,
-                                       kNumPossibleTransitions * kBeamSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(transition_matrix, kBeamSize,
+                                                   kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -823,10 +848,10 @@ TEST_F(SyntaxNetComponentTest, ExportsFixedFeatures) {
   }
 
   // Advance twice, so that the underlying parser fills the beam.
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
 
   // Get and check the raw link features.
   vector<int32> indices;
@@ -907,10 +932,10 @@ TEST_F(SyntaxNetComponentTest, AdvancesAccordingToHighestWeightedInputOption) {
   transition_matrix[kBatchOffset + 5] = 2 * kTransitionValue;
 
   // Advance twice, so that the underlying parser fills the beam.
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
 
   // Get and check the raw link features.
   vector<int32> indices;
@@ -1112,10 +1137,10 @@ TEST_F(SyntaxNetComponentTest, ExportsRawLinkFeatures) {
   }
 
   // Advance twice, so that the underlying parser fills the beam.
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
 
   // Get and check the raw link features.
   constexpr int kNumLinkFeatures = 2;
@@ -1269,5 +1294,21 @@ TEST_F(SyntaxNetComponentTest, TracingOutputsFeatureNames) {
   EXPECT_EQ(link_features.at(1).feature_name(), "stack(1).focus");
 }
 
+TEST_F(SyntaxNetComponentTest, BulkEmbedFixedFeaturesIsNotSupported) {
+  // Create an empty input batch and beam vector to initialize the parser.
+  Sentence sentence_0;
+
+  // TODO(googleuser): Wrap this in a lint-friendly helper function.
+  TextFormat::ParseFromString(kSentence0, &sentence_0);
+  string sentence_0_str;
+  sentence_0.SerializeToString(&sentence_0_str);
+
+  constexpr int kBeamSize = 1;
+  auto test_parser = CreateParserWithBeamSize(kBeamSize, {}, {sentence_0_str});
+  EXPECT_TRUE(test_parser->IsReady());
+  EXPECT_DEATH(test_parser->BulkEmbedFixedFeatures(0, 0, 0, {nullptr}, nullptr),
+               "Method not supported");
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h
index 4d94cfb5..d58aac88 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
+#ifndef DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
+#define DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
 
 #include <string>
 #include <vector>
@@ -29,12 +29,8 @@ namespace syntaxnet {
 namespace dragnn {
 
 // Provides feature extraction for linked features in the
-// WrapperParserComponent. This re-ues the EmbeddingFeatureExtractor
-// architecture to get another set of feature extractors. Note that we should
-// ignore predicate maps here, and we don't care about the vocabulary size
-// because all the feature values will be used for translation, but this means
-// we can configure the extractor from the GCL using the standard
-// neurosis-lib.wf syntax.
+// WrapperParserComponent. This re-uses the EmbeddingFeatureExtractor
+// architecture to get another set of feature extractors.
 //
 // Because it uses a different prefix, it can be executed in the same wf.stage
 // as the regular fixed extractor.
@@ -67,4 +63,4 @@ class SyntaxNetLinkFeatureExtractor : public ParserEmbeddingFeatureExtractor {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
+#endif  // DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc
index 7d5f2188..b4baa95f 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc
@@ -34,7 +34,7 @@ class ExportSpecTest : public ::testing::Test {
 TEST_F(ExportSpecTest, WritesChannelSpec) {
   TaskContext context;
 
-  context.SetParameter("neurosis_feature_syntax_version", "2");
+
   context.SetParameter("link_features", "input.focus;stack.focus");
   context.SetParameter("link_embedding_names", "tagger;parser");
   context.SetParameter("link_predicate_maps", "none;none");
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc
index a15e883b..b41c9ec3 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc
@@ -23,7 +23,9 @@ namespace dragnn {
 
 SyntaxNetTransitionState::SyntaxNetTransitionState(
     std::unique_ptr<ParserState> parser_state, SyntaxNetSentence *sentence)
-    : parser_state_(std::move(parser_state)), sentence_(sentence) {
+    : parser_state_(std::move(parser_state)),
+      sentence_(sentence),
+      is_gold_(false) {
   score_ = 0;
   current_beam_index_ = -1;
   parent_beam_index_ = 0;
@@ -60,21 +62,25 @@ std::unique_ptr<SyntaxNetTransitionState> SyntaxNetTransitionState::Clone()
   return new_state;
 }
 
-const int SyntaxNetTransitionState::ParentBeamIndex() const {
+int SyntaxNetTransitionState::ParentBeamIndex() const {
   return parent_beam_index_;
 }
 
-const int SyntaxNetTransitionState::GetBeamIndex() const {
+int SyntaxNetTransitionState::GetBeamIndex() const {
   return current_beam_index_;
 }
 
-void SyntaxNetTransitionState::SetBeamIndex(const int index) {
+bool SyntaxNetTransitionState::IsGold() const { return is_gold_; }
+
+void SyntaxNetTransitionState::SetGold(bool is_gold) { is_gold_ = is_gold; }
+
+void SyntaxNetTransitionState::SetBeamIndex(int index) {
   current_beam_index_ = index;
 }
 
-const float SyntaxNetTransitionState::GetScore() const { return score_; }
+float SyntaxNetTransitionState::GetScore() const { return score_; }
 
-void SyntaxNetTransitionState::SetScore(const float score) { score_ = score; }
+void SyntaxNetTransitionState::SetScore(float score) { score_ = score; }
 
 string SyntaxNetTransitionState::HTMLRepresentation() const {
   // Crude HTML string showing the stack and the word on the input.
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h
index 193b33f5..3b37d762 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
+#ifndef DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
+#define DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
 
 #include <vector>
 
@@ -31,11 +31,11 @@ namespace dragnn {
 class SyntaxNetTransitionState
     : public CloneableTransitionState<SyntaxNetTransitionState> {
  public:
-  // Create a SyntaxNetTransitionState to wrap this nlp_saft::ParserState.
+  // Creates a SyntaxNetTransitionState to wrap this ParserState.
   SyntaxNetTransitionState(std::unique_ptr<ParserState> parser_state,
                            SyntaxNetSentence *sentence);
 
-  // Initialize this TransitionState from a previous TransitionState. The
+  // Initializes this TransitionState from a previous TransitionState. The
   // ParentBeamIndex is the location of that previous TransitionState in the
   // provided beam.
   void Init(const TransitionState &parent) override;
@@ -43,21 +43,27 @@ class SyntaxNetTransitionState
   // Produces a new state with the same backing data as this state.
   std::unique_ptr<SyntaxNetTransitionState> Clone() const override;
 
-  // Return the beam index of the state passed into the initializer of this
+  // Returns the beam index of the state passed into the initializer of this
   // TransitionState.
-  const int ParentBeamIndex() const override;
+  int ParentBeamIndex() const override;
 
-  // Get the current beam index for this state.
-  const int GetBeamIndex() const override;
+  // Gets the current beam index for this state.
+  int GetBeamIndex() const override;
 
-  // Set the current beam index for this state.
-  void SetBeamIndex(const int index) override;
+  // Sets the current beam index for this state.
+  void SetBeamIndex(int index) override;
 
-  // Get the score associated with this transition state.
-  const float GetScore() const override;
+  // Gets the score associated with this transition state.
+  float GetScore() const override;
 
-  // Set the score associated with this transition state.
-  void SetScore(const float score) override;
+  // Sets the score associated with this transition state.
+  void SetScore(float score) override;
+
+  // Gets the state's gold-ness (if it is on or consistent with the oracle path)
+  bool IsGold() const override;
+
+  // Sets the gold-ness of this state.
+  void SetGold(bool is_gold) override;
 
   // Depicts this state as an HTML-language string.
   string HTMLRepresentation() const override;
@@ -108,7 +114,7 @@ class SyntaxNetTransitionState
     parent_for_token_.insert(parent_for_token_.begin() + token, parent);
   }
 
-  // Accessor for the underlying nlp_saft::ParserState.
+  // Accessor for the underlying ParserState.
   ParserState *parser_state() { return parser_state_.get(); }
 
   // Accessor for the underlying sentence object.
@@ -151,9 +157,12 @@ class SyntaxNetTransitionState
 
   // Trace of the history to produce this state.
   std::unique_ptr<ComponentTrace> trace_;
+
+  // True if this state is gold.
+  bool is_gold_;
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
+#endif  // DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc
index ab4ab303..a30b09ce 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc
@@ -134,6 +134,22 @@ TEST_F(SyntaxNetTransitionStateTest, CanSetAndGetScore) {
   EXPECT_EQ(test_state->GetScore(), kNewScore);
 }
 
+// Validates the consistency of the goldness setter and getter.
+TEST_F(SyntaxNetTransitionStateTest, CanSetAndGetGold) {
+  // Create and initialize a test state.
+  MockTransitionState mock_state;
+  auto test_state = CreateState();
+  test_state->Init(mock_state);
+
+  constexpr bool kOldGold = true;
+  test_state->SetGold(kOldGold);
+  EXPECT_EQ(test_state->IsGold(), kOldGold);
+
+  constexpr bool kNewGold = false;
+  test_state->SetGold(kNewGold);
+  EXPECT_EQ(test_state->IsGold(), kNewGold);
+}
+
 // This test ensures that the initializing state's current index is saved
 // as the parent beam index of the state being initialized.
 TEST_F(SyntaxNetTransitionStateTest, ReportsParentBeamIndex) {
diff --git a/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h b/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h
index 9fbd08a2..6e07f688 100644
--- a/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h
+++ b/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
+#ifndef DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
+#define DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
 
 #include <functional>
 #include <utility>
@@ -107,4 +107,4 @@ class BulkFeatureExtractor {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
+#endif  // DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
diff --git a/research/syntaxnet/dragnn/config_builder/__init__.py b/research/syntaxnet/dragnn/config_builder/__init__.py
new file mode 100644
index 00000000..e69de29b
diff --git a/research/syntaxnet/dragnn/core/BUILD b/research/syntaxnet/dragnn/core/BUILD
index 24978ab7..a52e91fb 100644
--- a/research/syntaxnet/dragnn/core/BUILD
+++ b/research/syntaxnet/dragnn/core/BUILD
@@ -33,8 +33,9 @@ cc_library(
     name = "compute_session",
     hdrs = ["compute_session.h"],
     deps = [
+        ":index_translator",
+        ":input_batch_cache",
         "//dragnn/components/util:bulk_feature_extractor",
-        "//dragnn/core:index_translator",
         "//dragnn/core/interfaces:component",
         "//dragnn/protos:spec_proto",
         "//dragnn/protos:trace_proto",
@@ -120,8 +121,10 @@ cc_test(
         ":compute_session",
         ":compute_session_impl",
         ":compute_session_pool",
+        ":input_batch_cache",
         "//dragnn/components/util:bulk_feature_extractor",
         "//dragnn/core/interfaces:component",
+        "//dragnn/core/interfaces:input_batch",
         "//dragnn/core/test:generic",
         "//dragnn/core/test:mock_component",
         "//dragnn/core/test:mock_transition_state",
@@ -248,6 +251,7 @@ cc_library(
         "//syntaxnet:base",
         "@org_tensorflow//third_party/eigen3",
     ],
+    alwayslink = 1,
 )
 
 # Tensorflow kernel libraries, for use with unit tests.
diff --git a/research/syntaxnet/dragnn/core/beam.h b/research/syntaxnet/dragnn/core/beam.h
index 534cfcd0..1529aef9 100644
--- a/research/syntaxnet/dragnn/core/beam.h
+++ b/research/syntaxnet/dragnn/core/beam.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_BEAM_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_BEAM_H_
+#ifndef DRAGNN_CORE_BEAM_H_
+#define DRAGNN_CORE_BEAM_H_
 
 #include <algorithm>
 #include <cmath>
@@ -43,19 +43,23 @@ class Beam {
     static_assert(
         std::is_base_of<CloneableTransitionState<T>, T>::value,
         "This class must be instantiated to use a CloneableTransitionState");
+    track_gold_ = false;
   }
 
+  // Sets whether or not the beam should track gold states.
+  void SetGoldTracking(bool track_gold) { track_gold_ = track_gold; }
+
   // Sets the Beam functions, as follows:
   // bool is_allowed(TransitionState *, int): Return true if transition 'int' is
   //   allowed for transition state 'TransitionState *'.
   // void perform_transition(TransitionState *, int): Performs transition 'int'
   //   on transition state 'TransitionState *'.
-  // int oracle_function(TransitionState *): Returns the oracle-specified action
-  //   for transition state 'TransitionState *'.
+  // vector<int> oracle_function(TransitionState *): Returns the oracle-
+  //   specified actions for transition state 'TransitionState *'.
   void SetFunctions(std::function<bool(T *, int)> is_allowed,
                     std::function<bool(T *)> is_final,
                     std::function<void(T *, int)> perform_transition,
-                    std::function<int(T *)> oracle_function) {
+                    std::function<vector<int>(T *)> oracle_function) {
     is_allowed_ = is_allowed;
     is_final_ = is_final;
     perform_transition_ = perform_transition;
@@ -74,12 +78,17 @@ class Beam {
     for (int i = 0; i < beam_.size(); ++i) {
       previous_beam_indices.at(i) = beam_[i]->ParentBeamIndex();
       beam_[i]->SetBeamIndex(i);
+
+      // TODO(googleuser): Add gold tracking to component-level state creation.
+      if (!track_gold_) {
+        beam_[i]->SetGold(false);
+      }
     }
     beam_index_history_.emplace_back(previous_beam_indices);
   }
 
   // Advances the Beam from the given transition matrix.
-  void AdvanceFromPrediction(const float transition_matrix[], int matrix_length,
+  bool AdvanceFromPrediction(const float *transition_matrix, int matrix_length,
                              int num_actions) {
     // Ensure that the transition matrix is the correct size. All underlying
     // states should have the same transition profile, so using the one at 0
@@ -89,91 +98,20 @@ class Beam {
            "state transitions!";
 
     if (max_size_ == 1) {
-      // In the case where beam size is 1, we can advance by simply finding the
-      // highest score and advancing the beam state in place.
-      VLOG(2) << "Beam size is 1. Using fast beam path.";
-      int best_action = -1;
-      float best_score = -INFINITY;
-      auto &state = beam_[0];
-      for (int action_idx = 0; action_idx < num_actions; ++action_idx) {
-        if (is_allowed_(state.get(), action_idx) &&
-            transition_matrix[action_idx] > best_score) {
-          best_score = transition_matrix[action_idx];
-          best_action = action_idx;
-        }
+      bool success = FastAdvanceFromPrediction(transition_matrix, num_actions);
+      if (!success) {
+        return false;
       }
-      CHECK_GE(best_action, 0) << "Num actions: " << num_actions
-                               << " score[0]: " << transition_matrix[0];
-      perform_transition_(state.get(), best_action);
-      const float new_score = state->GetScore() + best_score;
-      state->SetScore(new_score);
-      state->SetBeamIndex(0);
     } else {
-      // Create the vector of all possible transitions, along with their scores.
-      std::vector<Transition> candidates;
-
-      // Iterate through all beams, examining all actions for each beam.
-      for (int beam_idx = 0; beam_idx < beam_.size(); ++beam_idx) {
-        const auto &state = beam_[beam_idx];
-        for (int action_idx = 0; action_idx < num_actions; ++action_idx) {
-          // If the action is allowed, calculate the proposed new score and add
-          // the candidate action to the vector of all actions at this state.
-          if (is_allowed_(state.get(), action_idx)) {
-            Transition candidate;
-
-            // The matrix is laid out by beam index, with a linear set of
-            // actions for that index - so beam N's actions start at [nr. of
-            // actions]*[N].
-            const int matrix_idx = action_idx + beam_idx * num_actions;
-            CHECK_LT(matrix_idx, matrix_length)
-                << "Matrix index out of bounds!";
-            const double score_delta = transition_matrix[matrix_idx];
-            CHECK(!std::isnan(score_delta));
-            candidate.source_idx = beam_idx;
-            candidate.action = action_idx;
-            candidate.resulting_score = state->GetScore() + score_delta;
-            candidates.emplace_back(candidate);
-          }
-        }
-      }
-
-      // Sort the vector of all possible transitions and scores.
-      const auto comparator = [](const Transition &a, const Transition &b) {
-        return a.resulting_score > b.resulting_score;
-      };
-      std::stable_sort(candidates.begin(), candidates.end(), comparator);
-
-      // Apply the top transitions, up to a maximum of 'max_size_'.
-      std::vector<std::unique_ptr<T>> new_beam;
-      std::vector<int> previous_beam_indices(max_size_, -1);
-      const int beam_size =
-          std::min(max_size_, static_cast<int>(candidates.size()));
-      VLOG(2) << "Previous beam size = " << beam_.size();
-      VLOG(2) << "New beam size = " << beam_size;
-      VLOG(2) << "Maximum beam size = " << max_size_;
-      for (int i = 0; i < beam_size; ++i) {
-        // Get the source of the i'th transition.
-        const auto &transition = candidates[i];
-        VLOG(2) << "Taking transition with score: "
-                << transition.resulting_score
-                << " and action: " << transition.action;
-        VLOG(2) << "transition.source_idx = " << transition.source_idx;
-        const auto &source = beam_[transition.source_idx];
-
-        // Put the new transition on the new state beam.
-        auto new_state = source->Clone();
-        perform_transition_(new_state.get(), transition.action);
-        new_state->SetScore(transition.resulting_score);
-        new_state->SetBeamIndex(i);
-        previous_beam_indices.at(i) = transition.source_idx;
-        new_beam.emplace_back(std::move(new_state));
+      bool success = BeamAdvanceFromPrediction(transition_matrix, matrix_length,
+                                               num_actions);
+      if (!success) {
+        return false;
       }
-
-      beam_ = std::move(new_beam);
-      beam_index_history_.emplace_back(previous_beam_indices);
     }
 
     ++num_steps_;
+    return true;
   }
 
   // Advances the Beam from the state oracles.
@@ -182,7 +120,10 @@ class Beam {
     for (int i = 0; i < beam_.size(); ++i) {
       previous_beam_indices.at(i) = i;
       if (is_final_(beam_[i].get())) continue;
-      const auto oracle_label = oracle_function_(beam_[i].get());
+
+      // There will always be at least one oracular transition, and taking the
+      // first returned transition is never worse than any other option.
+      const int oracle_label = oracle_function_(beam_[i].get()).at(0);
       VLOG(2) << "AdvanceFromOracle beam_index:" << i
               << " oracle_label:" << oracle_label;
       perform_transition_(beam_[i].get(), oracle_label);
@@ -312,19 +253,180 @@ class Beam {
   // Returns the current size of the beam.
   const int size() const { return beam_.size(); }
 
+  // Returns true if at least one of the states in the beam is gold.
+  bool ContainsGold() {
+    if (!track_gold_) {
+      return false;
+    }
+    for (const auto &state : beam_) {
+      if (state->IsGold()) {
+        return true;
+      }
+    }
+    return false;
+  }
+
  private:
-  // Associates an action taken on an index into current_state_ with a score.
+  friend void BM_FastAdvance(int num_iters, int num_transitions);
+  friend void BM_BeamAdvance(int num_iters, int num_transitions,
+                             int max_beam_size);
+
+  // Associates an action taken with its source index.
   struct Transition {
     // The index of the source item.
     int source_idx;
 
     // The index of the action being taken.
     int action;
-
-    // The score of the full derivation.
-    double resulting_score;
   };
 
+  // In the case where beam size is 1, we can advance by simply finding the
+  // highest score and advancing the beam state in place.
+  bool FastAdvanceFromPrediction(const float *transition_matrix,
+                                 int num_actions) {
+    CHECK_EQ(1, max_size_)
+        << "Using fast advance on invalid beam. This should never happen.";
+    VLOG(2) << "Beam size is 1. Using fast beam path.";
+    constexpr int kNoActionChosen = -1;
+    int best_action = kNoActionChosen;
+    float best_score = -INFINITY;
+    auto &state = beam_[0];
+    for (int action_idx = 0; action_idx < num_actions; ++action_idx) {
+      if (std::isnan(transition_matrix[action_idx])) {
+        LOG(ERROR) << "Found a NaN in the transition matrix! Unable to "
+                      "continue. Num actions: "
+                   << num_actions << " index: " << action_idx;
+        return false;
+      }
+      if (is_allowed_(state.get(), action_idx) &&
+          transition_matrix[action_idx] > best_score) {
+        best_score = transition_matrix[action_idx];
+        best_action = action_idx;
+      }
+    }
+    if (best_action == kNoActionChosen) {
+      LOG(ERROR) << "No action was chosen! Unable to continue. Num actions: "
+                 << num_actions << " score[0]: " << transition_matrix[0];
+      return false;
+    }
+    bool is_gold = false;
+    if (track_gold_ && state->IsGold()) {
+      for (const auto &gold_transition : oracle_function_(state.get())) {
+        VLOG(3) << "Examining gold transition " << gold_transition
+                << " for source index 1";
+        if (gold_transition == best_action) {
+          is_gold = true;
+          break;
+        }
+      }
+    }
+    perform_transition_(state.get(), best_action);
+    const float new_score = state->GetScore() + best_score;
+    state->SetScore(new_score);
+    state->SetBeamIndex(0);
+    state->SetGold(is_gold);
+    return true;
+  }
+
+  // In case the beam size is greater than 1, we need to advance using
+  // standard beam search.
+  bool BeamAdvanceFromPrediction(const float *transition_matrix,
+                                 int matrix_length, int num_actions) {
+    VLOG(2) << "Beam size is " << max_size_ << ". Using standard beam search.";
+
+    // Keep the multimap sorted high to low. The sort order for
+    // identical keys is stable.
+    std::multimap<float, Transition, std::greater<float>> candidates;
+    float threshold = -INFINITY;
+
+    // Iterate through all beams, examining all actions for each beam.
+    for (int beam_idx = 0; beam_idx < beam_.size(); ++beam_idx) {
+      const auto &state = beam_[beam_idx];
+      const float score = state->GetScore();
+      for (int action_idx = 0; action_idx < num_actions; ++action_idx) {
+        if (is_allowed_(state.get(), action_idx)) {
+          // The matrix is laid out by beam index, with a linear set of
+          // actions for that index - so beam N's actions start at [nr. of
+          // actions]*[N].
+          const int matrix_idx = action_idx + beam_idx * num_actions;
+          CHECK_LT(matrix_idx, matrix_length) << "Matrix index out of bounds!";
+          const float resulting_score = score + transition_matrix[matrix_idx];
+          if (std::isnan(resulting_score)) {
+            LOG(ERROR) << "Resulting score was a NaN! Unable to continue. Num "
+                          "actions: "
+                       << num_actions << " action index " << action_idx;
+            return false;
+          }
+          if (candidates.size() == max_size_) {
+            // If the new score is lower than the bottom of the beam, move on.
+            if (resulting_score < threshold) {
+              continue;
+            }
+
+            // Otherwise, remove the bottom of the beam, making space
+            // for the new candidate.
+            candidates.erase(std::prev(candidates.end()));
+          }
+
+          // Add the new candidate, and update the threshold score.
+          const Transition candidate{beam_idx, action_idx};
+          candidates.emplace(resulting_score, candidate);
+          threshold = candidates.rbegin()->first;
+        }
+      }
+    }
+
+    // Apply the top transitions, up to a maximum of 'max_size_'.
+    std::vector<std::unique_ptr<T>> new_beam;
+    std::vector<int> previous_beam_indices(max_size_, -1);
+    const int beam_size = candidates.size();
+    new_beam.reserve(max_size_);
+    VLOG(2) << "Previous beam size = " << beam_.size();
+    VLOG(2) << "New beam size = " << beam_size;
+    VLOG(2) << "Maximum beam size = " << max_size_;
+    auto candidate_iterator = candidates.cbegin();
+    for (int i = 0; i < beam_size; ++i) {
+      // Get the score and source of the i'th transition.
+      const float resulting_score = candidate_iterator->first;
+      const auto &transition = candidate_iterator->second;
+      ++candidate_iterator;
+      VLOG(2) << "Taking transition with score: " << resulting_score
+              << " and action: " << transition.action;
+      VLOG(2) << "transition.source_idx = " << transition.source_idx;
+      const auto &source = beam_[transition.source_idx];
+
+      // Determine if the transition being taken will result in a gold state.
+      bool is_gold = false;
+      if (track_gold_ && source->IsGold()) {
+        for (const auto &gold_transition : oracle_function_(source.get())) {
+          VLOG(3) << "Examining gold transition " << gold_transition
+                  << " for source index " << transition.source_idx;
+          if (gold_transition == transition.action) {
+            VLOG(2) << "State from index " << transition.source_idx
+                    << " is gold.";
+            is_gold = true;
+            break;
+          }
+        }
+      }
+      VLOG(2) << "Gold examination complete for source index "
+              << transition.source_idx;
+
+      // Put the new transition on the new state beam.
+      auto new_state = source->Clone();
+      perform_transition_(new_state.get(), transition.action);
+      new_state->SetScore(resulting_score);
+      new_state->SetBeamIndex(i);
+      new_state->SetGold(is_gold);
+      previous_beam_indices.at(i) = transition.source_idx;
+      new_beam.emplace_back(std::move(new_state));
+    }
+
+    beam_ = std::move(new_beam);
+    beam_index_history_.emplace_back(previous_beam_indices);
+    return true;
+  }
+
   // The maximum beam size.
   int max_size_;
 
@@ -341,7 +443,7 @@ class Beam {
   std::function<void(T *, int)> perform_transition_;
 
   // Function to provide the oracle action for a given state.
-  std::function<int(T *)> oracle_function_;
+  std::function<vector<int>(T *)> oracle_function_;
 
   // The history of the states in this beam. The vector indexes across steps.
   // For every step, there is a vector in the vector. This inner vector denotes
@@ -355,9 +457,12 @@ class Beam {
 
   // The number of steps taken so far.
   int num_steps_;
+
+  // Whether to track golden states.
+  bool track_gold_;
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_BEAM_H_
+#endif  // DRAGNN_CORE_BEAM_H_
diff --git a/research/syntaxnet/dragnn/core/beam_test.cc b/research/syntaxnet/dragnn/core/beam_test.cc
index 7ff1f329..f4b8dc8d 100644
--- a/research/syntaxnet/dragnn/core/beam_test.cc
+++ b/research/syntaxnet/dragnn/core/beam_test.cc
@@ -15,11 +15,15 @@
 
 #include "dragnn/core/beam.h"
 
+#include <limits>
+#include <random>
+
 #include "dragnn/core/interfaces/cloneable_transition_state.h"
 #include "dragnn/core/interfaces/transition_state.h"
 #include "dragnn/core/test/mock_transition_state.h"
 #include <gmock/gmock.h>
 #include "tensorflow/core/platform/test.h"
+#include "tensorflow/core/platform/test_benchmark.h"
 
 namespace syntaxnet {
 namespace dragnn {
@@ -43,7 +47,7 @@ namespace {
 class TestTransitionState
     : public CloneableTransitionState<TestTransitionState> {
  public:
-  TestTransitionState() {}
+  TestTransitionState() : is_gold_(false) {}
 
   void Init(const TransitionState &parent) override {}
 
@@ -52,19 +56,25 @@ class TestTransitionState
     return ptr;
   }
 
-  const int ParentBeamIndex() const override { return parent_beam_index_; }
+  int ParentBeamIndex() const override { return parent_beam_index_; }
+
+  // Gets the current beam index for this state.
+  int GetBeamIndex() const override { return beam_index_; }
 
-  // Get the current beam index for this state.
-  const int GetBeamIndex() const override { return beam_index_; }
+  // Sets the current beam index for this state.
+  void SetBeamIndex(int index) override { beam_index_ = index; }
 
-  // Set the current beam index for this state.
-  void SetBeamIndex(const int index) override { beam_index_ = index; }
+  // Gets the score associated with this transition state.
+  float GetScore() const override { return score_; }
 
-  // Get the score associated with this transition state.
-  const float GetScore() const override { return score_; }
+  // Sets the score associated with this transition state.
+  void SetScore(float score) override { score_ = score; }
 
-  // Set the score associated with this transition state.
-  void SetScore(const float score) override { score_ = score; }
+  // Gets the gold-ness of this state (whether it is on the oracle path)
+  bool IsGold() const override { return is_gold_; }
+
+  // Sets the gold-ness of this state.
+  void SetGold(bool is_gold) override { is_gold_ = is_gold; }
 
   // Depicts this state as an HTML-language string.
   string HTMLRepresentation() const override { return ""; }
@@ -76,6 +86,8 @@ class TestTransitionState
   float score_;
 
   int transition_action_;
+
+  bool is_gold_;
 };
 
 // This transition function annotates a TestTransitionState with the action that
@@ -85,12 +97,14 @@ auto transition_function = [](TestTransitionState *state, int action) {
   cast_state->transition_action_ = action;
 };
 
-// Create oracle and permission functions that do nothing.
-auto null_oracle = [](TestTransitionState *) { return 0; };
+// Creates oracle and permission functions that do nothing.
+auto null_oracle = [](TestTransitionState *) -> const vector<int> {
+  return {0};
+};
 auto null_permissions = [](TestTransitionState *, int) { return true; };
 auto null_finality = [](TestTransitionState *) { return false; };
 
-// Create a unique_ptr with a test transition state in it and set its initial
+// Creates a unique_ptr with a test transition state in it and set its initial
 // score.
 std::unique_ptr<TestTransitionState> CreateState(float score) {
   std::unique_ptr<TestTransitionState> state;
@@ -99,6 +113,16 @@ std::unique_ptr<TestTransitionState> CreateState(float score) {
   return state;
 }
 
+// Creates a unique_ptr with a test transition state in it and set its initial
+// score. Also, set gold-ness to TRUE.
+std::unique_ptr<TestTransitionState> CreateGoldState(float score) {
+  std::unique_ptr<TestTransitionState> state;
+  state.reset(new TestTransitionState());
+  state->SetScore(score);
+  state->SetGold(true);
+  return state;
+}
+
 // Convenience accessor for the action field in TestTransitionState.
 int GetTransition(const TransitionState *state) {
   return (dynamic_cast<const TestTransitionState *>(state))->transition_action_;
@@ -114,11 +138,51 @@ void SetParentBeamIndex(TransitionState *state, int index) {
 // *****************************************************************************
 // Tests begin here.
 // *****************************************************************************
+TEST(BeamTest, AdvancesFromPredictionWithSingleBeamReturnsFalseOnNan) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kNan = std::numeric_limits<double>::quiet_NaN();
+  constexpr float kTransitionMatrix[kMatrixSize] = {1.0, kNan, 2.0, 3.0};
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+  EXPECT_FALSE(beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize,
+                                          kNumTransitions));
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithSingleBeamReturnsFalseOnNoneAllowed) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+  auto empty_permissions = [](TestTransitionState *, int) { return false; };
+  beam.SetFunctions(empty_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+  EXPECT_FALSE(beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize,
+                                          kNumTransitions));
+}
+
 TEST(BeamTest, AdvancesFromPredictionWithSingleBeam) {
   // Create a matrix of transitions.
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = kNumTransitions;
-  constexpr float matrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
   constexpr int kBestTransition = 2;
   constexpr float kOldScore = 3.0;
 
@@ -130,7 +194,7 @@ TEST(BeamTest, AdvancesFromPredictionWithSingleBeam) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), kBeamSize);
@@ -139,7 +203,8 @@ TEST(BeamTest, AdvancesFromPredictionWithSingleBeam) {
   EXPECT_EQ(GetTransition(beam.beam().at(0)), kBestTransition);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + matrix[kBestTransition]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(),
+            kOldScore + kTransitionMatrix[kBestTransition]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   EXPECT_EQ(beam.beam().at(0)->GetBeamIndex(), 0);
@@ -152,12 +217,166 @@ TEST(BeamTest, AdvancesFromPredictionWithSingleBeam) {
   EXPECT_EQ(history.at(1).at(0), 0);
 }
 
+TEST(BeamTest, NewlyCreatedStatesWithTrackingOffAreNotGold) {
+  // Create the beam.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  constexpr float kOldScore = 3.0;
+  states.push_back(CreateGoldState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+
+  // SetGoldTracking is false by default.
+  beam.SetGoldTracking(false);
+  beam.Init(std::move(states));
+
+  // Validate that the beam still has a gold state in it.
+  EXPECT_FALSE(beam.ContainsGold());
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithSingleBeamAndGoldTracking) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr int kBestTransition = 2;
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateGoldState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+
+  // Create an oracle that indicates the best transition is index 2.
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {1, 2};
+  EXPECT_CALL(mock_oracle_function, Call(_)).WillOnce(Return(oracle_labels));
+
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate the new beam.
+  EXPECT_EQ(beam.beam().size(), kBeamSize);
+
+  // Make sure the state has performed the expected transition.
+  EXPECT_EQ(GetTransition(beam.beam()[0]), kBestTransition);
+
+  // Make sure the state has had its score updated properly.
+  EXPECT_EQ(beam.beam()[0]->GetScore(),
+            kOldScore + kTransitionMatrix[kBestTransition]);
+
+  // Make sure that the beam index field is consistent with the actual beam idx.
+  EXPECT_EQ(beam.beam()[0]->GetBeamIndex(), 0);
+
+  // Make sure that the beam_state accessor actually accesses the beam.
+  EXPECT_EQ(beam.beam()[0], beam.beam_state(0));
+
+  // Validate the beam history field.
+  auto history = beam.history();
+  EXPECT_EQ(history[1][0], 0);
+
+  // Validate that the beam still has a gold state in it.
+  EXPECT_TRUE(beam.ContainsGold());
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithSingleBeamAndGoldTrackingFalloff) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr int kBestTransition = 2;
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateGoldState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+
+  // Create an oracle that indicates the best transition is NOT index 2.
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {0, 1};
+  EXPECT_CALL(mock_oracle_function, Call(_)).WillOnce(Return(oracle_labels));
+
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate the new beam.
+  EXPECT_EQ(beam.beam().size(), kBeamSize);
+
+  // Make sure the state has performed the expected transition.
+  EXPECT_EQ(GetTransition(beam.beam()[0]), kBestTransition);
+
+  // Make sure the state has had its score updated properly.
+  EXPECT_EQ(beam.beam()[0]->GetScore(),
+            kOldScore + kTransitionMatrix[kBestTransition]);
+
+  // Make sure that the beam index field is consistent with the actual beam idx.
+  EXPECT_EQ(beam.beam()[0]->GetBeamIndex(), 0);
+
+  // Make sure that the beam_state accessor actually accesses the beam.
+  EXPECT_EQ(beam.beam()[0], beam.beam_state(0));
+
+  // Validate the beam history field.
+  auto history = beam.history();
+  EXPECT_EQ(history[1][0], 0);
+
+  // Validate that the beam has no gold state in it.
+  EXPECT_FALSE(beam.ContainsGold());
+}
+
+TEST(BeamTest, NonGoldBeamDoesNotInvokeOracle) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateGoldState(kOldScore));
+  auto first_state = states[0].get();
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+
+  // Create an oracle that indicates the best transition is NOT index 2.
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {0, 1};
+  EXPECT_CALL(mock_oracle_function, Call(first_state))
+      .WillOnce(Return(oracle_labels));
+
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate that the beam has no gold state in it.
+  EXPECT_FALSE(beam.ContainsGold());
+
+  // Advance again. Since the oracle function above expects to be called exactly
+  // once, another call should not match and cause a failure.
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+}
+
 TEST(BeamTest, AdvancingCreatesNewTransitions) {
   // Create a matrix of transitions.
   constexpr int kMaxBeamSize = 8;
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
-  constexpr float matrix[kMatrixSize] = {
+  constexpr float kTransitionMatrix[kMatrixSize] = {
       30.0, 20.0, 40.0, 10.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
       00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
       00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0};
@@ -171,7 +390,7 @@ TEST(BeamTest, AdvancingCreatesNewTransitions) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 4);
@@ -183,10 +402,10 @@ TEST(BeamTest, AdvancingCreatesNewTransitions) {
   EXPECT_EQ(GetTransition(beam.beam().at(3)), 3);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + matrix[2]);
-  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScore + matrix[0]);
-  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScore + matrix[1]);
-  EXPECT_EQ(beam.beam().at(3)->GetScore(), kOldScore + matrix[3]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + kTransitionMatrix[2]);
+  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScore + kTransitionMatrix[0]);
+  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScore + kTransitionMatrix[1]);
+  EXPECT_EQ(beam.beam().at(3)->GetScore(), kOldScore + kTransitionMatrix[3]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
@@ -212,7 +431,7 @@ TEST(BeamTest, MultipleElementBeamsAdvanceAllElements) {
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
 
-  constexpr float matrix[kMatrixSize] = {
+  constexpr float kTransitionMatrix[kMatrixSize] = {
       30.0, 20.0, 40.0, 10.0,  // State 0
       31.0, 21.0, 41.0, 11.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
       00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
@@ -229,7 +448,7 @@ TEST(BeamTest, MultipleElementBeamsAdvanceAllElements) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 8);
@@ -247,14 +466,22 @@ TEST(BeamTest, MultipleElementBeamsAdvanceAllElements) {
   EXPECT_EQ(GetTransition(beam.beam().at(7)), 3);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScores[1] + matrix[6]);
-  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScores[0] + matrix[2]);
-  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScores[1] + matrix[4]);
-  EXPECT_EQ(beam.beam().at(3)->GetScore(), kOldScores[0] + matrix[0]);
-  EXPECT_EQ(beam.beam().at(4)->GetScore(), kOldScores[1] + matrix[5]);
-  EXPECT_EQ(beam.beam().at(5)->GetScore(), kOldScores[0] + matrix[1]);
-  EXPECT_EQ(beam.beam().at(6)->GetScore(), kOldScores[1] + matrix[7]);
-  EXPECT_EQ(beam.beam().at(7)->GetScore(), kOldScores[0] + matrix[3]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[6]);
+  EXPECT_EQ(beam.beam().at(1)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[2]);
+  EXPECT_EQ(beam.beam().at(2)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[4]);
+  EXPECT_EQ(beam.beam().at(3)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[0]);
+  EXPECT_EQ(beam.beam().at(4)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[5]);
+  EXPECT_EQ(beam.beam().at(5)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[1]);
+  EXPECT_EQ(beam.beam().at(6)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[7]);
+  EXPECT_EQ(beam.beam().at(7)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[3]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
@@ -273,19 +500,255 @@ TEST(BeamTest, MultipleElementBeamsAdvanceAllElements) {
   EXPECT_EQ(history.at(1).at(7), 0);
 }
 
+TEST(BeamTest, MultipleElementBeamsFailOnNan) {
+  // Create a matrix of transitions.
+  constexpr int kMaxBeamSize = 8;
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
+  constexpr float kNan = std::numeric_limits<double>::quiet_NaN();
+
+  constexpr float kTransitionMatrix[kMatrixSize] = {
+      30.0, 20.0, 40.0, 10.0,  // State 0
+      31.0, 21.0, kNan, 11.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
+      00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
+      00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0};
+
+  constexpr float kOldScores[] = {5.0, 7.0};
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateState(kOldScores[0]));
+  states.push_back(CreateState(kOldScores[1]));
+
+  Beam<TestTransitionState> beam(kMaxBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+
+  EXPECT_FALSE(beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize,
+                                          kNumTransitions));
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithMultipleStateBeamAndGoldTracking) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMaxBeamSize = 8;
+  constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
+  constexpr float kTransitionMatrix[kMatrixSize] = {
+      30.0, 20.0, 40.0, 10.0,   // State 0
+      31.0, 21.0, 41.0, 11.0,   // State 1
+      32.0, 22.0, 42.0, 12.0,   // State 2
+      33.0, 23.0, 43.0, 13.0,   // State 3
+      34.0, 24.0, 44.0, 14.0,   // State 4
+      35.0, 25.0, 45.0, 15.0,   // State 5
+      36.0, 26.0, 46.0, 16.0,   // State 6
+      37.0, 27.0, 47.0, 17.0};  // State 7
+  constexpr float kOldScores[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8};
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateGoldState(kOldScores[0]));
+  states.push_back(CreateGoldState(kOldScores[1]));
+  states.push_back(CreateGoldState(kOldScores[2]));
+  states.push_back(CreateGoldState(kOldScores[3]));
+  states.push_back(CreateGoldState(kOldScores[4]));
+  states.push_back(CreateGoldState(kOldScores[5]));
+  states.push_back(CreateGoldState(kOldScores[6]));
+  states.push_back(CreateGoldState(kOldScores[7]));
+
+  // Arbitrarily choose state 4 as the golden state.
+  auto gold_state = states[4].get();
+
+  // Create an oracle that will only return one gold transition - on transition
+  // 2 for state 6 (arbitrarily).
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {0, 2};
+  vector<int> null_labels = {};
+  EXPECT_CALL(mock_oracle_function, Call(testing::Ne(gold_state)))
+      .WillRepeatedly(Return(null_labels));
+  EXPECT_CALL(mock_oracle_function, Call(gold_state))
+      .WillOnce(Return(oracle_labels));
+
+  Beam<TestTransitionState> beam(kMaxBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate the new beam.
+  EXPECT_EQ(beam.beam().size(), 8);
+
+  // Make sure the state has performed the expected transition.
+  // In this case, every state will perform transition 2.
+  EXPECT_EQ(GetTransition(beam.beam()[0]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[1]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[2]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[3]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[4]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[5]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[6]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[7]), 2);
+
+  // Make sure the state has had its score updated properly. (Note that row
+  // 0 had the smallest transition score, so it ends up on the bottom of the
+  // beam, and so forth.) For the matrix index, N*kNumTransitions gets into the
+  // correct state row and we add 2 since that was the transition index.
+  EXPECT_EQ(beam.beam()[0]->GetScore(),
+            kOldScores[7] + kTransitionMatrix[7 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[0]->IsGold());
+
+  EXPECT_EQ(beam.beam()[1]->GetScore(),
+            kOldScores[6] + kTransitionMatrix[6 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[1]->IsGold());
+
+  EXPECT_EQ(beam.beam()[2]->GetScore(),
+            kOldScores[5] + kTransitionMatrix[5 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[2]->IsGold());
+
+  // This should be the gold state.
+  EXPECT_EQ(beam.beam()[3]->GetScore(),
+            kOldScores[4] + kTransitionMatrix[4 * kNumTransitions + 2]);
+  EXPECT_TRUE(beam.beam()[3]->IsGold());
+
+  EXPECT_EQ(beam.beam()[4]->GetScore(),
+            kOldScores[3] + kTransitionMatrix[3 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[4]->IsGold());
+
+  EXPECT_EQ(beam.beam()[5]->GetScore(),
+            kOldScores[2] + kTransitionMatrix[2 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[5]->IsGold());
+
+  EXPECT_EQ(beam.beam()[6]->GetScore(),
+            kOldScores[1] + kTransitionMatrix[1 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[6]->IsGold());
+
+  EXPECT_EQ(beam.beam()[7]->GetScore(),
+            kOldScores[0] + kTransitionMatrix[0 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[7]->IsGold());
+
+  // Validate that the beam still has a gold state in it.
+  EXPECT_TRUE(beam.ContainsGold());
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithMultipleGoldStates) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMaxBeamSize = 8;
+  constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
+  constexpr float kTransitionMatrix[kMatrixSize] = {
+      30.0, 20.0, 40.0, 10.0,   // State 0
+      31.0, 21.0, 41.0, 11.0,   // State 1
+      32.0, 22.0, 42.0, 12.0,   // State 2
+      33.0, 23.0, 43.0, 13.0,   // State 3
+      54.0, 24.0, 44.0, 14.0,   // State 4 (gold - next will have both states)
+      35.0, 25.0, 45.0, 15.0,   // State 5
+      36.0, 26.0, 46.0, 16.0,   // State 6
+      37.0, 27.0, 47.0, 17.0};  // State 7
+  constexpr float kOldScores[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8};
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateState(kOldScores[0]));
+  states.push_back(CreateState(kOldScores[1]));
+  states.push_back(CreateState(kOldScores[2]));
+  states.push_back(CreateState(kOldScores[3]));
+  states.push_back(CreateGoldState(kOldScores[4]));
+  states.push_back(CreateState(kOldScores[5]));
+  states.push_back(CreateState(kOldScores[6]));
+  states.push_back(CreateState(kOldScores[7]));
+
+  // Arbitrarily choose state 4 as the golden state.
+  auto gold_state = states[4].get();
+
+  // Create an oracle that will only return one gold transition - on transition
+  // 2 for state 6 (arbitrarily).
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {0, 2};
+  vector<int> null_labels = {};
+  EXPECT_CALL(mock_oracle_function, Call(gold_state))
+      .WillOnce(Return(oracle_labels))
+      .WillOnce(Return(oracle_labels));
+
+  Beam<TestTransitionState> beam(kMaxBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate the new beam.
+  EXPECT_EQ(beam.beam().size(), 8);
+
+  // Make sure the state has performed the expected transition.
+  // In this case, every state will perform transition 2.
+  EXPECT_EQ(GetTransition(beam.beam()[0]), 0);
+  EXPECT_EQ(GetTransition(beam.beam()[1]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[2]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[3]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[4]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[5]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[6]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[7]), 2);
+
+  // Make sure the state has had its score updated properly. (Note that row
+  // 0 had the smallest transition score, so it ends up on the bottom of the
+  // beam, and so forth.) For the matrix index, N*kNumTransitions gets into the
+  // correct state row and we add 2 since that was the transition index.
+  // This should be a gold state.
+  EXPECT_EQ(beam.beam()[0]->GetScore(),
+            kOldScores[4] + kTransitionMatrix[4 * kNumTransitions + 0]);
+  EXPECT_TRUE(beam.beam()[0]->IsGold());
+
+  EXPECT_EQ(beam.beam()[1]->GetScore(),
+            kOldScores[7] + kTransitionMatrix[7 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[1]->IsGold());
+
+  EXPECT_EQ(beam.beam()[2]->GetScore(),
+            kOldScores[6] + kTransitionMatrix[6 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[2]->IsGold());
+
+  EXPECT_EQ(beam.beam()[3]->GetScore(),
+            kOldScores[5] + kTransitionMatrix[5 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[3]->IsGold());
+
+  // This should be a gold state.
+  EXPECT_EQ(beam.beam()[4]->GetScore(),
+            kOldScores[4] + kTransitionMatrix[4 * kNumTransitions + 2]);
+  EXPECT_TRUE(beam.beam()[4]->IsGold());
+
+  EXPECT_EQ(beam.beam()[5]->GetScore(),
+            kOldScores[3] + kTransitionMatrix[3 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[5]->IsGold());
+
+  EXPECT_EQ(beam.beam()[6]->GetScore(),
+            kOldScores[2] + kTransitionMatrix[2 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[6]->IsGold());
+
+  EXPECT_EQ(beam.beam()[7]->GetScore(),
+            kOldScores[1] + kTransitionMatrix[1 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[7]->IsGold());
+
+  // Validate that the beam still has a gold state in it.
+  EXPECT_TRUE(beam.ContainsGold());
+}
+
 TEST(BeamTest, AdvancingDropsLowValuePredictions) {
   // Create a matrix of transitions.
   constexpr int kNumTransitions = 4;
   constexpr int kMaxBeamSize = 8;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
-  constexpr float matrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0,   // State 0
-                                         31.0, 21.0, 41.0, 11.0,   // State 1
-                                         32.0, 22.0, 42.0, 12.0,   // State 2
-                                         33.0, 23.0, 43.0, 13.0,   // State 3
-                                         34.0, 24.0, 44.0, 14.0,   // State 4
-                                         35.0, 25.0, 45.0, 15.0,   // State 5
-                                         36.0, 26.0, 46.0, 16.0,   // State 6
-                                         37.0, 27.0, 47.0, 17.0};  // State 7
+  constexpr float kTransitionMatrix[kMatrixSize] = {
+      30.0, 20.0, 40.0, 10.0,   // State 0
+      31.0, 21.0, 41.0, 11.0,   // State 1
+      32.0, 22.0, 42.0, 12.0,   // State 2
+      33.0, 23.0, 43.0, 13.0,   // State 3
+      34.0, 24.0, 44.0, 14.0,   // State 4
+      35.0, 25.0, 45.0, 15.0,   // State 5
+      36.0, 26.0, 46.0, 16.0,   // State 6
+      37.0, 27.0, 47.0, 17.0};  // State 7
   constexpr float kOldScores[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8};
 
   // Create the beam and transition it.
@@ -302,7 +765,7 @@ TEST(BeamTest, AdvancingDropsLowValuePredictions) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 8);
@@ -323,21 +786,21 @@ TEST(BeamTest, AdvancingDropsLowValuePredictions) {
   // beam, and so forth.) For the matrix index, N*kNumTransitions gets into the
   // correct state row and we add 2 since that was the transition index.
   EXPECT_EQ(beam.beam().at(0)->GetScore(),
-            kOldScores[7] + matrix[7 * kNumTransitions + 2]);
+            kOldScores[7] + kTransitionMatrix[7 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(1)->GetScore(),
-            kOldScores[6] + matrix[6 * kNumTransitions + 2]);
+            kOldScores[6] + kTransitionMatrix[6 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(2)->GetScore(),
-            kOldScores[5] + matrix[5 * kNumTransitions + 2]);
+            kOldScores[5] + kTransitionMatrix[5 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(3)->GetScore(),
-            kOldScores[4] + matrix[4 * kNumTransitions + 2]);
+            kOldScores[4] + kTransitionMatrix[4 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(4)->GetScore(),
-            kOldScores[3] + matrix[3 * kNumTransitions + 2]);
+            kOldScores[3] + kTransitionMatrix[3 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(5)->GetScore(),
-            kOldScores[2] + matrix[2 * kNumTransitions + 2]);
+            kOldScores[2] + kTransitionMatrix[2 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(6)->GetScore(),
-            kOldScores[1] + matrix[1 * kNumTransitions + 2]);
+            kOldScores[1] + kTransitionMatrix[1 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(7)->GetScore(),
-            kOldScores[0] + matrix[0 * kNumTransitions + 2]);
+            kOldScores[0] + kTransitionMatrix[0 * kNumTransitions + 2]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
@@ -358,7 +821,9 @@ TEST(BeamTest, AdvancingDropsLowValuePredictions) {
 TEST(BeamTest, AdvancesFromOracleWithSingleBeam) {
   // Create an oracle function for this state.
   constexpr int kOracleLabel = 3;
-  auto oracle_function = [](TransitionState *) { return kOracleLabel; };
+  auto oracle_function = [](TransitionState *) -> const vector<int> {
+    return {kOracleLabel};
+  };
 
   // Create the beam and transition it.
   std::vector<std::unique_ptr<TestTransitionState>> states;
@@ -392,21 +857,24 @@ TEST(BeamTest, AdvancesFromOracleWithMultipleStates) {
 
   // Create a beam with 8 transition states.
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize);
   for (int i = 0; i < kMaxBeamSize; ++i) {
-    // This is nonzero to test the oracle holding scores to 0.
+    // This is nonzero to test the oracle holding scores constant.
     states.push_back(CreateState(10.0));
   }
 
   std::vector<int> expected_actions;
 
   // Create an oracle function for this state. Use mocks for finer control.
-  testing::MockFunction<int(TestTransitionState *)> mock_oracle_function;
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
   for (int i = 0; i < kMaxBeamSize; ++i) {
     // We expect each state to be queried for its oracle label,
     // and then to be transitioned in place with its oracle label.
     int oracle_label = i % 3;  // 3 is arbitrary.
+    vector<int> oracle_labels = {oracle_label};
     EXPECT_CALL(mock_oracle_function, Call(states.at(i).get()))
-        .WillOnce(Return(oracle_label));
+        .WillOnce(Return(oracle_labels));
     expected_actions.push_back(oracle_label);
   }
 
@@ -435,6 +903,7 @@ TEST(BeamTest, ReportsNonFinality) {
 
   // Create a beam with 8 transition states.
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize);
   for (int i = 0; i < kMaxBeamSize; ++i) {
     // This is nonzero to test the oracle holding scores to 0.
     states.push_back(CreateState(10.0));
@@ -467,6 +936,7 @@ TEST(BeamTest, ReportsFinality) {
 
   // Create a beam with 8 transition states.
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize);
   for (int i = 0; i < kMaxBeamSize; ++i) {
     // This is nonzero to test the oracle holding scores to 0.
     states.push_back(CreateState(10.0));
@@ -493,7 +963,7 @@ TEST(BeamTest, IgnoresForbiddenTransitionActions) {
   constexpr int kMaxBeamSize = 4;
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
-  constexpr float matrix[kMatrixSize] = {
+  constexpr float kTransitionMatrix[kMatrixSize] = {
       10.0, 1000.0, 40.0, 30.0, 00.0, 0000.0, 00.0, 00.0,
       00.0, 0000.0, 00.0, 00.0, 00.0, 0000.0, 00.0, 00.0};
   constexpr float kOldScore = 4.0;
@@ -518,7 +988,7 @@ TEST(BeamTest, IgnoresForbiddenTransitionActions) {
   beam.SetFunctions(mock_permission_function.AsStdFunction(), null_finality,
                     transition_function, null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 3);
@@ -529,9 +999,9 @@ TEST(BeamTest, IgnoresForbiddenTransitionActions) {
   EXPECT_EQ(GetTransition(beam.beam().at(2)), 0);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + matrix[2]);
-  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScore + matrix[3]);
-  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScore + matrix[0]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + kTransitionMatrix[2]);
+  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScore + kTransitionMatrix[3]);
+  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScore + kTransitionMatrix[0]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
@@ -551,7 +1021,7 @@ TEST(BeamTest, BadlySizedMatrixDies) {
   // Create a matrix of transitions.
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = 4;  // We have a max beam size of 4; should be 16.
-  constexpr float matrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
 
   // Create the beam and transition it.
   std::vector<std::unique_ptr<TestTransitionState>> states;
@@ -564,7 +1034,8 @@ TEST(BeamTest, BadlySizedMatrixDies) {
   beam.Init(std::move(states));
 
   // This matrix should have 8 elements, not 4, so this should die.
-  EXPECT_DEATH(beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions),
+  EXPECT_DEATH(beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize,
+                                          kNumTransitions),
                "Transition matrix size does not match max beam size \\* number "
                "of state transitions");
 }
@@ -573,6 +1044,7 @@ TEST(BeamTest, BadlySizedBeamInitializationDies) {
   // Create an initialization beam too large for the max beam size.
   constexpr int kMaxBeamSize = 4;
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize + 1);
   for (int i = 0; i < kMaxBeamSize + 1; ++i) {
     states.push_back(CreateState(0.0));
   }
@@ -590,6 +1062,7 @@ TEST(BeamTest, ValidBeamIndicesAfterBeamInitialization) {
   // Create a standard beam.
   constexpr int kMaxBeamSize = 4;
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize);
   for (int i = 0; i < kMaxBeamSize; ++i) {
     states.push_back(CreateState(0.0));
   }
@@ -611,7 +1084,7 @@ TEST(BeamTest, FindPreviousIndexTracesHistory) {
   constexpr int kNumTransitions = 4;
   constexpr int kMaxBeamSize = 8;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
-  constexpr float matrix[kMatrixSize] = {
+  constexpr float kTransitionMatrix[kMatrixSize] = {
       30.0, 20.0, 40.0, 10.0,  // State 0
       31.0, 21.0, 41.0, 11.0,  // State 1
       00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
@@ -632,7 +1105,7 @@ TEST(BeamTest, FindPreviousIndexTracesHistory) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 8);
@@ -650,14 +1123,22 @@ TEST(BeamTest, FindPreviousIndexTracesHistory) {
   EXPECT_EQ(GetTransition(beam.beam().at(7)), 3);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScores[1] + matrix[6]);
-  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScores[0] + matrix[2]);
-  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScores[1] + matrix[4]);
-  EXPECT_EQ(beam.beam().at(3)->GetScore(), kOldScores[0] + matrix[0]);
-  EXPECT_EQ(beam.beam().at(4)->GetScore(), kOldScores[1] + matrix[5]);
-  EXPECT_EQ(beam.beam().at(5)->GetScore(), kOldScores[0] + matrix[1]);
-  EXPECT_EQ(beam.beam().at(6)->GetScore(), kOldScores[1] + matrix[7]);
-  EXPECT_EQ(beam.beam().at(7)->GetScore(), kOldScores[0] + matrix[3]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[6]);
+  EXPECT_EQ(beam.beam().at(1)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[2]);
+  EXPECT_EQ(beam.beam().at(2)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[4]);
+  EXPECT_EQ(beam.beam().at(3)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[0]);
+  EXPECT_EQ(beam.beam().at(4)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[5]);
+  EXPECT_EQ(beam.beam().at(5)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[1]);
+  EXPECT_EQ(beam.beam().at(6)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[7]);
+  EXPECT_EQ(beam.beam().at(7)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[3]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
diff --git a/research/syntaxnet/dragnn/core/component_registry.h b/research/syntaxnet/dragnn/core/component_registry.h
index 72449762..09baeca3 100644
--- a/research/syntaxnet/dragnn/core/component_registry.h
+++ b/research/syntaxnet/dragnn/core/component_registry.h
@@ -13,12 +13,17 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPONENT_REGISTRY_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPONENT_REGISTRY_H_
+#ifndef DRAGNN_CORE_COMPONENT_REGISTRY_H_
+#define DRAGNN_CORE_COMPONENT_REGISTRY_H_
 
 #include "dragnn/core/interfaces/component.h"
 #include "syntaxnet/registry.h"
 
+namespace syntaxnet {
+// Class registry for DRAGNN components.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("DRAGNN Component", dragnn::Component);
+}  // namespace syntaxnet
+
 // Macro to add a component to the registry. This macro associates a class with
 // its class name as a string, so FooComponent would be associated with the
 // string "FooComponent".
@@ -26,4 +31,4 @@
   REGISTER_SYNTAXNET_CLASS_COMPONENT(syntaxnet::dragnn::Component, #component, \
                                      component)
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPONENT_REGISTRY_H_
+#endif  // DRAGNN_CORE_COMPONENT_REGISTRY_H_
diff --git a/research/syntaxnet/dragnn/core/compute_session.h b/research/syntaxnet/dragnn/core/compute_session.h
index 74cbc677..5ccfa720 100644
--- a/research/syntaxnet/dragnn/core/compute_session.h
+++ b/research/syntaxnet/dragnn/core/compute_session.h
@@ -13,13 +13,14 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_H_
+#ifndef DRAGNN_CORE_COMPUTE_SESSION_H_
+#define DRAGNN_CORE_COMPUTE_SESSION_H_
 
 #include <string>
 
 #include "dragnn/components/util/bulk_feature_extractor.h"
 #include "dragnn/core/index_translator.h"
+#include "dragnn/core/input_batch_cache.h"
 #include "dragnn/core/interfaces/component.h"
 #include "dragnn/protos/spec.pb.h"
 #include "dragnn/protos/trace.pb.h"
@@ -64,10 +65,11 @@ class ComputeSession {
   // Advance the given component using the component's oracle.
   virtual void AdvanceFromOracle(const string &component_name) = 0;
 
-  // Advance the given component using the given score matrix.
-  virtual void AdvanceFromPrediction(const string &component_name,
-                                     const float score_matrix[],
-                                     int score_matrix_length) = 0;
+  // Advance the given component using the given score matrix, which is
+  // |num_items| x |num_actions|.
+  virtual bool AdvanceFromPrediction(const string &component_name,
+                                     const float *score_matrix, int num_items,
+                                     int num_actions) = 0;
 
   // Get the input features for the given component and channel. This passes
   // through to the relevant Component's GetFixedFeatures() call.
@@ -84,6 +86,15 @@ class ComputeSession {
   virtual int BulkGetInputFeatures(const string &component_name,
                                    const BulkFeatureExtractor &extractor) = 0;
 
+  // Directly computes the embedding matrix for all channels, advancing the
+  // component via the oracle until it is terminal. This call takes a vector
+  // of float embedding matrices, one per channel, in channel order.
+  virtual void BulkEmbedFixedFeatures(
+      const string &component_name, int batch_size_padding,
+      int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) = 0;
+
   // Get the input features for the given component and channel. This function
   // can return empty LinkFeatures protos, which represent unused padding slots
   // in the output weight tensor.
@@ -111,6 +122,10 @@ class ComputeSession {
   // Provides the ComputeSession with a batch of data to compute.
   virtual void SetInputData(const std::vector<string> &data) = 0;
 
+  // Like SetInputData(), but accepts an InputBatchCache directly, potentially
+  // bypassing de-serialization.
+  virtual void SetInputBatchCache(std::unique_ptr<InputBatchCache> batch) = 0;
+
   // Resets all components owned by this ComputeSession.
   virtual void ResetSession() = 0;
 
@@ -127,9 +142,14 @@ class ComputeSession {
   // validate correct construction of translators in tests.
   virtual const std::vector<const IndexTranslator *> Translators(
       const string &component_name) const = 0;
+
+  // Get a given component. CHECK-fail if the component's IsReady method
+  // returns false.
+  virtual Component *GetReadiedComponent(
+      const string &component_name) const = 0;
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_H_
+#endif  // DRAGNN_CORE_COMPUTE_SESSION_H_
diff --git a/research/syntaxnet/dragnn/core/compute_session_impl.cc b/research/syntaxnet/dragnn/core/compute_session_impl.cc
index e83db32d..097a01b6 100644
--- a/research/syntaxnet/dragnn/core/compute_session_impl.cc
+++ b/research/syntaxnet/dragnn/core/compute_session_impl.cc
@@ -161,11 +161,11 @@ void ComputeSessionImpl::AdvanceFromOracle(const string &component_name) {
   GetReadiedComponent(component_name)->AdvanceFromOracle();
 }
 
-void ComputeSessionImpl::AdvanceFromPrediction(const string &component_name,
-                                               const float score_matrix[],
-                                               int score_matrix_length) {
-  GetReadiedComponent(component_name)
-      ->AdvanceFromPrediction(score_matrix, score_matrix_length);
+bool ComputeSessionImpl::AdvanceFromPrediction(const string &component_name,
+                                               const float *score_matrix,
+                                               int num_items, int num_actions) {
+  return GetReadiedComponent(component_name)
+      ->AdvanceFromPrediction(score_matrix, num_items, num_actions);
 }
 
 int ComputeSessionImpl::GetInputFeatures(
@@ -182,6 +182,16 @@ int ComputeSessionImpl::BulkGetInputFeatures(
   return GetReadiedComponent(component_name)->BulkGetFixedFeatures(extractor);
 }
 
+void ComputeSessionImpl::BulkEmbedFixedFeatures(
+    const string &component_name, int batch_size_padding, int num_steps_padding,
+    int output_array_size, const vector<const float *> &per_channel_embeddings,
+    float *embedding_output) {
+  return GetReadiedComponent(component_name)
+      ->BulkEmbedFixedFeatures(batch_size_padding, num_steps_padding,
+                               output_array_size, per_channel_embeddings,
+                               embedding_output);
+}
+
 std::vector<LinkFeatures> ComputeSessionImpl::GetTranslatedLinkFeatures(
     const string &component_name, int channel_id) {
   auto *component = GetReadiedComponent(component_name);
@@ -288,6 +298,11 @@ void ComputeSessionImpl::SetInputData(const std::vector<string> &data) {
   input_data_.reset(new InputBatchCache(data));
 }
 
+void ComputeSessionImpl::SetInputBatchCache(
+    std::unique_ptr<InputBatchCache> batch) {
+  input_data_ = std::move(batch);
+}
+
 void ComputeSessionImpl::ResetSession() {
   // Reset all component states.
   for (auto &component_pair : components_) {
@@ -308,6 +323,7 @@ const std::vector<const IndexTranslator *> ComputeSessionImpl::Translators(
     const string &component_name) const {
   auto translators = GetTranslators(component_name);
   std::vector<const IndexTranslator *> const_translators;
+  const_translators.reserve(translators.size());
   for (const auto &translator : translators) {
     const_translators.push_back(translator);
   }
diff --git a/research/syntaxnet/dragnn/core/compute_session_impl.h b/research/syntaxnet/dragnn/core/compute_session_impl.h
index 3e219d4e..59d1f9db 100644
--- a/research/syntaxnet/dragnn/core/compute_session_impl.h
+++ b/research/syntaxnet/dragnn/core/compute_session_impl.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
+#ifndef DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
+#define DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
 
 #include <memory>
 
@@ -55,9 +55,9 @@ class ComputeSessionImpl : public ComputeSession {
 
   void AdvanceFromOracle(const string &component_name) override;
 
-  void AdvanceFromPrediction(const string &component_name,
-                             const float score_matrix[],
-                             int score_matrix_length) override;
+  bool AdvanceFromPrediction(const string &component_name,
+                             const float *score_matrix, int num_items,
+                             int num_actions) override;
 
   int GetInputFeatures(const string &component_name,
                        std::function<int32 *(int)> allocate_indices,
@@ -68,6 +68,12 @@ class ComputeSessionImpl : public ComputeSession {
   int BulkGetInputFeatures(const string &component_name,
                            const BulkFeatureExtractor &extractor) override;
 
+  void BulkEmbedFixedFeatures(
+      const string &component_name, int batch_size_padding,
+      int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override;
+
   std::vector<LinkFeatures> GetTranslatedLinkFeatures(
       const string &component_name, int channel_id) override;
 
@@ -84,6 +90,8 @@ class ComputeSessionImpl : public ComputeSession {
 
   void SetInputData(const std::vector<string> &data) override;
 
+  void SetInputBatchCache(std::unique_ptr<InputBatchCache> batch) override;
+
   void ResetSession() override;
 
   void SetTracing(bool tracing_on) override;
@@ -95,14 +103,14 @@ class ComputeSessionImpl : public ComputeSession {
   const std::vector<const IndexTranslator *> Translators(
       const string &component_name) const override;
 
+  // Get a given component. CHECK-fail if the component's IsReady method
+  // returns false.
+  Component *GetReadiedComponent(const string &component_name) const override;
+
  private:
   // Get a given component. Fails if the component is not found.
   Component *GetComponent(const string &component_name) const;
 
-  // Get a given component. CHECK-fail if the component's IsReady method
-  // returns false.
-  Component *GetReadiedComponent(const string &component_name) const;
-
   // Get the index translators for the given component.
   const std::vector<IndexTranslator *> &GetTranslators(
       const string &component_name) const;
@@ -154,4 +162,4 @@ class ComputeSessionImpl : public ComputeSession {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
+#endif  // DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
diff --git a/research/syntaxnet/dragnn/core/compute_session_impl_test.cc b/research/syntaxnet/dragnn/core/compute_session_impl_test.cc
index 74bef1f5..f615a5da 100644
--- a/research/syntaxnet/dragnn/core/compute_session_impl_test.cc
+++ b/research/syntaxnet/dragnn/core/compute_session_impl_test.cc
@@ -22,7 +22,9 @@
 #include "dragnn/core/component_registry.h"
 #include "dragnn/core/compute_session.h"
 #include "dragnn/core/compute_session_pool.h"
+#include "dragnn/core/input_batch_cache.h"
 #include "dragnn/core/interfaces/component.h"
+#include "dragnn/core/interfaces/input_batch.h"
 #include "dragnn/core/test/generic.h"
 #include "dragnn/core/test/mock_component.h"
 #include "dragnn/core/test/mock_transition_state.h"
@@ -65,8 +67,10 @@ class TestComponentType1 : public Component {
   int GetSourceBeamIndex(int current_index, int batch) const override {
     return 0;
   }
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int matrix_length) override {}
+  bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                             int num_actions) override {
+    return true;
+  }
   void AdvanceFromOracle() override {}
   bool IsTerminal() const override { return true; }
   std::function<int(int, int, int)> GetStepLookupFunction(
@@ -83,6 +87,10 @@ class TestComponentType1 : public Component {
                        int channel_id) const override {
     return 0;
   }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int embedding_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override {}
   int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override {
     return 0;
   }
@@ -133,8 +141,10 @@ class TestComponentType2 : public Component {
   int GetSourceBeamIndex(int current_index, int batch) const override {
     return 0;
   }
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int matrix_length) override {}
+  bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                             int num_actions) override {
+    return true;
+  }
   void AdvanceFromOracle() override {}
   bool IsTerminal() const override { return true; }
   std::function<int(int, int, int)> GetStepLookupFunction(
@@ -151,6 +161,10 @@ class TestComponentType2 : public Component {
                        int channel_id) const override {
     return 0;
   }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int embedding_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override {}
   int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override {
     return 0;
   }
@@ -201,8 +215,14 @@ class UnreadyComponent : public Component {
   int GetSourceBeamIndex(int current_index, int batch) const override {
     return 0;
   }
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int matrix_length) override {}
+  bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                             int num_actions) override {
+    return true;
+  }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int embedding_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override {}
   void AdvanceFromOracle() override {}
   bool IsTerminal() const override { return false; }
   std::function<int(int, int, int)> GetStepLookupFunction(
@@ -254,6 +274,18 @@ class ComputeSessionImplTestPoolAccessor {
   }
 };
 
+// An InputBatch that uses the serialized data directly.
+class IdentityBatch : public InputBatch {
+ public:
+  // Implements InputBatch.
+  void SetData(const std::vector<string> &data) override { data_ = data; }
+  int GetSize() const override { return data_.size(); }
+  const std::vector<string> GetSerializedData() const override { return data_; }
+
+ private:
+  std::vector<string> data_;  // the batch data
+};
+
 // *****************************************************************************
 // Tests begin here.
 // *****************************************************************************
@@ -739,7 +771,7 @@ TEST(ComputeSessionImplTest, InitializesComponentWithSource) {
   EXPECT_CALL(*mock_components["component_one"], GetBeam())
       .WillOnce(Return(beam));
 
-  // Expect that the second component will recieve that beam.
+  // Expect that the second component will receive that beam.
   EXPECT_CALL(*mock_components["component_two"],
               InitializeData(beam, kMaxBeamSize, NotNull()));
 
@@ -899,7 +931,7 @@ TEST(ComputeSessionImplTest, SetTracingPropagatesToAllComponents) {
   EXPECT_CALL(*mock_components["component_one"], GetBeam())
       .WillOnce(Return(beam));
 
-  // Expect that the second component will recieve that beam, and then its
+  // Expect that the second component will receive that beam, and then its
   // tracing will be initialized.
   EXPECT_CALL(*mock_components["component_two"],
               InitializeData(beam, kMaxBeamSize, NotNull()));
@@ -1084,12 +1116,12 @@ TEST(ComputeSessionImplTest, InterfacePassesThrough) {
   session->AdvanceFromOracle("component_one");
 
   // AdvanceFromPrediction()
-  constexpr int kScoreMatrixLength = 3;
-  const float score_matrix[kScoreMatrixLength] = {1.0, 2.3, 4.5};
+  const int kNumActions = 1;
+  const float score_matrix[] = {1.0, 2.3, 4.5};
   EXPECT_CALL(*mock_components["component_one"],
-              AdvanceFromPrediction(score_matrix, kScoreMatrixLength));
-  session->AdvanceFromPrediction("component_one", score_matrix,
-                                 kScoreMatrixLength);
+              AdvanceFromPrediction(score_matrix, batch_size, kNumActions));
+  session->AdvanceFromPrediction("component_one", score_matrix, batch_size,
+                                 kNumActions);
 
   // GetFixedFeatures
   auto allocate_indices = [](int size) -> int32 * { return nullptr; };
@@ -1109,6 +1141,11 @@ TEST(ComputeSessionImplTest, InterfacePassesThrough) {
       .WillOnce(Return(0));
   EXPECT_EQ(0, session->BulkGetInputFeatures("component_one", extractor));
 
+  // BulkEmbedFixedFeatures
+  EXPECT_CALL(*mock_components["component_one"],
+              BulkEmbedFixedFeatures(1, 2, 3, _, _));
+  session->BulkEmbedFixedFeatures("component_one", 1, 2, 3, {nullptr}, nullptr);
+
   // EmitOracleLabels()
   std::vector<std::vector<int>> oracle_labels = {{0, 1}, {2, 3}};
   EXPECT_CALL(*mock_components["component_one"], GetOracleLabels())
@@ -1154,7 +1191,7 @@ TEST(ComputeSessionImplTest, InterfaceRequiresReady) {
   constexpr int kScoreMatrixLength = 3;
   const float score_matrix[kScoreMatrixLength] = {1.0, 2.3, 4.5};
   EXPECT_DEATH(session->AdvanceFromPrediction("component_one", score_matrix,
-                                              kScoreMatrixLength),
+                                              kScoreMatrixLength, 1),
                "without first initializing it");
   constexpr int kArbitraryChannelId = 3;
   EXPECT_DEATH(session->GetInputFeatures("component_one", nullptr, nullptr,
@@ -1163,10 +1200,32 @@ TEST(ComputeSessionImplTest, InterfaceRequiresReady) {
   BulkFeatureExtractor extractor(nullptr, nullptr, nullptr, false, 0, 0);
   EXPECT_DEATH(session->BulkGetInputFeatures("component_one", extractor),
                "without first initializing it");
+  EXPECT_DEATH(session->BulkEmbedFixedFeatures("component_one", 0, 0, 0,
+                                               {nullptr}, nullptr),
+               "without first initializing it");
   EXPECT_DEATH(
       session->GetTranslatedLinkFeatures("component_one", kArbitraryChannelId),
       "without first initializing it");
 }
 
+TEST(ComputeSessionImplTest, SetInputBatchCache) {
+  // Use empty protos since we won't interact with components.
+  MasterSpec spec;
+  GridPoint hyperparams;
+  ComputeSessionPool pool(spec, hyperparams);
+  auto session = pool.GetSession();
+
+  // Initialize a cached IdentityBatch.
+  const std::vector<string> data = {"foo", "bar", "baz"};
+  std::unique_ptr<InputBatchCache> input_batch_cache(new InputBatchCache(data));
+  input_batch_cache->GetAs<IdentityBatch>();
+
+  // Inject the cache into the session.
+  session->SetInputBatchCache(std::move(input_batch_cache));
+
+  // Check that the injected batch can be retrieved.
+  EXPECT_EQ(session->GetSerializedPredictions(), data);
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/core/compute_session_pool.h b/research/syntaxnet/dragnn/core/compute_session_pool.h
index fba1e71e..f049f5f2 100644
--- a/research/syntaxnet/dragnn/core/compute_session_pool.h
+++ b/research/syntaxnet/dragnn/core/compute_session_pool.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
+#ifndef DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
+#define DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
 
 #include <memory>
 
@@ -29,14 +29,14 @@ namespace dragnn {
 
 class ComputeSessionPool {
  public:
-  // Create a ComputeSessionPool that creates ComputeSessions for the given
+  // Creates a ComputeSessionPool that creates ComputeSessions for the given
   // MasterSpec and hyperparameters.
   ComputeSessionPool(const MasterSpec &master_spec,
                      const GridPoint &hyperparams);
 
   virtual ~ComputeSessionPool();
 
-  // Get a ComputeSession. This function will attempt to use an already-created
+  // Gets a ComputeSession. This function will attempt to use an already-created
   // ComputeSession, but if none are available a new one will be created.
   std::unique_ptr<ComputeSession> GetSession();
 
@@ -49,6 +49,12 @@ class ComputeSessionPool {
     return num_unique_sessions_ - sessions_.size();
   }
 
+  // Returns the number of unique sessions that have been created.
+  int num_unique_sessions() { return num_unique_sessions_; }
+
+  // Returns a reference to the underlying spec for this pool.
+  const MasterSpec &GetSpec() const { return master_spec_; }
+
  private:
   friend class ComputeSessionImplTestPoolAccessor;
   friend class ComputeSessionPoolTestPoolAccessor;
@@ -99,4 +105,4 @@ class ComputeSessionPool {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
+#endif  // DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
diff --git a/research/syntaxnet/dragnn/core/compute_session_pool_test.cc b/research/syntaxnet/dragnn/core/compute_session_pool_test.cc
index 82d0735d..1e868802 100644
--- a/research/syntaxnet/dragnn/core/compute_session_pool_test.cc
+++ b/research/syntaxnet/dragnn/core/compute_session_pool_test.cc
@@ -207,6 +207,7 @@ TEST(ComputeSessionPoolTest, SupportsMultithreadedAccess) {
 
   std::vector<std::unique_ptr<tensorflow::Thread>> request_threads;
   constexpr int kNumThreadsToTest = 100;
+  request_threads.reserve(kNumThreadsToTest);
   for (int i = 0; i < kNumThreadsToTest; ++i) {
     request_threads.push_back(std::unique_ptr<tensorflow::Thread>(
         tensorflow::Env::Default()->StartThread(
diff --git a/research/syntaxnet/dragnn/core/index_translator.h b/research/syntaxnet/dragnn/core/index_translator.h
index 556e3588..2cb0ce06 100644
--- a/research/syntaxnet/dragnn/core/index_translator.h
+++ b/research/syntaxnet/dragnn/core/index_translator.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INDEX_TRANSLATOR_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INDEX_TRANSLATOR_H_
+#ifndef DRAGNN_CORE_INDEX_TRANSLATOR_H_
+#define DRAGNN_CORE_INDEX_TRANSLATOR_H_
 
 #include <memory>
 #include <vector>
@@ -80,4 +80,4 @@ class IndexTranslator {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INDEX_TRANSLATOR_H_
+#endif  // DRAGNN_CORE_INDEX_TRANSLATOR_H_
diff --git a/research/syntaxnet/dragnn/core/input_batch_cache.h b/research/syntaxnet/dragnn/core/input_batch_cache.h
index 1f3ef977..7d9d70a3 100644
--- a/research/syntaxnet/dragnn/core/input_batch_cache.h
+++ b/research/syntaxnet/dragnn/core/input_batch_cache.h
@@ -13,12 +13,15 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INPUT_BATCH_CACHE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INPUT_BATCH_CACHE_H_
+#ifndef DRAGNN_CORE_INPUT_BATCH_CACHE_H_
+#define DRAGNN_CORE_INPUT_BATCH_CACHE_H_
 
 #include <memory>
 #include <string>
+#include <type_traits>
 #include <typeindex>
+#include <typeinfo>
+#include <utility>
 
 #include "dragnn/core/interfaces/input_batch.h"
 #include "tensorflow/core/platform/logging.h"
@@ -42,6 +45,18 @@ class InputBatchCache {
   explicit InputBatchCache(const std::vector<string> &data)
       : stored_type_(std::type_index(typeid(void))), source_data_(data) {}
 
+  // Creates a InputBatchCache from the |batch|.  InputBatchSubclass must be a
+  // strict subclass of InputBatch, and |batch| must be non-null.  All calls to
+  // GetAs must match InputBatchSubclass.
+  template <class InputBatchSubclass>
+  explicit InputBatchCache(std::unique_ptr<InputBatchSubclass> batch)
+      : stored_type_(std::type_index(typeid(InputBatchSubclass))),
+        converted_data_(std::move(batch)) {
+    static_assert(IsStrictInputBatchSubclass<InputBatchSubclass>(),
+                  "InputBatchCache requires a strict subclass of InputBatch");
+    CHECK(converted_data_) << "Cannot initialize from a null InputBatch";
+  }
+
   // Adds a single string to the cache. Only useable before GetAs() has been
   // called.
   void AddData(const string &data) {
@@ -52,10 +67,14 @@ class InputBatchCache {
   }
 
   // Converts the stored strings into protos and return them in a specific
-  // InputBatch subclass. T should always be of type InputBatch. After this
-  // method is called once, all further calls must be of the same data type.
+  // InputBatch subclass. T should always be a strict subclass of InputBatch.
+  // After this method is called once, all further calls must be of the same
+  // data type.
   template <class T>
   T *GetAs() {
+    static_assert(
+        IsStrictInputBatchSubclass<T>(),
+        "GetAs<T>() requires that T is a strict subclass of InputBatch");
     if (!converted_data_) {
       stored_type_ = std::type_index(typeid(T));
       converted_data_.reset(new T());
@@ -69,14 +88,27 @@ class InputBatchCache {
     return dynamic_cast<T *>(converted_data_.get());
   }
 
+  // Returns the size of the batch.  Requires that GetAs() has been called.
+  int Size() const {
+    CHECK(converted_data_) << "Cannot return batch size without data.";
+    return converted_data_->GetSize();
+  }
+
   // Returns the serialized representation of the data held in the input batch
-  // object within this cache.
+  // object within this cache.  Requires that GetAs() has been called.
   const std::vector<string> SerializedData() const {
     CHECK(converted_data_) << "Cannot return batch without data.";
     return converted_data_->GetSerializedData();
   }
 
  private:
+  // Returns true if InputBatchSubclass is a strict subclass of InputBatch.
+  template <class InputBatchSubclass>
+  static constexpr bool IsStrictInputBatchSubclass() {
+    return std::is_base_of<InputBatch, InputBatchSubclass>::value &&
+           !std::is_same<InputBatch, InputBatchSubclass>::value;
+  }
+
   // The typeid of the stored data.
   std::type_index stored_type_;
 
@@ -90,4 +122,4 @@ class InputBatchCache {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INPUT_BATCH_CACHE_H_
+#endif  // DRAGNN_CORE_INPUT_BATCH_CACHE_H_
diff --git a/research/syntaxnet/dragnn/core/input_batch_cache_test.cc b/research/syntaxnet/dragnn/core/input_batch_cache_test.cc
index 46366344..3043acfb 100644
--- a/research/syntaxnet/dragnn/core/input_batch_cache_test.cc
+++ b/research/syntaxnet/dragnn/core/input_batch_cache_test.cc
@@ -32,6 +32,8 @@ class StringData : public InputBatch {
     }
   }
 
+  int GetSize() const override { return data_.size(); }
+
   const std::vector<string> GetSerializedData() const override { return data_; }
 
   std::vector<string> *data() { return &data_; }
@@ -50,6 +52,8 @@ class DifferentStringData : public InputBatch {
     }
   }
 
+  int GetSize() const override { return data_.size(); }
+
   const std::vector<string> GetSerializedData() const override { return data_; }
 
   std::vector<string> *data() { return &data_; }
@@ -58,6 +62,11 @@ class DifferentStringData : public InputBatch {
   std::vector<string> data_;
 };
 
+// Expects that two pointers have the same address.
+void ExpectSameAddress(const void *pointer1, const void *pointer2) {
+  EXPECT_EQ(pointer1, pointer2);
+}
+
 TEST(InputBatchCacheTest, ConvertsSingleInput) {
   string test_string = "Foo";
   InputBatchCache generic_set(test_string);
@@ -118,5 +127,48 @@ TEST(InputBatchCacheTest, ConvertsAddedInputDiesAfterGetAs) {
                "after the cache has been converted");
 }
 
+TEST(InputBatchCacheTest, SerializedDataAndSize) {
+  InputBatchCache generic_set;
+  generic_set.AddData("Foo");
+  generic_set.AddData("Bar");
+  generic_set.GetAs<StringData>();
+
+  const std::vector<string> expected_data = {"Foo_converted", "Bar_converted"};
+  EXPECT_EQ(expected_data, generic_set.SerializedData());
+  EXPECT_EQ(2, generic_set.Size());
+}
+
+TEST(InputBatchCacheTest, InitializeFromInputBatch) {
+  const std::vector<string> kInputData = {"foo", "bar", "baz"};
+  const std::vector<string> kExpectedData = {"foo_converted",  //
+                                             "bar_converted",  //
+                                             "baz_converted"};
+
+  std::unique_ptr<StringData> string_data(new StringData());
+  string_data->SetData(kInputData);
+  const StringData *string_data_ptr = string_data.get();
+
+  InputBatchCache generic_set(std::move(string_data));
+  auto data = generic_set.GetAs<StringData>();
+
+  ExpectSameAddress(string_data_ptr, data);
+  EXPECT_EQ(data->GetSize(), 3);
+  EXPECT_EQ(data->GetSerializedData(), kExpectedData);
+  EXPECT_EQ(*data->data(), kExpectedData);
+
+  // AddData() shouldn't work since the cache is already populated.
+  EXPECT_DEATH(generic_set.AddData("YOU MAY NOT DO THIS AND IT WILL DIE."),
+               "after the cache has been converted");
+
+  // GetAs() shouldn't work with a different type.
+  EXPECT_DEATH(generic_set.GetAs<DifferentStringData>(),
+               "Attempted to convert to two object types!");
+}
+
+TEST(InputBatchCacheTest, CannotInitializeFromNullInputBatch) {
+  EXPECT_DEATH(InputBatchCache(std::unique_ptr<StringData>()),
+               "Cannot initialize from a null InputBatch");
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h b/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h
index aa1355b0..1ad3fb00 100644
--- a/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h
+++ b/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
+#ifndef DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
+#define DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
 
 #include <memory>
 #include <vector>
@@ -33,26 +33,32 @@ class CloneableTransitionState : public TransitionState {
  public:
   ~CloneableTransitionState<T>() override {}
 
-  // Initialize this TransitionState from a previous TransitionState. The
+  // Initializes this TransitionState from a previous TransitionState. The
   // ParentBeamIndex is the location of that previous TransitionState in the
   // provided beam.
   void Init(const TransitionState &parent) override = 0;
 
-  // Return the beam index of the state passed into the initializer of this
+  // Returns the beam index of the state passed into the initializer of this
   // TransitionState.
-  const int ParentBeamIndex() const override = 0;
+  int ParentBeamIndex() const override = 0;
 
-  // Get the current beam index for this state.
-  const int GetBeamIndex() const override = 0;
+  // Gets the current beam index for this state.
+  int GetBeamIndex() const override = 0;
 
-  // Set the current beam index for this state.
-  void SetBeamIndex(const int index) override = 0;
+  // Sets the current beam index for this state.
+  void SetBeamIndex(int index) override = 0;
 
-  // Get the score associated with this transition state.
-  const float GetScore() const override = 0;
+  // Gets the score associated with this transition state.
+  float GetScore() const override = 0;
 
-  // Set the score associated with this transition state.
-  void SetScore(const float score) override = 0;
+  // Sets the score associated with this transition state.
+  void SetScore(float score) override = 0;
+
+  // Gets the gold-ness of this state (whether it is on the oracle path)
+  bool IsGold() const override = 0;
+
+  // Sets the gold-ness of this state.
+  void SetGold(bool is_gold) override = 0;
 
   // Depicts this state as an HTML-language string.
   string HTMLRepresentation() const override = 0;
@@ -64,4 +70,4 @@ class CloneableTransitionState : public TransitionState {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
+#endif  // DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
diff --git a/research/syntaxnet/dragnn/core/interfaces/component.h b/research/syntaxnet/dragnn/core/interfaces/component.h
index b382ab0a..a1bea275 100644
--- a/research/syntaxnet/dragnn/core/interfaces/component.h
+++ b/research/syntaxnet/dragnn/core/interfaces/component.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_COMPONENT_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_COMPONENT_H_
+#ifndef DRAGNN_CORE_INTERFACES_COMPONENT_H_
+#define DRAGNN_CORE_INTERFACES_COMPONENT_H_
 
 #include <vector>
 
@@ -83,11 +83,13 @@ class Component : public RegisterableClass<Component> {
   virtual std::function<int(int, int, int)> GetStepLookupFunction(
       const string &method) = 0;
 
-  // Advances this component from the given transition matrix.
-  virtual void AdvanceFromPrediction(const float transition_matrix[],
-                                     int transition_matrix_length) = 0;
+  // Advances this component from the given transition matrix, which is
+  // |num_items| x |num_actions|.
+  virtual bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                                     int num_actions) = 0;
 
-  // Advances this component from the state oracles.
+  // Advances this component from the state oracles. There is no return from
+  // this, since it should always succeed.
   virtual void AdvanceFromOracle() = 0;
 
   // Returns true if all states within this component are terminal.
@@ -110,6 +112,14 @@ class Component : public RegisterableClass<Component> {
   // BulkFeatureExtractor object to contain the functors and other information.
   virtual int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) = 0;
 
+  // Directly computes the embedding matrix for all channels, advancing the
+  // component via the oracle until it is terminal. This call takes a vector
+  // of EmbeddingMatrix structs, one per channel, in channel order.
+  virtual void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) = 0;
+
   // Extracts and returns the vector of LinkFeatures for the specified
   // channel. Note: these are NOT translated.
   virtual std::vector<LinkFeatures> GetRawLinkFeatures(
@@ -138,4 +148,4 @@ class Component : public RegisterableClass<Component> {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_COMPONENT_H_
+#endif  // DRAGNN_CORE_INTERFACES_COMPONENT_H_
diff --git a/research/syntaxnet/dragnn/core/interfaces/input_batch.h b/research/syntaxnet/dragnn/core/interfaces/input_batch.h
index 100ec76b..d087c7ef 100644
--- a/research/syntaxnet/dragnn/core/interfaces/input_batch.h
+++ b/research/syntaxnet/dragnn/core/interfaces/input_batch.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
+#ifndef DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
+#define DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
 
 #include <string>
 #include <vector>
@@ -32,14 +32,17 @@ class InputBatch {
  public:
   virtual ~InputBatch() {}
 
-  // Set the data to translate to the subclass' data type.
+  // Sets the data to translate to the subclass' data type.  Call at most once.
   virtual void SetData(const std::vector<string> &data) = 0;
 
-  // Translate the underlying data back to a vector of strings, as appropriate.
+  // Returns the size of the batch.
+  virtual int GetSize() const = 0;
+
+  // Translates the underlying data back to a vector of strings, as appropriate.
   virtual const std::vector<string> GetSerializedData() const = 0;
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
+#endif  // DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
diff --git a/research/syntaxnet/dragnn/core/interfaces/transition_state.h b/research/syntaxnet/dragnn/core/interfaces/transition_state.h
index c00409b9..24b52441 100644
--- a/research/syntaxnet/dragnn/core/interfaces/transition_state.h
+++ b/research/syntaxnet/dragnn/core/interfaces/transition_state.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
+#ifndef DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
+#define DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
 
 #include <memory>
 #include <vector>
@@ -44,19 +44,25 @@ class TransitionState {
 
   // Return the beam index of the state passed into the initializer of this
   // TransitionState.
-  virtual const int ParentBeamIndex() const = 0;
+  virtual int ParentBeamIndex() const = 0;
 
-  // Get the current beam index for this state.
-  virtual const int GetBeamIndex() const = 0;
+  // Gets the current beam index for this state.
+  virtual int GetBeamIndex() const = 0;
 
-  // Set the current beam index for this state.
-  virtual void SetBeamIndex(const int index) = 0;
+  // Sets the current beam index for this state.
+  virtual void SetBeamIndex(int index) = 0;
 
-  // Get the score associated with this transition state.
-  virtual const float GetScore() const = 0;
+  // Gets the score associated with this transition state.
+  virtual float GetScore() const = 0;
 
-  // Set the score associated with this transition state.
-  virtual void SetScore(const float score) = 0;
+  // Sets the score associated with this transition state.
+  virtual void SetScore(float score) = 0;
+
+  // Gets the gold-ness of this state (whether it is on the oracle path)
+  virtual bool IsGold() const = 0;
+
+  // Sets the gold-ness of this state.
+  virtual void SetGold(bool is_gold) = 0;
 
   // Depicts this state as an HTML-language string.
   virtual string HTMLRepresentation() const = 0;
@@ -65,4 +71,4 @@ class TransitionState {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
+#endif  // DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
diff --git a/research/syntaxnet/dragnn/core/ops/compute_session_op.h b/research/syntaxnet/dragnn/core/ops/compute_session_op.h
index 9780ca81..88bc18c8 100644
--- a/research/syntaxnet/dragnn/core/ops/compute_session_op.h
+++ b/research/syntaxnet/dragnn/core/ops/compute_session_op.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
+#ifndef DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
+#define DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
 
 #include <string>
 
@@ -66,4 +66,4 @@ class ComputeSessionOp : public tensorflow::OpKernel {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
+#endif  // DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc
index 28355557..761b28c7 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc
@@ -303,6 +303,73 @@ class BulkFixedEmbeddings : public ComputeSessionOp {
 REGISTER_KERNEL_BUILDER(Name("BulkFixedEmbeddings").Device(DEVICE_CPU),
                         BulkFixedEmbeddings);
 
+// See docstring in dragnn_bulk_ops.cc.
+class BulkEmbedFixedFeatures : public ComputeSessionOp {
+ public:
+  explicit BulkEmbedFixedFeatures(OpKernelConstruction *context)
+      : ComputeSessionOp(context) {
+    OP_REQUIRES_OK(context, context->GetAttr("num_channels", &num_channels_));
+
+    // The input vector's zeroth element is the state handle, and the remaining
+    // num_channels_ elements are tensors of float embeddings, one per channel.
+    vector<DataType> input_types(num_channels_ + 1, DT_FLOAT);
+    input_types[0] = DT_STRING;
+    const vector<DataType> output_types = {DT_STRING, DT_FLOAT, DT_INT32};
+    OP_REQUIRES_OK(context, context->MatchSignature(input_types, output_types));
+    OP_REQUIRES_OK(context, context->GetAttr("pad_to_batch", &pad_to_batch_));
+    OP_REQUIRES_OK(context, context->GetAttr("pad_to_steps", &pad_to_steps_));
+  }
+
+  bool OutputsHandle() const override { return true; }
+  bool RequiresComponentName() const override { return true; }
+
+  void ComputeWithState(OpKernelContext *context,
+                        ComputeSession *session) override {
+    const auto &spec = session->Spec(component_name());
+    int embedding_size = 0;
+    std::vector<const float *> embeddings(num_channels_);
+    for (int channel = 0; channel < num_channels_; ++channel) {
+      const int embeddings_index = channel + 1;
+      embedding_size += context->input(embeddings_index).shape().dim_size(1) *
+                        spec.fixed_feature(channel).size();
+      embeddings[channel] =
+          context->input(embeddings_index).flat<float>().data();
+    }
+    Tensor *embedding_vectors;
+    OP_REQUIRES_OK(context,
+                   context->allocate_output(
+                       1,
+                       TensorShape({pad_to_steps_ * pad_to_batch_ *
+                                        session->BeamSize(component_name()),
+                                    embedding_size}),
+                       &embedding_vectors));
+    Tensor *num_steps_tensor;
+    OP_REQUIRES_OK(context, context->allocate_output(2, TensorShape({}),
+                                                     &num_steps_tensor));
+    embedding_vectors->flat<float>().setZero();
+    int output_size = embedding_vectors->NumElements();
+    session->BulkEmbedFixedFeatures(component_name(), pad_to_batch_,
+                                    pad_to_steps_, output_size, embeddings,
+                                    embedding_vectors->flat<float>().data());
+    num_steps_tensor->scalar<int32>()() = pad_to_steps_;
+  }
+
+ private:
+  // Number of fixed feature channels.
+  int num_channels_;
+
+  // Will pad output to this many batch elements.
+  int pad_to_batch_;
+
+  // Will pad output to this many steps.
+  int pad_to_steps_;
+
+  TF_DISALLOW_COPY_AND_ASSIGN(BulkEmbedFixedFeatures);
+};
+
+REGISTER_KERNEL_BUILDER(Name("BulkEmbedFixedFeatures").Device(DEVICE_CPU),
+                        BulkEmbedFixedFeatures);
+
 // See docstring in dragnn_bulk_ops.cc.
 class BulkAdvanceFromOracle : public ComputeSessionOp {
  public:
@@ -387,8 +454,11 @@ class BulkAdvanceFromPrediction : public ComputeSessionOp {
         }
       }
       if (!session->IsTerminal(component_name())) {
-        session->AdvanceFromPrediction(component_name(), scores_per_step.data(),
-                                       scores_per_step.size());
+        bool success = session->AdvanceFromPrediction(
+            component_name(), scores_per_step.data(), num_items, num_actions);
+        OP_REQUIRES(
+            context, success,
+            tensorflow::errors::Internal("Unable to advance from prediction."));
       }
     }
   }
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc
index 01b776f6..8a4e368c 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc
@@ -375,6 +375,114 @@ TEST_F(DragnnBulkOpKernelsTest, BulkFixedEmbeddings) {
   EXPECT_EQ(kNumSteps, GetOutput(2)->scalar<int32>()());
 }
 
+TEST_F(DragnnBulkOpKernelsTest, BulkEmbedFixedFeatures) {
+  // Create and initialize the kernel under test.
+  constexpr int kBatchPad = 7;
+  constexpr int kStepPad = 5;
+  constexpr int kMaxBeamSize = 3;
+  TF_ASSERT_OK(
+      NodeDefBuilder("BulkEmbedFixedFeatures", "BulkEmbedFixedFeatures")
+          .Attr("component", kComponentName)
+          .Attr("num_channels", kNumChannels)
+          .Attr("pad_to_batch", kBatchPad)
+          .Attr("pad_to_steps", kStepPad)
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Input(FakeInput(DT_FLOAT))   // Embedding matrices.
+          .Finalize(node_def()));
+  MockComputeSession *mock_session = GetMockSession();
+  ComponentSpec spec;
+  spec.set_name(kComponentName);
+  auto chan0_spec = spec.add_fixed_feature();
+  constexpr int kChan0FeatureCount = 2;
+  chan0_spec->set_size(kChan0FeatureCount);
+  auto chan1_spec = spec.add_fixed_feature();
+  constexpr int kChan1FeatureCount = 1;
+  chan1_spec->set_size(kChan1FeatureCount);
+  EXPECT_CALL(*mock_session, Spec(kComponentName))
+      .WillOnce(testing::ReturnRef(spec));
+  EXPECT_CALL(*mock_session, BeamSize(kComponentName))
+      .WillOnce(testing::Return(kMaxBeamSize));
+
+  // Embedding matrices as additional inputs.
+  // For channel 0, the embeddings are [id, id, id].
+  // For channel 1, the embeddings are [id^2, id^2, id^2, ... ,id^2].
+  vector<float> embedding_matrix_0;
+  constexpr int kEmbedding0Size = 3;
+  vector<float> embedding_matrix_1;
+  constexpr int kEmbedding1Size = 9;
+  for (int id = 0; id < kNumIds; ++id) {
+    for (int i = 0; i < kEmbedding0Size; ++i) {
+      embedding_matrix_0.push_back(id);
+      LOG(INFO) << embedding_matrix_0.back();
+    }
+    for (int i = 0; i < kEmbedding1Size; ++i) {
+      embedding_matrix_1.push_back(id * id);
+      LOG(INFO) << embedding_matrix_0.back();
+    }
+  }
+
+  AddInputFromArray<float>(TensorShape({kNumIds, kEmbedding0Size}),
+                           embedding_matrix_0);
+  AddInputFromArray<float>(TensorShape({kNumIds, kEmbedding1Size}),
+                           embedding_matrix_1);
+
+  constexpr int kExpectedEmbeddingSize = kChan0FeatureCount * kEmbedding0Size +
+                                         kChan1FeatureCount * kEmbedding1Size;
+  constexpr int kExpectedOutputSize =
+      kExpectedEmbeddingSize * kBatchPad * kStepPad * kMaxBeamSize;
+
+  // This function takes the allocator functions passed into GetBulkFF, uses
+  // them to allocate a tensor, then fills that tensor based on channel.
+  auto eval_function = [=](const string &component_name, int batch_size_padding,
+                           int num_steps_padding, int output_array_size,
+                           const vector<const float *> &per_channel_embeddings,
+                           float *embedding_output) {
+    // Validate the control variables.
+    EXPECT_EQ(batch_size_padding, kBatchPad);
+    EXPECT_EQ(num_steps_padding, kStepPad);
+    EXPECT_EQ(output_array_size, kExpectedOutputSize);
+
+    // Validate the passed embeddings.
+    for (int i = 0; i < kNumIds; ++i) {
+      for (int j = 0; j < kEmbedding0Size; ++j) {
+        float ch0_embedding =
+            per_channel_embeddings.at(0)[i * kEmbedding0Size + j];
+        EXPECT_FLOAT_EQ(ch0_embedding, i)
+            << "Failed match at " << i << "," << j;
+      }
+      for (int j = 0; j < kEmbedding1Size; ++j) {
+        float ch1_embedding =
+            per_channel_embeddings.at(1)[i * kEmbedding1Size + j];
+        EXPECT_FLOAT_EQ(ch1_embedding, i * i)
+            << "Failed match at " << i << "," << j;
+      }
+    }
+
+    // Fill the output matrix to the expected size. This will trigger msan
+    // if the allocation wasn't big enough.
+    for (int i = 0; i < kExpectedOutputSize; ++i) {
+      embedding_output[i] = i;
+    }
+  };
+
+  EXPECT_CALL(*mock_session,
+              BulkEmbedFixedFeatures(kComponentName, _, _, _, _, _))
+      .WillOnce(testing::Invoke(eval_function));
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+
+  // Validate outputs.
+  EXPECT_EQ(kBatchPad * kStepPad * kMaxBeamSize,
+            GetOutput(1)->shape().dim_size(0));
+  EXPECT_EQ(kExpectedEmbeddingSize, GetOutput(1)->shape().dim_size(1));
+  auto output_data = GetOutput(1)->flat<float>();
+  for (int i = 0; i < kExpectedOutputSize; ++i) {
+    EXPECT_FLOAT_EQ(i, output_data(i));
+  }
+  EXPECT_EQ(kStepPad, GetOutput(2)->scalar<int32>()());
+}
+
 TEST_F(DragnnBulkOpKernelsTest, BulkFixedEmbeddingsWithPadding) {
   // Create and initialize the kernel under test.
   constexpr int kPaddedNumSteps = 5;
@@ -592,12 +700,54 @@ TEST_F(DragnnBulkOpKernelsTest, BulkAdvanceFromPrediction) {
   EXPECT_CALL(*mock_session,
               AdvanceFromPrediction(kComponentName,
                                     CheckScoresAreConsecutiveIntegersDivTen(),
-                                    kNumItems * kNumActions))
-      .Times(kNumSteps);
+                                    kNumItems, kNumActions))
+      .Times(kNumSteps)
+      .WillRepeatedly(Return(true));
 
   // Run the kernel.
   TF_EXPECT_OK(RunOpKernelWithContext());
 }
 
+TEST_F(DragnnBulkOpKernelsTest, BulkAdvanceFromPredictionFailsIfAdvanceFails) {
+  // Create and initialize the kernel under test.
+  TF_ASSERT_OK(
+      NodeDefBuilder("BulkAdvanceFromPrediction", "BulkAdvanceFromPrediction")
+          .Attr("component", kComponentName)
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Input(FakeInput(DT_FLOAT))   // Prediction scores for advancing.
+          .Finalize(node_def()));
+  MockComputeSession *mock_session = GetMockSession();
+
+  // Creates an input tensor such that each step will see a list of consecutive
+  // integers divided by 10 as scores.
+  vector<float> scores(kNumItems * kNumSteps * kNumActions);
+  for (int step(0), cnt(0); step < kNumSteps; ++step) {
+    for (int item = 0; item < kNumItems; ++item) {
+      for (int action = 0; action < kNumActions; ++action, ++cnt) {
+        scores[action + kNumActions * (step + item * kNumSteps)] = cnt / 10.0f;
+      }
+    }
+  }
+  AddInputFromArray<float>(TensorShape({kNumItems * kNumSteps, kNumActions}),
+                           scores);
+
+  EXPECT_CALL(*mock_session, BeamSize(kComponentName)).WillOnce(Return(1));
+  EXPECT_CALL(*mock_session, BatchSize(kComponentName))
+      .WillOnce(Return(kNumItems));
+  EXPECT_CALL(*mock_session, IsTerminal(kComponentName))
+      .Times(2)
+      .WillRepeatedly(Return(false));
+  EXPECT_CALL(*mock_session,
+              AdvanceFromPrediction(kComponentName,
+                                    CheckScoresAreConsecutiveIntegersDivTen(),
+                                    kNumItems, kNumActions))
+      .WillOnce(Return(true))
+      .WillOnce(Return(false));
+
+  // Run the kernel.
+  auto result = RunOpKernelWithContext();
+  EXPECT_FALSE(result.ok());
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc
index 4c2d444d..654b2c7f 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc
@@ -80,6 +80,38 @@ pad_to_batch: If set, the op will pad/truncate to this number of elements.
 pad_to_steps: If set, the op will pad/truncate to this number of steps.
 )doc");
 
+REGISTER_OP("BulkEmbedFixedFeatures")
+    .Input("handle: string")
+    .Input("embedding_matrix: num_channels * float")
+    .Output("output_handle: string")
+    .Output("embedding_vectors: float")
+    .Output("num_steps: int32")
+    .Attr("component: string")
+    .Attr("num_channels: int")
+    .Attr("pad_to_batch: int")
+    .Attr("pad_to_steps: int")
+    .SetIsStateful()
+    .Doc(R"doc(
+This op is a more efficient version of BulkFixedFeatures.
+
+It is intended to be run with large batch sizes at inference time. The op takes
+a handle to ComputeSession and embedding matrices as tensor inputs, and directly
+outputs concatenated embedding vectors. It calls the BulkEmbedFixedFeatures
+method on the underlying component directly, so it requires a padding vector
+to be passed.
+
+handle: A handle to ComputeSession.
+embedding_matrix: Embedding matrices.
+output_handle: A handle to the same ComputeSession after advancement.
+embedding_vectors: (matrix of float) Concatenated embeddings,
+  shaped as (batch * beam * token) x sum_channel(embedding_dim[channel]).
+num_steps: The batch was unrolled for these many steps.
+component: The name of a Component instance, matching the ComponentSpec.name.
+num_channels: The number of FixedFeature channels.
+pad_to_batch: The op will pad/truncate to this number of elements.
+pad_to_steps: The op will pad/truncate to this number of steps.
+)doc");
+
 REGISTER_OP("BulkAdvanceFromOracle")
     .Input("handle: string")
     .Output("output_handle: string")
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc b/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc
index a01b3772..cc6e9b20 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc
@@ -30,6 +30,7 @@
 #include "tensorflow/core/framework/tensor_shape.h"
 #include "tensorflow/core/lib/core/status.h"
 #include "tensorflow/core/lib/core/threadpool.h"
+#include "tensorflow/core/lib/io/path.h"
 #include "tensorflow/core/platform/logging.h"
 #include "tensorflow/core/platform/mutex.h"
 
@@ -40,6 +41,8 @@ using tensorflow::DT_INT32;
 using tensorflow::DT_INT64;
 using tensorflow::DT_STRING;
 using tensorflow::DataType;
+using tensorflow::io::Dirname;
+using tensorflow::io::JoinPath;
 using tensorflow::OpKernel;
 using tensorflow::OpKernelConstruction;
 using tensorflow::OpKernelContext;
@@ -53,6 +56,59 @@ namespace dragnn {
 
 typedef ResourceContainer<ComputeSession> ComputeSessionResource;
 typedef ResourceContainer<ComputeSessionPool> ComputeSessionPoolResource;
+typedef ResourceContainer<string> StringResource;
+
+namespace {
+
+const char kGlobalContainer[] = "__reserved_global_container";
+const char kBasePathTag[] = "__reserved_asset_base_path";
+const char kUnmanagedAssetDirectory[] = "assets.extra";
+
+// When restoring a graph from a SavedModel, this op will rewrite the MasterSpec
+// to point the DRAGNN components to the new resource locations. It will then
+// add a string resource to the resource manager, which will be used to
+// rebuild the masterspec before it is acquired in the GetComputeSession op.
+class SetAssetDirectory : public OpKernel {
+ public:
+  explicit SetAssetDirectory(OpKernelConstruction *context)
+      : OpKernel(context) {
+    OP_REQUIRES_OK(context, context->MatchSignature({DT_STRING}, {DT_STRING}));
+  }
+
+  void Compute(OpKernelContext *context) override {
+    ResourceMgr *rmgr = context->resource_manager();
+    const string asset_path = context->input(0).scalar<string>()();
+
+    // TODO(googleuser): Get this data in a way that isn't fragile as all hell.
+    // "I've done stuff I ain't proud of... and the stuff I am proud of is
+    // disgusting." -- Moe
+    auto extra_asset_dir =
+        JoinPath(Dirname(Dirname(asset_path)), kUnmanagedAssetDirectory);
+    LOG(INFO) << "Found extra assets path at:" << extra_asset_dir;
+
+    // Rather than attempt to rewrite the MasterSpec here, we save off a
+    // StringResource containing the new asset path. It will be used in
+    // the GetSession op, if it exists.
+    std::unique_ptr<string> asset_path_ptr(new string(extra_asset_dir));
+
+    OP_REQUIRES_OK(context, rmgr->Create<StringResource>(
+                                kGlobalContainer, kBasePathTag,
+                                new StringResource(std::move(asset_path_ptr))));
+
+    // This isn't used anywhere - it just allows us to have an output so that
+    // it's easier to reason about Tensorflow's graph execution.
+    Tensor *output;
+    OP_REQUIRES_OK(context,
+                   context->allocate_output(0, TensorShape({1}), &output));
+    output->vec<string>()(0) = asset_path;
+  }
+
+ private:
+  TF_DISALLOW_COPY_AND_ASSIGN(SetAssetDirectory);
+};
+
+REGISTER_KERNEL_BUILDER(Name("SetAssetDirectory").Device(DEVICE_CPU),
+                        SetAssetDirectory);
 
 // Given a MasterSpec proto, outputs a handle to a ComputeSession.
 class GetSession : public OpKernel {
@@ -66,6 +122,7 @@ class GetSession : public OpKernel {
     CHECK(master_spec_.ParseFromString(master_spec_str));
     CHECK(grid_point_.ParseFromString(grid_point_spec_str));
     OP_REQUIRES_OK(context, context->MatchSignature({DT_STRING}, {DT_STRING}));
+    has_overwritten_spec_ = false;
   }
 
   void Compute(OpKernelContext *context) override {
@@ -74,10 +131,32 @@ class GetSession : public OpKernel {
 
     // Create the pool for this container, or re-use one that was allocated in a
     // previous call.
-    auto create_pool = [this,
+    auto create_pool = [this, &rmgr,
                         &container](ComputeSessionPoolResource **resource) {
-      LOG(INFO) << "Creating new ComputeSessionPool in container handle: "
-      << container;
+      if (has_overwritten_spec_) {
+        // TODO(googleuser): Figure out a way to test this.
+        // If there's already an overwritten spec, use that.
+        LOG(INFO) << "Creating new ComputeSessionPool in container handle: "
+                  << container << " with previously overwritten master spec.";
+      } else {
+        // If not, try to find the resource base.
+        StringResource *resource_base;
+        auto resource_base_lookup = rmgr->Lookup<StringResource>(
+            kGlobalContainer, kBasePathTag, &resource_base);
+        if (resource_base_lookup.ok()) {
+          // If that exists, the spec must be rewritten.
+          string resource_base_path = *resource_base->get();
+          LOG(INFO) << "Creating new ComputeSessionPool in container handle: "
+                    << container << " using resource directory base "
+                    << resource_base_path;
+          RewriteMasterSpec(resource_base_path);
+          resource_base->Unref();
+        } else {
+          // If not, just use the spec as is.
+          LOG(INFO) << "Creating new ComputeSessionPool in container handle: "
+                    << container << " without editing master spec.";
+        }
+      }
       std::unique_ptr<ComputeSessionPool> pool(
           new ComputeSessionPool(master_spec_, grid_point_));
       *resource = new ComputeSessionPoolResource(std::move(pool));
@@ -120,6 +199,23 @@ class GetSession : public OpKernel {
   }
 
  private:
+  // Rewrites this op's saved MasterSpec, appending the new base directory.
+  void RewriteMasterSpec(const string &new_base) {
+    for (auto &component_spec : *master_spec_.mutable_component()) {
+      for (auto &resource_def : *component_spec.mutable_resource()) {
+        for (auto &part_def : *resource_def.mutable_part()) {
+          part_def.set_file_pattern(
+              JoinPath(new_base, part_def.file_pattern()));
+          VLOG(2) << "New path: " << part_def.file_pattern();
+        }
+      }
+    }
+
+    VLOG(3) << "Rewritten spec: " << master_spec_.DebugString();
+    has_overwritten_spec_ = true;
+  }
+
+  bool has_overwritten_spec_;
   MasterSpec master_spec_;
   GridPoint grid_point_;
 
@@ -141,7 +237,6 @@ REGISTER_KERNEL_BUILDER(Name("GetSession").Device(DEVICE_CPU), GetSession);
 class ReleaseSession : public OpKernel {
  public:
   explicit ReleaseSession(OpKernelConstruction *context) : OpKernel(context) {
-    string master_spec_str;
     OP_REQUIRES_OK(context, context->MatchSignature({DT_STRING}, {}));
   }
 
@@ -188,6 +283,53 @@ class ReleaseSession : public OpKernel {
 REGISTER_KERNEL_BUILDER(Name("ReleaseSession").Device(DEVICE_CPU),
                         ReleaseSession);
 
+// Returns statistics about session loads to the graph. This op returns the
+// total number of created Session objects and the number of those objects
+// that are currently being used in the ComputeSessionPool.
+class GetSessionCounts : public OpKernel {
+ public:
+  explicit GetSessionCounts(OpKernelConstruction *context) : OpKernel(context) {
+    OP_REQUIRES_OK(context, context->MatchSignature({DT_STRING}, {DT_INT64}));
+  }
+
+  void Compute(OpKernelContext *context) override {
+    const string container = context->input(0).scalar<string>()();
+    VLOG(1) << "Getting stats for container: " << container;
+    ResourceMgr *rmgr = context->resource_manager();
+
+    // Allocate the output tensors.
+    Tensor *output;
+    OP_REQUIRES_OK(context,
+                   context->allocate_output(0, TensorShape({2}), &output));
+
+    // Get the pool for this container.
+    ComputeSessionPoolResource *pool_resource;
+    auto result = rmgr->Lookup<ComputeSessionPoolResource>(container, "pool",
+                                                           &pool_resource);
+    if (!result.ok()) {
+      // If there's no ComputeSessionPoolResource, report 0 sessions created
+      // and 0 available.
+      output->vec<int64>()(0) = 0;
+      output->vec<int64>()(1) = 0;
+      return;
+    }
+
+    auto *pool = pool_resource->get();
+    CHECK(pool != nullptr);
+
+    output->vec<int64>()(0) = pool->num_unique_sessions();
+    output->vec<int64>()(1) = pool->num_outstanding_sessions();
+
+    pool_resource->Unref();
+  }
+
+ private:
+  TF_DISALLOW_COPY_AND_ASSIGN(GetSessionCounts);
+};
+
+REGISTER_KERNEL_BUILDER(Name("GetSessionCounts").Device(DEVICE_CPU),
+                        GetSessionCounts);
+
 /*******************************************************************************
  *                   ComputeSessionOps below here.
  ******************************************************************************/
@@ -233,9 +375,17 @@ class AdvanceFromPrediction : public ComputeSessionOp {
   void ComputeWithState(OpKernelContext *context,
                         ComputeSession *session) override {
     const Tensor &scores = context->input(1);
-    session->AdvanceFromPrediction(component_name(),
-                                   scores.tensor<float, 2>().data(),
-                                   scores.NumElements());
+    const int num_items = scores.shape().dim_size(0);
+    const int num_actions = scores.shape().dim_size(1);
+    bool success = session->AdvanceFromPrediction(
+        component_name(), scores.tensor<float, 2>().data(), num_items,
+        num_actions);
+    if (success) {
+      VLOG(2) << "Score: " << scores.tensor<float, 2>();
+    }
+    OP_REQUIRES(
+        context, success,
+        tensorflow::errors::Internal("Unable to advance from prediction."));
   }
 
  private:
@@ -247,13 +397,12 @@ REGISTER_KERNEL_BUILDER(Name("AdvanceFromPrediction").Device(DEVICE_CPU),
 
 // Given a handle to a ComputeSession and a channel index, outputs fixed
 // features.
-// Fixed features are returned as 3 vectors or equal length:
+// Fixed features are returned as 3 vectors of equal length:
 //   - ids: specifies which rows should be looked up in the embedding
 //   matrix,
 //   - weights: specifies a scale for each embedding vector,
 //   - indices: sorted vector that assigns the same index to embedding
-//   vectors
-//       that should be summed together.
+//   vectors that should be summed together.
 //
 // For example if we have 3 features, for a given channel, we might have:
 //   feature a: (5, 1)
@@ -300,7 +449,10 @@ class ExtractFixedFeatures : public ComputeSessionOp {
     int num_features = session->GetInputFeatures(
         component_name(), indices_allocator, ids_allocator, weights_allocator,
         channel_id_);
-    VLOG(2) << "Extracted " << num_features;
+    VLOG(2) << "Extracted features (" << num_features << "): "
+            << " ids="     << context->mutable_output(1)->vec<int64>()
+            << " weights=" <<  context->mutable_output(2)->vec<float>()
+            << " indices=" << context->mutable_output(0)->vec<int32>();
   }
 
  private:
@@ -524,6 +676,7 @@ class AttachDataReader : public ComputeSessionOp {
     auto input_data(context->input(1).vec<string>());
 
     std::vector<string> data;
+    data.reserve(input_data.size());
     for (int i = 0; i < input_data.size(); ++i) {
       data.push_back(input_data(i));
     }
@@ -642,5 +795,6 @@ class GetComponentTrace : public ComputeSessionOp {
 REGISTER_KERNEL_BUILDER(Name("GetComponentTrace").Device(DEVICE_CPU),
                         GetComponentTrace);
 
+}  // namespace
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc b/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc
index 92444fa9..f615b035 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc
@@ -17,6 +17,7 @@
 #include <memory>
 #include <vector>
 
+#include "dragnn/core/component_registry.h"
 #include "dragnn/core/compute_session.h"
 #include "dragnn/core/compute_session_pool.h"
 #include "dragnn/core/resource_container.h"
@@ -66,6 +67,87 @@ using testing::Return;
 
 typedef ResourceContainer<ComputeSession> ComputeSessionResource;
 typedef ResourceContainer<ComputeSessionPool> ComputeSessionPoolResource;
+typedef ResourceContainer<string> StringResource;
+
+namespace {
+const char kGlobalContainer[] = "__reserved_global_container";
+const char kBasePathTag[] = "__reserved_asset_base_path";
+const char kUnmanagedAssetDirectory[] = "assets.extra";
+}  // namespace
+
+// Define a test component to validate registered construction.
+class TestComponent : public Component {
+ public:
+  TestComponent() {}
+  void InitializeComponent(const ComponentSpec &spec) override {
+    name_ = spec.name();
+  }
+  void InitializeData(
+      const std::vector<std::vector<const TransitionState *>> &states,
+      int max_beam_size, InputBatchCache *input_data) override {}
+  void InitializeTracing() override {}
+  void DisableTracing() override {}
+  bool IsReady() const override { return true; }
+  string Name() const override { return name_; }
+  int BeamSize() const override { return 3; }
+  int BatchSize() const override { return 1; }
+  int StepsTaken(int batch_index) const override { return 0; }
+  int GetBeamIndexAtStep(int step, int current_index,
+                         int batch) const override {
+    return 0;
+  }
+  int GetSourceBeamIndex(int current_index, int batch) const override {
+    return 0;
+  }
+  bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                             int num_actions) override {
+    return true;
+  }
+  void AdvanceFromOracle() override {}
+  bool IsTerminal() const override { return true; }
+  std::function<int(int, int, int)> GetStepLookupFunction(
+      const string &method) override {
+    return nullptr;
+  }
+  std::vector<std::vector<const TransitionState *>> GetBeam() override {
+    std::vector<std::vector<const TransitionState *>> states;
+    return states;
+  }
+  int GetFixedFeatures(std::function<int32 *(int)> allocate_indices,
+                       std::function<int64 *(int)> allocate_ids,
+                       std::function<float *(int)> allocate_weights,
+                       int channel_id) const override {
+    return 0;
+  }
+  int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override {
+    return 0;
+  }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_matrix) override {}
+  std::vector<LinkFeatures> GetRawLinkFeatures(int channel_id) const override {
+    std::vector<LinkFeatures> ret;
+    return ret;
+  }
+  std::vector<std::vector<int>> GetOracleLabels() const override {
+    std::vector<std::vector<int>> ret;
+    return ret;
+  }
+  void FinalizeData() override {}
+  void ResetComponent() override {}
+
+  std::vector<std::vector<ComponentTrace>> GetTraceProtos() const override {
+    std::vector<std::vector<ComponentTrace>> ret;
+    return ret;
+  }
+  void AddTranslatedLinkFeaturesToTrace(
+      const std::vector<LinkFeatures> &features, int channel_id) override {}
+
+  string name_;
+};
+
+REGISTER_DRAGNN_COMPONENT(TestComponent);
 
 class DragnnOpKernelsTest : public tensorflow::OpsTestBase {
  public:
@@ -106,6 +188,42 @@ LinkFeatures MakeFeatures(int batch_index, int beam_index, int step) {
   return features;
 }
 
+// The SetAssetDirectory op should
+// 1. When given an asset path (foo/bar/baz/asset/thing), strip the path to
+//    foo/bar/baz and add 'assets.extra' to it.
+// 2. Store that path in the resource manager.
+TEST_F(DragnnOpKernelsTest, SetAssetDirectoryTest) {
+  // Create a MasterSpec and GridPoint string to pass into the attrs for this
+  // op.
+  const string new_asset_path = "new/directory/path/asset/master_spec";
+  const string expected_asset_path =
+      StrCat("new/directory/path/", kUnmanagedAssetDirectory);
+
+  // Create and initialize the kernel under test.
+  TF_ASSERT_OK(NodeDefBuilder("set_asset_directory", "SetAssetDirectory")
+                   .Input(FakeInput(DT_STRING))  // The new asset path.
+                   .Finalize(node_def()));
+  TF_ASSERT_OK(InitOp());
+
+  // Set the input data.
+  AddInputFromList<string>(TensorShape({1}), {new_asset_path});
+
+  // Reset the test context to ensure it's clean.
+  ResetOpKernelContext();
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+
+  // Expect that the ResourceMgr contains a the correct string.
+  StringResource *resource;
+  TF_EXPECT_OK(resource_mgr()->Lookup<StringResource>(kGlobalContainer,
+                                                      kBasePathTag, &resource));
+
+  EXPECT_EQ(*resource->get(), expected_asset_path);
+
+  resource->Unref();
+}
+
 // The GetSessionOp should
 // 1. create a ComputeSessionPool resource and store it in the ResourceMgr,
 // 2. create a ComputeSession resource and store it in the ResourceMgr,
@@ -164,6 +282,103 @@ TEST_F(DragnnOpKernelsTest, GetSessionOpTest) {
   pool_resource->Unref();
 }
 
+// If an asset_base_path resource exists, the GetSession op should prepend
+// that path to all paths in the MasterSpec before creating a session.
+TEST_F(DragnnOpKernelsTest, GetSessionWithAssetBasePathTest) {
+  // Create a MasterSpec and GridPoint string to pass into the attrs for this
+  // op.
+  const string new_asset_path = "new/base";
+  MasterSpec spec;
+
+  // The first component in the MasterSpec has one resource with one part.
+  auto component_one = spec.add_component();
+  auto backend_one = component_one->mutable_backend();
+  backend_one->set_registered_name("TestComponent");
+  component_one->add_resource()->add_part()->set_file_pattern(
+      "path/to/an/asset.txt");
+  const string expected_component_one_asset = "new/base/path/to/an/asset.txt";
+
+  auto component_two = spec.add_component();
+  auto backend_two = component_two->mutable_backend();
+  backend_two->set_registered_name("TestComponent");
+
+  // The second component's first resource has no assets.
+  component_two->add_resource();
+
+  // The second component's second resource has one part.
+  vector<string> expected_component_two_assets;
+  component_two->add_resource()->add_part()->set_file_pattern(
+      "another/dir/with/an/asset.txt");
+  expected_component_two_assets.push_back(
+      "new/base/another/dir/with/an/asset.txt");
+
+  // The second component's third resource has two parts.
+  auto third_resource = component_two->add_resource();
+  third_resource->add_part()->set_file_pattern(
+      "another/dir/with/an/asset3.jif");
+  expected_component_two_assets.push_back(
+      "new/base/another/dir/with/an/asset3.jif");
+  third_resource->add_part()->set_file_pattern(
+      "another/dir/with/an/asset4.jif");
+  expected_component_two_assets.push_back(
+      "new/base/another/dir/with/an/asset4.jif");
+
+  LOG(INFO) << spec.DebugString();
+
+  string master_spec_str;
+  spec.SerializeToString(&master_spec_str);
+
+  GridPoint hyperparams;
+  string hyperparams_str;
+  hyperparams.SerializeToString(&hyperparams_str);
+
+  // Create and initialize the kernel under test.
+  TF_ASSERT_OK(
+      NodeDefBuilder("get_session", "GetSession")
+          .Attr("master_spec", master_spec_str)
+          .Attr("grid_point", hyperparams_str)
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Finalize(node_def()));
+  TF_ASSERT_OK(InitOp());
+
+  // Set the input data.
+  const string container_string = "container_str";
+  AddInputFromList<string>(TensorShape({1}), {container_string});
+
+  // Reset the test context to ensure it's clean.
+  ResetOpKernelContext();
+
+  // Create the string in the resource manager.
+  std::unique_ptr<string> asset_path_ptr(new string(new_asset_path));
+
+  TF_EXPECT_OK(resource_mgr()->Create<StringResource>(
+      kGlobalContainer, kBasePathTag,
+      new StringResource(std::move(asset_path_ptr))));
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+
+  // Expect that the ResourceMgr contains a ComputeSessionPoolResource.
+  const string pool_id_str = "pool";
+  ComputeSessionPoolResource *pool_resource;
+  TF_EXPECT_OK(resource_mgr()->Lookup<ComputeSessionPoolResource>(
+      container_string, pool_id_str, &pool_resource));
+
+  // Validate that the master spec held by the pool has the new directory names.
+  auto rewritten_spec = pool_resource->get()->GetSpec();
+  EXPECT_EQ(rewritten_spec.component(0).resource(0).part(0).file_pattern(),
+            expected_component_one_asset);
+  EXPECT_EQ(rewritten_spec.component(1).resource(1).part(0).file_pattern(),
+            expected_component_two_assets.at(0));
+  EXPECT_EQ(rewritten_spec.component(1).resource(2).part(0).file_pattern(),
+            expected_component_two_assets.at(1));
+  EXPECT_EQ(rewritten_spec.component(1).resource(2).part(1).file_pattern(),
+            expected_component_two_assets.at(2));
+
+  // Unref the managed resources so they get destroyed properly.
+  pool_resource->Unref();
+}
+
 // The GetSessionOp should take a session stored in the resource manager
 // and return it to the ComputeSessionPool.
 TEST_F(DragnnOpKernelsTest, ReleaseSessionOpTest) {
@@ -217,6 +432,56 @@ TEST_F(DragnnOpKernelsTest, ReleaseSessionOpTest) {
   EXPECT_EQ(null_resource, nullptr);
 }
 
+// The GetSessionCounts op should report the number of sessions created and
+// free.
+TEST_F(DragnnOpKernelsTest, GetSessionCountsOpTest) {
+  // Create and initialize the kernel under test.
+  TF_ASSERT_OK(
+      NodeDefBuilder("get_session_counts", "GetSessionCounts")
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Finalize(node_def()));
+  TF_ASSERT_OK(InitOp());
+
+  // Set the input data.
+  const string container_string = "container_str";
+  AddInputFromList<string>(TensorShape({1}), {container_string});
+
+  // Reset the test context to ensure it's clean.
+  ResetOpKernelContext();
+
+  // Create a ComputeSessionPool.
+  MasterSpec spec;
+  GridPoint hyperparams;
+  std::unique_ptr<ComputeSessionPool> pool(
+      new ComputeSessionPool(spec, hyperparams));
+
+  // Get an unowned pointer to the ComputeSessionPool before moving
+  // the pool to the resource manager.
+  ComputeSessionPool *pool_ptr = pool.get();
+  TF_ASSERT_OK(resource_mgr()->Create<ComputeSessionPoolResource>(
+      container_string, "pool",
+      new ComputeSessionPoolResource(std::move(pool))));
+
+  // Create two ComputeSessions.
+  auto session_one = pool_ptr->GetSession();
+  auto session_two = pool_ptr->GetSession();
+
+  // Retun one of them.
+  pool_ptr->ReturnSession(std::move(session_two));
+
+  // At this point, the pool should report that it has one outstanding session
+  // and two sessions total.
+  EXPECT_EQ(1, pool_ptr->num_outstanding_sessions());
+  EXPECT_EQ(2, pool_ptr->num_unique_sessions());
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+
+  EXPECT_EQ(pool_ptr->num_unique_sessions(), GetOutput(0)->vec<int64>()(0));
+  EXPECT_EQ(pool_ptr->num_outstanding_sessions(),
+            GetOutput(0)->vec<int64>()(1));
+}
+
 // The AdvanceFromOracle op should call AdvanceFromOracle on the specified
 // component name.
 TEST_F(DragnnOpKernelsTest, AdvanceFromOracleOpTest) {
@@ -287,14 +552,65 @@ TEST_F(DragnnOpKernelsTest, AdvanceFromPredictionOpTest) {
 
   // Set expectations on the mock session.
   auto validator_function = [weights](const string &component_name,
-                                      const float score_matrix[],
-                                      int score_matrix_length) {
-    EXPECT_EQ(weights.size(), score_matrix_length);
+                                      const float *score_matrix, int num_items,
+                                      int num_actions) {
+    EXPECT_EQ(weights.size(), num_items * num_actions);
+    for (int i = 0; i < weights.size(); ++i) {
+      EXPECT_EQ(weights[i], score_matrix[i]);
+    }
+    return true;
+  };
+  EXPECT_CALL(*mock_session_ptr, AdvanceFromPrediction(component_name, _, _, _))
+      .WillOnce(Invoke(validator_function));
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+}
+
+// The AdvanceFromPredicton op should call AdvanceFromPrediction on the
+// specified component with the passed scores. If it returns false, the op
+// should not return OK.
+TEST_F(DragnnOpKernelsTest, AdvanceFromPredictionFailureTest) {
+  // Create and initialize the kernel under test.
+  const string component_name = "TESTING_COMPONENT_NAME";
+  TF_ASSERT_OK(
+      NodeDefBuilder("advance_from_prediction", "AdvanceFromPrediction")
+          .Attr("component", component_name)
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Input(FakeInput(DT_FLOAT))   // The prediction tensor.
+          .Finalize(node_def()));
+  TF_ASSERT_OK(InitOp());
+
+  // Set the input data.
+  const string container_string = "container_str";
+  const string id_string = "id_str";
+  AddInputFromList<string>(TensorShape({2}), {container_string, id_string});
+  const std::vector<float> weights = {1.1, 2.2, 3.3, 4.4};
+  AddInputFromArray<float>(TensorShape({2, 2}), weights);
+
+  // Reset the test context to ensure it's clean.
+  ResetOpKernelContext();
+
+  // Create a MockComputeSession and set expectations.
+  std::unique_ptr<MockComputeSession> mock_session(new MockComputeSession());
+  MockComputeSession *mock_session_ptr = mock_session.get();
+
+  // Wrap the ComputeSessionResource and put it into the resource manager.
+  TF_ASSERT_OK(resource_mgr()->Create<ComputeSessionResource>(
+      container_string, id_string,
+      new ComputeSessionResource(std::move(mock_session))));
+
+  // Set expectations on the mock session.
+  auto validator_function = [weights](const string &component_name,
+                                      const float *score_matrix, int num_items,
+                                      int num_actions) {
+    EXPECT_EQ(weights.size(), num_items * num_actions);
     for (int i = 0; i < weights.size(); ++i) {
       EXPECT_EQ(weights[i], score_matrix[i]);
     }
+    return true;
   };
-  EXPECT_CALL(*mock_session_ptr, AdvanceFromPrediction(component_name, _, _))
+  EXPECT_CALL(*mock_session_ptr, AdvanceFromPrediction(component_name, _, _, _))
       .WillOnce(Invoke(validator_function));
 
   // Run the kernel.
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc b/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc
index f2bd653b..c7d3c639 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc
@@ -18,6 +18,20 @@
 namespace syntaxnet {
 namespace dragnn {
 
+REGISTER_OP("SetAssetDirectory")
+    .Input("asset_directory: string")
+    .Output("asset_directory_out: string")
+    .SetIsStateful()
+    .Doc(R"doc(
+Override the paths to assets specified in the MasterSpec with the given
+asset_directory. This op must be called before any calls to GetSession, as it
+will create a new session pool with the overridden master spec.
+
+asset_directory: The directory containing all the assets. Note that all assets
+    must be in a single flat directory.
+asset_directory_out: The input, just as an output.
+)doc");
+
 REGISTER_OP("GetSession")
     .Input("container: string")
     .Attr("master_spec: string")
@@ -42,6 +56,18 @@ This ComputeSession will no longer be available after this op returns.
 handle: A handle to a ComputeSession that will be returned to the backing pool.
 )doc");
 
+REGISTER_OP("GetSessionCounts")
+    .Input("container: string")
+    .Output("stats: int64")
+    .SetIsStateful()
+    .Doc(R"doc(
+Given a container string, output session counts for that ComputeSessionPool.
+
+container: A unique identifier for the ComputeSessionPool to analyze.
+stats: A vector of stats. [0] is the total number of created sessions. [1] is
+the number of sessions that are currently not in the pool.
+)doc");
+
 REGISTER_OP("InitComponentData")
     .Input("handle: string")
     .Input("beam_size: int32")
@@ -123,28 +149,6 @@ component: The name of a Component instance, matching the ComponentSpec.name.
 output_handle: A handle to the same ComputeSession after advancement.
 )doc");
 
-REGISTER_OP("DragnnEmbeddingInitializer")
-    .Output("embeddings: float")
-    .Attr("embedding_input: string")
-    .Attr("vocab: string")
-    .Attr("scaling_coefficient: float = 1.0")
-    .Attr("seed: int = 0")
-    .Attr("seed2: int = 0")
-    .Doc(R"doc(
-*** PLACEHOLDER OP - FUNCTIONALITY NOT YET IMPLEMENTED ***
-
-Read embeddings from an an input for every key specified in a text vocab file.
-
-embeddings: A tensor containing embeddings from the specified sstable.
-embedding_input: Path to location with embedding vectors.
-vocab: Path to list of keys corresponding to the input.
-scaling_coefficient: A scaling coefficient for the embedding matrix.
-seed: If either `seed` or `seed2` are set to be non-zero, the random number
-      generator is seeded by the given seed.  Otherwise, it is seeded by a
-      random seed.
-seed2: A second seed to avoid seed collision.
-)doc");
-
 REGISTER_OP("ExtractFixedFeatures")
     .Input("handle: string")
     .Output("indices: int32")
diff --git a/research/syntaxnet/dragnn/core/resource_container.h b/research/syntaxnet/dragnn/core/resource_container.h
index 7ca72a05..7e06b856 100644
--- a/research/syntaxnet/dragnn/core/resource_container.h
+++ b/research/syntaxnet/dragnn/core/resource_container.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_RESOURCE_CONTAINER_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_RESOURCE_CONTAINER_H_
+#ifndef DRAGNN_CORE_RESOURCE_CONTAINER_H_
+#define DRAGNN_CORE_RESOURCE_CONTAINER_H_
 
 #include <memory>
 
@@ -48,4 +48,4 @@ class ResourceContainer : public tensorflow::ResourceBase {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_RESOURCE_CONTAINER_H_
+#endif  // DRAGNN_CORE_RESOURCE_CONTAINER_H_
diff --git a/research/syntaxnet/dragnn/core/test/BUILD b/research/syntaxnet/dragnn/core/test/BUILD
index 9810bd25..157b019f 100644
--- a/research/syntaxnet/dragnn/core/test/BUILD
+++ b/research/syntaxnet/dragnn/core/test/BUILD
@@ -26,6 +26,7 @@ cc_library(
     deps = [
         "//dragnn/components/util:bulk_feature_extractor",
         "//dragnn/core:compute_session",
+        "//dragnn/core:input_batch_cache",
         "//dragnn/protos:data_proto",
         "//dragnn/protos:spec_proto",
         "//syntaxnet:base",
diff --git a/research/syntaxnet/dragnn/core/test/generic.h b/research/syntaxnet/dragnn/core/test/generic.h
index 5624856b..b8e93d14 100644
--- a/research/syntaxnet/dragnn/core/test/generic.h
+++ b/research/syntaxnet/dragnn/core/test/generic.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_GENERIC_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_GENERIC_H_
+#ifndef DRAGNN_CORE_TEST_GENERIC_H_
+#define DRAGNN_CORE_TEST_GENERIC_H_
 
 #include <utility>
 
@@ -31,10 +31,18 @@ MATCHER_P(EqualsProto, a, "Protos are not equivalent:") {
   return a.DebugString() == arg.DebugString();
 }
 
+// Matches an error status whose message matches |substr|.
+MATCHER_P(IsErrorWithSubstr, substr,
+          string(negation ? "isn't" : "is") +
+          " an error Status whose message matches the substring '" +
+          ::testing::PrintToString(substr) + "'") {
+  return !arg.ok() && arg.error_message().find(substr) != string::npos;
+}
+
 // Returns the prefix for where the test data is stored.
 string GetTestDataPrefix();
 
 }  // namespace test
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_GENERIC_H_
+#endif  // DRAGNN_CORE_TEST_GENERIC_H_
diff --git a/research/syntaxnet/dragnn/core/test/mock_component.h b/research/syntaxnet/dragnn/core/test/mock_component.h
index 74d9986b..52373351 100644
--- a/research/syntaxnet/dragnn/core/test/mock_component.h
+++ b/research/syntaxnet/dragnn/core/test/mock_component.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
+#ifndef DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
+#define DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
 
 #include <gmock/gmock.h>
 
@@ -47,8 +47,8 @@ class MockComponent : public Component {
   MOCK_CONST_METHOD3(GetBeamIndexAtStep,
                      int(int step, int current_index, int batch));
   MOCK_CONST_METHOD2(GetSourceBeamIndex, int(int current_index, int batch));
-  MOCK_METHOD2(AdvanceFromPrediction,
-               void(const float transition_matrix[], int matrix_length));
+  MOCK_METHOD3(AdvanceFromPrediction, bool(const float *transition_matrix,
+                                           int num_items, int num_actions));
   MOCK_METHOD0(AdvanceFromOracle, void());
   MOCK_CONST_METHOD0(IsTerminal, bool());
   MOCK_METHOD0(GetBeam, std::vector<std::vector<const TransitionState *>>());
@@ -59,6 +59,11 @@ class MockComponent : public Component {
                          int channel_id));
   MOCK_METHOD1(BulkGetFixedFeatures,
                int(const BulkFeatureExtractor &extractor));
+  MOCK_METHOD5(BulkEmbedFixedFeatures,
+               void(int batch_size_padding, int num_steps_padding,
+                    int output_array_size,
+                    const vector<const float *> &per_channel_embeddings,
+                    float *embedding_output));
   MOCK_CONST_METHOD1(GetRawLinkFeatures,
                      std::vector<LinkFeatures>(int channel_id));
   MOCK_CONST_METHOD0(GetOracleLabels, std::vector<std::vector<int>>());
@@ -75,4 +80,4 @@ class MockComponent : public Component {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
+#endif  // DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
diff --git a/research/syntaxnet/dragnn/core/test/mock_compute_session.h b/research/syntaxnet/dragnn/core/test/mock_compute_session.h
index 8df455c4..26458968 100644
--- a/research/syntaxnet/dragnn/core/test/mock_compute_session.h
+++ b/research/syntaxnet/dragnn/core/test/mock_compute_session.h
@@ -13,16 +13,18 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
+#ifndef DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
+#define DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
 
-#include <gmock/gmock.h>
+#include <memory>
 
 #include "dragnn/components/util/bulk_feature_extractor.h"
 #include "dragnn/core/compute_session.h"
+#include "dragnn/core/input_batch_cache.h"
 #include "dragnn/protos/data.pb.h"
 #include "dragnn/protos/spec.pb.h"
 #include "syntaxnet/base.h"
+#include <gmock/gmock.h>
 #include "tensorflow/core/platform/test.h"
 
 namespace syntaxnet {
@@ -40,9 +42,9 @@ class MockComputeSession : public ComputeSession {
   MOCK_METHOD2(SourceComponentBeamSize,
                int(const string &component_name, int channel_id));
   MOCK_METHOD1(AdvanceFromOracle, void(const string &component_name));
-  MOCK_METHOD3(AdvanceFromPrediction,
-               void(const string &component_name, const float score_matrix[],
-                    int score_matrix_length));
+  MOCK_METHOD4(AdvanceFromPrediction,
+               bool(const string &component_name, const float *score_matrix,
+                    int num_items, int num_actions));
   MOCK_CONST_METHOD5(GetInputFeatures,
                      int(const string &component_name,
                          std::function<int32 *(int)> allocate_indices,
@@ -52,6 +54,11 @@ class MockComputeSession : public ComputeSession {
   MOCK_METHOD2(BulkGetInputFeatures,
                int(const string &component_name,
                    const BulkFeatureExtractor &extractor));
+  MOCK_METHOD6(BulkEmbedFixedFeatures,
+               void(const string &component_name, int batch_size_padding,
+                    int num_steps_padding, int output_array_size,
+                    const vector<const float *> &per_channel_embedding,
+                    float *embedding_output));
   MOCK_METHOD2(GetTranslatedLinkFeatures,
                std::vector<LinkFeatures>(const string &component_name,
                                          int channel_id));
@@ -68,9 +75,17 @@ class MockComputeSession : public ComputeSession {
   MOCK_CONST_METHOD1(GetDescription, string(const string &component_name));
   MOCK_CONST_METHOD1(Translators, const std::vector<const IndexTranslator *>(
                                       const string &component_name));
+  MOCK_CONST_METHOD1(GetReadiedComponent, Component *(const string &name));
+
+  // TODO(googleuser): Upgrade gMock to a version that supports mocking methods
+  // with move-only types, then remove this workaround.
+  MOCK_METHOD1(DoSetInputBatchCache, void(InputBatchCache *batch));
+  void SetInputBatchCache(std::unique_ptr<InputBatchCache> batch) override {
+    DoSetInputBatchCache(batch.get());
+  }
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
+#endif  // DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
diff --git a/research/syntaxnet/dragnn/core/test/mock_transition_state.h b/research/syntaxnet/dragnn/core/test/mock_transition_state.h
index a6737cb3..a90ff74e 100644
--- a/research/syntaxnet/dragnn/core/test/mock_transition_state.h
+++ b/research/syntaxnet/dragnn/core/test/mock_transition_state.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
+#ifndef DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
+#define DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
 
 #include <memory>
 
@@ -31,15 +31,17 @@ class MockTransitionState : public TransitionState {
  public:
   MOCK_METHOD1(Init, void(const TransitionState &parent));
   MOCK_CONST_METHOD0(Clone, std::unique_ptr<TransitionState>());
-  MOCK_CONST_METHOD0(ParentBeamIndex, const int());
-  MOCK_METHOD1(SetBeamIndex, void(const int index));
-  MOCK_CONST_METHOD0(GetBeamIndex, const int());
-  MOCK_CONST_METHOD0(GetScore, const float());
-  MOCK_METHOD1(SetScore, void(const float score));
+  MOCK_CONST_METHOD0(ParentBeamIndex, int());
+  MOCK_METHOD1(SetBeamIndex, void(int index));
+  MOCK_CONST_METHOD0(GetBeamIndex, int());
+  MOCK_CONST_METHOD0(GetScore, float());
+  MOCK_METHOD1(SetScore, void(float score));
+  MOCK_CONST_METHOD0(IsGold, bool());
+  MOCK_METHOD1(SetGold, void(bool is_gold));
   MOCK_CONST_METHOD0(HTMLRepresentation, string());
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
+#endif  // DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
diff --git a/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto b/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto
index aea09690..6e991e03 100644
--- a/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto
+++ b/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto
@@ -11,10 +11,6 @@ component {
       key: "language"
       value: "en"
     }
-    parameters {
-      key: "neurosis_feature_syntax_version"
-      value: "2"
-    }
     parameters {
       key: "parser_skip_deterministic"
       value: "false"
diff --git a/research/syntaxnet/dragnn/io/sentence_input_batch.h b/research/syntaxnet/dragnn/io/sentence_input_batch.h
index 7c355813..0343d470 100644
--- a/research/syntaxnet/dragnn/io/sentence_input_batch.h
+++ b/research/syntaxnet/dragnn/io/sentence_input_batch.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
+#ifndef DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
+#define DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
 
 #include <string>
 #include <vector>
@@ -35,6 +35,9 @@ class SentenceInputBatch : public InputBatch {
   void SetData(
       const std::vector<string> &stringified_sentence_protos) override;
 
+  // Returns the size of the batch.
+  int GetSize() const override { return data_.size(); }
+
   // Translates to a vector of stringified Sentence protos.
   const std::vector<string> GetSerializedData() const override;
 
@@ -49,4 +52,4 @@ class SentenceInputBatch : public InputBatch {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
+#endif  // DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
diff --git a/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc b/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc
index 0a3f6e69..516feecc 100644
--- a/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc
+++ b/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc
@@ -49,6 +49,9 @@ TEST(SentenceInputBatchTest, ConvertsFromStringifiedProtos) {
     EXPECT_NE(converted_data->at(i).workspace(), nullptr);
   }
 
+  // Check the batch size.
+  EXPECT_EQ(strings.size(), set.GetSize());
+
   // Get the data back out. The strings should be identical.
   auto output = set.GetSerializedData();
   EXPECT_EQ(output.size(), strings.size());
diff --git a/research/syntaxnet/dragnn/io/syntaxnet_sentence.h b/research/syntaxnet/dragnn/io/syntaxnet_sentence.h
index d9076b44..aaf19b6d 100644
--- a/research/syntaxnet/dragnn/io/syntaxnet_sentence.h
+++ b/research/syntaxnet/dragnn/io/syntaxnet_sentence.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_IO_SYNTAXNET_SENTENCE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_IO_SYNTAXNET_SENTENCE_H_
+#ifndef DRAGNN_IO_SYNTAXNET_SENTENCE_H_
+#define DRAGNN_IO_SYNTAXNET_SENTENCE_H_
 
 #include "syntaxnet/sentence.pb.h"
 #include "syntaxnet/workspace.h"
@@ -39,4 +39,4 @@ class SyntaxNetSentence {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_IO_SYNTAXNET_SENTENCE_H_
+#endif  // DRAGNN_IO_SYNTAXNET_SENTENCE_H_
diff --git a/research/syntaxnet/dragnn/protos/BUILD b/research/syntaxnet/dragnn/protos/BUILD
index 15592327..f4ae023a 100644
--- a/research/syntaxnet/dragnn/protos/BUILD
+++ b/research/syntaxnet/dragnn/protos/BUILD
@@ -26,6 +26,12 @@ tf_proto_library(
     srcs = ["spec.proto"],
 )
 
+tf_proto_library(
+    name = "runtime_proto",
+    srcs = ["runtime.proto"],
+    deps = [":spec_proto"],
+)
+
 tf_proto_library_py(
     name = "data_py_pb2",
     srcs = ["data.proto"],
diff --git a/research/syntaxnet/dragnn/protos/runtime.proto b/research/syntaxnet/dragnn/protos/runtime.proto
new file mode 100644
index 00000000..550a5d3c
--- /dev/null
+++ b/research/syntaxnet/dragnn/protos/runtime.proto
@@ -0,0 +1,81 @@
+syntax = "proto2";
+
+import "dragnn/protos/spec.proto";
+
+package syntaxnet.dragnn.runtime;
+
+// Performance tuning settings that only affect resource usage, not annotated
+// output or correctness.  This should be attached to the MasterSpec used to
+// initialize a Master.
+//
+// NEXT ID: 2
+message MasterPerformanceSettings {
+  extend MasterSpec {
+    optional MasterPerformanceSettings master_spec_extension = 160848628;
+  }
+
+  // Maximum size of the free list in the SessionStatePool.  NB: The default
+  // value may occasionally change.
+  optional uint64 session_state_pool_max_free_states = 1 [default = 4];
+}
+
+// As above, but for component-specific performance tuning settings.
+//
+// NEXT ID: 2
+message ComponentPerformanceSettings {
+  extend ComponentSpec {
+    optional ComponentPerformanceSettings component_spec_extension = 160999422;
+  }
+
+  // Number of steps to pre-allocate for the relevant component.  NB: The
+  // default value may occasionally change.
+  optional uint32 pre_allocate_num_steps = 1 [default = 50];
+}
+
+// Specification of an ArrayVariableStore.
+//
+// NEXT ID: 5
+message ArrayVariableStoreSpec {
+  // Characteristics of the variable data.  The binary that loads the variables
+  // must match these characteristics.
+  optional uint32 version = 1;  // required version of the byte array format
+  optional uint32 alignment_bytes = 2;  // required alignment of the byte array
+  optional bool is_little_endian = 3;  // required endian-ness of the byte array
+
+  // Variable specifications, in order of appearance in the byte array.
+  repeated VariableSpec variable = 4;
+}
+
+// Specification of a single serialized variable.
+//
+// NEXT ID: 6
+message VariableSpec {
+  // Formats for serialized pre-trained variables.  See VariableStore::Lookup()
+  // for descriptions of the enumerators.
+  enum Format {
+    FORMAT_UNKNOWN = 0;
+    FORMAT_FLAT = 1;
+    FORMAT_ROW_MAJOR_MATRIX = 2;
+    FORMAT_COLUMN_BLOCKED_ROW_MAJOR_MATRIX = 3;
+  }
+
+  // Name of the variable.
+  optional string name = 1;
+
+  // Format of the variable.
+  optional Format format = 2 [default = FORMAT_UNKNOWN];
+
+  // Dimensions of variables. The semantics depends on the format, but is always
+  // in logical units (number of floats, etc.) rather than bytes,
+  //
+  //  * flat: single value with the length of the vector
+  //  * row-major and column-major: two values, [rows, columns]
+  //  * row-blocked column-major: three values, [rows, columns, row_block_size]
+  repeated uint32 dimension = 5;
+
+  // Number of sub-views in the AlignedArea that contained the variable.
+  optional uint64 num_views = 3;
+
+  // Sub-view size in bytes for the AlignedArea that contained the variable.
+  optional uint64 view_size = 4;
+}
diff --git a/research/syntaxnet/dragnn/protos/spec.proto b/research/syntaxnet/dragnn/protos/spec.proto
index e4d4fd31..3e42ac1d 100644
--- a/research/syntaxnet/dragnn/protos/spec.proto
+++ b/research/syntaxnet/dragnn/protos/spec.proto
@@ -16,6 +16,7 @@ message MasterSpec {
   // Whether to extract debug traces.
   optional bool debug_tracing = 4 [default = false];
 
+  extensions 1000 to max;
   reserved 2, 3, 5;
 }
 
@@ -28,8 +29,7 @@ message ComponentSpec {
   // TransitionSystem to use.
   optional RegisteredModuleSpec transition_system = 2;
 
-  // Resources that this component depends on. These are copied to TaskInputs
-  // when calling SAFT code.
+  // Resources that this component depends on.
   repeated Resource resource = 3;
 
   // Feature space configurations.
@@ -58,6 +58,8 @@ message ComponentSpec {
 
   // Default max number of active states for beam inference.
   optional int32 inference_beam_size = 12 [default = 1];
+
+  extensions 1000 to max;
 }
 
 // Super generic container for any registered sub-piece of DRAGNN.
@@ -65,14 +67,11 @@ message RegisteredModuleSpec {
   // Name of the registered class.
   optional string registered_name = 1;
 
-  // Parameters to set while initializing this system; these are copied to
-  // Parameters in a TaskSpec when calling SAFT code, or via kwargs in TF Python
-  // code.
+  // Parameters to set while initializing this system.
   map<string, string> parameters = 2;
 }
 
-// Fixed resources that will be converted into TaskInput's when calling SAFT
-// code.
+// Fixed resource.
 message Resource {
   optional string name = 1;
   repeated Part part = 2;
@@ -218,6 +217,9 @@ message GridPoint {
   optional double gradient_clip_norm = 11 [default = 0.0];
 
   // A spec for using multiple optimization methods.
+  //
+  // This is not guaranteed to work for recursively-defined composite
+  // optimizers.
   message CompositeOptimizerSpec {
     // First optimizer.
     optional GridPoint method1 = 1;
@@ -227,6 +229,11 @@ message GridPoint {
 
     // After this number of steps, switch from first to second.
     optional int32 switch_after_steps = 3;
+
+    // Whether to reset the learning rate (which normally decays) after
+    // switching optimizers. Limitations: It will only reset to the initial
+    // learning rate, and won't work for recursively-defined optimizers.
+    optional bool reset_learning_rate = 4 [default = false];
   }
   optional CompositeOptimizerSpec composite_optimizer_spec = 12;
 
@@ -247,6 +254,7 @@ message GridPoint {
   // place. Typically a single component.
   optional string self_norm_components_filter = 21;
 
+  extensions 1000 to max;
   reserved 5, 6;
 }
 
diff --git a/research/syntaxnet/dragnn/python/BUILD b/research/syntaxnet/dragnn/python/BUILD
index 60ba4080..f1c528ab 100644
--- a/research/syntaxnet/dragnn/python/BUILD
+++ b/research/syntaxnet/dragnn/python/BUILD
@@ -16,6 +16,11 @@ cc_binary(
     ],
 )
 
+filegroup(
+    name = "testdata",
+    data = glob(["testdata/**"]),
+)
+
 py_library(
     name = "load_dragnn_cc_impl_py",
     srcs = ["load_dragnn_cc_impl.py"],
@@ -64,7 +69,51 @@ py_library(
 py_library(
     name = "dragnn_ops",
     srcs = ["dragnn_ops.py"],
-    deps = [],
+    deps = [
+        ":load_dragnn_cc_impl_py",
+        "//dragnn/core:dragnn_bulk_ops",
+        "//dragnn/core:dragnn_ops",
+        "//syntaxnet:load_parser_ops_py",
+    ],
+)
+
+py_library(
+    name = "dragnn_model_saver_lib",
+    srcs = ["dragnn_model_saver_lib.py"],
+    deps = [
+        ":dragnn_ops",
+        ":graph_builder",
+        ":load_dragnn_cc_impl_py",
+        ":network_units",
+        "//dragnn/protos:spec_py_pb2",
+        "//syntaxnet:load_parser_ops_py",
+        "//syntaxnet:sentence_py_pb2",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+        "@org_tensorflow//tensorflow/core:protos_all_py",
+    ],
+)
+
+py_test(
+    name = "dragnn_model_saver_lib_test",
+    srcs = ["dragnn_model_saver_lib_test.py"],
+    data = [":testdata"],
+    deps = [
+        ":dragnn_model_saver_lib",
+        "//dragnn/protos:spec_py_pb2",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+    ],
+)
+
+py_binary(
+    name = "dragnn_model_saver",
+    srcs = ["dragnn_model_saver.py"],
+    deps = [
+        ":dragnn_model_saver_lib",
+        ":spec_builder",
+        "//dragnn/protos:spec_py_pb2",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+        "@org_tensorflow//tensorflow/core:protos_all_py",
+    ],
 )
 
 py_library(
@@ -76,6 +125,7 @@ py_library(
         ":composite_optimizer",
         ":dragnn_ops",
         ":network_units",
+        ":transformer_units",
         ":wrapped_units",
         "//dragnn/protos:spec_py_pb2",
         "//syntaxnet/util:check",
@@ -184,10 +234,7 @@ py_test(
         ":bulk_component",
         ":components",
         ":dragnn_ops",
-        ":load_dragnn_cc_impl_py",
         ":network_units",
-        "//dragnn/core:dragnn_bulk_ops",
-        "//dragnn/core:dragnn_ops",
         "//dragnn/protos:spec_py_pb2",
         "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:sentence_py_pb2",
@@ -201,7 +248,6 @@ py_test(
     srcs = ["composite_optimizer_test.py"],
     deps = [
         ":composite_optimizer",
-        ":load_dragnn_cc_impl_py",
         "//dragnn/core:dragnn_bulk_ops",
         "//dragnn/core:dragnn_ops",
         "//syntaxnet:load_parser_ops_py",
@@ -217,15 +263,13 @@ py_test(
     data = [
         "//dragnn/core:testdata",
     ],
+    shard_count = 5,
     tags = [
         "notsan",
     ],
     deps = [
         ":dragnn_ops",
         ":graph_builder",
-        ":load_dragnn_cc_impl_py",
-        "//dragnn/core:dragnn_bulk_ops",
-        "//dragnn/core:dragnn_ops",
         "//dragnn/protos:spec_py_pb2",
         "//dragnn/protos:trace_py_pb2",
         "//syntaxnet:load_parser_ops_py",
@@ -240,7 +284,6 @@ py_test(
     size = "small",
     srcs = ["network_units_test.py"],
     deps = [
-        ":load_dragnn_cc_impl_py",
         ":network_units",
         "//dragnn/core:dragnn_bulk_ops",
         "//dragnn/core:dragnn_ops",
@@ -256,6 +299,7 @@ py_test(
     srcs = ["sentence_io_test.py"],
     data = ["//syntaxnet:testdata"],
     deps = [
+        ":dragnn_ops",
         ":sentence_io",
         "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:parser_ops",
@@ -373,3 +417,30 @@ py_library(
         "@org_tensorflow//tensorflow:tensorflow_py",
     ],
 )
+
+py_library(
+    name = "transformer_units",
+    srcs = ["transformer_units.py"],
+    deps = [
+        ":network_units",
+        "//syntaxnet/util:check",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+    ],
+)
+
+py_test(
+    name = "transformer_units_test",
+    size = "small",
+    srcs = ["transformer_units_test.py"],
+    deps = [
+        ":network_units",
+        ":transformer_units",
+        "//dragnn/core:dragnn_bulk_ops",
+        "//dragnn/core:dragnn_ops",
+        "//dragnn/protos:spec_py_pb2",
+        "//syntaxnet:load_parser_ops_py",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+        "@org_tensorflow//tensorflow/core:protos_all_py",
+    ],
+)
+
diff --git a/research/syntaxnet/dragnn/python/biaffine_units.py b/research/syntaxnet/dragnn/python/biaffine_units.py
index c34a2ed6..7c70e157 100644
--- a/research/syntaxnet/dragnn/python/biaffine_units.py
+++ b/research/syntaxnet/dragnn/python/biaffine_units.py
@@ -95,7 +95,7 @@ class BiaffineDigraphNetwork(network_units.NetworkUnitInterface):
     self._regularized_weights.extend(self._weights)
 
     # Negative Layer.dim indicates that the dimension is dynamic.
-    self._layers.append(network_units.Layer(self, 'adjacency', -1))
+    self._layers.append(network_units.Layer(component, 'adjacency', -1))
 
   def create(self,
              fixed_embeddings,
@@ -209,7 +209,8 @@ class BiaffineLabelNetwork(network_units.NetworkUnitInterface):
     self._params.extend(self._weights + self._biases)
     self._regularized_weights.extend(self._weights)
 
-    self._layers.append(network_units.Layer(self, 'labels', self._num_labels))
+    self._layers.append(
+        network_units.Layer(component, 'labels', self._num_labels))
 
   def create(self,
              fixed_embeddings,
diff --git a/research/syntaxnet/dragnn/python/bulk_component.py b/research/syntaxnet/dragnn/python/bulk_component.py
index f00ac92f..86ebefd0 100644
--- a/research/syntaxnet/dragnn/python/bulk_component.py
+++ b/research/syntaxnet/dragnn/python/bulk_component.py
@@ -216,9 +216,11 @@ def build_cross_entropy_loss(logits, gold):
   logits = tf.gather(logits, valid)
   correct = tf.reduce_sum(tf.to_int32(tf.nn.in_top_k(logits, gold, 1)))
   total = tf.size(gold)
-  cost = tf.reduce_sum(
-      tf.contrib.nn.deprecated_flipped_sparse_softmax_cross_entropy_with_logits(
-          logits, tf.cast(gold, tf.int64))) / tf.cast(total, tf.float32)
+  with tf.control_dependencies([tf.assert_positive(total)]):
+    cost = tf.reduce_sum(
+        tf.nn.sparse_softmax_cross_entropy_with_logits(
+            labels=tf.cast(gold, tf.int64), logits=logits)) / tf.cast(
+                total, tf.float32)
   return cost, correct, total
 
 
@@ -267,6 +269,22 @@ class BulkFeatureExtractorComponentBuilder(component.ComponentBuilderBase):
     correct, total = tf.constant(0), tf.constant(0)
     return state.handle, cost, correct, total
 
+  def build_post_restore_hook(self):
+    """Builds a graph that should be executed after the restore op.
+
+    This graph is intended to be run once, before the inference pipeline is
+    run.
+
+    Returns:
+      setup_op - An op that, when run, guarantees all setup ops will run.
+    """
+    logging.info('Building restore hook for component: %s', self.spec.name)
+    with tf.variable_scope(self.name):
+      if callable(getattr(self.network, 'build_post_restore_hook', None)):
+        return [self.network.build_post_restore_hook()]
+      else:
+        return []
+
   def build_greedy_inference(self, state, network_states,
                              during_training=False):
     """Extracts features and advances a batch using the oracle path.
diff --git a/research/syntaxnet/dragnn/python/bulk_component_test.py b/research/syntaxnet/dragnn/python/bulk_component_test.py
index 5db5f056..99cb97e0 100644
--- a/research/syntaxnet/dragnn/python/bulk_component_test.py
+++ b/research/syntaxnet/dragnn/python/bulk_component_test.py
@@ -41,9 +41,6 @@ from dragnn.python import dragnn_ops
 from dragnn.python import network_units
 from syntaxnet import sentence_pb2
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
 
 
@@ -473,6 +470,17 @@ class BulkComponentTest(test_util.TensorFlowTestCase):
              [2], [-1], [-1], [-1],
              [2], [3], [-1], [-1]])
 
+  def testBuildLossFailsOnNoExamples(self):
+    with tf.Graph().as_default():
+      logits = tf.constant([[0.5], [-0.5], [0.5], [-0.5]])
+      gold = tf.constant([-1, -1, -1, -1])
+      result = bulk_component.build_cross_entropy_loss(logits, gold)
+
+      # Expect loss computation to generate a runtime error due to the gold
+      # tensor containing no valid examples.
+      with self.test_session() as sess:
+        with self.assertRaises(tf.errors.InvalidArgumentError):
+          sess.run(result)
 
 if __name__ == '__main__':
   googletest.main()
diff --git a/research/syntaxnet/dragnn/python/component.py b/research/syntaxnet/dragnn/python/component.py
index e38a216f..51dc89d9 100644
--- a/research/syntaxnet/dragnn/python/component.py
+++ b/research/syntaxnet/dragnn/python/component.py
@@ -46,9 +46,8 @@ class MasterState(object):
   """Simple utility to encapsulate tensors associated with the master state.
 
   Attributes:
-    handle: string tensor handle to the underlying nlp_saft::dragnn::MasterState
-    current_batch_size: int tensor containing the batch size following the most
-        recent MasterState::Reset().
+    handle: string tensor handle to the underlying ComputeSession.
+    current_batch_size: int tensor containing the current batch size.
   """
 
   def __init__(self, handle, current_batch_size):
@@ -390,7 +389,11 @@ class DynamicComponentBuilder(ComponentBuilderBase):
       correctly predicted actions, and the total number of actions.
     """
     logging.info('Building component: %s', self.spec.name)
-    with tf.control_dependencies([tf.assert_equal(self.training_beam_size, 1)]):
+    # Add 0 to training_beam_size to disable eager static evaluation.
+    # This is possible because tensorflow's constant_value does not
+    # propagate arithmetic operations.
+    with tf.control_dependencies([
+        tf.assert_equal(self.training_beam_size + 0, 1)]):
       stride = state.current_batch_size * self.training_beam_size
 
     cost = tf.constant(0.)
@@ -462,10 +465,10 @@ class DynamicComponentBuilder(ComponentBuilderBase):
 
     # Saves completed arrays and return final state and cost.
     state.handle = output[0]
+    cost = output[1]
     correct = output[2]
     total = output[3]
     arrays = output[4:]
-    cost = output[1]
 
     # Store handles to the final output for use in subsequent tasks.
     network_state = network_states[self.name]
@@ -475,6 +478,9 @@ class DynamicComponentBuilder(ComponentBuilderBase):
             array=arrays[index])
 
     # Normalize the objective by the total # of steps taken.
+    # Note: Total could be zero by a number of reasons, including:
+    #   * Oracle labels not being emitted.
+    #   * No steps being taken if component is terminal at the start of a batch.
     with tf.control_dependencies([tf.assert_greater(total, 0)]):
       cost /= tf.to_float(total)
 
@@ -524,11 +530,14 @@ class DynamicComponentBuilder(ComponentBuilderBase):
             during_training=during_training)
         next_arrays = update_tensor_arrays(network_tensors, arrays)
         with tf.control_dependencies([x.flow for x in next_arrays]):
-          logits = self.network.get_logits(network_tensors)
-          logits = tf.cond(self.locally_normalize,
-                           lambda: tf.nn.log_softmax(logits), lambda: logits)
-          handle = dragnn_ops.advance_from_prediction(
-              handle, logits, component=self.name)
+          if self.num_actions == 1:  # deterministic; take oracle transition
+            handle = dragnn_ops.advance_from_oracle(handle, component=self.name)
+          else:  # predict next transition using network logits
+            logits = self.network.get_logits(network_tensors)
+            logits = tf.cond(self.locally_normalize,
+                             lambda: tf.nn.log_softmax(logits), lambda: logits)
+            handle = dragnn_ops.advance_from_prediction(
+                handle, logits, component=self.name)
         return [handle] + next_arrays
 
     # Create the TensorArray's to store activations for downstream/recurrent
diff --git a/research/syntaxnet/dragnn/python/composite_optimizer.py b/research/syntaxnet/dragnn/python/composite_optimizer.py
index 71aff9b2..0ae69d6d 100644
--- a/research/syntaxnet/dragnn/python/composite_optimizer.py
+++ b/research/syntaxnet/dragnn/python/composite_optimizer.py
@@ -12,8 +12,9 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """An optimizer that switches between several methods."""
+import functools
+
 
 import tensorflow as tf
 from tensorflow.python.training import optimizer
@@ -28,7 +29,7 @@ class CompositeOptimizer(optimizer.Optimizer):
                optimizer2,
                switch,
                use_locking=False,
-               name='Composite'):
+               name="Composite"):
     """Construct a new Composite optimizer.
 
     Args:
@@ -47,24 +48,20 @@ class CompositeOptimizer(optimizer.Optimizer):
     self._switch = switch
 
   def apply_gradients(self, grads_and_vars, global_step=None, name=None):
-
-    return tf.cond(
-        self._switch,
-        lambda: self._optimizer1.apply_gradients(grads_and_vars,
-                                                 global_step, name),
-        lambda: self._optimizer2.apply_gradients(grads_and_vars,
-                                                 global_step, name)
-    )
-
+    return tf.cond(self._switch,
+                   functools.partial(self._optimizer1.apply_gradients,
+                                     grads_and_vars, global_step, name),
+                   functools.partial(self._optimizer2.apply_gradients,
+                                     grads_and_vars, global_step, name))
 
   def get_slot(self, var, name):
-    slot1 = self._optimizer1.get_slot(var, name)
-    slot2 = self._optimizer2.get_slot(var, name)
-    if slot1 and slot2:
-      raise LookupError('Slot named %s for variable %s populated for both '
-                        'optimizers' % (name, var.name))
-    return slot1 or slot2
+    if name.startswith("c1-"):
+      return self._optimizer1.get_slot(var, name[3:])
+    else:
+      return self._optimizer2.get_slot(var, name[3:])
 
   def get_slot_names(self):
-    return sorted(self._optimizer1.get_slot_names() +
-                  self._optimizer2.get_slot_names())
+    opt1_names = self._optimizer1.get_slot_names()
+    opt2_names = self._optimizer2.get_slot_names()
+    return sorted(["c1-{}".format(name) for name in opt1_names] +
+                  ["c2-{}".format(name) for name in opt2_names])
diff --git a/research/syntaxnet/dragnn/python/composite_optimizer_test.py b/research/syntaxnet/dragnn/python/composite_optimizer_test.py
index ea18982d..464c31f4 100644
--- a/research/syntaxnet/dragnn/python/composite_optimizer_test.py
+++ b/research/syntaxnet/dragnn/python/composite_optimizer_test.py
@@ -12,7 +12,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Tests for CompositeOptimizer."""
 
 
@@ -99,8 +98,8 @@ class CompositeOptimizerTest(test_util.TensorFlowTestCase):
       optimizer1 = MockAdamOptimizer(0.05)
       optimizer2 = MockMomentumOptimizer(0.05, 0.5)
       switch = tf.less(step, 100)
-      optimizer = composite_optimizer.CompositeOptimizer(optimizer1, optimizer2,
-                                                         switch)
+      optimizer = composite_optimizer.CompositeOptimizer(
+          optimizer1, optimizer2, switch)
       train_op = optimizer.minimize(loss)
 
       sess.run(tf.global_variables_initializer())
@@ -111,16 +110,19 @@ class CompositeOptimizerTest(test_util.TensorFlowTestCase):
         sess.run(train_op)
         sess.run(tf.assign_add(step, 1))
         slot_names = optimizer.get_slot_names()
-        self.assertItemsEqual(
-            slot_names,
-            ["m", "v", "momentum", "adam_counter", "momentum_counter"])
-        adam_counter = sess.run(optimizer.get_slot(w, "adam_counter"))
-        momentum_counter = sess.run(optimizer.get_slot(w, "momentum_counter"))
+        adam_slots = ["c1-m", "c1-v", "c1-adam_counter"]
+        momentum_slots = ["c2-momentum", "c2-momentum_counter"]
+        self.assertItemsEqual(slot_names, adam_slots + momentum_slots)
+        adam_counter = sess.run(optimizer.get_slot(w, "c1-adam_counter"))
+        momentum_counter = sess.run(
+            optimizer.get_slot(w, "c2-momentum_counter"))
         self.assertEqual(adam_counter, min(iteration + 1, 100))
         self.assertEqual(momentum_counter, max(iteration - 99, 0))
         if iteration % 20 == 0:
-          logging.info("%d %s %d %d", iteration, sess.run([switch, step, w, b]),
-                       adam_counter, momentum_counter)
+          logging.info("%d %s %d %d", iteration,
+                       sess.run([switch, step, w, b]), adam_counter,
+                       momentum_counter)
+
 
 if __name__ == "__main__":
   googletest.main()
diff --git a/research/syntaxnet/dragnn/python/dragnn_model_saver.py b/research/syntaxnet/dragnn/python/dragnn_model_saver.py
new file mode 100644
index 00000000..bb0170d8
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/dragnn_model_saver.py
@@ -0,0 +1,85 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Converter for DRAGNN checkpoint+master-spec files to TF SavedModels.
+
+This script loads a DRAGNN model from a checkpoint and master-spec and saves it
+to a TF SavedModel checkpoint. The checkpoint and master-spec together must
+form a complete model - see the conll_checkpoint_converter.py for an example
+of how to convert CONLL checkpoints, since they are not complete.
+"""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import tensorflow as tf
+
+from google.protobuf import text_format
+from dragnn.protos import spec_pb2
+from dragnn.python import dragnn_model_saver_lib as saver_lib
+
+flags = tf.app.flags
+FLAGS = flags.FLAGS
+
+flags.DEFINE_string('master_spec', None, 'Path to task context with '
+                    'inputs and parameters for feature extractors.')
+flags.DEFINE_string('params_path', None, 'Path to trained model parameters.')
+flags.DEFINE_string('export_path', '', 'Output path for exported servo model.')
+flags.DEFINE_bool('export_moving_averages', False,
+                  'Whether to export the moving average parameters.')
+
+
+def export(master_spec_path, params_path, export_path,
+           export_moving_averages):
+  """Restores a model and exports it in SavedModel form.
+
+  This method loads a graph specified by the spec at master_spec_path and the
+  params in params_path. It then saves the model in SavedModel format to the
+  location specified in export_path.
+
+  Args:
+    master_spec_path: Path to a proto-text master spec.
+    params_path: Path to the parameters file to export.
+    export_path: Path to export the SavedModel to.
+    export_moving_averages: Whether to export the moving average parameters.
+  """
+
+  graph = tf.Graph()
+  master_spec = spec_pb2.MasterSpec()
+  with tf.gfile.FastGFile(master_spec_path) as fin:
+    text_format.Parse(fin.read(), master_spec)
+
+  # Remove '/' if it exists at the end of the export path, ensuring that
+  # path utils work correctly.
+  stripped_path = export_path.rstrip('/')
+  saver_lib.clean_output_paths(stripped_path)
+
+  short_to_original = saver_lib.shorten_resource_paths(master_spec)
+  saver_lib.export_master_spec(master_spec, graph)
+  saver_lib.export_to_graph(master_spec, params_path, stripped_path, graph,
+                            export_moving_averages)
+  saver_lib.export_assets(master_spec, short_to_original, stripped_path)
+
+
+def main(unused_argv):
+  # Run the exporter.
+  export(FLAGS.master_spec, FLAGS.params_path,
+         FLAGS.export_path, FLAGS.export_moving_averages)
+  tf.logging.info('Export complete.')
+
+
+if __name__ == '__main__':
+  tf.app.run()
diff --git a/research/syntaxnet/dragnn/python/dragnn_model_saver_lib.py b/research/syntaxnet/dragnn/python/dragnn_model_saver_lib.py
new file mode 100644
index 00000000..a4c4a075
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/dragnn_model_saver_lib.py
@@ -0,0 +1,244 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+"""A program to export a DRAGNN model via SavedModel."""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+import tempfile
+
+import tensorflow as tf
+
+from google.protobuf import text_format
+from dragnn.protos import spec_pb2
+from dragnn.python import graph_builder
+
+# The saved model tags to export.  The same set of tags must be specified when
+# loading the saved model.
+_SAVED_MODEL_TAGS = [tf.saved_model.tag_constants.SERVING]
+
+
+def clean_output_paths(stripped_path):
+  """Ensures that the output path is cleaned and ready to receive a model."""
+  # If the export path's directory doesn't exist, create it.
+  export_directory = os.path.dirname(stripped_path)
+  if not tf.gfile.Exists(export_directory):
+    tf.logging.info('%s does not exist; creating it.' % export_directory)
+    tf.gfile.MakeDirs(export_directory)
+
+  # Remove any existing model on this export path, since exporting will fail
+  # if the model directory already exists.
+  if tf.gfile.Exists(stripped_path):
+    tf.logging.info('%s already exists; deleting it.' % stripped_path)
+    tf.gfile.DeleteRecursively(stripped_path)
+
+
+def shorten_resource_paths(master_spec):
+  """Shortens the resource file paths in a MasterSpec.
+
+  Replaces resource paths in the MasterSpec with shortened paths and builds a
+  mapping from the shortened path to the original path. Note that shortened
+  paths are relative to the 'assets.extra' directory of the SavedModel. Also
+  removes resources from FixedFeatureChannel, since they are not exported.
+
+  NB: The format of the shortened resource paths should be considered an
+  implementation detail and may change.
+
+  Args:
+    master_spec: MasterSpec proto to sanitize.
+
+  Returns:
+    Dict mapping from shortened resource path to original resource path.
+  """
+  for component_spec in master_spec.component:
+    for feature_spec in component_spec.fixed_feature:
+      feature_spec.ClearField('pretrained_embedding_matrix')
+      feature_spec.ClearField('vocab')
+
+  shortened_to_original = {}
+  original_to_shortened = {}
+  for component_index, component_spec in enumerate(master_spec.component):
+    component_name = 'component_{}_{}'.format(component_index,
+                                              component_spec.name)
+    for resource_index, resource_spec in enumerate(component_spec.resource):
+      resource_name = 'resource_{}_{}'.format(resource_index,
+                                              resource_spec.name)
+      for part_index, part in enumerate(resource_spec.part):
+        part_name = 'part_{}'.format(part_index)
+        shortened_path = os.path.join('resources', component_name,
+                                      resource_name, part_name)
+        if part.file_pattern not in original_to_shortened:
+          shortened_to_original[shortened_path] = part.file_pattern
+          original_to_shortened[part.file_pattern] = shortened_path
+
+        part.file_pattern = original_to_shortened[part.file_pattern]
+
+  return shortened_to_original
+
+
+def export_master_spec(master_spec, external_graph):
+  """Exports a MasterSpec.
+
+  Args:
+    master_spec: MasterSpec proto.
+    external_graph: tf.Graph that will be used to export the SavedModel.
+  """
+  # Implementation note: We can't export the original MasterSpec file directly
+  # because it uses short paths.  We also can't replace the original MasterSpec
+  # file with the new version, because the file may have other users.
+
+  # Write the new spec to a temp file and export it.  The basename will be
+  # exported in the SavedModel, so use mkdtemp() with a fixed basename.
+  master_spec_path = os.path.join(tempfile.mkdtemp(), 'master_spec')
+  with tf.gfile.FastGFile(master_spec_path, 'w') as fout:
+    fout.write(text_format.MessageToString(master_spec))
+  with external_graph.as_default():
+    asset_file_tensor = tf.constant(
+        master_spec_path, name='master_spec_filepath')
+    tf.add_to_collection(tf.GraphKeys.ASSET_FILEPATHS, asset_file_tensor)
+
+
+def export_assets(master_spec, shortened_to_original, saved_model_path):
+  """Exports the assets in a master_spec into a SavedModel directory.
+
+  This method exports a master_spec and associated files into the SavedModel's
+  'assets.extra' directory (which is unmanaged). All resources are added to the
+  'assets.extra' directory using sanitized paths. The master spec itself is
+  located at the base of the assets.extra directory.
+
+  NB: Only exports resource files in MasterSpec.component.resource, not the
+  embedding init resources in FixedFeatureChannel.
+
+  Args:
+    master_spec: Proto master spec.
+    shortened_to_original: Mapping returned by shorten_resource_paths().
+    saved_model_path: Path to an already-created SavedModel directory.
+  """
+  if not tf.gfile.Exists(saved_model_path):
+    tf.logging.fatal('Unable to export assets - directory %s does not exist!' %
+                     saved_model_path)
+  asset_dir = os.path.join(saved_model_path, 'assets.extra')
+  tf.logging.info('Exporting assets to model at %s' % asset_dir)
+
+  # First, write the MasterSpec that will be used to export the data.
+  tf.gfile.MakeDirs(asset_dir)
+  with tf.gfile.FastGFile(os.path.join(asset_dir, 'master_spec'),
+                          'w') as out_file:
+    out_file.write(text_format.MessageToString(master_spec))
+
+  # Then, copy all the asset files.
+  for component_spec in master_spec.component:
+    for resource_spec in component_spec.resource:
+      tf.logging.info('Copying assets for resource %s/%s.' %
+                      (component_spec.name, resource_spec.name))
+      for part in resource_spec.part:
+        original_file = shortened_to_original[part.file_pattern]
+        new_file = os.path.join(asset_dir, part.file_pattern)
+        tf.logging.info('Asset %s was renamed to %s.' % (original_file,
+                                                         new_file))
+        if tf.gfile.Exists(new_file):
+          tf.logging.info('%s already exists, skipping copy.' % (new_file))
+        else:
+          new_dir = os.path.dirname(new_file)
+          tf.gfile.MakeDirs(new_dir)
+          tf.logging.info('Copying %s to %s' % (original_file, new_dir))
+          tf.gfile.Copy(original_file, new_file, overwrite=True)
+  tf.logging.info('Asset export complete.')
+
+
+def export_to_graph(master_spec,
+                    params_path,
+                    export_path,
+                    external_graph,
+                    export_moving_averages,
+                    signature_name='model'):
+  """Restores a model and exports it in SavedModel form.
+
+  This method loads a graph specified by the master_spec and the params in
+  params_path into the graph given in external_graph. It then saves the model
+  in SavedModel format to the location specified in export_path.
+
+  Args:
+    master_spec: Proto master spec.
+    params_path: Path to the parameters file to export.
+    export_path: Path to export the SavedModel to.
+    external_graph: A tf.Graph() object to build the graph inside.
+    export_moving_averages: Whether to export the moving average parameters.
+    signature_name: Name of the signature to insert.
+  """
+  tf.logging.info(
+      'Exporting graph with signature_name "%s" and use_moving_averages = %s' %
+      (signature_name, export_moving_averages))
+
+  tf.logging.info('Building the graph')
+  with external_graph.as_default(), tf.device('/device:CPU:0'):
+    hyperparam_config = spec_pb2.GridPoint()
+    hyperparam_config.use_moving_average = export_moving_averages
+    builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
+    post_restore_hook = builder.build_post_restore_hook()
+    annotation = builder.add_annotation()
+    builder.add_saver()
+
+  # Resets session.
+  session_config = tf.ConfigProto(
+      log_device_placement=False,
+      intra_op_parallelism_threads=10,
+      inter_op_parallelism_threads=10)
+
+  with tf.Session(graph=external_graph, config=session_config) as session:
+    tf.logging.info('Initializing variables...')
+    session.run(tf.global_variables_initializer())
+
+    tf.logging.info('Loading params...')
+    session.run('save/restore_all', {'save/Const:0': params_path})
+
+    tf.logging.info('Saving.')
+
+    with tf.device('/device:CPU:0'):
+      saved_model_builder = tf.saved_model.builder.SavedModelBuilder(
+          export_path)
+
+      signature_map = {
+          signature_name:
+              tf.saved_model.signature_def_utils.build_signature_def(
+                  inputs={
+                      'inputs':
+                          tf.saved_model.utils.build_tensor_info(
+                              annotation['input_batch'])
+                  },
+                  outputs={
+                      'annotations':
+                          tf.saved_model.utils.build_tensor_info(
+                              annotation['annotations'])
+                  },
+                  method_name=tf.saved_model.signature_constants.
+                  PREDICT_METHOD_NAME),
+      }
+
+      tf.logging.info('Input is: %s', annotation['input_batch'].name)
+      tf.logging.info('Output is: %s', annotation['annotations'].name)
+
+      saved_model_builder.add_meta_graph_and_variables(
+          session,
+          tags=_SAVED_MODEL_TAGS,
+          legacy_init_op=tf.group(
+              post_restore_hook,
+              builder.build_warmup_graph(
+                  tf.get_collection(tf.GraphKeys.ASSET_FILEPATHS)[0])),
+          signature_def_map=signature_map,
+          assets_collection=tf.get_collection(tf.GraphKeys.ASSET_FILEPATHS))
+
+      saved_model_builder.save()
diff --git a/research/syntaxnet/dragnn/python/dragnn_model_saver_lib_test.py b/research/syntaxnet/dragnn/python/dragnn_model_saver_lib_test.py
new file mode 100644
index 00000000..be93846d
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/dragnn_model_saver_lib_test.py
@@ -0,0 +1,131 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Test for dragnn.python.dragnn_model_saver_lib."""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+
+import tensorflow as tf
+
+from google.protobuf import text_format
+from tensorflow.python.framework import test_util
+from tensorflow.python.platform import googletest
+from dragnn.protos import spec_pb2
+from dragnn.python import dragnn_model_saver_lib
+
+FLAGS = tf.app.flags.FLAGS
+
+
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
+class DragnnModelSaverLibTest(test_util.TensorFlowTestCase):
+
+  def LoadSpec(self, spec_path):
+    master_spec = spec_pb2.MasterSpec()
+    root_dir = os.path.join(FLAGS.test_srcdir,
+                            'dragnn/python')
+    with file(os.path.join(root_dir, 'testdata', spec_path), 'r') as fin:
+      text_format.Parse(fin.read().replace('TOPDIR', root_dir), master_spec)
+      return master_spec
+
+  def CreateLocalSpec(self, spec_path):
+    master_spec = self.LoadSpec(spec_path)
+    master_spec_name = os.path.basename(spec_path)
+    outfile = os.path.join(FLAGS.test_tmpdir, master_spec_name)
+    fout = open(outfile, 'w')
+    fout.write(text_format.MessageToString(master_spec))
+    return outfile
+
+  def ValidateAssetExistence(self, master_spec, export_path):
+    asset_path = os.path.join(export_path, 'assets.extra')
+
+    # The master spec should exist.
+    expected_path = os.path.join(asset_path, 'master_spec')
+    tf.logging.info('Validating existence of %s' % expected_path)
+    self.assertTrue(os.path.isfile(expected_path))
+
+    # For every part in every resource in every component, the resource should
+    # exist at [export_path]/assets.extra/[component file path]
+    path_list = []
+    for component_spec in master_spec.component:
+      for resource_spec in component_spec.resource:
+        for part in resource_spec.part:
+          expected_path = os.path.join(asset_path,
+                                       part.file_pattern.strip(os.path.sep))
+          tf.logging.info('Validating existence of %s' % expected_path)
+          self.assertTrue(os.path.isfile(expected_path))
+          path_list.append(expected_path)
+
+    # Return a set of all unique paths.
+    return set(path_list)
+
+  def testModelExport(self):
+    # Get the master spec and params for this graph.
+    master_spec = self.LoadSpec('ud-hungarian.master-spec')
+    params_path = os.path.join(
+        FLAGS.test_srcdir, 'dragnn/python/testdata'
+        '/ud-hungarian.params')
+
+    # Export the graph via SavedModel. (Here, we maintain a handle to the graph
+    # for comparison, but that's usually not necessary.)
+    export_path = os.path.join(FLAGS.test_tmpdir, 'export')
+    saver_graph = tf.Graph()
+
+    shortened_to_original = dragnn_model_saver_lib.shorten_resource_paths(
+        master_spec)
+
+    dragnn_model_saver_lib.export_master_spec(master_spec, saver_graph)
+
+    dragnn_model_saver_lib.export_to_graph(
+        master_spec,
+        params_path,
+        export_path,
+        saver_graph,
+        export_moving_averages=False)
+
+    # Export the assets as well.
+    dragnn_model_saver_lib.export_assets(master_spec, shortened_to_original,
+                                         export_path)
+
+    # Validate that the assets are all in the exported directory.
+    path_set = self.ValidateAssetExistence(master_spec, export_path)
+
+    # This master-spec has 4 unique assets. If there are more, we have not
+    # uniquified the assets properly.
+    self.assertEqual(len(path_set), 4)
+
+    # Restore the graph from the checkpoint into a new Graph object.
+    restored_graph = tf.Graph()
+    restoration_config = tf.ConfigProto(
+        log_device_placement=False,
+        intra_op_parallelism_threads=10,
+        inter_op_parallelism_threads=10)
+
+    with tf.Session(graph=restored_graph, config=restoration_config) as sess:
+      tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING],
+                                 export_path)
+
+
+if __name__ == '__main__':
+  googletest.main()
diff --git a/research/syntaxnet/dragnn/python/dragnn_ops.py b/research/syntaxnet/dragnn/python/dragnn_ops.py
index 8a640107..299e9ba8 100644
--- a/research/syntaxnet/dragnn/python/dragnn_ops.py
+++ b/research/syntaxnet/dragnn/python/dragnn_ops.py
@@ -16,9 +16,9 @@
 """Groups the DRAGNN TensorFlow ops in one module."""
 
 
-try:
-  from dragnn.core.ops.gen_dragnn_bulk_ops import *
-  from dragnn.core.ops.gen_dragnn_ops import *
-except ImportError as e:
-    raise e
+from dragnn.core.ops.gen_dragnn_bulk_ops import *
+from dragnn.core.ops.gen_dragnn_ops import *
 
+
+import dragnn.python.load_dragnn_cc_impl
+import syntaxnet.load_parser_ops
diff --git a/research/syntaxnet/dragnn/python/graph_builder.py b/research/syntaxnet/dragnn/python/graph_builder.py
index 014fd4a9..fe68ff12 100644
--- a/research/syntaxnet/dragnn/python/graph_builder.py
+++ b/research/syntaxnet/dragnn/python/graph_builder.py
@@ -12,11 +12,11 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Builds a DRAGNN graph for local training."""
 
-
+import collections
 import tensorflow as tf
+
 from tensorflow.core.protobuf import saver_pb2
 from tensorflow.python.platform import tf_logging as logging
 
@@ -32,6 +32,37 @@ except KeyError, e:
   logging.info(str(e))
 
 
+def _validate_grid_point(hyperparams, is_sub_optimizer=False):
+  """Validates that a grid point's configuration is reasonable.
+
+  Args:
+    hyperparams (spec_pb2.GridPoint): Grid point to validate.
+    is_sub_optimizer (bool): Whether this optimizer is a sub-optimizer of
+      a composite optimizer.
+
+  Raises:
+    ValueError: If the grid point is not valid.
+  """
+  valid_methods = ('gradient_descent', 'adam', 'lazyadam', 'momentum',
+                   'composite')
+  if hyperparams.learning_method not in valid_methods:
+    raise ValueError('Unknown learning method (optimizer)')
+
+  if is_sub_optimizer:
+    for base_only_field in ('decay_steps', 'decay_base', 'decay_staircase'):
+      if hyperparams.HasField(base_only_field):
+        raise ValueError('Field {} is not valid for sub-optimizers of a '
+                         'composite optimizer.'.format(base_only_field))
+
+  if hyperparams.learning_method == 'composite':
+    spec = hyperparams.composite_optimizer_spec
+    if spec.switch_after_steps < 1:
+      raise ValueError('switch_after_steps {} not valid for composite '
+                       'optimizer!'.format(spec.switch_after_steps))
+    for sub_optimizer in (spec.method1, spec.method2):
+      _validate_grid_point(sub_optimizer, is_sub_optimizer=True)
+
+
 def _create_learning_rate(hyperparams, step_var):
   """Creates learning rate var, with decay and switching for CompositeOptimizer.
 
@@ -40,21 +71,31 @@ def _create_learning_rate(hyperparams, step_var):
       learning_method to determine optimizer class to use.
     step_var: tf.Variable, global training step.
 
+  Raises:
+    ValueError: If the composite optimizer is set, but not correctly configured.
+
   Returns:
     a scalar `Tensor`, the learning rate based on current step and hyperparams.
   """
   if hyperparams.learning_method != 'composite':
     base_rate = hyperparams.learning_rate
+    adjusted_steps = step_var
   else:
     spec = hyperparams.composite_optimizer_spec
     switch = tf.less(step_var, spec.switch_after_steps)
     base_rate = tf.cond(switch, lambda: tf.constant(spec.method1.learning_rate),
                         lambda: tf.constant(spec.method2.learning_rate))
+    if spec.reset_learning_rate:
+      adjusted_steps = tf.cond(switch, lambda: step_var,
+                               lambda: step_var - spec.switch_after_steps)
+    else:
+      adjusted_steps = step_var
+
   return tf.train.exponential_decay(
-      base_rate,
-      step_var,
-      hyperparams.decay_steps,
-      hyperparams.decay_base,
+      learning_rate=base_rate,
+      global_step=adjusted_steps,
+      decay_steps=hyperparams.decay_steps,
+      decay_rate=hyperparams.decay_base,
       staircase=hyperparams.decay_staircase)
 
 
@@ -158,6 +199,7 @@ class MasterBuilder(object):
     self.spec = master_spec
     self.hyperparams = (spec_pb2.GridPoint()
                         if hyperparam_config is None else hyperparam_config)
+    _validate_grid_point(self.hyperparams)
     self.pool_scope = pool_scope
 
     # Set the graph-level random seed before creating the Components so the ops
@@ -260,6 +302,25 @@ class MasterBuilder(object):
     all_nodes['run'] = run_op
     return all_nodes
 
+  def build_warmup_graph(self, asset_dir):
+    """Builds a warmup graph.
+
+    This graph performs a MasterSpec asset location rewrite via
+    SetAssetDirectory, then grabs a ComputeSession and immediately returns it.
+    By grabbing a session, we cause the underlying transition systems to cache
+    their static data reads.
+
+    Args:
+      asset_dir: The base directory to append to all resources.
+
+    Returns:
+      A single op suitable for passing to the legacy_init_op of the ModelSaver.
+    """
+    with tf.control_dependencies([dragnn_ops.set_asset_directory(asset_dir)]):
+      session = self._get_compute_session()
+      release_op = dragnn_ops.release_session(session)
+    return tf.group(release_op, name='run')
+
   def build_training(self,
                      handle,
                      compute_gradients=True,
@@ -408,6 +469,8 @@ class MasterBuilder(object):
     # Restore that subsequent builds don't use average by default.
     self.read_from_avg = False
 
+    cost = tf.check_numerics(cost, message='Cost is not finite.')
+
     # Returns named access to common outputs.
     outputs = {
         'cost': cost,
@@ -447,8 +510,14 @@ class MasterBuilder(object):
     Returns:
       setup_op - An op that, when run, guarantees all setup ops will run.
     """
-    with tf.control_dependencies(
-        [comp.build_post_restore_hook() for comp in self.components]):
+    control_ops = []
+    for comp in self.components:
+      hook = comp.build_post_restore_hook()
+      if isinstance(hook, collections.Iterable):
+        control_ops.extend(hook)
+      else:
+        control_ops.append(hook)
+    with tf.control_dependencies(control_ops):
       return tf.no_op(name='post_restore_hook_master')
 
   def build_inference(self, handle, use_moving_average=False):
@@ -597,10 +666,8 @@ class MasterBuilder(object):
 
   def add_saver(self):
     """Adds a Saver for all variables in the graph."""
-    logging.info('Saving non-quantized variables:\n\t%s', '\n\t'.join(
-        [x.name for x in tf.global_variables() if 'quantized' not in x.name]))
+    logging.info('Saving variables:\n\t%s',
+                 '\n\t'.join([x.name for x in tf.global_variables()]))
     self.saver = tf.train.Saver(
-        var_list=[
-            x for x in tf.global_variables() if 'quantized' not in x.name
-        ],
+        var_list=[x for x in tf.global_variables()],
         write_version=saver_pb2.SaverDef.V1)
diff --git a/research/syntaxnet/dragnn/python/graph_builder_test.py b/research/syntaxnet/dragnn/python/graph_builder_test.py
index 3ca81599..b1f712ea 100644
--- a/research/syntaxnet/dragnn/python/graph_builder_test.py
+++ b/research/syntaxnet/dragnn/python/graph_builder_test.py
@@ -12,7 +12,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Tests for graph_builder."""
 
 
@@ -35,14 +34,8 @@ from tensorflow.python.framework import test_util
 from tensorflow.python.platform import googletest
 from tensorflow.python.platform import tf_logging as logging
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
-if not hasattr(FLAGS, 'test_srcdir'):
-  FLAGS.test_srcdir = ''
-if not hasattr(FLAGS, 'test_tmpdir'):
-  FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
 
 _DUMMY_GOLD_SENTENCE = """
 token {
@@ -157,6 +150,13 @@ token {
 ]
 
 
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
 def _as_op(x):
   """Always returns the tf.Operation associated with a node."""
   return x.op if isinstance(x, tf.Tensor) else x
@@ -264,7 +264,8 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
     gold_doc_2 = sentence_pb2.Sentence()
     text_format.Parse(_DUMMY_GOLD_SENTENCE_2, gold_doc_2)
     reader_strings = [
-        gold_doc.SerializeToString(), gold_doc_2.SerializeToString()
+        gold_doc.SerializeToString(),
+        gold_doc_2.SerializeToString()
     ]
     tf.logging.info('Generating graph with config: %s', hyperparam_config)
     with tf.Graph().as_default():
@@ -294,18 +295,35 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
     self.RunTraining(
         self.MakeHyperparams(learning_method='adam', use_moving_average=True))
 
+  def testTrainingWithLazyAdamAndNoAveraging(self):
+    """Adds code coverage for lazy ADAM without the use of moving averaging."""
+    self.RunTraining(
+        self.MakeHyperparams(
+            learning_method='lazyadam', use_moving_average=False))
+
   def testTrainingWithCompositeOptimizer(self):
     """Adds code coverage for CompositeOptimizer."""
+    self.RunCompositeOptimizerTraining(False)
+
+  def testTrainingWithCompositeOptimizerResetLearningRate(self):
+    """Adds code coverage for CompositeOptimizer."""
+    self.RunCompositeOptimizerTraining(True)
+
+  def RunCompositeOptimizerTraining(self, reset_learning_rate):
     grid_point = self.MakeHyperparams(learning_method='composite')
-    grid_point.composite_optimizer_spec.method1.learning_method = 'adam'
-    grid_point.composite_optimizer_spec.method2.learning_method = 'momentum'
-    grid_point.composite_optimizer_spec.method2.momentum = 0.9
+    spec = grid_point.composite_optimizer_spec
+    spec.reset_learning_rate = reset_learning_rate
+    spec.switch_after_steps = 1
+    spec.method1.learning_method = 'adam'
+    spec.method2.learning_method = 'momentum'
+    spec.method2.momentum = 0.9
     self.RunTraining(grid_point)
 
   def RunFullTrainingAndInference(self,
                                   test_name,
                                   master_spec_path=None,
                                   master_spec=None,
+                                  hyperparam_config=None,
                                   component_weights=None,
                                   unroll_using_oracle=None,
                                   num_evaluated_components=1,
@@ -320,7 +338,8 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
     gold_doc_2 = sentence_pb2.Sentence()
     text_format.Parse(_DUMMY_GOLD_SENTENCE_2, gold_doc_2)
     gold_reader_strings = [
-        gold_doc.SerializeToString(), gold_doc_2.SerializeToString()
+        gold_doc.SerializeToString(),
+        gold_doc_2.SerializeToString()
     ]
 
     test_doc = sentence_pb2.Sentence()
@@ -328,8 +347,10 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
     test_doc_2 = sentence_pb2.Sentence()
     text_format.Parse(_DUMMY_TEST_SENTENCE_2, test_doc_2)
     test_reader_strings = [
-        test_doc.SerializeToString(), test_doc.SerializeToString(),
-        test_doc_2.SerializeToString(), test_doc.SerializeToString()
+        test_doc.SerializeToString(),
+        test_doc.SerializeToString(),
+        test_doc_2.SerializeToString(),
+        test_doc.SerializeToString()
     ]
 
     if batch_size_limit is not None:
@@ -338,7 +359,8 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
 
     with tf.Graph().as_default():
       tf.set_random_seed(1)
-      hyperparam_config = spec_pb2.GridPoint()
+      if not hyperparam_config:
+        hyperparam_config = spec_pb2.GridPoint()
       builder = graph_builder.MasterBuilder(
           master_spec, hyperparam_config, pool_scope=test_name)
       target = spec_pb2.TrainTarget()
@@ -493,6 +515,22 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
         expected_num_actions=12,
         expected=_TAGGER_PARSER_EXPECTED_SENTENCES)
 
+  def testTaggerParserNanDeath(self):
+    hyperparam_config = spec_pb2.GridPoint()
+    hyperparam_config.learning_rate = 1.0
+
+    # The large learning rate should trigger check_numerics.
+    with self.assertRaisesRegexp(tf.errors.InvalidArgumentError,
+                                 'Cost is not finite'):
+      self.RunFullTrainingAndInference(
+          'tagger-parser',
+          'tagger_parser_master_spec.textproto',
+          hyperparam_config=hyperparam_config,
+          component_weights=[0., 1., 1.],
+          unroll_using_oracle=[False, True, True],
+          expected_num_actions=12,
+          expected=_TAGGER_PARSER_EXPECTED_SENTENCES)
+
   def testTaggerParserWithAttention(self):
     spec = self.LoadSpec('tagger_parser_master_spec.textproto')
 
@@ -621,6 +659,18 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
       self.checkOpOrder('annotations', anno['annotations'],
                         ['GetSession', 'ReleaseSession'])
 
+  def testWarmupGetsAndReleasesSession(self):
+    """Checks that create_warmup_graph creates Get and ReleaseSession."""
+    test_name = 'warmup-graph-structure'
+
+    with tf.Graph().as_default():
+      # Build the actual graphs. The choice of spec is arbitrary, as long as
+      # training and annotation nodes can be constructed.
+      builder, _ = self.getBuilderAndTarget(test_name)
+      warmup = builder.build_warmup_graph('foo')
+      self.checkOpOrder('annotations', warmup,
+                        ['SetAssetDirectory', 'GetSession', 'ReleaseSession'])
+
   def testAttachDataReader(self):
     """Checks that train['run'] and 'annotations' call AttachDataReader."""
     test_name = 'attach-data-reader'
diff --git a/research/syntaxnet/dragnn/python/lexicon.py b/research/syntaxnet/dragnn/python/lexicon.py
index b56ca0e8..bdd61f1c 100644
--- a/research/syntaxnet/dragnn/python/lexicon.py
+++ b/research/syntaxnet/dragnn/python/lexicon.py
@@ -28,7 +28,8 @@ def create_lexicon_context(path):
   context = task_spec_pb2.TaskSpec()
   for name in [
       'word-map', 'tag-map', 'tag-to-category', 'lcword-map', 'category-map',
-      'char-map', 'char-ngram-map', 'label-map', 'prefix-table', 'suffix-table'
+      'char-map', 'char-ngram-map', 'label-map', 'prefix-table', 'suffix-table',
+      'known-word-map'
   ]:
     context.input.add(name=name).part.add(file_pattern=os.path.join(path, name))
   return context
diff --git a/research/syntaxnet/dragnn/python/lexicon_test.py b/research/syntaxnet/dragnn/python/lexicon_test.py
index d23442bc..340d9250 100644
--- a/research/syntaxnet/dragnn/python/lexicon_test.py
+++ b/research/syntaxnet/dragnn/python/lexicon_test.py
@@ -28,13 +28,7 @@ from dragnn.python import lexicon
 from syntaxnet import parser_trainer
 from syntaxnet import task_spec_pb2
 
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
-if not hasattr(FLAGS, 'test_srcdir'):
-  FLAGS.test_srcdir = ''
-if not hasattr(FLAGS, 'test_tmpdir'):
-  FLAGS.test_tmpdir = tf.test.get_temp_dir()
 
 
 _EXPECTED_CONTEXT = r"""
@@ -48,9 +42,17 @@ input { name: "char-ngram-map" Part { file_pattern: "/tmp/char-ngram-map" } }
 input { name: "label-map" Part { file_pattern: "/tmp/label-map" } }
 input { name: "prefix-table" Part { file_pattern: "/tmp/prefix-table" } }
 input { name: "suffix-table" Part { file_pattern: "/tmp/suffix-table" } }
+input { name: "known-word-map" Part { file_pattern: "/tmp/known-word-map" } }
 """
 
 
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
 class LexiconTest(tf.test.TestCase):
 
   def testCreateLexiconContext(self):
diff --git a/research/syntaxnet/dragnn/python/network_units.py b/research/syntaxnet/dragnn/python/network_units.py
index a42c5dc3..ebf4241d 100644
--- a/research/syntaxnet/dragnn/python/network_units.py
+++ b/research/syntaxnet/dragnn/python/network_units.py
@@ -12,7 +12,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Basic network units used in assembling DRAGNN graphs."""
 
 from __future__ import absolute_import
@@ -21,6 +20,8 @@ from __future__ import print_function
 
 import abc
 
+
+import numpy as np
 import tensorflow as tf
 from tensorflow.python.ops import nn
 from tensorflow.python.ops import tensor_array_ops as ta
@@ -141,17 +142,22 @@ def add_embeddings(channel_id, feature_spec, seed=None):
     embeddings = syntaxnet_ops.word_embedding_initializer(
         vectors=feature_spec.pretrained_embedding_matrix.part[0].file_pattern,
         vocabulary=feature_spec.vocab.part[0].file_pattern,
+
         num_special_embeddings=1,
         embedding_init=1.0,
         seed=seed1,
         seed2=seed2)
-    return tf.get_variable(name, initializer=tf.reshape(embeddings, shape))
+    return tf.get_variable(
+        name,
+        initializer=tf.reshape(embeddings, shape),
+        trainable=not feature_spec.is_constant)
   else:
     return tf.get_variable(
         name,
         shape,
         initializer=tf.random_normal_initializer(
-            stddev=1.0 / feature_spec.embedding_dim**.5, seed=seed))
+            stddev=1.0 / feature_spec.embedding_dim**.5, seed=seed),
+        trainable=not feature_spec.is_constant)
 
 
 def embedding_lookup(embedding_matrix, indices, ids, weights, size):
@@ -183,7 +189,7 @@ def fixed_feature_lookup(component, state, channel_id, stride):
 
   Args:
     component: Component object in which to look up the fixed features.
-    state: MasterState object for the live nlp_saft::dragnn::MasterState.
+    state: MasterState object for the live ComputeSession.
     channel_id: int id of the fixed feature to look up.
     stride: int Tensor of current batch * beam size.
 
@@ -228,6 +234,100 @@ def get_input_tensor(fixed_embeddings, linked_embeddings):
   return tf.concat([e.tensor for e in embeddings], 1)
 
 
+def add_var_initialized(name, shape, init_type, divisor=1.0, stddev=1e-4):
+  """Creates a tf.Variable with the given shape and initialization.
+
+  Args:
+    name: variable name
+    shape: variable shape
+    init_type: type of initialization (random, xavier, identity, varscale)
+    divisor: numerator for identity initialization where in_dim != out_dim,
+      should divide both in_dim and out_dim
+    stddev: standard deviation for random normal initialization
+
+  Returns:
+    tf.Variable object with the given shape and initialization
+
+  Raises:
+    ValueError: if identity initialization is specified for a tensor of rank < 4
+    NotImplementedError: if an unimplemented type of initialization is specified
+  """
+  if init_type == 'random':
+    # Random normal initialization
+    return tf.get_variable(
+        name,
+        shape=shape,
+        initializer=tf.random_normal_initializer(stddev=stddev),
+        dtype=tf.float32)
+  if init_type == 'xavier':
+    # Xavier normal initialization (Glorot and Bengio, 2010):
+    # http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf
+    return tf.get_variable(
+        name,
+        shape=shape,
+        initializer=tf.contrib.layers.xavier_initializer(),
+        dtype=tf.float32)
+  if init_type == 'varscale':
+    # Variance scaling initialization (He at al. 2015):
+    # https://arxiv.org/abs/1502.01852
+    return tf.get_variable(
+        name,
+        shape=shape,
+        initializer=tf.contrib.layers.variance_scaling_initializer(),
+        dtype=tf.float32)
+  if init_type == 'identity':
+    # "Identity initialization" described in Yu and Koltun (2015):
+    # https://arxiv.org/abs/1511.07122v3 eqns. (4) and (5)
+    rank = len(shape)
+    square = shape[-1] == shape[-2]
+    if rank < 2:
+      raise ValueError(
+          'Identity initialization requires a tensor with rank >= 2. The given '
+          'shape has rank ' + str(rank))
+
+    if shape[-1] % divisor != 0 or shape[-2] % divisor != 0:
+      raise ValueError('Divisor must divide both shape[-1]=' + str(shape[-1]) +
+                       ' and shape[-2]=' + str(shape[-2]) + '. Divisor is: ' +
+                       str(divisor))
+
+    # If the desired shape is > 2 dimensions, we only want to set the values
+    # in the middle along the last two dims.
+    middle_indices = [int(s / 2) for s in shape]
+    middle_indices = middle_indices[:-2]
+
+    base_array = NotImplemented
+    if square:
+      if rank == 2:
+        base_array = np.eye(shape[-1])
+      else:
+        base_array = np.zeros(shape, dtype=np.float32)
+        base_array[[[i] for i in middle_indices]] = np.eye(shape[-1])
+    else:
+      # NOTE(strubell): We use NumPy's RNG here and not TensorFlow's because
+      # constructing this matrix with tf ops is tedious and harder to read.
+      base_array = np.random.normal(
+          size=shape, loc=0, scale=stddev).astype(np.float32)
+      m = divisor / shape[-1]
+
+      identity = np.eye(int(divisor))
+      x_stretch = int(shape[-1] / divisor)
+      y_stretch = int(shape[-2] / divisor)
+      x_stretched_ident = np.repeat(identity, x_stretch, 1)
+      xy_stretched_ident = np.repeat(x_stretched_ident, y_stretch, 0)
+      indices = np.where(xy_stretched_ident == 1.0)
+
+      if rank == 2:
+        base_array[indices[0], indices[1]] = m
+      else:
+        arr = base_array[[[i] for i in middle_indices]][0]
+        arr[indices[0], indices[1]] = m
+        base_array[[[i] for i in middle_indices]] = arr
+    return tf.get_variable(name, initializer=base_array)
+
+  raise NotImplementedError('Initialization type ' + init_type +
+                            ' is not implemented.')
+
+
 def get_input_tensor_with_stride(fixed_embeddings, linked_embeddings, stride):
   """Constructs an input tensor with a separate dimension for steps.
 
@@ -304,8 +404,8 @@ def lookup_named_tensor(name, named_tensors):
   for named_tensor in named_tensors:
     if named_tensor.name == name:
       return named_tensor
-  raise KeyError('Name "%s" not found in named tensors: %s' %
-                 (name, named_tensors))
+  raise KeyError('Name "%s" not found in named tensors: %s' % (name,
+                                                               named_tensors))
 
 
 def activation_lookup_recurrent(component, state, channel_id, source_array,
@@ -317,7 +417,7 @@ def activation_lookup_recurrent(component, state, channel_id, source_array,
 
   Args:
     component: Component object in which to look up the fixed features.
-    state: MasterState object for the live nlp_saft::dragnn::MasterState.
+    state: MasterState object for the live ComputeSession.
     channel_id: int id of the fixed feature to look up.
     source_array: TensorArray from which to fetch feature vectors, expected to
         have size [steps + 1] elements of shape [stride, D] each.
@@ -381,7 +481,7 @@ def activation_lookup_other(component, state, channel_id, source_tensor,
 
   Args:
     component: Component object in which to look up the fixed features.
-    state: MasterState object for the live nlp_saft::dragnn::MasterState.
+    state: MasterState object for the live ComputeSession.
     channel_id: int id of the fixed feature to look up.
     source_tensor: Tensor from which to fetch feature vectors. Expected to have
         have shape [steps + 1, stride, D].
@@ -494,8 +594,8 @@ class LayerNorm(object):
 
       # Compute layer normalization using the batch_normalization function.
       variance_epsilon = 1E-12
-      outputs = nn.batch_normalization(
-          inputs, mean, variance, beta, gamma, variance_epsilon)
+      outputs = nn.batch_normalization(inputs, mean, variance, beta, gamma,
+                                       variance_epsilon)
       outputs.set_shape(inputs_shape)
       return outputs
 
@@ -529,12 +629,13 @@ class Layer(object):
       TensorArray object
     """
     check.Gt(self.dim, 0, 'Cannot create array when dimension is dynamic')
-    tensor_array = ta.TensorArray(dtype=tf.float32,
-                                  size=0,
-                                  dynamic_size=True,
-                                  clear_after_read=False,
-                                  infer_shape=False,
-                                  name='%s_array' % self.name)
+    tensor_array = ta.TensorArray(
+        dtype=tf.float32,
+        size=0,
+        dynamic_size=True,
+        clear_after_read=False,
+        infer_shape=False,
+        name='%s_array' % self.name)
 
     # Start each array with all zeros. Special values will still be learned via
     # the extra embedding dimension stored for each linked feature channel.
@@ -588,9 +689,6 @@ def maybe_apply_dropout(inputs, keep_prob, per_sequence, stride=None):
     shape of |inputs|, containing the masked or original inputs, depending on
     whether dropout was actually performed.
   """
-  check.Ge(inputs.get_shape().ndims, 2, 'inputs must be rank 2 or 3')
-  check.Le(inputs.get_shape().ndims, 3, 'inputs must be rank 2 or 3')
-  flat = (inputs.get_shape().ndims == 2)
 
   if keep_prob >= 1.0:
     return inputs
@@ -598,6 +696,11 @@ def maybe_apply_dropout(inputs, keep_prob, per_sequence, stride=None):
   if not per_sequence:
     return tf.nn.dropout(inputs, keep_prob)
 
+  # We only check the dims if we are applying per-sequence dropout
+  check.Ge(inputs.get_shape().ndims, 2, 'inputs must be rank 2 or 3')
+  check.Le(inputs.get_shape().ndims, 3, 'inputs must be rank 2 or 3')
+  flat = (inputs.get_shape().ndims == 2)
+
   check.NotNone(stride, 'per-sequence dropout requires stride')
   dim = inputs.get_shape().as_list()[-1]
   check.NotNone(dim, 'inputs must have static activation dimension, but have '
@@ -629,7 +732,7 @@ class NetworkUnitInterface(object):
     layers (list): List of Layer objects to track network layers that should
       be written to Tensors during training and inference.
   """
-  __metaclass__ = abc.ABCMeta  # required for @abstractmethod
+  __metaclass__ = abc.ABCMeta  # required for @abc.abstractmethod
 
   def __init__(self, component, init_layers=None, init_context_layers=None):
     """Initializes parameters for embedding matrices.
@@ -692,8 +795,8 @@ class NetworkUnitInterface(object):
 
     # Compute the cumulative dimension of all inputs.  If any input has dynamic
     # dimension, then the result is -1.
-    input_dims = (self._fixed_feature_dims.values() +
-                  self._linked_feature_dims.values())
+    input_dims = (
+        self._fixed_feature_dims.values() + self._linked_feature_dims.values())
     if any(x < 0 for x in input_dims):
       self._concatenated_input_dim = -1
     else:
@@ -844,8 +947,7 @@ class NetworkUnitInterface(object):
         tf.reduce_sum(
             tf.multiply(
                 h_tensor, tf.reshape(p_vec, [-1, 1]), name='time_together2'),
-            0),
-        0)
+            0), 0)
     return tf.matmul(
         r_vec,
         self._component.get_variable('attention_weights_pu'),
@@ -908,6 +1010,7 @@ class FeedForwardNetwork(NetworkUnitInterface):
     Parameters used to construct the network:
       hidden_layer_sizes: comma-separated list of ints, indicating the
         number of hidden units in each hidden layer.
+      omit_logits (False): Whether to elide the logits layer.
       layer_norm_input (False): Whether or not to apply layer normalization
         on the concatenated input to the network.
       layer_norm_hidden (False): Whether or not to apply layer normalization
@@ -928,21 +1031,24 @@ class FeedForwardNetwork(NetworkUnitInterface):
           when the |dropout_keep_prob| parameter is negative.
     """
     self._attrs = get_attrs_with_defaults(
-        component.spec.network_unit.parameters, defaults={
+        component.spec.network_unit.parameters,
+        defaults={
             'hidden_layer_sizes': '',
+            'omit_logits': False,
             'layer_norm_input': False,
             'layer_norm_hidden': False,
             'nonlinearity': 'relu',
             'dropout_keep_prob': -1.0,
             'dropout_per_sequence': False,
-            'dropout_all_layers': False})
+            'dropout_all_layers': False
+        })
 
     # Initialize the hidden layer sizes before running the base initializer, as
-    # the base initializer may need to know the size of of the hidden layer for
+    # the base initializer may need to know the size of the hidden layer for
     # recurrent connections.
-    self._hidden_layer_sizes = (
-        map(int, self._attrs['hidden_layer_sizes'].split(','))
-        if self._attrs['hidden_layer_sizes'] else [])
+    self._hidden_layer_sizes = (map(
+        int, self._attrs['hidden_layer_sizes'].split(','))
+                                if self._attrs['hidden_layer_sizes'] else [])
     super(FeedForwardNetwork, self).__init__(component)
 
     # Infer dropout rate from network parameters and grid hyperparameters.
@@ -960,9 +1066,8 @@ class FeedForwardNetwork(NetworkUnitInterface):
       self._params.extend(self._layer_norm_input.params)
 
     if self._attrs['layer_norm_hidden']:
-      self._layer_norm_hidden = LayerNorm(self._component, 'layer_0',
-                                          self._hidden_layer_sizes[0],
-                                          tf.float32)
+      self._layer_norm_hidden = LayerNorm(
+          self._component, 'layer_0', self._hidden_layer_sizes[0], tf.float32)
       self._params.extend(self._layer_norm_hidden.params)
 
     # Extract nonlinearity from |tf.nn|.
@@ -984,13 +1089,11 @@ class FeedForwardNetwork(NetworkUnitInterface):
         self._params.append(
             tf.get_variable(
                 'bias_%d' % index, [hidden_layer_size],
-                initializer=tf.constant_initializer(
-                    0.2, dtype=tf.float32)))
+                initializer=tf.constant_initializer(0.2, dtype=tf.float32)))
 
       self._weights.append(weights)
       self._layers.append(
-          Layer(
-              component, name='layer_%d' % index, dim=hidden_layer_size))
+          Layer(component, name='layer_%d' % index, dim=hidden_layer_size))
       last_layer_dim = hidden_layer_size
 
     # Add a convenience alias for the last hidden layer, if any.
@@ -1000,7 +1103,7 @@ class FeedForwardNetwork(NetworkUnitInterface):
     # By default, regularize only the weights.
     self._regularized_weights.extend(self._weights)
 
-    if component.num_actions:
+    if component.num_actions and not self._attrs['omit_logits']:
       self._params.append(
           tf.get_variable(
               'weights_softmax', [last_layer_dim, component.num_actions],
@@ -1010,8 +1113,7 @@ class FeedForwardNetwork(NetworkUnitInterface):
               'bias_softmax', [component.num_actions],
               initializer=tf.zeros_initializer()))
       self._layers.append(
-          Layer(
-              component, name='logits', dim=component.num_actions))
+          Layer(component, name='logits', dim=component.num_actions))
 
   def create(self,
              fixed_embeddings,
@@ -1078,10 +1180,8 @@ class FeedForwardNetwork(NetworkUnitInterface):
       return self._hidden_layer_sizes[-1]
 
     if not layer_name.startswith('layer_'):
-      logging.fatal(
-          'Invalid layer name: "%s" Can only retrieve from "logits", '
-          '"last_layer", and "layer_*".',
-          layer_name)
+      logging.fatal('Invalid layer name: "%s" Can only retrieve from "logits", '
+                    '"last_layer", and "layer_*".', layer_name)
 
     # NOTE(danielandor): Since get_layer_size is called before the
     # model has been built, we compute the layer size directly from
@@ -1157,7 +1257,8 @@ class LSTMNetwork(NetworkUnitInterface):
 
     self._params.extend([
         self._x2i, self._h2i, self._c2i, self._bi, self._x2o, self._h2o,
-        self._c2o, self._bo, self._x2c, self._h2c, self._bc])
+        self._c2o, self._bo, self._x2c, self._h2c, self._bc
+    ])
 
     lstm_h_layer = Layer(component, name='lstm_h', dim=self._hidden_layer_sizes)
     lstm_c_layer = Layer(component, name='lstm_c', dim=self._hidden_layer_sizes)
@@ -1168,20 +1269,20 @@ class LSTMNetwork(NetworkUnitInterface):
     self._layers.extend(self._context_layers)
 
     self._layers.append(
-        Layer(
-            component, name='layer_0', dim=self._hidden_layer_sizes))
+        Layer(component, name='layer_0', dim=self._hidden_layer_sizes))
 
-    self.params.append(tf.get_variable(
-        'weights_softmax', [self._hidden_layer_sizes, component.num_actions],
-        initializer=tf.random_normal_initializer(stddev=1e-4)))
+    self.params.append(
+        tf.get_variable(
+            'weights_softmax',
+            [self._hidden_layer_sizes, component.num_actions],
+            initializer=tf.random_normal_initializer(stddev=1e-4)))
     self.params.append(
         tf.get_variable(
             'bias_softmax', [component.num_actions],
             initializer=tf.zeros_initializer()))
 
     self._layers.append(
-        Layer(
-            component, name='logits', dim=component.num_actions))
+        Layer(component, name='logits', dim=component.num_actions))
 
   def create(self,
              fixed_embeddings,
@@ -1215,6 +1316,13 @@ class LSTMNetwork(NetworkUnitInterface):
     i_h_tm1 = context_tensor_arrays[0].read(length - 1)
     i_c_tm1 = context_tensor_arrays[1].read(length - 1)
 
+    # label c and h inputs
+    i_c_tm1 = tf.identity(i_c_tm1, name='lstm_c_in')
+    i_h_tm1 = tf.identity(i_h_tm1, name='lstm_h_in')
+
+    # label the feature input (for debugging purposes)
+    input_tensor = tf.identity(input_tensor, name='input_tensor')
+
     # apply dropout according to http://arxiv.org/pdf/1409.2329v5.pdf
     if during_training and self._input_dropout_rate < 1:
       input_tensor = tf.nn.dropout(input_tensor, self._input_dropout_rate)
@@ -1251,7 +1359,8 @@ class LSTMNetwork(NetworkUnitInterface):
 
     h = tf.identity(ht, name='layer_0')
 
-    logits = tf.nn.xw_plus_b(ht, tf.get_variable('weights_softmax'),
+    logits = tf.nn.xw_plus_b(ht,
+                             tf.get_variable('weights_softmax'),
                              tf.get_variable('bias_softmax'))
 
     if self._component.spec.attention_component:
@@ -1284,7 +1393,7 @@ class ConvNetwork(NetworkUnitInterface):
       widths: comma separated list of ints, number of steps input to the
               convolutional kernel at every layer.
       depths: comma separated list of ints, number of channels input to the
-              convolutional kernel at every layer.
+              convolutional kernel at every layer except the first.
       output_embedding_dim: int, number of output channels for the convolutional
               kernel of the last layer, which receives no ReLU activation and
               therefore can be used in a softmax output. If zero, this final
@@ -1298,6 +1407,13 @@ class ConvNetwork(NetworkUnitInterface):
         sequence, instead of once per step.  See Gal and Ghahramani
         (https://arxiv.org/abs/1512.05287).
 
+    Raises:
+      RuntimeError: if the number of widths is not equal to the number of
+          depths - 1.
+
+    The input depth of the first layer is inferred from the total concatenated
+    size of the input features.
+
     Hyperparameters used:
       dropout_rate: The probability that an input is not dropped.  Only used
           when the |dropout_keep_prob| parameter is negative.
@@ -1305,21 +1421,34 @@ class ConvNetwork(NetworkUnitInterface):
 
     super(ConvNetwork, self).__init__(component)
     self._attrs = get_attrs_with_defaults(
-        component.spec.network_unit.parameters, defaults={
+        component.spec.network_unit.parameters,
+        defaults={
             'widths': '',
             'depths': '',
             'output_embedding_dim': 0,
             'nonlinearity': 'relu',
             'dropout_keep_prob': -1.0,
-            'dropout_per_sequence': False})
+            'dropout_per_sequence': False
+        })
 
     self._weights = []
     self._biases = []
     self._widths = map(int, self._attrs['widths'].split(','))
-    self._depths = map(int, self._attrs['depths'].split(','))
+    self._depths = [self._concatenated_input_dim]
+
+    # Since we infer the input dimension, depths could be empty
+    if self._attrs['depths']:
+      self._depths.extend(map(int, self._attrs['depths'].split(',')))
+
     self._output_dim = self._attrs['output_embedding_dim']
     if self._output_dim:
       self._depths.append(self._output_dim)
+
+    if len(self._widths) != len(self._depths) - 1:
+      raise RuntimeError(
+          'Unmatched widths/depths: %d/%d (depths should equal widths + 1)' %
+          (len(self._widths), len(self._depths)))
+
     self.kernel_shapes = []
     for i in range(len(self._depths) - 1):
       self.kernel_shapes.append(
@@ -1350,10 +1479,9 @@ class ConvNetwork(NetworkUnitInterface):
 
     self._params.extend(self._weights + self._biases)
     self._layers.append(
-        Layer(
-            component, name='conv_output', dim=self._depths[-1]))
-    self._regularized_weights.extend(self._weights[:-1] if self._output_dim else
-                                     self._weights)
+        Layer(component, name='conv_output', dim=self._depths[-1]))
+    self._regularized_weights.extend(self._weights[:-1]
+                                     if self._output_dim else self._weights)
 
   def create(self,
              fixed_embeddings,
@@ -1365,7 +1493,7 @@ class ConvNetwork(NetworkUnitInterface):
     """Requires |stride|; otherwise see base class."""
     if stride is None:
       raise RuntimeError("ConvNetwork needs 'stride' and must be called in the "
-                         "bulk feature extractor component.")
+                         'bulk feature extractor component.')
     input_tensor = get_input_tensor_with_stride(fixed_embeddings,
                                                 linked_embeddings, stride)
 
@@ -1388,8 +1516,253 @@ class ConvNetwork(NetworkUnitInterface):
         if i < (len(self._weights) - 1) or not self._output_dim:
           conv = self._nonlinearity(conv, name=scope.name)
     return [
+        tf.reshape(conv, [-1, self._depths[-1]], name='reshape_activations')
+    ]
+
+  def _maybe_apply_dropout(self, inputs, stride):
+    # The |inputs| are rank 4 (one 1xN "image" per sequence).  Squeeze out and
+    # restore the singleton image height, so dropout is applied to the normal
+    # rank 3 batched input tensor.
+    inputs = tf.squeeze(inputs, [1])
+    inputs = maybe_apply_dropout(inputs, self._dropout_rate,
+                                 self._attrs['dropout_per_sequence'], stride)
+    inputs = tf.expand_dims(inputs, 1)
+    return inputs
+
+
+class ConvMultiNetwork(NetworkUnitInterface):
+  """Implementation of a convolutional feed forward net with a side tower."""
+
+  def __init__(self, component):
+    """Initializes kernels and biases for this convolutional net.
+
+    Args:
+      component: parent ComponentBuilderBase object.
+
+    Parameters used to construct the network:
+      widths: comma separated list of ints, number of steps input to the
+              convolutional kernel at every layer.
+      depths: comma separated list of ints, number of channels input to the
+              convolutional kernel at every layer except the first.
+      output_embedding_dim: int, number of output channels for the convolutional
+              kernel of the last layer, which receives no ReLU activation and
+              therefore can be used in a softmax output. If zero, this final
+              layer is disabled entirely.
+      side_tower_index: An int representing the layer of the tower that the
+              side tower will start from. 0 is the input data and 'num_layers'
+              is the output.
+      side_tower_widths: comma separated list of ints, number of steps input to
+              the convolutional kernel at every layer of the side tower.
+      side_tower_depths: comma separated list of ints, number of channels input
+              to the convolutional kernel at every layer of the side tower save
+              the first.
+      side_tower_output_embedding_dim: int, number of output channels for the
+              kernel of the last layer, which receives no ReLU activation and
+              therefore can be used in a softmax output. If zero, this final
+              layer is disabled entirely.
+      nonlinearity ('relu'): Name of function from module "tf.nn" to apply to
+        each hidden layer; e.g., "relu" or "elu".
+      dropout_keep_prob (-1.0): The probability that an input is not dropped.
+        If >= 1.0, disables dropout.  If < 0.0, uses the global |dropout_rate|
+        hyperparameter.
+      dropout_per_sequence (False): If true, sample the dropout mask once per
+        sequence, instead of once per step.  See Gal and Ghahramani
+        (https://arxiv.org/abs/1512.05287).
+
+    Raises:
+      RuntimeError: if the number of widths is not equal to the number of
+          depths - 1.
+
+    The input depth of the first layer is inferred from the total concatenated
+    size of the input features.
+
+    Hyperparameters used:
+      dropout_rate: The probability that an input is not dropped.  Only used
+          when the |dropout_keep_prob| parameter is negative.
+    """
+
+    super(ConvMultiNetwork, self).__init__(component)
+    self._attrs = get_attrs_with_defaults(
+        component.spec.network_unit.parameters,
+        defaults={
+            'widths': '',
+            'depths': '',
+            'output_embedding_dim': 0,
+            'side_tower_index': 0,
+            'side_tower_widths': '',
+            'side_tower_depths': '',
+            'side_tower_output_embedding_dim': 0,
+            'nonlinearity': 'relu',
+            'dropout_keep_prob': -1.0,
+            'dropout_per_sequence': False
+        })
+
+    # Examine the widths and depths for the primary tower.
+    self._weights = []
+    self._biases = []
+    self._widths = map(int, self._attrs['widths'].split(','))
+    self._depths = [self._concatenated_input_dim]
+
+    # Since we infer the input dimension, depths could be empty.
+    if self._attrs['depths']:
+      self._depths.extend(map(int, self._attrs['depths'].split(',')))
+
+    self._output_dim = self._attrs['output_embedding_dim']
+    if self._output_dim:
+      self._depths.append(self._output_dim)
+
+    if len(self._widths) != len(self._depths) - 1:
+      raise RuntimeError(
+          'Unmatched widths/depths: %d/%d (depths should equal widths + 1)' %
+          (len(self._widths), len(self._depths)))
+
+    # Create the kernels for the primary tower.
+    self.kernel_shapes = []
+    for i in range(len(self._depths) - 1):
+      self.kernel_shapes.append(
+          [1, self._widths[i], self._depths[i], self._depths[i + 1]])
+    for i in range(len(self._depths) - 1):
+      with tf.variable_scope('conv%d' % i):
+        self._weights.append(
+            tf.get_variable(
+                'weights',
+                self.kernel_shapes[i],
+                initializer=tf.random_normal_initializer(stddev=1e-4),
+                dtype=tf.float32))
+        bias_init = 0.0 if (i == len(self._widths) - 1) else 0.2
+        self._biases.append(
+            tf.get_variable(
+                'biases',
+                self.kernel_shapes[i][-1],
+                initializer=tf.constant_initializer(bias_init),
+                dtype=tf.float32))
+
+    # Examine the widths and depths for the side tower.
+    self._side_index = self._attrs['side_tower_index']
+    self._side_weights = []
+    self._side_biases = []
+    self._side_widths = map(int, self._attrs['side_tower_widths'].split(','))
+    self._side_depths = [self._depths[self._side_index]]
+
+    # Since we infer the input dimension, depths could be empty.
+    if self._attrs['side_tower_depths']:
+      self._side_depths.extend(
+          map(int, self._attrs['side_tower_depths'].split(',')))
+
+    self._side_output_dim = self._attrs['side_tower_output_embedding_dim']
+    if self._side_output_dim:
+      self._depths.append(self._side_output_dim)
+
+    if len(self._side_widths) != len(self._side_depths) - 1:
+      raise RuntimeError(
+          'Unmatched widths/depths: %d/%d (depths should equal widths + 1)' %
+          (len(self._side_widths), len(self._side_depths)))
+
+    # Create the kernels for the side tower, if there is more than one layer.
+    self.side_kernel_shapes = []
+    for i in range(len(self._side_depths) - 1):
+      self.side_kernel_shapes.append([
+          1, self._side_widths[i], self._side_depths[i], self._side_depths[i
+                                                                           + 1]
+      ])
+    for i in range(len(self._side_depths) - 1):
+      with tf.variable_scope('side_conv%d' % i):
+        self._side_weights.append(
+            tf.get_variable(
+                'weights',
+                self.side_kernel_shapes[i],
+                initializer=tf.random_normal_initializer(stddev=1e-4),
+                dtype=tf.float32))
+        bias_init = 0.0 if (i == len(self._side_widths) - 1) else 0.2
+        self._side_biases.append(
+            tf.get_variable(
+                'biases',
+                self.side_kernel_shapes[i][-1],
+                initializer=tf.constant_initializer(bias_init),
+                dtype=tf.float32))
+
+    # Extract nonlinearity from |tf.nn|.
+    self._nonlinearity = getattr(tf.nn, self._attrs['nonlinearity'])
+
+    # Infer dropout rate from network parameters and grid hyperparameters.
+    self._dropout_rate = self._attrs['dropout_keep_prob']
+    if self._dropout_rate < 0.0:
+      self._dropout_rate = component.master.hyperparams.dropout_rate
+
+    self._params.extend(self._weights + self._biases + self._side_weights +
+                        self._side_biases)
+
+    # Append primary tower layers to the data structure.
+    self._layers.append(
+        Layer(component, name='conv_output', dim=self._depths[-1]))
+    if self._output_dim:
+      self._regularized_weights.extend(self._weights[:-1])
+    else:
+      self._regularized_weights.extend(self._weights)
+
+    # Append side tower layers to the data structure.
+    self._layers.append(
+        Layer(component, name='conv_side_output', dim=self._side_depths[-1]))
+    if self._side_output_dim:
+      self._regularized_weights.extend(self._side_weights[:-1])
+    else:
+      self._regularized_weights.extend(self._side_weights)
+
+  def create(self,
+             fixed_embeddings,
+             linked_embeddings,
+             context_tensor_arrays,
+             attention_tensor,
+             during_training,
+             stride=None):
+    """Requires |stride|; otherwise see base class."""
+    if stride is None:
+      raise RuntimeError("ConvNetwork needs 'stride' and must be called in the "
+                         'bulk feature extractor component.')
+    input_tensor = get_input_tensor_with_stride(fixed_embeddings,
+                                                linked_embeddings, stride)
+
+    # TODO(googleuser): Add context and attention.
+    del context_tensor_arrays, attention_tensor
+
+    # On CPU, add a dimension so that the 'image' has shape
+    # [stride, 1, num_steps, D].
+    conv = tf.expand_dims(input_tensor, 1)
+    for i in range(len(self._depths) - 1):
+      if i == self._side_index:
+        logging.info('Creating side tower at index %d', i)
+        side_conv = conv
+        for j in range(len(self._side_depths) - 1):
+          with tf.variable_scope('side_conv%d' % j, reuse=True) as scope:
+            if during_training:
+              side_conv.set_shape([None, 1, None, self._side_depths[j]])
+              side_conv = self._maybe_apply_dropout(side_conv, stride)
+            side_conv = tf.nn.conv2d(
+                side_conv,
+                self._component.get_variable('weights'), [1, 1, 1, 1],
+                padding='SAME')
+            side_conv = tf.nn.bias_add(side_conv,
+                                       self._component.get_variable('biases'))
+            if j < (len(self._side_weights) - 1) or not self._side_output_dim:
+              side_conv = self._nonlinearity(side_conv, name=scope.name)
+
+      with tf.variable_scope('conv%d' % i, reuse=True) as scope:
+        if during_training:
+          conv.set_shape([None, 1, None, self._depths[i]])
+          conv = self._maybe_apply_dropout(conv, stride)
+        conv = tf.nn.conv2d(
+            conv,
+            self._component.get_variable('weights'), [1, 1, 1, 1],
+            padding='SAME')
+        conv = tf.nn.bias_add(conv, self._component.get_variable('biases'))
+        if i < (len(self._weights) - 1) or not self._output_dim:
+          conv = self._nonlinearity(conv, name=scope.name)
+
+    return [
+        tf.reshape(conv, [-1, self._depths[-1]], name='reshape_activations'),
         tf.reshape(
-            conv, [-1, self._depths[-1]], name='reshape_activations')
+            side_conv, [-1, self._side_depths[-1]],
+            name='reshape_side_activations'),
     ]
 
   def _maybe_apply_dropout(self, inputs, stride):
@@ -1406,20 +1779,17 @@ class ConvNetwork(NetworkUnitInterface):
 class PairwiseConvNetwork(NetworkUnitInterface):
   """Implementation of a pairwise 2D convolutional feed forward network.
 
-  For a sequence of N tokens, all N^2 pairs of concatenated input features are
-  constructed. If each input vector is of length D, then the sequence is
-  represented by an image of dimensions [N, N] with 2*D channels per pixel.
-  I.e. pixel [i, j] has a representation that is the concatenation of the
-  representations of the tokens at i and at j.
-
-  To use this network for graph edge scoring, for instance by using the "heads"
-  transition system, the output layer needs to have dimensions [N, N] and only
-  a single channel. The network takes care of outputting an [N, N] sized layer,
-  but the user needs to ensure that the output depth equals 1.
-
-  TODO(googleuser): Like Dozat and Manning, we will need an
-  additional network to label the edges, and the ability to read head
-  and modifier representations from different inputs.
+  For two sequences of representations of N tokens, all N^2 pairs of
+  concatenated input features are constructed. If each input vector is of
+  length D, then the sequence is represented by an image of dimensions [N, N]
+  with 2*D channels per pixel. I.e. pixel [i, j] has a representation that is
+  the concatenation of the representations of the tokens at i and at j.
+
+  To use this network for graph edge scoring, for instance by using the
+  "heads_labels" transition system, the output layer needs to have dimensions
+  [N, N*num_labels]. The network takes care of outputting an [N, N*last_dim]
+  sized layer, but the user needs to ensure that the output depth equals the
+  desired number of output labels.
   """
 
   def __init__(self, component):
@@ -1430,62 +1800,98 @@ class PairwiseConvNetwork(NetworkUnitInterface):
           convolutional kernel at every layer.
       widths: comma separated list of ints, number of steps input to the
           convolutional kernel at every layer.
-      relu_layers: comma separate list of ints, the id of layers after which
-          to apply a relu activation. *By default, all but the final layer will
-          have a relu activation applied.*
-
-    To generate a network with M layers, both 'depths' and 'widths' must be of
-    length M. The input depth of the first layer is inferred from the total
-    concatenated size of the input features.
+      dropout: comma separated list of floats, dropout keep probability for each
+          layer.
+      bias_init: comma separated list of floats, constant bias initializer for
+          each layer.
+      initialization: comma separated list of strings, initialization for each
+          layer. See add_var_initialized() for available initialization schemes.
+      activation_layers: comma separated list of ints, the id of layers after
+          which to apply an activation. *By default, all but the final layer
+          will have an activation applied.*
+      activation: anything defined in tf.nn.
+
+    To generate a network with M layers, 'depths', 'widths', 'dropout',
+    'bias_init' and 'initialization' must be of length M. The input depth of the
+    first layer is inferred from the total concatenated size of the input
+    features.
 
     Args:
       component: parent ComponentBuilderBase object.
 
     Raises:
-      RuntimeError: if the number of depths and weights are not equal.
-      ValueError: if the final depth is not equal to 1.
+      RuntimeError: if the lists of dropout, bias_init, initialization, and
+          widths do not have equal length, or the number of widths is not
+          equal to the number of depths - 1.
     """
     parameters = component.spec.network_unit.parameters
     super(PairwiseConvNetwork, self).__init__(component)
 
+    self._source_dim = self._linked_feature_dims['sources']
+    self._target_dim = self._linked_feature_dims['targets']
+
     # Each input pixel will comprise the concatenation of two tokens, so the
     # input depth is double that for a single token.
-    self._depths = [self._concatenated_input_dim * 2]
-    self._depths.extend(map(int, parameters['depths'].split(',')))
+    self._depths = [self._source_dim + self._target_dim]
     self._widths = map(int, parameters['widths'].split(','))
     self._num_layers = len(self._widths)
-    if len(self._depths) != self._num_layers + 1:
-      raise RuntimeError('Unmatched depths/weights %s/%s' %
-                         (parameters['depths'], parameters['weights']))
-    if self._depths[-1] != 1:
-      raise ValueError('Final depth is not equal to 1 in %s' %
-                       parameters['depths'])
+    self._dropout = map(float, parameters['dropout'].split(',')) if parameters[
+        'dropout'] else [1.0] * self._num_layers
+    self._bias_init = map(float, parameters['bias_init'].split(
+        ',')) if parameters['bias_init'] else [0.01] * self._num_layers
+    self._initialization = parameters['initialization'].split(
+        ',') if parameters['initialization'] else ['xavier'] * self._num_layers
+    param_lengths = map(len, [
+        self._widths, self._dropout, self._bias_init, self._initialization
+    ])
+    if not all(param_lengths[0] == param_len for param_len in param_lengths):
+      raise RuntimeError(
+          'Unmatched widths/dropout/bias_init/initialization: ' +
+          '%d/%d/%d/%d' % (param_lengths[0], param_lengths[1],
+                           param_lengths[2], param_lengths[3]))
+
+    self._depths.extend(map(int, parameters['depths'].split(',')))
+    if len(self._depths) != len(self._widths) + 1:
+      raise RuntimeError(
+          'Unmatched widths/depths: %d/%d (depths should equal widths + 1)' %
+          (len(self._widths), len(self._depths)))
+
+    if parameters['activation']:
+      self._activation = parameters['activation']
+    else:
+      self._activation = 'relu'
+    self._activation_fn = getattr(tf.nn, self._activation)
+
+    self._num_labels = self._depths[-1]
+
+    if parameters['activation_layers']:
+      self._activation_layers = set(map(int,
+                                        parameters['activation_layers'].split(
+                                            ',')))
+    else:
+      self._activation_layers = set(range(self._num_layers - 1))
 
     self._kernel_shapes = []
     for i, width in enumerate(self._widths):
-      self._kernel_shapes.append(
-          [width, width, self._depths[i], self._depths[i + 1]])
-    if parameters['relu_layers']:
-      self._relu_layers = set(map(int, parameters['relu_layers'].split(',')))
-    else:
-      self._relu_layers = set(range(self._num_layers - 1))
+      if self._activation == 'glu' and i in self._activation_layers:
+        self._kernel_shapes.append(
+            [width, width, self._depths[i], 2*self._depths[i + 1]])
+      else:
+        self._kernel_shapes.append(
+            [width, width, self._depths[i], self._depths[i + 1]])
 
     self._weights = []
     self._biases = []
     for i, kernel_shape in enumerate(self._kernel_shapes):
       with tf.variable_scope('conv%d' % i):
         self._weights.append(
-            tf.get_variable(
-                'weights',
-                kernel_shape,
-                initializer=tf.random_normal_initializer(stddev=1e-4),
-                dtype=tf.float32))
-        bias_init = 0.0 if i in self._relu_layers else 0.2
+            add_var_initialized('weights', kernel_shape, self._initialization[
+                i]))
         self._biases.append(
             tf.get_variable(
                 'biases',
                 kernel_shape[-1],
-                initializer=tf.constant_initializer(bias_init),
+                initializer=tf.constant_initializer(self._bias_init[i]),
                 dtype=tf.float32))
 
     self._params.extend(self._weights + self._biases)
@@ -1500,34 +1906,46 @@ class PairwiseConvNetwork(NetworkUnitInterface):
              during_training,
              stride=None):
     """Requires |stride|; otherwise see base class."""
+    del context_tensor_arrays, attention_tensor  # Unused.
     # TODO(googleuser): Normalize the arguments to create(). 'stride'
     # is unused by the recurrent network units, while 'context_tensor_arrays'
     # and 'attenion_tensor_array' is unused by bulk network units. b/33587044
     if stride is None:
       raise ValueError("PairwiseConvNetwork needs 'stride'")
 
-    input_tensor = get_input_tensor_with_stride(fixed_embeddings,
-                                                linked_embeddings, stride)
-
-    # TODO(googleuser): Add dropout.
-    del context_tensor_arrays, attention_tensor, during_training  # Unused.
-
-    num_steps = tf.shape(input_tensor)[1]
-    arg1 = tf.expand_dims(input_tensor, 1)
-    arg1 = tf.tile(arg1, tf.stack([1, num_steps, 1, 1]))
-    arg2 = tf.expand_dims(input_tensor, 2)
-    arg2 = tf.tile(arg2, tf.stack([1, 1, num_steps, 1]))
+    sources = lookup_named_tensor('sources', linked_embeddings).tensor
+    targets = lookup_named_tensor('targets', linked_embeddings).tensor
+
+    source_tokens = tf.reshape(sources, [stride, -1, 1, self._source_dim])
+    target_tokens = tf.reshape(targets, [stride, 1, -1, self._target_dim])
+
+    # sources and targets should have shapes [b, n, 1, s] and [b, 1, n, t],
+    # respectively. Since we just reshaped them, we can check that all dims are
+    # as expected by checking the one unknown dim, i.e. their num_steps (n) dim.
+    sources_shape = tf.shape(source_tokens)
+    targets_shape = tf.shape(target_tokens)
+    num_steps = sources_shape[1]
+    with tf.control_dependencies([tf.assert_equal(num_steps, targets_shape[2],
+                                                  name='num_steps_mismatch')]):
+      arg1 = tf.tile(source_tokens, tf.stack([1, 1, num_steps, 1]))
+      arg2 = tf.tile(target_tokens, tf.stack([1, num_steps, 1, 1]))
     conv = tf.concat([arg1, arg2], 3)
     for i in xrange(self._num_layers):
       with tf.variable_scope('conv%d' % i, reuse=True) as scope:
-        conv = tf.nn.conv2d(
-            conv,
-            self._component.get_variable('weights'), [1, 1, 1, 1],
-            padding='SAME')
+        if during_training:
+          conv = maybe_apply_dropout(conv, self._dropout[i], False)
+        conv = tf.nn.conv2d(conv,
+                            self._component.get_variable('weights'),
+                            [1, 1, 1, 1],
+                            padding='SAME')
         conv = tf.nn.bias_add(conv, self._component.get_variable('biases'))
-        if i in self._relu_layers:
-          conv = tf.nn.relu(conv, name=scope.name)
-    return [tf.reshape(conv, [-1, num_steps], name='reshape_activations')]
+        if i in self._activation_layers:
+          conv = self._activation_fn(conv, name=scope.name)
+    return [
+        tf.reshape(
+            conv, [-1, num_steps * self._num_labels],
+            name='reshape_activations')
+    ]
 
 
 class ExportFixedFeaturesNetwork(NetworkUnitInterface):
@@ -1593,7 +2011,7 @@ class SplitNetwork(NetworkUnitInterface):
 
     for slice_index in xrange(self._num_slices):
       self._layers.append(
-          Layer(self, 'slice_%s' % slice_index, self._slice_dim))
+          Layer(component, 'slice_%s' % slice_index, self._slice_dim))
 
   def create(self,
              fixed_embeddings,
@@ -1602,5 +2020,103 @@ class SplitNetwork(NetworkUnitInterface):
              attention_tensor,
              during_training,
              stride=None):
+    """See base class."""
     input_bnxd = get_input_tensor(fixed_embeddings, linked_embeddings)
     return tf.split(input_bnxd, self._num_slices, axis=1)
+
+
+class GatherNetwork(NetworkUnitInterface):
+  """Network unit that gathers input according to specified step indices.
+
+  This can be used to implement a non-trivial linked feature (i.e., where the
+  link mapping is more complex than 'input.focus').  Extract the step indices
+  using a BulkFeatureIdExtractorComponentBuilder, and then gather activations
+  using this network.
+
+  Note that the step index -1 is special: gathering it will retrieve a padding
+  vector, which can be constant (zeros) or trainable.
+
+  Parameters:
+    trainable_padding (False): Whether the padding vector is trainable.
+
+  Features:
+    indices: [B * N, 1] The step indices to gather, local to each batch item.
+      These are local in the sense that, for each batch item, the step indices
+      are in the range [-1,N).
+    All other features are concatenated into a [B * N, D] matrix.
+
+  Layers:
+    outputs: [B * N, D] The first slice of the input.
+  """
+
+  def __init__(self, component):
+    """Initializes weights and layers.
+
+    Args:
+      component: Parent ComponentBuilderBase object.
+    """
+    super(GatherNetwork, self).__init__(component)
+    self._attrs = get_attrs_with_defaults(
+        component.spec.network_unit.parameters, {'trainable_padding': False})
+
+    check.In('indices', self._linked_feature_dims,
+             'Missing required linked feature')
+    check.Eq(self._linked_feature_dims['indices'], 1,
+             'Wrong dimension for "indices" feature')
+    self._dim = self._concatenated_input_dim - 1  # exclude 'indices'
+    self._layers.append(Layer(component, 'outputs', self._dim))
+
+    if self._attrs['trainable_padding']:
+      self._params.append(
+          tf.get_variable(
+              'pre_padding', [1, 1, self._dim],
+              initializer=tf.random_normal_initializer(stddev=1e-4),
+              dtype=tf.float32))
+
+  def create(self,
+             fixed_embeddings,
+             linked_embeddings,
+             context_tensor_arrays,
+             attention_tensor,
+             during_training,
+             stride=None):
+    """Requires |stride|; otherwise see base class."""
+    check.NotNone(stride,
+                  'BulkBiLSTMNetwork requires "stride" and must be called '
+                  'in the bulk feature extractor component.')
+
+    # Extract the batched local step indices.
+    local_indices = lookup_named_tensor('indices', linked_embeddings)
+    local_indices_bxn = tf.reshape(local_indices.tensor, [stride, -1])
+    local_indices_bxn = tf.to_int32(local_indices_bxn)
+    num_steps = tf.shape(local_indices_bxn)[1]
+
+    # Collect all other inputs as a batched tensor.
+    linked_embeddings = [
+        named_tensor for named_tensor in linked_embeddings
+        if named_tensor.name != 'indices'
+    ]
+    inputs_bnxd = get_input_tensor(fixed_embeddings, linked_embeddings)
+
+    # Prepend the padding vector, which may be trainable or constant.
+    inputs_bxnxd = tf.reshape(inputs_bnxd, [stride, -1, self._dim])
+    if self._attrs['trainable_padding']:
+      padding_1x1xd = self._component.get_variable('pre_padding')
+      padding_bx1xd = tf.tile(padding_1x1xd, [stride, 1, 1])
+    else:
+      padding_bx1xd = tf.zeros([stride, 1, self._dim], tf.float32)
+    inputs_bxnxd = tf.concat([padding_bx1xd, inputs_bxnxd], 1)
+    inputs_bnxd = tf.reshape(inputs_bxnxd, [-1, self._dim])
+
+    # As mentioned above, for each batch item the local step indices are in the
+    # range [-1,N).  To compensate for batching and padding, the local indices
+    # must be progressively offset into "global" indices such that batch item b
+    # is in the range [b*(N+1),(b+1)*(N+1)).
+    batch_indices_b = tf.range(stride)
+    batch_indices_bx1 = tf.expand_dims(batch_indices_b, 1)
+    local_to_global_offsets_bx1 = batch_indices_bx1 * (num_steps + 1) + 1
+    global_indices_bxn = local_indices_bxn + local_to_global_offsets_bx1
+    global_indices_bn = tf.reshape(global_indices_bxn, [-1])
+
+    outputs_bnxd = tf.gather(inputs_bnxd, global_indices_bn)
+    return [outputs_bnxd]
diff --git a/research/syntaxnet/dragnn/python/network_units_test.py b/research/syntaxnet/dragnn/python/network_units_test.py
index d913c526..fa4ae17c 100644
--- a/research/syntaxnet/dragnn/python/network_units_test.py
+++ b/research/syntaxnet/dragnn/python/network_units_test.py
@@ -16,16 +16,16 @@
 """Tests for network_units."""
 
 
+import numpy as np
 import tensorflow as tf
+
+from google.protobuf import text_format
 from tensorflow.python.framework import test_util
 from tensorflow.python.platform import googletest
 
 from dragnn.protos import spec_pb2
 from dragnn.python import network_units
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
 
 
@@ -66,6 +66,9 @@ class MockComponent(object):
   def attr(self, name):
     return self._attrs[name]
 
+  def get_variable(self, name):
+    return tf.get_variable(name)
+
 
 class MockMaster(object):
 
@@ -77,6 +80,15 @@ class MockMaster(object):
     }
 
 
+class MockNetwork(object):
+
+  def __init__(self, **dims):
+    self._dims = dims
+
+  def get_layer_size(self, name):
+    return self._dims[name]
+
+
 class NetworkUnitsLookupTest(test_util.TensorFlowTestCase):
 
   def setUp(self):
@@ -155,5 +167,256 @@ class GetAttrsWithDefaultsTest(test_util.TensorFlowTestCase):
     _assert_attr_is_true('TRUE')
 
 
+class GatherNetworkTest(test_util.TensorFlowTestCase):
+
+  def setUp(self):
+    # Clear the graph and all existing variables.  Otherwise, variables created
+    # in different tests may collide with each other.
+    tf.reset_default_graph()
+
+    self._master = MockMaster()
+    self._master.spec = spec_pb2.MasterSpec()
+    text_format.Parse("""
+      component {
+        name: 'test'
+        backend { registered_name: 'TestComponent' }
+        linked_feature {
+          name: 'indices'
+          fml: 'input.focus'
+          size: 1
+          embedding_dim: -1
+          source_component: 'previous'
+          source_translator: 'identity'
+          source_layer: 'index_layer'
+        }
+        linked_feature {
+          name: 'features'
+          fml: 'input.focus'
+          size: 1
+          embedding_dim: -1
+          source_component: 'previous'
+          source_translator: 'identity'
+          source_layer: 'feature_layer'
+        }
+        network_unit {
+          registered_name: 'GatherNetwork'
+        }
+      }
+    """, self._master.spec)
+    self._component = MockComponent(self._master,
+                                    self._master.spec.component[0])
+    self._master.lookup_component['previous'].network = MockNetwork(
+        index_layer=1, feature_layer=2)
+
+  def testConstantPadding(self):
+    with tf.Graph().as_default(), self.test_session():
+      with tf.variable_scope('test_scope'):
+        network = network_units.GatherNetwork(self._component)
+
+      # Construct a batch of two items with 3 and 2 steps, respectively.
+      indices = tf.constant([[1], [2], [0],  # item 1
+                             [-1], [0], [-1]],  # item 2
+                            dtype=tf.int64)
+      features = tf.constant([[1.0, 1.5], [2.0, 2.5], [3.0, 3.5],  # item 1
+                              [4.0, 4.5], [5.0, 5.5], [6.0, 6.5]],  # item 2
+                             dtype=tf.float32)
+
+      fixed_embeddings = []
+      linked_embeddings = [
+          network_units.NamedTensor(indices, 'indices', 1),
+          network_units.NamedTensor(features, 'features', 2)
+      ]
+
+      with tf.variable_scope('test_scope', reuse=True):
+        outputs = network.create(fixed_embeddings, linked_embeddings, None,
+                                 None, True, 2)
+      gathered = outputs[0]
+
+      # Zeros will be substituted for index -1.
+      self.assertAllEqual(gathered.eval(),
+                          [[2.0, 2.5],  # gathered from 1
+                           [3.0, 3.5],  # gathered from 2
+                           [1.0, 1.5],  # gathered from 0
+                           [0.0, 0.0],  # gathered from -1
+                           [4.0, 4.5],  # gathered from 0
+                           [0.0, 0.0]])  # gathered from -1
+
+  def testTrainablePadding(self):
+    self._component.spec.network_unit.parameters['trainable_padding'] = 'true'
+    with tf.Graph().as_default(), self.test_session():
+      with tf.variable_scope('test_scope'):
+        network = network_units.GatherNetwork(self._component)
+
+      # Construct a batch of two items with 3 and 2 steps, respectively.
+      indices = tf.constant([[1], [2], [0],  # item 1
+                             [-1], [0], [-1]],  # item 2
+                            dtype=tf.int64)
+      features = tf.constant([[1.0, 1.5], [2.0, 2.5], [3.0, 3.5],  # item 1
+                              [4.0, 4.5], [5.0, 5.5], [6.0, 6.5]],  # item 2
+                             dtype=tf.float32)
+
+      fixed_embeddings = []
+      linked_embeddings = [
+          network_units.NamedTensor(indices, 'indices', 1),
+          network_units.NamedTensor(features, 'features', 2)
+      ]
+
+      with tf.variable_scope('test_scope', reuse=True):
+        outputs = network.create(fixed_embeddings, linked_embeddings, None,
+                                 None, True, 2)
+      gathered = outputs[0]
+
+      # Ensure that the padding variable is initialized.
+      tf.global_variables_initializer().run()
+
+      # Randomly-initialized padding will be substituted for index -1.
+      self.assertAllEqual(gathered[0].eval(), [2.0, 2.5])  # gathered from 1
+      self.assertAllEqual(gathered[1].eval(), [3.0, 3.5])  # gathered from 2
+      self.assertAllEqual(gathered[2].eval(), [1.0, 1.5])  # gathered from 0
+      tf.logging.info('padding = %s', gathered[3].eval())  # gathered from -1
+      self.assertAllEqual(gathered[4].eval(), [4.0, 4.5])  # gathered from 0
+      tf.logging.info('padding = %s', gathered[5].eval())  # gathered from -1
+
+      # Though random, the padding must identical.
+      self.assertAllEqual(gathered[3].eval(), gathered[5].eval())
+
+
+class IdentityInitializerTest(test_util.TensorFlowTestCase):
+
+  def IdentityInitializerHelper(self, shape, expected, divisor=1.0, std=1e-4):
+    """Tests identity initialization by comparing expected to actual array.
+
+    Tests the given expected array against the result of calling
+    network_units.add_var_initialized() with the given params and
+    init_type='identity'.
+
+    Args:
+      shape: shape of the array
+      expected: expected contents of the array to initialize
+      divisor: numerator for identity initialization where the last two dims
+        of the array are not equal; should divide both of the last two dims
+      std: standard deviation for random normal samples
+    """
+    with tf.Graph().as_default(), self.test_session() as session:
+      np.random.seed(4)
+      tensor = network_units.add_var_initialized('tensor', shape, 'identity',
+                                                 divisor=divisor, stddev=std)
+      session.run(tf.global_variables_initializer())
+      actual = session.run(tensor)
+      self.assertAllClose(actual, expected, 1e-8, 1e-8)
+
+  def IdentityInitializerSquareHelper(self, shape, middles):
+    """Tests identity initialization when last two dims are equal.
+
+    When the last two dims of the array are equal, identity initialization
+    should simply set the center matrix in the last two dimensions to the
+    identity, with all other entries set to zero.
+
+    Args:
+      shape: shape of the array to initialize
+      middles: indices into the middle of all axes except the last two. It
+          must be the case that len(middles) == len(shape) - 2.
+    """
+    expected = np.zeros(shape, dtype='float32')
+    expected[[[m] for m in middles]] = np.eye(shape[-1])
+    self.IdentityInitializerHelper(shape, expected)
+
+  def testIdentityInitializerSquareRank2(self):
+    shape = (3, 3)
+    expected = np.eye(shape[-1]).astype('float32')
+    self.IdentityInitializerHelper(shape, expected)
+
+  def testIdentityInitializerSquareRank3(self):
+    shape = (2, 4, 4)
+    middles = [1]
+    self.IdentityInitializerSquareHelper(shape, middles)
+
+  def testIdentityInitializerSquareRank4(self):
+    shape = (2, 3, 4, 4)
+    middles = [1, 1]
+    self.IdentityInitializerSquareHelper(shape, middles)
+
+  def testIdentityInitializerSquareRank5(self):
+    shape = (2, 3, 4, 5, 5)
+    middles = [1, 1, 2]
+    self.IdentityInitializerSquareHelper(shape, middles)
+
+  def testIdentityInitializerNonSquareRank2FirstDimLarger(self):
+    divisor = 3.
+    std = 1e-3
+    shape = (6, 3)
+    m = divisor/shape[-1]
+    expected = [[m, 4.99951362e-04, -9.95908980e-04],
+                [m, -4.18301526e-04, -1.58457726e-03],
+                [-6.47706795e-04, m, 3.32250027e-04],
+                [-1.14747661e-03, m, -8.79869258e-05],
+                [4.25072387e-04, 3.32253141e-04, m],
+                [3.50997143e-04, -6.06887275e-04, m]]
+    self.IdentityInitializerHelper(shape, expected, divisor, std)
+
+  def testIdentityInitializerNonSquareRank2FirstDimSmaller(self):
+    divisor = 2.
+    std = 1e-3
+    shape = (2, 4)
+    m = divisor / shape[-1]
+    expected = [[m, m, -9.95908980e-04, 6.93598529e-04],
+                [-4.18301526e-04, -1.58457726e-03, m, m]]
+    self.IdentityInitializerHelper(shape, expected, divisor, std)
+
+  def testIdentityInitializerNonSquareRank3(self):
+    divisor = 2.
+    std = 1e-3
+    shape = (2, 2, 6)
+    m = divisor / shape[-1]
+    expected = [[[5.05617063e-05, 4.99951362e-04, -9.95908980e-04,
+                  6.93598529e-04, -4.18301526e-04, -1.58457726e-03],
+                 [-6.47706795e-04, 5.98575163e-04, 3.32250027e-04,
+                  -1.14747661e-03, 6.18669670e-04, -8.79869258e-05]],
+                [[m, m, m,
+                  3.50997143e-04, -6.06887275e-04, 1.54697930e-03],
+                 [7.23341596e-04, 4.61355667e-05, -9.82991653e-04,
+                  m, m, m]]]
+    self.IdentityInitializerHelper(shape, expected, divisor, std)
+
+  def testIdentityInitializerNonSquareRank4(self):
+    divisor = 2.
+    std = 1e-3
+    shape = (2, 3, 2, 8)
+    m = divisor / float(shape[-1])
+    expected = [
+        [[[5.05617063e-05, 4.99951362e-04, -9.95908980e-04, 6.93598529e-04,
+           -4.18301526e-04, -1.58457726e-03, -6.47706795e-04, 5.98575163e-04],
+          [3.32250027e-04, -1.14747661e-03, 6.18669670e-04, -8.79869258e-05,
+           4.25072387e-04, 3.32253141e-04, -1.15681626e-03, 3.50997143e-04]],
+
+         [[-6.06887275e-04, 1.54697930e-03, 7.23341596e-04, 4.61355667e-05,
+           -9.82991653e-04, 5.44327377e-05, 1.59892938e-04, -1.20894820e-03],
+          [2.22336012e-03, 3.94295203e-04, 1.69235771e-03, -1.11281220e-03,
+           1.63574750e-03, -1.36096554e-03, -6.51225855e-04, 5.42451337e-04]],
+
+         [[4.80062481e-05, -2.35807360e-03, -1.10558409e-03, 8.37836356e-04,
+           2.08787085e-03, 9.14840959e-04, -2.76203355e-04, 7.96511886e-04],
+          [-1.14379858e-03, 5.09919773e-04, -1.34746032e-03, -9.36010019e-06,
+           -1.30704633e-04, 8.02086608e-04, -3.02963977e-04, 1.20200263e-03]]],
+
+        [[[-1.96745284e-04, 8.36528721e-04, 7.86602264e-04, -1.84087583e-03,
+           3.75474883e-05, 3.59280530e-05, -7.78739923e-04, 1.79410708e-04],
+          [-1.45553437e-03, 5.56185201e-04, 5.09778853e-04, 3.00445536e-04,
+           2.47658417e-03, 3.52343399e-04, 6.74710027e-05, -7.32264714e-04]],
+
+         [[m, m, m, m,
+           1.58469542e-04, 1.99008291e-03, 1.16418756e-03, 2.42660157e-04],
+          [1.37992005e-03, -5.45587063e-05, 7.95233937e-04, 1.90899627e-05,
+           m, m, m, m]],
+
+         [[-1.09712186e-03, -5.28196048e-04, -2.37977528e-03, -6.07683673e-04,
+           -1.07529014e-03, 2.02240516e-03, -5.64875314e-04, -1.54292909e-03],
+          [8.70841788e-04, -1.75210531e-04, 4.86030076e-05, 1.88646198e-04,
+           2.09313483e-04, -3.74444906e-04, 9.54698597e-04, 5.23247640e-04]]]
+    ]
+
+    self.IdentityInitializerHelper(shape, expected, divisor, std)
+
+
 if __name__ == '__main__':
   googletest.main()
diff --git a/research/syntaxnet/dragnn/python/perf_test_data/master-spec b/research/syntaxnet/dragnn/python/perf_test_data/master-spec
new file mode 100644
index 00000000..6f50eaed
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/perf_test_data/master-spec
@@ -0,0 +1,171 @@
+component {
+  name: "convnet"
+  transition_system {
+    registered_name: "shift-only"
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "lexifuse-repository"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/lexifuse.lexifuse-repository/repository"
+      file_format: "repository"
+      record_format: "entity"
+    }
+  }
+  resource {
+    name: "brain-parser-model"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.convnet.model-init/brain-parser-model"
+      file_format: "model"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "transition-system-data"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.convnet.model-init/transition-system-data"
+      file_format: "model"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "words-embedding-input"
+    part {
+      file_pattern: "/readahead/512M/cns/lg-d/home/saft/corpora/word-embeddings/en/word2vec/1billion/word2vec-embedding-bi-true-32.sst"
+      file_format: "sstable"
+      record_format: "dist_belief.TokenEmbedding"
+    }
+  }
+  resource {
+    name: "words-vocab-input"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.convnet.model-init/vocab"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "component-builder-module"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.convnet.component-builder-module/module-spec"
+      file_format: "pbtxt"
+      record_format: ""
+    }
+  }
+  fixed_feature {
+    name: "char_ngram"
+    fml: "input.token.lexifuse-char-ngram"
+    embedding_dim: 16
+    vocabulary_size: 16500
+    size: 1
+    predicate_map: "hashed"
+  }
+  fixed_feature {
+    name: "words"
+    fml: "input.word"
+    embedding_dim: 32
+    vocabulary_size: 39395
+    size: 1
+    predicate_map: "hashed"
+  }
+  network_unit {
+    registered_name: "IdentityNetwork"
+  }
+  backend {
+    registered_name: "ParserComponent"
+  }
+  num_actions: 1
+  attention_component: ""
+  component_builder {
+    registered_name: "components.common.dragnn.python.conv_component.ConvComponentBuilder"
+    parameters {
+      key: "depths"
+      value: "48,128"
+    }
+    parameters {
+      key: "output_dims"
+      value: "45"
+    }
+    parameters {
+      key: "widths"
+      value: "7"
+    }
+  }
+  training_beam_size: 1
+  inference_beam_size: 1
+}
+component {
+  name: "tagger"
+  transition_system {
+    registered_name: "tagger"
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "tag-map"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/lexifuse.lexicon/tag-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "lexifuse-repository"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/lexifuse.lexifuse-repository/repository"
+      file_format: "repository"
+      record_format: "entity"
+    }
+  }
+  resource {
+    name: "brain-parser-model"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.tagger.model-init/brain-parser-model"
+      file_format: "model"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "transition-system-data"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.tagger.model-init/transition-system-data"
+      file_format: "model"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "component-builder-module"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.tagger.component-builder-module/module-spec"
+      file_format: "pbtxt"
+      record_format: ""
+    }
+  }
+  linked_feature {
+    name: "convnet"
+    fml: "input.focus"
+    embedding_dim: -1
+    size: 1
+    source_component: "convnet"
+    source_translator: "identity"
+    source_layer: "conv0_logits"
+  }
+  network_unit {
+    registered_name: "IdentityNetwork"
+  }
+  backend {
+    registered_name: "ParserComponent"
+  }
+  num_actions: 45
+  attention_component: ""
+  component_builder {
+    registered_name: "bulk_component.BulkAnnotatorComponentBuilder"
+  }
+  training_beam_size: 1
+  inference_beam_size: 1
+}
diff --git a/research/syntaxnet/dragnn/python/perf_test_data/params b/research/syntaxnet/dragnn/python/perf_test_data/params
new file mode 100644
index 00000000..62fd9d27
Binary files /dev/null and b/research/syntaxnet/dragnn/python/perf_test_data/params differ
diff --git a/research/syntaxnet/dragnn/python/perf_test_data/sample_docs.pickle b/research/syntaxnet/dragnn/python/perf_test_data/sample_docs.pickle
new file mode 100644
index 00000000..842ad77d
Binary files /dev/null and b/research/syntaxnet/dragnn/python/perf_test_data/sample_docs.pickle differ
diff --git a/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py b/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py
index 5dfb0013..beac7c97 100644
--- a/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py
+++ b/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py
@@ -28,7 +28,7 @@ from dragnn.python import spec_builder
 def _make_basic_master_spec():
   """Constructs a simple spec.
 
-  Modified version of nlp/saft/opensource/dragnn/tools/parser_trainer.py
+  Modified version of dragnn/tools/parser_trainer.py
 
   Returns:
     spec_pb2.MasterSpec instance.
diff --git a/research/syntaxnet/dragnn/python/sentence_io.py b/research/syntaxnet/dragnn/python/sentence_io.py
index 6f70c98c..534ee54b 100644
--- a/research/syntaxnet/dragnn/python/sentence_io.py
+++ b/research/syntaxnet/dragnn/python/sentence_io.py
@@ -18,21 +18,26 @@ import tensorflow as tf
 from syntaxnet.ops import gen_parser_ops
 
 
-class ConllSentenceReader(object):
-  """A reader for conll files, with optional projectivizing."""
+class FormatSentenceReader(object):
+  """A reader for formatted files, with optional projectivizing."""
 
-  def __init__(self, filepath, batch_size=32,
-               projectivize=False, morph_to_pos=False):
+  def __init__(self,
+               filepath,
+               record_format,
+               batch_size=32,
+               check_well_formed=False,
+               projectivize=False,
+               morph_to_pos=False):
     self._graph = tf.Graph()
     self._session = tf.Session(graph=self._graph)
     task_context_str = """
           input {
             name: 'documents'
-            record_format: 'conll-sentence'
+            record_format: '%s'
             Part {
              file_pattern: '%s'
             }
-          }""" % filepath
+          }""" % (record_format, filepath)
     if morph_to_pos:
       task_context_str += """
           Parameter {
@@ -51,7 +56,8 @@ class ConllSentenceReader(object):
     with self._graph.as_default():
       self._source, self._is_last = gen_parser_ops.document_source(
           task_context_str=task_context_str, batch_size=batch_size)
-      self._source = gen_parser_ops.well_formed_filter(self._source)
+      if check_well_formed:
+        self._source = gen_parser_ops.well_formed_filter(self._source)
       if projectivize:
         self._source = gen_parser_ops.projectivize_filter(self._source)
 
@@ -77,3 +83,20 @@ class ConllSentenceReader(object):
         break
     tf.logging.info('Read %d sentences.' % len(corpus))
     return corpus
+
+
+class ConllSentenceReader(FormatSentenceReader):
+  """A sentence reader that uses an underlying 'conll-sentence' reader."""
+
+  def __init__(self,
+               filepath,
+               batch_size=32,
+               projectivize=False,
+               morph_to_pos=False):
+    super(ConllSentenceReader, self).__init__(
+        filepath,
+        'conll-sentence',
+        check_well_formed=True,
+        batch_size=batch_size,
+        projectivize=projectivize,
+        morph_to_pos=morph_to_pos)
diff --git a/research/syntaxnet/dragnn/python/sentence_io_test.py b/research/syntaxnet/dragnn/python/sentence_io_test.py
index f7adc0ad..305158f1 100644
--- a/research/syntaxnet/dragnn/python/sentence_io_test.py
+++ b/research/syntaxnet/dragnn/python/sentence_io_test.py
@@ -19,16 +19,19 @@ import tensorflow as tf
 from tensorflow.python.framework import test_util
 from tensorflow.python.platform import googletest
 
+from dragnn.python import dragnn_ops
+
 from dragnn.python import sentence_io
 from syntaxnet import sentence_pb2
 
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
-if not hasattr(FLAGS, 'test_srcdir'):
-  FLAGS.test_srcdir = ''
-if not hasattr(FLAGS, 'test_tmpdir'):
-  FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
 
 
 class ConllSentenceReaderTest(test_util.TensorFlowTestCase):
diff --git a/research/syntaxnet/dragnn/python/spec_builder.py b/research/syntaxnet/dragnn/python/spec_builder.py
index 08ae2bcc..718931f3 100644
--- a/research/syntaxnet/dragnn/python/spec_builder.py
+++ b/research/syntaxnet/dragnn/python/spec_builder.py
@@ -174,16 +174,22 @@ class ComponentSpecBuilder(object):
     """Shorthand to add a fixed_feature using kwargs."""
     self.spec.fixed_feature.add(**kwargs)
 
-  def add_link(self, source, source_layer=None, source_translator='identity',
-               name=None, **kwargs):
+  def add_link(self,
+               source,
+               source_layer=None,
+               source_translator='identity',
+               name=None,
+               **kwargs):
     """Add a link using default naming and layers only."""
     if source_layer is None:
       source_layer = source.default_source_layer()
     if name is None:
       name = source.spec.name
     self.spec.linked_feature.add(
-        source_component=source.spec.name, source_layer=source_layer,
-        name=name, source_translator=source_translator,
+        source_component=source.spec.name,
+        source_layer=source_layer,
+        name=name,
+        source_translator=source_translator,
         **kwargs)
 
   def fill_from_resources(self, resource_path, tf_master=''):
@@ -209,13 +215,18 @@ class ComponentSpecBuilder(object):
         'Set a transition system before calling fill_from_resources().')
 
     context = lexicon.create_lexicon_context(resource_path)
+
+    # If there are any transition system-specific params or resources,
+    # copy them over into the context.
+    for resource in self.spec.resource:
+      context.input.add(name=resource.name).part.add(
+          file_pattern=resource.part[0].file_pattern)
     for key, value in self.spec.transition_system.parameters.iteritems():
       context.parameter.add(name=key, value=value)
 
     context.parameter.add(
         name='brain_parser_embedding_dims',
-        value=';'.join(
-            [str(x.embedding_dim) for x in self.spec.fixed_feature]))
+        value=';'.join([str(x.embedding_dim) for x in self.spec.fixed_feature]))
     context.parameter.add(
         name='brain_parser_features',
         value=';'.join([x.fml for x in self.spec.fixed_feature]))
@@ -243,6 +254,7 @@ class ComponentSpecBuilder(object):
       self.spec.linked_feature[i].size = len(
           self.spec.linked_feature[i].fml.split(' '))
 
+    del self.spec.resource[:]
     for resource in context.input:
       self.spec.resource.add(name=resource.name).part.add(
           file_pattern=resource.part[0].file_pattern)
diff --git a/research/syntaxnet/dragnn/python/spec_builder_test.py b/research/syntaxnet/dragnn/python/spec_builder_test.py
index abae0120..4b5e9693 100644
--- a/research/syntaxnet/dragnn/python/spec_builder_test.py
+++ b/research/syntaxnet/dragnn/python/spec_builder_test.py
@@ -27,13 +27,14 @@ from dragnn.python import spec_builder
 
 from syntaxnet import parser_trainer
 
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
-if not hasattr(FLAGS, 'test_srcdir'):
-  FLAGS.test_srcdir = ''
-if not hasattr(FLAGS, 'test_tmpdir'):
-  FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
 
 
 class SpecBuilderTest(tf.test.TestCase):
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.char-ngram-map b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.char-ngram-map
new file mode 100644
index 00000000..90abab4f
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.char-ngram-map
@@ -0,0 +1,9943 @@
+9942
+e 15965
+a 14481
+t 13195
+l 10226
+s 9856
+n 9295
+k 8323
+z 7517
+i 7336
+r 7230
+o 6691
+ 6265
+ 5700
+g 5129
+m 5093
+y 3359
+b 3341
+v 3177
+d 3166
+sz 2925
+el 2499
+h 2290
+, 2250
+en 1925
+et 1899
+ 1880
+j 1827
+ 1744
+gy 1727
+u 1683
+p 1670
+er 1584
+ 1567
+te 1549
+le 1475
+. 1465
+ze 1387
+s 1358
+eg 1357
+al 1355
+az 1338
+an 1331
+at 1310
+f 1299
+c 1271
+ta 1241
+tt 1192
+ak 1163
+ek 1154
+me 1032
+r 1029
+or 1027
+ne 1017
+re 983
+em 980
+ke 977
+es 970
+nt 962
+la 960
+ny 952
+is 930
+l 929
+be 923
+ 900
+s 894
+ve 886
+in 884
+ 883
+t 872
+on 867
+ll 857
+ko 843
+n 834
+lt 829
+ol 809
+na 780
+mi 763
+sze 763
+A 758
+zt 756
+os 751
+ez 738
+se 729
+ok 710
+rt 709
+ra 697
+ba 690
+to 688
+ar 673
+g 662
+n 662
+t 660
+k 644
+z 640
+r 638
+ha 635
+ka 635
+ik 603
+cs 585
+og 582
+ho 580
+ly 579
+ot 568
+sa 557
+l 555
+s 554
+ag 544
+ye 543
+de 540
+egy 536
+t 533
+l 529
+za 526
+ 522
+ni 520
+v 516
+ti 514
+ki 513
+- 510
+va 509
+nd 508
+s 504
+l 498
+ma 497
+zo 497
+bb 496
+am 493
+k 492
+ro 491
+g 490
+oz 487
+l 486
+ban 484
+m 484
+ri 478
+zer 478
+as 473
+ga 472
+t 460
+t 453
+li 451
+meg 446
+he 443
+ad 438
+so 435
+ed 433
+ben 427
+k 421
+sz 419
+t 417
+il 415
+ett 407
+szt 405
+nak 398
+ya 398
+m 395
+ele 394
+st 388
+z 388
+ogy 383
+int 382
+ott 382
+fe 380
+fo 380
+nek 378
+ap 373
+hog 358
+nem 357
+len 355
+zet 354
+it 350
+ere 349
+ge 344
+kz 341
+ja 338
+ss 335
+sg 334
+z 330
+t 328
+ut 323
+v 322
+kor 321
+je 320
+ 320
+r 317
+ 315
+j 314
+ai 311
+mo 311
+agy 310
+si 309
+vi 307
+da 306
+ig 306
+ll 303
+sg 302
+rs 301
+b 301
+do 300
+ts 300
+di 299
+let 299
+ny 297
+M 294
+1 293
+ter 285
+pe 283
+l 280
+min 277
+nk 277
+t 276
+0 273
+k 273
+ul 272
+r 272
+po 270
+K 268
+v 266
+tet 265
+om 264
+aj 259
+n 258
+eze 256
+gya 255
+p 251
+l 251
+szo 248
+tal 248
+zi 247
+z 247
+lm 246
+rd 246
+ala 244
+ia 244
+ell 243
+rm 243
+ely 242
+esz 242
+yi 240
+lk 238
+rt 238
+ny 237
+E 236
+hat 235
+9 231
+ts 231
+fel 230
+nn 230
+d 229
+S 227
+gye 227
+us 225
+mel 223
+tel 223
+ci 222
+isz 222
+vo 222
+lle 221
+ln 220
+go 219
+leg 218
+sza 218
+el 216
+gi 215
+yo 215
+sz 215
+ete 214
+het 213
+pa 212
+" 209
+i 208
+g 206
+ts 205
+v 205
+d 204
+osz 203
+tot 203
+m 202
+ab 201
+l 201
+vez 201
+i 200
+g 199
+rin 199
+eke 198
+rv 198
+iz 197
+lo 197
+n 196
+ent 195
+k 195
+lla 194
+ill 193
+vl 192
+id 189
+ren 189
+bi 186
+mb 186
+r 186
+eh 184
+hi 183
+r 183
+ato 182
+kk 182
+Az 181
+ev 181
+n 181
+k 180
+B 179
+no 179
+ld 178
+nye 178
+2 177
+csa 177
+lt 177
+vet 176
+se 176
+t 176
+ov 175
+at 174
+sok 174
+tat 174
+ros 173
+asz 172
+kat 172
+mn 172
+h 171
+olt 171
+z 170
+val 169
+tu 168
+ked 167
+k 167
+T 166
+ssz 164
+tr 164
+ei 163
+et 163
+ls 161
+un 161
+end 160
+ir 160
+ng 160
+ker 159
+et 158
+tte 158
+z 157
+l 157
+ind 156
+lat 156
+nc 156
+for 154
+mr 154
+dt 153
+eri 152
+rb 151
+s 151
+kel 150
+mag 150
+nte 150
+tk 150
+s 150
+lam 149
+ro 149
+al 148
+r 148
+av 147
+ene 147
+kez 147
+tj 147
+tl 147
+ese 145
+gaz 145
+jel 145
+koz 145
+ls 145
+ge 145
+n 144
+ve 144
+ame 143
+lta 143
+tek 143
+ra 143
+s 143
+art 142
+tta 140
+hel 139
+G 138
+d 138
+elm 138
+mu 138
+zd 138
+ej 137
+orm 137
+rl 137
+tk 137
+zte 137
+ami 136
+kb 136
+H 135
+ont 135
+b 135
+l 135
+s 135
+z 134
+nde 133
+bo 132
+emb 132
+sak 132
+sen 132
+tak 132
+ba 132
+el 131
+mbe 131
+s 131
+ors 130
+r 130
+at 129
+k 129
+lj 129
+tn 129
+so 129
+ls 128
+zn 128
+zon 128
+ber 127
+eti 127
+ku 127
+th 127
+kr 126
+mil 126
+rsz 126
+k 126
+ds 125
+r 125
+tr 125
+zal 125
+P 124
+ket 124
+nag 124
+rg 124
+rr 124
+vol 124
+ve 124
+att 123
+hoz 123
+m 123
+rm 123
+ud 123
+5 122
+f 122
+j 122
+lye 121
+ug 121
+zz 121
+: 120
+elt 120
+gat 120
+lli 120
+lk 120
+tn 120
+tr 120
+za 120
+d 119
+iv 119
+zta 119
+z 119
+j 119
+zm 118
+V 117
+eb 117
+ep 117
+tik 117
+zt 117
+tt 117
+tar 116
+yan 116
+le 116
+ara 115
+ata 115
+lt 115
+vel 115
+as 114
+ehe 114
+kl 114
+tes 114
+zen 114
+fi 113
+od 113
+tan 113
+ond 112
+te 112
+3 111
+p 111
+zel 111
+fog 110
+l 110
+sz 110
+zot 110
+l 110
+F 109
+b 109
+al 108
+est 108
+kn 108
+lg 108
+zs 108
+zg 108
+19 107
+dig 107
+lv 107
+ob 107
+s 107
+vr 107
+yar 107
+zem 107
+sa 107
+mn 106
+rk 106
+sk 106
+ten 106
+unk 106
+vis 106
+zl 106
+be 106
+bb 106
+D 105
+I 105
+b 105
+ci 105
+oro 105
+uk 105
+c 105
+ne 105
+ava 104
+mg 104
+nap 104
+nt 104
+t 104
+er 103
+lap 103
+rn 103
+ds 102
+ert 102
+kt 102
+pr 102
+z 102
+rt 101
+s 101
+ves 101
+erv 100
+tv 100
+bb 100
+N 99
+eln 99
+eme 99
+nz 99
+res 99
+tb 99
+zat 99
+zs 99
+els 98
+kp 98
+r 98
+gyo 97
+lak 97
+sem 97
+lt 96
+nt 96
+nyi 96
+oka 96
+rs 96
+t 96
+azo 95
+dol 95
+gyi 95
+kt 95
+lh 95
+oly 95
+st 95
+zs 95
+Ma 94
+men 94
+szi 94
+v 94
+yt 94
+t 94
+kn 93
+sek 93
+ts 93
+kal 92
+kos 92
+p 92
+b 92
+ur 91
+L 90
+enn 90
+ez 90
+ms 90
+nl 90
+tos 90
+ac 89
+mon 89
+nis 89
+tk 89
+R 88
+aka 88
+alk 88
+edi 88
+par 88
+uta 88
+z 88
+re 88
+( 87
+) 87
+ce 87
+cse 87
+den 87
+ege 87
+lte 87
+rz 87
+tok 87
+na 87
+7 86
+azt 86
+ed 86
+jo 86
+ju 86
+jt 86
+lem 86
+y 86
+g 86
+aki 85
+ani 85
+bel 85
+leh 85
+ns 85
+tle 85
+zz 85
+la 85
+4 84
+ori 84
+osa 84
+sb 84
+tb 84
+z 84
+99 83
+Z 83
+iu 83
+j 83
+oga 83
+tn 83
+zak 83
+v 83
+lt 83
+abb 82
+gs 82
+lal 82
+les 82
+lko 82
+ll 82
+nyo 82
+nk 82
+olg 82
+ton 82
+um 82
+gi 82
+c 81
+jd 81
+ly 80
+si 80
+ss 80
+Sz 79
+eve 79
+gb 79
+ic 79
+pi 79
+rl 79
+rn 79
+sz 79
+vg 79
+yen 79
+d 79
+azd 78
+b 78
+cso 78
+du 78
+get 78
+gr 78
+ie 78
+kr 78
+ut 78
+ad 77
+del 77
+kr 77
+las 77
+mer 77
+ut 77
+rs 77
+v 77
+8 76
+ah 76
+ajd 76
+dta 76
+ebb 76
+elk 76
+ezt 76
+rve 76
+go 76
+si 76
+gy 76
+ede 75
+etl 75
+jt 75
+jk 75
+j 75
+kon 75
+lan 75
+00 74
+apo 74
+im 74
+ort 74
+ru 74
+tja 74
+vek 74
+6 73
+au 73
+biz 73
+erb 73
+ir 73
+ls 73
+rl 73
+san 73
+zr 73
+m 73
+t 73
+J 72
+eg 72
+ide 72
+ika 72
+ln 72
+lya 72
+ony 72
+rsa 72
+sor 72
+sz 72
+yb 72
+zda 72
+alm 71
+bl 71
+das 71
+k 71
+laj 71
+nb 71
+nto 71
+r 71
+y 71
+rd 71
+ad 70
+dik 70
+ll 70
+yes 70
+zt 70
+ke 70
+k 70
+le 70
+199 69
+alo 69
+kv 69
+mos 69
+ozt 69
+van 69
+ko 69
+r 69
+O 68
+bbi 68
+gn 68
+ken 68
+li 68
+nok 68
+ola 68
+rto 68
+sel 68
+tem 68
+rt 68
+rd 68
+t 68
+Mi 67
+d 67
+ez 67
+mun 67
+nne 67
+nya 67
+ov 67
+ped 67
+rte 67
+yel 67
+ys 67
+zl 67
+ch 66
+dn 66
+han 66
+ib 66
+lek 66
+lis 66
+nna 66
+tm 66
+vn 66
+vn 66
+yer 66
+gi 66
+em 65
+ks 65
+mm 65
+pes 65
+su 65
+tr 65
+yek 65
+yz 65
+zik 65
+zk 65
+st 65
+z 65
+ako 64
+f 64
+gal 64
+kka 64
+l 64
+pol 64
+szl 64
+tk 64
+vil 64
+ly 64
+lt 64
+Ko 63
+ann 63
+ks 63
+m 63
+ncs 63
+rc 63
+ult 63
+zek 63
+ati 62
+dj 62
+don 62
+erm 62
+gl 62
+kba 62
+mr 62
+oss 62
+oz 62
+rh 62
+rom 62
+yet 62
+g 62
+j 62
+hz 61
+kar 61
+lke 61
+oz 61
+pon 61
+tha 61
+zab 61
+l 61
+d 61
+ec 60
+f 60
+gl 60
+il 60
+ini 60
+lom 60
+nl 60
+obb 60
+p 60
+zto 60
+ef 59
+emz 59
+gf 59
+gu 59
+iga 59
+jr 59
+l 59
+mz 59
+nti 59
+por 59
+rl 59
+s 59
+tb 59
+ci 59
+-e 58
+akk 58
+etn 58
+fol 58
+fl 58
+gv 58
+ise 58
+kra 58
+lel 58
+met 58
+nl 58
+s 58
+tud 58
+zol 58
+zl 58
+st 58
+n 58
+n 58
+C 57
+ank 57
+egf 57
+etk 57
+h 57
+iva 57
+kko 57
+lf 57
+lna 57
+mar 57
+nos 57
+oli 57
+sik 57
+sz 57
+tj 57
+ugy 57
+vat 57
+pe 57
+bu 56
+gt 56
+kai 56
+kap 56
+lma 56
+m 56
+sal 56
+st 56
+yik 56
+dr 55
+ds 55
+elj 55
+er 55
+gg 55
+lts 55
+op 55
+pro 55
+rat 55
+tsz 55
+yn 55
+bba 54
+b 54
+elv 54
+enc 54
+ev 54
+gh 54
+gs 54
+iku 54
+ip 54
+jn 54
+jv 54
+kus 54
+oko 54
+pt 54
+ran 54
+sr 54
+tk 54
+t 54
+usz 54
+i 54
+bor 53
+fa 53
+lb 53
+lmi 53
+lg 53
+nu 53
+okb 53
+pn 53
+rbe 53
+rde 53
+rek 53
+sm 53
+sol 53
+son 53
+ste 53
+teg 53
+tl 53
+t 53
+von 53
+zr 53
+d 53
+tt 53
+Ez 52
+eny 52
+h 52
+kes 52
+lt 52
+oc 52
+ret 52
+mo 52
+rt 52
+-b 51
+adt 51
+cg 51
+dul 51
+ess 51
+j 51
+kbe 51
+kke 51
+ll 51
+ord 51
+rv 51
+rs 51
+st 51
+tl 51
+ver 51
+zok 51
+zv 51
+d 51
+20 50
+ali 50
+egn 50
+egs 50
+eng 50
+iz 50
+ml 50
+ndo 50
+ost 50
+ozo 50
+tko 50
+tor 50
+zg 50
+zor 50
+zt 50
+nz 50
+lt 50
+ada 49
+aro 49
+arr 49
+eli 49
+gsz 49
+iat 49
+mik 49
+ono 49
+rep 49
+rme 49
+rra 49
+set 49
+sn 49
+vag 49
+vas 49
+v 49
+i 49
+v 49
+ang 48
+fej 48
+ges 48
+gj 48
+hal 48
+iti 48
+kad 48
+lha 48
+om 48
+per 48
+sr 48
+d 48
+ld 48
+r 48
+b 48
+aga 47
+aza 47
+dal 47
+dot 47
+ize 47
+lit 47
+mia 47
+r 47
+ss 47
+sz 47
+yk 47
+zm 47
+g 47
+to 47
+ana 46
+ari 46
+bl 46
+dv 46
+er 46
+has 46
+ism 46
+ist 46
+kol 46
+lad 46
+li 46
+lu 46
+nf 46
+or 46
+pp 46
+rj 46
+sba 46
+ss 46
+ven 46
+yv 46
+zni 46
+p 46
+l 46
+Mag 45
+ag 45
+atk 45
+bn 45
+det 45
+ers 45
+hez 45
+jl 45
+kv 45
+lg 45
+lni 45
+ln 45
+rta 45
+sr 45
+tve 45
+t 45
+zp 45
+n 45
+te 45
+t 45
+ama 44
+gna 44
+h 44
+kis 44
+kna 44
+lje 44
+lyi 44
+mat 44
+mok 44
+mt 44
+nka 44
+oln 44
+tla 44
+ula 44
+ysz 44
+zb 44
+zin 44
+li 44
+s 44
+U 43
+dsz 43
+d 43
+ekb 43
+eni 43
+epe 43
+gk 43
+ht 43
+lr 43
+nyt 43
+okr 43
+ona 43
+p 43
+rad 43
+rgy 43
+rke 43
+tis 43
+uda 43
+vb 43
+vt 43
+yu 43
+cs 43
+t 43
+bb 43
+ta 43
+al 42
+ar 42
+b 42
+dat 42
+elh 42
+el 42
+fl 42
+gok 42
+gon 42
+id 42
+ite 42
+il 42
+lik 42
+lt 42
+mut 42
+nk 42
+n 42
+oll 42
+szk 42
+szn 42
+tbe 42
+tke 42
+yze 42
+no 42
+j 42
+Ba 41
+Ha 41
+ane 41
+any 41
+dd 41
+gos 41
+his 41
+ine 41
+lag 41
+lme 41
+lyt 41
+mze 41
+nba 41
+nev 41
+nv 41
+oza 41
+rb 41
+rk 41
+tol 41
+tt 41
+x 41
+g 41
+re 41
+10 40
+and 40
+atj 40
+aut 40
+bes 40
+ela 40
+kia 40
+kin 40
+kr 40
+mt 40
+ol 40
+rem 40
+seb 40
+tl 40
+t 40
+zov 40
+zk 40
+zl 40
+sz 40
+to 40
+ri 40
+z 40
+n 40
+-t 39
+SZ 39
+aho 39
+anc 39
+csi 39
+egk 39
+fon 39
+iko 39
+it 39
+izo 39
+kot 39
+ld 39
+net 39
+rak 39
+sai 39
+ts 39
+ub 39
+ur 39
+yez 39
+ld 39
+z 39
+k 39
+k 39
+bs 38
+dek 38
+dez 38
+en 38
+gba 38
+gys 38
+gy 38
+gr 38
+hiv 38
+ina 38
+ire 38
+jes 38
+kul 38
+kl 38
+maj 38
+ml 38
+ozz 38
+pl 38
+rok 38
+roz 38
+sas 38
+ske 38
+sl 38
+toz 38
+vl 38
+zav 38
+zle 38
+zu 38
+zn 38
+l 38
+m 38
+ze 38
+sz 38
+anu 37
+atn 37
+br 37
+c 37
+cm 37
+ezd 37
+gek 37
+gn 37
+kt 37
+lc 37
+ln 37
+mp 37
+nge 37
+old 37
+on 37
+pj 37
+pl 37
+rba 37
+s 37
+tt 37
+tm 37
+v 37
+ym 37
+yob 37
+yr 37
+z 37
+ant 36
+apa 36
+b 36
+ca 36
+ega 36
+gym 36
+g 36
+ipa 36
+ir 36
+jdo 36
+kne 36
+lgo 36
+lhe 36
+lyo 36
+ml 36
+m 36
+ndt 36
+nd 36
+nny 36
+nyb 36
+onb 36
+ser 36
+ssa 36
+t. 36
+tam 36
+the 36
+tra 36
+yak 36
+ri 36
+Fe 35
+an 35
+ea 35
+ej 35
+elf 35
+etv 35
+goz 35
+har 35
+kc 35
+kd 35
+kt 35
+mes 35
+mis 35
+pt 35
+ron 35
+sko 35
+sl 35
+tag 35
+tav 35
+tov 35
+ts 35
+y 35
+zga 35
+ga 35
+gb 35
+rk 35
+rv 35
+e 35
+0- 34
+aly 34
+co 34
+es 34
+hol 34
+nt 34
+od 34
+pv 34
+rel 34
+rla 34
+ror 34
+rre 34
+rp 34
+sta 34
+tiz 34
+tul 34
+tv 34
+tz 34
+ybe 34
+y 34
+ 34
+l 34
+m 34
+va 34
+h 34
+lk 34
+nt 34
+zt 34
+ke 34
+Bu 33
+Or 33
+ajt 33
+alb 33
+amo 33
+ci 33
+dem 33
+egt 33
+emo 33
+erz 33
+esk 33
+gad 33
+gas 33
+hi 33
+if 33
+ike 33
+ik 33
+jut 33
+jn 33
+kci 33
+lja 33
+lg 33
+maz 33
+md 33
+mk 33
+nes 33
+nko 33
+nm 33
+pia 33
+pu 33
+red 33
+r 33
+sn 33
+tna 33
+ts 33
+tti 33
+u 33
+vs 33
+ts 33
+gv 33
+me 33
+ta 33
+je 33
+-be 32
+Me 32
+ado 32
+ape 32
+bbe 32
+dni 32
+enk 32
+es 32
+etb 32
+gel 32
+got 32
+iac 32
+id 32
+inc 32
+ing 32
+izt 32
+in 32
+kh 32
+lez 32
+lb 32
+nci 32
+nds 32
+pen 32
+tne 32
+tni 32
+yne 32
+zh 32
+v 32
+zi 32
+zl 32
+gy 32
+en 32
+v 32
+200 31
+Cs 31
+Ga 31
+Gy 31
+Ka 31
+all 31
+apj 31
+bev 31
+dn 31
+edd 31
+eje 31
+fen 31
+gen 31
+iss 31
+ius 31
+jn 31
+lsz 31
+lyn 31
+lp 31
+orv 31
+ppe 31
+pr 31
+rt 31
+sab 31
+seh 31
+tk 31
+yta 31
+bo 31
+ma 31
+r 31
+a 31
+j 31
+pa 31
+-k 30
+30 30
+K 30
+ae 30
+aj 30
+cs 30
+dap 30
+du 30
+ens 30
+erk 30
+err 30
+ezn 30
+gm 30
+gy 30
+gz 30
+hr 30
+ics 30
+ila 30
+kl 30
+kre 30
+kt 30
+kv 30
+man 30
+os 30
+ov 30
+pvi 30
+rm 30
+til 30
+ 30
+u 30
+ul 30
+p 30
+na 30
+tt 30
+k 30
+Eg 29
+Sze 29
+ajn 29
+ass 29
+bal 29
+bbs 29
+bs 29
+cl 29
+enz 29
+erg 29
+ex 29
+gra 29
+gve 29
+gy 29
+k 29
+lda 29
+lev 29
+lm 29
+lyz 29
+lr 29
+lt 29
+ll 29
+mv 29
+nyu 29
+orl 29
+rs 29
+rt 29
+rs 29
+sei 29
+tre 29
+tv 29
+tl 29
+vit 29
+yos 29
+zz 29
+zt 29
+k 29
+pp 29
+pv 29
+g 29
+s 29
+ale 28
+alt 28
+ap 28
+dar 28
+dve 28
+dn 28
+egh 28
+eit 28
+eki 28
+ets 28
+e 28
+haj 28
+ily 28
+isk 28
+j 28
+kik 28
+kod 28
+kn 28
+l- 28
+lej 28
+lto 28
+lt 28
+mba 28
+mek 28
+nik 28
+nv 28
+or 28
+ozn 28
+rit 28
+sv 28
+tas 28
+uto 28
+yh 28
+yre 28
+yb 28
+yt 28
+zbe 28
+zs 28
+zl 28
+rg 28
+rm 28
+ss 28
+ja 28
+v 28
+s 28
+Egy 27
+Min 27
+Ta 27
+ak 27
+ak 27
+aso 27
+atl 27
+azg 27
+baj 27
+bet 27
+bl 27
+ddi 27
+des 27
+dja 27
+ejl 27
+ekr 27
+emm 27
+es 27
+gfe 27
+gy 27
+gp 27
+jb 27
+kan 27
+mad 27
+mr 27
+ner 27
+nh 27
+ogl 27
+org 27
+r- 27
+rdu 27
+rd 27
+rga 27
+rha 27
+rl 27
+sme 27
+sn 27
+teh 27
+tom 27
+tts 27
+yba 27
+yil 27
+yom 27
+zn 27
+z 27
+g 27
+rn 27
+lt 27
+li 27
+r 27
+l 27
+? 26
+Bud 26
+W 26
+aku 26
+bef 26
+bek 26
+cia 26
+ep 26
+eu 26
+ged 26
+g 26
+iai 26
+io 26
+itk 26
+jr 26
+kit 26
+ksz 26
+ldi 26
+lj 26
+lk 26
+lk 26
+mit 26
+moz 26
+nda 26
+nia 26
+ntj 26
+nul 26
+orb 26
+pc 26
+saj 26
+seg 26
+sse 26
+sti 26
+st 26
+tba 26
+tt 26
+ur 26
+vs 26
+w 26
+yag 26
+yf 26
+yol 26
+yug 26
+yve 26
+nt 26
+r 26
+sr 26
+ba 26
+kk 26
+Ki 25
+Ne 25
+aba 25
+api 25
+br 25
+dh 25
+dos 25
+dl 25
+dr 25
+ecs 25
+edv 25
+egi 25
+fiz 25
+fv 25
+ger 25
+gla 25
+gre 25
+gn 25
+gr 25
+haz 25
+ium 25
+jav 25
+jog 25
+jra 25
+kok 25
+k 25
+los 25
+lov 25
+lt 25
+mt 25
+ndi 25
+nle 25
+nc 25
+okk 25
+orr 25
+pcs 25
+sap 25
+sra 25
+sk 25
+tit 25
+tl 25
+up 25
+yei 25
+zm 25
+zna 25
+zza 25
+b 25
+j 25
+r 25
+vi 25
+gy 25
+r 25
+do 25
+r 25
+nt 25
+z 25
+-es 24
+Kf 24
+Mo 24
+Va 24
+ain 24
+ait 24
+dok 24
+ekk 24
+erh 24
+gfo 24
+ih 24
+ili 24
+ito 24
+is 24
+jno 24
+kiv 24
+ll 24
+lv 24
+lyb 24
+mot 24
+nj 24
+ntr 24
+nz 24
+oci 24
+olj 24
+oma 24
+onn 24
+pet 24
+rab 24
+rny 24
+rol 24
+sh 24
+sla 24
+ty 24
+tb 24
+te 24
+ul 24
+yed 24
+yoz 24
+y 24
+zde 24
+zes 24
+zlo 24
+zoc 24
+ja 24
+m 24
+an 24
+r 24
+n 24
+El 23
+Kz 23
+Ti 23
+acs 23
+apc 23
+arc 23
+bad 23
+dei 23
+dm 23
+dre 23
+dte 23
+dk 23
+ds 23
+enl 23
+era 23
+er 23
+ezi 23
+gle 23
+gyk 23
+g 23
+ht 23
+hr 23
+iad 23
+igy 23
+imi 23
+jan 23
+lfo 23
+lka 23
+lve 23
+ly 23
+ls 23
+lk 23
+mmi 23
+mog 23
+nk 23
+nta 23
+ny 23
+omb 23
+ons 23
+pl 23
+rev 23
+rhe 23
+rt 23
+rn 23
+sod 23
+s 23
+tj 23
+tj 23
+vk 23
+vd 23
+yal 23
+yon 23
+yr 23
+zn 23
+zr 23
+zp 23
+zs 23
+vo 23
+gy 23
+kk 23
+jr 23
+1- 22
+97 22
+az 22
+cs 22
+dz 22
+dl 22
+efo 22
+egm 22
+ein 22
+ekt 22
+eml 22
+etr 22
+gbe 22
+gha 22
+gus 22
+gyv 22
+hn 22
+lcs 22
+lep 22
+lva 22
+ld 22
+lv 22
+mj 22
+nys 22
+ny 22
+ora 22
+pai 22
+ps 22
+rna 22
+sm 22
+sv 22
+ul 22
+vid 22
+yok 22
+y 22
+zre 22
+zt 22
+zze 22
+ju 22
+rh 22
+th 22
+l 22
+bb 22
+,5 21
+T 21
+arl 21
+bus 21
+dej 21
+der 21
+dt 21
+elo 21
+ern 21
+el 21
+fr 21
+gt 21
+gt 21
+gt 21
+hn 21
+inf 21
+ink 21
+jai 21
+jle 21
+jk 21
+kom 21
+kb 21
+kn 21
+lf 21
+ld 21
+mas 21
+mol 21
+nce 21
+nin 21
+nov 21
+nyk 21
+nyv 21
+nyz 21
+ng 21
+ol 21
+opo 21
+osi 21
+pte 21
+ris 21
+riu 21
+rma 21
+rti 21
+s- 21
+sop 21
+tho 21
+tus 21
+tt 21
+vb 21
+yas 21
+zeg 21
+zv 21
+zc 21
+lj 21
+sb 21
+ta 21
+g 21
+m 21
+zb 21
+s 21
+be 21
+-i 20
+- 20
+Gaz 20
+Ho 20
+J 20
+Nem 20
+abi 20
+aci 20
+adi 20
+ard 20
+bl 20
+ed 20
+ema 20
+erd 20
+eur 20
+gis 20
+gja 20
+gte 20
+gyr 20
+hag 20
+hit 20
+hor 20
+ij 20
+in 20
+jon 20
+kam 20
+ki 20
+kl 20
+ldo 20
+ls 20
+mez 20
+nal 20
+nat 20
+ndu 20
+niu 20
+ns 20
+ns 20
+nz 20
+n 20
+okn 20
+okt 20
+omo 20
+onl 20
+pat 20
+pok 20
+pn 20
+reg 20
+rge 20
+rni 20
+rog 20
+rv 20
+rze 20
+r 20
+sna 20
+sp 20
+sul 20
+sb 20
+tr 20
+tj 20
+uni 20
+ymi 20
+y 20
+zl 20
+zt 20
+zk 20
+zg 20
+ld 20
+lk 20
+tl 20
+j 20
+ze 20
+m 20
+rt 20
+r 20
+th 20
+nk 20
+ny 20
+ly 20
+50 19
+Bo 19
+Eu 19
+Eur 19
+ago 19
+akt 19
+asl 19
+az 19
+bol 19
+cha 19
+dm 19
+dn 19
+d 19
+edm 19
+efe 19
+egb 19
+egr 19
+en 19
+ft 19
+hir 19
+ive 19
+kie 19
+ks 19
+lb 19
+lne 19
+lg 19
+lr 19
+neg 19
+ng 19
+nyf 19
+ny 19
+nh 19
+ocs 19
+oh 19
+oks 19
+olc 19
+pj 19
+pl 19
+pot 19
+pri 19
+p 19
+ral 19
+rod 19
+rr 19
+rse 19
+rth 19
+rtj 19
+rvo 19
+szv 19
+sl 19
+tf 19
+tb 19
+v 19
+yor 19
+y 19
+yl 19
+zpo 19
+zpr 19
+h 19
+h 19
+rn 19
+v 19
+va 19
+g 19
+jt 19
+z 19
+v 19
+997 18
+Da 18
+En 18
+Fer 18
+Fi 18
+Kft 18
+Pe 18
+a- 18
+ab 18
+adn 18
+aik 18
+akc 18
+az 18
+bon 18
+dk 18
+dt 18
+egj 18
+egv 18
+eg 18
+eg 18
+ekn 18
+ew 18
+gge 18
+ham 18
+ich 18
+ikt 18
+iro 18
+ib 18
+job 18
+juk 18
+k- 18
+kil 18
+koc 18
+kta 18
+ks 18
+kz 18
+lin 18
+liz 18
+lz 18
+ld 18
+ls 18
+mj 18
+nd 18
+ngo 18
+nz 18
+nl 18
+olo 18
+oni 18
+orn 18
+pos 18
+rac 18
+rd 18
+rc 18
+rt 18
+sbe 18
+sre 18
+sb 18
+t- 18
+tc 18
+tm 18
+tz 18
+tk 18
+tz 18
+utc 18
+vaz 18
+vbe 18
+vos 18
+vt 18
+vl 18
+y- 18
+yt 18
+yr 18
+zan 18
+zep 18
+zkv 18
+zne 18
+zv 18
+zt 18
+ho 18
+zt 18
+sr 18
+tj 18
+la 18
+ra 18
+ke 18
+z 18
+ze 18
+ze 18
+l 18
+-s 17
+000 17
+11 17
+5- 17
+7- 17
+An 17
+Br 17
+Tu 17
+ak 17
+amb 17
+atb 17
+bar 17
+bk 17
+b 17
+cen 17
+ck 17
+ece 17
+ee 17
+ft. 17
+gk 17
+gs 17
+hl 17
+hv 17
+ial 17
+itt 17
+iut 17
+jeg 17
+kem 17
+kev 17
+kto 17
+leb 17
+lig 17
+lmo 17
+lm 17
+mai 17
+ms 17
+ms 17
+nam 17
+ndk 17
+nl 17
+nni 17
+nsz 17
+nt 17
+nk 17
+n 17
+ns 17
+odi 17
+oo 17
+raj 17
+ram 17
+re 17
+rk 17
+rz 17
+rg 17
+rt 17
+sv 17
+szs 17
+tai 17
+tev 17
+tin 17
+tm 17
+tun 17
+tv 17
+uga 17
+ved 17
+vi 17
+yko 17
+ys 17
+ys 17
+zed 17
+zsi 17
+ztr 17
+zve 17
+zt 17
+zk 17
+di 17
+j 17
+ni 17
+gr 17
+li 17
+l 17
+sb 17
+ss 17
+j 17
+tm 17
+ts 17
+d 17
+se 17
+zp 17
+z 17
+se 17
+-n 16
+2- 16
+Ak 16
+Cse 16
+Er 16
+HV 16
+Mar 16
+NS 16
+NSZ 16
+Po 16
+Re 16
+Rt 16
+Rt. 16
+af 16
+agj 16
+ajl 16
+azp 16
+azz 16
+bk 16
+csu 16
+dne 16
+dzs 16
+dj 16
+erj 16
+gy 16
+hos 16
+hu 16
+ige 16
+is 16
+jez 16
+kif 16
+ldr 16
+mir 16
+mpo 16
+ndr 16
+nu 16
+oda 16
+onz 16
+oso 16
+ovi 16
+pad 16
+pel 16
+rf 16
+rl 16
+rz 16
+sad 16
+sin 16
+str 16
+ss 16
+uc 16
+udo 16
+uln 16
+uso 16
+vic 16
+viz 16
+yeg 16
+yza 16
+zai 16
+zd 16
+zhe 16
+zob 16
+zti 16
+zr 16
+zk 16
+zd 16
+gg 16
+nd 16
+rc 16
+su 16
+bk 16
+de 16
+ka 16
+rs 16
+rz 16
+c 16
+ci 16
+f 16
+ka 16
+k 16
+me 16
+nn 16
+n 16
+n 16
+a 16
+12 15
+2, 15
+4- 15
+9- 15
+Am 15
+HVG 15
+Ke 15
+Kl 15
+Kos 15
+Le 15
+M 15
+VG 15
+Vi 15
+Ze 15
+Zs 15
+aco 15
+adj 15
+ans 15
+bn 15
+dec 15
+doz 15
+dr 15
+dd 15
+ebe 15
+ebo 15
+edn 15
+ego 15
+eig 15
+eik 15
+exp 15
+fal 15
+fek 15
+fes 15
+fil 15
+fl 15
+fra 15
+gga 15
+gin 15
+gp 15
+gyz 15
+hon 15
+hb 15
+ilt 15
+ion 15
+ita 15
+ij 15
+ik 15
+jab 15
+jus 15
+jt 15
+jl 15
+kas 15
+kov 15
+log 15
+lot 15
+mz 15
+nd 15
+ni 15
+nki 15
+nth 15
+nyn 15
+np 15
+n 15
+omm 15
+onc 15
+ope 15
+ore 15
+osb 15
+ozi 15
+pek 15
+psz 15
+pz 15
+rai 15
+rje 15
+rk 15
+rs 15
+suk 15
+sv 15
+tn 15
+tog 15
+tv 15
+ti 15
+udt 15
+ugo 15
+uh 15
+uka 15
+uz 15
+xp 15
+xpo 15
+yam 15
+yf 15
+yit 15
+yz 15
+zf 15
+zom 15
+zn 15
+ 15
+g 15
+gy 15
+gr 15
+i 15
+ko 15
+ln 15
+t 15
+t 15
+t 15
+zi 15
+mi 15
+ts 15
+vb 15
+v 15
+v 15
+ri 15
+r 15
+rz 15
+te 15
+z 15
+ks 15
+lf 15
+ln 15
+nk 15
+ad 15
+! 14
+-c 14
+-f 14
+0. 14
+1, 14
+25 14
+6- 14
+60 14
+8- 14
+80 14
+98 14
+Be 14
+He 14
+Is 14
+La 14
+Na 14
+Pr 14
+P 14
+Sza 14
+abo 14
+agu 14
+ate 14
+cem 14
+che 14
+dai 14
+dan 14
+dha 14
+dna 14
+dn 14
+dl 14
+db 14
+ek 14
+ept 14
+erc 14
+faj 14
+ggy 14
+ibe 14
+ibo 14
+ji 14
+jn 14
+kek 14
+kho 14
+llt 14
+lp 14
+lr 14
+lv 14
+ln 14
+la 14
+mc 14
+ms 14
+mg 14
+nfl 14
+nga 14
+nyl 14
+ny 14
+nr 14
+ogr 14
+ot 14
+pk 14
+pod 14
+pt 14
+rce 14
+rig 14
+ri 14
+rob 14
+sj 14
+tap 14
+tk 14
+tt 14
+ta 14
+ti 14
+tr 14
+vai 14
+vj 14
+vs 14
+vr 14
+yl 14
+yn 14
+y 14
+yj 14
+zd 14
+zn 14
+l 14
+do 14
+ls 14
+rb 14
+rk 14
+tt 14
+gb 14
+he 14
+kb 14
+k 14
+pz 14
+v 14
+ro 14
+t 14
+ll 14
+m 14
+zv 14
+ja 14
+ld 14
+l 14
+zd 14
+h 14
+ne 14
+,2 13
+-K 13
+-a 13
+-ba 13
+-sz 13
+- 13
+.- 13
+9. 13
+96 13
+999 13
+; 13
+Al 13
+EN 13
+ENS 13
+Jn 13
+Li 13
+L 13
+Meg 13
+Pi 13
+SP 13
+SZ- 13
+Z- 13
+ajo 13
+akn 13
+apu 13
+asa 13
+br 13
+b 13
+csk 13
+cs 13
+dag 13
+edt 13
+ejt 13
+ekv 13
+ezz 13
+fia 13
+fig 13
+fu 13
+fr 13
+fn 13
+gar 13
+gol 13
+gr 13
+guk 13
+gl 13
+g 13
+h 13
+iba 13
+ik 13
+ile 13
+ilm 13
+iv 13
+jla 13
+jto 13
+kb 13
+kt 13
+kut 13
+kz 13
+lde 13
+lga 13
+ll 13
+lm 13
+lon 13
+lub 13
+lc 13
+lm 13
+li 13
+mcs 13
+mf 13
+miu 13
+mme 13
+mb 13
+nai 13
+nbe 13
+ndj 13
+nep 13
+nie 13
+nn 13
+nk 13
+nt 13
+oha 13
+ou 13
+pan 13
+pas 13
+pja 13
+pn 13
+ras 13
+rea 13
+rej 13
+rez 13
+rj 13
+rle 13
+rul 13
+rus 13
+sec 13
+sup 13
+sh 13
+tth 13
+tl 13
+tm 13
+tl 13
+udj 13
+utt 13
+voz 13
+vr 13
+yis 13
+zke 13
+ztu 13
+ 13
+nc 13
+z 13
+ 13
+gz 13
+ki 13
+m 13
+tv 13
+di 13
+k 13
+nb 13
+zg 13
+ni 13
+tt 13
+nn 13
+d 13
+rs 13
+so 13
+s 13
+t 13
+-j 12
+-m 12
+-o 12
+-r 12
+-n 12
+.. 12
+B 12
+De 12
+Enn 12
+Gy 12
+Ja 12
+Ju 12
+Kor 12
+Kr 12
+Mos 12
+N 12
+R 12
+Te 12
+Tud 12
+Tr 12
+ad 12
+ag 12
+ark 12
+ath 12
+atr 12
+azi 12
+bok 12
+br 12
+bz 12
+cb 12
+cc 12
+db 12
+dt 12
+eh 12
+eld 12
+emc 12
+emp 12
+er 12
+fer 12
+fin 12
+fl 12
+gje 12
+gke 12
+gny 12
+gyh 12
+had 12
+hes 12
+hn 12
+iek 12
+ig 12
+ilo 12
+ilv 12
+ira 12
+i 12
+jc 12
+jen 12
+js 12
+jt 12
+jn 12
+km 12
+kv 12
+kz 12
+lbe 12
+ld 12
+lib 12
+llo 12
+lun 12
+lvi 12
+ll 12
+lz 12
+ml 12
+mk 12
+nfe 12
+nnt 12
+nn 12
+nom 12
+nve 12
+nb 12
+nv 12
+ok 12
+olv 12
+onv 12
+otm 12
+ppa 12
+pra 12
+pze 12
+rag 12
+rah 12
+ria 12
+rik 12
+riv 12
+rz 12
+sat 12
+sho 12
+sne 12
+som 12
+szp 12
+t.- 12
+tme 12
+tr 12
+tva 12
+tt 12
+ung 12
+up 12
+var 12
+vd 12
+v 12
+yha 12
+ym 12
+yna 12
+z- 12
+zgy 12
+zha 12
+zl 12
+zl 12
+z 12
+sk 12
+l- 12
+rv 12
+re 12
+be 12
+h 12
+kn 12
+ss 12
+rg 12
+r 12
+li 12
+lh 12
+d 12
+le 12
+ve 12
+zo 12
+-cs 11
+-h 11
+40 11
+92 11
+94 11
+95 11
+AT 11
+ATO 11
+Dae 11
+Du 11
+Dub 11
+EU 11
+Gye 11
+In 11
+J 11
+Ls 11
+MF 11
+Mik 11
+NA 11
+NAT 11
+PD 11
+RT 11
+SPD 11
+TO 11
+Ve 11
+ads 11
+adv 11
+aew 11
+ake 11
+akr 11
+ap 11
+arb 11
+aug 11
+av 11
+bc 11
+bia 11
+bl 11
+cek 11
+cel 11
+con 11
+csn 11
+dhe 11
+dk 11
+dor 11
+egg 11
+eh 11
+eks 11
+ek 11
+elg 11
+emt 11
+eru 11
+esi 11
+ev 11
+ewo 11
+ezm 11
+ezr 11
+feg 11
+fk 11
+gia 11
+gyb 11
+her 11
+ib 11
+iem 11
+igl 11
+ig 11
+ik 11
+imm 11
+ivi 11
+ij 11
+it 11
+it 11
+jet 11
+jte 11
+kab 11
+kim 11
+ks 11
+kva 11
+kv 11
+kz 11
+lab 11
+lju 11
+lok 11
+lt 11
+ly 11
+lm 11
+lz 11
+mal 11
+msz 11
+neh 11
+ngz 11
+nh 11
+nm 11
+np 11
+nr 11
+nzi 11
+nr 11
+ns 11
+obl 11
+ova 11
+pal 11
+pus 11
+rb 11
+ril 11
+rko 11
+rot 11
+sg 11
+ska 11
+szu 11
+ss 11
+tl 11
+tum 11
+tt 11
+udn 11
+ugu 11
+umo 11
+veg 11
+vem 11
+vsz 11
+vv 11
+vj 11
+vt 11
+vk 11
+wo 11
+woo 11
+yj 11
+yk 11
+yp 11
+yul 11
+zis 11
+zko 11
+zva 11
+ll 11
+jc 11
+lo 11
+p 11
+rj 11
+rv 11
+s 11
+te 11
+tv 11
+zb 11
+i 11
+ln 11
+p 11
+r 11
+zm 11
+ja 11
+s 11
+ti 11
+o 11
+ss 11
+so 11
+-v 10
+13 10
+3, 10
+4. 10
+Co 10
+Csa 10
+DS 10
+Eze 10
+I. 10
+Kon 10
+Orb 10
+Ra 10
+Si 10
+So 10
+Tit 10
+Vik 10
+ahi 10
+amf 10
+at 10
+at 10
+bce 10
+bil 10
+bin 10
+b 10
+chn 10
+cit 10
+cz 10
+dde 10
+deg 10
+dj 10
+dom 10
+dk 10
+eda 10
+egl 10
+egu 10
+ekl 10
+el 10
+emr 10
+enb 10
+epl 10
+eto 10
+et 10
+ez 10
+f 10
+gan 10
+gpi 10
+gta 10
+gb 10
+gg 10
+g 10
+i- 10
+iak 10
+ifi 10
+igi 10
+in 10
+ird 10
+ir 10
+izs 10
+ik 10
+jj 10
+jok 10
+jta 10
+jt 10
+jz 10
+j 10
+kb 10
+khe 10
+kid 10
+kl 10
+kte 10
+kt 10
+ky 10
+kb 10
+ks 10
+lei 10
+ler 10
+ln 10
+lol 10
+ls 10
+lti 10
+lyh 10
+lyr 10
+mbu 10
+mf 10
+mus 10
+n- 10
+nd 10
+ngs 10
+nn 10
+nt 10
+odo 10
+of 10
+ogo 10
+og 10
+oki 10
+olh 10
+omi 10
+oms 10
+onf 10
+oto 10
+pil 10
+pr 10
+ps 10
+rca 10
+rdo 10
+riz 10
+rja 10
+rub 10
+ruk 10
+rva 10
+rj 10
+rr 10
+sf 10
+sk 10
+sno 10
+stv 10
+sz 10
+sk 10
+st 10
+tca 10
+tje 10
+tro 10
+tse 10
+tz 10
+tn 10
+ubc 10
+ube 10
+uh 10
+ukc 10
+und 10
+uri 10
+usi 10
+vje 10
+yir 10
+yle 10
+yt 10
+yn 10
+zad 10
+zaj 10
+zba 10
+zig 10
+zi 10
+zt 10
+zt 10
+s 10
+gp 10
+nl 10
+rl 10
+tn 10
+tu 10
+p 10
+rf 10
+t 10
+zk 10
+nh 10
+ve 10
+d 10
+gy 10
+so 10
+za 10
+ko 10
+rn 10
+sz 10
+ra 10
+sz 10
+gg 10
+l 10
+s 10
+d 10
+ri 10
+14 9
+18 9
+2. 9
+992 9
+998 9
+Ami 9
+And 9
+Bar 9
+Eb 9
+Ez 9
+G 9
+Hi 9
+Ist 9
+Klu 9
+Kov 9
+K 9
+Mr 9
+Nm 9
+Oro 9
+Ped 9
+RTL 9
+Ro 9
+TL 9
+Tal 9
+Val 9
+Vo 9
+abd 9
+aeb 9
+ajz 9
+aln 9
+app 9
+apr 9
+apt 9
+arm 9
+bd 9
+bru 9
+bud 9
+bur 9
+bn 9
+cai 9
+cba 9
+ced 9
+dak 9
+din 9
+dit 9
+di 9
+dv 9
+dr 9
+dm 9
+e- 9
+edh 9
+eha 9
+eir 9
+elz 9
+emi 9
+env 9
+en 9
+esb 9
+ezh 9
+fot 9
+f 9
+gai 9
+gj 9
+gv 9
+gy- 9
+gyn 9
+gyt 9
+gy 9
+gz 9
+g 9
+hae 9
+hh 9
+hid 9
+hr 9
+ida 9
+ido 9
+iel 9
+ihe 9
+ino 9
+jb 9
+jv 9
+kee 9
+kih 9
+kj 9
+kr 9
+lav 9
+lba 9
+lic 9
+lid 9
+liu 9
+llg 9
+lre 9
+lv 9
+lb 9
+lj 9
+lk 9
+l 9
+mma 9
+mmu 9
+mn 9
+mt 9
+m 9
+mg 9
+nd 9
+nel 9
+ngy 9
+nhe 9
+nor 9
+npa 9
+oa 9
+obo 9
+ogi 9
+okh 9
+onu 9
+ove 9
+ovj 9
+ozg 9
+ozv 9
+pir 9
+pta 9
+rbi 9
+rcs 9
+rda 9
+ref 9
+rei 9
+rgi 9
+rip 9
+rka 9
+rk 9
+rso 9
+ruh 9
+rg 9
+rk 9
+rt 9
+sc 9
+sg 9
+sun 9
+sz 9
+tab 9
+taz 9
+tm 9
+tru 9
+ttm 9
+ty 9
+tn 9
+tn 9
+ull 9
+usb 9
+vak 9
+vei 9
+vti 9
+vve 9
+vc 9
+yai 9
+yk 9
+yg 9
+zaz 9
+zsg 9
+ztj 9
+zb 9
+zv 9
+zn 9
+ 9
+gh 9
+lh 9
+sh 9
+sn 9
+ig 9
+lv 9
+ni 9
+pk 9
+ps 9
+rl 9
+tr 9
+vv 9
+np 9
+ni 9
+p 9
+tl 9
+rb 9
+vi 9
+z 9
+to 9
+ke 9
+lk 9
+lm 9
+ve 9
+sz 9
+,3 8
+,6 8
+-1 8
+-ne 8
+-t 8
+-n 8
+1-j 8
+17 8
+195 8
+8, 8
+90 8
+97- 8
+99. 8
+Azt 8
+Ban 8
+Do 8
+D 8
+Fel 8
+Ge 8
+Her 8
+H 8
+II 8
+Ig 8
+Kar 8
+Ny 8
+P 8
+Pt 8
+Sa 8
+Sc 8
+Sch 8
+Sv 8
+Sv 8
+To 8
+Un 8
+Uni 8
+Vj 8
+Vja 8
+Vl 8
+Vla 8
+We 8
+Zo 8
+Zso 8
+ace 8
+air 8
+akm 8
+als 8
+alu 8
+al 8
+amp 8
+atv 8
+auk 8
+bbn 8
+bb 8
+bej 8
+bj 8
+bos 8
+bra 8
+bn 8
+ccs 8
+cok 8
+cs 8
+c 8
+di 8
+dje 8
+dk 8
+ds 8
+eak 8
+edz 8
+ed 8
+efi 8
+eho 8
+emj 8
+enf 8
+esn 8
+eth 8
+et 8
+et 8
+fed 8
+fik 8
+fs 8
+gma 8
+gs 8
+gs 8
+gt 8
+gut 8
+gg 8
+gk 8
+g 8
+hav 8
+hz 8
+ici 8
+ier 8
+ikn 8
+imp 8
+ir 8
+j- 8
+jah 8
+jk 8
+js 8
+jl 8
+kiz 8
+kma 8
+koa 8
+kr 8
+ktu 8
+kl 8
+kk 8
+lef 8
+lln 8
+lc 8
+lb 8
+lk 8
+l 8
+m- 8
+mjo 8
+mm 8
+mp 8
+mra 8
+mre 8
+mr 8
+muz 8
+mb 8
+ml 8
+nd 8
+nn 8
+nt 8
+ns 8
+n 8
+oal 8
+ogj 8
+ols 8
+olu 8
+onk 8
+oru 8
+osn 8
+ozs 8
+pei 8
+poz 8
+pun 8
+rfi 8
+rh 8
+rm 8
+rno 8
+rr 8
+rst 8
+rsu 8
+rtn 8
+rtu 8
+rzi 8
+rzs 8
+rb 8
+rv 8
+rk 8
+rv 8
+rg 8
+rt 8
+rk 8
+rr 8
+sd 8
+st 8
+st 8
+sk 8
+sn 8
+st 8
+tf 8
+tny 8
+td 8
+tz 8
+ui 8
+ume 8
+umi 8
+urg 8
+ur 8
+uzs 8
+vk 8
+yin 8
+yke 8
+yk 8
+zk 8
+zse 8
+a 8
+ad 8
+gs 8
+ka 8
+lu 8
+ng 8
+n 8
+c 8
+cs 8
+gg 8
+g 8
+kh 8
+kr 8
+lj 8
+n 8
+tf 8
+vt 8
+zi 8
+mm 8
+gu 8
+rh 8
+s 8
+t 8
+lc 8
+re 8
+z 8
+js 8
+d 8
+lj 8
+f 8
+ol 8
+ 8
+,8 7
+-3 7
+-as 7
+-el 7
+-j 7
+-ka 7
+-ko 7
+-p 7
+00- 7
+00. 7
+100 7
+16 7
+194 7
+22 7
+3- 7
+31 7
+33 7
+7-b 7
+At 7
+B 7
+D- 7
+DP 7
+Dl 7
+Em 7
+GD 7
+GDP 7
+Gal 7
+Gr 7
+Gb 7
+IM 7
+IMF 7
+Il 7
+Je 7
+Jr 7
+Kl 7
+LS 7
+LSZ 7
+Lo 7
+ML 7
+MLS 7
+Mer 7
+O- 7
+Szo 7
+TO- 7
+Tib 7
+Tb 7
+Ug 7
+Zen 7
+adr 7
+ag 7
+aha 7
+ahh 7
+aib 7
+ak 7
+amt 7
+amu 7
+an 7
+an 7
+an 7
+apn 7
+ash 7
+as 7
+bat 7
+bem 7
+bis 7
+bro 7
+bul 7
+bv 7
+cer 7
+chi 7
+cs 7
+cv 7
+dbe 7
+dra 7
+ds 7
+eem 7
+ej 7
+eko 7
+ek 7
+elb 7
+elr 7
+en 7
+ep 7
+er- 7
+esl 7
+et- 7
+ez 7
+e 7
+f 7
+gb 7
+gd 7
+gez 7
+gh 7
+gig 7
+gmu 7
+gor 7
+gse 7
+gvi 7
+gze 7
+gzo 7
+gl 7
+heg 7
+hho 7
+hin 7
+hov 7
+hz 7
+h 7
+ice 7
+idi 7
+iet 7
+iha 7
+ins 7
+isb 7
+iuk 7
+iv 7
+is 7
+jeb 7
+jko 7
+jm 7
+jug 7
+jv 7
+kak 7
+kij 7
+kir 7
+kr 7
+kr 7
+kum 7
+kur 7
+l-k 7
+lac 7
+lk 7
+lly 7
+lob 7
+loz 7
+ltb 7
+ltj 7
+ltu 7
+lv 7
+lb 7
+lj 7
+ln 7
+mec 7
+med 7
+mh 7
+mic 7
+miv 7
+mor 7
+mti 7
+mt 7
+mv 7
+mk 7
+mf 7
+nke 7
+nl 7
+nts 7
+ntu 7
+nv 7
+nyp 7
+nze 7
+nzt 7
+obr 7
+odn 7
+oml 7
+ong 7
+onj 7
+ozd 7
+pb 7
+pko 7
+rav 7
+rci 7
+rco 7
+rmo 7
+rne 7
+rd 7
+rj 7
+rs 7
+rs 7
+sb 7
+sed 7
+sig 7
+sle 7
+soh 7
+sso 7
+sz- 7
+szm 7
+sl 7
+sb 7
+s 7
+tei 7
+tk 7
+tn 7
+tt 7
+tp 7
+tk 7
+tn 7
+tv 7
+ukr 7
+uma 7
+umb 7
+ura 7
+usa 7
+uss 7
+ul 7
+vac 7
+viv 7
+vot 7
+yh 7
+yj 7
+yv 7
+yk 7
+yt 7
+yr 7
+yj 7
+zdt 7
+zd 7
+zim 7
+zum 7
+zn 7
+zd 7
+zi 7
+g 7
+jo 7
+ki 7
+m 7
+nb 7
+rr 7
+ru 7
+r 7
+tj 7
+tm 7
+vi 7
+zn 7
+zu 7
+r 7
+b 7
+gs 7
+kt 7
+pt 7
+tb 7
+tl 7
+g 7
+zi 7
+- 7
+ds 7
+ke 7
+sz 7
+di 7
+g 7
+ki 7
+t 7
+c 7
+d 7
+g 7
+ti 7
+di 7
+ny 7
+rz 7
+v 7
+z 7
+r 7
+f 7
+j 7
+jt 7
+nt 7
+r 7
+-Ko 6
+-or 6
+-ta 6
+-te 6
+.-t 6
+... 6
+15 6
+196 6
+2,5 6
+28 6
+30- 6
+5, 6
+7. 6
+70 6
+75 6
+AI 6
+AID 6
+BE 6
+BES 6
+Bal 6
+Bi 6
+Bor 6
+Br 6
+EB 6
+EBE 6
+ES 6
+ESZ 6
+Fa 6
+Fid 6
+Fr 6
+Ger 6
+Gi 6
+Go 6
+Ham 6
+Hu 6
+ID 6
+IDS 6
+II. 6
+Im 6
+Imr 6
+K- 6
+Kfo 6
+Kra 6
+K 6
+Man 6
+Mit 6
+M 6
+Ol 6
+Ors 6
+PD- 6
+Pa 6
+Pil 6
+Pri 6
+Sim 6
+Sp 6
+S 6
+Tr 6
+Tra 6
+T 6
+Ugy 6
+Vol 6
+V 6
+V 6
+Wa 6
+Wel 6
+Zol 6
+Zsi 6
+aa 6
+abj 6
+ach 6
+adh 6
+ajb 6
+ak- 6
+alh 6
+alj 6
+alp 6
+alv 6
+ano 6
+apb 6
+ar- 6
+arj 6
+ar 6
+ar 6
+ast 6
+ave 6
+avo 6
+b- 6
+bb 6
+bda 6
+bei 6
+bja 6
+bne 6
+bri 6
+bsz 6
+bz 6
+br 6
+bz 6
+bd 6
+chr 6
+ciu 6
+col 6
+cs 6
+cu 6
+daz 6
+dk 6
+ds 6
+duk 6
+dva 6
+dk 6
+dg 6
+ebr 6
+ech 6
+eji 6
+ej 6
+el- 6
+el 6
+el 6
+er 6
+etm 6
+et 6
+feb 6
+fg 6
+fga 6
+fok 6
+f 6
+fg 6
+fb 6
+ft 6
+g- 6
+gb 6
+geg 6
+gei 6
+gho 6
+gm 6
+gne 6
+gro 6
+gva 6
+gy 6
+gb 6
+gi 6
+gt 6
+hib 6
+hne 6
+hr 6
+hm 6
+hs 6
+hs 6
+ica 6
+ifo 6
+igh 6
+ikk 6
+in 6
+iso 6
+ir 6
+jba 6
+jl 6
+jos 6
+jts 6
+jun 6
+jr 6
+jt 6
+kig 6
+kj 6
+kn 6
+kri 6
+kro 6
+kt 6
+l-K 6
+ldt 6
+lie 6
+lim 6
+lki 6
+lmu 6
+ln 6
+lpo 6
+lys 6
+la 6
+ll 6
+mak 6
+mbo 6
+mio 6
+mi 6
+nan 6
+nas 6
+nb 6
+nd 6
+ned 6
+nfo 6
+nkb 6
+nkr 6
+nkt 6
+ntk 6
+nyh 6
+nyr 6
+ny 6
+ns 6
+oba 6
+ock 6
+odu 6
+od 6
+ogn 6
+oj 6
+omp 6
+om 6
+or 6
+ot 6
+ovs 6
+oz 6
+pa- 6
+pap 6
+ph 6
+pna 6
+pr 6
+p 6
+pk 6
+ps 6
+rap 6
+rcb 6
+rd 6
+rl 6
+rn 6
+rp 6
+rs 6
+ru 6
+rza 6
+rb 6
+rf 6
+rd 6
+sot 6
+sp 6
+st 6
+szf 6
+szr 6
+tg 6
+th 6
+tmu 6
+ttj 6
+ttu 6
+tur 6
+tu 6
+tr 6
+tz 6
+td 6
+tn 6
+tr 6
+ukt 6
+uk 6
+uli 6
+una 6
+ust 6
+vir 6
+vok 6
+vre 6
+vb 6
+vr 6
+vt 6
+v 6
+wa 6
+xi 6
+yg 6
+yt 6
+zeb 6
+zez 6
+ze 6
+zfi 6
+zla 6
+zmi 6
+zn 6
+zp 6
+zso 6
+zts 6
+zus 6
+zk 6
+zc 6
+zv 6
+gu 6
+mi 6
+nk 6
+pr 6
+tr 6
+zo 6
+d 6
+gt 6
+lp 6
+ls 6
+r 6
+s 6
+s 6
+to 6
+vs 6
+s 6
+ze 6
+zo 6
+ak 6
+b 6
+dj 6
+dt 6
+fa 6
+g 6
+l 6
+to 6
+vi 6
+v 6
+zs 6
+de 6
+d 6
+nh 6
+nl 6
+rl 6
+r 6
+r 6
+t 6
+k 6
+dz 6
+rg 6
+rk 6
+sp 6
+ 6
+dn 6
+kn 6
+lt 6
+p 6
+fa 6
+s 6
+t 6
+,1 5
+,9 5
+-5 5
+-d 5
+-eg 5
+-fo 5
+-he 5
+-ig 5
+-ke 5
+-os 5
+- 5
+0- 5
+10- 5
+120 5
+198 5
+27 5
+3. 5
+35 5
+4, 5
+500 5
+57 5
+6-o 5
+6- 5
+64 5
+7-e 5
+8. 5
+80- 5
+9, 5
+9-b 5
+9-e 5
+98- 5
+996 5
+Ad 5
+Aki 5
+Ale 5
+Ar 5
+Baj 5
+Ber 5
+Br 5
+Bun 5
+EU- 5
+El 5
+Ers 5
+Far 5
+Fen 5
+Fil 5
+Fo 5
+F 5
+Hav 5
+Hor 5
+Hun 5
+Hy 5
+Iv 5
+Jo 5
+Jz 5
+Kia 5
+Kou 5
+Kt 5
+Laj 5
+Lon 5
+Lu 5
+Mac 5
+Mel 5
+Mic 5
+Mil 5
+Mu 5
+Mg 5
+M 5
+Ni 5
+Oly 5
+Op 5
+Pn 5
+S- 5
+Se 5
+Sok 5
+St 5
+Szt 5
+Sn 5
+Th 5
+Tv 5
+U- 5
+Vag 5
+Van 5
+Y 5
+Z-k 5
+Zem 5
+a-b 5
+abe 5
+ab 5
+add 5
+ad 5
+agg 5
+agi 5
+ahe 5
+ail 5
+aks 5
+al 5
+amh 5
+amj 5
+am 5
+apk 5
+aps 5
+apv 5
+ars 5
+aru 5
+ar 5
+aty 5
+ax 5
+azn 5
+azu 5
+bak 5
+bbr 5
+bb 5
+bea 5
+bec 5
+beh 5
+bir 5
+bot 5
+bum 5
+cal 5
+cio 5
+ck 5
+def 5
+dg 5
+dip 5
+djm 5
+dt 5
+dt 5
+ds 5
+da 5
+dr 5
+eau 5
+ecc 5
+eg 5
+eib 5
+ej 5
+eo 5
+epi 5
+eta 5
+etf 5
+ey 5
+ezv 5
+er 5
+fan 5
+ff 5
+fic 5
+fut 5
+fn 5
+fi 5
+ft 5
+gak 5
+gd 5
+gem 5
+gjo 5
+gmo 5
+gul 5
+gv 5
+gj 5
+g 5
+gr 5
+hai 5
+hek 5
+ht 5
+huz 5
+h 5
+ias 5
+ibu 5
+ieg 5
+ife 5
+ii 5
+ije 5
+ikl 5
+ima 5
+im 5
+in 5
+ior 5
+iri 5
+irt 5
+iv 5
+izm 5
+iv 5
+i 5
+jat 5
+jed 5
+jei 5
+jma 5
+j 5
+kav 5
+keg 5
+kei 5
+kn 5
+kop 5
+kt 5
+ki 5
+kj 5
+kn 5
+ks 5
+ki 5
+lbu 5
+lfe 5
+lge 5
+lj 5
+ll 5
+lod 5
+lse 5
+lt 5
+lul 5
+lj 5
+lz 5
+lr 5
+lr 5
+lt 5
+lh 5
+mam 5
+mh 5
+mi 5
+mj 5
+ml 5
+ml 5
+mna 5
+mul 5
+mc 5
+m 5
+mt 5
+nad 5
+nar 5
+nch 5
+nco 5
+neb 5
+nfr 5
+nf 5
+ng 5
+nij 5
+nit 5
+ni 5
+nja 5
+nju 5
+nj 5
+nla 5
+nme 5
+nst 5
+ntn 5
+ntt 5
+ny- 5
+odt 5
+oe 5
+ofi 5
+ogh 5
+oku 5
+or- 5
+orc 5
+orz 5
+osl 5
+osu 5
+ota 5
+ouc 5
+ozh 5
+p- 5
+pl 5
+ps 5
+pt 5
+p 5
+r-i 5
+raf 5
+rd 5
+reh 5
+rgb 5
+ric 5
+rie 5
+rof 5
+rop 5
+rov 5
+rty 5
+rt 5
+rum 5
+ry 5
+rm 5
+rr 5
+sb 5
+sf 5
+shi 5
+sid 5
+sit 5
+sos 5
+spo 5
+st 5
+sve 5
+szh 5
+sh 5
+sr 5
+sk 5
+sr 5
+tb 5
+tec 5
+tej 5
+tex 5
+tfo 5
+tim 5
+tsa 5
+tuk 5
+tut 5
+tvi 5
+tv 5
+tt 5
+tg 5
+tv 5
+tr 5
+to 5
+uch 5
+udi 5
+ugd 5
+ug 5
+ukb 5
+ulh 5
+ulm 5
+ux 5
+uza 5
+vev 5
+vf 5
+vfo 5
+via 5
+vk 5
+vt 5
+v 5
+vb 5
+y-e 5
+yfo 5
+yga 5
+yot 5
+yte 5
+yb 5
+zas 5
+zei 5
+zic 5
+zit 5
+zky 5
+zme 5
+zmu 5
+zno 5
+zs 5
+zth 5
+ztv 5
+zzo 5
+zj 5
+zi 5
+zm 5
+zk 5
+n 5
+g 5
+gy 5
+j 5
+gt 5
+ig 5
+mu 5
+nj 5
+nn 5
+r- 5
+rp 5
+sf 5
+zs 5
+z 5
+di 5
+gl 5
+lo 5
+lr 5
+pn 5
+rb 5
+sn 5
+s 5
+t 5
+vf 5
+vr 5
+z 5
+l 5
+ne 5
+n 5
+ra 5
+rj 5
+sz 5
+vo 5
+c 5
+gi 5
+it 5
+l 5
+nk 5
+d 5
+kv 5
+nm 5
+ns 5
+tv 5
+zz 5
+cs 5
+di 5
+r 5
+th 5
+tv 5
+lb 5
+lv 5
+re 5
+te 5
+- 5
+dj 5
+dt 5
+h 5
+ip 5
+j 5
+n 5
+zs 5
+z 5
+le 5
+,25 4
+,4 4
+,5- 4
+,7 4
+-2 4
+-30 4
+-M 4
+-eu 4
+-g 4
+-ip 4
+-re 4
+-s 4
+0, 4
+0-a 4
+0-b 4
+02 4
+1,5 4
+1-b 4
+1-e 4
+180 4
+2-b 4
+23 4
+29 4
+3,5 4
+300 4
+43 4
+45 4
+47 4
+55 4
+6, 4
+7, 4
+91 4
+92- 4
+93 4
+96- 4
+991 4
+994 4
+Akk 4
+Bat 4
+Bel 4
+Bro 4
+Bn 4
+Bc 4
+Ca 4
+Cor 4
+DSZ 4
+Di 4
+Ele 4
+Emi 4
+Ezt 4
+Ezz 4
+FB 4
+Fej 4
+Fio 4
+Fra 4
+F 4
+FK 4
+G- 4
+Gro 4
+Gyu 4
+Has 4
+Hi 4
+Hol 4
+Hyu 4
+Id 4
+Ik 4
+Ika 4
+Int 4
+Iva 4
+Jel 4
+Jug 4
+Kam 4
+Kap 4
+Kel 4
+Ker 4
+Kis 4
+Kre 4
+Ku 4
+K 4
+Kr 4
+Lig 4
+Lis 4
+MFB 4
+Nag 4
+Nap 4
+Naw 4
+Nyu 4
+Ope 4
+Ora 4
+Per 4
+Por 4
+Poz 4
+Rad 4
+Rob 4
+Ra 4
+SZD 4
+Szl 4
+Sz 4
+Sz 4
+Tam 4
+Tan 4
+Tar 4
+Tha 4
+VG- 4
+Ves 4
+ZD 4
+ZDS 4
+Za 4
+acb 4
+ack 4
+ael 4
+afg 4
+agn 4
+ags 4
+agt 4
+ah 4
+ajk 4
+aju 4
+akh 4
+amn 4
+am 4
+arg 4
+arz 4
+as 4
+as 4
+at 4
+aus 4
+aw 4
+awa 4
+axi 4
+ay 4
+azs 4
+az 4
+a 4
+bez 4
+bik 4
+bli 4
+bl 4
+bny 4
+bs 4
+bt 4
+bk 4
+bt 4
+b 4
+cke 4
+cl 4
+cla 4
+cot 4
+cs- 4
+cve 4
+d- 4
+df 4
+dib 4
+dj 4
+dl 4
+dse 4
+dtu 4
+dur 4
+dz 4
+dv 4
+dj 4
+dz 4
+dj 4
+dl 4
+ead 4
+ean 4
+edj 4
+ed 4
+elc 4
+em 4
+erl 4
+et 4
+eum 4
+evo 4
+ezs 4
+fag 4
+fat 4
+fj 4
+f 4
+fr 4
+gb 4
+gc 4
+gf 4
+gg 4
+ghe 4
+ghi 4
+gh 4
+git 4
+gka 4
+gk 4
+glo 4
+gme 4
+gs 4
+gti 4
+gto 4
+gtu 4
+gt 4
+gu 4
+gyj 4
+gy 4
+gzi 4
+gl 4
+hen 4
+hni 4
+hs 4
+hul 4
+hum 4
+hr 4
+ht 4
+id 4
+ifj 4
+igm 4
+ihi 4
+ilk 4
+ime 4
+ipl 4
+isi 4
+is 4
+itj 4
+itm 4
+it 4
+ivo 4
+iza 4
+izi 4
+ib 4
+ii 4
+iz 4
+jaz 4
+jda 4
+jh 4
+jj 4
+jzf 4
+js 4
+jk 4
+kah 4
+kep 4
+kf 4
+kl 4
+kp 4
+kpa 4
+kso 4
+kt 4
+kvi 4
+kc 4
+kv 4
+k 4
+lau 4
+lca 4
+led 4
+le 4
+le 4
+lgy 4
+lk 4
+ll 4
+lny 4
+ln 4
+lt 4
+lum 4
+lut 4
+lvo 4
+lyf 4
+ly 4
+lz 4
+l 4
+li 4
+lt 4
+lk 4
+le 4
+lf 4
+ll 4
+lv 4
+mac 4
+mib 4
+mid 4
+mle 4
+mlo 4
+mod 4
+muk 4
+mv 4
+mi 4
+mg 4
+nay 4
+nbs 4
+ncz 4
+ndh 4
+nea 4
+nei 4
+nen 4
+ngb 4
+ngj 4
+ngt 4
+nho 4
+niv 4
+niz 4
+nji 4
+nkn 4
+nku 4
+nl 4
+nma 4
+nre 4
+nt- 4
+nuk 4
+nun 4
+nva 4
+nyj 4
+ny 4
+nzb 4
+nzu 4
+nz 4
+nt 4
+nk 4
+n 4
+ode 4
+on 4
+oor 4
+opj 4
+opt 4
+osv 4
+ote 4
+ovo 4
+pak 4
+pba 4
+pez 4
+phe 4
+pig 4
+plo 4
+pl 4
+pni 4
+ps 4
+pti 4
+pb 4
+rae 4
+rau 4
+raz 4
+rg 4
+rid 4
+ri 4
+rk 4
+rli 4
+rn 4
+rn 4
+rri 4
+rr 4
+rtb 4
+rtt 4
+ra 4
+rt 4
+rg 4
+rk 4
+rs 4
+sar 4
+sch 4
+sef 4
+she 4
+sk 4
+spa 4
+sr 4
+sr 4
+stu 4
+sf 4
+sj 4
+sn 4
+st 4
+sd 4
+t-e 4
+tc 4
+tc 4
+td 4
+tez 4
+tif 4
+tiv 4
+tka 4
+tl 4
+tr 4
+ttb 4
+tt 4
+tvo 4
+tm 4
+td 4
+ucc 4
+ud 4
+ukk 4
+ulc 4
+upa 4
+use 4
+utn 4
+uty 4
+uv 4
+veh 4
+vg 4
+vh 4
+vri 4
+vu 4
+vg 4
+vr 4
+vz 4
+v 4
+xis 4
+yat 4
+yau 4
+yb 4
+yc 4
+yeb 4
+yim 4
+yja 4
+yny 4
+ypa 4
+yp 4
+yun 4
+yj 4
+yl 4
+zah 4
+zev 4
+zf 4
+zia 4
+zl 4
+zm 4
+zsd 4
+zsu 4
+zsz 4
+zs 4
+zt 4
+zt 4
+zul 4
+zup 4
+zur 4
+zz 4
+zr 4
+zk 4
+zu 4
+zb 4
+ze 4
+zs 4
+zt 4
+zn 4
+K 4
+K- 4
+r 4
+l 4
+p 4
+r 4
+bl 4
+f 4
+gn 4
+j- 4
+kb 4
+kk 4
+l 4
+ns 4
+r 4
+r 4
+tk 4
+zh 4
+zm 4
+ 4
+r 4
+je 4
+j 4
+kl 4
+k 4
+lh 4
+lz 4
+rg 4
+rh 4
+rm 4
+sk 4
+tt 4
+zt 4
+zz 4
+ 4
+r 4
+k 4
+m 4
+n 4
+p 4
+bu 4
+ho 4
+kk 4
+kr 4
+k 4
+lt 4
+l 4
+mu 4
+zk 4
+zt 4
+zu 4
+g 4
+kn 4
+ks 4
+l 4
+l 4
+t 4
+u 4
+ul 4
+zh 4
+zs 4
+f 4
+fo 4
+jj 4
+ls 4
+lz 4
+tj 4
+ls 4
+ne 4
+r 4
+t 4
+zl 4
+fo 4
+g 4
+ir 4
+po 4
+r 4
+te 4
+e 4
+t 4
+z 4
+-0 3
+-B 3
+-D 3
+-H 3
+-c 3
+-d 3
+-fe 3
+-f 3
+-ho 3
+-k 3
+-k 3
+-me 3
+-m 3
+-m 3
+-pa 3
+-ve 3
+-v 3
+0-1 3
+0-3 3
+0-e 3
+0-r 3
+002 3
+02- 3
+07 3
+1,1 3
+1- 3
+1. 3
+10. 3
+110 3
+14. 3
+19- 3
+2,2 3
+2,6 3
+2-e 3
+20- 3
+21 3
+24 3
+25- 3
+26 3
+31- 3
+32 3
+34 3
+350 3
+37 3
+39 3
+4-5 3
+4-b 3
+4-e 3
+48 3
+49 3
+5-3 3
+5-b 3
+5- 3
+5. 3
+50- 3
+59 3
+600 3
+69 3
+7,2 3
+79 3
+8,2 3
+8-a 3
+8-b 3
+8-i 3
+85 3
+86 3
+91- 3
+92. 3
+94- 3
+964 3
+97. 3
+993 3
+Af 3
+Aka 3
+Ama 3
+Any 3
+Att 3
+Au 3
+Bab 3
+Bad 3
+Bib 3
+Bl 3
+Bla 3
+Bon 3
+Boz 3
+Bra 3
+Car 3
+Ch 3
+Csi 3
+D-t 3
+DF 3
+Don 3
+Dr 3
+Eb- 3
+Ebb 3
+Ec 3
+Ed 3
+Ei 3
+Eic 3
+Ell 3
+Elm 3
+Erz 3
+Es 3
+F- 3
+For 3
+Fl 3
+F 3
+G-n 3
+GB 3
+Gl 3
+G 3
+Gd 3
+Han 3
+His 3
+H 3
+Hr 3
+H 3
+Hb 3
+IK 3
+Iga 3
+Ily 3
+Isk 3
+Jan 3
+Jar 3
+KG 3
+KGB 3
+Kal 3
+Kat 3
+Kea 3
+Kh 3
+Kie 3
+Kim 3
+Kla 3
+Kli 3
+Kok 3
+Kn 3
+Leg 3
+Lib 3
+MD 3
+MDF 3
+MT 3
+MU 3
+Mak 3
+Mal 3
+Mas 3
+Mez 3
+Miu 3
+Miv 3
+Moz 3
+Ms 3
+M 3
+Mz 3
+Ms 3
+Nis 3
+No 3
+Om 3
+Om 3
+Pel 3
+Pir 3
+Pol 3
+Pre 3
+Pu 3
+Pr 3
+Pz 3
+Q 3
+Rei 3
+Rez 3
+Ri 3
+Ric 3
+Ru 3
+Rk 3
+SA 3
+SZK 3
+Saa 3
+Spa 3
+Sz 3
+TK 3
+Tav 3
+Teg 3
+Ter 3
+Tie 3
+Tor 3
+Tui 3
+T 3
+Tn 3
+Tk 3
+Tz 3
+U-t 3
+Veg 3
+Vil 3
+Vc 3
+V 3
+Vr 3
+Wi 3
+Wo 3
+X 3
+Z-n 3
+ZK 3
+a, 3
+aar 3
+abs 3
+adu 3
+afe 3
+ag- 3
+age 3
+ag 3
+aim 3
+aiv 3
+aje 3
+ajr 3
+ak 3
+al- 3
+ams 3
+anj 3
+an 3
+asu 3
+as 3
+at- 3
+aud 3
+aux 3
+avu 3
+a 3
+a 3
+ag 3
+b-c 3
+bb 3
+bd 3
+biu 3
+bna 3
+boc 3
+bog 3
+bom 3
+br 3
+bt 3
+bta 3
+bl 3
+bn 3
+cad 3
+cbe 3
+cca 3
+ceg 3
+ces 3
+cik 3
+cin 3
+cr 3
+csb 3
+csr 3
+cs 3
+cva 3
+cze 3
+dba 3
+dda 3
+dea 3
+dfo 3
+dg 3
+dia 3
+dil 3
+dim 3
+dis 3
+djo 3
+dj 3
+dog 3
+dov 3
+dro 3
+dug 3
+dup 3
+dus 3
+db 3
+db 3
+dz 3
+dz 3
+dg 3
+dn 3
+d 3
+eai 3
+eav 3
+edb 3
+egp 3
+egz 3
+ehs 3
+eiv 3
+ej 3
+ekh 3
+ekm 3
+ek 3
+enj 3
+ero 3
+ery 3
+er 3
+es 3
+etu 3
+eva 3
+evi 3
+ev 3
+ev 3
+ews 3
+eye 3
+eb 3
+e 3
+er 3
+fak 3
+feh 3
+fir 3
+fi 3
+fj 3
+fos 3
+fri 3
+fj 3
+fk 3
+fk 3
+fj 3
+fh 3
+fo 3
+fz 3
+gab 3
+gam 3
+gcs 3
+gfi 3
+gi 3
+gi 3
+gpr 3
+gr 3
+gur 3
+gyf 3
+gz 3
+gz 3
+gd 3
+gj 3
+gv 3
+gk 3
+gs 3
+gn 3
+gs 3
+hev 3
+hih 3
+hm 3
+hsz 3
+ht. 3
+hb 3
+hf 3
+hz 3
+iah 3
+ian 3
+ib 3
+ien 3
+ies 3
+igo 3
+iho 3
+ija 3
+ijt 3
+ikv 3
+imo 3
+inn 3
+ipo 3
+irg 3
+irk 3
+is- 3
+isa 3
+isc 3
+isn 3
+isv 3
+is 3
+itr 3
+itu 3
+it 3
+iuc 3
+if 3
+ih 3
+i 3
+ir 3
+jal 3
+jci 3
+jek 3
+jf 3
+jho 3
+jip 3
+jja 3
+jli 3
+jna 3
+jn 3
+jsz 3
+jth 3
+jt 3
+jv 3
+jb 3
+jv 3
+jk 3
+k-k 3
+kau 3
+ka 3
+kef 3
+kic 3
+ki 3
+kli 3
+klu 3
+kl 3
+kl 3
+ktr 3
+kv 3
+kd 3
+km 3
+kv 3
+km 3
+kd 3
+k 3
+ko 3
+lar 3
+lcv 3
+ldg 3
+lec 3
+lex 3
+le 3
+lgr 3
+lho 3
+lh 3
+lh 3
+lia 3
+ljo 3
+lj 3
+llh 3
+lm- 3
+lpa 3
+lt 3
+lt 3
+lud 3
+lvt 3
+lv 3
+lyg 3
+lyk 3
+lyv 3
+ly 3
+lze 3
+lzo 3
+lz 3
+lg 3
+lp 3
+mbi 3
+mei 3
+mey 3
+mie 3
+mif 3
+mja 3
+mk 3
+mpi 3
+mp 3
+mta 3
+mv 3
+mz 3
+ncv 3
+ndv 3
+ngu 3
+nir 3
+nje 3
+nkc 3
+nol 3
+nri 3
+ntb 3
+nt 3
+nt 3
+nt 3
+nvo 3
+nyc 3
+nyg 3
+ny 3
+nz 3
+nz 3
+nk 3
+ns 3
+nr 3
+nl 3
+o- 3
+obi 3
+ob 3
+of 3
+ogv 3
+oke 3
+ok 3
+ole 3
+olf 3
+olk 3
+om- 3
+omr 3
+om 3
+onm 3
+onr 3
+on 3
+oo- 3
+opp 3
+orj 3
+os- 3
+ose 3
+os 3
+otj 3
+our 3
+p-s 3
+pac 3
+pit 3
+pi 3
+pje 3
+pka 3
+pl 3
+pov 3
+pr 3
+puc 3
+pul 3
+pve 3
+pr 3
+pk 3
+q 3
+qu 3
+r-e 3
+r-k 3
+r-o 3
+r-v 3
+rch 3
+rdt 3
+re 3
+rfe 3
+rj 3
+rk 3
+rmi 3
+rpe 3
+rro 3
+rsi 3
+rsv 3
+run 3
+rut 3
+rvg 3
+rz 3
+rm 3
+r- 3
+ri 3
+rz 3
+rj 3
+rg 3
+rk 3
+rt 3
+scs 3
+sd 3
+sep 3
+sev 3
+sic 3
+sie 3
+sil 3
+sim 3
+sip 3
+siv 3
+ski 3
+sni 3
+sof 3
+sr 3
+ssu 3
+sug 3
+szj 3
+sl 3
+sb 3
+sn 3
+sd 3
+sc 3
+sj 3
+t-K 3
+tax 3
+teb 3
+tgy 3
+tid 3
+tio 3
+tj 3
+tso 3
+tto 3
+tya 3
+tyi 3
+tyj 3
+tz 3
+tg 3
+tp 3
+tm 3
+tz 3
+ua 3
+ubi 3
+ubl 3
+uca 3
+udh 3
+udv 3
+uis 3
+ukn 3
+ulo 3
+umr 3
+um 3
+upl 3
+ure 3
+urt 3
+urv 3
+us- 3
+us 3
+us 3
+v- 3
+vgy 3
+vig 3
+vul 3
+vv 3
+vb 3
+vr 3
+vj 3
+ws 3
+y-t 3
+yab 3
+yb 3
+ycs 3
+yfa 3
+yho 3
+yh 3
+yki 3
+yla 3
+yme 3
+yn 3
+yr 3
+yr 3
+ys 3
+yzi 3
+yz 3
+ys 3
+yl 3
+yn 3
+yk 3
+yl 3
+yr 3
+zau 3
+zb 3
+zdu 3
+zec 3
+zeh 3
+zeu 3
+zj 3
+zki 3
+zn 3
+zog 3
+zst 3
+zsv 3
+zug 3
+zuk 3
+zj 3
+zr 3
+zg 3
+zg 3
+lt 3
+m 3
+r 3
+sz 3
+n 3
+bi 3
+cl 3
+gm 3
+g 3
+kr 3
+lg 3
+ml 3
+nu 3
+po 3
+rz 3
+tf 3
+ti 3
+ty 3
+n 3
+do 3
+d 3
+gh 3
+js 3
+j 3
+j 3
+k- 3
+kn 3
+lg 3
+lm 3
+ma 3
+na 3
+nh 3
+n 3
+p- 3
+p 3
+sh 3
+tk 3
+v 3
+zv 3
+z 3
+li 3
+mv 3
+ni 3
+pu 3
+rn 3
+ru 3
+rv 3
+vj 3
+vt 3
+cs 3
+d 3
+ha 3
+ip 3
+ky 3
+m 3
+pi 3
+po 3
+re 3
+r 3
+zo 3
+z 3
+ 3
+r 3
+dn 3
+ge 3
+k- 3
+nf 3
+nz 3
+n 3
+p 3
+sv 3
+v 3
+za 3
+zn 3
+zo 3
+zr 3
+jd 3
+lv 3
+l 3
+s 3
+tk 3
+tl 3
+ts 3
+ze 3
+z 3
+b 3
+bn 3
+h 3
+ll 3
+t 3
+fe 3
+ga 3
+ha 3
+he 3
+in 3
+is 3
+m 3
+m 3
+rj 3
+rr 3
+r 3
+r 3
+s 3
+ti 3
+tl 3
+t 3
+v 3
+zn 3
+ki 3
+nb 3
+ni 3
+n 3
+' 2
+,37 2
+-10 2
+-12 2
+-4 2
+-6 2
+-7 2
+-Ba 2
+-C 2
+-G 2
+-Ka 2
+-Ki 2
+-K 2
+-Ma 2
+-T 2
+-T 2
+-bo 2
+-b 2
+-de 2
+-ei 2
+-em 2
+-er 2
+-f 2
+-g 2
+-je 2
+-ku 2
+-n 2
+-po 2
+-ra 2
+-r 2
+-r 2
+-t 2
+-t 2
+-t 2
+-u 2
+-vi 2
+-v 2
+-i 2
+-r 2
+-t 2
+-z 2
+-i 2
+-r 2
+.-b 2
+.-v 2
+0-i 2
+007 2
+05 2
+07- 2
+1,8 2
+10, 2
+105 2
+11, 2
+130 2
+150 2
+16- 2
+160 2
+17- 2
+18- 2
+19. 2
+190 2
+192 2
+197 2
+2-n 2
+21- 2
+220 2
+24. 2
+26- 2
+28. 2
+29- 2
+3,6 2
+3-0 2
+31. 2
+32, 2
+33. 2
+38 2
+4,2 2
+4,5 2
+4-r 2
+400 2
+41 2
+42 2
+44 2
+48- 2
+5,3 2
+5- 2
+51 2
+56 2
+58 2
+59- 2
+6,3 2
+6-b 2
+61 2
+61, 2
+64- 2
+65 2
+68 2
+7-i 2
+7-t 2
+71 2
+72 2
+77 2
+8,5 2
+8-r 2
+8- 2
+800 2
+81 2
+84 2
+860 2
+9-1 2
+9- 2
+90- 2
+947 2
+948 2
+949 2
+95- 2
+950 2
+957 2
+959 2
+969 2
+98. 2
+99- 2
+990 2
+995 2
+AP 2
+APE 2
+Ada 2
+Afg 2
+Alb 2
+Alk 2
+Ani 2
+Ank 2
+Ara 2
+Ata 2
+Av 2
+Az 2
+B- 2
+BL 2
+Bak 2
+Beh 2
+Biz 2
+Bod 2
+Bos 2
+Bre 2
+Br 2
+Bur 2
+Bc 2
+B 2
+CD 2
+Ce 2
+Chi 2
+Con 2
+Cso 2
+DF- 2
+DS- 2
+Dag 2
+Dar 2
+Dem 2
+Dis 2
+Dn 2
+Dny 2
+Dob 2
+Dz 2
+Dzu 2
+EF 2
+EFA 2
+EH 2
+EH- 2
+Eco 2
+Eg 2
+Ek 2
+Ek 2
+Elh 2
+Els 2
+Enr 2
+Erc 2
+Err 2
+Et 2
+FA 2
+FI 2
+FIK 2
+F 2
+F 2
+Fr 2
+Gam 2
+Gim 2
+Gio 2
+Gir 2
+Gla 2
+Gn 2
+Gnj 2
+God 2
+Goe 2
+Gu 2
+Gy 2
+Gn 2
+G 2
+H- 2
+H-e 2
+HI 2
+HIV 2
+Haj 2
+Hat 2
+Hel 2
+Hon 2
+Hot 2
+H 2
+HV 2
+Hr 2
+Ht 2
+Hz 2
+H 2
+III 2
+IS 2
+IV 2
+IV- 2
+Ide 2
+Id 2
+Ige 2
+Igo 2
+Ild 2
+Ind 2
+Ing 2
+Ir 2
+Isz 2
+Iz 2
+Izm 2
+Jac 2
+Jag 2
+Jam 2
+Jos 2
+Jud 2
+Jus 2
+Jl 2
+J 2
+Jv 2
+J 2
+K-o 2
+Kan 2
+Kau 2
+Kaz 2
+Kht 2
+Kir 2
+Kj 2
+Kn 2
+Koh 2
+Kol 2
+Kom 2
+Kri 2
+Kul 2
+Kup 2
+Kr 2
+K 2
+Lab 2
+Lak 2
+Las 2
+Leh 2
+Lek 2
+Lem 2
+Len 2
+Lou 2
+L 2
+MTK 2
+Mai 2
+Men 2
+Mih 2
+Mi 2
+Mol 2
+Mom 2
+Mun 2
+M 2
+MV 2
+Mt 2
+M 2
+Ml 2
+Mv 2
+Nek 2
+Nyi 2
+Np 2
+N 2
+Nv 2
+O-e 2
+O-t 2
+Ok 2
+Okt 2
+Orv 2
+Os 2
+PE 2
+PEH 2
+PO 2
+PT 2
+PTF 2
+Pes 2
+Pie 2
+Pon 2
+Pos 2
+Pra 2
+Pro 2
+Put 2
+QI 2
+RTS 2
+Rab 2
+Raj 2
+Ran 2
+Ruh 2
+Rb 2
+R 2
+Rg 2
+R 2
+S-b 2
+SPO 2
+Sad 2
+Sen 2
+Si 2
+Sk 2
+Sko 2
+Sor 2
+Spo 2
+Ste 2
+St 2
+Szi 2
+Sz 2
+S 2
+St 2
+TF 2
+TS 2
+Tel 2
+Tet 2
+Tis 2
+Tup 2
+T 2
+Tr 2
+UE 2
+UEF 2
+US 2
+USA 2
+Uk 2
+Ukr 2
+Ut 2
+V- 2
+V-v 2
+VI 2
+VII 2
+Vat 2
+Vid 2
+Voo 2
+Vu 2
+Vl 2
+Vg 2
+Wal 2
+Was 2
+Wes 2
+Wh 2
+Whi 2
+Wil 2
+Wor 2
+W 2
+Wr 2
+XV 2
+XVI 2
+Yb 2
+Ybl 2
+Yo 2
+Z-e 2
+Z-f 2
+Zor 2
+a-m 2
+a-t 2
+aad 2
+abh 2
+abl 2
+abr 2
+abu 2
+adb 2
+ade 2
+adl 2
+aer 2
+aes 2
+aff 2
+afr 2
+agb 2
+agr 2
+agv 2
+aif 2
+aih 2
+aj- 2
+aja 2
+ajh 2
+aji 2
+ajj 2
+ajm 2
+ajv 2
+akb 2
+akj 2
+akp 2
+alc 2
+amm 2
+amr 2
+anr 2
+ap 2
+are 2
+asd 2
+asi 2
+asn 2
+asr 2
+ats 2
+atu 2
+at 2
+at 2
+avr 2
+avt 2
+av 2
+ay- 2
+azf 2
+azk 2
+al 2
+a 2
+an 2
+bbl 2
+beg 2
+beo 2
+bh 2
+bh 2
+bic 2
+bie 2
+bit 2
+bi 2
+bla 2
+ble 2
+blo 2
+bm 2
+bm 2
+bni 2
+bob 2
+bod 2
+bre 2
+br 2
+bso 2
+buk 2
+bj 2
+bc 2
+bc 2
+bz 2
+bl 2
+can 2
+cat 2
+cet 2
+cig 2
+cip 2
+cir 2
+civ 2
+cks 2
+cn 2
+cos 2
+cr 2
+csl 2
+czi 2
+cb 2
+cr 2
+dam 2
+dex 2
+dic 2
+die 2
+dir 2
+div 2
+dle 2
+dmo 2
+dob 2
+dr 2
+dua 2
+dum 2
+dze 2
+dt 2
+d- 2
+dd 2
+dh 2
+dt 2
+dl 2
+d 2
+dg 2
+dh 2
+di 2
+dp 2
+dv 2
+dz 2
+e-a 2
+eal 2
+ebi 2
+eci 2
+eck 2
+edf 2
+eeg 2
+een 2
+eer 2
+efa 2
+ef 2
+eg 2
+eg 2
+eg 2
+ehh 2
+eh 2
+eic 2
+eis 2
+eka 2
+ekc 2
+elp 2
+elu 2
+el 2
+el 2
+emk 2
+ems 2
+emu 2
+em 2
+en- 2
+enh 2
+en 2
+epa 2
+eph 2
+eps 2
+erf 2
+es- 2
+esa 2
+esf 2
+esh 2
+evr 2
+ev 2
+ewi 2
+exa 2
+exk 2
+ext 2
+ezb 2
+en 2
+ep 2
+ffe 2
+ffi 2
+fi- 2
+fid 2
+fie 2
+fi 2
+fi 2
+fli 2
+fro 2
+fur 2
+fus 2
+fr 2
+fv 2
+fp 2
+g! 2
+g-i 2
+gap 2
+gib 2
+gik 2
+giu 2
+gj 2
+gkr 2
+gli 2
+gl 2
+gno 2
+gn 2
+god 2
+gov 2
+gs 2
+gt 2
+gug 2
+gy 2
+gza 2
+gz 2
+gd 2
+gh 2
+g- 2
+gr 2
+gj 2
+hac 2
+hhe 2
+hie 2
+hil 2
+hl 2
+hom 2
+hrg 2
+hus 2
+hg 2
+hd 2
+ht 2
+hl 2
+hv 2
+h 2
+hl 2
+h 2
+ia- 2
+iav 2
+ibi 2
+idr 2
+idu 2
+idz 2
+iej 2
+iew 2
+iff 2
+if 2
+if 2
+igr 2
+igu 2
+ij 2
+iki 2
+ikr 2
+ik 2
+imn 2
+imu 2
+in- 2
+inj 2
+inr 2
+inv 2
+iov 2
+ipr 2
+ip 2
+ip 2
+iq 2
+iqu 2
+irc 2
+irr 2
+iru 2
+ir 2
+itb 2
+its 2
+ity 2
+it 2
+it 2
+it 2
+iv 2
+i 2
+id 2
+im 2
+in 2
+ik 2
+j-s 2
+jag 2
+jak 2
+jap 2
+jas 2
+jb 2
+jcb 2
+jdn 2
+jev 2
+jfa 2
+jil 2
+jje 2
+jov 2
+jt 2
+jud 2
+juh 2
+jza 2
+jzi 2
+js 2
+j 2
+j 2
+jt 2
+jr 2
+jt 2
+jl 2
+k-K 2
+k-h 2
+kae 2
+keb 2
+kfu 2
+kha 2
+kh 2
+ki- 2
+kib 2
+kii 2
+ki 2
+kja 2
+kje 2
+kk- 2
+kk 2
+kla 2
+km 2
+km 2
+kny 2
+kr 2
+kr 2
+ksa 2
+kti 2
+kt 2
+kt 2
+kud 2
+kun 2
+kve 2
+kv 2
+kk 2
+kb 2
+lah 2
+lai 2
+lbo 2
+lb 2
+lci 2
+lcz 2
+ldu 2
+lee 2
+lfi 2
+li- 2
+lir 2
+lku 2
+llj 2
+lm 2
+lm 2
+lno 2
+lor 2
+lpe 2
+lpr 2
+lra 2
+lr 2
+lso 2
+ls 2
+ltt 2
+lvh 2
+lyp 2
+ly 2
+lz 2
+lz 2
+lk 2
+ld 2
+ll 2
+lz 2
+lj 2
+ln 2
+l- 2
+l 2
+maf 2
+mb 2
+mem 2
+mfi 2
+mih 2
+mla 2
+mm 2
+mne 2
+mn 2
+mpa 2
+mpu 2
+mr 2
+ms 2
+mte 2
+mp 2
+mn 2
+mh 2
+n-k 2
+n-m 2
+nac 2
+naz 2
+nbu 2
+nb 2
+ncu 2
+nc 2
+ndb 2
+nd 2
+ney 2
+nfa 2
+nf 2
+ngl 2
+ng 2
+nim 2
+ni 2
+njo 2
+nkf 2
+nkk 2
+nks 2
+nk 2
+nk 2
+nm 2
+nnh 2
+noj 2
+not 2
+noz 2
+np 2
+nra 2
+nso 2
+nsv 2
+ns 2
+ntg 2
+nt 2
+nvi 2
+ny 2
+nz- 2
+nza 2
+nzn 2
+nzo 2
+nz 2
+nz 2
+n 2
+nm 2
+ns 2
+nz 2
+nt 2
+nj 2
+nt 2
+ne 2
+o- 2
+obe 2
+obs 2
+ods 2
+oeb 2
+oge 2
+ogg 2
+ogs 2
+ogt 2
+ohl 2
+ojk 2
+okj 2
+okl 2
+ol- 2
+ome 2
+omf 2
+omt 2
+om 2
+one 2
+onh 2
+on 2
+oon 2
+opu 2
+orh 2
+osk 2
+osm 2
+os 2
+otb 2
+oti 2
+oui 2
+ox 2
+oxi 2
+pb 2
+pin 2
+pk 2
+pla 2
+pm 2
+pm 2
+pne 2
+pr 2
+pub 2
+puk 2
+put 2
+pc 2
+pp 2
+pt 2
+pc 2
+pj 2
+p 2
+pr 2
+que 2
+r-f 2
+r. 2
+ra 2
+rbo 2
+rbr 2
+rb 2
+rb 2
+rdd 2
+rdi 2
+rdr 2
+rd 2
+rd 2
+rec 2
+rfo 2
+rg- 2
+rgu 2
+rg 2
+rho 2
+rib 2
+rim 2
+riq 2
+rjo 2
+rj 2
+rld 2
+rl 2
+rnj 2
+roc 2
+roh 2
+rsm 2
+rs 2
+rt- 2
+rtm 2
+rtv 2
+rt 2
+rvb 2
+rvh 2
+rvi 2
+rzo 2
+rzu 2
+rz 2
+rf 2
+rv 2
+rl 2
+rp 2
+rz 2
+rg 2
+rn 2
+rz 2
+rn 2
+rz 2
+rc 2
+rs 2
+rf 2
+ri 2
+rz 2
+rb 2
+re 2
+rl 2
+s-K 2
+s-c 2
+s-f 2
+s-k 2
+s-t 2
+sb 2
+sb 2
+see 2
+sej 2
+sfe 2
+sfo 2
+sha 2
+sia 2
+sib 2
+sir 2
+si 2
+sj 2
+sku 2
+sky 2
+sl 2
+sl 2
+smi 2
+sm 2
+sn 2
+sn 2
+sov 2
+spe 2
+stm 2
+sto 2
+st 2
+sum 2
+sva 2
+sv 2
+sz 2
+sf 2
+st 2
+ss 2
+sp 2
+sr 2
+t, 2
+t- 2
+tad 2
+tbi 2
+tb 2
+tb 2
+tda 2
+ted 2
+tee 2
+tfe 2
+tf 2
+tge 2
+tic 2
+tie 2
+tig 2
+ti 2
+tju 2
+tki 2
+tmi 2
+tox 2
+tri 2
+tr 2
+tss 2
+ttn 2
+tt 2
+tuc 2
+tug 2
+tye 2
+tz 2
+td 2
+tc 2
+tt 2
+t- 2
+tb 2
+th 2
+tt 2
+ual 2
+ubo 2
+ucr 2
+ud 2
+ue 2
+uf 2
+ugg 2
+ugr 2
+ugt 2
+ug 2
+uha 2
+uhr 2
+uin 2
+ukh 2
+ulb 2
+ulj 2
+umn 2
+umt 2
+upe 2
+upo 2
+upr 2
+urk 2
+uru 2
+usr 2
+uth 2
+uva 2
+uxe 2
+vaj 2
+vha 2
+vhe 2
+vih 2
+vin 2
+vja 2
+vj 2
+vk 2
+vn 2
+vsk 2
+vte 2
+vm 2
+vh 2
+vt 2
+vv 2
+vr 2
+vr 2
+vi 2
+was 2
+wi 2
+wsk 2
+x- 2
+xa 2
+xan 2
+xe 2
+xem 2
+xik 2
+xk 2
+xko 2
+xt 2
+y-d 2
+y-k 2
+yb 2
+yem 2
+yep 2
+yfi 2
+yh 2
+yid 2
+yie 2
+yij 2
+yip 2
+yn 2
+yog 2
+yra 2
+yv- 2
+yzo 2
+yv 2
+z-M 2
+z-t 2
+zae 2
+zam 2
+zap 2
+zar 2
+za 2
+zc 2
+zdo 2
+zd 2
+zef 2
+zej 2
+zew 2
+zex 2
+zg 2
+zhi 2
+zho 2
+zib 2
+zio 2
+ziu 2
+zi 2
+zja 2
+zk 2
+zsa 2
+zsk 2
+ztg 2
+zty 2
+zt 2
+zut 2
+zb 2
+zh 2
+za 2
+zb 2
+zf 2
+zh 2
+zn 2
+zd 2
+zl 2
+P 2
+PT 2
+V 2
+V 2
+l 2
+pp 2
+p 2
+rt 2
+nk 2
+s 2
+st 2
+be 2
+da 2
+db 2
+dl 2
+dn 2
+d 2
+g! 2
+gy 2
+g 2
+g 2
+im 2
+jd 2
+j 2
+lm 2
+mb 2
+mr 2
+mt 2
+mv 2
+n- 2
+np 2
+nv 2
+pa 2
+rf 2
+s- 2
+sm 2
+sp 2
+sv 2
+t 2
+ve 2
+v 2
+v 2
+v 2
+zz 2
+p 2
+ba 2
+br 2
+db 2
+dj 2
+dt 2
+gc 2
+gk 2
+gp 2
+ja 2
+kp 2
+ks 2
+kv 2
+k 2
+lb 2
+lu 2
+l 2
+l 2
+nk 2
+nn 2
+n 2
+pc 2
+ph 2
+pi 2
+pm 2
+rj 2
+t, 2
+ta 2
+ti 2
+tn 2
+tv 2
+zb 2
+zh 2
+zn 2
+d 2
+f 2
+fe 2
+jb 2
+nf 2
+nm 2
+n 2
+rh 2
+ri 2
+rs 2
+r 2
+va 2
+v 2
+v 2
+z- 2
+zb 2
+du 2
+e 2
+fi 2
+fo 2
+f 2
+he 2
+hi 2
+ia 2
+je 2
+kb 2
+kh 2
+ku 2
+k 2
+lv 2
+ma 2
+mi 2
+ro 2
+ru 2
+r 2
+sa 2
+z 2
+bm 2
+dt 2
+gn 2
+gz 2
+kr 2
+ll 2
+nd 2
+p- 2
+ri 2
+rm 2
+rr 2
+tl 2
+b 2
+ci 2
+g 2
+jf 2
+ju 2
+j 2
+j 2
+r 2
+si 2
+tm 2
+tn 2
+v 2
+v 2
+zn 2
+zt 2
+c 2
+ck 2
+h 2
+kb 2
+kh 2
+ki 2
+p 2
+pp 2
+sz 2
+tk 2
+v 2
+ve 2
+-h 2
+-p 2
+bi 2
+b 2
+ib 2
+it 2
+j 2
+ka 2
+kb 2
+n 2
+or 2
+pr 2
+r- 2
+sr 2
+s 2
+v 2
+zh 2
+zm 2
+b 2
+bb 2
+ek 2
+en 2
+h 2
+lt 2
+l 2
+nc 2
+n 2
+r 2
+te 2
+z 2
+!- 1
+!-g 1
+"- 1
+"-n 1
+"J 1
+"J 1
+"P 1
+"Pr 1
+'9 1
+'99 1
+(i 1
+(i) 1
++ 1
++3 1
+,12 1
+,19 1
+,33 1
+,4- 1
+,45 1
+,64 1
+,8- 1
+,9- 1
+,93 1
+-1, 1
+-14 1
+-15 1
+-22 1
+-23 1
+-3, 1
+-40 1
+-5- 1
+-50 1
+-8 1
+-80 1
+-9 1
+-96 1
+-A 1
+-Am 1
+-Br 1
+-Co 1
+-Cs 1
+-Da 1
+-De 1
+-Di 1
+-E 1
+-Eu 1
+-F 1
+-Fi 1
+-Gi 1
+-Gy 1
+-He 1
+-Hi 1
+-Ho 1
+-K 1
+-MP 1
+-MT 1
+-P 1
+-Pr 1
+-W 1
+-W 1
+-Z 1
+-Ze 1
+-ab 1
+-ai 1
+-al 1
+-am 1
+-au 1
+-bi 1
+-b 1
+-fr 1
+-ga 1
+-gy 1
+-hi 1
+-h 1
+-h 1
+-id 1
+-il 1
+-jo 1
+-j 1
+-j 1
+-ki 1
+-k 1
+-k 1
+-l 1
+-le 1
+-ma 1
+-m 1
+-na 1
+-n 1
+-od 1
+-pi 1
+-ps 1
+-ro 1
+-r 1
+-se 1
+-ti 1
+-tu 1
+-t 1
+-uk 1
+-ut 1
+-z 1
+-ze 1
+-t 1
+-t 1
+- 1
+-g 1
+.-j 1
+.-n 1
+.j 1
+.j 1
+0" 1
+0"- 1
+0,1 1
+0,5 1
+0,7 1
+0,8 1
+0-2 1
+0-4 1
+0-5 1
+0-8 1
+0-s 1
+0-t 1
+0- 1
+0.- 1
+00" 1
+001 1
+003 1
+01 1
+01- 1
+02, 1
+03 1
+04 1
+1,2 1
+1,3 1
+1,4 1
+1,7 1
+1,9 1
+1-1 1
+1-i 1
+1-t 1
+102 1
+104 1
+107 1
+112 1
+12, 1
+12- 1
+12. 1
+13- 1
+13. 1
+134 1
+135 1
+139 1
+14, 1
+140 1
+147 1
+15- 1
+16+ 1
+164 1
+17. 1
+170 1
+171 1
+175 1
+188 1
+19, 1
+2,3 1
+2,4 1
+2,9 1
+2-0 1
+2-2 1
+2-3 1
+2-6 1
+2-r 1
+2-t 1
+2- 1
+20, 1
+20. 1
+214 1
+22, 1
+22- 1
+23, 1
+23- 1
+24- 1
+25. 1
+27- 1
+270 1
+279 1
+28, 1
+28- 1
+280 1
+29. 1
+2K 1
+3,3 1
+3,4 1
+3,7 1
+3,9 1
+3-2 1
+3-4 1
+3-5 1
+3-a 1
+3- 1
+311 1
+330 1
+338 1
+35, 1
+35- 1
+36 1
+38, 1
+39. 1
+396 1
+4,1 1
+4-1 1
+4-9 1
+4-f 1
+4- 1
+40. 1
+413 1
+42, 1
+430 1
+434 1
+44, 1
+44. 1
+450 1
+46 1
+47, 1
+47- 1
+47. 1
+485 1
+49- 1
+49. 1
+5,5 1
+5,6 1
+5,7 1
+5,8 1
+5-1 1
+5-2 1
+5-6 1
+5-7 1
+5-e 1
+5-i 1
+52 1
+52. 1
+53 1
+53, 1
+55- 1
+553 1
+56- 1
+57- 1
+6+ 1
+6+3 1
+6,6 1
+6,8 1
+6-7 1
+6-a 1
+6. 1
+60. 1
+62 1
+66 1
+660 1
+67 1
+67- 1
+68. 1
+69- 1
+7,8 1
+7- 1
+70- 1
+700 1
+71, 1
+73 1
+76 1
+76, 1
+77. 1
+79- 1
+8,3 1
+8,6 1
+8,9 1
+8-t 1
+81- 1
+82 1
+84- 1
+84. 1
+85, 1
+85. 1
+87 1
+88 1
+880 1
+89 1
+9,2 1
+9,4 1
+9,5 1
+9,8 1
+9,9 1
+9-d 1
+9.j 1
+90. 1
+900 1
+925 1
+927 1
+93- 1
+93. 1
+94. 1
+944 1
+955 1
+96. 1
+967 1
+970 1
+973 1
+979 1
+980 1
+981 1
+984 1
+989 1
+AG 1
+AS 1
+AS- 1
+AW 1
+AWS 1
+Ab 1
+Abo 1
+Add 1
+Adi 1
+Ado 1
+Afr 1
+Ah 1
+Ahm 1
+Akc 1
+Ako 1
+Aks 1
+Akt 1
+Alf 1
+All 1
+Alm 1
+Alt 1
+Amb 1
+Ame 1
+Am 1
+Ant 1
+Arb 1
+Aro 1
+Arr 1
+As 1
+Asz 1
+Ate 1
+Atr 1
+Aud 1
+Aus 1
+Aut 1
+Avr 1
+Avt 1
+Aze 1
+Azz 1
+B-s 1
+B- 1
+BL- 1
+BM 1
+BMW 1
+BS 1
+BS- 1
+Ba 1
+Bef 1
+Ben 1
+Bil 1
+Bok 1
+Bol 1
+Bom 1
+Bp 1
+Bp. 1
+Brd 1
+Bk 1
+Bl 1
+Br 1
+B 1
+Br 1
+B 1
+Br 1
+B 1
+Bl 1
+Bh 1
+Bv 1
+CB 1
+CD- 1
+CK 1
+CT 1
+CTK 1
+Cam 1
+Cen 1
+Ces 1
+Che 1
+Ci 1
+Cig 1
+Col 1
+Coo 1
+Cos 1
+Cot 1
+D-h 1
+D-m 1
+D-n 1
+D-s 1
+DP- 1
+Dan 1
+Dat 1
+Dau 1
+Den 1
+Dep 1
+Der 1
+Die 1
+Dj 1
+Dji 1
+Dol 1
+Dom 1
+Dor 1
+Dr. 1
+Dra 1
+Dru 1
+D 1
+Dn 1
+Dn 1
+D 1
+Dn 1
+Ea 1
+Eas 1
+Ece 1
+Edd 1
+Edg 1
+Edu 1
+Elk 1
+Elu 1
+Elv 1
+El 1
+Emb 1
+Eme 1
+Eml 1
+End 1
+Ene 1
+Eng 1
+Eny 1
+Ere 1
+Ern 1
+Ero 1
+Er 1
+Ess 1
+Est 1
+Esz 1
+Eti 1
+Ett 1
+Ez 1
+E 1
+Er 1
+F-F 1
+F-e 1
+F-n 1
+FO 1
+FOR 1
+Fal 1
+Fig 1
+Fir 1
+Fiu 1
+Fj 1
+Fjo 1
+Fod 1
+Fok 1
+Fre 1
+Fri 1
+Fu 1
+Ful 1
+Fl 1
+Fs 1
+Fg 1
+Fr 1
+Fb 1
+Fi 1
+Fv 1
+G-t 1
+GB- 1
+Gaa 1
+Gab 1
+Gel 1
+Gen 1
+Glo 1
+Gog 1
+Gon 1
+Gra 1
+Gr 1
+Gr 1
+Gug 1
+Gur 1
+Gy 1
+Gy 1
+Gp 1
+Gz 1
+G 1
+Gn 1
+G 1
+Gz 1
+HVM 1
+Hab 1
+Hac 1
+Had 1
+Hah 1
+Haz 1
+Heg 1
+Hei 1
+Hen 1
+Hep 1
+Hic 1
+Hit 1
+Hoe 1
+Hog 1
+Hom 1
+Hos 1
+Hov 1
+Hoz 1
+Hus 1
+Hya 1
+Hg 1
+Hn 1
+Hj 1
+Ht 1
+H 1
+Hs 1
+I- 1
+I- 1
+IK- 1
+ISE 1
+ISM 1
+Igy 1
+Ili 1
+Ilj 1
+Inf 1
+Inv 1
+Ip 1
+Ipa 1
+Iro 1
+Ir 1
+It 1
+Itt 1
+Ive 1
+Jee 1
+Jer 1
+Jev 1
+Joa 1
+Jog 1
+Joh 1
+Jun 1
+Jur 1
+Jut 1
+Juv 1
+Jl 1
+Jn 1
+J 1
+Jr 1
+K-b 1
+K-p 1
+K-r 1
+K-t 1
+KF 1
+KFO 1
+KH 1
+KHV 1
+Kab 1
+Kas 1
+Kav 1
+Kec 1
+Ked 1
+Kem 1
+Kev 1
+Khu 1
+Kic 1
+Kij 1
+Kil 1
+Kiv 1
+Kiz 1
+Kje 1
+Kju 1
+Kno 1
+Knu 1
+Kob 1
+Kod 1
+Kop 1
+Ks 1
+K 1
+Ks 1
+Kd 1
+Kl 1
+Kh 1
+Kz 1
+L- 1
+L-b 1
+L. 1
+Lad 1
+Laf 1
+Lap 1
+Lel 1
+Lep 1
+Les 1
+Lew 1
+Lip 1
+Liv 1
+Lp 1
+Lpu 1
+Lt 1
+Ltd 1
+Luc 1
+Lui 1
+Luj 1
+Lut 1
+Lux 1
+Ln 1
+Lt 1
+Lk 1
+Lt 1
+M0 1
+M0- 1
+M1 1
+M1- 1
+MI 1
+MIK 1
+MP 1
+MPP 1
+MS 1
+MSZ 1
+MTA 1
+MW 1
+MZ 1
+MZE 1
+Mab 1
+Mad 1
+Mah 1
+Maj 1
+Mat 1
+Maz 1
+Mec 1
+Mek 1
+Mie 1
+Mir 1
+Mis 1
+Moh 1
+Mon 1
+Moo 1
+Mor 1
+Mov 1
+Mr 1
+Mro 1
+Mul 1
+Mum 1
+Mus 1
+Md 1
+Mt 1
+M 1
+Mg 1
+M 1
+Mn 1
+NB 1
+NB- 1
+NM 1
+NMI 1
+Nac 1
+Nas 1
+Neh 1
+Nev 1
+New 1
+Nic 1
+Nik 1
+Nob 1
+Noh 1
+Nor 1
+Ny 1
+Ny 1
+N 1
+Nd 1
+Ng 1
+O-b 1
+O-h 1
+O-o 1
+OR 1
+OR- 1
+Od 1
+Oda 1
+Ol 1
+On 1
+Oni 1
+Opt 1
+Ore 1
+Orw 1
+Osk 1
+Oss 1
+Ot 1
+Ott 1
+P- 1
+P-t 1
+PN 1
+PNB 1
+PP 1
+Pac 1
+Paj 1
+Pak 1
+Pal 1
+Par 1
+Paz 1
+Pf 1
+Pfe 1
+Ph 1
+Phi 1
+Pik 1
+Pit 1
+Pof 1
+Pr 1
+Ps 1
+Psz 1
+Pul 1
+Pk 1
+Pl 1
+Pl 1
+P 1
+Pd 1
+QI- 1
+Qu 1
+Qua 1
+R- 1
+R-g 1
+RH 1
+Rea 1
+Red 1
+Reg 1
+Rek 1
+Rem 1
+Ren 1
+Rep 1
+Res 1
+Reu 1
+Rev 1
+Rod 1
+Rog 1
+Roh 1
+Rom 1
+Ros 1
+Rus 1
+Rd 1
+Rj 1
+Rm 1
+R 1
+Rz 1
+Rb 1
+Rv 1
+S-e 1
+S-s 1
+S-t 1
+SAS 1
+SE 1
+SM 1
+SS 1
+SS- 1
+SZP 1
+SZT 1
+Sah 1
+Sak 1
+Sam 1
+Sea 1
+Seo 1
+Ser 1
+Sie 1
+Sir 1
+Soh 1
+Som 1
+Sop 1
+Spi 1
+Str 1
+Sy 1
+Sys 1
+Szm 1
+Szu 1
+Sz 1
+Sz 1
+Sz 1
+Sr 1
+S 1
+Sl 1
+TA 1
+TF- 1
+Tab 1
+Tap 1
+Tat 1
+Tes 1
+Tev 1
+The 1
+Tim 1
+Tod 1
+Tol 1
+Ton 1
+Top 1
+Tov 1
+T 1
+TR 1
+T 1
+Tr 1
+Tm 1
+Tt 1
+T 1
+Tz 1
+U-c 1
+U-n 1
+UC 1
+UCK 1
+UM 1
+UMZ 1
+UN 1
+UNM 1
+UR 1
+URH 1
+Ue 1
+Uec 1
+Uga 1
+Ur 1
+Uru 1
+Uta 1
+Uto 1
+VM 1
+Vaj 1
+Var 1
+Vas 1
+Vec 1
+Vek 1
+Vel 1
+Vez 1
+Voc 1
+Vuk 1
+Vr 1
+Vd 1
+Vk 1
+Vl 1
+Vr 1
+V 1
+Vz 1
+WS 1
+Wag 1
+Wat 1
+Wie 1
+Wol 1
+XI 1
+XII 1
+Y2 1
+Y2K 1
+Yol 1
+Yor 1
+Z-c 1
+ZE 1
+ZK- 1
+ZP 1
+ZT 1
+ZT 1
+Zac 1
+Zal 1
+Zap 1
+Zav 1
+Zef 1
+Zei 1
+Zet 1
+Zsa 1
+Zy 1
+Zyc 1
+a-B 1
+a-G 1
+a-H 1
+a-T 1
+a-c 1
+a-d 1
+a-h 1
+a-p 1
+a- 1
+aal 1
+abn 1
+abt 1
+acg 1
+acv 1
+ac 1
+ac 1
+ad- 1
+adf 1
+adg 1
+adm 1
+ad 1
+ad 1
+aeg 1
+aek 1
+afi 1
+afo 1
+afu 1
+af 1
+af 1
+agd 1
+agh 1
+agk 1
+agl 1
+agm 1
+agz 1
+ah 1
+ah 1
+ai- 1
+aid 1
+aig 1
+ais 1
+ai 1
+ajc 1
+ajf 1
+aj 1
+ald 1
+alf 1
+alr 1
+aml 1
+amv 1
+am 1
+am 1
+am 1
+anv 1
+anz 1
+ao 1
+aot 1
+apd 1
+aph 1
+apz 1
+ap 1
+ap 1
+aq 1
+aqu 1
+arn 1
+ary 1
+ar 1
+as- 1
+asb 1
+ase 1
+asf 1
+ask 1
+atf 1
+atg 1
+atp 1
+atz 1
+at 1
+at 1
+aul 1
+aur 1
+auz 1
+avs 1
+avy 1
+av 1
+ax 1
+aze 1
+azl 1
+al 1
+an 1
+ar 1
+an 1
+ar 1
+a 1
+at 1
+a 1
+ad 1
+b-n 1
+b-u 1
+bac 1
+bae 1
+bag 1
+bah 1
+bai 1
+bam 1
+bas 1
+bav 1
+baz 1
+bb- 1
+bbf 1
+bbj 1
+bbk 1
+bbt 1
+bb 1
+bb 1
+bch 1
+be- 1
+beb 1
+bee 1
+bf 1
+bfo 1
+bi- 1
+bib 1
+big 1
+bju 1
+bj 1
+bk 1
+bl- 1
+boj 1
+bou 1
+bsb 1
+buc 1
+buf 1
+bun 1
+by 1
+bz 1
+bz 1
+bb 1
+bc 1
+bm 1
+bv 1
+bv 1
+bc 1
+bk 1
+bn 1
+bz 1
+bl 1
+br 1
+br 1
+bv 1
+cak 1
+cas 1
+cce 1
+cd 1
+cde 1
+ce" 1
+ce- 1
+ceW 1
+cea 1
+cev 1
+cg 1
+cga 1
+chb 1
+cho 1
+cht 1
+chu 1
+ch 1
+cid 1
+cie 1
+cif 1
+cim 1
+ci 1
+cka 1
+ckb 1
+ckl 1
+ck 1
+cna 1
+cni 1
+com 1
+cop 1
+cp 1
+cpe 1
+cre 1
+csf 1
+csj 1
+css 1
+csz 1
+cs 1
+cs 1
+cud 1
+cuk 1
+cul 1
+cum 1
+cun 1
+cur 1
+czo 1
+czy 1
+cf 1
+ck 1
+cn 1
+ct 1
+cz 1
+d-B 1
+d-c 1
+d-f 1
+d. 1
+dab 1
+dac 1
+dah 1
+daj 1
+dav 1
+db 1
+db 1
+dd 1
+de- 1
+ded 1
+deh 1
+deo 1
+de 1
+dfe 1
+dga 1
+dgo 1
+did 1
+dif 1
+dii 1
+diu 1
+dji 1
+dju 1
+dk 1
+dlo 1
+dm 1
+dm 1
+dny 1
+dn 1
+dn 1
+dn 1
+doh 1
+dp 1
+dpe 1
+dr. 1
+dri 1
+dr 1
+dr 1
+dr 1
+ds 1
+dts 1
+dt 1
+dt 1
+dun 1
+duu 1
+duv 1
+dv 1
+dv 1
+dv 1
+dy 1
+dh 1
+di 1
+dv 1
+dz 1
+dd 1
+di 1
+dr 1
+dz 1
+db 1
+dc 1
+df 1
+di 1
+dv 1
+dk 1
+dm 1
+dr 1
+dk 1
+de 1
+dh 1
+dt 1
+de 1
+dr 1
+ds 1
+e" 1
+e-C 1
+e-e 1
+e-i 1
+e-k 1
+e-l 1
+e-o 1
+e-t 1
+eW 1
+eWa 1
+eag 1
+eat 1
+eaz 1
+eba 1
+eb 1
+eb 1
+eco 1
+ecz 1
+ec 1
+eds 1
+edu 1
+ed 1
+ee- 1
+eel 1
+eep 1
+eet 1
+efl 1
+efn 1
+ef 1
+egc 1
+egd 1
+eg 1
+eh- 1
+ehg 1
+ehm 1
+eh 1
+ei- 1
+eid 1
+eif 1
+eih 1
+eim 1
+ej- 1
+ejj 1
+ejo 1
+ek- 1
+ekd 1
+eku 1
+ek 1
+em- 1
+emf 1
+emh 1
+emn 1
+em 1
+em 1
+eno 1
+en 1
+eol 1
+eos 1
+eot 1
+eou 1
+eoz 1
+epj 1
+epo 1
+er 1
+esc 1
+esg 1
+esr 1
+esv 1
+es 1
+ety 1
+eud 1
+eut 1
+ev- 1
+evg 1
+evj 1
+ev 1
+ex- 1
+exu 1
+ey- 1
+ez- 1
+ezf 1
+ezk 1
+ezo 1
+ez 1
+ek 1
+et 1
+fa- 1
+fae 1
+far 1
+fei 1
+ffo 1
+fii 1
+fis 1
+fit 1
+fj. 1
+fle 1
+fn 1
+fne 1
+foz 1
+fr 1
+fuk 1
+fun 1
+fuv 1
+fy 1
+fb 1
+fr 1
+ft 1
+fz 1
+fm 1
+fb 1
+fk 1
+fn 1
+fz 1
+fr 1
+fl 1
+fa 1
+fg 1
+fl 1
+fm 1
+fu 1
+f 1
+f 1
+f 1
+g!- 1
+g-k 1
+g-t 1
+g- 1
+ga- 1
+gbi 1
+gb 1
+gc 1
+gdo 1
+gdu 1
+ge- 1
+gej 1
+gf 1
+gg 1
+gg 1
+ghr 1
+ghs 1
+ght 1
+gh 1
+gid 1
+gie 1
+gio 1
+gip 1
+gki 1
+gko 1
+gku 1
+gk 1
+glu 1
+gl 1
+gl 1
+gl 1
+gni 1
+gn 1
+gom 1
+gop 1
+gpe 1
+gp 1
+gri 1
+gr 1
+gsi 1
+gso 1
+gsp 1
+gst 1
+gum 1
+gun 1
+gvo 1
+gv 1
+gyp 1
+gyu 1
+gzs 1
+gz 1
+gh 1
+gv 1
+gg 1
+gk 1
+g 1
+gb 1
+gc 1
+gh 1
+gs 1
+gk 1
+gl 1
+gm 1
+gr 1
+gn 1
+gb 1
+gd 1
+gr 1
+gz 1
+h- 1
+h-s 1
+ha- 1
+hab 1
+hb 1
+hb 1
+hed 1
+hei 1
+hg 1
+hgj 1
+hip 1
+hll 1
+hma 1
+hme 1
+hnn 1
+hno 1
+hoc 1
+hod 1
+hok 1
+hot 1
+hou 1
+hra 1
+htj 1
+hur 1
+hk 1
+hs 1
+h 1
+hu 1
+hn 1
+hs 1
+ha 1
+hc 1
+hz 1
+hd 1
+ht 1
+hf 1
+hl 1
+ht 1
+i) 1
+i-c 1
+i-f 1
+i-j 1
+i-k 1
+i-s 1
+i-t 1
+i-v 1
+i- 1
+iag 1
+iam 1
+iar 1
+ia 1
+ibb 1
+ibc 1
+ibl 1
+ib 1
+icc 1
+ick 1
+icn 1
+ico 1
+icu 1
+icz 1
+idt 1
+id 1
+ieb 1
+ifu 1
+if 1
+ih 1
+iim 1
+iin 1
+iip 1
+iir 1
+iiz 1
+ijn 1
+iju 1
+ik- 1
+ikb 1
+iks 1
+ild 1
+ilh 1
+il 1
+il 1
+imb 1
+imr 1
+im 1
+inh 1
+iog 1
+iol 1
+ipn 1
+ipp 1
+ips 1
+ipu 1
+irb 1
+irs 1
+isg 1
+ish 1
+isp 1
+isu 1
+itf 1
+itv 1
+it 1
+it 1
+it 1
+ivb 1
+ivk 1
+iv 1
+iy 1
+iye 1
+izd 1
+izg 1
+izn 1
+izr 1
+izu 1
+izz 1
+ik 1
+il 1
+ip 1
+i 1
+ir 1
+ia 1
+i 1
+ig 1
+ii 1
+ik 1
+j-C 1
+j-b 1
+j-c 1
+j. 1
+ja- 1
+jam 1
+jb 1
+jc 1
+jdu 1
+jd 1
+je- 1
+jer 1
+jfu 1
+jha 1
+jic 1
+jim 1
+jin 1
+jiv 1
+jj 1
+jkh 1
+jl 1
+jl 1
+jme 1
+jmi 1
+jne 1
+jod 1
+jor 1
+jou 1
+jr 1
+jso 1
+jtj 1
+jtv 1
+jub 1
+jul 1
+juz 1
+jve 1
+jvi 1
+jv 1
+jzo 1
+jzs 1
+jh 1
+jz 1
+jh 1
+ji 1
+jj 1
+jj 1
+js 1
+jt 1
+jg 1
+k-Z 1
+k-b 1
+k-c 1
+k-f 1
+k-i 1
+k-j 1
+k-n 1
+k-s 1
+k-v 1
+ka- 1
+kaa 1
+kag 1
+kao 1
+kce 1
+kcs 1
+kd 1
+kda 1
+ke- 1
+kfe 1
+kft 1
+kg 1
+kga 1
+kht 1
+khu 1
+kh 1
+kio 1
+kiu 1
+ki 1
+ki 1
+kju 1
+kj 1
+kkc 1
+kks 1
+kk 1
+kl- 1
+kl 1
+koh 1
+koo 1
+ksu 1
+kts 1
+kup 1
+kuv 1
+kyt 1
+ko 1
+k 1
+kh 1
+km 1
+kc 1
+kj 1
+kk 1
+km 1
+kp 1
+kz 1
+kt 1
+kn 1
+ks 1
+kd 1
+kl 1
+l-A 1
+l-P 1
+l-a 1
+l-b 1
+l-c 1
+l-d 1
+l-g 1
+l-h 1
+l-i 1
+l-j 1
+l-m 1
+l-p 1
+l-s 1
+l- 1
+la, 1
+la- 1
+lax 1
+laz 1
+la 1
+lbr 1
+lb 1
+lb 1
+lb 1
+ld- 1
+ldd 1
+ldj 1
+ldm 1
+ldv 1
+ld 1
+ld 1
+le- 1
+lea 1
+leu 1
+lfa 1
+lfr 1
+lfu 1
+lf 1
+lgu 1
+lg 1
+lhi 1
+lh 1
+lij 1
+lip 1
+liy 1
+ljh 1
+lk 1
+ll- 1
+llk 1
+llu 1
+lmb 1
+lmj 1
+lms 1
+lmv 1
+lnb 1
+lp 1
+lr 1
+lsi 1
+lss 1
+lth 1
+ltn 1
+lur 1
+lus 1
+lux 1
+lvb 1
+ly( 1
+lyu 1
+lza 1
+li 1
+lj 1
+lz 1
+lv 1
+le 1
+lh 1
+lp 1
+lt 1
+lm 1
+lp 1
+le 1
+lz 1
+m-D 1
+m-f 1
+m-r 1
+m-t 1
+mbn 1
+mbr 1
+mb 1
+mb 1
+mb 1
+mce 1
+md 1
+mdo 1
+meh 1
+mf 1
+mhi 1
+mho 1
+mij 1
+miz 1
+mi 1
+mje 1
+mj 1
+mke 1
+mki 1
+mk 1
+mli 1
+mmt 1
+mob 1
+moc 1
+mou 1
+mpe 1
+mpr 1
+mp 1
+mr 1
+mse 1
+msu 1
+mtu 1
+mt 1
+mt 1
+mud 1
+mum 1
+md 1
+mh 1
+mm 1
+mz 1
+md 1
+mv 1
+mr 1
+mv 1
+mn 1
+mg 1
+mk 1
+mv 1
+mp 1
+mr 1
+n-W 1
+n-e 1
+n-s 1
+n-v 1
+n- 1
+na, 1
+naf 1
+nbo 1
+nb 1
+nb 1
+ncc 1
+ncp 1
+ncr 1
+ndf 1
+ndm 1
+new 1
+nez 1
+ngi 1
+ngr 1
+ngv 1
+ng 1
+nha 1
+nhi 1
+nh 1
+nid 1
+nii 1
+nip 1
+nkj 1
+nkv 1
+nk 1
+nlj 1
+nl 1
+nn- 1
+nnf 1
+nnl 1
+noc 1
+non 1
+nr 1
+nr 1
+ns- 1
+nsc 1
+nse 1
+nsk 1
+nsu 1
+ns 1
+ns 1
+ntv 1
+nty 1
+nt 1
+nuf 1
+num 1
+nut 1
+nyd 1
+nym 1
+nzk 1
+nzm 1
+nzr 1
+nz 1
+nz 1
+nz 1
+nd 1
+nj 1
+nb 1
+ni 1
+nj 1
+nc 1
+na 1
+nd 1
+nh 1
+nj 1
+nn 1
+nt 1
+nn 1
+nz 1
+nt 1
+n- 1
+ni 1
+nn 1
+o-m 1
+oan 1
+obn 1
+obt 1
+obu 1
+obz 1
+ocd 1
+och 1
+odm 1
+odp 1
+odv 1
+ody 1
+odz 1
+oem 1
+oet 1
+oex 1
+ofe 1
+ofo 1
+ogf 1
+ogu 1
+og 1
+og 1
+ohi 1
+ohn 1
+oho 1
+oh 1
+oi 1
+ois 1
+oje 1
+ojj 1
+oj 1
+ok- 1
+ok 1
+ok 1
+olb 1
+ol 1
+ol 1
+omc 1
+omd 1
+omj 1
+on 1
+on 1
+ook 1
+oop 1
+oov 1
+oo 1
+opa 1
+opc 1
+oph 1
+opi 1
+opy 1
+op 1
+ork 1
+osc 1
+osh 1
+osp 1
+otr 1
+ot 1
+ot 1
+oug 1
+oul 1
+ous 1
+ovn 1
+ovv 1
+ov 1
+oze 1
+ozm 1
+ozu 1
+o 1
+or 1
+o 1
+oh 1
+p-E 1
+p-k 1
+p. 1
+paj 1
+pbe 1
+pci 1
+pd 1
+pd 1
+pea 1
+pec 1
+peh 1
+pg 1
+pgy 1
+pha 1
+phi 1
+pic 1
+pie 1
+pih 1
+pik 1
+pip 1
+pis 1
+piu 1
+pjo 1
+pj 1
+pk 1
+pk 1
+ple 1
+pn 1
+poc 1
+poe 1
+pom 1
+pop 1
+ppo 1
+pre 1
+psi 1
+pso 1
+ps 1
+pt 1
+puh 1
+pv 1
+py 1
+pyr 1
+pz 1
+pz 1
+pz 1
+pd 1
+pm 1
+pv 1
+pb 1
+pr 1
+ps 1
+pi 1
+qui 1
+r-B 1
+r-H 1
+r-M 1
+r-h 1
+r-m 1
+r-r 1
+r-u 1
+ra- 1
+rax 1
+ra 1
+ra 1
+rb 1
+rb 1
+rck 1
+rcn 1
+rcz 1
+rc 1
+rd- 1
+rdj 1
+rdn 1
+rds 1
+rd 1
+reb 1
+reu 1
+rfa 1
+rfy 1
+rf 1
+rgh 1
+rg 1
+rg 1
+rhi 1
+rhu 1
+rif 1
+rij 1
+rio 1
+rir 1
+rju 1
+rk- 1
+rkk 1
+rk 1
+rmj 1
+rml 1
+rn- 1
+rns 1
+rn 1
+roj 1
+roo 1
+rou 1
+rpa 1
+rp 1
+rp 1
+rr- 1
+rru 1
+rr 1
+rsf 1
+rsp 1
+rtd 1
+rtf 1
+rtk 1
+rts 1
+rt 1
+rt 1
+ruc 1
+rug 1
+rvs 1
+rvu 1
+rw 1
+rwe 1
+ryb 1
+rzb 1
+rz 1
+ri 1
+rn 1
+ra 1
+rd 1
+rv 1
+r 1
+rl 1
+rt 1
+rb 1
+rl 1
+rr 1
+rn 1
+ra 1
+rb 1
+rh 1
+rn 1
+rv 1
+r 1
+rt 1
+rz 1
+s-D 1
+s-H 1
+s-e 1
+s-i 1
+s-m 1
+s-p 1
+s-z 1
+s- 1
+sav 1
+sbl 1
+sbo 1
+sbu 1
+sb 1
+scu 1
+sc 1
+sda 1
+sde 1
+sdi 1
+se- 1
+sea 1
+ses 1
+sf 1
+sga 1
+sge 1
+sh 1
+sij 1
+sis 1
+si 1
+sje 1
+sj 1
+sk 1
+sob 1
+spi 1
+sp 1
+sp 1
+ss 1
+ss 1
+stb 1
+stj 1
+stt 1
+sty 1
+st 1
+sub 1
+sus 1
+sut 1
+svi 1
+sv 1
+szb 1
+szc 1
+szd 1
+sz 1
+s 1
+sj 1
+sp 1
+s 1
+se 1
+sk 1
+sn 1
+so 1
+sp 1
+sh 1
+si 1
+sk 1
+ss 1
+st 1
+sg 1
+sz 1
+sh 1
+sk 1
+sn 1
+t-D 1
+t-G 1
+t-M 1
+t-T 1
+t-b 1
+t-f 1
+t-h 1
+t-n 1
+t-s 1
+ta- 1
+tb- 1
+tbo 1
+tbu 1
+td. 1
+td 1
+tfa 1
+tfi 1
+tga 1
+th 1
+tib 1
+tih 1
+tip 1
+tir 1
+ti 1
+tjo 1
+tli 1
+tl 1
+tl 1
+tmo 1
+tm 1
+tno 1
+tn 1
+tob 1
+toe 1
+tof 1
+toh 1
+toi 1
+toj 1
+to 1
+tp 1
+tpo 1
+tr 1
+tsc 1
+tsd 1
+tsu 1
+ttk 1
+ttl 1
+tui 1
+typ 1
+ty 1
+tc 1
+td 1
+th 1
+th 1
+tl 1
+tr 1
+tc 1
+te 1
+tf 1
+th 1
+to 1
+t 1
+tj 1
+tg 1
+tm 1
+t 1
+tk 1
+tr 1
+uar 1
+ubb 1
+ubr 1
+ub 1
+uck 1
+uco 1
+ud- 1
+ude 1
+ufa 1
+uff 1
+ugh 1
+ugl 1
+ugs 1
+uho 1
+uj 1
+ujz 1
+uki 1
+uko 1
+uk 1
+uk 1
+uld 1
+ulf 1
+uls 1
+ul 1
+um- 1
+umm 1
+ump 1
+ums 1
+um 1
+unb 1
+uno 1
+unt 1
+un 1
+un 1
+urb 1
+urd 1
+urn 1
+urr 1
+ush 1
+usk 1
+usn 1
+usu 1
+us 1
+ute 1
+uti 1
+utj 1
+utv 1
+utz 1
+uu 1
+uum 1
+uve 1
+uv 1
+ux- 1
+uze 1
+v-f 1
+vad 1
+vb- 1
+vba 1
+vb 1
+vec 1
+vge 1
+vie 1
+vio 1
+vip 1
+vi 1
+vki 1
+vko 1
+vk 1
+vl 1
+vla 1
+vna 1
+vni 1
+voj 1
+vra 1
+vru 1
+vr 1
+vso 1
+vto 1
+vtu 1
+vuk 1
+vva 1
+vvi 1
+vy 1
+vh 1
+vz 1
+v 1
+vs 1
+vz 1
+vk 1
+vp 1
+vs 1
+vt 1
+wa- 1
+we 1
+wel 1
+wh 1
+whi 1
+wic 1
+wis 1
+wsp 1
+x-h 1
+x-t 1
+xte 1
+xti 1
+xu 1
+xu 1
+x 1
+xc 1
+y( 1
+y(i 1
+y-a 1
+y-f 1
+ya, 1
+yac 1
+yaf 1
+yap 1
+yav 1
+ybi 1
+yb 1
+yci 1
+yd 1
+yde 1
+yec 1
+yf 1
+yg 1
+yh 1
+yi- 1
+yia 1
+yib 1
+yig 1
+yih 1
+yiv 1
+yl 1
+ymo 1
+ym 1
+yni 1
+yn 1
+yod 1
+ypo 1
+ypr 1
+yps 1
+yri 1
+yso 1
+yst 1
+ys 1
+yto 1
+yt 1
+yuk 1
+yur 1
+yva 1
+yvb 1
+yvi 1
+yvk 1
+yvo 1
+yvr 1
+yvt 1
+yvv 1
+yv 1
+yv 1
+yz 1
+yz 1
+yg 1
+yi 1
+ym 1
+yv 1
+yp 1
+y 1
+yr 1
+ys 1
+yk 1
+ys 1
+yt 1
+yb 1
+yk 1
+yl 1
+yt 1
+yz 1
+yf 1
+yj 1
+yr 1
+z-c 1
+z-k 1
+z-m 1
+z-p 1
+z-s 1
+za- 1
+zaa 1
+zag 1
+za 1
+za 1
+zbu 1
+zb 1
+zb 1
+zce 1
+zc 1
+zdh 1
+zdi 1
+zd 1
+zd 1
+zea 1
+zfa 1
+zfe 1
+zfo 1
+zf 1
+zf 1
+zg 1
+zid 1
+zie 1
+zil 1
+zir 1
+ziv 1
+ziz 1
+zjo 1
+zkb 1
+zku 1
+zk 1
+zk 1
+zli 1
+zlu 1
+zmo 1
+zm 1
+znu 1
+zny 1
+zod 1
+zos 1
+zpa 1
+zra 1
+zsb 1
+zsj 1
+zsl 1
+zsm 1
+zsn 1
+zs 1
+zs 1
+ztb 1
+ztk 1
+ztm 1
+zub 1
+zud 1
+zuh 1
+zun 1
+zvi 1
+zv 1
+zy 1
+zy- 1
+zv 1
+zg 1
+zv 1
+zj 1
+zl 1
+zs 1
+zr 1
+zr 1
+zs 1
+zc 1
+zj 1
+zm 1
+zv 1
+zz 1
+zc 1
+zz 1
+R 1
+k 1
+ko 1
+rg 1
+ro 1
+rp 1
+rv 1
+s 1
+sv 1
+t 1
+tm 1
+z 1
+zs 1
+le 1
+lv 1
+ne 1
+rd 1
+t 1
+ta 1
+v 1
+va 1
+rd 1
+re 1
+r 1
+r 1
+s 1
+sz 1
+t 1
+t 1
+ja 1
+jl 1
+js 1
+r 1
+ri 1
+bj 1
+bn 1
+br 1
+de 1
+dj 1
+dt 1
+dz 1
+fa 1
+fi 1
+fo 1
+fu 1
+g- 1
+gc 1
+gk 1
+gv 1
+ha 1
+ik 1
+in 1
+ir 1
+it 1
+jk 1
+jl 1
+j 1
+kl 1
+kn 1
+kt 1
+k 1
+k 1
+lb 1
+le 1
+lf 1
+lr 1
+lv 1
+lz 1
+l 1
+mc 1
+me 1
+mj 1
+nh 1
+n 1
+n 1
+o 1
+os 1
+re 1
+ry 1
+sc 1
+sd 1
+se 1
+s 1
+tb 1
+tg 1
+t 1
+vk 1
+vl 1
+vr 1
+ze 1
+zf 1
+zk 1
+z 1
+z 1
+t 1
+ 1
+u 1
+us 1
+da 1
+dh 1
+dk 1
+ds 1
+d 1
+ga 1
+gf 1
+gj 1
+gn 1
+go 1
+g 1
+g 1
+ho 1
+in 1
+jj 1
+kf 1
+kg 1
+km 1
+k 1
+la 1
+ll 1
+l 1
+l 1
+mh 1
+mj 1
+mk 1
+m 1
+nu 1
+n 1
+pa 1
+pb 1
+pg 1
+pj 1
+pr 1
+rc 1
+ro 1
+rr 1
+r 1
+s- 1
+sc 1
+sv 1
+s 1
+t- 1
+td 1
+th 1
+tm 1
+t 1
+vj 1
+vk 1
+za 1
+zl 1
+zr 1
+zs 1
+di 1
+e 1
+el 1
+j- 1
+jk 1
+j 1
+ke 1
+ko 1
+kr 1
+lt 1
+lu 1
+me 1
+ml 1
+mo 1
+n- 1
+na 1
+nr 1
+o 1
+ok 1
+p 1
+r- 1
+rf 1
+rk 1
+rm 1
+r 1
+tk 1
+tt 1
+vk 1
+vn 1
+vr 1
+zh 1
+zk 1
+zm 1
+zn 1
+zt 1
+z 1
+z 1
+-g 1
+-k 1
+-m 1
+-r 1
+-s 1
+-t 1
+as 1
+b 1
+cc 1
+cz 1
+da 1
+dh 1
+dn 1
+dr 1
+dv 1
+eg 1
+el 1
+fe 1
+fu 1
+f 1
+h 1
+ik 1
+iv 1
+i 1
+j 1
+ki 1
+k 1
+lh 1
+li 1
+ln 1
+me 1
+m 1
+ny 1
+n 1
+o 1
+os 1
+rt 1
+sl 1
+su 1
+t- 1
+te 1
+ti 1
+tm 1
+t 1
+ve 1
+zi 1
+zn 1
+zv 1
+be 1
+dj 1
+dr 1
+gg 1
+j 1
+jj 1
+kj 1
+kl 1
+k 1
+le 1
+lj 1
+ln 1
+lv 1
+mb 1
+mm 1
+mp 1
+m 1
+n- 1
+ni 1
+nr 1
+nv 1
+rd 1
+rf 1
+rs 1
+sn 1
+s 1
+s 1
+tm 1
+ts 1
+zc 1
+zf 1
+zk 1
+zm 1
+z 1
+ba 1
+b 1
+i 1
+jb 1
+jh 1
+jn 1
+jv 1
+la 1
+ld 1
+lm 1
+ln 1
+l 1
+na 1
+n 1
+ri 1
+rk 1
+rn 1
+ro 1
+rr 1
+s- 1
+s 1
+td 1
+za 1
+zi 1
+zo 1
+zz 1
+z 1
+dv 1
+d 1
+hn 1
+k 1
+l- 1
+l 1
+m 1
+mp 1
+nc 1
+rd 1
+ri 1
+ro 1
+rt 1
+rz 1
+r 1
+ss 1
+st 1
+ti 1
+z 1
+k 1
+ke 1
+s 1
+sz 1
+-m 1
+au 1
+b 1
+c 1
+cs 1
+da 1
+db 1
+ek 1
+el 1
+er 1
+f 1
+go 1
+hi 1
+hm 1
+h 1
+ik 1
+iv 1
+jo 1
+j 1
+kk 1
+kr 1
+k 1
+l- 1
+l 1
+nk 1
+os 1
+ra 1
+rk 1
+rn 1
+r 1
+u 1
+ut 1
+zi 1
+zk 1
+zt 1
+ 1
+l 1
+ 1
+r 1
+t 1
+ 1
+v 1
+ 1
+t 1
+ 1
+g 1
+c 1
+cs 1
+fo 1
+he 1
+h 1
+ke 1
+kn 1
+k 1
+k 1
+ne 1
+nm 1
+nn 1
+n 1
+p 1
+pa 1
+re 1
+r 1
+r 1
+s 1
+v 1
+ze 1
+zi 1
+zk 1
+zn 1
+z 1
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.label-map b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.label-map
new file mode 100644
index 00000000..3e7d7e64
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.label-map
@@ -0,0 +1,55 @@
+54
+punct 4368
+det 3909
+amod:att 3717
+nmod:obl 2587
+nsubj 1968
+nmod:att 1853
+cc 1386
+conj 1373
+root 1361
+dobj 1269
+advmod:mode 1057
+name 733
+nmod 636
+case 568
+mark 552
+advmod:tlocy 544
+compound:preverb 339
+neg 322
+advcl 315
+nummod 253
+acl 235
+xcomp 229
+appos 198
+amod:mode 165
+remnant 159
+parataxis 138
+cop 137
+ccomp:obj 130
+compound 122
+csubj 121
+ccomp:obl 114
+iobj 78
+advmod:locy 63
+ccomp 55
+amod:obl 45
+advmod:tto 31
+dobj:lvc 31
+aux 23
+advmod:to 20
+list 19
+ccomp:pred 13
+advmod:que 12
+advmod:tfrom 12
+nmod:obllvc 8
+nsubj:lvc 3
+advmod:obl 2
+amod:attlvc 2
+goeswith 2
+advmod 1
+dep 1
+discourse 1
+dislocated 1
+nmod:attlvc 1
+vocative 1
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.master-spec b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.master-spec
new file mode 100644
index 00000000..9fe100ff
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.master-spec
@@ -0,0 +1,213 @@
+component {
+  name: "rl_rnn"
+  transition_system {
+    registered_name: "shift-only"
+    parameters {
+      key: "left-to-right"
+      value: "false"
+    }
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "char-ngram-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.char-ngram-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "word-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.word-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "label-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.label-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  fixed_feature {
+    name: "char_ngram"
+    fml: "input.token.char-ngram"
+    embedding_dim: 16
+    vocabulary_size: 9943
+    size: 1
+  }
+  fixed_feature {
+    name: "other"
+    fml: "input.token {digit hyphen punctuation-amount quote }"
+    embedding_dim: 8
+    vocabulary_size: 5
+    size: 4
+  }
+  fixed_feature {
+    name: "words"
+    fml: "input.word"
+    embedding_dim: 64
+    vocabulary_size: 11090
+    size: 1
+  }
+  network_unit {
+    registered_name: "wrapped_units.LayerNormBasicLSTMNetwork"
+    parameters {
+      key: "hidden_layer_sizes"
+      value: "256"
+    }
+  }
+  component_builder {
+    registered_name: 'DynamicComponentBuilder'
+  }
+  backend {
+    registered_name: "SyntaxNetComponent"
+  }
+  num_actions: 1
+  attention_component: ""
+}
+component {
+  name: "tagger"
+  transition_system {
+    registered_name: "tagger"
+    parameters {
+      key: "join_category_to_pos"
+      value: "true"
+    }
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "tag-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.tag-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "label-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.label-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  fixed_feature {
+    name: "action"
+    fml: "last-action"
+    embedding_dim: 32
+    vocabulary_size: 100
+    size: 1
+  }
+  linked_feature {
+    name: "encoder"
+    fml: "input.focus"
+    embedding_dim: 64
+    size: 1
+    source_component: "rl_rnn"
+    source_translator: "reverse-token"
+    source_layer: "state_h_0"
+  }
+  network_unit {
+    registered_name: "wrapped_units.LayerNormBasicLSTMNetwork"
+    parameters {
+      key: "hidden_layer_sizes"
+      value: "256"
+    }
+  }
+  component_builder {
+    registered_name: 'DynamicComponentBuilder'
+  }
+  backend {
+    registered_name: "SyntaxNetComponent"
+  }
+  num_actions: 642
+  attention_component: ""
+}
+component {
+  name: "parser"
+  transition_system {
+    registered_name: "arc-standard"
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "label-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.label-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  fixed_feature {
+    name: "action"
+    fml: "last-action"
+    embedding_dim: 32
+    vocabulary_size: 100
+    size: 1
+  }
+  fixed_feature {
+    name: "labels"
+    fml: "stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(2).label stack(1).child(-2).label"
+    embedding_dim: 16
+    vocabulary_size: 57
+    size: 12
+  }
+  linked_feature {
+    name: "encoder"
+    fml: "input.focus"
+    embedding_dim: 64
+    size: 1
+    source_component: "rl_rnn"
+    source_translator: "reverse-token"
+    source_layer: "state_h_0"
+  }
+  linked_feature {
+    name: "parser-rnn"
+    fml: "stack.focus stack(1).focus"
+    embedding_dim: 64
+    size: 2
+    source_component: "parser"
+    source_translator: "shift-reduce-step"
+    source_layer: "layer_0"
+  }
+  linked_feature {
+    name: "tagger"
+    fml: "input.focus stack.focus stack(1).focus"
+    embedding_dim: 64
+    size: 3
+    source_component: "tagger"
+    source_translator: "identity"
+    source_layer: "state_h_0"
+  }
+  network_unit {
+    registered_name: 'FeedForwardNetwork'
+    parameters {
+      key: "hidden_layer_sizes"
+      value: "256,256"
+    }
+    parameters {
+      key: "layer_norm_hidden"
+      value: "True"
+    }
+  }
+  component_builder {
+    registered_name: 'DynamicComponentBuilder'
+  }
+  backend {
+    registered_name: "SyntaxNetComponent"
+  }
+  num_actions: 109
+  attention_component: ""
+}
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.params b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.params
new file mode 100644
index 00000000..637082c4
Binary files /dev/null and b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.params differ
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.tag-map b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.tag-map
new file mode 100644
index 00000000..fd798701
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.tag-map
@@ -0,0 +1,643 @@
+642
+attribute { name: "POS" value: "PUNCT" } 4371
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Art" } attribute { name: "POS" value: "DET" } 3595
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1633
+attribute { name: "POS" value: "CONJ" } 1397
+attribute { name: "POS" value: "ADV" } 1321
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 1280
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 1097
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 987
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 784
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 609
+attribute { name: "POS" value: "ADP" } 576
+attribute { name: "POS" value: "SCONJ" } 558
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 530
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 483
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 441
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 377
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 371
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 366
+attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "ADV" } 335
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 319
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 286
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 285
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 266
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 232
+attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 216
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 210
+attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "ADV" } 207
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 206
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 188
+attribute { name: "Degree" value: "Pos" } attribute { name: "POS" value: "ADV" } 177
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 170
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 167
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 161
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 155
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 151
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 136
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 134
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 132
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 125
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 118
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 115
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 107
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 106
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 103
+attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "ADV" } 97
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 95
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 89
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Art" } attribute { name: "POS" value: "DET" } 88
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 87
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 84
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 83
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 81
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 79
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 78
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Ord" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 77
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 76
+attribute { name: "POS" value: "PART" } 74
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 71
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 69
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 69
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 64
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 61
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 61
+attribute { name: "VerbForm" value: "Trans" } attribute { name: "POS" value: "ADV" } 60
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 58
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "POS" value: "NUM" } 58
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 57
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 57
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 57
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 53
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 49
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 49
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Ord" } attribute { name: "POS" value: "ADJ" } 46
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 46
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 45
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 41
+attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "ADV" } 41
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 40
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 39
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 37
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 37
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 36
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 35
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 35
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 35
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 35
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 34
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 34
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 33
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 33
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 33
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 31
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 31
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 31
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 31
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 30
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 30
+attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "ADV" } 30
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 29
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 28
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 28
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 28
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 27
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 27
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 27
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 26
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 26
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 25
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 25
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 25
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 24
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 24
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 23
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 23
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 23
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 22
+attribute { name: "Degree" value: "Cmp" } attribute { name: "POS" value: "ADV" } 22
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 21
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 21
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 21
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 21
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 21
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "DET" } 21
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 20
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 20
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 20
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 19
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 19
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 19
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 18
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 18
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 18
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 18
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 18
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 18
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 17
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 17
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 17
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 17
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 16
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 16
+attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 16
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 15
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 15
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 15
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 15
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 15
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 15
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 15
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 15
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 15
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 14
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 14
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 14
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 14
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 14
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 13
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 13
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 13
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 13
+attribute { name: "POS" value: "X" } 13
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 12
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 12
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 12
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 12
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 12
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "ADJ" } 12
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 12
+attribute { name: "POS" value: "INTJ" } 12
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 11
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 11
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 11
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 11
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 11
+attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "ADV" } 11
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 10
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 10
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 10
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 10
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 10
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 10
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 10
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 9
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 9
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 9
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 9
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 9
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 9
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 9
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 9
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 9
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 9
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 9
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 9
+attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 9
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 8
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 8
+attribute { name: "Case" value: "Acc" } attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 8
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 8
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 8
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 8
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 8
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 8
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 8
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Poss" value: "Yes" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 8
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 8
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 8
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 7
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 7
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 7
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 7
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "PRON" } 7
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartFut" } attribute { name: "POS" value: "ADJ" } 7
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 7
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 6
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 6
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 6
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 6
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 5
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 5
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 5
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 5
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 5
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 5
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 5
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 5
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "DET" } 5
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 5
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "DET" } 5
+attribute { name: "Degree" value: "Pos" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "ADV" } 5
+attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 5
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Ade" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Ade" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 4
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 4
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 4
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 4
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Dist" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 4
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "All" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 3
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Dis" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 3
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 3
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartFut" } attribute { name: "POS" value: "ADJ" } 3
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 3
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "PROPN" } 3
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 3
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "2" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "DET" } 3
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 3
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Abs" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ade" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 2
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 2
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Dis" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "POS" value: "NUM" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 2
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 2
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Degree" value: "Sup" } attribute { name: "POS" value: "ADV" } 2
+attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "2" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "2" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Dis" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Gen" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "3" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "3" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Loc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Ord" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Dist" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Definite" value: "2" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd,Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp,Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "2" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "2" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp,Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "2" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Degree" value: "Pos" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "ADV" } 1
+attribute { name: "Mood" value: "Pot" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.word-map b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.word-map
new file mode 100644
index 00000000..5ef85ce5
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.word-map
@@ -0,0 +1,11088 @@
+11087
+a 2185
+, 2170
+. 1326
+az 857
+A 461
+s 438
+is 338
+hogy 331
+ 320
+nem 247
+" 205
+Az 169
+: 120
+egy 120
+s 111
+szerint 107
+mr 99
+mg 90
+csak 87
+( 86
+) 86
+de 86
+volt 84
+meg 77
+azt 75
+ki 63
+sem 62
+kt 59
+millird 58
+el 56
+ha 54
+mint 53
+kell 52
+pedig 51
+tbb 51
+utn 47
+kztt 46
+egyik 42
+kormny 41
+magyar 41
+van 41
+milli 39
+els 37
+lehet 37
+majd 37
+aki 36
+hiszen 36
+ltal 36
+j 36
+orosz 35
+vagy 35
+azonban 33
+hanem 33
+nagy 33
+amely 32
+arra 32
+ez 32
+miatt 32
+annak 31
+v 31
+fel 30
+gazdasgi 30
+illetve 30
+most 30
+be 29
+pldul 29
+akkor 28
+ami 28
+forint 28
+olyan 28
+? 26
+szzalkos 26
+t 26
+ta 26
+gy 26
+ezt 25
+mert 25
+minden 25
+szerb 25
+gy 25
+Ez 24
+mlt 24
+nemzetkzi 24
+amelynek 23
+jv 23
+legnagyobb 23
+ma 23
+politikai 23
+azrt 22
+mintegy 22
+utbbi 22
+cg 21
+ugyanis 21
+cm 20
+szzalkkal 20
+tavaly 20
+ahol 19
+eltt 19
+idn 19
+mellett 19
+mondta 19
+szmra 19
+viszont 19
+m 19
+ 19
+amikor 18
+ezer 18
+ezrt 18
+lesz 18
+nhny 18
+szemben 18
+ugyan 18
+vi 18
+Magyar 17
+bell 17
+cseh 17
+egsz 17
+hrom 17
+hten 17
+korbban 17
+valamint 17
+vek 17
+alatt 16
+elnk 16
+j 16
+ppen 16
+Nem 15
+koszovi 15
+kltsgvetsi 15
+mindig 15
+name 15
+nmet 15
+trk 15
+gy 15
+llami 15
+10 14
+30 14
+Ferenc 14
+Ha 14
+arrl 14
+egyes 14
+egyre 14
+fontos 14
+helyzet 14
+jvre 14
+kellene 14
+kerlt 14
+kzl 14
+lenne 14
+lv 14
+ms 14
+nagyon 14
+nincs 14
+ott 14
+volna 14
+llam 14
+ves 14
+jra 14
+; 13
+albnok 13
+amit 13
+egyelre 13
+egybknt 13
+elejn 13
+ellenre 13
+fldrengs 13
+kveten 13
+le 13
+miutn 13
+msik 13
+sajt 13
+szlovk 13
+szzalka 13
+val 13
+vannak 13
+vezetje 13
+vben 13
+! 12
+Ennek 12
+Gazprom 12
+Jnos 12
+Rt. 12
+alapjn 12
+csupn 12
+egyetlen 12
+ellen 12
+elnke 12
+elssorban 12
+ember 12
+hazai 12
+helyi 12
+kellett 12
+kerl 12
+kormnyf 12
+mg 12
+nagyobb 12
+sok 12
+szzalkt 12
+voltak 12
+ll 12
+jabb 12
+-e 11
+HVG 11
+Lszl 11
+alig 11
+azzal 11
+bank 11
+csecsen 11
+cgek 11
+el 11
+este 11
+eurpai 11
+hivatalos 11
+ht 11
+idejn 11
+ilyen 11
+ismt 11
+janur 11
+jelentette 11
+kztti 11
+klfldi 11
+legalbb 11
+lehetett 11
+mjus 11
+msodik 11
+nlkl 11
+orszg 11
+semmi 11
+szakrtk 11
+szerbek 11
+szerdn 11
+teht 11
+tovbb 11
+11 10
+20 10
+abban 10
+amelyben 10
+augusztus 10
+egykori 10
+elleni 10
+elmlt 10
+elszr 10
+fl 10
+gazdasg 10
+hozz 10
+id 10
+jelenleg 10
+jelents 10
+kzs 10
+legfontosabb 10
+magas 10
+mi 10
+mikzben 10
+moszkvai 10
+mgis 10
+ngy 10
+rendkvli 10
+rszt 10
+szzalk 10
+st 10
+teljes 10
+trtnt 10
+trvny 10
+vezet 10
+vlt 10
+vgn 10
+ve 10
+ket 10
+Ezrt 9
+Istvn 9
+Kft. 9
+Kovcs 9
+Magyarorszgon 9
+RTL 9
+Viktor 9
+adott 9
+akik 9
+akr 9
+al 9
+azaz 9
+csaldi 9
+dollros 9
+egytt 9
+el 9
+ezek 9
+ezen 9
+idei 9
+inkbb 9
+jegyzett 9
+kis 9
+legyen 9
+maga 9
+miniszterelnk 9
+napokban 9
+nemcsak 9
+sikerlt 9
+tagja 9
+teljesen 9
+terv 9
+tette 9
+tjkoztatta 9
+tl 9
+llamf 9
+l 9
+n 9
+vvel 9
+t 9
+ton 9
+1997 8
+2 8
+Budapest 8
+ENSZ 8
+Klub 8
+Orbn 8
+Pedig 8
+Tito 8
+ad 8
+akit 8
+bizottsg 8
+ebben 8
+eddig 8
+egyszer 8
+ellenzk 8
+elmondta 8
+elg 8
+emberek 8
+ennek 8
+erre 8
+ezzel 8
+fknt 8
+hamarosan 8
+hasonl 8
+hatalom 8
+helyett 8
+itt 8
+jogi 8
+jl 8
+jnius 8
+katonai 8
+korbbi 8
+kpvisel 8
+kszlt 8
+klnsen 8
+lett 8
+mind 8
+miniszter 8
+nemzeti 8
+parlamenti 8
+persze 8
+szeptember 8
+szma 8
+taln 8
+tartott 8
+tovbbi 8
+tz 8
+ugyancsak 8
+vrhat 8
+vrhatan 8
+ll 8
+ra 8
+rtelmben 8
+vekben 8
+ven 8
+nkormnyzat 8
+100 7
+1999. 7
+2000. 7
+50 7
+7 7
+De 7
+Dubcek 7
+Gyerev 7
+Gyrgy 7
+IMF 7
+Mint 7
+ahhoz 7
+attl 7
+aztn 7
+azta 7
+bels 7
+br 7
+dollr 7
+export 7
+ezttal 7
+fejlesztsi 7
+f 7
+fvros 7
+fvrosi 7
+hogyan 7
+horvt 7
+hosszabb 7
+h 7
+javaslat 7
+jllehet 7
+jval 7
+kapott 7
+katolikus 7
+kedden 7
+keleti 7
+kvetkez 7
+kzlekedsi 7
+legfeljebb 7
+lehetv 7
+lthat 7
+lpett 7
+magt 7
+parlament 7
+pnzgyi 7
+rszt 7
+sor 7
+szinte 7
+szocildemokratk 7
+szz 7
+szp 7
+tallt 7
+tavalyi 7
+tegnap 7
+teszi 7
+tett 7
+tudni 7
+trsasg 7
+vlasztsok 7
+vlsg 7
+vros 7
+s 7
+llt 7
+letben 7
+rdekben 7
+rintett 7
+k 7
+- 6
+... 6
+200 6
+25 6
+40 6
+5 6
+60 6
+Azt 6
+Bank 6
+Budapesti 6
+Br 6
+EU 6
+Eurpai 6
+GDP 6
+Imre 6
+Koszov 6
+Kztrsasg 6
+Magyarorszg 6
+S 6
+Simicska 6
+Svjc 6
+Szemjonov 6
+Szerb 6
+Zoltn 6
+adatok 6
+ahogy 6
+akiknek 6
+amelyek 6
+azonnal 6
+baleset 6
+budapesti 6
+brsg 6
+cskkent 6
+clja 6
+december 6
+eddigi 6
+ellenzki 6
+erk 6
+fog 6
+folyamatosan 6
+forintos 6
+forintra 6
+gyorsan 6
+hajland 6
+hat 6
+hatsgok 6
+hivatkozva 6
+hiba 6
+ideiglenes 6
+idben 6
+immr 6
+ipari 6
+ismert 6
+javaslatot 6
+jugoszlv 6
+kereskedelmi 6
+kevesebb 6
+kezddtt 6
+kpes 6
+krds 6
+kltsgvets 6
+krlmnyek 6
+kzponti 6
+kzvetlen 6
+kzlte 6
+legalbbis 6
+magyarorszgi 6
+marad 6
+megfelel 6
+megyben 6
+mely 6
+melynek 6
+milyen 6
+mindssze 6
+munkt 6
+nappal 6
+nemrg 6
+november 6
+nlunk 6
+n 6
+okozta 6
+olasz 6
+pontosan 6
+pnzgyminiszter 6
+rossz 6
+r 6
+soha 6
+sorn 6
+szavak 6
+szeretn 6
+szintn 6
+szmos 6
+sz 6
+szl 6
+szvetsgi 6
+tervt 6
+terletn 6
+testlet 6
+tovbb 6
+tudott 6
+tudta 6
+tbbek 6
+tzoltk 6
+unis 6
+utal 6
+utcai 6
+vele 6
+vett 6
+vezette 6
+vezetk 6
+vilg 6
+vilgpiaci 6
+vlasztsi 6
+vllalatok 6
+vgre 6
+vgig 6
+lre 6
+rta 6
+sszesen 6
+lsn 6
+szi 6
+t 6
+12 5
+4 5
+6 5
+75 5
+8 5
+Andrs 5
+Egy 5
+Egyeslt 5
+Ezek 5
+Gerhard 5
+Gbor 5
+London 5
+MLSZ 5
+Ma 5
+Magyarorszgra 5
+Pter 5
+SPD 5
+Tibor 5
+Tv 5
+Trkorszg 5
+Uni 5
+Van 5
+Zeman 5
+ad 5
+ahogyan 5
+akar 5
+akinek 5
+akkori 5
+alakult 5
+albn 5
+amelyet 5
+anyagi 5
+arnya 5
+bajnoki 5
+balkni 5
+belfldi 5
+benne 5
+cserkeszek 5
+dollrnyi 5
+dnts 5
+e 5
+elemzk 5
+ellenttben 5
+embere 5
+ennl 5
+etnikai 5
+ezeltt 5
+fel 5
+fogja 5
+foglalkoz 5
+forgalom 5
+forintot 5
+hasonlan 5
+helyen 5
+hossz 5
+hozott 5
+htfn 5
+hres 5
+hnap 5
+igazgatja 5
+igen 5
+inflci 5
+jelenlegi 5
+jobban 5
+jutott 5
+karacsjok 5
+kedvez 5
+kereslet 5
+kerlhet 5
+kezben 5
+kizrlag 5
+killts 5
+korntsem 5
+kpest 5
+krdst 5
+kszl 5
+krlbell 5
+krli 5
+kvetkeztben 5
+kvet 5
+kzgyls 5
+kztrsasg 5
+kztrsasgi 5
+kzti 5
+klkereskedelmi 5
+klnbz 5
+klnleges 5
+lakossg 5
+lapunkat 5
+lp 5
+magasabb 5
+magukat 5
+megkezdett 5
+megye 5
+megyei 5
+megllapods 5
+mikor 5
+mindenki 5
+minl 5
+mirt 5
+mondja 5
+mris 5
+mrleg 5
+mter 5
+mdon 5
+mgtt 5
+mkdik 5
+nehz 5
+nyert 5
+nmi 5
+nvekv 5
+ntt 5
+okozott 5
+olaj 5
+oroszok 5
+orvos 5
+osztrk 5
+piacon 5
+prt 5
+rendszer 5
+rendszervlts 5
+rendrsg 5
+rvn 5
+rvid 5
+sokkal 5
+szakmai 5
+szerbiai 5
+szerepet 5
+szeretem 5
+szocilis 5
+szovjet 5
+szmt 5
+szm 5
+szksges 5
+szletett 5
+tartani 5
+teleplsek 5
+termels 5
+termszetesen 5
+tervet 5
+tovbbra 5
+tud 5
+tudja 5
+tulajdonosa 5
+trca 5
+tvozott 5
+trvnyt 5
+ugyanakkor 5
+utni 5
+valamennyi 5
+viszony 5
+vrosban 5
+vgi 5
+gy 5
+tmeneti 5
+lelmiszeriparban 5
+lett 5
+rte 5
+grt 5
+ssze 5
+t 5
+1 4
+1-jtl 4
+1997-ben 4
+2. 4
+2000 4
+80 4
+AIDS 4
+Aki 4
+Ami 4
+Amikor 4
+Bajnokok 4
+Daewoo 4
+Erste 4
+Eurpa 4
+Ezt 4
+Ezzel 4
+Fenyves 4
+Fillr 4
+Hiba 4
+I. 4
+Jrai 4
+J 4
+Kiad 4
+Konzumbank 4
+Kouchner 4
+Lajos 4
+MFB 4
+Martonyi 4
+Mert 4
+Mikls 4
+Minden 4
+Minisztrium 4
+Moszkvban 4
+Mg 4
+NATO 4
+Olyan 4
+Persze 4
+Radsul 4
+Schrder 4
+Szab 4
+Tudjman 4
+Ugyanakkor 4
+Vlagyimir 4
+Zsigmond 4
+adja 4
+adtak 4
+adventi 4
+afganisztni 4
+alaposan 4
+alaptja 4
+amerikai 4
+amint 4
+amgy 4
+azokat 4
+azokban 4
+azon 4
+azonos 4
+beruhzsok 4
+bizonyos 4
+biztos 4
+boszniai 4
+busz 4
+bdzs 4
+csaknem 4
+csapat 4
+cserkesz 4
+cmmel 4
+decemberben 4
+dolgozk 4
+ebbl 4
+egy-egy 4
+egyarnt 4
+egyben 4
+egyedi 4
+egyeslet 4
+egyms 4
+egyszer 4
+egyltaln 4
+egyni 4
+egyttmkds 4
+elfogadott 4
+ellene 4
+elnki 4
+eltti 4
+emelkedik 4
+energetikai 4
+errl 4
+ersebb 4
+esetben 4
+esetleg 4
+esetben 4
+esik 4
+ezekben 4
+ezeltti 4
+fekv 4
+feladat 4
+fizetett 4
+fognak 4
+fogyaszti 4
+forintnyi 4
+francia 4
+fvrosban 4
+gyors 4
+gllvk 4
+hagyjk 4
+hangslyozta 4
+hatalmas 4
+helyet 4
+hinyban 4
+hordnknti 4
+huzavona 4
+hzak 4
+ideiglenesen 4
+igazi 4
+iskolt 4
+jelent 4
+jellemz 4
+jobb 4
+jr 4
+jrt 4
+jvben 4
+kabinet 4
+kapcsolatban 4
+kapnak 4
+keresztl 4
+keretben 4
+kezdd 4
+kiadsok 4
+kialakult 4
+kitev 4
+kivl 4
+koalci 4
+kormnynak 4
+kortrs 4
+koszork 4
+kpviselje 4
+krdsek 4
+krt 4
+ktoldal 4
+kzzel 4
+kvl 4
+krhzba 4
+knnyen 4
+krt 4
+kzel 4
+kzelmltban 4
+kztk 4
+kzsen 4
+kzssg 4
+klgyminiszter 4
+leginkbb 4
+legmagasabb 4
+legutbbi 4
+lehetsg 4
+levl 4
+ltszik 4
+makrogazdasgi 4
+maradt 4
+megerstette 4
+ment 4
+mindenesetre 4
+mindkt 4
+mit 4
+mivel 4
+mutatott 4
+mrkt 4
+msfl 4
+mrtk 4
+nap 4
+napig 4
+napra 4
+nekem 4
+nekik 4
+nevezte 4
+nincsenek 4
+norvg 4
+nyelv 4
+nyolc 4
+nyugati 4
+nlkli 4
+oktber 4
+oktberben 4
+oroszorszgi 4
+parancsnoka 4
+piaci 4
+polgri 4
+pnteken 4
+pnzt 4
+rendelkezik 4
+rsze 4
+sikeres 4
+sokan 4
+sorban 4
+szempontjbl 4
+szerepel 4
+szerept 4
+szervezetek 4
+szobor 4
+szobrot 4
+szombati 4
+szmt 4
+szzalkot 4
+szt 4
+sznpadra 4
+szt 4
+szksg 4
+takarkossgi 4
+tartja 4
+tartomny 4
+tartomnyban 4
+tartomnyi 4
+termelsi 4
+tervek 4
+tervezett 4
+titkos 4
+titkra 4
+tonna 4
+tbornok 4
+tlibok 4
+tmogatst 4
+tvon 4
+tnyez 4
+tbbi 4
+tbbsge 4
+trtnelmi 4
+trtnik 4
+tlsgosan 4
+vagyok 4
+valban 4
+vasrnap 4
+verseny 4
+veszi 4
+veszlyt 4
+vissza 4
+vonatkoz 4
+vlik 4
+vgzett 4
+vgre 4
+vlik 4
+zsid 4
+llamok 4
+n 4
+llamhztartsi 4
+llamtitkra 4
+llnak 4
+lltja 4
+lltlag 4
+rnak 4
+lelmiszer-ipari 4
+let 4
+rdekes 4
+rvnyes 4
+r 4
+rja 4
+risi 4
+rs 4
+nkntes 4
+l 4
+ 4
+sszel 4
+1-jn 3
+14. 3
+1992. 3
+1997. 3
+1999 3
+3 3
+3,5 3
+30-n 3
+57 3
+8,25 3
+Akadmia 3
+Akkor 3
+Batistuta 3
+Bernard 3
+Bond 3
+Bozky 3
+Budapesten 3
+Budapestre 3
+Bundesbank 3
+Corso 3
+Csak 3
+Csehszlovkia 3
+Dl-Koreban 3
+E 3
+EBESZ 3
+Eb 3
+Egyetem 3
+Egybknt 3
+Emiatt 3
+Erzsbet 3
+Eurpban 3
+Fidesz 3
+Fiorentina 3
+Fortuna 3
+Gyula 3
+HVG-nek 3
+Hertha 3
+Hiszen 3
+Hungria 3
+Hyundai 3
+II. 3
+Igaz 3
+Ilyen 3
+Jugoszlvia 3
+Jzsef 3
+Keane 3
+Kereskedelmi 3
+Ki 3
+Kiemelt 3
+Kim 3
+Kok 3
+Kontra 3
+Koszovban 3
+Kreml 3
+Kt 3
+Kzben 3
+Klnsen 3
+Ligja 3
+MU 3
+Macednia 3
+Manchester 3
+Meg 3
+Megyei 3
+Merthogy 3
+Milos 3
+Miutn 3
+Mivel 3
+Mr 3
+Mrpedig 3
+Mszaki 3
+Nawa 3
+Nmetorszg 3
+Nmetorszgban 3
+Omr 3
+Orahovacban 3
+Oroszorszg 3
+Orszggyls 3
+Sndor 3
+Talibn 3
+Tarzan 3
+Tegnap 3
+Tui 3
+Tbb 3
+Valencia 3
+Veszprm 3
+Vjahirev 3
+Vclav 3
+Welteke 3
+Zsolt 3
+akarja 3
+akci 3
+aktv 3
+alacsony 3
+alaptvny 3
+album 3
+aligha 3
+alkalmas 3
+alkotmnyban 3
+alkotmnyerej 3
+amelyen 3
+amire 3
+annyira 3
+autk 3
+azoknak 3
+bankok 3
+bele 3
+belgyi 3
+berlini 3
+beszlt 3
+betegsg 3
+bevezetett 3
+bizonnyal 3
+bizonyult 3
+biztonsgi 3
+budai 3
+buszok 3
+chaebolnak 3
+csald 3
+csehorszgi 3
+csoport 3
+cskken 3
+cget 3
+clz 3
+cmvd 3
+demokratikus 3
+dokumentum 3
+dolgozott 3
+dolgoz 3
+dollrra 3
+dollrrt 3
+dntst 3
+eddiginl 3
+egyedl 3
+egyeslsek 3
+egykor 3
+egymssal 3
+egyttes 3
+ekkor 3
+elakadt 3
+eleji 3
+elhangzott 3
+eljuttatott 3
+elkpzelhet 3
+elltni 3
+elltshoz 3
+eltelt 3
+elrte 3
+eladsban 3
+elbb 3
+ell 3
+emberi 3
+embert 3
+emlegetik 3
+eredmnye 3
+ers 3
+esetleges 3
+esztendben 3
+exportilletk 3
+ezeket 3
+fal 3
+fegyveresek 3
+fele 3
+fellendls 3
+felben 3
+fiatal 3
+fogadta 3
+fogjk 3
+fogyaszts 3
+fogyasztk 3
+folytatni 3
+foly 3
+forgalmi 3
+fnykp 3
+fl 3
+fggetlenl 3
+garantlt 3
+gazdasgra 3
+gondoljk 3
+gondolt 3
+gyakorolt 3
+gyilkos 3
+gyzelmt 3
+hajlandak 3
+hangzott 3
+harcolnak 3
+hatssal 3
+haza 3
+hegyekben 3
+helyettes 3
+helyettests 3
+helyezett 3
+hivatalba 3
+hivatali 3
+hiny 3
+hinya 3
+holott 3
+hozta 3
+hbor 3
+hrt 3
+hmunksok 3
+hnapban 3
+hnapok 3
+idre 3
+igaz 3
+igazgatsg 3
+igazn 3
+igyekeznek 3
+indul 3
+iraki 3
+irodk 3
+irnti 3
+irny 3
+irnyt 3
+ismtelten 3
+iszlmista 3
+isztambuli 3
+jelen 3
+jelenti 3
+jelents 3
+jelentsen 3
+jelezte 3
+jut 3
+jr 3
+jnnek 3
+jlius 3
+jliusban 3
+jniusi 3
+kamionok 3
+kapcsolatos 3
+karacsj 3
+katasztrfa 3
+katonk 3
+keddi 3
+kegytrgyak 3
+kerestek 3
+kerleti 3
+kerljn 3
+kerlnek 3
+kevs 3
+kevsb 3
+kiadvny 3
+kialaktsa 3
+kiderlt 3
+kidolgozott 3
+kiemelked 3
+kisebb 3
+kiskereskedelmi 3
+kiszemelt 3
+kommunikcis 3
+komoly 3
+koncentrci 3
+kormnyt 3
+kultra 3
+kr 3
+kpei 3
+krni 3
+krtk 3
+kszltek 3
+kvnja 3
+kr 3
+krben 3
+krzetekben 3
+krnek 3
+ksznhet 3
+ktelez 3
+kzvetlenl 3
+kz 3
+kls 3
+labdarg 3
+lakta 3
+laki 3
+legfelsbb 3
+legfbb 3
+legjobb 3
+legkevsb 3
+legszebb 3
+lehetsget 3
+lesznek 3
+ltszlag 3
+llek 3
+macedn 3
+maguknak 3
+magyar-orosz 3
+magra 3
+magnak 3
+mamutcgek 3
+maradnak 3
+megfelelen 3
+meghaladta 3
+megjelen 3
+megnyerte 3
+megtartott 3
+megteremtse 3
+menjen 3
+mindazonltal 3
+mindenkori 3
+mire 3
+mondott 3
+mondvn 3
+mostani 3
+munkagyi 3
+mutatk 3
+msok 3
+mrkzst 3
+mdostsnak 3
+mdost 3
+mg 3
+mltban 3
+mlva 3
+msor 3
+mszaki 3
+mtrgyak 3
+nagykvetsg 3
+napilap 3
+napirendre 3
+napon 3
+negatv 3
+neki 3
+nevezett 3
+nyelvi 3
+nyilatkozatban 3
+nyilvn 3
+nyolcvanas 3
+nyomst 3
+nmetek 3
+np 3
+nv 3
+nvekedse 3
+nvelsre 3
+ok 3
+oka 3
+okozza 3
+oktatsi 3
+oldalon 3
+orszgok 3
+orvosi 3
+partiznok 3
+pedaggus 3
+percben 3
+piac 3
+polgrmester 3
+politikus 3
+politikusok 3
+problmt 3
+pr 3
+prtja 3
+plda 3
+pnz 3
+pnzintzet 3
+rajta 3
+ratifiklta 3
+rendelkez 3
+rendszernek 3
+rengeteg 3
+roppant 3
+rubeles 3
+rubelt 3
+radsul 3
+rjuk 3
+rgi 3
+rszvnyek 3
+sajtos 3
+se 3
+segtsgt 3
+senki 3
+sikert 3
+sincs 3
+sokak 3
+sokat 3
+spanyol 3
+svjci 3
+szabad 3
+szabadon 3
+szakemberek 3
+szemantikai 3
+szemmel 3
+szempontbl 3
+szemlyes 3
+szemlyi 3
+szenvedett 3
+szeptemberben 3
+szerda 3
+szerdra 3
+szeretnk 3
+szerkezettalakts 3
+szervezett 3
+szerzett 3
+szerzdst 3
+szerny 3
+szolgl 3
+szmon 3
+szmtani 3
+sznt 3
+szzalknak 3
+szzalkra 3
+szkhely 3
+szvesen 3
+szlt 3
+szvivje 3
+sjtott 3
+slyos 3
+srgssgi 3
+tancs 3
+tart 3
+tartanak 3
+tartjk 3
+tart 3
+tarts 3
+tekinthet 3
+teljestmny 3
+teret 3
+tern 3
+terleteken 3
+terleti 3
+tesz 3
+tevkenysgt 3
+tiszteletben 3
+tudnak 3
+tulajdonos 3
+tulajdonba 3
+tulajdonban 3
+tmadsok 3
+trgyalsok 3
+trsg 3
+tbbsgi 3
+tmeges 3
+tmegkzlekeds 3
+trtnet 3
+trtn 3
+trvnyben 3
+tkje 3
+tnik 3
+utas 3
+utols 3
+vagyis 3
+valaki 3
+valsznleg 3
+venni 3
+vesztette 3
+vezetse 3
+vezeti 3
+vezrkari 3
+villamos 3
+vilgpiacon 3
+vits 3
+vonatkozik 3
+vdolja 3
+vlasztott 3
+vllalkozsok 3
+vrnak 3
+vrtnl 3
+vgleg 3
+vgl 3
+vletlen 3
+vletlenl 3
+zajlik 3
+zrta 3
+llami 3
+m 3
+llamadssg 3
+llamnak 3
+lltjk 3
+ltalnos 3
+prilis 3
+r 3
+rak 3
+rbevtel 3
+ron 3
+tlagosan 3
+l 3
+lelmet 3
+letre 3
+lnek 3
+lt 3
+ptmny 3
+rdekldk 3
+rdemes 3
+rint 3
+rkezett 3
+rt 3
+rtke 3
+rtkesteni 3
+vig 3
+vre 3
+rva 3
+ra 3
+rra 3
+reg 3
+sszege 3
+ssztermk 3
+tjn 3
+gy 3
+nnepek 3
+ressg 3
+rizetbe 3
+10. 2
+105 2
+110 2
+13 2
+15 2
+160 2
+17 2
+18 2
+180 2
+180-as 2
+19. 2
+190 2
+1959-es 2
+1964-ben 2
+1990-es 2
+1991-ben 2
+1992 2
+1992-ben 2
+1992-es 2
+1996-ban 2
+1998 2
+1998-ban 2
+1998-ig 2
+1998. 2
+1999-ben 2
+2,5 2
+2,6 2
+20-30 2
+2000-ben 2
+2000-re 2
+2002-ben 2
+21-n 2
+22 2
+220 2
+24. 2
+26-n 2
+28. 2
+3-0 2
+30-ig 2
+300 2
+31. 2
+33 2
+33. 2
+350 2
+4,2 2
+4-5 2
+4-es 2
+4. 2
+400 2
+43 2
+45 2
+500 2
+51 2
+55 2
+58 2
+6,3 2
+6-os 2
+6-n 2
+600 2
+65 2
+7,2 2
+70 2
+72 2
+8-n 2
+90 2
+APEH-elnk 2
+Adams 2
+Alexander 2
+Amadinda 2
+Andrssal 2
+Attila 2
+Aztn 2
+Azrt 2
+B 2
+Babiucrl 2
+Bad 2
+Balbo 2
+Balogh 2
+Barcelona 2
+Black 2
+Bordeaux 2
+Brker 2
+Brkernl 2
+Bcs-Kiskun 2
+Bnyszati 2
+Bcsben 2
+Csakhogy 2
+Csaldok 2
+Cseh 2
+Csernomirgyin 2
+Daewoo-talakts 2
+Dariusz 2
+Dobson 2
+Don 2
+Dzurinda 2
+Dl-Korea 2
+Ebbl 2
+Egyelre 2
+Egyes 2
+Egyre 2
+Egyrszt 2
+Eichel 2
+Ekzben 2
+Elemzk 2
+Elmondta 2
+Els 2
+Enrique 2
+Erre 2
+Eurpa-bajnok 2
+Ezen 2
+Farins 2
+Fejr 2
+Felgyelet 2
+Franjo 2
+Frin 2
+Galria 2
+Gaming 2
+Godesberg-i 2
+Groznijt 2
+Gyerevet 2
+Gyrk 2
+Gnt-K 2
+Hamburgba 2
+Hamed 2
+Hans 2
+Hasonl 2
+Havril 2
+Helmut 2
+Hotel 2
+HV 2
+Hrom 2
+Hbner 2
+Idn 2
+Igen 2
+Igor 2
+Ikar 2
+Ikarus 2
+Ildik 2
+International 2
+Ivanov 2
+Izmitben 2
+Jackson 2
+James 2
+Jaroslav 2
+Jelcin 2
+Juszupov 2
+Jllehet 2
+KGB 2
+Kapera 2
+Karacsj- 2
+Katolikus 2
+Kfor-erk 2
+Kft.-t 2
+Kft.-tl 2
+Kht. 2
+Kiss 2
+Klicsko 2
+Korbban 2
+Kosovska 2
+Koszovt 2
+Krankovics 2
+Kravtex 2
+Krisn 2
+Knnyen 2
+Krvastsori 2
+Kztkezel 2
+Kzlk 2
+Las 2
+Legutbb 2
+Leksa 2
+Lemberg 2
+List 2
+Liszt 2
+Mai 2
+Makkabi 2
+Man 2
+Mark 2
+Maszd 2
+Melis 2
+Michalczewski 2
+Michalke 2
+Mikuls 2
+Miknt 2
+Mindez 2
+Mindezt 2
+Mitrovica 2
+Mirt 2
+Molnr 2
+Most 2
+Moszkvba 2
+Mozgalom 2
+MV 2
+Mrvny-tenger 2
+Ms 2
+Mtys 2
+Mzeumban 2
+Mller 2
+NATO-t 2
+NSZK 2
+Nagy 2
+Napok 2
+Nekem 2
+Nemcsak 2
+Nemzeti 2
+Nyugatra 2
+Operahzban 2
+Orosz 2
+Pelagjt 2
+Pest 2
+Pilinszky 2
+Pirot 2
+Porto 2
+Praha 2
+Preininger 2
+Putyin 2
+Pzmny 2
+Pnz- 2
+Pnzgyminisztrium 2
+RTS 2
+Rabobank 2
+Rankovic 2
+Reichardt 2
+Robinson 2
+Rt.-vel 2
+Ruhrgas 2
+Rba 2
+Rgen 2
+SPO 2
+Saarbrckenben 2
+Sadler 2
+Schrdert 2
+Si 2
+Sokan 2
+Sparta 2
+Sport 2
+Svjcban 2
+Szemjonovot 2
+Szeptember 2
+Szlovkia 2
+Szovjetuni 2
+Szmos 2
+Szpmvszeti 2
+St 2
+Talics 2
+Talicsot 2
+Tams 2
+Tavaly 2
+Tietmeyer 2
+Titt 2
+Torgyn 2
+Trajkovics 2
+Tudomnyos 2
+Tupras 2
+Trk 2
+Tkepiaci 2
+UEFA 2
+USA 2
+United 2
+Vagyis 2
+Vjahirevet 2
+Vjahirevre 2
+Volf 2
+Voorbergen 2
+Vrs 2
+Wesselnyi 2
+White 2
+World 2
+XVIII. 2
+Zeneakadmin 2
+Zoran 2
+Zsolnay 2
+abba 2
+adatokat 2
+addig 2
+adni 2
+adta 2
+adk 2
+adssg 2
+adzs 2
+afrikai 2
+aggaszt 2
+ajnlatval 2
+akad 2
+akadnak 2
+akadlyait 2
+akadlyozta 2
+akarata 2
+akkora 2
+aktulis 2
+alaktotta 2
+alaktottam 2
+alapja 2
+alapvet 2
+alaptott 2
+alaptotta 2
+alaptvnynak 2
+alapt 2
+alatti 2
+alelnk 2
+alezredes 2
+alkalmazsa 2
+alkalommal 2
+alkotja 2
+alkotmny 2
+alkot 2
+alpesi 2
+als 2
+alrt 2
+all 2
+amatr 2
+amellyel 2
+amelyik 2
+amihez 2
+amin 2
+amolyan 2
+and 2
+angol 2
+ankarai 2
+annl 2
+anyag 2
+apadt 2
+apja 2
+autbuszok 2
+autplyn 2
+azok 2
+azutn 2
+bajnoksgban 2
+bankszektor 2
+becslsek 2
+befektetsre 2
+befektetk 2
+bejelentette 2
+belvros 2
+belli 2
+benzin 2
+beszmolja 2
+beszl 2
+betiltott 2
+betlt 2
+bevezetse 2
+bevezetsre 2
+bevtelbl 2
+bevtelek 2
+bizonygatta 2
+bizonytalankods 2
+bizottsga 2
+biztonsg 2
+biztosan 2
+bonyolult 2
+brit 2
+brutt 2
+brmelyik 2
+bcsi 2
+brk 2
+brlatokat 2
+bzik 2
+brtnbntets 2
+bven 2
+chaebol 2
+cigny 2
+csapatot 2
+csapst 2
+csatjt 2
+csehek 2
+csepeli 2
+cserkeszeknek 2
+csinl 2
+csinltam 2
+csomagtervet 2
+cskkentst 2
+cstrtkn 2
+cgegyeslsekre 2
+clpontja 2
+cmt 2
+darab 2
+decemberi 2
+deficitet 2
+deficitje 2
+dikok 2
+dikot 2
+dolgok 2
+dolgoztam 2
+dollrt 2
+drasztikus 2
+dl-koreai 2
+dleltt 2
+dli 2
+dlkelet-zsiai 2
+dlnyugatra 2
+dlre 2
+djazottak 2
+dnt 2
+dntttek 2
+dntbrskodst 2
+edz 2
+egyenesen 2
+egyestsvel 2
+egyeslt 2
+egyetrtenek 2
+egyhz 2
+egymsba 2
+egymst 2
+egyszersmind 2
+egyszeren 2
+egysges 2
+egysgre 2
+egyb 2
+egyttesben 2
+egszen 2
+egszsgi 2
+egszsggyi 2
+egszben 2
+ehhez 2
+eladst 2
+elegend 2
+eleje 2
+elejtl 2
+elemz 2
+elengedhetetlen 2
+elfogadta 2
+elhalasztott 2
+elindulni 2
+elindtott 2
+elismerte 2
+elkerlni 2
+elkpeszt 2
+elkvetett 2
+ellenfl 2
+ellenkezleg 2
+ellenttek 2
+ellenzkiek 2
+elltsi 2
+elmaradt 2
+elnkvlaszts 2
+elnknek 2
+elnkt 2
+elnkn 2
+elnkt 2
+eltrsek 2
+eltnt 2
+elveszti 2
+elvetette 2
+elbe 2
+elgedetten 2
+elrni 2
+elrtk 2
+elads 2
+eladst 2
+eldje 2
+elfordult 2
+elirnyzott 2
+elre 2
+eltte 2
+elzetes 2
+elz 2
+emelkedett 2
+emellett 2
+emelnk 2
+emelte 2
+emelse 2
+emelsre 2
+emelst 2
+emiatt 2
+emltik 2
+eredeti 2
+eredmny 2
+eredmnyeit 2
+eredmnyt 2
+erejk 2
+er 2
+erlteti 2
+esemny 2
+esett 2
+esti 2
+estt, 2
+eszembe 2
+eszkzzel 2
+eslyt 2
+es 2
+eurs 2
+ezredforduls 2
+fatlis 2
+februrban 2
+februri 2
+fegyverek 2
+fejldst 2
+feladatknt 2
+feladatnak 2
+feladatok 2
+feladatokkal 2
+feladta 2
+felett 2
+feletti 2
+felkrtek 2
+fellendlse 2
+felntt 2
+feloldst 2
+fels 2
+felteheten 2
+feltnt 2
+felvonsa 2
+fennakadst 2
+fenntartott 2
+fennll 2
+fenyeget 2
+fenyegetznek 2
+fertztt 2
+festett 2
+feszltsg 2
+fia 2
+fideszes 2
+figyelemre 2
+figyelmet 2
+film- 2
+fizetkpes 2
+foglalkozott 2
+fogva 2
+fogyasztkat 2
+folyamatos 2
+folytatja 2
+folytatott 2
+folytatsa 2
+folytatdik 2
+fordulnak 2
+fordul 2
+forinttal 2
+forma 2
+formban 2
+forrsok 2
+forrsokbl 2
+fotmvsz 2
+flidben 2
+flves 2
+fltt 2
+fgg 2
+fbb 2
+fiskoln 2
+fnk 2
+forvos 2
+fs 2
+fvrost 2
+ftolajhoz 2
+garancia 2
+gazdasgban 2
+gazdasgot 2
+gondolom 2
+gondolunk 2
+gyakorlat 2
+gyakorlatilag 2
+gyakorta 2
+gyakran 2
+gyanjukat 2
+gyarapodik 2
+gyerekek 2
+gyermek 2
+gyermekek 2
+gyermeket 2
+gyorsabb 2
+gyr 2
+gyri 2
+gyzelem 2
+gyzelme 2
+gyztt 2
+gyjtsenek 2
+hagyott 2
+hagyta 2
+hajnalban 2
+hajtott 2
+hallgatk 2
+halottak 2
+halla 2
+hallt 2
+hamarabb 2
+hangslyoz 2
+harcba 2
+harcosok 2
+harmadik 2
+hasznos 2
+hasznljk 2
+hatalmnak 2
+hatvan 2
+hatlya 2
+hatlyba 2
+hatr 2
+hatros 2
+hatrozott 2
+hatrrsg 2
+hatsra 2
+havazs 2
+hazja 2
+hely 2
+helyben 2
+helyettestheti 2
+helyettestsnek 2
+helyezte 2
+helyhatsgi 2
+helyzetben 2
+helyzete 2
+helyzetket 2
+helyre 2
+hetekben 2
+heti 2
+heves 2
+hibtlan 2
+hihetetlen 2
+hiteleire 2
+hiteleket 2
+hitelekre 2
+hitelintzeti 2
+hivatalban 2
+hivatkoz 2
+hinyzik 2
+hinyt 2
+hoztak 2
+hozzltott 2
+hozztette 2
+hoz 2
+humorral 2
+hbort 2
+hromszorosra 2
+htterben 2
+httrben 2
+htkznapi 2
+httel 2
+htves 2
+hrek 2
+hvei 2
+hnapokban 2
+hnapos 2
+hnappal 2
+hse 2
+ideig 2
+ideje 2
+idny 2
+idszak 2
+idszakban 2
+igazgattancs 2
+igazolsok 2
+igazolsokat 2
+igazsggyi 2
+igencsak 2
+igyekszik 2
+igyekv 2
+ignyt 2
+illetk 2
+illetkes 2
+illetkesek 2
+illeten 2
+ilyenek 2
+ilyenkor 2
+indokolja 2
+indulnak 2
+indult 2
+inflcis 2
+inflcit 2
+infrastruktra 2
+ingyen 2
+integrci 2
+intenzv 2
+intett 2
+intzkeds 2
+intzmnyek 2
+intzmnyekben 2
+intzmnyt 2
+intzte 2
+invitlta 2
+irnyba 2
+irnybl 2
+irnytst 2
+iskola 2
+iskolk 2
+iskolztatsi 2
+ismeretlen 2
+itthon 2
+jagur 2
+januri 2
+japn 2
+javaslatt 2
+jele 2
+jelensg 2
+jelentett 2
+jelentsek 2
+jelentst 2
+jelentsebb 2
+jelentsge 2
+jelentsg 2
+jelez 2
+jogot 2
+jutnak 2
+jutottak 2
+jratot 2
+jrm 2
+jtszik 2
+jtszott 2
+jtktr 2
+jrszt 2
+jt 2
+jtt 2
+jvedki 2
+kalapcs 2
+kantonizci 2
+kap 2
+kapacitssal 2
+kapcsoldik 2
+kapcsn 2
+kaptak 2
+kaptam 2
+karcsonyfatzek 2
+kedvelte 2
+keletkezett 2
+kellkppen 2
+kenyereskocsi 2
+kereskedelemben 2
+kereskedk 2
+kermiatrgyak 2
+kerlhetnek 2
+kerljenek 2
+kett 2
+kezdte 2
+kezdtk 2
+kezeli 2
+kezre 2
+kiadott 2
+kialakulst 2
+kifizetni 2
+kihirdetst 2
+kijelentette 2
+kikiltsi 2
+kilencvenes 2
+kilomter 2
+kiltsba 2
+kimaradt 2
+kinevezett 2
+kinevezse 2
+kisebbsgi 2
+killtson 2
+koalcis 2
+kockztatja 2
+komolyabb 2
+koncerten 2
+konferencia 2
+konferencin 2
+konjunktra 2
+kor 2
+kora 2
+korig 2
+korltai 2
+korltozst 2
+kormnnyal 2
+kormnya 2
+kormnyoldalon 2
+kormnyprt 2
+koronrt 2
+koszor 2
+kurizum 2
+kutatsok 2
+krt 2
+knyszerlt 2
+knytelenek 2
+kpezik 2
+kptelen 2
+kpviselhz 2
+kpviselk 2
+kpviselknek 2
+krdsekrl 2
+krte 2
+ksz 2
+ksztett 2
+ksbb 2
+ktszer 2
+knlati 2
+kvn 2
+kvnjk 2
+kvnt 2
+krhzban 2
+kd 2
+klcsns 2
+knny 2
+knyv- 2
+krnyezet 2
+krnykn 2
+krre 2
+krzsi 2
+krl 2
+kr 2
+ksznheten 2
+ktelezen 2
+ktet 2
+kttt 2
+kvetkezmnye 2
+kvetkezmnyekkel 2
+kzelebb 2
+kzeledik 2
+kzeli 2
+kzelrl 2
+kzelben 2
+kzgylsen 2
+kzgylst 2
+kzgylsn 2
+kzigazgatsi 2
+kzlekedik 2
+kzlekeds 2
+kzlemny 2
+kzoktatsi 2
+kzpont 2
+kzpnzekbl 2
+kztisztviseli 2
+kzz 2
+kzlt 2
+kzltk 2
+kznsg 2
+kzssgek 2
+kzlk 2
+kldtk 2
+klfldiek 2
+klvilgtl 2
+kln 2
+klnbsg 2
+klnfle 2
+klnmegbzottja 2
+klgyi 2
+kzdelem 2
+kzdelme 2
+kzdelmet 2
+lakos 2
+laksokban 2
+lap 2
+lapunknak 2
+lebontsa 2
+lefolytatst 2
+legjobban 2
+legkritikusabb 2
+legkzelebb 2
+legtbb 2
+legyenek 2
+lehetne 2
+lehetsgt 2
+lejtszott 2
+lelkesedett 2
+lemezbl 2
+lemondani 2
+lemondott 2
+lengyel 2
+lennnek 2
+levelet 2
+levelben 2
+levlpaprjn 2
+lezrni 2
+lezrta 2
+likvidits 2
+listn 2
+lncok 2
+lnya 2
+lt 2
+lthatatlan 2
+lthattunk 2
+lthatan 2
+ltjk 2
+ltni 2
+ltogatott 2
+ltogatsn 2
+ltom 2
+ltszott 2
+ltvnyosan 2
+lgitrsasg 2
+lpst 2
+ltre 2
+ltrejtt 2
+lvn 2
+lrai 2
+magam 2
+magnak 2
+mai 2
+maradshoz 2
+marad 2
+matematiknl 2
+megbeszlseken 2
+megbzott 2
+megerstett 2
+megfogalmazott 2
+megfontolsok 2
+meggyjtott 2
+meghaltak 2
+meghatrozott 2
+meghvtk 2
+megint 2
+megjelent 2
+megjelense 2
+megkaptam 2
+megkzelteni 2
+megrendezni 2
+megszntetse 2
+megszntetsrl 2
+megtudtuk 2
+megugrott 2
+megvalstsra 2
+megvlt 2
+megvsrolja 2
+megy 2
+megyeszkhelyen 2
+megllapodni 2
+megllapodst 2
+megrkezett 2
+megrkezik 2
+mell 2
+melyen 2
+melyrl 2
+menedzsere 2
+menekltek 2
+mentn 2
+mernylet 2
+mernyletet 2
+metr 2
+miatti 2
+millirddal 2
+millis 2
+minap 2
+mindenekeltt 2
+mindenhol 2
+mindenkinek 2
+mindenkppen 2
+mindent 2
+mindenron 2
+mindentt 2
+mintha 2
+minsg 2
+minstette 2
+mond 2
+mondtk 2
+motorolajok 2
+mozgalom 2
+mozog 2
+multinacionlis 2
+munkakrben 2
+munkanlkliek 2
+mutat 2
+mutatja 2
+mutatjk 2
+mutatkozik 2
+mutatnak 2
+mjusban 2
+mra 2
+mrciusban 2
+mrks 2
+msodszor 2
+msrszt 2
+mst 2
+mgsem 2
+mlygarzs 2
+mrtkben 2
+mdostsa 2
+mdszerek 2
+mltn 2
+mfaj 2
+mfajban 2
+mkdsi 2
+mkdst 2
+mveket 2
+mvszeti 2
+nad 2
+nagykvet 2
+nagymester 2
+nagyobbik 2
+nagyok 2
+nagyszabs 2
+nagyszer 2
+napjainkban 2
+napjn 2
+napvilgot 2
+negyedik 2
+negyedben 2
+negyedvben 2
+negyedves 2
+nehezen 2
+nemet 2
+nemrgiben 2
+nett 2
+netn 2
+neves 2
+nevet 2
+nevezi 2
+nevvel 2
+nev 2
+nyelvhasznlat 2
+nyeresget 2
+nyersolaj 2
+nyersolajrakat 2
+nyilvnossgra 2
+nyitott 2
+nyitottak 2
+nyolcadik 2
+nyomban 2
+nyomn 2
+nyugat-eurpai 2
+nyugatra 2
+nyugdjba 2
+nyugodtan 2
+nylik 2
+nyjtott 2
+npszersgbl 2
+nven 2
+nzettsge 2
+nzve 2
+nzk 2
+nvekeds 2
+nvekedsi 2
+nvekedst 2
+nvekedst 2
+nvekedsvel 2
+nvekszik 2
+nvelheti 2
+nvelst 2
+oda 2
+okn 2
+olajtrsasgok 2
+olcsbban 2
+olcsn 2
+oldalt 2
+olvashat 2
+oly 2
+operatv 2
+orszggylsi 2
+orszgokban 2
+orszgos 2
+orszgszerte 2
+osszk 2
+osztlyvezetje 2
+parlamentje 2
+parlamenttel 2
+partner 2
+pedaggiai 2
+pedaggusok 2
+perc 2
+peridus 2
+pesti 2
+pillanatnyi 2
+plaktot 2
+polgrmesteri 2
+politika 2
+pontja 2
+pontos 2
+pontot 2
+porondon 2
+portugl 2
+posztjrl 2
+posztrl 2
+pozcijt 2
+pristinai 2
+problma 2
+produkcijban 2
+profi 2
+program 2
+programjban 2
+prgai 2
+puccs 2
+plya 2
+plykon 2
+plyzatot 2
+ppa 2
+prtelnk 2
+prton 2
+pldaknt 2
+pldnyban 2
+ptlkot 2
+pspki 2
+pspkk 2
+rajzfilm 2
+rakpart 2
+rang 2
+reformok 2
+reklmoz 2
+remekel 2
+remnykedhet 2
+remnykedhetnek 2
+rendezni 2
+rendezvny 2
+rendezs 2
+rendszerek 2
+rendszerben 2
+rendr 2
+rendrsgi 2
+rendrk 2
+repltr 2
+relis 2
+ringbe 2
+rokon 2
+roma 2
+rubel 2
+rgen 2
+rgi 2
+rsztvevk 2
+rszre 2
+segly 2
+seglyt 2
+segtsget 2
+sehova 2
+semmikppen 2
+sikerl 2
+sorozatot 2
+sorsukrl 2
+stabilits 2
+sugrzott 2
+szabadsg 2
+szabadtani 2
+szablyozott 2
+szablyoz 2
+szakmailag 2
+szakrti 2
+szankcik 2
+szavai 2
+szavakat 2
+szavazatok 2
+szegedi 2
+szegny 2
+szekta 2
+szembe 2
+szembeni 2
+szemlyben 2
+szentendrei 2
+szentornak 2
+szerbeket 2
+szerdai 2
+szerelem 2
+szerencsre 2
+szerencss 2
+szerencstlensg 2
+szerepelnek 2
+szereprl 2
+szerette 2
+szerinte 2
+szervezetnek 2
+szervezsben 2
+szerzds 2
+szerzi 2
+szigor 2
+szinten 2
+szintet 2
+szintre 2
+szint 2
+szobrsz 2
+szocialistk 2
+szocildemokrata 2
+szocildemokratkat 2
+szoksos 2
+szomszdos 2
+szorgalmaz 2
+szorz 2
+szllt 2
+szlltani 2
+szllt 2
+szm 2
+szmolva 2
+szmukra 2
+szmban 2
+szmnak 2
+szmtanak 2
+szmthat 2
+szmthatnak 2
+szmtott 2
+szmtsok 2
+szmtgpes 2
+szn 2
+szndkt 2
+szrazfldi 2
+szrmazs 2
+szrmaz 2
+szrnyalsa 2
+szzalkban 2
+szzalkra 2
+szlssges 2
+szpen 2
+sznes 2
+sznhzi 2
+sznhznak 2
+sznpadi 2
+sznpadon 2
+sznsz 2
+szlva 2
+szlsszabadsg 2
+szviv 2
+szuli 2
+szvetsg 2
+szksge 2
+sfelszerelseket 2
+sppedt 2
+tagjnak 2
+tagok 2
+talpra 2
+tallkozni 2
+tallkozott 2
+tallkozkat 2
+talltk 2
+tankteles 2
+tancsadsi 2
+tapasztalatai 2
+tapasztalja 2
+tarthat 2
+tartomnyt 2
+tartotta 2
+tartottk 2
+tartozott 2
+tartozst 2
+tartstipari 2
+tartzkodsa 2
+tartzkod 2
+tavasszal 2
+taxisok 2
+tb 2
+teheraut 2
+tejipari 2
+tekintette 2
+tekintik 2
+tekintlyelv 2
+telepls 2
+teleplst 2
+televzi 2
+tengerentli 2
+tenni 2
+teremt 2
+terhel 2
+terhestancsads 2
+termk 2
+termkek 2
+termszetes 2
+termszeti 2
+terveket 2
+terlete 2
+terleten 2
+terletre 2
+teszik 2
+tetszenek 2
+tetszik 2
+tettem 2
+tevkenyked 2
+tevkenysg 2
+tiltja 2
+tiszt 2
+tisztn 2
+tizedik 2
+tonnnknt 2
+tragdia 2
+tudjk 2
+tudok 2
+tulajdonban 2
+tulajdoni 2
+tulajdonukban 2
+tjkoztatott 2
+tmadk 2
+tmogatja 2
+tmogatjk 2
+tmogats 2
+trgyak 2
+trgyalni 2
+trsadalmat 2
+trsadalomban 2
+trsait 2
+tvol-keleti 2
+tvolsgi 2
+tl 2
+tlen 2
+tmja 2
+tny 2
+tnyezk 2
+tnyleg 2
+tr 2
+trdre 2
+tren 2
+trni 2
+trsgben 2
+ttele 2
+tv 2
+tpus 2
+tz-tz 2
+tzezer 2
+tbben 2
+tbbet 2
+tbbnyire 2
+tbbszr 2
+tbbsg 2
+tbbsgben 2
+tbbsgben 2
+tbbsgt 2
+tkletesen 2
+tmeg 2
+tmegkzlekedsi 2
+tri 2
+trtnete 2
+trtnetnek 2
+trvnyek 2
+trvnyes 2
+trvnyszk 2
+trzstkj 2
+trkorszgi 2
+trkk 2
+tllk 2
+tzet 2
+tkeemels 2
+tkeers 2
+tkjt 2
+tkt 2
+tzoltknak 2
+tzoltsg 2
+ugyanaz 2
+utakon 2
+utat 2
+utcban 2
+utol 2
+utoljra 2
+utbbit 2
+vajon 2
+valami 2
+valls 2
+vehetnek 2
+velk 2
+vennie 2
+versenyt 2
+veszik 2
+vesztesge 2
+vesztesget 2
+veszlybe 2
+veszt 2
+vettk 2
+vezr 2
+vilggazdasgi 2
+vilghbor 2
+vilgi 2
+vilgmret 2
+virradra 2
+virtulis 2
+viszonyok 2
+vitt 2
+vizet 2
+vizitet 2
+vizsglni 2
+voltakppen 2
+voltunk 2
+von 2
+vonatok 2
+vdolt 2
+vlasz 2
+vlaszt 2
+vlaszthatjk 2
+vlasztotta 2
+vlasztottk 2
+vlasztsokat 2
+vlasztk 2
+vllalhatnak 2
+vllalkozs 2
+vlnak 2
+vlogatott 2
+vlogatottat 2
+vlogatottban 2
+vlsgbl 2
+vltak 2
+vltott 2
+vltozat 2
+vltsk 2
+vr 2
+vrakozsok 2
+vrhatk 2
+vrja 2
+vrosba 2
+vrosi 2
+vrostl 2
+vsrolja 2
+vdelmi 2
+vge 2
+vgleges 2
+vgrehajtst 2
+vgs 2
+vgzetes 2
+vgzs 2
+vghez 2
+vlekedett 2
+vlem 2
+vlemnye 2
+vli 2
+vlte 2
+washingtoni 2
+zent 2
+zenvel 2
+zsfolt 2
+zgrbi 2
+zrva 2
+zme 2
+ltalnos 2
+ppen 2
+j 2
+sti 2
+gazatban 2
+gazatokban 2
+llambiztonsgi 2
+llammal 2
+llamot 2
+llapota 2
+lltotta 2
+lltottk 2
+lltsa 2
+ltalban 2
+rokba 2
+rversen 2
+rbl 2
+talakuls 2
+tlagos 2
+lek 2
+letbe 2
+letemben 2
+letk 2
+lveztem 2
+lnklse 2
+ptsi 2
+ptszeti 2
+ptst 2
+ri 2
+rkeztek 2
+rthet 2
+rtk 2
+rtkben 2
+rtkekre 2
+rtkes 2
+rtkt 2
+rtk 2
+rzik 2
+szak-kaukzusi 2
+szre 2
+veken 2
+vszmvlts 2
+vszzad 2
+vtizede 2
+vtizedek 2
+vtizedeken 2
+rja 2
+rt 2
+tlet 2
+tlte 2
+tltk 2
+zben 2
+n 2
+nmagban 2
+nll 2
+sszedlt 2
+sszeg 2
+sszegekkel 2
+sszehasonltsban 2
+sszejvetelt 2
+sszektse 2
+sztnz 2
+tlet 2
+jfajta 2
+jraeloszts 2
+jsgokban 2
+thlzaton 2
+tlevlolvas 2
+ttorlaszokat 2
+gyben 2
+gyvezetje 2
+nnepls 2
+thangszerek 2
+zletek 2
+rztt 2
+rlt 2
+"Jvprogram 1
+"Prince" 1
+' 1
+'99 1
+0,7 1
+0-2 1
+007-esbl 1
+1,1 1
+1,12 1
+1,19-es 1
+1,2 1
+1,4-1,5-s 1
+1,5-2 1
+1,8 1
+1,9 1
+1-1 1
+1-es 1
+1-je 1
+1-tl 1
+1. 1
+10,1 1
+10,8 1
+10-12 1
+10-15 1
+10-ig 1
+10-ig 1
+10.-jlius 1
+102,9 1
+104 1
+107 1
+11,5 1
+11,7 1
+110-120 1
+112-es 1
+12,2 1
+12. 1
+120 1
+120,5 1
+120. 1
+1200 1
+13-22 1
+13. 1
+130 1
+1300 1
+134 1
+135,3 1
+139 1
+14 1
+14,1 1
+140 1
+147,2 1
+15-n 1
+150 1
+1500 1
+16 1
+16+3 1
+16-ai 1
+16-n 1
+164 1
+17-bl 1
+17-es 1
+17. 1
+1700 1
+171 1
+175 1
+18-a 1
+18-i 1
+1880-as 1
+19,5 1
+19-e 1
+19-es 1
+1925-ben 1
+1927 1
+1944. 1
+1947-es 1
+1947. 1
+1948-ban 1
+1948-tl 1
+1949-ben 1
+1949. 1
+195 1
+1950-ben 1
+1950-es 1
+1955-ben 1
+1957 1
+1957-tl 1
+1964 1
+1967-ben 1
+1969 1
+1969-ben 1
+1970 1
+1979-ben 1
+198 1
+1980-ban 1
+1981-ben 1
+1984-rl 1
+1989 1
+1991 1
+1991-es 1
+1993 1
+1993-as 1
+1993. 1
+1994-96-os 1
+1994-ben 1
+1994-es 1
+1994. 1
+1995-ben 1
+1995-s 1
+1996 1
+1996-os 1
+1996. 1
+1997-es 1
+1997-eshez 1
+1997-tl 1
+1998-as 1
+1999.jnius 1
+2,2 1
+2,25 1
+2,33 1
+2,5-3 1
+2,5-3,5 1
+2-0 1
+2-3 1
+2-6 1
+2-n 1
+2-nl 1
+2-tl 1
+2-n 1
+20-40 1
+200-300 1
+2000"-nek 1
+2000-tl 1
+2001-ben 1
+2002-re 1
+2003 1
+2007-ig 1
+214 1
+22,6 1
+22-23 1
+23 1
+23,64 1
+23-n 1
+24-fle 1
+25-30 1
+25-ei 1
+25. 1
+26 1
+27 1
+27-i 1
+270 1
+279 1
+28 1
+28,5 1
+28-rl 1
+2800 1
+29 1
+29-n 1
+29-tl 1
+29. 1
+3,37 1
+3,4 1
+3,6 1
+3,9 1
+3-4 1
+3-5 1
+3. 1
+30-i 1
+31 1
+31-ei 1
+31-i 1
+31-ig 1
+311 1
+32 1
+32,4 1
+32,5 1
+330 1
+338 1
+34 1
+35-t 1
+3500-ra 1
+36 1
+37 1
+38,37 1
+39. 1
+396 1
+4,5 1
+4-5-n 1
+4-rl 1
+4-n 1
+40. 1
+41 1
+413 1
+42 1
+42,5 1
+430 1
+434 1
+44,5 1
+4500 1
+46 1
+47 1
+485,7 1
+49 1
+5,3 1
+5,5 1
+5,6 1
+5,8 1
+5-10 1
+5-6 1
+5-7 1
+5-ig 1
+5. 1
+50-50 1
+52. 1
+553,7 1
+56 1
+56-os 1
+59 1
+6,6 1
+6-7 1
+60. 1
+61,5 1
+61,8 1
+62 1
+660 1
+68 1
+68. 1
+69 1
+7,8 1
+7-n 1
+70-80 1
+71,3 1
+76,8-ra 1
+77 1
+77. 1
+79 1
+8,5 1
+8,6 1
+8,9-del 1
+8-as 1
+80-as 1
+800 1
+81 1
+82 1
+84. 1
+85 1
+85. 1
+86 1
+860 1
+8600 1
+87 1
+9 1
+9,2 1
+9,45 1
+9,8 1
+9,93 1
+9-10 1
+9-14 1
+90. 1
+900 1
+95 1
+97-ben 1
+973 1
+AG 1
+AIDS-esek 1
+AIDS-szel 1
+AWS 1
+Abonyi 1
+Addig 1
+Adige 1
+Adorjn 1
+Afganisztn 1
+Afganisztnban 1
+Afrika 1
+Ahmed 1
+Akci 1
+Akinek 1
+Akkoriban 1
+Akopjan 1
+Akszjonyenko 1
+Aktulis 1
+Albatroszt 1
+Albert 1
+Alechinsky 1
+Alekszander 1
+Alex 1
+Alfonst 1
+Alkotmnybrsghoz 1
+Alkotmnysrtnek 1
+Allgemeine 1
+Almsi 1
+Altenkirchenben 1
+Amadindnak 1
+Ambrus 1
+Amint 1
+Amg 1
+Andrstl 1
+Andrs 1
+Anita 1
+Anitval 1
+Ankarba 1
+Ankarbl 1
+Antoni 1
+Anya 1
+Anyegin 1
+Anynyit 1
+Aracsicsnak 1
+Arahamija 1
+Arbour 1
+Aronyian 1
+Arrl 1
+Aszlan 1
+Atatrk 1
+Atatrkkel 1
+Atex-holding 1
+Atrium 1
+Attl 1
+Audit 1
+Ausev 1
+Aut 1
+Avrukh 1
+Avtoexport 1
+Azeltt 1
+Azzal 1
+BL 1
+BL-ben 1
+BMW 1
+BS-beli 1
+Babiucot 1
+Baden-Wrttemberg 1
+Bajororszgban 1
+Bakonyba 1
+Baku 1
+Balekok 1
+Bankot 1
+Banktl 1
+Barankovics 1
+Baranya, 1
+Baranyai 1
+Barca 1
+Barcelont 1
+Bartunkat 1
+Batumiban 1
+Ban 1
+Be 1
+Befejezte 1
+Behavazdtak 1
+Behgjet 1
+Belarusz 1
+Belgrd 1
+Belgrdba 1
+Beljavszkij 1
+Benk 1
+Berg 1
+Berzi 1
+Biberachot 1
+Bibical 1
+Biblical 1
+Bildt 1
+Bizonyos 1
+Biztonsgi 1
+Blair 1
+Bodmrre 1
+Bodo 1
+Bokros 1
+Boldogg 1
+Bomba 1
+Borba 1
+Borban 1
+Bordeaux-t 1
+Borisz 1
+Bosznia-Hercegovina 1
+Boszniban 1
+Bp. 1
+Brandenburgban 1
+Brandt 1
+Brazliban 1
+Brdjanin 1
+Brent 1
+Bronzanyagt 1
+Brosnan 1
+Brosnannek 1
+Brozt 1
+Brkerhez 1
+Brsszelben 1
+Brszszelben 1
+Budalakk 1
+Budapestet 1
+Budapestig 1
+Budapestrl 1
+Budapesttl 1
+Budejovice-i 1
+Bundesrat 1
+Bundestagban 1
+Burroughs 1
+Burny 1
+Bn 1
+Bnk 1
+Bcs 1
+Bcset 1
+Bkesi 1
+Bla 1
+Br 1
+Brsgi 1
+Brzsnyi 1
+Blent 1
+Bhm 1
+Bven 1
+C 1
+CB 1
+CD 1
+CD-m 1
+CTK 1
+Camus 1
+Carl 1
+Carmen-elads 1
+Carmenben 1
+Center 1
+Cesk 1
+Cherokeet 1
+Chillida 1
+Chironis 1
+Cignybr 1
+Collins 1
+Connery 1
+Consulting 1
+Corriere 1
+Cosi 1
+Cottbusban 1
+Csabval 1
+Csaldgyi 1
+Csapody 1
+Csecsenfldre 1
+Csellegyttestl 1
+Csepel 1
+Cserkassziban 1
+Cserkesszkben 1
+Cserkeszflddel 1
+Cserkeszfldn 1
+Csernyin 1
+Csiburdanidze 1
+Csillagszem 1
+Csirkefejnek 1
+Csobnka 1
+Csong 1
+D 1
+Daewoo-megllapodsban 1
+Daewoonak 1
+Daewoonl 1
+Daewooval 1
+Daewoohoz 1
+Dagesztn 1
+Dagesztnban 1
+Dante 1
+Dautov 1
+Demokrata 1
+Demszky 1
+Denise 1
+Deportivt 1
+Di 1
+Disney 1
+Disney-feldolgozs 1
+Djindjics 1
+Dnyeper 1
+Dnyipropetrovszk 1
+Dolomit 1
+Domonkos 1
+Donyeckben 1
+Dorny 1
+Dr. 1
+Draskovics 1
+Drulovics 1
+Dubceket 1
+Dubceknak 1
+Dubcekrl 1
+Dubrava 1
+Dniel 1
+Dl-Amerikban 1
+Dl-Koret 1
+Dnes 1
+Dnt 1
+EBESZ-cscson 1
+EBESZ-konferencit 1
+EBESZ-kldttsg 1
+ENSZ-ftitkr 1
+ENSZ-kormnyzat 1
+ENSZ-kzigazgats 1
+ENSZ-nagykvete 1
+ENSZ-nek 1
+EU-csatlakozs 1
+EU-n 1
+EU-tagsg 1
+EU-tagllamok 1
+EU-tagllamokhoz 1
+Eastern 1
+Eb-cmmeccsre 1
+Eb-cmmrkzse 1
+Eb-n 1
+Ebben 1
+Ecevit 1
+Economic 1
+Economist 1
+Eddig 1
+Edgar 1
+Eduardo 1
+Egyeslet 1
+Egyeslete 1
+Egyidejleg 1
+Egszsget 1
+Egszsggyi 1
+Eichel-csomagot 1
+Eleinte 1
+Elengedhetetlen 1
+Elhangzik 1
+Elhitettk 1
+Elkpzelhet 1
+Ellenfelei 1
+Ellenllsi 1
+Eller 1
+Elmegy 1
+Eluralkodott 1
+Elvi 1
+Elg 1
+Elszllsnl 1
+Elszr 1
+Elvrosi 1
+Elzetes 1
+Elz 1
+Emberfeletti 1
+Emellett 1
+Emil 1
+Emlkezni 1
+Endrnek 1
+Energia 1
+Engem 1
+Enying 1
+Ercel 1
+Ercsi 1
+Eredmnyek 1
+Ernst 1
+Erol 1
+Erstnl 1
+Ers 1
+Essenben 1
+Este 1
+Eszerint 1
+Etienne 1
+Ettl 1
+Eurpa-bajnoki 1
+Eurpa-bajnoksgon 1
+Eurpa-bajnoksgra 1
+Ezekben 1
+Ezeket 1
+Ezenfell 1
+Ezttal 1
+Ersi 1
+FIK 1
+FIK-rszvnyeit 1
+Faludi 1
+Far 1
+Farag 1
+Farit 1
+Fejlesztsi 1
+Fejrben 1
+Felhoztk 1
+Felkszt 1
+Felsenstein 1
+Felszabadultak 1
+Felszabadtsi 1
+Felvetdik 1
+Fennllsa 1
+Ferencet 1
+Ferencsik 1
+Ferguson 1
+Ferke 1
+Fidesz-MPP 1
+Fidesz-kzeli 1
+Figo 1
+Filippov 1
+Fiorentinbl 1
+First 1
+Fiumban 1
+Fjodorovna 1
+Fodor 1
+Fokozatosan 1
+France 1
+Frankfurter 1
+Freud 1
+Frigyes 1
+Full 1
+FK-orszgi 1
+FK-orszgok 1
+FK-piacon 1
+FK-tagllamok 1
+Flhold 1
+Fszek 1
+Fggetlen 1
+Flp 1
+Flp-szigetek 1
+Flp-szigeteki 1
+Frds 1
+Fbiztossgnak 1
+Fiskoln 1
+Fvrosi 1
+GDP-t 1
+Gaal 1
+Gabriel 1
+Galambos 1
+Galkin 1
+Gallery 1
+Galleryben 1
+Galriban 1
+Gazda 1
+Gazekszportot 1
+Gazi 1
+Gazizullin 1
+Gazprom-rszvnypakettet 1
+Gazpromban 1
+Gazprommal 1
+Gazpromot 1
+Gelfand 1
+Genscher 1
+Gergely 1
+Gimnzium 1
+Gimnziumot 1
+Giovanni 1
+Giovannira 1
+Girondins 1
+Glamour 1
+Glatz 1
+Globus 1
+Gnjilane 1
+Gnjilanban 1
+Goebbelset 1
+Goebbelsi 1
+Goghra 1
+Gonzales 1
+Gratullunk 1
+Groznij 1
+Groznijtl 1
+Grbics 1
+Grzitl 1
+Guglielmo 1
+Gurieli 1
+Gyerektrtnet 1
+Gyerevk 1
+Gyuri 1
+Gyr 1
+Gygyszer 1
+Gynyr 1
+Gyrgyt 1
+Gyr-MTK 1
+Gyz 1
+Gborral 1
+Gbort 1
+Gpgyr 1
+Gza 1
+Gdrs 1
+Gdll 1
+Gdlln 1
+Gnther 1
+Gz 1
+HIV-vrus 1
+HIV-vrushordoz 1
+HVG-t 1
+Habsburg 1
+Hacsak 1
+Hadsereg 1
+Haht-Tzeg 1
+Hajdu 1
+Hajd 1
+Hamburg 1
+Hameddel 1
+Hans-Dietrich 1
+Hasim 1
+Hasonlan 1
+Hatezer 1
+Hatrozatkptelensg 1
+Hava 1
+Havel 1
+Havellal 1
+Hazudik 1
+Hegeds 1
+Heinrich 1
+Henoch 1
+Hepta-csoport 1
+Hercegvel 1
+Herendi 1
+Herndi 1
+Hertha-Barcelona 1
+Hitel 1
+Ho 1
+Hoeme 1
+Hogy 1
+Hol 1
+Holbrooke 1
+Holyfield 1
+Hombach 1
+Honvdelmi 1
+Honvdsg 1
+Horn 1
+Horn-kabinet 1
+Horvth 1
+Horvtorszgban 1
+Horvtorszgot 1
+Hossz 1
+Hov 1
+Hozztette 1
+Hungary 1
+Hunor 1
+Huszr 1
+Hyatt 1
+Hyundait 1
+Hgba 1
+Hny 1
+Ht 1
+Htrnyos 1
+Hz 1
+Hzban 1
+Hja 1
+Htfi 1
+Hrad 1
+Hradjt 1
+Hrkzlsi 1
+Hsz 1
+Hbner-Hickl-sszecsaps 1
+ISE 1
+ISM 1
+Ide 1
+Ideiglenes 1
+Igyekezett 1
+Ilie 1
+Ilja 1
+In 1
+Indonzia 1
+Indonziban 1
+Infernjt 1
+Ingatlaniroda 1
+Ingatlankezel 1
+Intzet 1
+Intzetben 1
+Invest 1
+Iparkamara 1
+Irodalom 1
+Irnt 1
+Iskola 1
+Iskola, 1
+Iskolt 1
+Isztambul 1
+Isztambulbl 1
+Itt 1
+Ivancsuk 1
+Ivanovval 1
+Iveco 1
+Jagur 1
+Jagurrl 1
+Jan 1
+Jane 1
+Janurtl 1
+Jardel 1
+Jeep 1
+Jeles 1
+Jellemzbb 1
+Jerusalem 1
+Jevgenyij 1
+Joan 1
+Jogtudomnyi 1
+Johann 1
+Josip 1
+Joszeliani 1
+Judaika 1
+Judit 1
+Jugoszlvirt 1
+Jung 1
+Jurij 1
+Jutarnji 1
+Juventus 1
+Jn 1
+Jrai-csomagot 1
+Jrdnyi 1
+Jrni 1
+Jzsefnek 1
+Jzsi 1
+Jv 1
+Jlius 1
+Jnius 1
+Jrgen 1
+KFOR-gpek 1
+KGB-gynk 1
+KHVM 1
+Kabard-Balkr 1
+Kalauz 1
+Kaljuzsnij 1
+Kalmr 1
+Kamara 1
+Kambodzsa 1
+Kamionok 1
+Kamondi 1
+Kandahrban 1
+Kang 1
+Kapolyi 1
+Kaposvr 1
+Karacsj-Cserkesz 1
+Karbont 1
+Kardelj 1
+Karl 1
+Karosa 1
+Karn 1
+Kaszjanov 1
+Katircioglu 1
+Kavan 1
+Kazimierz 1
+Kazinczy-djat 1
+Kecskemtrl 1
+Kedvezbbnek 1
+Kelebitl 1
+Kelenfldi 1
+Kelet 1
+Kelet-Kzp-Eurpa 1
+Kemal 1
+Kereszty 1
+Kevsb 1
+Kfor 1
+Kfor-illetkesek 1
+Kfor-katona 1
+Kfor-katonkat 1
+Kft 1
+Kft.- 1
+Kft.-be 1
+Kft.-bl 1
+Kft.-nek 1
+Khurtidze 1
+Kia 1
+Kicserltk 1
+Kijev 1
+Kily 1
+Kirly 1
+Kirly(i) 1
+Kivteles 1
+Kizrlag 1
+Kjetil 1
+Kjung 1
+Klapka 1
+Klaus-kabinet 1
+Klausszal 1
+Klimmt 1
+Klubban 1
+Knorr-Bremse 1
+Knut 1
+Kobalija 1
+Kodly 1
+Kohl 1
+Kohllal 1
+Kollarits 1
+Kolozsvrhoz 1
+Komische 1
+Kompozcii 1
+Konculj 1
+Koncz 1
+Konzervgyrtk 1
+Kopint-Datorg 1
+Korcsnoj 1
+Korcsnojjal 1
+Korea 1
+Korbbi 1
+Koszovi 1
+Koszovra 1
+Kouchnerhez 1
+Kraszenkov 1
+Kravola 1
+Krecz 1
+Kulcskrds 1
+Kulturlis 1
+Kupa 1
+Kupa-mrkzs 1
+Kr 1
+Krmn 1
+Krollyal 1
+Kroly 1
+Ksztek 1
+Ktszer 1
+Ktszz 1
+Ksrtetek 1
+Kd 1
+Klnben 1
+Knyvkiad 1
+Kzalaptvny 1
+Kzel 1
+Kzlekedsi 1
+Kzponti 1
+Kzterlet-fenntart 1
+Kztrsasgban 1
+Kzs 1
+Kzssgnek 1
+Kzttk 1
+Khne 1
+Kls 1
+Kln 1
+Klnleges 1
+Klgyminisztrium 1
+Kzdenek 1
+L. 1
+Labem 1
+Labemben 1
+Laden 1
+Lafontaine 1
+Lajossal 1
+Lakner 1
+Lakos 1
+Lapunknak 1
+Legfkppen 1
+Lehetleg 1
+Lehmannhoz 1
+Lelkileg 1
+Lengyelorszgban 1
+Lenszkijnek 1
+Lepsny 1
+Lesz 1
+Lewis-Holyfield-cscsrangadjt 1
+Libahara 1
+Libchavy 1
+Liboslav 1
+Ligja-mrkzsen 1
+Liptmezn 1
+Livio 1
+Louis 1
+Louise 1
+Lputjan 1
+Ltd. 1
+Lucane 1
+Luis 1
+Lujza 1
+Lutz 1
+Luxemburgba 1
+Lnczos 1
+Ltni 1
+Lk 1
+Lteznek 1
+M0-s 1
+M1-es 1
+MDF 1
+MDF-Fidesz-szkhzgy 1
+MDF-es 1
+MLSZ-elnk 1
+MLSZ-nek 1
+MSZP 1
+MTA 1
+MTK 1
+Mabetex 1
+Macedniban 1
+Macednibl 1
+Madridot 1
+Magdolnnak 1
+Magldtl 1
+Magvet 1
+Magyarorszg! 1
+Magyarorszg!-gal 1
+Magyarorszgi 1
+Magnlevelet 1
+Mahir 1
+Majdnem 1
+Makk 1
+Malajzia 1
+Malakov 1
+Maldoror 1
+Mangurina 1
+Marceau 1
+Marczibnyi 1
+Marghescun 1
+Margit 1
+Maria 1
+Marina 1
+Mario 1
+Martinnak 1
+Martonyi-vizittl 1
+Maszhadov 1
+Maticni 1
+Mazlum-Der 1
+Meciar 1
+Megkzelthetetlenn 1
+Meglepett 1
+Meglepetsre 1
+Megszerveztk 1
+Megtisztel 1
+Megy 1
+Megjhodsi 1
+Mekkora 1
+Mellette 1
+Mello 1
+Melnyik-csoport 1
+Mendelssohnnak 1
+Menekltgyi 1
+Mez 1
+Mezgazdasgi 1
+Meznyjtkban 1
+Micurinak 1
+Mieltt 1
+Mihail 1
+Mihly 1
+Mike 1
+Mikolajivban 1
+Mikor 1
+Milliyet 1
+Milosevics 1
+Mindaz 1
+Mindazonltal 1
+Mindegyik 1
+Mindenesetre 1
+Mindenkinek 1
+Mindig 1
+Mindkt 1
+Minisztriumnak 1
+Mir 1
+Misszi 1
+Mit 1
+Mitrohin 1
+Mitsubishi 1
+Mituinak 1
+Mohamed 1
+Momcsilo 1
+Momir 1
+Monokli 1
+Moore 1
+Moralesrl 1
+Moses 1
+Mostanban 1
+Moszkva 1
+Moszkvnak 1
+Movszeszian 1
+Mozart 1
+Mroziewicz 1
+Mulomedicina 1
+Mumadi 1
+Munka 1
+Munks 1
+Music 1
+Mdl 1
+Mria 1
+Msrszt 1
+Mgis 1
+Mteres 1
+Mg 1
+Mnika 1
+Mzeum 1
+Mvek 1
+Mvszeti 1
+NATO-bombzsok 1
+NATO-ellenes 1
+NATO-ellenrzs 1
+NATO-hoz 1
+NATO-orosz 1
+NSZK-ban 1
+Nachtjournal 1
+Nagymez 1
+Nagyon 1
+Napi 1
+Napjainkban 1
+Naseem 1
+Nawa-tulajdonos 1
+Nehz 1
+Nemzetkzi 1
+Nevezetes 1
+New 1
+Nicola 1
+Nikolett 1
+Nis 1
+Nisbe 1
+Nisen 1
+Nobel-djas 1
+Noha 1
+Norvginak 1
+Nyikolaj 1
+Nyitott 1
+Nyugat 1
+Nyugattl 1
+Nyry 1
+Nyrfa 1
+Ndasdi 1
+Ngy 1
+Nmet 1
+Nmeth 1
+Nmetorszgbl 1
+Nprajzi 1
+Npszabadsg 1
+Nvekednek 1
+Nvelheti 1
+Oda 1
+Oktatsi 1
+Oktberben 1
+Olykor 1
+Olmpuszt 1
+Oniscsuk 1
+Opera 1
+Operbe 1
+Optimista 1
+Orahovac 1
+Orbn-rdekeltsg 1
+Orbnk 1
+Oregon 1
+Oroszorszgba 1
+Oroszorszgban 1
+Oroszorszgbl 1
+Oroszorszgot 1
+Orszggylsnek 1
+Orszgos 1
+Orszgszerte 1
+Orvosi 1
+Orvosnak 1
+Orwell 1
+Oskar 1
+Osszma 1
+Ott 1
+PNB-s 1
+Pacolli 1
+Pajert 1
+Pakisztnban 1
+Pall 1
+Parancsnoksgnak 1
+Pazar 1
+Pedaggiai 1
+Pelikn 1
+Pfeiffer 1
+Phil 1
+Pierce 1
+Pierre 1
+Piket 1
+Pilis 1
+Pilisszntba 1
+Pilisszntval 1
+Pilisvrsvrt 1
+Pirotba 1
+Pitypang 1
+Pofozsok 1
+Polgr 1
+Polgri 1
+Poltavban 1
+Ponomarjov 1
+Pontosan 1
+Portisch 1
+Portofin 1
+Poszeidonnal 1
+Posztjt 1
+Pozsony 1
+Pozsonyba 1
+Pozsonyban 1
+Pozsonynak 1
+PriceWaterhouse-Coopers 1
+Primakov 1
+Pristinban 1
+Pristintl 1
+Privatizcis 1
+Problma 1
+Promotion 1
+Prga 1
+Pszahisz 1
+Pulmann-kocsi 1
+Pkozdi 1
+Pl 1
+Prizsban 1
+Prt 1
+Prtja 1
+Pzmndi 1
+Pldul 1
+Pnzgyi 1
+Pterfy 1
+Pternek 1
+Pterrel 1
+Pdium 1
+QI 1
+QI-rdekeltsg 1
+Quality 1
+Radikal 1
+Radnti 1
+Radoslav 1
+Radovan 1
+Raj 1
+Rajfu 1
+Real 1
+Redmont 1
+Reggel 1
+Reinhard 1
+Rekdalnak 1
+Rem 1
+Rendezknt 1
+Replj 1
+Restaro 1
+Reuter 1
+Review 1
+Reznk 1
+Reznket 1
+Reznkrl 1
+Rice 1
+Richard 1
+Richards 1
+Robbananyaggal 1
+Robert 1
+Rod 1
+Roger 1
+Rohamosan 1
+Romanisin 1
+Rosszul 1
+Rt.-t 1
+Rt.-tl 1
+Ruszlan 1
+Rdi 1
+Rjuk 1
+Rkosi 1
+Rkosinak 1
+Rkczi 1
+Rm 1
+Rzsa 1
+Rber 1
+Rvidtv 1
+SAS-behv 1
+SPD-hveknek 1
+SPD-n 1
+SPD-s 1
+SPD-t 1
+SPD-tag 1
+SPD-tbbsg 1
+SS-tiszt 1
+SZDSZ 1
+SZDSZ-es 1
+SZDSZ-frakcijnak 1
+SZDSZ-kpviselnek 1
+SZTR 1
+Saar-vidken 1
+Sah 1
+Sakkszvetsg 1
+Samsung 1
+Schieber 1
+Schumacher 1
+Sean 1
+Senki 1
+Senklszky 1
+Seoul 1
+Sera 1
+Siemens 1
+Sir 1
+Skopje 1
+Skopjhez 1
+Soha 1
+Sok 1
+Sokkal 1
+Sokig 1
+Somogyszobon 1
+Sophie 1
+Sor 1
+Soros-sztndjat 1
+Spanyolorszgban 1
+Spir 1
+Stein 1
+Steve 1
+Strauss 1
+Stdi 1
+Stdijnak 1
+System 1
+Szabn 1
+Szahartl 1
+Szajdajev 1
+Szakadr 1
+Szakemberek 1
+Szakmailag 1
+Szakszolglatot 1
+Szakrti 1
+Szakrtk 1
+Szamos-parti 1
+Szebeni 1
+Szekszrdon 1
+Szent-Gyrgyi 1
+Szentgyrgyi 1
+Szenvedlyes 1
+Szerbia 1
+Szerbival 1
+Szerdn 1
+Szerencsre 1
+Szergej 1
+Szerinte 1
+Szervezete 1
+Szernyen 1
+Szik 1
+Szingapr 1
+Szlobodan 1
+Szlovk 1
+Szmirin 1
+Szocildemokrata 1
+Szocilis 1
+Szolgltat 1
+Szolidarits 1
+Szovjetuniba 1
+Sztanyiszlav 1
+Sztojkovszki 1
+Sztyepasin 1
+Sztlin 1
+Sztlin-szobor 1
+Szupeszu 1
+Szsz 1
+Szzhalombatta 1
+Szkesfehrvron 1
+Sznhzhoz 1
+Sznhznak 1
+Szval 1
+Szulban 1
+Szultl 1
+Szvetsg 1
+Szvetsgnek 1
+Szcs 1
+Szcs 1
+Sndorral 1
+Sndortl 1
+Srospataki 1
+Slyosnak 1
+Tab 1
+Talmud-fordts 1
+Taln 1
+Tampban 1
+Tamsi 1
+Tannhuser 1
+Tancs 1
+Tancsa 1
+Tancshoz 1
+Tapies 1
+Tarzannak 1
+Tatyjna 1
+Tavasszal 1
+Telekom 1
+Teljesen 1
+Termelsk 1
+Termszetesen 1
+Tervek 1
+Testleti 1
+Tetejkig 1
+Tettk 1
+Tevje-alaktsra 1
+Thaci 1
+Thacik 1
+Thaifld 1
+Thaifldn 1
+The 1
+Tiborn 1
+Tibort 1
+Tietmeyerrel 1
+Timmant 1
+Tisza-parti 1
+Tisztsgviselk 1
+Todt 1
+Tolna, 1
+Tony 1
+Topalov 1
+Torricelli 1
+Tovbbi 1
+Trafban 1
+Trajkovics-fle 1
+Trajkovics-tervezet 1
+Trapattoni 1
+Tudatosan 1
+Tudjmant 1
+Tudjk 1
+Tudom 1
+Tudomsunk 1
+Tudtuk 1
+Trnok 1
+Tnyek 1
+Tnyekkel 1
+Tnyleg 1
+Tbbnyire 1
+Tbbszr 1
+Tbbsgket 1
+Tbbves 1
+Tmegbalesetet 1
+Trtnelmi 1
+Trvnyszk 1
+Trk 1
+Trkorszgban 1
+Trkorszgnak 1
+Trkorszgot 1
+Trkvsz 1
+Ttschinger 1
+Tkepiacban 1
+Tzeg 1
+Tzolt 1
+UCK 1
+UMZE 1
+UNMIK 1
+URH 1
+Uecker 1
+Ugatjk 1
+Ugyan 1
+Ugyanez 1
+Ukrajna 1
+Ukrajnban 1
+Universumnak 1
+Urusz-Martan 1
+Utalt 1
+Utoljra 1
+Vaganjan 1
+Vagy 1
+Vagyonkezel 1
+Vajon 1
+Valami 1
+Valamikor 1
+Valencia-Girondens 1
+Valentyin 1
+Vall 1
+Valban 1
+Vars 1
+Vas 1
+Vatikn 1
+Vatiknban 1
+Vecernji 1
+Vegas-i 1
+Vegasban 1
+Vegyk 1
+Vekker 1
+Vele 1
+Vesztre 1
+Vezr 1
+Vida 1
+Vidovszky 1
+Viktornak 1
+Villamos 1
+Vilgbank 1
+Vilgszervezet 1
+Vjahirev-fle 1
+Vladimir 1
+Vladimr 1
+Vlaszov 1
+Vlaszovot 1
+Vocke 1
+Vollebaekkel 1
+Volt 1
+Voln 1
+Volnbusz 1
+Vu 1
+Vuk 1
+Vlasztsi 1
+Vllalat 1
+Vrpalota 1
+Vdelem 1
+Vgh 1
+Vgl 1
+Vks 1
+Vlemnye 1
+Vrtesboglrra 1
+Vzgyi 1
+Vrsvri 1
+Wagner 1
+Walt 1
+Walter 1
+Washington 1
+Washingtont 1
+Well-Press 1
+Weltekre 1
+Wely 1
+Wien 1
+Wilhelm 1
+Willy 1
+Wolframjt 1
+Wrzburgban 1
+XII. 1
+Y2K 1
+Ybl 1
+Ybl-palota 1
+Yollari 1
+York-i 1
+Zacher 1
+Zala-Tzeg 1
+Zaporozsje 1
+Zavart 1
+Zefirus-csoportnak 1
+Zeitung 1
+Zeneakadmia 1
+Zeneiskola 1
+Zeneiskolt 1
+Zenemvszeti 1
+Zetorok 1
+Zsarol 1
+Zsiga 1
+Zsivkovics 1
+Zsoldos 1
+Zsolnay-dszvza 1
+Zsolnay-trgyak 1
+Zycie 1
+abazinok 1
+abbl 1
+abhzokhoz 1
+ablakt 1
+abortuszon 1
+abszolt 1
+adand 1
+adat 1
+adatai 1
+adatait 1
+adatbzisok 1
+adatbzissal 1
+adatvdelmi 1
+addigra 1
+adhatnk 1
+adige-abhz 1
+adjk 1
+adnak 1
+adn 1
+adomnyaikat 1
+aduv 1
+ad- 1
+adbevteleket 1
+addan 1
+adfajtk 1
+adhatsg 1
+adhivatal 1
+adjt 1
+adkedvezmny 1
+adrendszer 1
+adrendre 1
+adsok 1
+adssga 1
+adssgainak 1
+adssghegy 1
+adssghegyet 1
+adssgot 1
+adssgllomny 1
+adssgllomnya 1
+adt 1
+adval 1
+agresszira 1
+agrr- 1
+ahelyett 1
+ajndka 1
+ajnlani 1
+ajnlat 1
+ajnljk 1
+ajnlsainak 1
+akadtak 1
+akadlya 1
+akadlyozni 1
+akadlyoztats 1
+akadlyoztatst 1
+akadlyoztatstl 1
+akadlyt 1
+akadmiai 1
+akadmira 1
+akarat 1
+akaratnak 1
+akarjuk 1
+akarjk 1
+akart 1
+akartam 1
+akarunk 1
+akcentussal 1
+akcifilm-forgatknyvri 1
+akciknak 1
+akcira 1
+akcit 1
+akcival 1
+akiktl 1
+akire 1
+akivel 1
+aknzhatjk 1
+aktivistaknt 1
+aktvan 1
+alacsonyak 1
+alakja 1
+alakul 1
+alakultak 1
+alakulsa 1
+alakulsra 1
+alaktania 1
+alaktank 1
+alaktja 1
+alaktottak 1
+alaktsai 1
+alaktsval 1
+alanyi 1
+alap 1
+alapanyag-termelk 1
+alapbrek 1
+alapbrket 1
+alapjt 1
+alapkamat 1
+alapkvetelmnyem 1
+alapklettelen 1
+alapozva 1
+alapozzk 1
+alapszably 1
+alapszik 1
+alaptalanul 1
+alaptke-emelst 1
+alapuljon 1
+alapveten 1
+alaptvnyokat 1
+albertfalvai 1
+albuma 1
+albumot 1
+albnokkal 1
+alelnke 1
+alighanem 1
+alkalmasak 1
+alkalmasnak 1
+alkalmazkods 1
+alkalmazkodsi 1
+alkalmazott 1
+alkalmazottaibl 1
+alkalmazottakra 1
+alkalmazottal 1
+alkalmazottja 1
+alkalmazta 1
+alkalmi 1
+alkalmbl 1
+alkalombl 1
+alkimista 1
+alkoholtl 1
+alkotjk 1
+alkotmnybrsgnl 1
+alkotmnybrsgtl 1
+alkotsa 1
+alkotshoz 1
+alkoti 1
+alkotjval 1
+alkotpros 1
+alma 1
+alsbb 1
+alshz 1
+altatja 1
+altbornagy 1
+altbornagyot 1
+aludt 1
+alulfejlett 1
+alvilgi 1
+alvs 1
+albb 1
+almerls 1
+alterveznk 1
+altervezsnek 1
+alrta 1
+alrsi 1
+ambciit 1
+amelybl 1
+amelyekben 1
+amelyeket 1
+amelyeknek 1
+amelyiktl 1
+amelyre 1
+amerikait 1
+amiben 1
+amik 1
+amiket 1
+amiknek 1
+amikorra 1
+amilyen 1
+amilyenben 1
+amivel 1
+amita 1
+amnesztit 1
+amputlja 1
+amg 1
+angliai 1
+angolok 1
+angolos 1
+angolszsz 1
+angolt 1
+angolul 1
+annyiban 1
+annyit 1
+annyival 1
+antidemokratikus 1
+antikommunista 1
+anyaga 1
+anyagban 1
+anyagok 1
+anyagot 1
+anyagt 1
+apad 1
+apai 1
+apokalypsise 1
+apropjn 1
+aprsgot 1
+apmat 1
+apsomat 1
+aquincumi 1
+arany 1
+aranykincs 1
+aranykincset 1
+araszol 1
+arat 1
+aratva 1
+archaikus 1
+archetpusok 1
+argentin 1
+ars 1
+arny 1
+arnylag 1
+arnynak 1
+arnyosan 1
+arnyt 1
+arnynak 1
+asszimilldott 1
+asszonyt 1
+aszfalton 1
+athni 1
+atom-tengeralattjr 1
+atomtuds 1
+atrocitsok 1
+attas 1
+attasja 1
+attast 1
+atyja 1
+atyjt 1
+atyskod 1
+auditorok 1
+augusztusi 1
+aukci 1
+aukcijra 1
+auljban 1
+automata 1
+automatikus 1
+automatikusan 1
+autonmia 1
+autonmit 1
+aut 1
+autba 1
+autbaleset 1
+autbusz 1
+autcsoda 1
+auteladsok 1
+autgyrtsi 1
+auti 1
+autjt 1
+autkat 1
+autkkal 1
+autplyjn 1
+autplyv 1
+auts 1
+autsok 1
+autsoknak 1
+autt 1
+autval 1
+avarok 1
+aznap 1
+azokbl 1
+azokkal 1
+azonnali 1
+azonostania 1
+baj 1
+bajbajutottak 1
+bajbajutottakon 1
+bajnoksg 1
+bajnoksgon 1
+bajnoksgot 1
+bajnoksgban 1
+bajok 1
+bajtrsat 1
+bal-jobb 1
+balesetekben 1
+balesetet 1
+baleseti 1
+balkrok 1
+baloldalon 1
+balszerencsvel 1
+bambn 1
+banditk 1
+banditkban 1
+bankra 1
+bankvilg 1
+bankrgenerci 1
+bariton 1
+baritonistbl 1
+baritonjval 1
+baritonrepertort 1
+baritonszerep 1
+barokk 1
+baromfi- 1
+barti 1
+bartja 1
+bartjhoz 1
+bartom 1
+bartomra 1
+bartsggal 1
+bartunknak 1
+beadta 1
+beavatkozik 1
+beavatkoznak 1
+beavatkoznia 1
+beazonostott 1
+bebizonyosodott 1
+becsszott 1
+beczett 1
+beengedst 1
+befagyasztott 1
+befagyasztottk 1
+befejezend 1
+befejezetlen 1
+befejezi 1
+befejezni 1
+befejezsben 1
+befejezsre 1
+befejezst 1
+befejezdik 1
+befektetsek 1
+befizetse 1
+befogadsval 1
+befolysolhatja 1
+befolysolja 1
+befolysos 1
+befolysuk 1
+befolyst 1
+befordul 1
+beftenek 1
+begpelni 1
+behavazott 1
+behozatali 1
+behlz 1
+beigazoldik 1
+beigazoldtak 1
+beiktatjk 1
+beiktatott 1
+beiktatsa 1
+bejelentett 1
+bejelents 1
+bejelentsek 1
+bejelentst 1
+bejrs 1
+bejr 1
+bekvetkezhet 1
+bekvetkezte 1
+bel- 1
+belebonyoldtak 1
+belebmulni 1
+beleegyezett 1
+beleegyezse 1
+belement 1
+belerohant 1
+beleszlni 1
+belertve 1
+belfldn 1
+belga-holland 1
+belgrdi 1
+belgygysz 1
+belgygysz-pszichitert 1
+belgygyszati 1
+belpolitika 1
+belpolitikai 1
+belseje 1
+belthatatlan 1
+belgyminiszter 1
+bellk 1
+bemenekteni 1
+bemutatkoznak 1
+bemsznak 1
+benn 1
+bennem 1
+bennfentes 1
+benyoms 1
+benzinkutak 1
+benzinr-emelkeds 1
+beolvasztjk 1
+beosztsokba 1
+beragad 1
+berendezseiben 1
+beruhzsaik 1
+beruhzsi 1
+beruhzsnak 1
+beruhzstl 1
+beruhzk 1
+beszerzett 1
+beszmolt 1
+beszmoli 1
+beszd 1
+beszdbl 1
+beszdhez 1
+beszdtechnikt 1
+beszdt 1
+beszlek 1
+beszlget 1
+beszlgettnk 1
+beszlgetsre 1
+beszlni 1
+besgk 1
+betegeket 1
+betegellts 1
+betegsgk 1
+betesz 1
+betiltotta 1
+betonfal 1
+betrsult 1
+bettdalait 1
+betlttt 1
+betk 1
+bevallom 1
+bevallotta 1
+bevetsvel 1
+bevezets 1
+bevezetsnek 1
+bevezetsvel 1
+bevlt 1
+bevsrlkzpontok 1
+bevtel 1
+bevteleit 1
+bevteleket 1
+bevtelt 1
+bezrni 1
+bezrs 1
+bin 1
+birodalmat 1
+birtokolta 1
+birtokban 1
+bizalmas 1
+bizalmast 1
+bizalmat 1
+bizalom 1
+bizonytalan 1
+bizonyulnak 1
+bizonyultak 1
+bizonyra 1
+bizonytania 1
+bizonytja 1
+bizonytotta 1
+bizonytk 1
+bizottsgban 1
+bizottsgokat 1
+biztat 1
+biztonsgot 1
+biztonsgnak 1
+biztonsgrl 1
+biztonsgt 1
+biztosnak 1
+biztost 1
+biztostaniuk 1
+biztostotta 1
+biztostottnak 1
+biztostva 1
+biztostsbl 1
+biztostsi 1
+blokd 1
+bojkottlsra 1
+boksz 1
+bokszol 1
+bokszolni 1
+boldog 1
+boldogg 1
+bolgroknl 1
+bolognai 1
+boltjt 1
+bomba 1
+bombaglt 1
+boncols 1
+bontja 1
+bontjk 1
+bonts 1
+bonyodalom 1
+bonyolultsga 1
+borult 1
+borzaszt 1
+borszat 1
+bort 1
+borthatja 1
+borltbbak 1
+bosszt 1
+botrnyt 1
+bravrok 1
+bravrra 1
+brigdnak 1
+brigdokkal 1
+bronzrmet 1
+buffoszerepeit 1
+bukkantak 1
+buksa 1
+bulikon 1
+busszal 1
+buszkzlekeds 1
+buszmegll 1
+buszokbl 1
+by 1
+bcsi 1
+bn 1
+bntalmaztak 1
+bnyacg 1
+bnyavrosba 1
+bnyi 1
+bnysztasson 1
+bnsmd 1
+bnsmdja 1
+brsonyos 1
+bzis 1
+bzisokat 1
+bkefenntartk 1
+bksen 1
+bltfrdsa 1
+bntotta 1
+br 1
+brbe 1
+bre 1
+brfejleszts 1
+brfejlesztse 1
+brkocsit 1
+brnvekedst 1
+brtblt 1
+brt 1
+br 1
+brlat 1
+brlatbl 1
+brlatzn 1
+brlni 1
+brltak 1
+brli 1
+brsgi 1
+brsgokat 1
+bznak 1
+bzott 1
+bztk 1
+bk 1
+blcsjeknt 1
+brzhez 1
+brzk 1
+bcst 1
+bza 1
+bzt 1
+bdzst 1
+bdzstervekben 1
+bntetlensget 1
+bntetnek 1
+bnteteljrs 1
+bntetjogi 1
+bntett 1
+brokrcia 1
+brn 1
+bvtsk 1
+bvtsben 1
+bvl 1
+bvlhetnek 1
+bvlse 1
+bnbakok 1
+bnbocsnathoz 1
+bncselekmnyek 1
+bncselekmnyeket 1
+bnmegelzsi 1
+bnsnek 1
+bnzs 1
+bnldzsi 1
+bvs 1
+cegldi 1
+centis 1
+centralizci 1
+cenzrzza 1
+ceremnira 1
+chaebolcsdt 1
+chaebolellenes 1
+chaeboljnak 1
+chaebolok 1
+cikke 1
+cikket 1
+cikknket 1
+cimborlna 1
+cipk 1
+cipkereskedelmi 1
+cirkalmas 1
+cirkl 1
+civil 1
+civileknek 1
+clausus 1
+combnyaktrst 1
+copyright 1
+csaldiptlk-folyst 1
+csaldnak 1
+csaldok 1
+csaldot 1
+csaldtagjai 1
+csaldgyi 1
+csalds 1
+csapata 1
+csapatbl 1
+csapatkapitnya 1
+csapatok 1
+csapattal 1
+csapnak 1
+csapott 1
+csatlakozzanak 1
+csatlakozst 1
+csatolnk 1
+csatolt 1
+csatornnak 1
+csatr 1
+csatrozsokban 1
+cseh-szlovkiai 1
+cseheknl 1
+csekly 1
+cselekedtnk 1
+cseldknyvezni 1
+cserpklyha 1
+csevegsekre 1
+csigatempban 1
+csillagszr 1
+csinlja 1
+csinljk 1
+csinlni 1
+csinlt 1
+csoda 1
+csodaketyerk 1
+csodlatos 1
+csodlkoznunk 1
+csomagterv 1
+csomagtervhez 1
+csompontja 1
+csompontok 1
+csoportba 1
+csoporthoz 1
+csoportja 1
+csoportjban 1
+csoportjt 1
+csoportmrkzsei 1
+csoportnak 1
+csoportok 1
+csoportoknak 1
+csoportokra 1
+csoporttal 1
+csupadsz 1
+csri 1
+cskkentek 1
+cskkenteni 1
+cskkenten 1
+cskkentik 1
+cskkentse 1
+cskkentsre 1
+cskkentsvel 1
+cskkenst 1
+cskken 1
+cskkenen 1
+csndes 1
+cscsidben 1
+csszs 1
+cstrtkre 1
+csd 1
+csdbe 1
+csdt 1
+csrs-csavarsra 1
+cudar 1
+cukorrpa 1
+cfolta 1
+cr 1
+cgalapt 1
+cgcsoport 1
+cgcsoporthoz 1
+cge 1
+cgeknek 1
+cginformci 1
+cl 1
+clba 1
+clirnyosan 1
+cljuk 1
+cljbl 1
+clkitzseinek 1
+clkitzsnek 1
+clokra 1
+clozta 1
+clozzk 1
+clpontjai 1
+clt 1
+cltartalkot 1
+clunk 1
+clllomsra 1
+cmek 1
+cmlapjnak 1
+cmmeccst 1
+cmoldaln 1
+cmrt 1
+da 1
+dacra 1
+dalmt 1
+dalsznhzban 1
+dalsznhznak 1
+dalnekes 1
+dandrtbornok 1
+darabban 1
+darabjai 1
+darabjaiban 1
+darabjaim 1
+darabjban 1
+darabok 1
+darabokat 1
+darabokban 1
+darabot 1
+decembere 1
+decemberben 1
+decentralizlt 1
+deficit 1
+dehonesztl 1
+dekabrista 1
+delegl 1
+della 1
+demokratizldshoz 1
+demokrcia 1
+demokrcira 1
+demokrcit 1
+derekn 1
+derl 1
+derlts 1
+derltsnak 1
+destabilizlja 1
+detoxiklkban 1
+di 1
+dideregni 1
+differencilt 1
+digitalizlt 1
+diktlnak 1
+dilemmit 1
+diligygysz 1
+dinamikusan 1
+dinamikja 1
+dinoszaurusz 1
+diploma 1
+diplomcia 1
+diplomja 1
+diplomk 1
+dirigense 1
+diriglsval 1
+diszpcserk 1
+dikltszmra 1
+dikokat 1
+dikoknak 1
+dobni 1
+dobtak 1
+dohny 1
+doktora 1
+doktrna 1
+dokumentumban 1
+dokumentumot 1
+dolgom 1
+dolgot 1
+dolgozhattam 1
+dolgozik 1
+dolgoznak 1
+dolgozni 1
+dolgozom 1
+dolgoztassk 1
+dolgozzon 1
+dolgozi 1
+dolguk 1
+dollrban 1
+dollrral 1
+dolog 1
+domborzata 1
+donorokat 1
+dortmundiknt 1
+dr. 1
+drogfogyasztk 1
+drogok 1
+drga 1
+drgulnak 1
+drgulsa 1
+drgtja 1
+drmai 1
+dugban 1
+dugk 1
+duma 1
+dunafldvri 1
+dupljra 1
+dupljt 1
+durva 1
+durvasga 1
+durvul 1
+dzsungel 1
+dzsungelkutat 1
+dzsungelt 1
+dzsungellet 1
+dtum 1
+dtumrl 1
+dtumrl 1
+ddelgette 1
+dl-amerikai 1
+dl-szerbiai 1
+dlkeleti 1
+dlszlv 1
+dlutn 1
+djakat 1
+djamrt 1
+djaz 1
+djazott 1
+djtadknt 1
+dszvendg 1
+dsztett 1
+dsztik 1
+dzelolajra 1
+dmpingbe 1
+dntenek 1
+dntenik 1
+dntetlent 1
+dnti 1
+dntse 1
+dntseikkel 1
+dntshoz 1
+dntst 1
+dntttk 1
+dnt 1
+dntnek 1
+dht 1
+dlt 1
+ebbe 1
+edzd 1
+ednyben 1
+egekig 1
+egy-kt 1
+egybehangzan 1
+egybekttt 1
+egyebek 1
+egyedisge 1
+egyeduralomra 1
+egyenltett 1
+egyenltettk 1
+egyensly 1
+egyenslyban 1
+egyes-egyedl 1
+egyesek 1
+egyeseket 1
+egyests 1
+egyestse 1
+egyesleti 1
+egyeslnek 1
+egyeslsekre 1
+egyetem 1
+egyetemben 1
+egyetemen 1
+egyetemet 1
+egyetemi 1
+egyetrt 1
+egyezmnyt 1
+egyezsg 1
+egyezsget 1
+egyfajta 1
+egyforma 1
+egyhamar 1
+egyhzfnek 1
+egyhzi 1
+egyhzuk 1
+egyidejleg 1
+egyig 1
+egyiknek 1
+egymillird 1
+egymsnak 1
+egynapos 1
+egynmelyikben 1
+egyrszt 1
+egyszeri 1
+egyszerbb 1
+egysg 1
+egysgek 1
+egysgesen 1
+egytl 1
+egynek 1
+egyrtelm 1
+egyvi 1
+egyttal 1
+egyttessel 1
+egyttltek 1
+egyttmkdni 1
+egyttmkdsi 1
+egyttmkdsre 1
+egyttmkdssel 1
+egyttmkdst 1
+egzisztencija 1
+egszsgbiztostsi 1
+egszsges 1
+egszsgpnztrak 1
+egszsgt 1
+egszsggy 1
+egszsggyireformlpseket 1
+egszt 1
+ejtett 1
+ejtette 1
+ejternyjvel 1
+ekkora 1
+eladsa 1
+eladsi 1
+eladsok 1
+eladsra 1
+eladsbl 1
+elad 1
+eladk 1
+eladsodott 1
+eladsodst 1
+elapadt 1
+elbeszlsnk 1
+elbcsztassa 1
+elcsigzottan 1
+eldugott 1
+eldnteni 1
+elegancija 1
+eleget 1
+elejre 1
+elektromos 1
+elektronikai 1
+eleme 1
+elemek 1
+elemekkel 1
+elemzs 1
+elemzse 1
+elemzsi 1
+elemben 1
+elengedte 1
+elevenednek 1
+elfelejtettk 1
+elfelejtheti 1
+elfogad 1
+elfogad- 1
+elfogadhat 1
+elfogadhatnak 1
+elfogadni 1
+elfoglalt 1
+elfoglaltsg 1
+elfoglaltsgot 1
+elfoglaltk 1
+elfoglalva 1
+elfogott 1
+elfogultak 1
+elfolyik 1
+elfutottak 1
+elgondolt 1
+elhagytk 1
+elhangzottak 1
+elhatrozott 1
+elhatroztk 1
+elhelyezked 1
+elhelyezzk 1
+elhnyja 1
+elhreslt 1
+elindulnak 1
+elindult 1
+elismerik 1
+elismersemrt 1
+elismersre 1
+elismerst 1
+elisztai 1
+eljutni 1
+eljutottunk 1
+eljuttatja 1
+eljuttatni 1
+eljrsa 1
+elkendzsben 1
+elkendzsvel 1
+elkeresztelt 1
+elkerlje 1
+elkesereds 1
+elkpzelhetnek 1
+elkpzels 1
+elkpzelsei 1
+elkpzelsek 1
+elkpzelseket 1
+elkpzelst 1
+elktelezettsgt 1
+elkvetkezend 1
+elkldte 1
+ellenben 1
+ellensg 1
+ellensgnek 1
+ellenttekben 1
+ellenttes 1
+ellenrzse 1
+ellenrztt 1
+elltnia 1
+elltogasson 1
+ellttam 1
+ellts 1
+elltsok 1
+elmarads 1
+elmegy 1
+elmeneklt 1
+elmeslnek 1
+elmondja 1
+elmondottakra 1
+elmondtk 1
+elmozdtani 1
+elmletet 1
+elmleti 1
+elnagyolt 1
+elnapolt 1
+elnapolta 1
+elnevezett 1
+elnevezs 1
+elnyerse 1
+elnmtsra 1
+elnzse 1
+elnzst 1
+elnk-vezrigazgatja 1
+elnkjellt 1
+elnkk 1
+elnkl 1
+elnksg 1
+elnkvlasztson 1
+elnkvlasztst 1
+elnkhez 1
+elnkv 1
+elodz 1
+eloltottk 1
+elolvad 1
+elosztank 1
+eloszts 1
+elosztsi 1
+elosztsra 1
+elrablsval 1
+elsejei 1
+elszakadni 1
+elszakadssal 1
+elszenvedni 1
+elszigeteltsg 1
+elszigetelshez 1
+elszlltshoz 1
+elszlltst 1
+elszrmazott 1
+elsl 1
+elslhet 1
+elsknt 1
+elsszm 1
+elteltvel 1
+elterjedse 1
+eltiltssal 1
+eltrse 1
+eltkltsgnek 1
+eltrlik 1
+eltrlsrl 1
+eltrlst 1
+eltntette 1
+eltntettk 1
+eluntam 1
+elutastott 1
+elvben 1
+elvesztette 1
+elvetettk 1
+elvileg 1
+elviselse 1
+elvittk 1
+elvontk 1
+elvonsai 1
+elvtrs 1
+elvtrsi 1
+elvlassza 1
+elvlasztfal 1
+elvlik 1
+elvrs 1
+elvrsai 1
+elvrsoknak 1
+elvgzett 1
+elzavartk 1
+elzrjk 1
+elzrt 1
+elzrtaknak 1
+elgazs 1
+elrulta 1
+elgedetlenebbek 1
+elgedetlenebbl 1
+elgedetlensget 1
+elgedettebbek 1
+elgsges 1
+elgtelen 1
+elnekelte 1
+elrt 1
+elrzkenylten 1
+elldzik 1
+eladni 1
+eladsra 1
+eladssal 1
+eladsunkkal 1
+eladjnak 1
+eladk 1
+elbb-utbb 1
+elbbibe 1
+elbbiek 1
+eldjvel 1
+eldk 1
+elfeltevse 1
+elfordulhat 1
+elirnyzatokhoz 1
+elksztettek 1
+elksztettnek 1
+elksztsbl 1
+elnye 1
+elnyeit 1
+elnys 1
+elprivatizci 1
+elrejelzseik 1
+elszeretettel 1
+elszerzds 1
+elterjesztett 1
+elterjesztst 1
+elvrosi 1
+elzetesen 1
+elzmnye 1
+elrni 1
+elrnnak 1
+elrt 1
+elrta 1
+elrs 1
+elrsaival 1
+elrsok 1
+eltletek 1
+elzst 1
+embereit 1
+embereket 1
+embergyerek 1
+emberisg 1
+emberisget 1
+emberrel 1
+emberre 1
+embernk 1
+emelhesse 1
+emelkedni 1
+emelkedse 1
+emelkedsvel 1
+emelt 1
+emeltk 1
+emels 1
+emelsvel 1
+emlkeik 1
+emlkezet 1
+emlkezni 1
+emlkezve 1
+emlkmknt 1
+emlkszem 1
+emltett 1
+emltst 1
+energia 1
+energiahordozk 1
+energiahordozkrt 1
+energiaszektorban 1
+energiaramlsban 1
+energikusak 1
+engedett 1
+engedik 1
+engedmnyekre 1
+engedve 1
+engedlyt 1
+engedsnek 1
+ennyien 1
+ennyire 1
+enyhteni 1
+enyht 1
+enyhlt 1
+eozin-mzzal 1
+epicentruma 1
+eredetileg 1
+eredmnyei 1
+eredmnyekhez 1
+eredmnyes 1
+eredmnyez 1
+eredmnynek 1
+eredmnyk 1
+erejt 1
+erej 1
+erklcs 1
+erfesztseit 1
+erfesztsekben 1
+eri 1
+erik 1
+erltetse 1
+ersen 1
+erssge 1
+erszak 1
+erszakkal 1
+erszakos 1
+erstett 1
+erstsk 1
+erstse 1
+erst 1
+ert 1
+erteljesen 1
+ertlen 1
+ervel 1
+esedkes 1
+esetekben 1
+esetre 1
+esettanulmnyok 1
+esetn 1
+esetre 1
+esetkben 1
+esnek 1
+esten 1
+estje 1
+ests 1
+eszkznek 1
+eszkzk 1
+eszkzket 1
+eszmecsere 1
+eszmecsert 1
+esztendeje 1
+esztends 1
+esztendvel 1
+esly 1
+eslyt 1
+etnikuma 1
+etnozent 1
+etnhoz 1
+ettl 1
+eur 1
+eurt 1
+eurrt 1
+exkormnyf 1
+exkormnyft 1
+exportilletket 1
+exportjt 1
+exportjval 1
+exportrknek 1
+ezekbl 1
+ezeken 1
+ezekkel 1
+ezekre 1
+ezerrel 1
+ezredes 1
+ezren 1
+ezres 1
+ezltal 1
+ezstrmesnek 1
+fa 1
+fagyos 1
+fagyott 1
+faj 1
+fajjal 1
+fajta 1
+fajult 1
+fakadtak 1
+fakadan 1
+fala 1
+falat 1
+falatot 1
+fallal 1
+falu 1
+falubl 1
+falvak 1
+fan 1
+fantasztikus 1
+fantomm 1
+fantzia 1
+farmert 1
+februrjban 1
+februrjtl 1
+fedezi 1
+fedezni 1
+fedezsre 1
+fedte 1
+fedlzeten 1
+fednven 1
+fegyelmez 1
+fegyhzbntetsre 1
+fegyveres 1
+fegyvereseknek 1
+fegyverraktrokat 1
+fegyvert 1
+fehr 1
+fejezi 1
+fejeznk 1
+fejezte 1
+fejeztk 1
+fejezdne 1
+fejezdtek 1
+fejjel 1
+fejlesztse 1
+fejlesztseit 1
+fejlesztsek 1
+fejlesztsekben 1
+fejlesztseket 1
+fejlesztst 1
+fejlett 1
+fejldjn 1
+fejldsnek 1
+fejldtt 1
+fejtette 1
+fejre 1
+fekete 1
+feketegazdasg 1
+feketelevest 1
+feladata 1
+feladatait 1
+feladatelltshoz 1
+feladatokat 1
+feladatot 1
+feldarabolsa 1
+feldarabolsra 1
+feldolgozipar 1
+feldolgozk 1
+feldolgozkkal 1
+feldolgozknak 1
+feldhdtt 1
+feledst 1
+felejtsd 1
+felek 1
+felelt 1
+felelsek 1
+felelssge 1
+felelssget 1
+felelssgre 1
+felemelse 1
+felems 1
+felengedjen 1
+felesge 1
+felfel 1
+felfigyelnek 1
+felfoghat 1
+felfogssal 1
+felfggesztette 1
+felgyorsulhatnak 1
+felhajtotta 1
+felhasznlhat 1
+felhasznljk 1
+felhasznlt 1
+felhborodott 1
+felhvja 1
+felhvott 1
+felhzsa 1
+felidzsvel 1
+feljelentettjeit 1
+feljelentst 1
+felkels 1
+felkiltjelknt 1
+felkrte 1
+felkrst 1
+felkrst 1
+felkszlt 1
+felknlt 1
+fellebbezst 1
+fellelhet 1
+fellendlt 1
+fellendlst 1
+fellendlsnek 1
+fellpsre 1
+fellpsrl 1
+felmehet 1
+felmentette 1
+felmerlnek 1
+felmrhetik 1
+felnttet 1
+felnttkorunk 1
+feloldank 1
+felolddst 1
+feloszlatst 1
+felosztsval 1
+felsorakoztatni 1
+felsoroltk 1
+felszolgltk 1
+felszllst 1
+felszmolsa 1
+felszmolst 1
+felsznre 1
+felszlalsokban 1
+felszltott 1
+felszltotta 1
+felszltsnak 1
+felshz 1
+feltehet 1
+feltehetleg 1
+felturbzott 1
+felttel 1
+feltteleit 1
+felttelezik 1
+felttelezn 1
+felttelezsek 1
+felttelknt 1
+feltltshez 1
+feltltdtek 1
+feltnen 1
+felvilgosods 1
+felvltaniuk 1
+felvlt 1
+felvsrlsokra 1
+felvsrlsval 1
+felvteleknek 1
+felvtelre 1
+felll 1
+fellednek 1
+felre 1
+felt 1
+felrtk 1
+felvelst 1
+feljtott 1
+feljts 1
+felgyelet 1
+felgyeleti 1
+felgyelbizottsg 1
+fell 1
+felletes 1
+fellratsval 1
+fennakadsokat 1
+fennakadsra 1
+fenntartani 1
+fenntartja 1
+fenntartsa 1
+fenntartsa 1
+fenntartsai 1
+fenntartsait 1
+fennllnak 1
+fennllt 1
+fenyegette 1
+fenyegettk 1
+fenyeget 1
+fenyfk 1
+fertzttek 1
+festmny- 1
+festmnyek 1
+fesztivlok 1
+feszt 1
+feszltebb 1
+feszltsgek 1
+feszltsget 1
+feszltsggccal 1
+fiam 1
+fiatalabb 1
+fiatalember 1
+fiatalembert 1
+figura 1
+figurja 1
+figyelmeztettek 1
+figyelmeztets 1
+figyelmnk 1
+filmadagot 1
+filmben 1
+filmet 1
+filmjnek 1
+filmszemln 1
+filmvsznakrl 1
+filozfikra 1
+filozfus 1
+finanszrozott 1
+finanszrozs 1
+finanszrozsban 1
+finanszrozsi 1
+finoman 1
+finomsga 1
+finomsgok 1
+finomtban 1
+finomtja 1
+finomtk 1
+finljval 1
+fisklis 1
+fizessk 1
+fizet 1
+fizetik 1
+fizetni 1
+fizetsemels 1
+fizetsi 1
+fizetskptelenn 1
+fizetskptelensg 1
+fizetssel 1
+fizetsnek 1
+fira 1
+figyermeke 1
+fogadja 1
+fogadnia 1
+fogadott 1
+fogadtatott 1
+fogadtk 1
+fogadcsoportban 1
+fogadszveg 1
+fogalmazzon 1
+fogalmt 1
+foglalkozik 1
+foglalkozom 1
+foglalkoztam 1
+foglalkoztatottak 1
+foglalkoztatottsgot 1
+foglalkoztatta 1
+foglalkoztats 1
+foglalkoztatshoz 1
+foglalkoztat 1
+foglalt 1
+foglaltakat 1
+foglaltaknak 1
+fogsgbl 1
+fogtak 1
+fogyaszt 1
+fogyaszthatja 1
+fogyasztott 1
+fogyasztir-vltozsra 1
+fogyasztkhoz 1
+fogyatkossguk 1
+fogyott 1
+fokozott 1
+fokozsa 1
+fokozshoz 1
+folyamat 1
+folyamatok 1
+folyamatokba 1
+folyamatokkal 1
+folyamn 1
+folyhat 1
+folyik 1
+folyt 1
+folytassa 1
+folytassk 1
+folytathatta 1
+folytatjk 1
+folytatnak 1
+folytats 1
+folytatsaknt 1
+folytatsra 1
+folytatst 1
+folytatdjk 1
+folyton 1
+fontolra 1
+fonmk 1
+fondva 1
+fordulat 1
+fordulatot 1
+fordulok 1
+fordult 1
+fordulban 1
+forduljban 1
+fordulponthoz 1
+forduls 1
+fordult 1
+fordtani 1
+fordtania 1
+fordthat 1
+fordtottak 1
+forgalma 1
+forgalmuk 1
+forgatta 1
+forgatsok 1
+forg 1
+forintnl 1
+forintrl 1
+forintrt 1
+formagazdagsga 1
+formasgokhoz 1
+forminak 1
+formja 1
+formjban 1
+formjt 1
+formk 1
+formlisan 1
+formldott 1
+formt 1
+forradalom 1
+forrsa 1
+forr 1
+fortlyt 1
+fosztotta 1
+fotogrfusnak 1
+fot 1
+fotk 1
+fotkra 1
+fotn 1
+fots 1
+fotzta 1
+frakcijn 1
+frakcijnak 1
+frakcik 1
+frakcivezet-helyettese 1
+frankfurti 1
+frontrl 1
+frzisok 1
+fukar 1
+funkcionl 1
+futamidej 1
+futmvet 1
+fuvarozkat 1
+fbl 1
+fjdalmas 1
+fjdalmasra 1
+fjlalja 1
+fradtsg 1
+fzik 1
+fkberendezseket 1
+fken 1
+fktelenebb 1
+flelmet 1
+flig 1
+flmillird 1
+flplynl 1
+flrertenk 1
+flrerts 1
+flrertseket 1
+flvi 1
+flvre 1
+flrnknt 1
+flrs 1
+fmjelzett 1
+fnyes 1
+fnykpeket 1
+frfi 1
+frfi-nekszextettl 1
+frfiak 1
+frfiaknl 1
+frfias 1
+frfiimittor 1
+frfire 1
+frfii 1
+frhet 1
+frjnek 1
+frne 1
+frhelyeit 1
+fkuszljon 1
+frumon 1
+frumra 1
+fl 1
+fldgz 1
+fldgzt 1
+fldgztermelsnek 1
+fldmozgs 1
+fldrengstl 1
+flvetknek 1
+flnye 1
+fltte 1
+fltti 1
+fnt 1
+fadszed 1
+fbl 1
+fgonoszt 1
+fhadiszllsra 1
+fhivatal 1
+fhlzat 1
+fkatona 1
+fleg 1
+fmsoridben 1
+fnemesek 1
+fnl 1
+fnki 1
+fnkt 1
+fosztlyvezet-helyettese 1
+fpolgrmester 1
+fpolgrmestervel 1
+fre 1
+fsre 1
+fszemlli 1
+fszerepet 1
+fszerepli 1
+fszereplje 1
+fszerkesztje 1
+ftiszt 1
+ftitkra 1
+futakon 1
+fvros-kormny 1
+fvrosba 1
+fvroshoz 1
+fvrosnak 1
+fvrosban 1
+fllamgysznek 1
+ftvonalakon 1
+fgysz 1
+ftolaj-szlltmny 1
+ftolaj-szlltmnybl 1
+ftolajat 1
+fzik 1
+fzdik 1
+fzdtt 1
+gabonatancs 1
+galrija 1
+garanciavllalsa 1
+garancit 1
+garantltan 1
+gazdasgba 1
+gazdasgkutatk 1
+gazdasgunkra 1
+gazdasgban 1
+gazdirl 1
+gazdlkodni 1
+gazdlkodniuk 1
+gazdlkodsa 1
+gazdlkod 1
+gerillavezrek 1
+gerjeszti 1
+gigantikus 1
+gipszminta 1
+giusto 1
+globalizci 1
+globalizcirl 1
+globalizlt 1
+gnosztikusok 1
+gondja 1
+gondjait 1
+gondolataimat 1
+gondolkodsra 1
+gondolkodi 1
+gondolok 1
+gondoltam 1
+gondossgrl 1
+gondot 1
+gondozsban 1
+gonosz 1
+gorillacsaldban 1
+grafiki 1
+grf 1
+grzok 1
+gumival 1
+gyakoribb 1
+gyakorlata 1
+gyakorlati 1
+gyakorlatok 1
+gyakorlatokra 1
+gyakorlreplseket 1
+gyakorolhatjk 1
+gyakoroltak 1
+gyakrabban 1
+gyan 1
+gyans 1
+gyanst 1
+gyantlanul 1
+gyaraptja 1
+gyaraptotta 1
+gyed 1
+gyengjt 1
+gyenglked 1
+gyengnek 1
+gyerek 1
+gyerekeket 1
+gyerekekkel 1
+gyermekkorunk 1
+gyermekvdelmi 1
+gyertyalng 1
+gyertykat 1
+gyertykkal 1
+gyertyt 1
+gyorsabban 1
+gyorsforgalmi 1
+gyorsvast 1
+gyorsvastt 1
+gyorsvillamossal 1
+gyrak 1
+gyrakhoz 1
+gyrban 1
+gyrbl 1
+gyrt 1
+gyrtk 1
+gygyszerhiny 1
+gygyszermrgezetteket 1
+gygythatatlan 1
+gygytott 1
+gykeres 1
+gynyr 1
+gynyrsges 1
+gylekezst 1
+gyzni 1
+gyzte 1
+gyjtemnybl 1
+gyjtemnynek 1
+gyjthetnek 1
+gyjtk 1
+gla 1
+gln 1
+gnti 1
+grda 1
+grdhoz 1
+gtja 1
+gz 1
+gzkondenztumot 1
+gzolaj 1
+gztrsasg 1
+gp 1
+gpei 1
+gpek 1
+gpi 1
+gpipari 1
+gpkocsiba 1
+gpkocsivezetjt 1
+gpkocsivezetrl 1
+gpkocsiradat 1
+gpszmrnkket 1
+gl 1
+gllal 1
+gzmozdonyok 1
+habr 1
+hadi 1
+hadiipari 1
+hadmveleteket 1
+hadosztlyparancsnok 1
+hadsereggel 1
+hadseregnek 1
+hadseregnek 1
+hadvezets 1
+hadllst 1
+hadrnak 1
+hagyniuk 1
+hagyn 1
+hagyomnny 1
+hagyomny 1
+hagyomnyokhoz 1
+hagyomnyos 1
+hagyomnyosan 1
+hagyomnyteremt 1
+hagy 1
+hajdani 1
+hajlandsggal 1
+hajlktalanrl 1
+hajrban 1
+hajtogatjk 1
+hajtottk 1
+hajtsk 1
+hajtva 1
+hajtanyag 1
+halad 1
+haladja 1
+haladjon 1
+haladt 1
+haladva 1
+halasztott 1
+halaszt 1
+hallatlanul 1
+hallatott 1
+hallatn 1
+hallgathatbb 1
+hallgatok 1
+hallgatknak 1
+halmaza 1
+halmozott 1
+halmoztak 1
+halott 1
+haltak 1
+hallesetekre 1
+hallratlt 1
+hallig 1
+hallnak 1
+hamar 1
+hamisnak 1
+hamiss 1
+hangjegyre 1
+hangjval 1
+hangos 1
+hangosan 1
+hangot 1
+hangoztatott 1
+hangoztatta 1
+hangoztatva 1
+hangszereket 1
+hangvtelek 1
+hangzanak 1
+hangzik 1
+harag 1
+haragja 1
+haragv 1
+harca 1
+harcban 1
+harcnak 1
+harcok 1
+hard 1
+harmada 1
+harmincperces 1
+harmonikus 1
+hashrtyagyulladst 1
+hasonlthat 1
+hasonlsgt 1
+hasson 1
+hasznostjk 1
+hasznot 1
+hasznlata 1
+hasznlhatatlansga 1
+hasznlja 1
+hasznlta 1
+hasznltk 1
+haszonlvezi 1
+hatalmassgaival 1
+hatalmi 1
+hatalmukkal 1
+hatalomba 1
+hatalomra 1
+hatszorosa 1
+hatllyal 1
+hatlybalpstl 1
+hatlyon 1
+hatra 1
+hatrain 1
+hatrait 1
+hatrideje 1
+hatrozata 1
+hatrozathoz 1
+hatrozottsga 1
+hatroztak 1
+hatrozzk 1
+hatrszakasz 1
+hatrllomsok 1
+hatrra 1
+hatrtkelhelyek 1
+hatrtlpk 1
+hatrrizeti 1
+hatrrsgi 1
+hatsa 1
+hatsairl 1
+hatskrben 1
+hatskrrl 1
+hatskrk 1
+hatst 1
+hatkonyabb 1
+hatsgi 1
+hatsgokat 1
+hatsgokkal 1
+hatsgoknak 1
+hatsgokra 1
+havas 1
+havat 1
+havazsok 1
+hazahozatalra 1
+hazahvjk 1
+hazajtt 1
+hazatr 1
+hazatrt 1
+hazautalsainak 1
+hazaveznyeltk 1
+hazugsgon 1
+hegyei 1
+hegyi 1
+helikoptereikkel 1
+helyettese 1
+helyettk 1
+helyeztetik 1
+helyieknek 1
+helyileg 1
+helyisget 1
+helyre 1
+helyrelltani 1
+helyrelltjk 1
+helyrellts 1
+helyrelltsa 1
+helysznen 1
+helyszni 1
+helytelen 1
+helytllsban 1
+helyzetbe 1
+helyzetekben 1
+helyzetet 1
+helyzethez 1
+helyzeti 1
+helyzetrl 1
+helyzett 1
+helyn 1
+helykn 1
+helytt 1
+hengergetik 1
+hete 1
+heteken 1
+hetem 1
+hetilap 1
+hetilapja 1
+hetben 1
+hevesen 1
+hibbl 1
+hibja 1
+hibtlanul 1
+hibzott 1
+hidak 1
+hidakon 1
+hidat 1
+hideg 1
+hideghbor 1
+hideghbors 1
+hidegvre 1
+hihetetlenl 1
+hipnzisban 1
+hirdeti 1
+hirdettek 1
+hirdettk 1
+hirdet 1
+hiszek 1
+hiszem 1
+hitelcsomagot 1
+hiteleit 1
+hitelez 1
+hitelezi 1
+hitelezje 1
+hitelkeretrl 1
+hitelkptelensge 1
+hitelt 1
+hivatalban 1
+hivatallal 1
+hivatalnokok 1
+hivatalosan 1
+hivataltl 1
+hivatkoznak 1
+hivatott 1
+hibaval 1
+hinyai 1
+hinynak 1
+hinyt 1
+hinyz 1
+hinyrzetem 1
+hoc 1
+hogyha 1
+hollandok 1
+hollandokat 1
+holnap 1
+holttestet 1
+holttestre 1
+homokjt 1
+homoszexulisokat 1
+honvdelem 1
+honvdelmi 1
+hordoz 1
+hordtk 1
+hordnknt 1
+hosszan 1
+hosszas 1
+hoz 1
+hozhat 1
+hozni 1
+hozn 1
+hoznnak 1
+hoztk 1
+hozza 1
+hozzon 1
+hozzjuk 1
+hozzjrulhat 1
+hozzjrult 1
+hozzlttak 1
+hozznylni 1
+hozzsegtett 1
+hozzszokhattak 1
+hozztve 1
+hozzvetleg 1
+hull 1
+hullm 1
+hullmot 1
+humor 1
+huszonkt 1
+huszont 1
+hborban 1
+hborrl 1
+hbors 1
+hgai 1
+hgkat 1
+hl 1
+hljuk 1
+hlsak 1
+hl 1
+hls 1
+hlzatok 1
+hlzatn 1
+hlzatnak 1
+hny 1
+hrmas 1
+hromflekpp 1
+hromszzalkos 1
+hromves 1
+hrtani 1
+hrtja 1
+ht 1
+htgerincsrls 1
+htra 1
+htralv 1
+htrnybl 1
+htteret 1
+httrmagazinjnak 1
+hz 1
+hzhoz 1
+hziorvosok 1
+hztartsok 1
+hztetn 1
+hzt 1
+hztl 1
+hrosza 1
+htfi 1
+htre 1
+httag 1
+htvgkre 1
+hd 1
+hdig 1
+hr 1
+hreket 1
+hressgei 1
+hresztelsekkel 1
+hrhedten 1
+hrigazgatja 1
+hrmsorok 1
+hrosztlynak 1
+hrszerzsnek 1
+hrgynksg 1
+hrl 1
+hve 1
+hvni 1
+hvott 1
+hvsokat 1
+hvst 1
+hakadlyok 1
+hba 1
+hban 1
+hbuckkbl 1
+hcsapdba 1
+hfog 1
+hfvs 1
+hfvsok 1
+hlnc 1
+hlnccal 1
+hmar 1
+hmargpei 1
+hmentestsre 1
+hnapja 1
+hnapjaira 1
+hnapokkal 1
+hnapon 1
+hnapra 1
+htakart 1
+htorlasz 1
+htorlaszokon 1
+hval 1
+hvihar 1
+hzuhatag 1
+hs- 1
+hsipar 1
+hsipari 1
+hsz 1
+hszas 1
+hszezren 1
+hznak 1
+hzn 1
+hztak 1
+hzza 1
+hfokon 1
+hsk 1
+hsnkbl 1
+hsnket 1
+htipar 1
+ice 1
+ide 1
+ide-oda 1
+idegen 1
+idegrendszert 1
+idegllapotnak 1
+idejben 1
+idejt 1
+identitsnak 1
+idek 1
+idilli 1
+idnynek 1
+idzi 1
+idzte 1
+idhzsra 1
+idjrsa 1
+idjrst 1
+idkzben 1
+idlegesen 1
+idpontjrl 1
+idpontjt 1
+idrl 1
+idrl-idre 1
+idszakt 1
+idszer 1
+idvel 1
+ifj. 1
+ifj 1
+ifjsgi 1
+ifjt 1
+igazgat 1
+igazgatjnak 1
+igazgatjt 1
+igazgatn 1
+igazgatsgt 1
+igazgattancsban 1
+igazgattancsi 1
+igazgattancsba 1
+igazolni 1
+igazolst 1
+igazsgossg 1
+igazsgszolgltats 1
+igazuk 1
+igazbl 1
+igaztani 1
+igaztjk 1
+igaztva 1
+igenis 1
+igent 1
+igyekezhet 1
+igyekeztek 1
+igny 1
+ignybe 1
+ignye 1
+ignyeit 1
+ignyek 1
+ignyel 1
+ignyelnek 1
+ignyl 1
+ijesztgette 1
+illek 1
+illem 1
+illene 1
+illeti 1
+illetmnyalapot 1
+illetni 1
+illetkesei 1
+illetleg 1
+illen 1
+ily 1
+ilyeneket 1
+immunbetegsg 1
+import 1
+import-szeszesital 1
+imdjk 1
+incidens 1
+index 1
+individualistbb 1
+individuum 1
+indoklsban 1
+indokoljk 1
+indokoltk 1
+indulatok 1
+indulatokat 1
+induls 1
+indtanak 1
+indtott 1
+indtotta 1
+indtottak 1
+indtvnyozta 1
+indtvnyt 1
+inflcihoz 1
+inflcikiegyenltsben 1
+inflcitl 1
+informatikusokat 1
+informci 1
+informciszolgltatst 1
+informcirt 1
+infrastrukturlis 1
+infrastruktrja 1
+ingadozsai 1
+ingatlan 1
+ingatlanad 1
+ingatlanvagyonnak 1
+ingerlt 1
+ingus 1
+ingyenes 1
+ingyenesen 1
+ingzk 1
+innia 1
+integrlsa 1
+intellektus 1
+interj 1
+interjjban 1
+intermodlis 1
+intervallum 1
+intzett 1
+intzik 1
+intzkedsek 1
+intzkedseket 1
+intzkedsi 1
+intzkedssorozat 1
+intzkedst 1
+intzmny 1
+intzmnyben 1
+intzmnyeket 1
+intzmnyrendszer 1
+intzmnyrendszere 1
+ipar 1
+ipargat 1
+iparzsi 1
+irdatlan 1
+irgalmazzon 1
+irigy 1
+iroda 1
+irodt 1
+irtzom 1
+irnta 1
+irnyelvek 1
+irnyoz 1
+irnyul 1
+irnyul 1
+irnytja 1
+irnytott 1
+irnyts 1
+irnyti 1
+irny 1
+irnia 1
+iskolarett 1
+iskolba 1
+iskolskor 1
+ismeretes 1
+ismeretlensgre 1
+ismerhetik 1
+ismerkedtem 1
+ismerte 1
+ismertette 1
+ismertt 1
+ismerve 1
+ismtelni 1
+ismtelt 1
+isten 1
+iszlm 1
+iszlmbart 1
+iszlmistk 1
+iszogatnak 1
+itthoni 1
+itliai 1
+izgalmas 1
+izmiti 1
+izraeliek 1
+janurban 1
+janurjban 1
+javaslatokat 1
+javasol 1
+javasolja 1
+javasolta 1
+javult 1
+javulsnak 1
+javban 1
+jegybanki 1
+jegybankja 1
+jegyzettel 1
+jegyzi 1
+jegyzkben 1
+jegyrt 1
+jel 1
+jelek 1
+jelenben 1
+jelenik 1
+jelenltre 1
+jelenltben 1
+jelensge 1
+jelentene 1
+jelentenek 1
+jelentennek 1
+jelentet 1
+jelenthet 1
+jelentik 1
+jelentkezhetnek 1
+jelentkeztek 1
+jelentkez 1
+jelentkezt 1
+jelentseiben 1
+jelentseket 1
+jelentsben 1
+jelentsnek 1
+jelentsre 1
+jelentsket 1
+jelent 1
+jelentsgnek 1
+jelen 1
+jelkpes 1
+jelleggel 1
+jellemezte 1
+jellemeztk 1
+jellemzivel 1
+jelznek 1
+jelzt 1
+jelltje 1
+jelltjei 1
+jobbik 1
+jobbkzp 1
+jobbnak 1
+jog 1
+jogaikat 1
+jogersen 1
+jogokat 1
+jogon 1
+jogosult 1
+jogosultsgt 1
+jogost 1
+jogrendszerrel 1
+jogszably 1
+jogvd 1
+jogn 1
+jogsza 1
+jogszi 1
+jubileumi 1
+judaika-rvers 1
+judaisztika 1
+jugoszlviai 1
+juhokat 1
+juhszkutyk 1
+jussanak 1
+jutalmaznak 1
+juthat 1
+juthattak 1
+jutni 1
+juttassanak 1
+juttatta 1
+juttattak 1
+juttatsaik 1
+jut 1
+jrandsg 1
+jratai 1
+jrhatv 1
+jrmhz 1
+jrmpark 1
+jrmveiket 1
+jrmvek 1
+jrmvvel 1
+jrni 1
+jrta 1
+jrulnak 1
+jrst 1
+jrrre 1
+jrrzik 1
+jtssza 1
+jtszanak 1
+jtszani 1
+jtszanunk 1
+jtszhattam 1
+jtszhattunk 1
+jtszmt 1
+jtszottak 1
+jtszottunk 1
+jtszottk 1
+jtknap 1
+jtkosaira 1
+jtkosokat 1
+jtkostrsnak 1
+jtkszenvedlyembl 1
+jtkvezet 1
+jtkvezetn 1
+jtkban 1
+jk 1
+jkedv 1
+jkvnsgok 1
+jslata 1
+jsolnak 1
+jv 1
+jvhagysra 1
+jn 1
+jnne 1
+jvedelemcentralizci 1
+jvedelemkiegsztsi 1
+jvedelemptl 1
+jvedelmek 1
+jvedelmeket 1
+jvedelmekre 1
+jvkphez 1
+jliusi 1
+kabardok 1
+kabinetfnke 1
+kaland 1
+kalandjai 1
+kalandok 1
+kalandos 1
+kamara 1
+kamaraegyttes 1
+kamatadra 1
+kamatfizetsre 1
+kamatpolitika 1
+kamattmogats 1
+kamattmogatst 1
+kamerahasznlat 1
+kamerkra 1
+kamion 1
+kamionokra 1
+kampnya 1
+kampnyfogsknt 1
+kampnyolnia 1
+kampnynak 1
+kanadai 1
+kancellr 1
+kancellrja 1
+kancellrjnak 1
+kancellrnl 1
+kandall 1
+kandallk 1
+kantonizlst 1
+kantonoknak 1
+kantonokra 1
+kantonra 1
+kaotikus 1
+kapacitsaikat 1
+kapcsolat 1
+kapcsolatait 1
+kapcsolatba 1
+kapcsolatok 1
+kapcsolatokat 1
+kapcsolatokban 1
+kapcsolatokrl 1
+kapcsolatt 1
+kapcsolja 1
+kapcsold 1
+kapitalizcija 1
+kapjon 1
+kapni 1
+kapu 1
+kapusa 1
+kapusedznek 1
+kar 1
+karacsj-cserkesz 1
+karacsjokkal 1
+karacsjoknak 1
+karakterisztikus 1
+karambolt 1
+karitatv 1
+karon 1
+karrier 1
+karrieristk 1
+karcsonyfk 1
+karcsonyi 1
+katalgusbl 1
+katasztrfaelhrtsi 1
+katasztrft 1
+kategrij 1
+katona 1
+katonatiszt 1
+katont 1
+kaukzusi 1
+kavart 1
+kedvelem 1
+kedvelt 1
+kedves 1
+kedvez 1
+kedvezmnyes 1
+kedvezmnyezett 1
+kedvezbb 1
+kedvezbben 1
+kedvezek 1
+kedveztlen 1
+kedveztlenl 1
+kedvrt 1
+kefir 1
+kegyetlenkedseirl 1
+kegytrgy- 1
+kelet-eurpai 1
+keletkezhetnek 1
+keletkeznek 1
+keletnmetek 1
+kelt 1
+keltettk 1
+kemny 1
+kenyeret 1
+kerekedett 1
+keresetemelkeds 1
+keresetkiegszts 1
+kereshettem 1
+kereskedelmt 1
+kereskeds 1
+keresked 1
+keresleti 1
+keresletre 1
+keresnek 1
+keressk 1
+keresztbe 1
+keresztelkedjen 1
+keresztnydemokrata 1
+keresztl-kasul 1
+keres 1
+keretek 1
+kereteken 1
+keretlegnyek 1
+keretn 1
+kerknyomokbl 1
+kertett 1
+kertsek 1
+kerletekbl 1
+kerlhetett 1
+kerlni 1
+kerlnnek 1
+kerlk 1
+kerlvel 1
+kettvlsa 1
+kettvlst 1
+keverke 1
+keveset 1
+kezdemnyezett 1
+kezdemnyezheti 1
+kezdemnyezs 1
+kezdeni 1
+kezdetben 1
+kezdetnek 1
+kezdhette 1
+kezdtek 1
+kezdtem 1
+kezdsi 1
+kezddik 1
+kezddne 1
+kezddnek 1
+kezelheti 1
+kezelik 1
+kezelte 1
+kezeltk 1
+kezels 1
+kezelsre 1
+kezelsvel 1
+kezel 1
+kezeli 1
+kezeljk 1
+kezem 1
+kezessget 1
+kezessgvllals 1
+kezessgvllalst 1
+kezet 1
+kezhez 1
+kezn 1
+kft 1
+kht. 1
+ki- 1
+kiadni 1
+kiadvnya 1
+kiadvnyban 1
+kiadsa 1
+kiadsai 1
+kiadsokat 1
+kiadsunk 1
+kiadsban 1
+kiad 1
+kiagyali 1
+kialakulni 1
+kialakulshoz 1
+kialaktshoz 1
+kialaktsra 1
+kibocstshoz 1
+kibogarszniuk 1
+kicsempszni 1
+kicserltk 1
+kicsit 1
+kiderl 1
+kidolgozatlan 1
+kidolgozsa 1
+kidolgozi 1
+kiegyenltse 1
+kiegszlve 1
+kiejteni 1
+kiejtsrt 1
+kielgteni 1
+kiemelt 1
+kiemelten 1
+kiemeltnek 1
+kiemeltk 1
+kiesse 1
+kifejezetten 1
+kifejtette 1
+kifejtettk 1
+kifejtsre 1
+kifel 1
+kifizetetlen 1
+kifizetnie 1
+kifogyhatatlan 1
+kifogsoljk 1
+kifogsolt 1
+kifogsoltk 1
+kifogssal 1
+kifosztania 1
+kifutplyjt 1
+kihalt 1
+kihasznlni 1
+kihasznlnk 1
+kihasznltsga 1
+kihasznlva 1
+kihelyezseinek 1
+kihirdetni 1
+kiindulsi 1
+kiizzadni 1
+kijellte 1
+kijutott 1
+kijnni 1
+kik 1
+kikapcsolni 1
+kikezdtk 1
+kiknyszertse 1
+kikltztettk 1
+kikvetelje 1
+kilencven 1
+kilomterre 1
+kilomterrel 1
+kilbalni 1
+kilbalsnak 1
+kilbal 1
+kiltsaikat 1
+kiltket 1
+kils 1
+kimaradtak 1
+kimegy 1
+kimenekteni 1
+kimenektst 1
+kimondhatv 1
+kimondtk 1
+kimunklsa 1
+kimutathat 1
+kinevezni 1
+kineveztek 1
+kinnlevsgt 1
+kiolvasni 1
+kirendeltsgeihez 1
+kirobbant 1
+kirobbansrt 1
+kiruccans 1
+kirndulsok 1
+kis- 1
+kisbankban 1
+kisbefektet 1
+kisbefektetk 1
+kisebbik 1
+kisebbsg 1
+kisebbsgben 1
+kisgazdk 1
+kiskapuk 1
+kiskereskedelemben 1
+kismret 1
+kispnz 1
+kisugrzs 1
+kisvrosokban 1
+kisvrtatva 1
+kiszabadtsa 1
+kiszabott 1
+kiszabst 1
+kiszmthatatlan 1
+kiszmthatsgon 1
+kiszradt 1
+kitalljuk 1
+kitartknak 1
+kiterjedt 1
+kiterjedsvel 1
+kiterjed 1
+kiterjesztette 1
+kitermelsi 1
+kitr 1
+kitrse 1
+kitntetetteknek 1
+kitntets 1
+kitntetst 1
+kiutat 1
+kivel 1
+kivetett 1
+kivitel 1
+kiviteli 1
+kivizsglst 1
+kivizsgl 1
+kivonul 1
+kivonult 1
+kivonul 1
+kivlasztst 1
+kivlnak 1
+kivlt 1
+kivlt 1
+kivlsg 1
+kivsroltk 1
+kivgeztek 1
+kivtelek 1
+kivtelvel 1
+kizrja 1
+kizrt 1
+kizrta 1
+killt 1
+killtani 1
+killtsa 1
+killtsbl 1
+killtsnak 1
+killtsok 1
+killtsrl 1
+killtst 1
+killtsn 1
+killttermeket 1
+kilezdtek 1
+kiptst 1
+kirst 1
+kirtett 1
+kirlt 1
+kirlsnek 1
+klasszikus 1
+klinikai 1
+klubigazgatja 1
+klubok 1
+kluboknak 1
+klringelszmols 1
+kockzatos 1
+kocsija 1
+kocsinak 1
+kocsit 1
+kokettlt 1
+koldust 1
+kollgiumi 1
+kollgjnak 1
+kolozsvri 1
+kolozsvriak 1
+kommentlt 1
+kommentlta 1
+kommunikljanak 1
+kommunista 1
+kommunistk 1
+komorult 1
+kompenzciknt 1
+kompozcikat 1
+kompromittl 1
+koncentrcira 1
+koncentrltam 1
+koncentrlunk 1
+koncertanyagt 1
+koncertdarabjaim 1
+koncesszis 1
+konferenciatermet 1
+konfliktusok 1
+konfliktust 1
+konfrontci 1
+konglomertum 1
+konjunktra-dekonjunktra 1
+konjunktratesztjben 1
+konkrt 1
+konkurencia 1
+konkurencin 1
+konkurens 1
+konstellcik 1
+konstrukciban 1
+konszolidldsra 1
+kontakt 1
+kontinensvetlked 1
+kontinensvetlkedt 1
+konvenci 1
+konvertibilis 1
+konvertlhat 1
+konvojgy 1
+konzervgyr 1
+konzervgyrak 1
+konzerviparban 1
+konzorciumnak 1
+koordinlt 1
+korban 1
+kordban 1
+koreai 1
+korhatr 1
+korltait 1
+korltlanul 1
+korltozni 1
+korltozott 1
+korltozza 1
+korltozsok 1
+korltozsokat 1
+kormny-elterjesztss 1
+kormnybizottsg 1
+kormnycsapatok 1
+kormnyfi 1
+kormnyhatrozat 1
+kormnyjavaslatokbl 1
+kormnykoalci 1
+kormnykoalcis 1
+kormnynl 1
+kormnyok 1
+kormnyokat 1
+kormnyprogramban 1
+kormnyprti 1
+kormnyprtok 1
+kormnyra 1
+kormnyvlts 1
+kormnyzat 1
+kormnynak 1
+kormnylst 1
+koronba 1
+koront 1
+korosztly 1
+korosztlyban 1
+korrektsgen 1
+korrumplsval 1
+korszakot 1
+korszer 1
+korszersggel 1
+korszersd 1
+kort 1
+kor 1
+kornl 1
+koszorn 1
+kozmetikzsval 1
+krachbl 1
+kreatv 1
+krelt 1
+kritika 1
+kritikus 1
+krzis 1
+krzisei 1
+kudarca 1
+kudarcot 1
+kulcsfontossg 1
+kulcsjtkosai 1
+kultikus 1
+kultikust 1
+kulturlis-trtneti 1
+kultusza 1
+kultusztrca 1
+kultrk 1
+kumikok 1
+kupadntt 1
+kuratriuma 1
+kutatott 1
+kutatva 1
+kutatsi 1
+kutati 1
+kutatk 1
+kutyk 1
+kuvaszok 1
+kvtarendszer 1
+kvthoz 1
+kvtt 1
+kdereket 1
+klyhagyrt 1
+klyhk 1
+kosz 1
+krok 1
+krokat 1
+krokkal 1
+krokrl 1
+krptolhatja 1
+ktybl 1
+kvhzi 1
+kvsznetre 1
+kl 1
+kmhistrijukhoz 1
+kmkedtek 1
+knyelmetlenebb 1
+knyszerlells 1
+knyszertl 1
+knyszertsk 1
+knyszertse 1
+knyszerlhet 1
+knytelen 1
+kpeket 1
+kpesek 1
+kpessgeiket 1
+kpet 1
+kpeznie 1
+kpeztek 1
+kptelenek 1
+kpviselett 1
+kpviselik 1
+kpviselhzat 1
+kpviseli 1
+kpviselibl 1
+kpviselinek 1
+kpviselt 1
+kpviselvel 1
+kpzeletszlte 1
+kpzeltek 1
+kpzse 1
+kpzmvszei 1
+kpn 1
+krdezhetn 1
+krdezn 1
+krdezte 1
+krdsei 1
+krdseiben 1
+krdseket 1
+krdsrl 1
+krdsben 1
+krdst 1
+krdsnkre 1
+kri 1
+krik 1
+krlelik 1
+krnek 1
+krnie 1
+kr 1
+ksik 1
+kstek 1
+kszek 1
+kszenltben 1
+kszenltihitel-megllapodshoz 1
+kszfizet 1
+kszleteinek 1
+kszpnzben 1
+kszpnznek 1
+kszpnzt 1
+kszsgt 1
+ksztermk 1
+ksztermkrak 1
+ksztenek 1
+ksztsekor 1
+ksztsnl 1
+kszt 1
+kszti 1
+kszlhetett 1
+kszlnek 1
+kszlni 1
+kszlnnek 1
+kszltsg 1
+kszltsgben 1
+kszlk 1
+kszlkkel 1
+ksseket 1
+ksssel 1
+ks 1
+ksbbiekben 1
+ksn 1
+kt-hrom 1
+ktharmados 1
+ktmillird 1
+ktnapos 1
+ktnyelv 1
+ktosztat 1
+ktszzezer 1
+ktszztven 1
+ktsgbe 1
+ktsgtelen 1
+ktvesen 1
+kzben 1
+kzbentartsa 1
+kzenfekv 1
+kzhezvtele 1
+kzi 1
+kzigrntokat 1
+kziratok 1
+kzre 1
+kmletlen 1
+knljk 1
+ksr 1
+ksrte 1
+ksrzeni 1
+ksrzenje 1
+kvncsi 1
+kvnnak 1
+kvnsgnak 1
+kvnunk 1
+kdja 1
+kkuszsznyegre 1
+kmban 1
+krhz 1
+krhzukban 1
+krokoz 1
+kbmter 1
+kbmterre 1
+kdsts 1
+klcsnt 1
+klcsnztt 1
+klcsnsen 1
+klcsnssge 1
+kltsgei 1
+kltsgek 1
+kltsgvetsbe 1
+kltsgvetsbl 1
+kltsgvetsekbl 1
+kltsgvetsknt 1
+kltsgvetsnek 1
+kltsgt 1
+knnyebb 1
+knnyedn 1
+knynyezett 1
+knyvben 1
+knyve 1
+knyvek 1
+knyvritkasg 1
+knyvtr 1
+knyvviteli 1
+knyrtelen 1
+knyrgnek 1
+krbe-krbe 1
+krbevettk 1
+krbl 1
+kre 1
+krgyrt 1
+krnyezeti 1
+krnyezetvdelmi 1
+krnykbeli 1
+krnyken 1
+krnyki 1
+krnykt 1
+krvonalazdna 1
+krzetbe 1
+krzetben 1
+krzethez 1
+kr 1
+krben 1
+krkre 1
+krti 1
+krtnak 1
+krlmnyei 1
+krlmnyeinek 1
+krlmnyekrl 1
+krlvett 1
+krltte 1
+ksznhetem 1
+kszntik 1
+ktelessge 1
+ktelessgk 1
+ktelezettsgekkel 1
+ktelezte 1
+ktetlen 1
+ktvny 1
+ktttek 1
+ktttk 1
+ktdjn 1
+ktdnek 1
+kvessenek 1
+kvetel 1
+kvetelik 1
+kvetelmnyeket 1
+kvetels 1
+kvetett 1
+kveti 1
+kvetik 1
+kvetkezetes 1
+kvetkezett 1
+kvetkezmny 1
+kvetkezmnyeire 1
+kvetkezmnyeit 1
+kvettek 1
+kvetnek 1
+kzakaratra 1
+kzalkalmazotti 1
+kzbeszerzsi 1
+kzbeszd 1
+kzbeszdben 1
+kzcl 1
+kze 1
+kzegbe 1
+kzelg 1
+kzeljvben 1
+kzelmlt 1
+kzelt 1
+kzeltik 1
+kzeltsre 1
+kzepes 1
+kzepesnl 1
+kzepette 1
+kzepn 1
+kzforgalm 1
+kzgazdszok 1
+kzgylse 1
+kzhangulatnak 1
+kzhivatalnoktl 1
+kzhivataltl 1
+kzismert 1
+kzkedvelt 1
+kzlekedett 1
+kzlekedhet 1
+kzlekedni 1
+kzlekedsre 1
+kzlekedst 1
+kzlekedsnek 1
+kzlemnyre 1
+kzls 1
+kzlsek 1
+kzmkivlts 1
+kznemesek 1
+kzoktats 1
+kzpontilag 1
+kzpontja 1
+kzpontjai 1
+kzpontjban 1
+kzre 1
+kzreadtk 1
+kzremkdssel 1
+kzszerepl 1
+kzszolglati 1
+kzsg 1
+kzsgekben 1
+kztartozsaik 1
+kzteherviselst 1
+kztiszteletnek 1
+kztrsasgba 1
+kztrsasgban 1
+kztrsasgbl 1
+kztrsasgban 1
+kzvettett 1
+kzvettik 1
+kzvettsben 1
+kzvlemny-kutatsok 1
+kzvlemnyt 1
+kzztett 1
+kzllapotokba 1
+kzletbl 1
+kzp-kelet-eurpai 1
+kzp-szerbiai 1
+kzpkategrij 1
+kzpvllalkozsok 1
+kzlje 1
+kznsge 1
+kznsget 1
+kzssgi 1
+kzttieket 1
+kzthlzat 1
+kztkezel 1
+kldi 1
+kldjk 1
+kldte 1
+kldtek 1
+kldttsge 1
+klfldrl 1
+klfldn 1
+klkereskedelem 1
+klkereskedelme 1
+klkpviselet 1
+klvilggal 1
+klnben 1
+klnbsgek 1
+klnbsget 1
+klnbzsgt 1
+klnmegbzott 1
+klnvonatnak 1
+klgyminiszteri 1
+klgyminiszterrel 1
+klgyminisztriumtl 1
+kszkdtt 1
+kzdelmek 1
+kzdelmeket 1
+kzdelmket 1
+kzdenek 1
+kzdenie 1
+kzdttek 1
+kzdszellemnek 1
+kdarab 1
+kolajimportot 1
+kolajra 1
+kolajtermkekre 1
+labdargs-fejlesztsi 1
+labdarg-mrkzseket 1
+labdarg-szvetsg 1
+labdra 1
+labdt 1
+labdval 1
+lakhatatlan 1
+lakosa 1
+lakosokat 1
+lakossgi 1
+lakost 1
+lakozott 1
+laksban 1
+lakit 1
+lakitl 1
+lakja 1
+lankad 1
+lapockaveregetssel 1
+lappang 1
+lapzrtnkkor 1
+lapt 1
+laprteslsek 1
+lassan 1
+lassult 1
+lass 1
+le-lecsukdik 1
+leadtk 1
+lebegett 1
+lebontottk 1
+lebontsnak 1
+lebonyoltani 1
+leblyegzse 1
+lecskkent 1
+lefedi 1
+lefjn 1
+lefjst 1
+legbksebbnek 1
+legeltetik 1
+legenda 1
+legendnak 1
+legersebb 1
+legfelkszltebb 1
+leggazdagabb 1
+leggyorsabb 1
+leghamarabb 1
+legkemnyebb 1
+legkisebb 1
+legksbb 1
+leglnyegesebb 1
+legmltbbnak 1
+legmlyebben 1
+legnehezebb 1
+legnpesebb 1
+legoptimistbbak 1
+legritkbb 1
+legrosszabb 1
+legsimbb 1
+legstabilabb 1
+legszebben 1
+legslyosabb 1
+legtbbet 1
+legtbbszr 1
+legutols 1
+legutbb 1
+legyzhetetlen 1
+legyzhetetlennek 1
+legzsrosabb 1
+legltalnosabb 1
+legjabb 1
+lehessen 1
+lehetetlen 1
+lehetleg 1
+lehetsge 1
+lehetsgeit 1
+lehetsgekrl 1
+lehetsgk 1
+lehlt 1
+lejrat 1
+lejtssza 1
+lekerlt 1
+lektora 1
+lelassult 1
+leleplezseit 1
+lelkes 1
+lelkeseds 1
+lelkesen 1
+lelklet 1
+lelte 1
+leltek 1
+lelpett 1
+lemaradtak 1
+lemez- 1
+lemezfelvtel 1
+lemonds 1
+lemondsra 1
+lemondst 1
+lendletet 1
+lengyeleknl 1
+lenni 1
+leromlottakat 1
+leszakadt 1
+leszek 1
+leszerelse 1
+leszlltott 1
+leszlltotta 1
+leszgezi 1
+leszgezte 1
+lesznk 1
+letartztatsban 1
+letartztatst 1
+leteltvel 1
+leteszik 1
+lettem 1
+lettbe 1
+letltend 1
+letlttt 1
+letrse 1
+levegbe 1
+levele 1
+levelt 1
+levetette 1
+levezetse 1
+levonva 1
+levltott 1
+levlben 1
+lezratta 1
+lezrtk 1
+lezrst 1
+lelltani 1
+lenyvllalatok 1
+lenyvllalatbl 1
+leptst 1
+lepls 1
+lertkeldsbl 1
+lerhatatlan 1
+lertak 1
+libasorban 1
+liberalizci 1
+liberalizlja 1
+liberalizld 1
+licence 1
+licitet 1
+likviditsi 1
+limina 1
+listja 1
+listkon 1
+listt 1
+literenknti 1
+lobbantja 1
+lobogott 1
+lokalizldtak 1
+lokomotvknt 1
+lomposan 1
+londoni 1
+luxemburgi 1
+lyukasztgats 1
+lb 1
+lba 1
+lbainl 1
+lbal 1
+lbbeli-kiskereskedelmi 1
+lm 1
+lnc 1
+lncokkal 1
+lncreakcit 1
+lngba 1
+lngjait 1
+lngok 1
+lngokban 1
+lngra 1
+lnyt 1
+lsd 1
+lthatatlannak 1
+lthattk 1
+lthatk 1
+lthatv 1
+ltja 1
+ltjuk 1
+ltnak 1
+ltn 1
+ltogasson 1
+ltogatsa 1
+ltogatsuk 1
+ltogatsnak 1
+ltogat 1
+ltogatit 1
+ltogatkra 1
+ltott 1
+ltszanak 1
+ltsz 1
+lttatja 1
+lttk 1
+ltva 1
+ltvn 1
+ltvnny 1
+ltvnya 1
+ltvnyos 1
+ltvnyossg 1
+lza 1
+lggmb 1
+lgideszantost 1
+lgier 1
+lgikzlekedsi 1
+lgkr 1
+lgkrt 1
+lgslyban 1
+lgzsi 1
+lggyi 1
+llegeztet 1
+llektl 1
+lnyege 1
+lnyeges 1
+lnyegesebb 1
+lnyrl 1
+lpcsjig 1
+lpcsjrl 1
+lphettem 1
+lpni 1
+lpnie 1
+lpsben 1
+lpst 1
+lp 1
+ltesteni 1
+ltestmny 1
+ltestmnyt 1
+lteslt 1
+ltezik 1
+ltfontossg 1
+ltrehozst 1
+ltrejtte 1
+ltszma 1
+ltszmcskkentst 1
+ltszmnak 1
+ltt 1
+lzerirnyts 1
+lrvi 1
+lkst 1
+lvssel 1
+lvszdandr 1
+lvst 1
+madrcsont 1
+maffia 1
+maffizk 1
+magabiztosan 1
+magasak 1
+magaslatn 1
+magasztos 1
+magasptssel 1
+magazinjt 1
+maguk 1
+magukv 1
+magyar-romn 1
+magyar-ukrn 1
+magyardemokratk 1
+magyarul 1
+magyarzta 1
+magzatelhajtst 1
+magban 1
+magnbnbe 1
+magngazdasgban 1
+magngyjtemny 1
+magnlevelet 1
+magnlevl 1
+magnosts 1
+magnszemly 1
+magnszemlyknt 1
+magnvlemnyknt 1
+magnyosan 1
+magnntdben 1
+magrl 1
+magtl 1
+magval 1
+magrt 1
+magt 1
+majdnem 1
+malom- 1
+malj 1
+mamutcg 1
+mamutvllalkozsok 1
+manapsg 1
+manchesteri 1
+manipulltsgt 1
+manufakturlis 1
+maradand 1
+maradhat 1
+maradjanak 1
+maradtak 1
+maradk 1
+marketingigazgatja 1
+marosvsrhelyi 1
+marsall 1
+marsallnak 1
+margp 1
+materben 1
+matracot 1
+meccs 1
+meccseit 1
+meccsrl 1
+meddig 1
+megadztatsrl 1
+megakadhat 1
+megakadlyozni 1
+megakadlyozta 1
+megakaszthatja 1
+megalakult 1
+megalakulsa 1
+megalapt 1
+megalztats 1
+megannyi 1
+megbeszlsen 1
+megbetegedseket 1
+megbklst 1
+megbnult 1
+megbntotta 1
+megbzhatsggal 1
+megbzsbl 1
+megcsfolta 1
+megduplzdott 1
+megegyezett 1
+megegyezik 1
+megegyezssel 1
+megegyez 1
+megelgedett 1
+megelgelte 1
+megelzend 1
+megelzi 1
+megelzst 1
+megemszteni 1
+megenyhlt 1
+megersdtek 1
+megesik 1
+megeszik 1
+megfelel 1
+megfelelni 1
+megfelelt 1
+megfelelnek 1
+megfellebbezte 1
+megfenyegetik 1
+megfenyegette 1
+megfigyels 1
+megfigyelsi 1
+megfigyelk 1
+megfogadjk 1
+megfogadtam 1
+megfogadtk 1
+megfogyatkozott 1
+megfontolsaikat 1
+megfontolsokbl 1
+megformls 1
+megformlsa 1
+megflemlts 1
+meggyilkoltak 1
+meggyzen 1
+meggtolni 1
+meghaladja 1
+meghaladni 1
+meghallgathatja 1
+meghallgatja 1
+meghallgatta 1
+meghatrozn 1
+meghatroz 1
+meghatroznak 1
+meghirdetett 1
+meghirdettk 1
+meghosszabbtsk 1
+meghosszabbtsa 1
+meghozatala 1
+meghozatalval 1
+meghtrlt 1
+meghvsa 1
+megindul 1
+megindult 1
+megingott 1
+megismerkedst 1
+megismertk 1
+megismerse 1
+megismtli 1
+megismtlse 1
+megismtlst 1
+megjelentek 1
+megjelensvel 1
+megjelents 1
+megjrt 1
+megjsolhat 1
+megjsolni 1
+megkaphassk 1
+megkapta 1
+megkereste 1
+megkezddtek 1
+megkezddtt 1
+megkockztathat 1
+megkrdezett 1
+megkrdjelezhet 1
+megkrdjelezdik 1
+megksrelte 1
+megktsekor 1
+megkttt 1
+megkvetelt 1
+megkveti 1
+meglehetsen 1
+meglengettk 1
+meglepetscsapata 1
+meglepetse 1
+meglepetsre 1
+megmagyarzni 1
+megmarad 1
+megmenteni 1
+megmenthesse 1
+megmentsre 1
+megmunklsnak 1
+megmutatja 1
+megmutatjk 1
+megmutatkozsa 1
+megmutatkozstl 1
+megmutatni 1
+megmutatta 1
+megmrkzm 1
+megmrkztt 1
+megnyilvnulsa 1
+megnyilvnul 1
+megnyirblshoz 1
+megnyitja 1
+megnyitott 1
+megnyitottk 1
+megnyitsnak 1
+megnyugtatan 1
+megnylt 1
+megoldani 1
+megoldotta 1
+megoldsairl 1
+megoldst 1
+megoldshoz 1
+megoldst 1
+megosztottsg 1
+megosztottsgt 1
+megosztsrl 1
+megosztst 1
+megosztst 1
+megprbljk 1
+megprblkoztak 1
+megprbltatsairl 1
+megragadhatja 1
+megrakott 1
+megrendtheti 1
+megromlott 1
+megromlshoz 1
+megrostlta 1
+megrz 1
+megsebeslt 1
+megsebesltek 1
+megsemmists 1
+megsemmistsben 1
+megsemmistst 1
+megsprolsra 1
+megszabni 1
+megszaktst 1
+megszavazni 1
+megszavazn 1
+megszerettk 1
+megszerezzen 1
+megszervezse 1
+megszerzett 1
+megszerzse 1
+megszorongatst 1
+megszortsait 1
+megszortsok 1
+megszort 1
+megszgyentsek 1
+megszptheti 1
+megszlalnak 1
+megszlethet 1
+megszletshez 1
+megszntetve 1
+megszntets 1
+megszntetsekre 1
+megsznne 1
+megszntek 1
+megszn 1
+megsrtse 1
+megtallhatjk 1
+megtalltk 1
+megtanult 1
+megtapasztaltk 1
+megtehetne 1
+megtekinthetik 1
+megtekinthetk 1
+megteremtshez 1
+megteremtsnek 1
+megteremtst 1
+megtette 1
+megtiltotta 1
+megtiltottk 1
+megtilt 1
+megtudta 1
+megtlteni 1
+megtrtnhet 1
+megtrtnhetsnek 1
+megtrtnt 1
+megvalstani 1
+megvalstsban 1
+megvenni 1
+megverte 1
+megviseltk 1
+megvizsglja 1
+megvontk 1
+megvltoztak 1
+megvsrolhatk 1
+megvdte 1
+megvtelre 1
+meglltam 1
+meglltani 1
+megtalkodott 1
+meglhetshez 1
+meglni 1
+megpteni 1
+megptsben 1
+megptst 1
+megplni 1
+megplt 1
+megrkeznek 1
+megrkezni 1
+megrkezs 1
+megrt 1
+megrzs 1
+megrt 1
+meglttek 1
+megrltek 1
+megszta 1
+megsztuk 1
+megsztk 1
+megrzsvel 1
+mekkora 1
+meleg 1
+melegsg 1
+melletti 1
+mellkasukig 1
+mellki 1
+mellktvonalon 1
+melyben 1
+melybl 1
+melyeket 1
+memorandumot 1
+menedzserek 1
+menedzsment 1
+menedket 1
+menekls 1
+meneklsi 1
+meneklsrl 1
+menetre 1
+mennek 1
+mennem 1
+menni 1
+mennyire 1
+mennyisget 1
+mentette 1
+mentettk 1
+menti 1
+ments 1
+mentsben 1
+mentsi 1
+mentsirnyts 1
+mentk 1
+mentszolglat 1
+mentvet 1
+meredekebb 1
+meredeken 1
+merengett 1
+merre 1
+mertek 1
+mernylethez 1
+mernyletre 1
+merben 1
+meseaut 1
+meseelem 1
+mester 1
+mestere 1
+mestersgbeli 1
+meskre 1
+mesli 1
+meslnek 1
+metrt 1
+mezgazdasgi 1
+mezgazdasgot 1
+meznyben 1
+meznyt 1
+mibl 1
+midibusz 1
+midibuszainl 1
+midibuszokba 1
+mieltt 1
+miknt 1
+mikppen 1
+millirdnyi 1
+millirdos 1
+millirdot 1
+millian 1
+milliban 1
+millit 1
+minapi 1
+mindazokhoz 1
+mindeddig 1
+mindegyik 1
+mindekzben 1
+mindenbe 1
+mindenek 1
+mindenfle 1
+mindennapi 1
+mindennel 1
+mindezt 1
+mindmig 1
+miniatr 1
+minimlbrnl 1
+minimlzenhez 1
+minisztere 1
+miniszterek 1
+miniszterelnk-helyettes 1
+miniszterelnk-helyettessel 1
+miniszterelnkkel 1
+miniszterelnknek 1
+minisztert 1
+minisztrium 1
+minisztriumi 1
+minisztriumhoz 1
+minthogy 1
+minsge 1
+minstettk 1
+miszerint 1
+mivoltra 1
+miltal 1
+mobiltelefonok 1
+mocskos 1
+modern 1
+modernizci 1
+modor 1
+mondani 1
+mondanivalja 1
+mondan 1
+mondat 1
+mondataiban 1
+mondatok 1
+mondhat 1
+mondhatnak 1
+mondhatni 1
+mondjon 1
+mondjk 1
+mondtak 1
+mondtam 1
+monetris 1
+monolitikus 1
+monstrum 1
+montenegri 1
+montenegriak 1
+moratriumot 1
+mosolyog 1
+mosonmagyarvri 1
+mostanra 1
+mostoha 1
+motorbenzinre 1
+motorcsnakon 1
+motorja 1
+motoron 1
+mozaikszer 1
+mozdulat 1
+mozdulhattak 1
+mozgatsa 1
+mozgatsval 1
+mozgst 1
+mozgst 1
+mozinzk 1
+mozivsznon 1
+mulattat 1
+mullah 1
+mumifiklt 1
+munka 1
+munkaadknak 1
+munkaer 1
+munkaerrt 1
+munkagp 1
+munkahelyeken 1
+munkahelyeket 1
+munkahelyi 1
+munkahelyrl 1
+munkaignyesnek 1
+munkalehetsg 1
+munkanlkli 1
+munkanlkli-jrulkot 1
+munkanlklisg 1
+munkaszervezssel 1
+munkaszzad 1
+munkatrsa 1
+munkatrsainak 1
+munkatrstl 1
+munkavllalk 1
+munkavllalkat 1
+munkavgzsrt 1
+munkba 1
+munkik 1
+munkim 1
+munkimmal 1
+munkjba 1
+munkjn 1
+munkjrl 1
+munkltathoz 1
+munkm 1
+munkmat 1
+munkssgrl 1
+munkrt 1
+muncit 1
+musicaljben 1
+muszlimok 1
+mutassk 1
+mutatta 1
+mutattak 1
+mutattk 1
+mutats 1
+muzelis 1
+muzsika 1
+muzsikus-zeneszerz 1
+muzsikusok 1
+muzsikkkal 1
+muzsikm 1
+muzsiknak 1
+muzsikt 1
+mjusrl 1
+mr-mr 1
+mrcius 1
+mrciusban 1
+mrciusra 1
+mrka 1
+mrkanv 1
+mrktl 1
+mrmint 1
+mrtrokat 1
+ms-ms 1
+msfl-ktszeres 1
+msikrl 1
+mskor 1
+msknt 1
+msnak 1
+msodpercen 1
+msokat 1
+mssal 1
+msznak 1
+mdiahatsg 1
+mghozz 1
+mgpedig 1
+mlt 1
+mltan 1
+mly 1
+mlyrepls 1
+mlysgbe 1
+mlypts 1
+mretekben 1
+mrgeldik 1
+mrgezsi 1
+mrkzseire 1
+mrkzsek 1
+mrkzsen 1
+mrkzssel 1
+mrkzsre 1
+mrlegbl 1
+mrlege 1
+mrleggel 1
+mrni 1
+mrskeljk 1
+mrsklse 1
+mrskl 1
+mrskldik 1
+mrskldtt 1
+mrt 1
+mrtek 1
+mrtkadnak 1
+mrtke 1
+mrtkhez 1
+mrtkkel 1
+mrtknek 1
+mrtkt 1
+mterre 1
+mterrel 1
+mtoszait 1
+mtoszrendszer 1
+mves 1
+md 1
+mdja 1
+mdostani 1
+mdosts 1
+mdostsok 1
+mdostsrl 1
+mdostsval 1
+mdot 1
+mdozatait 1
+mdszer 1
+mdszereit 1
+mdszereket 1
+mdszerhez 1
+mdszert 1
+mgtti 1
+mlik 1
+mltat 1
+mltjval 1
+mncheni 1
+m 1
+mfajbl 1
+mfajban 1
+mfordtsban 1
+mhely 1
+mkincseinek 1
+mkincsek 1
+mkdjn 1
+mkdnek 1
+mkdni 1
+mkdtetsi 1
+mkdse 1
+mkdsben 1
+mkdsn 1
+mkdtt 1
+mkd 1
+mkdk 1
+mrl 1
+msora 1
+msornak 1
+msorokat 1
+msoroknak 1
+msorukkal 1
+msorra 1
+mszak 1
+mszakjukat 1
+mszer 1
+mteremben 1
+mtrgy-aukciknak 1
+mve 1
+mveimrl 1
+mveit 1
+mveivel 1
+mvet 1
+mvnek 1
+mvsz 1
+mvszetkhz 1
+mvszi 1
+mvszknt 1
+mvsznevem 1
+na 1
+nadrgszjat 1
+nagy- 1
+nagyapjnak 1
+nagyban 1
+nagyfok 1
+nagyhatalmak 1
+nagyhatalom 1
+nagykvete 1
+nagykveti 1
+nagykvetsgnek 1
+nagykvetvel 1
+nagymret 1
+nagypolitikban 1
+nagysga 1
+nagysgrl 1
+nagyvonal 1
+nagyvllalat 1
+nagyvllalatok 1
+nagyvllalkozsok 1
+nagyvrosokban 1
+nagygyk 1
+nagyrdem 1
+nagyzem 1
+napban 1
+napilapnak 1
+napirend 1
+napirendjn 1
+napirendrl 1
+napja 1
+napjt 1
+napkzben 1
+napok 1
+napokig 1
+narancssrga 1
+negatvokat 1
+negyedbe 1
+negyedszzaddal 1
+negyedt 1
+negyvenen 1
+negyvent 1
+neheze 1
+nehzkes 1
+nehzsly 1
+nemesebb 1
+nemesedett 1
+nemesi 1
+nemessg 1
+nemfizetsek 1
+nemhogy 1
+nemkvnatos 1
+nemzet 1
+nemzete 1
+nemzetisg 1
+nemzetisg 1
+neve 1
+nevelked 1
+nevem 1
+nevez 1
+nevezetesen 1
+nevezettek 1
+nevezik 1
+neveztk 1
+nevezsi 1
+nevben 1
+nevhez 1
+nevn 1
+nevrl 1
+nevt 1
+nevkhz 1
+newspeak 1
+nisi 1
+no 1
+nominlisan 1
+normatvk 1
+norvgot 1
+novemberi 1
+novemberre 1
+novemberben 1
+numerus 1
+nyalogathatja 1
+nyelven 1
+nyelvtudomnyok 1
+nyer 1
+nyeregben 1
+nyeresges 1
+nyers 1
+nyersanyag 1
+nyersanyagrt 1
+nyerte 1
+nyertek 1
+nyerautomatnl 1
+nyersorozattal 1
+nyilatkozat 1
+nyilatkozata 1
+nyilatkozatokat 1
+nyilatkozatt 1
+nyilatkozni 1
+nyilatkozott 1
+nyilatkozta 1
+nyilatkozva 1
+nyilvnos 1
+nyilvnosan 1
+nyilvnossgban 1
+nyilvnval 1
+nyit 1
+nyitotta 1
+nyitottk 1
+nyitva 1
+nyolcadikok 1
+nyolcas 1
+nyolcszz 1
+nyomai 1
+nyomatkot 1
+nyomdokain 1
+nyomorsgra 1
+nyomot 1
+nyomott 1
+nyomozs 1
+nyomozst 1
+nyomtatott 1
+nyomban 1
+nyomsra 1
+nyomsra 1
+nyugatnmet 1
+nyugdj-biztostsi 1
+nyugdjasok 1
+nyugdjkorhatrt 1
+nyugovra 1
+nyugtalant 1
+nyri 1
+nyron 1
+nyjtand 1
+nyjtanunk 1
+nyjthatnak 1
+nyjtjk 1
+nyjtsanak 1
+nyjtsra 1
+nyjt 1
+nci 1
+ngy- 1
+ngyes 1
+ngyessel 1
+ngyet 1
+ngyszz 1
+ngyszgestsvel 1
+ngytag 1
+ngyzetkilomter 1
+ngyzetmter 1
+ngyzett 1
+ngyves 1
+nktek 1
+nlkle 1
+nlkliek 1
+nlklzhetetlen 1
+nlklz 1
+nmely 1
+nmeteknek 1
+nmeteknl 1
+nmileg 1
+npei 1
+npek 1
+npekhez 1
+npessget 1
+npessggel 1
+npszerbb 1
+npszersge 1
+npszoks 1
+npszmlls 1
+nvrtknl 1
+nzegette 1
+nzem 1
+nzetazonossg 1
+nzeteltrs 1
+nzettsgi 1
+nzettsgnek 1
+nzhetnek 1
+nzlek 1
+nznik 1
+nztk 1
+nzket 1
+nznek 1
+nvekedett 1
+nvekedjen 1
+nvekednek 1
+nvekedni 1
+nvekednnek 1
+nvekedsben 1
+nvelhetik 1
+nveli 1
+nveln 1
+nvelte 1
+nvelsrl 1
+ni 1
+nk 1
+nkkel 1
+nknek 1
+nknl 1
+nt 1
+odaveznyeltek 1
+okai 1
+okokbl 1
+okokkal 1
+okolta 1
+okoltk 1
+okoz 1
+okozhasson 1
+okozhat 1
+okozna 1
+okoznak 1
+okoztak 1
+okoz 1
+okozi 1
+okra 1
+oktats 1
+oktberi 1
+olajat 1
+olajbnyszati 1
+olajcgek 1
+olajmez 1
+olajmillirdos 1
+olajtartlyokra 1
+olajvezetkben 1
+olajvllalat 1
+olajron 1
+olaszokkal 1
+olaszokra 1
+olcs 1
+oldalas 1
+oldalirnyban 1
+oldalrl 1
+oldals 1
+oldalra 1
+oldalrl 1
+olimpiai 1
+olvastam 1
+olvask 1
+ominzus 1
+opcit 1
+operahzi 1
+operasznpadon 1
+operatvan 1
+operanekes 1
+operettet 1
+operban 1
+operja 1
+operkat 1
+operland 1
+operlja 1
+operltk 1
+optimistbbak 1
+optimizmus 1
+opusz 1
+orahovaci 1
+oratriumszlista 1
+ordas 1
+ordibltak 1
+orosz-csecsen 1
+oroszokkal 1
+oroszt 1
+orra 1
+orszgaiban 1
+orszgainkat 1
+orszgban 1
+orszgbl 1
+orszghatrokon 1
+orszgnak 1
+orszgokat 1
+orszgot 1
+orvosbl 1
+orvoscsoport 1
+orvosnak 1
+orvosunk 1
+osli 1
+osszanak 1
+ostromt 1
+oszlatja 1
+osztani 1
+osztatlan 1
+osztja 1
+osztott 1
+osztottk 1
+osztoznak 1
+osztlya 1
+osztlyban 1
+osztlyhoz 1
+osztlyokon 1
+osztlyozkat 1
+osztlyra 1
+osztlyt 1
+osztlynak 1
+osztsval 1
+ottani 1
+otthoni 1
+otthoniaknak 1
+otthonmaradsra 1
+otthonokban 1
+otthont 1
+otthontalann 1
+otthonteremts 1
+otthonuk 1
+otthonukbl 1
+pajzsknt 1
+pakurra 1
+panaszkodnak 1
+panaszkodott 1
+panaszradat 1
+paprok 1
+papron 1
+parancsnok 1
+parancsnokai 1
+parancsol 1
+parkolhassanak 1
+parkolba 1
+parkolban 1
+parkolhely 1
+parkolkkal 1
+partizn 1
+partizn-mdit 1
+partiznhbor 1
+partnervel 1
+partvidkn 1
+pasas 1
+passzolni 1
+patthelyzet 1
+pedaggusknt 1
+pedaggust 1
+pehelysly 1
+perben 1
+percekre 1
+percet 1
+pergethetik 1
+perverzeknek 1
+perjrafelvtel-kezdemnyeznek 1
+perjrafelvtelhez 1
+perjrafelvtelt 1
+pesszimista 1
+pesszimistk 1
+piacgazdasg 1
+piacok 1
+piacokrt 1
+piacot 1
+piacvezet 1
+pihen-meleged 1
+pikantria 1
+pilisi 1
+pilisszntiak 1
+pillanatban 1
+pillantsokat 1
+pirogrnit 1
+piszok 1
+poeticaknt 1
+polgrai 1
+polgrmester-vlasztst 1
+polgrok 1
+polgroknak 1
+polgrsg 1
+politikusokkal 1
+politikusoknak 1
+politikba 1
+politikjukat 1
+politiktl 1
+pompval 1
+pont 1
+pontjain 1
+pontjairl 1
+pontjait 1
+pontknt 1
+ponttal 1
+ponttlaga 1
+populrisabb 1
+porcelnbl 1
+port 1
+posztkommunista 1
+posztokat 1
+poszton 1
+posztra 1
+potencilis 1
+pozciharc 1
+pozciit 1
+pragmatikus 1
+praxis 1
+premierjt 1
+primitv 1
+privatizci 1
+privatizcijban 1
+privatizcijnak 1
+privatizcijrl 1
+privatizcis 1
+privatizcival 1
+privatizlsa 1
+privatizlsbl 1
+privatizl 1
+problmja 1
+problmjt 1
+problmkkal 1
+problmm 1
+problms 1
+produkcik 1
+produkcikban 1
+produkcim 1
+produkcira 1
+professzor 1
+profiknt 1
+profithes 1
+prognosztizljk 1
+programban 1
+programja 1
+programjba 1
+programokbl 1
+programrl 1
+projekci 1
+protezslt 1
+provokcinak 1
+prblnak 1
+prblok 1
+prbnak 1
+pszichiter 1
+pszichiternek 1
+pszichs 1
+publiklt 1
+publiklshoz 1
+puccsot 1
+puha 1
+pukkadni 1
+puszta 1
+pusztrl 1
+puszttotta 1
+pusztt 1
+plforduls 1
+plyafutsnak 1
+plyakezdsnek 1
+plyaudvari 1
+plyaudvarig 1
+plyja 1
+plyjn 1
+plyt 1
+plyzatokra 1
+pnclszekrnynek 1
+pncltermeiben 1
+prbeszdet 1
+prhuzamosan 1
+prosmrkzst 1
+prosul 1
+prosult 1
+prtjt 1
+prtok 1
+prtokat 1
+prtokra 1
+prttagok 1
+prtllsbl 1
+pcsi 1
+pldakpnek 1
+pldnyainak 1
+pnteki 1
+pntekre 1
+pnzben 1
+pnzbrsggal 1
+pnzbl 1
+pnze 1
+pnzintzetek 1
+pnzkrds 1
+pnzmennyisg 1
+pnznyel 1
+pnzre 1
+pnztrost 1
+pnzbl 1
+pnzn 1
+pnzrt 1
+pnzgyminiszteri 1
+pnzgyminisztert 1
+pti 1
+ptalkatrsz 1
+ptlkban 1
+ptlkra 1
+ptolhatnak 1
+ptolja 1
+ptolva 1
+pspk 1
+pspkknek 1
+rabbi-szobrocska 1
+rabszolgamunkt 1
+rabul 1
+radiklis 1
+ragadtak 1
+ragaszkodik 1
+rajzai 1
+rajzfilmek 1
+rajzfilmen 1
+rajzoldik 1
+raktr 1
+rakdott 1
+rangjt 1
+rangok 1
+rangsorban 1
+rapszodikus 1
+ratifiklsa 1
+reaglt 1
+reakci 1
+reakcikat 1
+realista 1
+rebesgettk 1
+recesszit 1
+reflektorait 1
+reformintzkedsektl 1
+reformja 1
+reformokat 1
+reformoknak 1
+reformot 1
+regionlis 1
+regisztrci 1
+regisztrljk 1
+regisztrltak 1
+regresszi 1
+regnybeli 1
+regnyhse 1
+regnynek 1
+rejl 1
+rejtzkd 1
+rekedt 1
+rekedtek 1
+relaxcis 1
+remek 1
+remekm 1
+remlhetleg 1
+remlik 1
+remlt 1
+remnyei 1
+remnykednek 1
+remnyt 1
+rendben 1
+rendelet 1
+rendeljenek 1
+rendeljk 1
+rendelkezsei 1
+rendeltek 1
+rendeltetsi 1
+rendeltk 1
+rendelket 1
+rendes 1
+rendez 1
+rendezetlen 1
+rendezetlensge 1
+rendezett 1
+rendezik 1
+rendezvnysorozat 1
+rendezsi 1
+rendezsre 1
+rendezsrl 1
+rendezs 1
+rendez 1
+rendezvel 1
+rendfenntartk 1
+rendknt 1
+rendkvl 1
+rendszerbe 1
+rendszerbl 1
+rendszeres 1
+rendszerhez 1
+rendszernek 1
+rendszerspecifikus 1
+rendszert 1
+rendszer 1
+rendr-fkapitnysg 1
+rendri 1
+rendrjrrre 1
+rendrre 1
+rendrsge 1
+rendrsget 1
+rendrsgre 1
+rendek 1
+rendre 1
+replni 1
+replt 1
+replk 1
+replrajtot 1
+repltren 1
+restancija 1
+restitci 1
+restitcis 1
+rezet 1
+rezidencija 1
+rezsim 1
+relgazdasg 1
+relgazdasgtl 1
+relkeresetekhez 1
+relrtk-nvekedst 1
+relrtkben 1
+relrtken 1
+riasztjk 1
+riaszt 1
+rideg 1
+riportere 1
+riportjait 1
+riportot 1
+ritka 1
+ritkasgok 1
+ritkn 1
+ritmusos 1
+ritmus 1
+rivalizlsukat 1
+robbantsos 1
+rokona 1
+rokonai 1
+rokonszenvnek 1
+rolt 1
+romantika 1
+romantikus 1
+romjain 1
+romlik 1
+romlott 1
+romlottak 1
+romlst 1
+romk 1
+romkat 1
+romniai 1
+rontotta 1
+rosszfik 1
+rosszulltek 1
+rt-nl 1
+rubellel 1
+rubelre 1
+rugalmas 1
+rutinos 1
+rads 1
+rbeszlni 1
+rbeszls 1
+rcsokat 1
+rdiban 1
+rdifelvteleink 1
+rdikritika 1
+rdival 1
+rfizetst 1
+rjjjn 1
+rkvetkez 1
+rlttek 1
+rmutatnak 1
+rmutatott 1
+rszorultsguk 1
+rszorulk 1
+rta 1
+rtermett 1
+rvegye 1
+rzott 1
+rzta 1
+rgin 1
+rszben 1
+rszegysgek 1
+rszei 1
+rszein 1
+rszeiv 1
+rszeknt 1
+rszesedse 1
+rszesl 1
+rszeslkre 1
+rszint 1
+rszleg 1
+rszlegtl 1
+rszleteirl 1
+rszletek 1
+rszmunkaidnek 1
+rsztulajdonosa 1
+rsztvevi 1
+rszvny 1
+rszvnycsomag 1
+rszvnyeinek 1
+rszvnyeit 1
+rszvnyeseit 1
+rszvnypakettel 1
+rszvtel 1
+rszvteli 1
+rszvtelre 1
+rszvtelt 1
+rszben 1
+rszrl 1
+rszvel 1
+rteg 1
+rtegelt 1
+rtegelst 1
+r 1
+rla 1
+rlam 1
+rgnek 1
+rgztettk 1
+rgzt 1
+rviden 1
+rvidesen 1
+rvidre 1
+rg 1
+sajnos 1
+sajnlom 1
+sajt 1
+sajtbemutatt 1
+sajtnak 1
+sajtosztlya 1
+sajttjkoztatn 1
+sajtrteslsek 1
+sajtossgok 1
+sakk-sekk-bstya 1
+sakkasztalhoz 1
+sakkcsapat 1
+sakkolimpin 1
+sakkletbe 1
+salamoni 1
+sarat 1
+sarkallhatja 1
+sarkon 1
+sebeit 1
+sebeket 1
+sebessggel 1
+sebessgvltn 1
+sebessgvel 1
+sebeslteket 1
+seglyakcikhoz 1
+seglyezs 1
+seglyhv 1
+seglynyjt 1
+seglynyjtknak 1
+segt 1
+segtett 1
+segtette 1
+segtheti 1
+segtik 1
+segtsenek 1
+segtsg 1
+segtsgvel 1
+segtsgrt 1
+segtsben 1
+segtkszsgt 1
+semmibe 1
+semmifle 1
+semmilyent 1
+semminem 1
+semmisteni 1
+semmit 1
+semmitmondsra 1
+sertsszllt 1
+siet 1
+sietsgre 1
+siettettk 1
+sikere 1
+sikeredett 1
+sikernek 1
+sikerrel 1
+sikertl 1
+siker 1
+siklani 1
+sifoki 1
+skopjei 1
+sofr 1
+sofrjei 1
+sofrjvel 1
+sokadszor 1
+sokakat 1
+sokaknak 1
+sokba 1
+soknemzetisg 1
+sokszor 1
+sokszorosan 1
+sokszorostott 1
+sora 1
+sorjzsban 1
+sorolt 1
+soron 1
+soros 1
+sorozatban 1
+sorozatgyrtst 1
+sorozatok 1
+sorrendbe 1
+sorsa 1
+sorsot 1
+sorszmozott 1
+sort 1
+sorllst 1
+spiritulis 1
+sportbizottsgnak 1
+sporthetilap 1
+sportjsgr-trsadalom 1
+stabilitst 1
+stabilizcis 1
+stabilizldik 1
+stagnltak 1
+sterilizlatlan 1
+stimmel 1
+stratgia 1
+stratgijnak 1
+struktrjnak 1
+stbja 1
+stbnak 1
+sttusokat 1
+sttust 1
+stlusrzkkel 1
+stdijban 1
+stdimunkt 1
+summa 1
+svd 1
+svd 1
+szabadabb 1
+szabadd 1
+szabadgondolkod 1
+szabadrgsnl 1
+szabadsghinyos 1
+szabadultak 1
+szabja 1
+szabolcsi 1
+szabotlta 1
+szabotlsval 1
+szabta 1
+szably 1
+szablyaihoz 1
+szablyok 1
+szablyozza 1
+szablyozsa 1
+szablytalansgaiban 1
+szablytalansgok 1
+szak- 1
+szakadr 1
+szakadk 1
+szakadkokat 1
+szakasza 1
+szakasznak 1
+szakaszt 1
+szakember 1
+szakembereik 1
+szakembereket 1
+szakszervezet 1
+szaktrca 1
+szakrt 1
+szakrtje 1
+szaladt 1
+szanlsnak 1
+szaporodik 1
+szaporodtak 1
+szavainak 1
+szavatolni 1
+szavatolsa 1
+szavazat 1
+szavazatszerz 1
+szavazattbbsggel 1
+szavazatbl 1
+szavazatval 1
+szavaztak 1
+szavazs 1
+szavazhelyisgeket 1
+szavazik 1
+szavukat 1
+szavt 1
+szadi 1
+szedett 1
+szektrl 1
+szelekkel 1
+szelid 1
+szelleme 1
+szellemisgt 1
+szem 1
+szembenlls 1
+szembenllss 1
+szembenznie 1
+szembeszllni 1
+szeme 1
+szemem 1
+szemes 1
+szeminriumokat 1
+szeminriumra 1
+szemlerja 1
+szemll 1
+szempontok 1
+szemben 1
+szemly 1
+szemlyaut 1
+szemlyautk 1
+szemlye 1
+szemlyek 1
+szemlyesen 1
+szemlygpkocsik 1
+szemlyijvedelemad-kulcsot 1
+szemlyisg 1
+szemlyisgi 1
+szemlyisgrl 1
+szemlyszllt 1
+szemvegszr 1
+szentestett 1
+szentgyrgyi 1
+szenvedte 1
+szenvedllyel 1
+szenzci 1
+szenzcija 1
+szeparatistk 1
+szerbl 1
+szerelvnyeket 1
+szerelipari 1
+szerencsnek 1
+szerencssek 1
+szerencstlenl 1
+szerep 1
+szerepe 1
+szerepeit 1
+szerepeket 1
+szerepekre 1
+szerepelt 1
+szerepeltem 1
+szerephez 1
+szereplst 1
+szerepljeknt 1
+szereplk 1
+szeretet 1
+szeretne 1
+szeretnnek 1
+szerettk 1
+szeretje 1
+szerezni 1
+szereztek 1
+szerezzen 1
+szerezzenek 1
+szerintem 1
+szerintk 1
+szerkezete 1
+szerkezeti 1
+szerkezettalaktssal 1
+szerkezet 1
+szert 1
+szervek 1
+szervezet 1
+szervezeteire 1
+szervezetben 1
+szervezetnek 1
+szervezte 1
+szerveztek 1
+szerveztk 1
+szervezse 1
+szervezi 1
+szervhez 1
+szervokormnyt 1
+szerzemnyei 1
+szerzemnyekbl 1
+szerz 1
+szerzdtethetnek 1
+szerzdsek 1
+szerzk 1
+szezonban 1
+szfrbl 1
+szilveszter 1
+szimpatikus 1
+szimpatizlnak 1
+szimptival 1
+szingapri 1
+szinkron 1
+szintren 1
+szja 1
+szlovkiai 1
+szlovkok 1
+szlovneknl 1
+szlv 1
+szoborrl 1
+szobt 1
+szocdemek 1
+szocialista 1
+szocializmus 1
+szocildemokratnak 1
+szokatlan 1
+szoks 1
+szoksok 1
+szolglat 1
+szolglatot 1
+szolglattal 1
+szolglhatja 1
+szolglt 1
+szolgltam 1
+szolgltat 1
+szolgltathat 1
+szolgltatsi 1
+szolgltatsokat 1
+szolidarits 1
+szolidaritsi 1
+szombaton 1
+szomszd 1
+szomszdaiknl 1
+szomszdok 1
+szorgalmaz 1
+szorgalmaztk 1
+szorgalmazza 1
+szorongatva 1
+szorongst 1
+szorosabb 1
+szorul 1
+szortani 1
+szovjeteknek 1
+szponzornak 1
+sztori 1
+sztrjkhullmra 1
+sztr 1
+sztrcsapatval 1
+szublimls 1
+szuggesztivitssal 1
+szuggesztis 1
+szuperkm 1
+szurkolnak 1
+szurkoltam 1
+szbor 1
+szguldott 1
+szlak 1
+szllnak 1
+szllodaszobjban 1
+szllodban 1
+szllodk 1
+szllodkat 1
+szllt 1
+szllsoljk 1
+szlltjk 1
+szlltmny 1
+szlltmnynak 1
+szlltmnyok 1
+szlltja 1
+szmairl 1
+szmban 1
+szmlatartozsa 1
+szmolhat 1
+szmolni 1
+szmolt 1
+szmot 1
+szmozott 1
+szmtalanszor 1
+szmtaniuk 1
+szmthatna 1
+szmthattak 1
+szmtottak 1
+szmtsai 1
+szmtsokat 1
+szmtgpbe 1
+szmtgpek 1
+szndkainak 1
+szndkos 1
+szndkosan 1
+szndkot 1
+szndkoznak 1
+szndk 1
+szraz 1
+szrmazik 1
+szrmazsa 1
+szrmazsi 1
+szzad 1
+szzadban 1
+szzadbl 1
+szzadfordul 1
+szzalkrl 1
+szzalkval 1
+szzmterenknt 1
+szdljn 1
+szke 1
+szkel 1
+szkesfehrvri 1
+szkhelyen 1
+szkben 1
+szl 1
+szles 1
+szlesebb 1
+szlestst 1
+szlsebesen 1
+szlssgesen 1
+szln 1
+sznhidrognek 1
+szpek 1
+szpet 1
+szpnek 1
+szpsge 1
+szpsgk 1
+sztaprzott 1
+sztaprzva 1
+sztltt 1
+sztosztott 1
+sztszrt 1
+sztvlasztsa 1
+szn- 1
+szneiben 1
+sznfalak 1
+sznfoltot 1
+sznhelyn 1
+sznhz 1
+szniirodalom 1
+sznikritikusokbl 1
+sznmvben 1
+sznmvszeti 1
+szvritmust 1
+szvtipr 1
+szvbe 1
+szvben 1
+szba 1
+szban 1
+szhasznlattal 1
+szl 1
+szlaltathatok 1
+szlhatnak 1
+szltjk 1
+szltott 1
+szrakoztat 1
+sztr 1
+sztra 1
+sztrt 1
+sztrnak 1
+sztrval 1
+szktt 1
+szk 1
+szrfzsei-forgsai 1
+szvegek 1
+szveget 1
+szvetkezeti 1
+szvetsgen 1
+szvetsgest 1
+szksgem 1
+szksgesnl 1
+szksgessge 1
+szksgnk 1
+szleire 1
+szletik 1
+szletnek 1
+szletsnapi 1
+szletsnek 1
+szlets 1
+szlk 1
+sznet 1
+sznetelnnek 1
+sznetet 1
+szntesse 1
+szntetik 1
+szk 1
+szkebb 1
+szknek 1
+szkssge 1
+szklt 1
+sznt 1
+szz 1
+srga 1
+srknyrepln 1
+svoss 1
+srtetlenl 1
+srthet 1
+srlse 1
+srlsekkel 1
+srlssel 1
+srlsveszlyes 1
+selket 1
+skos 1
+snek 1
+soktatk 1
+splya 1
+sremlkt 1
+srokon 1
+sron 1
+stalpakon 1
+start 1
+sttsgbe 1
+sjt 1
+slyhatrt 1
+slyosbtotta 1
+slyossgnak 1
+slyt 1
+sllyedt 1
+srgetett 1
+srgette 1
+stipar 1
+sr 1
+ta 1
+tabunak 1
+tagadjk 1
+taggal 1
+tagjai 1
+tagjaitl 1
+tagjaknt 1
+tagkztrsasg 1
+tagorszg 1
+tagozatknt 1
+tagllamaiban 1
+tag 1
+takar 1
+takarkoskodni 1
+takarkat 1
+taksljk 1
+taksltk 1
+taktikzni 1
+talaj 1
+talpon 1
+tallattal 1
+tallatt 1
+tallgatta 1
+tallhat 1
+tallhatak 1
+tallhatk 1
+talljon 1
+talljk 1
+tallkozhatott 1
+tallkozunk 1
+tallkoz 1
+tallkozjn 1
+tallkozjt 1
+tallkozn 1
+tallkozt 1
+tallni 1
+tallta 1
+talltam 1
+tanakodni 1
+tantermek 1
+tanulmny 1
+tanulmnyait 1
+tanulmnyozzk 1
+tanulni 1
+tanulnia 1
+tanulsgosak 1
+tanult 1
+tanul 1
+tanyt 1
+tancsa 1
+tancsadst 1
+tancsad 1
+tancsadkkal 1
+tancsadt 1
+tancskozsa 1
+tancsolt 1
+tancsot 1
+tanrknt 1
+tanrok 1
+tantana 1
+tantott 1
+tantvnya 1
+tantvnyainak 1
+tants 1
+tantsi 1
+tansga 1
+tapad 1
+tapasztalat 1
+tapasztalatok 1
+tapasztalatokat 1
+tapasztalhat 1
+tapasztaltam 1
+tapsolhattunk 1
+tartalmazza 1
+tartalmaz 1
+tartalommal 1
+tartand 1
+tartank 1
+tartottak 1
+tartozik 1
+tartoznak 1
+tartozsnak 1
+tartoz 1
+tartsa 1
+tartsn 1
+tartsra 1
+tartkat 1
+tartsan 1
+tavalyeltt 1
+tavalyhoz 1
+tavalyihoz 1
+tavalyinl 1
+tavaszn 1
+taxisblokd 1
+tb- 1
+technikai 1
+technikailag 1
+techniknak 1
+technolgirt 1
+tee-t 1
+teendi 1
+tegnapi 1
+teherautnyi 1
+teherbe 1
+tehergpkocsik 1
+tehetetlen 1
+tehetett 1
+tehetnek 1
+tehetsgesebben 1
+tehette 1
+tej- 1
+tejiparban 1
+tekercset 1
+tekintetben 1
+tekintete 1
+tekintett 1
+tekinthetnek 1
+tekinthetk 1
+tekintve 1
+telefonhlzatokat 1
+telefonvonal-hinyt 1
+telepedhetnek 1
+telephelyeiket 1
+teleplseire 1
+teleplsen 1
+teleplsnek 1
+teleplst 1
+telet 1
+televzizsban 1
+telhetett 1
+teljestmnye 1
+teljestmnyn 1
+teljestmnyt 1
+teljestmny 1
+teljest 1
+teljhatalm 1
+tellett 1
+telt 1
+teltett 1
+teltst 1
+tematikus 1
+temetni 1
+temettek 1
+temetkben 1
+tempj 1
+tendencia 1
+tendenciavltozs 1
+tendencit 1
+tengelyszlessgben 1
+tennk 1
+tenyerkbl 1
+tereli 1
+tereltk 1
+teremben 1
+teremnek 1
+teremteni 1
+terepet 1
+terepjr-gpkocsik 1
+terheik 1
+terhek 1
+terheket 1
+terhelik 1
+terhelnk 1
+terhessgk 1
+terjed 1
+terjeszkedni 1
+terjesztett 1
+terjeszti 1
+termelt 1
+termelsben 1
+termelskiess 1
+termel 1
+termben 1
+termke 1
+termkeket 1
+termnyt 1
+termszet 1
+termszetesnek 1
+termszetnl 1
+terroristakzpontok 1
+terrorizmussal 1
+tervbe 1
+tervbl 1
+terve 1
+terveik 1
+terveivel 1
+tervez 1
+tervezet 1
+tervezete 1
+tervezetet 1
+tervezetnek 1
+tervezi 1
+tervezik 1
+terveznek 1
+tervezze 1
+tervszersgt 1
+tertik 1
+terletekrl 1
+terletet 1
+terletfejlesztsre 1
+terletnek 1
+terlet 1
+testbe 1
+testvre 1
+testletben 1
+testre 1
+testrei 1
+tesznek 1
+tetemes 1
+tetszeni 1
+tetszett 1
+tetsz 1
+tettek 1
+tettt 1
+tetzve 1
+tet 1
+tevkenykedik 1
+tevkenysgi 1
+tevkenysgket 1
+tev 1
+textilruk 1
+thai 1
+tilt 1
+tiltakoznak 1
+tiltakozott 1
+tiltakoztak 1
+tiltakozst 1
+tiszabecsin 1
+tisztelegtek 1
+tisztelettel 1
+tisztelte 1
+tisztes 1
+tisztessgesek 1
+tisztessgesekre 1
+tisztessgtelenek 1
+tisztessgtelenekre 1
+tisztogat 1
+tisztsgeitl 1
+tisztsgviselit 1
+tisztsgviselk 1
+tisztsgviselknt 1
+tisztsgbl 1
+tisztzatlan 1
+tisztzni 1
+tisztrl 1
+tisztt 1
+titkokhoz 1
+titkosszolglat 1
+titkosszolglati 1
+titkosszolglatok 1
+titoistk 1
+tizeddel 1
+tizedre 1
+tizenkilencedik 1
+tizenkt 1
+tobzdik 1
+tokii 1
+tolakszik 1
+tolerancia 1
+tologatjuk 1
+tologats 1
+tombol 1
+tonnjt 1
+tonnra 1
+torlaszokat 1
+torldtak 1
+torlds 1
+torna 1
+tornra 1
+torzultak 1
+totalitrius 1
+tovbbadott 1
+tovbbjuts 1
+tovbbtanuls 1
+tovbbtshoz 1
+toxikolgiai 1
+tradicionlis 1
+tragdiknak 1
+traktoron 1
+transzcendens 1
+transzparens 1
+transzportban 1
+tranzitforgalomban 1
+trolibusz 1
+tucat 1
+tucatot 1
+tudat 1
+tudata 1
+tudhatott 1
+tudhatta 1
+tudhat 1
+tudna 1
+tudom 1
+tudomnyos 1
+tudtam 1
+tudtuk 1
+tudtk 1
+tudsukat 1
+tuds 1
+tud 1
+tuds 1
+tudsa 1
+tulajdon 1
+tulajdonkppen 1
+tulajdonosai 1
+tulajdonosi 1
+tulajdonosknt 1
+tulajdonostrsakat 1
+tulajdonostrst 1
+tulajdonbl 1
+tulajdont 1
+tulajdontotta 1
+turizmus 1
+tutte 1
+tbla 1
+tblt 1
+tborban 1
+tdzsik 1
+tjkoztatsa 1
+tjkoztatst 1
+tjkoztatbl 1
+tjkoztatn 1
+tjkozdhatnak 1
+tmadjk 1
+tmadt 1
+tmadtk 1
+tmads 1
+tmadsait 1
+tmadsokban 1
+tmadsokkal 1
+tmadsokra 1
+tmasztott 1
+tmaszt 1
+tmogatni 1
+tmogatnk 1
+tmogattak 1
+tmogattk 1
+tmogatsokat 1
+tmogatsra 1
+tmogatsrl 1
+tmogatst 1
+tmogatsval 1
+tn 1
+tncok 1
+tnczennek 1
+trcsz 1
+trctl 1
+trgy 1
+trgyaln 1
+trgyalta 1
+trgyals 1
+trgyalsokon 1
+trgyalsnak 1
+trgyat 1
+trlaton 1
+trsa 1
+trsadalmi 1
+trsadalom 1
+trsadalombiztostsi 1
+trsai 1
+trsainak 1
+trsasgg 1
+trsasgot 1
+trsasgban 1
+trstulajdonosa 1
+trsulat 1
+trsulni 1
+trsnak 1
+ttong 1
+tvirati 1
+tvirszlny 1
+tvkzls 1
+tvlatokat 1
+tvol 1
+tvoztak 1
+tvozsa 1
+tvozsban 1
+tvozsra 1
+tvozst 1
+tvozsuk 1
+tvoz 1
+tvozk 1
+tvra 1
+tv 1
+tged 1
+tli 1
+tmi 1
+tmk 1
+tnyek 1
+tnyezkrt 1
+tnyt 1
+trbe 1
+trdkig 1
+trnek 1
+trszintjnl 1
+trsgbeli 1
+trsgek 1
+trsget 1
+trsgnkben 1
+trt 1
+tt 1
+tteleket 1
+tve 1
+tvbemond 1
+tziseikben 1
+tzen 1
+tzezren 1
+tzkor 1
+tzmillival 1
+tra 1
+tratekercs 1
+tbbforduls 1
+tbbletforrst 1
+tbbnemzetisg 1
+tbbsgre 1
+tbbsgn 1
+tbbsgk 1
+tbb 1
+tbbrt 1
+tkletes 1
+tlteni 1
+tltheti 1
+tlti 1
+tltik 1
+tlttte 1
+tmegesen 1
+tmegmegmozduls 1
+tnkremennek 1
+trekedett 1
+trekednek 1
+trekszik 1
+tretlenl 1
+trleszts 1
+trlesztsre 1
+trmelk 1
+trtnelemben 1
+trtnelme 1
+trtnetbe 1
+trtnetet 1
+trtneti 1
+trtnetn 1
+trtntek 1
+trtnse 1
+trtnsek 1
+trvnnyel 1
+trvnycsomagnak 1
+trvnyi 1
+trvnyjavaslat 1
+trvnyknyve 1
+trvnynek 1
+trzskznsgnk 1
+trzstkvel 1
+trkeny 1
+trst 1
+trltek 1
+trtt 1
+tladtak 1
+tldimenzionlstl 1
+tlmutat 1
+tlterhelheti 1
+tlterheltsge 1
+tltermelsi 1
+tlteszi 1
+tlzott 1
+tlzottaknak 1
+tlzottan 1
+tlzssal 1
+tllt 1
+tntetst 1
+tntet 1
+trelmetlenl 1
+trk 1
+trkk 1
+tzek 1
+tzrsgi 1
+tke 1
+tkeemelsben 1
+tkeemelsek 1
+tkeemelsrl 1
+tkeemelssel 1
+tkekoncentrci 1
+tkepiacok 1
+tketartalkba 1
+tketbblet 1
+tketmegek 1
+tketrlesztsre 1
+tkjnek 1
+tkj 1
+tknl 1
+tksti 1
+tkvel 1
+tle 1
+tzsdei 1
+tzsdinek 1
+t 1
+tnt 1
+tn 1
+tz 1
+tzesetek 1
+tzkrok 1
+tznk 1
+tzoltkat 1
+tzn-vzen 1
+u 1
+udvarn 1
+ugyanarra 1
+ugyanolyan 1
+ugyanott 1
+ukrn 1
+ukrnok 1
+unatkozik 1
+universitasra 1
+univerzum 1
+unihoz 1
+urakat 1
+uralkodik 1
+uralmt 1
+urusz-martani 1
+urt 1
+utaljk 1
+utalt 1
+utasaikat 1
+utasflkben 1
+utasokat 1
+utastotta 1
+utastsra 1
+utastst 1
+utazni 1
+utazom 1
+utazott 1
+utazzon 1
+utazssal 1
+utazst 1
+utaz 1
+utca 1
+utcaihoz 1
+utcaival 1
+utcai 1
+utckon 1
+utcn 1
+utolssorban 1
+utnptls 1
+utnptlst 1
+utbb 1
+utbbiak 1
+utbbiakat 1
+utbbiakkal 1
+utbbira 1
+utdaknt 1
+utdra 1
+utdllama 1
+utdllamaiban 1
+utdnak 1
+utpija 1
+vacsora 1
+vacsorra 1
+vagon 1
+vagyonhoz 1
+vagyonmegoszts 1
+vagyonrendezs 1
+vagyonvdelmi 1
+vagyon 1
+valahol 1
+valakinek 1
+valamelyik 1
+valamifle 1
+valamilyen 1
+valamireval 1
+valamirt 1
+vall 1
+valljuk 1
+vallott 1
+vallsi 1
+valutabevtelei 1
+valutkban 1
+valjban 1
+valsznnek 1
+valsgos 1
+valsgra 1
+varsi 1
+varzsljt 1
+vasdarabb 1
+vasutat 1
+vasttal 1
+vastvonalakon 1
+vastvonalon 1
+vb-cmmrkzsre 1
+vegyes 1
+vegyesvllalata 1
+vegyipari 1
+vehet 1
+veheti 1
+velem 1
+velnk 1
+vendgek 1
+vendgeket 1
+vendgforgalom 1
+vendgjtkn 1
+vendgszerepls 1
+venn 1
+veresget 1
+veresgrt 1
+veretlen 1
+vergdnek 1
+verseinek 1
+versengenek 1
+versengs 1
+versengsbe 1
+versenyben 1
+versenyen 1
+versenyeztets 1
+versenygazdasg 1
+versenykpessg 1
+versenykpessgrt 1
+versenytrsaik 1
+versenytrsaikkal 1
+versenytrsuk 1
+vert 1
+verzi 1
+verzit 1
+vesebeteget 1
+vesszen 1
+vesszk 1
+vesz 1
+veszem 1
+veszendbe 1
+veszhet 1
+vesztegeltek 1
+vesztegl 1
+vesztes 1
+vesztese 1
+vesztesei 1
+vesztesggel 1
+vesztett 1
+vesztettem 1
+veszly 1
+veszlyezteti 1
+veszlyforrsai 1
+veszlyforrss 1
+veszlyre 1
+vesztett 1
+vetnek 1
+vetni 1
+vette 1
+vettem 1
+vetlkedik 1
+vetlkeds 1
+vetlytrsa 1
+vevi 1
+vevt 1
+vezessenek 1
+vezet 1
+vezetett 1
+vezethet 1
+vezeti 1
+vezetni 1
+vezettek 1
+vezetkes 1
+vezetkre 1
+vezets 1
+vezetshez 1
+vezetsben 1
+vezets 1
+vezetibl 1
+vezetinek 1
+vezetire 1
+vezetjt 1
+vezetsgi 1
+veznyletvel 1
+vezrevezs 1
+vezrezredes 1
+vezrigazgat 1
+vezrigazgatnak 1
+vezrt 1
+vezrrnagy 1
+viaszkpik 1
+videotkra 1
+vidk- 1
+vidken 1
+vidkfejleszts 1
+vidkrl 1
+villamosenergetikai 1
+villamosmrnkket 1
+villamosok 1
+villamossal 1
+villanymozdony 1
+villanyvezetkek 1
+villanyramot 1
+vilg- 1
+vilga 1
+vilgbajnok-jellti 1
+vilgbajnoki 1
+vilgbajnokjelltje 1
+vilgban 1
+vilgcg 1
+vilggazdasg 1
+vilghbors 1
+vilghr 1
+vilgmagyarzatknt 1
+vilgos 1
+vilgosan 1
+vilgpiac 1
+vilgszerte 1
+vilgszervezet 1
+vilgviszonylatban 1
+vinni 1
+viselkedjenek 1
+viselkednek 1
+viselkedsn 1
+viselkedsket 1
+viselt 1
+visel 1
+visszaadja 1
+visszaesst 1
+visszaessvel 1
+visszajelzst 1
+visszajuttatst 1
+visszalpjenek 1
+visszaszerzi 1
+visszaszolgltatsnak 1
+visszateleplse 1
+visszatrni 1
+visszatrt 1
+visszatrsk 1
+visszautaltk 1
+visszavonva 1
+visszavsrlsa 1
+visszavsrlsi 1
+visszalltsa 1
+visszalve 1
+visszalseket 1
+visz 1
+viszonozva 1
+viszonya 1
+viszonyban 1
+viszonylag 1
+viszonyokhoz 1
+viszonyszma 1
+viszonyt 1
+viszonyban 1
+viszonytsi 1
+viszlykodtak 1
+viszlyokat 1
+vita 1
+vitasorozat 1
+vitathat 1
+vitatjk 1
+vitatkozni 1
+vitatta 1
+vitt 1
+vittek 1
+vittk 1
+vitjba 1
+vitjt 1
+vitkat 1
+vitktl 1
+vitn 1
+vitra 1
+viv 1
+vizes 1
+vizitje 1
+vizsglat 1
+vizsglatban 1
+vizsglta 1
+vizsgldik 1
+voksok 1
+voksols 1
+voksukat 1
+voltam 1
+volumene 1
+volument 1
+vonakodva 1
+vonja 1
+vonnak 1
+vonni 1
+vonnk 1
+vontattk 1
+vonul 1
+vonulhattak 1
+vonz 1
+vonzak 1
+vonzds 1
+vonsa 1
+vonst 1
+vd 1
+vdak 1
+vdlottak 1
+vdolhat 1
+vdoljk 1
+vdolta 1
+vdoltk 1
+vgtk 1
+vgynak 1
+vgs 1
+vghidak 1
+vlaszom 1
+vlasztani 1
+vlaszthatnak 1
+vlasztja 1
+vlasztmnyi 1
+vlasztottam 1
+vlaszts 1
+vlasztst 1
+vlasztival 1
+vlasztkat 1
+vlhat 1
+vllal 1
+vllalat 1
+vllalata 1
+vllalatbirodalmnak 1
+vllalati 1
+vllalatokkal 1
+vllalatot 1
+vllalatt 1
+vllalhatok 1
+vllalhat 1
+vllalkozsba 1
+vllalkozsnak 1
+vllalkozst 1
+vllalkoz 1
+vllalkozjnak 1
+vllalnia 1
+vllalt 1
+vllalta 1
+vllalva 1
+vlniuk 1
+vlogatottbeli 1
+vlogatottjban 1
+vlsga 1
+vlsgban 1
+vlsggal 1
+vlsgbl 1
+vltani 1
+vltozata 1
+vltozatlanul 1
+vltozik 1
+vltozott 1
+vltoztatnak 1
+vltoztats 1
+vltoztatsok 1
+vltozs 1
+vltozsok 1
+vltozst 1
+vltson 1
+vltk 1
+vlyoghz 1
+vmjnak 1
+vmtarifkkal 1
+vrakozsa 1
+vrakozsra 1
+vrakoz 1
+vrbli 1
+vrjk 1
+vrosa 1
+vrosatyk 1
+vrosok 1
+vrosokban 1
+vrosvezets 1
+vrosvezet 1
+vsr 1
+vsrlsaik 1
+vsrlk 1
+vsrlkra 1
+vsrol 1
+vsrolni 1
+vdend 1
+vdjegyek 1
+vds 1
+vdintzkedsekkel 1
+vdnek 1
+vgbe 1
+vgelszmolssal 1
+vgeredmny 1
+vget 1
+vgig 1
+vgigaludta 1
+vgighzdik 1
+vgigg 1
+vginl 1
+vgrehajtsi 1
+vgrehajtshoz 1
+vgtelenn 1
+vgzi 1
+vgzk 1
+vlelmt 1
+vlemnyek 1
+vlemnynek 1
+vlemnyt 1
+vlt 1
+vr 1
+vrmrgezst 1
+vszhelyzetbl 1
+vteli 1
+vtelre 1
+vtelr 1
+vrussal 1
+vvja 1
+vvott 1
+vrs 1
+vrsvriak 1
+whiskyt 1
+zagyva 1
+zajlanak 1
+zajl 1
+zajos 1
+zavargsokat 1
+zene 1
+zeneakadmistt 1
+zenei 1
+zeneszerz 1
+zeneszerzzseniket 1
+zenk 1
+zenket 1
+zennek 1
+zenre 1
+ziccerben 1
+zoksz 1
+zongoraszvitemet 1
+zord 1
+zsoldos 1
+zsolnai 1
+zsfoltsgot 1
+zrkznak 1
+zrlat 1
+zrni 1
+zrtak 1
+zrtkr 1
+zrult 1
+zrsa 1
+zrjelbe 1
+zszlajt 1
+zszl 1
+zmmel 1
+zmben 1
+zrichi 1
+PTF 1
+PTF-nek 1
+kos 1
+llamokban 1
+llamoknak 1
+lltk 1
+llsbrze 1
+ltalban 1
+rgus 1
+ron 1
+rpd 1
+rverst 1
+svnyolaj 1
+tmeneti 1
+zsiban 1
+let 1
+lvezettel 1
+l-pontszmaikat 1
+l-pontszm 1
+nek-Zene 1
+pt 1
+ptipari 1
+rdemes 1
+rthetn 1
+rtktzsdn 1
+szak-Kaukzus 1
+szak-Kaukzusban 1
+szaknyugat-Magyarorszgon 1
+ta 1
+va 1
+n 1
+nkntes 1
+nkntesek 1
+rdgkkel 1
+regasszony 1
+rksg 1
+rlk 1
+sztnsen 1
+tdik 1
+jabb 1
+jlaki 1
+jsolt 1
+risten 1
+fa-tartozsai 1
+ga 1
+gak 1
+gazat 1
+gazaton 1
+gazatra 1
+gon 1
+ldozat 1
+ldozata 1
+ldozatainak 1
+ldozatknt 1
+ldozatnak 1
+ldozatok 1
+ldozatot 1
+llamalkot 1
+llamft 1
+llamhztarts 1
+llamok 1
+llampolgri 1
+llampolgrok 1
+llamra 1
+llamtitkokat 1
+llamtitkr-helyettesi 1
+llamtitkrt 1
+llamnak 1
+llandsulnia 1
+llapot 1
+llapotban 1
+llapotok 1
+llapotot 1
+llapott 1
+llaptsa 1
+llatok 1
+llatokkal 1
+llatbrzols 1
+llhat 1
+llhatnak 1
+lljanak 1
+lltak 1
+lltk 1
+llsa 1
+llsajnlatok 1
+llsbrze 1
+llskeress 1
+llskeressnek 1
+llspontja 1
+llspontok 1
+llsra 1
+llst 1
+llsbl 1
+llt 1
+llthassa 1
+llthatom 1
+lltsanak 1
+lltsokat 1
+lltst 1
+lmainak 1
+lmatlansgban 1
+ltalam 1
+polnak 1
+polsa 1
+pol 1
+prilisban 1
+prilisi 1
+prilisban 1
+radata 1
+rai 1
+rakat 1
+ralku 1
+ram 1
+ramot 1
+rbevtele 1
+rbevtelk 1
+remelkeds 1
+rfolyamok 1
+rfolyamvltozsok 1
+rindex 1
+ringadozsai 1
+rjn 1
+rkokba 1
+rkokbl 1
+rnyakat 1
+rnykgazdasgnak 1
+rnykban 1
+rnykt 1
+rnl 1
+rnvekeds 1
+rrl 1
+rstruktrjt 1
+rszintjt 1
+rtmogatsi 1
+rvers 1
+rversi 1
+rversre 1
+rvltozsainak 1
+ssuk 1
+svnykincsekben 1
+talakul 1
+talakult 1
+talakulsokra 1
+talaktani 1
+talaktsa 1
+talaktsok 1
+talaktst 1
+tbocstkpessggel 1
+tengedsvel 1
+tesnie 1
+tformldjon 1
+tfjt 1
+thrtani 1
+tigazolsi 1
+tkelhelyn 1
+tkos 1
+tkltztetst 1
+tlagemberek 1
+tlaggal 1
+tlagnak 1
+tlagosnl 1
+tlaghoz 1
+tlthat 1
+tlthatsg 1
+tlpni 1
+tlpi 1
+tmegy 1
+tmenetileg 1
+tnyjtsa 1
+treplse 1
+tszervezsi 1
+tszervezssel 1
+tszervezshez 1
+tszllst 1
+ttrt 1
+ttrst 1
+tttelesen 1
+ttrt 1
+tutaz 1
+tvette 1
+tvilgts 1
+tvilgtsi 1
+tlssel 1
+tvel 1
+ttemezsre 1
+ttemezsrl 1
+brednie 1
+bredve 1
+des- 1
+desanym 1
+desapja 1
+geten 1
+gtj 1
+jjel 1
+jszaka 1
+jszakai 1
+jszakt 1
+lelem- 1
+lelmiszer-fogyaszts 1
+lelmiszerek 1
+lelmiszergyrtknak 1
+lelmiszerrak 1
+lemiszeriparban 1
+lesen 1
+letem 1
+leternk 1
+letet 1
+letfontossgnak 1
+letmdjra 1
+lettartam 1
+letveszly 1
+letbe 1
+letvt 1
+li 1
+lmnnyel 1
+lmnyt 1
+lte 1
+ltet 1
+ltbls 1
+lve 1
+lvezetes 1
+lvezik 1
+lvezni 1
+lvezte 1
+lrl 1
+lnk 1
+lknek 1
+nekei 1
+nekelni 1
+nekelsz 1
+nekelt 1
+nekes 1
+nekesek 1
+nekli 1
+nekls 1
+pp 1
+ptenek 1
+ptenk 1
+ptette 1
+ptkezs 1
+ptsen 1
+pttetett 1
+ptszt 1
+ptsvel 1
+pt 1
+ptipari 1
+ptmvszeti 1
+pl 1
+plet 1
+pletfenntartssal 1
+pletbe 1
+pletben 1
+pletnek 1
+plett 1
+pl 1
+rckzet 1
+rdek 1
+rdekbl 1
+rdekeinek 1
+rdekeit 1
+rdekelt 1
+rdekelte 1
+rdekeltek 1
+rdekeltsgeken 1
+rdekeltsgt 1
+rdekesebb 1
+rdekl 1
+rdekldnek 1
+rdekldket 1
+remrt 1
+rezhet 1
+reznm 1
+reztek 1
+rezteti 1
+rhet 1
+rhet 1
+rint 1
+rintene 1
+rintenek 1
+rintheti 1
+rinti 1
+rintkezsi 1
+rjen 1
+rkezne 1
+rkez 1
+rni 1
+rnie 1
+rtelmes 1
+rtelmetlenebb 1
+rtelmetlensgig 1
+rtelmezhet 1
+rtelmezsi 1
+rtelm 1
+rtenie 1
+rteslt 1
+rteslsei 1
+rteslseink 1
+rteslsek 1
+rtetden 1
+rthetetlenl 1
+rtheten 1
+rthetsghez 1
+rti 1
+rtik 1
+rtkeinek 1
+rtkeltk 1
+rtken 1
+rtkestik 1
+rtkestse 1
+rtkestsvel 1
+rtket 1
+rtknek 1
+rtkpapr-keresked 1
+rtkpaprok 1
+rtktzsdn 1
+rtkllsgt 1
+rv 1
+rveiket 1
+rvnybe 1
+rvnyesnek 1
+rvnyt 1
+rzelmek 1
+rzelmeket 1
+rzem 1
+rzi 1
+rzkelhet 1
+rzkelteti 1
+rzkem 1
+rzkenyen 1
+rzst 1
+rz 1
+rstl 1
+r 1
+szak-koszovi 1
+szaki 1
+szaki-tengeri 1
+szakkelet-boszniai 1
+szrevesz 1
+szrevette 1
+szrevettk 1
+tkezsi 1
+tteremben 1
+vekig 1
+venknti 1
+vesek 1
+vesen 1
+vet 1
+vezredben 1
+vfordul 1
+vfordulja 1
+vforduljra 1
+vforduljt 1
+vfordult 1
+vihez 1
+vjratban 1
+vknyv 1
+vrl 1
+vszzados 1
+vtized 1
+vtizedben 1
+vben 1
+greteinek 1
+gretet 1
+rjon 1
+rnnak 1
+rok 1
+rott 1
+rtak 1
+rs 1
+rsban 1
+r 1
+r-rendez 1
+rasztalfiknak 1
+tlete 1
+tletid 1
+tlhetnk 1
+piumtermels 1
+rakor 1
+riscg 1
+risok 1
+risvllalat 1
+rk 1
+rkban 1
+rkon 1
+rkra 1
+rn 1
+rrl 1
+va 1
+vatosak 1
+vatosan 1
+lelte 1
+lti 1
+nfelfedezsi 1
+nirnijt 1
+nkormnyzati 1
+nkormnyzatok 1
+nkormnyzatokat 1
+nkormnyzatoknak 1
+nkormnyzatoknl 1
+nkorrekcira 1
+nknyes 1
+nnel 1
+nrl 1
+nlltlanul 1
+rdggel 1
+rmnyek 1
+rvend 1
+rksge 1
+rkrvny 1
+rks 1
+rksdsellenes 1
+rltem 1
+sszeadjuk 1
+sszecsapsnak 1
+sszecsapsok 1
+sszefoglal 1
+sszefogs 1
+sszeget 1
+sszegylt 1
+sszegrt 1
+sszeg 1
+sszehvott 1
+sszekapcsolsban 1
+sszekuszldott 1
+sszekttetsben 1
+sszektsekor 1
+sszektst 1
+sszekt 1
+sszektknt 1
+sszessgben 1
+sszeszedni 1
+sszeszmllsakor 1
+sszetartozs 1
+sszettele 1
+sszetrte 1
+sszevetve 1
+sszevonni 1
+sszevons 1
+sszevonsokra 1
+sszellts 1
+sszelltst 1
+sszelltsukban 1
+sszelltsban 1
+sszellts 1
+sszpontostottak 1
+ssztartozsa 1
+tmilli 1
+tven 1
+tvenszer 1
+tvenves 1
+tdik 1
+vezet 1
+vezett 1
+gyhogy 1
+jabbakkal 1
+jbl 1
+jdonsg 1
+jdonsgot 1
+jdonslt 1
+jjszletve 1
+jjvlasztott 1
+jjpts 1
+jjptsi 1
+jraindult 1
+jravlasztjk 1
+jrantik 1
+jrantsvel 1
+jsg 1
+jsgok 1
+jsgrja 1
+jsgrkat 1
+jsgrknak 1
+jvidki 1
+r 1
+rknt 1
+szva 1
+tdj 1
+thlzat 1
+thlzatot 1
+ti 1
+tja 1
+tmunksok 1
+tmutats 1
+tnak 1
+tszakasz 1
+tvesztkbl 1
+dvzlte 1
+dtital-gyrts 1
+ggyel 1
+ggyel-bajjal 1
+gye 1
+gyek 1
+gyekben 1
+gyeletet 1
+gynknvsorok 1
+gyvezet 1
+gyvivknt 1
+gyvdje 1
+gybe 1
+gyszsg 1
+ldglnek 1
+ldzs 1
+ldzi 1
+lnek 1
+ltem 1
+lse 1
+lsein 1
+lsnek 1
+lk 1
+nnep 1
+nnepekkel 1
+nnepekre 1
+nnepel 1
+nnepelhet 1
+nnepelhette 1
+nnepelte 1
+nnepsget 1
+res 1
+rggyel 1
+rgynek 1
+temben 1
+teme 1
+temt 1
+tik 1
+tkzetek 1
+tkzik 1
+tsk 1
+veg 1
+zemanyag 1
+zemanyag-knlat 1
+zemanyag-rak 1
+zemanyaghiny 1
+zemanyagok 1
+zemanyagrakra 1
+zembe 1
+zemei 1
+zemeltetk 1
+zemi 1
+zeneteit 1
+zenetnek 1
+zletrszt 1
+zlettel 1
+ket 1
+szintn 1
+reknt 1
+rizd 1
+rizetlenl 1
+rizni 1
+rkd 1
+rzik 1
+rlet 1
+srgi 1
+szn 1
+r 1
diff --git a/research/syntaxnet/dragnn/python/trainer_lib.py b/research/syntaxnet/dragnn/python/trainer_lib.py
index 57451f85..f53cb894 100644
--- a/research/syntaxnet/dragnn/python/trainer_lib.py
+++ b/research/syntaxnet/dragnn/python/trainer_lib.py
@@ -152,8 +152,9 @@ def run_training(sess, trainers, annotator, evaluator, pretrain_steps,
       for label, metric in summaries.iteritems():
         write_summary(summary_writer, label, metric, actual_step + step)
       eval_metric = summaries['eval_metric']
+      tf.logging.info('Current eval metric: %.2f', eval_metric)
       if best_eval_metric < eval_metric:
-        tf.logging.info('Updating best eval to %.2f%%, saving checkpoint.',
+        tf.logging.info('Updating best eval to %.2f, saving checkpoint.',
                         eval_metric)
         best_eval_metric = eval_metric
         saver.save(sess, checkpoint_filename)
diff --git a/research/syntaxnet/dragnn/python/transformer_units.py b/research/syntaxnet/dragnn/python/transformer_units.py
new file mode 100644
index 00000000..4e7ddb1a
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/transformer_units.py
@@ -0,0 +1,584 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Network units implementing the Transformer network (Vaswani et al. 2017).
+
+Heavily adapted from the tensor2tensor implementation of the Transformer,
+described in detail here: https://arxiv.org/abs/1706.03762.
+"""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import numpy as np
+import tensorflow as tf
+
+from dragnn.python import network_units
+
+
+def add_timing_signal_1d(x, min_timescale=1.0, max_timescale=1.0e4):
+  """Adds a bunch of sinusoids of different frequencies to a Tensor.
+
+  Each channel of the input Tensor is incremented by a sinusoid of a different
+  frequency and phase.
+
+  This allows attention to learn to use absolute and relative positions.
+  Timing signals should be added to some precursors of both the query and the
+  memory inputs to attention.
+
+  The use of relative position is possible because sin(x+y) and cos(x+y) can be
+  expressed in terms of y, sin(x) and cos(x).
+
+  In particular, we use a geometric sequence of timescales starting with
+  min_timescale and ending with max_timescale.  The number of different
+  timescales is equal to channels / 2. For each timescale, we
+  generate the two sinusoidal signals sin(timestep/timescale) and
+  cos(timestep/timescale).  All of these sinusoids are concatenated in
+  the channels dimension.
+
+  Args:
+    x: a Tensor with shape [batch, length, channels]
+    min_timescale: a float
+    max_timescale: a float
+
+  Returns:
+    a Tensor the same shape as x.
+  """
+  length = tf.shape(x)[1]
+  channels = tf.shape(x)[2]
+  pos = tf.to_float(tf.range(length))
+  num_timescales = channels // 2
+  log_timescale_increment = (
+      np.log(float(max_timescale) / float(min_timescale)) /
+      (tf.to_float(num_timescales) - 1))
+  inv_timescales = min_timescale * tf.exp(
+      tf.to_float(tf.range(num_timescales)) * -log_timescale_increment)
+  scaled_time = tf.expand_dims(pos, 1) * tf.expand_dims(inv_timescales, 0)
+  signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)
+  signal = tf.pad(signal, [[0, 0], [0, tf.mod(channels, 2)]])
+  signal = tf.reshape(signal, [1, length, channels])
+  return x + signal
+
+
+def split_last_dimension(x, n):
+  """Partitions x so that the last dimension becomes two dimensions.
+
+  The first of these two dimensions is n.
+
+  Args:
+    x: a Tensor with shape [..., m]
+    n: an integer.
+
+  Returns:
+    a Tensor with shape [..., n, m/n]
+  """
+  old_shape = x.get_shape().dims
+  last = old_shape[-1]
+  new_shape = old_shape[:-1] + [n] + [last // n if last else None]
+  ret = tf.reshape(x, tf.concat([tf.shape(x)[:-1], [n, -1]], 0))
+  ret.set_shape(new_shape)
+  return ret
+
+
+def combine_last_two_dimensions(x):
+  """Reshape x so that the last two dimensions become one.
+
+  Args:
+    x: a Tensor with shape [..., a, b]
+
+  Returns:
+    a Tensor with shape [..., ab]
+  """
+  old_shape = x.get_shape().dims
+  a, b = old_shape[-2:]
+  new_shape = old_shape[:-2] + [a * b if a and b else None]
+  ret = tf.reshape(x, tf.concat([tf.shape(x)[:-2], [-1]], 0))
+  ret.set_shape(new_shape)
+  return ret
+
+
+def split_heads(x, num_heads):
+  """Splits channels (dimension 3) into multiple heads (becomes dimension 1).
+
+  Args:
+    x: a Tensor with shape [batch, length, channels]
+    num_heads: an integer
+
+  Returns:
+    a Tensor with shape [batch, num_heads, length, channels / num_heads]
+  """
+  return tf.transpose(split_last_dimension(x, num_heads), [0, 2, 1, 3])
+
+
+def combine_heads(x):
+  """Performs the inverse of split_heads.
+
+  Args:
+    x: a Tensor with shape [batch, num_heads, length, channels / num_heads]
+
+  Returns:
+    a Tensor with shape [batch, length, channels]
+  """
+  return combine_last_two_dimensions(tf.transpose(x, [0, 2, 1, 3]))
+
+
+def compute_padding_mask(lengths):
+  """Computes an additive mask for padding.
+
+  Given the non-padded sequence lengths for the batch, computes a mask that will
+  send padding attention to 0 when added to logits before applying a softmax.
+
+  Args:
+    lengths: a Tensor containing the sequence length of each batch element
+
+  Returns:
+    A Tensor of shape [batch_size, 1, 1, max_len] with zeros in non-padding
+    entries and -1e9 in padding entries.
+  """
+  lengths = tf.reshape(lengths, [-1])
+  mask = tf.sequence_mask(lengths)
+
+  # This will be used as an additive mask, so we want the inverse of the mask
+  # produced by tf.sequence_mask.
+  inv_mask = tf.to_float(tf.logical_not(mask))
+
+  mem_padding = inv_mask * -1e9
+  return tf.expand_dims(tf.expand_dims(mem_padding, 1), 1)
+
+
+def dot_product_attention(queries, keys, values, dropout_keep_rate, bias=None):
+  """Computes dot-product attention.
+
+  Args:
+    queries: a Tensor with shape [batch, heads, seq_len, depth_keys]
+    keys: a Tensor with shape [batch, heads, seq_len, depth_keys]
+    values: a Tensor with shape [batch, heads, seq_len, depth_values]
+    dropout_keep_rate: dropout proportion of units to keep
+    bias: A bias to add before applying the softmax, or None. This can be used
+          for masking padding in the batch.
+
+  Returns:
+    A Tensor with shape [batch, heads, seq_len, depth_values].
+  """
+  # [batch, num_heads, seq_len, seq_len]
+  logits = tf.matmul(queries, keys, transpose_b=True)
+  if bias is not None:
+    logits += bias
+
+  attn_weights = tf.nn.softmax(logits)
+
+  # Dropping out the attention links for each of the heads
+  attn_weights = network_units.maybe_apply_dropout(attn_weights,
+                                                   dropout_keep_rate,
+                                                   False)
+  return tf.matmul(attn_weights, values)
+
+
+def residual(old_input, new_input, dropout_keep_rate, layer_norm):
+  """Residual layer combining old_input and new_input.
+
+  Computes old_input + dropout(new_input) if layer_norm is None; otherwise:
+  layer_norm(old_input + dropout(new_input)).
+
+  Args:
+    old_input: old float32 Tensor input to residual layer
+    new_input: new float32 Tensor input to residual layer
+    dropout_keep_rate: dropout proportion of units to keep
+    layer_norm: network_units.LayerNorm to apply to residual output, or None
+
+  Returns:
+    float32 Tensor output of residual layer.
+  """
+  res_sum = old_input + network_units.maybe_apply_dropout(new_input,
+                                                          dropout_keep_rate,
+                                                          False)
+  return layer_norm.normalize(res_sum) if layer_norm else res_sum
+
+
+def mlp(component, input_tensor, dropout_keep_rate, depth):
+  """Feed the input through an MLP.
+
+  Each layer except the last is followed by a ReLU activation and dropout.
+
+  Args:
+    component: the DRAGNN Component containing parameters for the MLP
+    input_tensor: the float32 Tensor input to the MLP.
+    dropout_keep_rate: dropout proportion of units to keep
+    depth: depth of the MLP.
+
+  Returns:
+    the float32 output Tensor
+  """
+  for i in range(depth):
+    ff_weights = component.get_variable('ff_weights_%d' % i)
+    input_tensor = tf.nn.conv2d(input_tensor,
+                                ff_weights,
+                                [1, 1, 1, 1],
+                                padding='SAME')
+    # Apply ReLU and dropout to all but the last layer
+    if i < depth - 1:
+      input_tensor = tf.nn.relu(input_tensor)
+      input_tensor = network_units.maybe_apply_dropout(input_tensor,
+                                                       dropout_keep_rate,
+                                                       False)
+  return input_tensor
+
+
+class TransformerEncoderNetwork(network_units.NetworkUnitInterface):
+  """Implementation of the Transformer network encoder."""
+
+  def __init__(self, component):
+    """Initializes parameters for this Transformer unit.
+
+    Args:
+      component: parent ComponentBuilderBase object.
+
+    Parameters used to construct the network:
+      num_layers: number of transformer layers (attention + MLP)
+      hidden_size: size of hidden layers in MLPs
+      filter_size: filter width for each attention head
+      num_heads: number of attention heads
+      residual_dropout: dropout keep rate for residual layers
+      attention_dropout: dropout keep rate for attention weights
+      mlp_dropout: dropout keep rate for mlp layers
+      initialization: initialization scheme to use for model parameters
+      bias_init: initial value for bias parameters
+      scale_attention: whether to scale attention parameters by filter_size^-0.5
+      layer_norm_residuals: whether to perform layer normalization on residual
+        layers
+      timing_signal: whether to add a position-wise timing signal to the input
+      kernel: kernel width in middle MLP layers
+      mlp_layers: number of MLP layers. Must be >= 2.
+
+    Raises:
+      ValueError: if mlp_layers < 2.
+
+    The input depth of the first layer is inferred from the total concatenated
+    size of the input features, minus 1 to account for the sequence lengths.
+
+    Hyperparameters used:
+      dropout_rate: The probability that an input is not dropped. This is the
+          default when the |dropout_keep_prob| parameter is unset.
+    """
+
+    super(TransformerEncoderNetwork, self).__init__(component)
+    default_dropout_rate = component.master.hyperparams.dropout_rate
+    self._attrs = network_units.get_attrs_with_defaults(
+        component.spec.network_unit.parameters, defaults={
+            'num_layers': 4,
+            'hidden_size': 256,
+            'filter_size': 64,
+            'num_heads': 8,
+            'residual_drop': default_dropout_rate,
+            'attention_drop': default_dropout_rate,
+            'mlp_drop': default_dropout_rate,
+            'initialization': 'xavier',
+            'bias_init': 0.001,
+            'scale_attention': True,
+            'layer_norm_residuals': True,
+            'timing_signal': True,
+            'kernel': 1,
+            'mlp_layers': 2})
+
+    self._num_layers = self._attrs['num_layers']
+    self._hidden_size = self._attrs['hidden_size']
+    self._filter_size = self._attrs['filter_size']
+    self._num_heads = self._attrs['num_heads']
+    self._residual_dropout = self._attrs['residual_drop']
+    self._attention_dropout = self._attrs['attention_drop']
+    self._mlp_dropout = self._attrs['mlp_drop']
+    self._initialization = self._attrs['initialization']
+    self._bias_init = self._attrs['bias_init']
+    self._scale_attn = self._attrs['scale_attention']
+    self._layer_norm_res = self._attrs['layer_norm_residuals']
+    self._timing_signal = self._attrs['timing_signal']
+    self._kernel = self._attrs['kernel']
+    self._mlp_depth = self._attrs['mlp_layers']
+
+    if self._mlp_depth < 2:
+      raise ValueError('TransformerEncoderNetwork needs mlp_layers >= 2')
+
+    self._combined_filters = self._num_heads * self._filter_size
+
+    self._weights = []
+    self._biases = []
+    self._layer_norms = {}
+
+    # Hacky: one dimension comes from the lengths input; subtract it.
+    self._concatenated_input_dim -= 1
+
+    # Initial projection of inputs, this is mainly to project input down to the
+    # right size for residual layers
+    proj_shape = [1, 1, self._concatenated_input_dim, self._combined_filters]
+    self._weights.append(
+        network_units.add_var_initialized('init_proj', proj_shape,
+                                          self._initialization))
+    self._biases.append(tf.get_variable('init_bias',
+                                        self._combined_filters,
+                                        initializer=tf.constant_initializer(
+                                            self._bias_init),
+                                        dtype=tf.float32))
+
+    for i in range(self._num_layers):
+      with tf.variable_scope('transform_%d' % i):
+        # Attention weights: 3 * self.combined_filters = (q, k, v)
+        # We assume that q, k and v all have the same dimension
+        attn_shape = [1, 1, self._combined_filters, 3 * self._combined_filters]
+        self._weights.append(
+            network_units.add_var_initialized('attn_weights',
+                                              attn_shape,
+                                              self._initialization))
+
+        # Attention final projection weights
+        proj_shape = [1, 1, self._combined_filters, self._combined_filters]
+        self._weights.append(
+            network_units.add_var_initialized('proj_weights',
+                                              proj_shape,
+                                              self._initialization))
+
+        # MLP weights
+        with tf.variable_scope('mlp'):
+          ff_shape = [1, 1, self._combined_filters, self._hidden_size]
+          self._weights.append(
+              network_units.add_var_initialized('ff_weights_0',
+                                                ff_shape,
+                                                self._initialization))
+          ff_shape = [1, self._kernel, self._hidden_size, self._hidden_size]
+          for j in range(1, self._mlp_depth - 1):
+            self._weights.append(
+                network_units.add_var_initialized('ff_weights_%d' % j,
+                                                  ff_shape,
+                                                  self._initialization))
+          ff_shape = [1, 1, self._hidden_size, self._combined_filters]
+          self._weights.append(
+              network_units.add_var_initialized('ff_weights_%d' %
+                                                (self._mlp_depth - 1),
+                                                ff_shape,
+                                                self._initialization))
+
+        # Layer normalization for residual layers
+        if self._layer_norm_res:
+          attn_layer_norm = network_units.LayerNorm(component,
+                                                    'attn_layer_norm_%d' % i,
+                                                    self._combined_filters,
+                                                    tf.float32)
+          self._layer_norms['attn_layer_norm_%d' % i] = attn_layer_norm
+
+          ff_layer_norm = network_units.LayerNorm(component,
+                                                  'ff_layer_norm_%d' % i,
+                                                  self._combined_filters,
+                                                  tf.float32)
+          self._layer_norms['ff_layer_norm_%d' % i] = ff_layer_norm
+
+          # Layer norm parameters are not added to self._weights,
+          # which means that they are not l2 regularized
+          self._params.extend(attn_layer_norm.params + ff_layer_norm.params)
+
+    self._params.extend(self._weights)
+    self._params.extend(self._biases)
+    self._regularized_weights.extend(self._weights)
+    self._layers.append(
+        network_units.Layer(component, name='transformer_output',
+                            dim=self._combined_filters))
+
+  def create(self,
+             fixed_embeddings,
+             linked_embeddings,
+             context_tensor_arrays,
+             attention_tensor,
+             during_training,
+             stride=None):
+    """Requires |stride|; otherwise see base class."""
+    del context_tensor_arrays, attention_tensor
+    if stride is None:
+      raise RuntimeError("TransformerEncoderNetwork needs 'stride' and must be "
+                         "called in the bulk feature extractor component.")
+
+    lengths = network_units.lookup_named_tensor('lengths', linked_embeddings)
+    lengths_s = tf.to_int32(tf.squeeze(lengths.tensor, [1]))
+    num_steps = tf.reduce_max(lengths_s)
+
+    in_tensor = network_units.lookup_named_tensor('features', linked_embeddings)
+    input_tensor = tf.reshape(in_tensor.tensor, [stride, num_steps, -1])
+
+    if self._timing_signal:
+      input_tensor = add_timing_signal_1d(input_tensor)
+
+    # Adds a dimension for conv2d
+    input_tensor = tf.expand_dims(input_tensor, 1)
+
+    # For masking padding in attention
+    mask = compute_padding_mask(lengths_s)
+
+    conv = tf.nn.conv2d(input_tensor,
+                        self._component.get_variable('init_proj'),
+                        [1, 1, 1, 1], padding='SAME')
+    conv = tf.nn.bias_add(conv, self._component.get_variable('init_bias'))
+
+    for i in range(self._num_layers):
+      with tf.variable_scope('transform_%d' % i, reuse=True):
+        attn_weights = self._component.get_variable('attn_weights')
+        attn_combined = tf.nn.conv2d(conv,
+                                     attn_weights,
+                                     [1, 1, 1, 1],
+                                     padding='SAME')
+        attn_combined = tf.squeeze(attn_combined, 1)
+
+        # Splits combined projection into queries, keys, and values
+        queries, keys, values = tf.split(attn_combined,
+                                         [self._combined_filters]*3,
+                                         axis=2)
+
+        # Splits each of queries, keys, values into attention heads
+        queries = split_heads(queries, self._num_heads)
+        keys = split_heads(keys, self._num_heads)
+        values = split_heads(values, self._num_heads)
+        if self._scale_attn:
+          queries *= self._filter_size**-0.5
+
+        # Performs dot product attention and concatenates the resulting heads
+        attended = dot_product_attention(queries, keys, values,
+                                         self._attention_dropout, mask)
+        attended = combine_heads(attended)
+
+        # Projects combined heads
+        attended = tf.expand_dims(attended, 1)
+        proj = tf.nn.conv2d(attended,
+                            self._component.get_variable('proj_weights'),
+                            [1, 1, 1, 1],
+                            padding='SAME')
+
+        # Residual connection between input and attended input
+        attn_layer_norm_params = None
+        if self._layer_norm_res:
+          attn_layer_norm_params = self._layer_norms['attn_layer_norm_%d' % i]
+        proj_res = residual(conv, proj, self._residual_dropout,
+                            attn_layer_norm_params)
+
+        # Feed forward
+        with tf.variable_scope('mlp'):
+          ff = mlp(self._component, proj_res, self._mlp_dropout,
+                   self._mlp_depth)
+
+        # Residual connection between attended input and feed forward layers
+        ff_layer_norm_params = None
+        if self._layer_norm_res:
+          ff_layer_norm_params = self._layer_norms['ff_layer_norm_%d' % i]
+        conv = residual(proj_res, ff, self._residual_dropout,
+                        ff_layer_norm_params)
+
+    return [tf.reshape(conv, [-1, self._combined_filters],
+                       name='reshape_activations')]
+
+
+class PairwiseBilinearLabelNetwork(network_units.NetworkUnitInterface):
+  r"""Network unit that computes pairwise bilinear label scores.
+
+  Given source and target representations for each token, this network unit
+  computes bilinear scores for each label for each of the N^2 combinations of
+  source and target tokens, rather than for only N already-computed
+  source/target pairs (as is performed by the biaffine_units). The output is
+  suitable as input to e.g. the heads_labels transition system.
+  Specifically, a weights tensor W called `bilinear' is used to compute bilinear
+  scores B for input tensors S and T:
+
+    B_{bnml} = \sum_{i,j} S_{bni} W_{ilj} T{bmj}
+
+  for batches b, steps n and m and labels l.
+
+  Parameters:
+    num_labels: The number of dependency labels, L.
+
+  Features:
+    sources: [B * N, S] matrix of batched activations for source tokens.
+    targets: [B * N, T] matrix of batched activations for target tokens.
+
+  Layers:
+    bilinear_scores: [B * N, N * L] matrix where vector b*N*N*L+t contains
+                     per-label scores for all N possible arcs from token t in
+                     batch b.
+  """
+
+  def __init__(self, component):
+    super(PairwiseBilinearLabelNetwork, self).__init__(component)
+    parameters = component.spec.network_unit.parameters
+
+    self._num_labels = int(parameters['num_labels'])
+
+    self._source_dim = self._linked_feature_dims['sources']
+    self._target_dim = self._linked_feature_dims['targets']
+
+    self._weights = []
+    self._weights.append(
+        network_units.add_var_initialized('bilinear',
+                                          [self._source_dim,
+                                           self._num_labels,
+                                           self._target_dim],
+                                          'xavier'))
+
+    self._params.extend(self._weights)
+    self._regularized_weights.extend(self._weights)
+    self._layers.append(network_units.Layer(component,
+                                            name='bilinear_scores',
+                                            dim=self._num_labels))
+
+  def create(self,
+             fixed_embeddings,
+             linked_embeddings,
+             context_tensor_arrays,
+             attention_tensor,
+             during_training,
+             stride=None):
+    """Requires |stride|; otherwise see base class."""
+    del context_tensor_arrays, attention_tensor
+    if stride is None:
+      raise RuntimeError("PairwiseBilinearLabelNetwork needs 'stride' and must "
+                         "be called in a bulk component.")
+
+    sources = network_units.lookup_named_tensor('sources', linked_embeddings)
+    sources_tensor = tf.reshape(sources.tensor, [stride, -1, self._source_dim])
+
+    targets = network_units.lookup_named_tensor('targets', linked_embeddings)
+    targets_tensor = tf.reshape(targets.tensor, [stride, -1, self._target_dim])
+
+    # Dimensions: source_dim x num_labels x target_dim
+    bilinear_params = self._component.get_variable('bilinear')
+
+    # Ensures that num_steps is the same for both inputs
+    num_steps = tf.shape(sources_tensor)[1]
+    with tf.control_dependencies([tf.assert_equal(num_steps,
+                                                  tf.shape(targets_tensor)[1],
+                                                  name='num_steps_mismatch')]):
+      # Dimensions:
+      # (batch_size*num_steps x source_dim) *
+      #   (source_dim x num_labels*target_dim)
+      #     = (batch_size*num_steps x num_labels*target_dim)
+      lin = tf.matmul(tf.reshape(sources_tensor, [-1, self._source_dim]),
+                      tf.reshape(bilinear_params, [self._source_dim, -1]))
+
+      # (batch_size x num_steps*num_labels x target_dim) *
+      #   (batch_size x num_steps x target_dim)^T
+      #     = (batch_size x num_steps*num_labels x num_steps)
+      bilin = tf.matmul(
+          tf.reshape(lin, [-1, num_steps*self._num_labels, self._target_dim]),
+          targets_tensor, transpose_b=True)
+
+    # (batch_size x num_steps*num_labels x num_steps) ->
+    #   (batch_size x num_steps x num_steps*num_labels)
+    scores = tf.transpose(bilin, [0, 2, 1])
+
+    return [tf.reshape(scores, [-1, num_steps*self._num_labels],
+                       name='reshape_activations')]
diff --git a/research/syntaxnet/dragnn/python/transformer_units_test.py b/research/syntaxnet/dragnn/python/transformer_units_test.py
new file mode 100644
index 00000000..8c80eb92
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/transformer_units_test.py
@@ -0,0 +1,90 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Tests for dragnn.python.transformer_units."""
+
+
+import numpy as np
+import tensorflow as tf
+
+from tensorflow.python.framework import test_util
+from tensorflow.python.platform import googletest
+
+from dragnn.python import transformer_units
+
+
+class TransformerTest(test_util.TensorFlowTestCase):
+
+  def testComputePadding(self):
+    with tf.Graph().as_default(), self.test_session() as session:
+      lengths = [5, 1, 2, 0]
+      expected = [[[[0, 0, 0, 0, 0]]],
+                  [[[0, -1e9, -1e9, -1e9, -1e9]]],
+                  [[[0, 0, -1e9, -1e9, -1e9]]],
+                  [[[-1e9, -1e9, -1e9, -1e9, -1e9]]]]
+      tensor = transformer_units.compute_padding_mask(lengths)
+      session.run(tf.global_variables_initializer())
+      actual = session.run(tensor)
+      self.assertAllEqual(actual, expected)
+
+  def testDotProductAttention(self):
+    with tf.Graph().as_default(), self.test_session() as session:
+      padding = [[[[0, 0, 0, 0, 0]]],
+                 [[[0, -1e9, -1e9, -1e9, -1e9]]]]
+      # batch x heads x length x d
+      np.random.seed(4)
+      q = np.random.random((2, 2, 5, 2)).astype(np.float32)
+      k = np.random.random((2, 2, 5, 2)).astype(np.float32)
+      v = np.random.random((2, 2, 5, 2)).astype(np.float32)
+
+      # Should have shape: 2x2x5x5. Computed as follows:
+      # r = np.einsum('hijk,hilk->hijl', q, k) + padding_bias
+      # r = r - np.expand_dims(np.max(r, axis=-1), -1)
+      # r = np.exp(r)
+      # ax_sum = np.expand_dims(np.sum(r, axis=-1), -1)
+      # r = r / ax_sum
+      # for i in range(2):
+      #   for j in range(2):
+      #     np.dot(r[i,j], v[i,j])
+      expected = [[[[0.46580601, 0.64643575],
+                    [0.46182397, 0.64578158],
+                    [0.46866544, 0.64562998],
+                    [0.47930001, 0.64838011],
+                    [0.45466267, 0.64061598]],
+                   [[0.50887558, 0.39900422],
+                    [0.51721343, 0.39245871],
+                    [0.50348963, 0.40090425],
+                    [0.49889359, 0.4035989],
+                    [0.50523872, 0.39916877]]],
+                  [[[0.26092216, 0.41247222],
+                    [0.26092216, 0.41247222],
+                    [0.26092216, 0.41247222],
+                    [0.26092216, 0.41247222],
+                    [0.26092216, 0.41247222]],
+                   [[0.34745133, 0.05888009],
+                    [0.34745133, 0.05888009],
+                    [0.34745133, 0.05888009],
+                    [0.34745133, 0.05888009],
+                    [0.34745133, 0.05888009]]]]
+
+      tensor = transformer_units.dot_product_attention(q, k, v, 1.0, padding)
+      session.run(tf.global_variables_initializer())
+      actual = session.run(tensor)
+
+      self.assertAllClose(actual, expected, 1e-6, 1e-6)
+
+
+if __name__ == '__main__':
+  googletest.main()
diff --git a/research/syntaxnet/dragnn/python/visualization.py b/research/syntaxnet/dragnn/python/visualization.py
index f39c80bb..76ac144c 100644
--- a/research/syntaxnet/dragnn/python/visualization.py
+++ b/research/syntaxnet/dragnn/python/visualization.py
@@ -12,7 +12,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Helper library for visualizations.
 
 TODO(googleuser): Find a more reliable way to serve stuff from IPython
@@ -64,6 +63,17 @@ def parse_trace_json(trace):
     JSON str, as expected by visualization tools.
   """
   as_proto = trace_pb2.MasterTrace.FromString(trace)
+
+  # Sanitize non-UTF8 captions. One case where this occurs is for byte LSTMs,
+  # which may be processing a sub-sequence of a UTF-8 multi-byte sequence.
+  for component_trace in as_proto.component_trace:
+    for step_trace in component_trace.step_trace:
+      if isinstance(step_trace.caption, str):
+        try:
+          unicode(step_trace.caption, 'utf-8')
+        except UnicodeDecodeError:
+          step_trace.caption = repr(step_trace.caption)  # Safe encoding.
+
   as_json = json_format.MessageToJson(
       as_proto, preserving_proto_field_name=True)
   return as_json
diff --git a/research/syntaxnet/dragnn/python/wrapped_units.py b/research/syntaxnet/dragnn/python/wrapped_units.py
index 4843aa41..5e6347f6 100644
--- a/research/syntaxnet/dragnn/python/wrapped_units.py
+++ b/research/syntaxnet/dragnn/python/wrapped_units.py
@@ -27,6 +27,60 @@ from dragnn.python import network_units as dragnn
 from syntaxnet.util import check
 
 
+def capture_variables(function, scope_name):
+  """Captures and returns variables created by a function.
+
+  Runs |function| in a scope of name |scope_name| and returns the list of
+  variables created by |function|.
+
+  Args:
+    function: Function whose variables should be captured.  The function should
+        take one argument, its enclosing variable scope.
+    scope_name: Variable scope in which the |function| is evaluated.
+
+  Returns:
+    List of created variables.
+  """
+  # Use a dict to dedupe captured variables.
+  created_vars = {}
+
+  def _custom_getter(getter, *args, **kwargs):
+    """Calls the real getter and captures its result in |created_vars|."""
+    real_variable = getter(*args, **kwargs)
+    created_vars[real_variable.name] = real_variable
+    return real_variable
+
+  with tf.variable_scope(
+      scope_name, reuse=None, custom_getter=_custom_getter) as scope:
+    function(scope)
+  return created_vars.values()
+
+
+def apply_with_captured_variables(function, scope_name, component):
+  """Applies a function using previously-captured variables.
+
+  The counterpart to capture_variables(); invokes |function| in a scope of name
+  |scope_name|, extracting captured variables from the |component|.
+
+  Args:
+    function: Function to apply using captured variables.  The function should
+        take one argument, its enclosing variable scope.
+    scope_name: Variable scope in which the |function| is evaluated.  Must match
+        the scope passed to capture_variables().
+    component: Component from which to extract captured variables.
+
+  Returns:
+    Results of function application.
+  """
+  def _custom_getter(getter, *args, **kwargs):
+    """Retrieves the normal or moving-average variables."""
+    return component.get_variable(var_params=getter(*args, **kwargs))
+
+  with tf.variable_scope(
+      scope_name, reuse=True, custom_getter=_custom_getter) as scope:
+    return function(scope)
+
+
 class BaseLSTMNetwork(dragnn.NetworkUnitInterface):
   """Base class for wrapped LSTM networks.
 
@@ -179,43 +233,12 @@ class BaseLSTMNetwork(dragnn.NetworkUnitInterface):
     ]
 
   def _capture_variables_as_params(self, function):
-    """Captures variables created by a function in |self._params|.
-
-    Args:
-      function: Function whose variables should be captured.  The function
-          should take one argument, its enclosing variable scope.
-    """
-    created_vars = {}
-
-    def _custom_getter(getter, *args, **kwargs):
-      """Calls the real getter and captures its result in |created_vars|."""
-      real_variable = getter(*args, **kwargs)
-      created_vars[real_variable.name] = real_variable
-      return real_variable
-
-    with tf.variable_scope(
-        'cell', reuse=None, custom_getter=_custom_getter) as scope:
-      function(scope)
-    self._params.extend(created_vars.values())
+    """Captures variables created by a function in |self._params|."""
+    self._params.extend(capture_variables(function, 'cell'))
 
   def _apply_with_captured_variables(self, function):
-    """Applies a function using previously-captured variables.
-
-    Args:
-      function: Function to apply using captured variables.  The function
-          should take one argument, its enclosing variable scope.
-
-    Returns:
-      Results of function application.
-    """
-
-    def _custom_getter(getter, *args, **kwargs):
-      """Retrieves the normal or moving-average variables."""
-      return self._component.get_variable(var_params=getter(*args, **kwargs))
-
-    with tf.variable_scope(
-        'cell', reuse=True, custom_getter=_custom_getter) as scope:
-      return function(scope)
+    """Applies a function using previously-captured variables."""
+    return apply_with_captured_variables(function, 'cell', self._component)
 
 
 class LayerNormBasicLSTMNetwork(BaseLSTMNetwork):
diff --git a/research/syntaxnet/dragnn/tensorflow_ops.bzl b/research/syntaxnet/dragnn/tensorflow_ops.bzl
index 6d5ac9c3..473b7a59 100644
--- a/research/syntaxnet/dragnn/tensorflow_ops.bzl
+++ b/research/syntaxnet/dragnn/tensorflow_ops.bzl
@@ -331,7 +331,7 @@ def tf_cc_test(name, srcs, deps, linkstatic=0, tags=[], data=[], size="medium",
                  linkstatic=linkstatic,
                  tags=tags)
 
-# Part of the testing workflow requires a distinguishable name for the build
+# Part of the testing process requires a distinguishable name for the build
 # rules that involve a GPU, even if otherwise identical to the base rule.
 def tf_cc_test_gpu(name, srcs, deps, linkstatic=0, tags=[], data=[],
                    size="medium", suffix="", args=None):
@@ -534,13 +534,13 @@ def _py_wrap_cc_impl(ctx):
     fail("Exactly one SWIG source file label must be specified.", "srcs")
   module_name = ctx.attr.module_name
   src = ctx.files.srcs[0]
-  inputs = set([src])
+  inputs = depset([src])
   inputs += ctx.files.swig_includes
   for dep in ctx.attr.deps:
     inputs += dep.cc.transitive_headers
   inputs += ctx.files._swiglib
   inputs += ctx.files.toolchain_deps
-  swig_include_dirs = set(_get_repository_roots(ctx, inputs))
+  swig_include_dirs = depset(_get_repository_roots(ctx, inputs))
   swig_include_dirs += sorted([f.dirname for f in ctx.files._swiglib])
   args = ["-c++",
           "-python",
@@ -558,7 +558,7 @@ def _py_wrap_cc_impl(ctx):
              outputs=outputs,
              mnemonic="PythonSwig",
              progress_message="SWIGing " + src.path)
-  return struct(files=set(outputs))
+  return struct(files=depset(outputs))
 
 _py_wrap_cc = rule(
     attrs = {
@@ -627,7 +627,7 @@ def _get_repository_roots(ctx, files):
 
 # Bazel rule for collecting the header files that a target depends on.
 def _transitive_hdrs_impl(ctx):
-  outputs = set()
+  outputs = depset()
   for dep in ctx.attr.deps:
     outputs += dep.cc.transitive_headers
   return struct(files=outputs)
@@ -669,10 +669,10 @@ def tf_custom_op_library_additional_deps():
 # tf_collected_deps will be the union of the deps of the current target
 # and the tf_collected_deps of the dependencies of this target.
 def _collect_deps_aspect_impl(target, ctx):
-  alldeps = set()
+  alldeps = depset()
   if hasattr(ctx.rule.attr, "deps"):
     for dep in ctx.rule.attr.deps:
-      alldeps = alldeps | set([dep.label])
+      alldeps = alldeps | depset([dep.label])
       if hasattr(dep, "tf_collected_deps"):
         alldeps = alldeps | dep.tf_collected_deps
   return struct(tf_collected_deps=alldeps)
diff --git a/research/syntaxnet/dragnn/tools/BUILD b/research/syntaxnet/dragnn/tools/BUILD
index 84a35225..1a7f800a 100644
--- a/research/syntaxnet/dragnn/tools/BUILD
+++ b/research/syntaxnet/dragnn/tools/BUILD
@@ -5,6 +5,18 @@ filegroup(
     srcs = glob(["testdata/**"]),
 )
 
+py_binary(
+    name = "conll_checkpoint_converter",
+    srcs = ["conll_checkpoint_converter.py"],
+    deps = [
+        "//dragnn/protos:spec_py_pb2",
+        "//dragnn/python:dragnn_model_saver_lib",
+        "//dragnn/python:spec_builder",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+        "@org_tensorflow//tensorflow/core:protos_all_py",
+    ],
+)
+
 py_binary(
     name = "evaluator",
     srcs = ["evaluator.py"],
@@ -19,6 +31,21 @@ py_binary(
     ],
 )
 
+py_binary(
+    name = "legacy_parse_to_conll",
+    srcs = ["legacy_parse_to_conll.py"],
+    tags = [
+        "notap",
+        "optonly",
+    ],
+    deps = [
+        ":components",
+        "//dragnn/python:dragnn_ops",
+        "//dragnn/python:evaluation",
+        "//dragnn/python:spec_builder",
+    ],
+)
+
 py_binary(
     name = "segmenter-evaluator",
     srcs = ["segmenter-evaluator.py"],
@@ -35,8 +62,8 @@ py_binary(
 )
 
 py_binary(
-    name = "parse-to-conll",
-    srcs = ["parse-to-conll.py"],
+    name = "parse_to_conll",
+    srcs = ["parse_to_conll.py"],
     tags = [
         "notap",
         "optonly",
@@ -44,6 +71,7 @@ py_binary(
     deps = [
         ":components",
         "//dragnn/python:dragnn_ops",
+        "//dragnn/python:evaluation",
         "//dragnn/python:spec_builder",
     ],
 )
@@ -85,11 +113,9 @@ py_binary(
         "//dragnn/protos:spec_py_pb2",
         "//dragnn/python:evaluation",
         "//dragnn/python:graph_builder",
-        "//dragnn/python:load_dragnn_cc_impl_py",
         "//dragnn/python:sentence_io",
         "//dragnn/python:spec_builder",
         "//dragnn/python:trainer_lib",
-        "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:parser_ops",
         "@org_tensorflow//tensorflow:tensorflow_py",
         "@org_tensorflow//tensorflow/core:protos_all_py",
@@ -106,11 +132,9 @@ py_binary(
         "//dragnn/python:dragnn_ops",
         "//dragnn/python:evaluation",
         "//dragnn/python:graph_builder",
-        "//dragnn/python:load_dragnn_cc_impl_py",
         "//dragnn/python:sentence_io",
         "//dragnn/python:spec_builder",
         "//dragnn/python:trainer_lib",
-        "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:parser_ops",
         "//syntaxnet:sentence_py_pb2",
         "//syntaxnet:task_spec_py_pb2",
@@ -168,9 +192,7 @@ py_library(
         "//dragnn/core:dragnn_ops",
         "//dragnn/protos:spec_py_pb2",
         "//dragnn/python:graph_builder",
-        "//dragnn/python:load_dragnn_cc_impl_py",
         "//dragnn/python:sentence_io",
-        "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:parser_ops",
         "//syntaxnet:sentence_py_pb2",
         "@org_tensorflow//tensorflow:tensorflow_py",
diff --git a/research/syntaxnet/dragnn/tools/benchmarks/BUILD b/research/syntaxnet/dragnn/tools/benchmarks/BUILD
new file mode 100644
index 00000000..77eeebf4
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/benchmarks/BUILD
@@ -0,0 +1,11 @@
+cc_test(
+    name = "beam_benchmark",
+    srcs = ["beam_benchmark.cc"],
+    deps = [
+        "//dragnn/core:beam",
+        "//dragnn/core/interfaces:cloneable_transition_state",
+        "//dragnn/core/interfaces:transition_state",
+        "//dragnn/core/test:mock_transition_state",
+        "@org_tensorflow//tensorflow/core:test",
+    ],
+)
diff --git a/research/syntaxnet/dragnn/tools/benchmarks/beam_benchmark.cc b/research/syntaxnet/dragnn/tools/benchmarks/beam_benchmark.cc
new file mode 100644
index 00000000..9e677d2f
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/benchmarks/beam_benchmark.cc
@@ -0,0 +1,193 @@
+// Copyright 2017 Google Inc. All Rights Reserved.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+// =============================================================================
+
+#include "dragnn/core/beam.h"
+
+#include <limits>
+#include <random>
+
+#include "dragnn/core/interfaces/cloneable_transition_state.h"
+#include "dragnn/core/interfaces/transition_state.h"
+#include "dragnn/core/test/mock_transition_state.h"
+#include <gmock/gmock.h>
+#include "tensorflow/core/platform/test.h"
+#include "tensorflow/core/platform/test_benchmark.h"
+
+namespace syntaxnet {
+namespace dragnn {
+
+using testing::MockFunction;
+using testing::Ne;
+using testing::Return;
+using testing::_;
+
+namespace {
+
+// *****************************************************************************
+// Test-internal class definitions.
+// *****************************************************************************
+
+// Create a very basic transition state to test the beam. All it does is keep
+// track of its current beam index and score, as well as providing a field
+// for the transition function to write in what transition occurred.
+// Note that this class does not fulfill the entire TransitionState contract,
+// since it is only used in this particular test.
+class TestTransitionState
+    : public CloneableTransitionState<TestTransitionState> {
+ public:
+  TestTransitionState() : is_gold_(false) {}
+
+  void Init(const TransitionState &parent) override {}
+
+  std::unique_ptr<TestTransitionState> Clone() const override {
+    std::unique_ptr<TestTransitionState> ptr(new TestTransitionState());
+    return ptr;
+  }
+
+  int ParentBeamIndex() const override { return parent_beam_index_; }
+
+  // Gets the current beam index for this state.
+  int GetBeamIndex() const override { return beam_index_; }
+
+  // Sets the current beam index for this state.
+  void SetBeamIndex(int index) override { beam_index_ = index; }
+
+  // Gets the score associated with this transition state.
+  float GetScore() const override { return score_; }
+
+  // Sets the score associated with this transition state.
+  void SetScore(float score) override { score_ = score; }
+
+  // Gets the gold-ness of this state (whether it is on the oracle path)
+  bool IsGold() const override { return is_gold_; }
+
+  // Sets the gold-ness of this state.
+  void SetGold(bool is_gold) override { is_gold_ = is_gold; }
+
+  // Depicts this state as an HTML-language string.
+  string HTMLRepresentation() const override { return ""; }
+
+  int parent_beam_index_;
+
+  int beam_index_;
+
+  float score_;
+
+  int transition_action_;
+
+  bool is_gold_;
+};
+
+// This transition function annotates a TestTransitionState with the action that
+// was chosen for the transition.
+auto transition_function = [](TestTransitionState *state, int action) {
+  TestTransitionState *cast_state = dynamic_cast<TestTransitionState *>(state);
+  cast_state->transition_action_ = action;
+};
+
+// Creates oracle and permission functions that do nothing.
+auto null_oracle = [](TestTransitionState *) -> const vector<int> {
+  return {0};
+};
+auto null_permissions = [](TestTransitionState *, int) { return true; };
+auto null_finality = [](TestTransitionState *) { return false; };
+
+// Creates a unique_ptr with a test transition state in it and set its initial
+// score.
+std::unique_ptr<TestTransitionState> CreateState(float score) {
+  std::unique_ptr<TestTransitionState> state;
+  state.reset(new TestTransitionState());
+  state->SetScore(score);
+  return state;
+}
+
+}  // namespace
+
+// *****************************************************************************
+// Tests begin here.
+// *****************************************************************************
+// Helper function for creating random transition matrices of a particular size.
+std::vector<float> MakeRandomVector(int size) {
+  std::default_random_engine engine;
+  std::uniform_real_distribution<float> dist(0., 10.);
+  auto gen = std::bind(dist, engine);
+  std::vector<float> vec(size);
+  std::generate(vec.begin(), vec.end(), gen);
+  return vec;
+}
+
+// Benchmark Beam::FastAdvanceFromPrediction for a beam size of 1 and
+// a variety of transition system sizes.
+void BM_FastAdvance(int num_iters, int num_transitions) {
+  tensorflow::testing::StopTiming();
+
+  // Create a matrix of transitions.
+  constexpr int kMaxBeamSize = 1;
+  const int matrix_size = num_transitions * kMaxBeamSize;
+  const std::vector<float> matrix = MakeRandomVector(matrix_size);
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  constexpr float kOldScore = 4.0;
+  states.push_back(CreateState(kOldScore));
+
+  Beam<TestTransitionState> beam(kMaxBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(matrix.data(), matrix_size, num_transitions);
+  ASSERT_EQ(beam.beam().size(), kMaxBeamSize);
+
+  tensorflow::testing::StartTiming();
+  for (int i = 0; i < num_iters; ++i) {
+    beam.FastAdvanceFromPrediction(matrix.data(), num_transitions);
+  }
+  ASSERT_EQ(beam.beam().size(), kMaxBeamSize);
+}
+BENCHMARK(BM_FastAdvance)->Range(2, 128);
+
+// Benchmark Beam::BeamAdvanceFromPrediction for a variety of beam
+// sizes and transition system sizes.
+void BM_BeamAdvance(int num_iters, int num_transitions, int max_beam_size) {
+  tensorflow::testing::StopTiming();
+
+  // Create a matrix of transitions.
+  const int matrix_size = num_transitions * max_beam_size;
+  const std::vector<float> matrix = MakeRandomVector(matrix_size);
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  constexpr float kOldScore = 4.0;
+  states.push_back(CreateState(kOldScore));
+
+  Beam<TestTransitionState> beam(max_beam_size);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+  while (beam.beam().size() < max_beam_size) {
+    beam.AdvanceFromPrediction(matrix.data(), matrix_size, num_transitions);
+  }
+  ASSERT_EQ(beam.beam().size(), max_beam_size);
+
+  tensorflow::testing::StartTiming();
+  for (int i = 0; i < num_iters; ++i) {
+    beam.BeamAdvanceFromPrediction(matrix.data(), matrix_size, num_transitions);
+  }
+  ASSERT_EQ(beam.beam().size(), max_beam_size);
+}
+BENCHMARK(BM_BeamAdvance)->RangePair(2, 128, 1, 64);
+
+}  // namespace dragnn
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/tools/conll_checkpoint_converter.py b/research/syntaxnet/dragnn/tools/conll_checkpoint_converter.py
new file mode 100644
index 00000000..980dec2b
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/conll_checkpoint_converter.py
@@ -0,0 +1,103 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Conversion script for CoNLL checkpoints to DRAGNN SavedModel format.
+
+This script loads and finishes a CoNLL checkpoint, then exports it as a
+SavedModel. It expects that the CoNLL RNN cells have been updated using the
+RNN update script.
+"""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+import tensorflow as tf
+
+from google.protobuf import text_format
+from dragnn.protos import spec_pb2
+from dragnn.python import dragnn_model_saver_lib as saver_lib
+from dragnn.python import spec_builder
+
+flags = tf.app.flags
+FLAGS = flags.FLAGS
+
+flags.DEFINE_string('master_spec', None, 'Path to task context with '
+                    'inputs and parameters for feature extractors.')
+flags.DEFINE_string('params_path', None, 'Path to trained model parameters.')
+flags.DEFINE_string('export_path', '', 'Output path for exported servo model.')
+flags.DEFINE_string('resource_path', '',
+                    'Base directory for resources in the master spec.')
+flags.DEFINE_bool('export_moving_averages', True,
+                  'Whether to export the moving average parameters.')
+
+
+def export(master_spec_path, params_path, resource_path, export_path,
+           export_moving_averages):
+  """Restores a model and exports it in SavedModel form.
+
+  This method loads a graph specified by the spec at master_spec_path and the
+  params in params_path. It then saves the model in SavedModel format to the
+  location specified in export_path.
+
+  Args:
+    master_spec_path: Path to a proto-text master spec.
+    params_path: Path to the parameters file to export.
+    resource_path: Path to resources in the master spec.
+    export_path: Path to export the SavedModel to.
+    export_moving_averages: Whether to export the moving average parameters.
+  """
+  # Old CoNLL checkpoints did not need a known-word-map. Create a temporary if
+  # that file is missing.
+  if not tf.gfile.Exists(os.path.join(resource_path, 'known-word-map')):
+    with tf.gfile.FastGFile(os.path.join(resource_path, 'known-word-map'),
+                            'w') as out_file:
+      out_file.write('This file intentionally left blank.')
+
+  graph = tf.Graph()
+  master_spec = spec_pb2.MasterSpec()
+  with tf.gfile.FastGFile(master_spec_path) as fin:
+    text_format.Parse(fin.read(), master_spec)
+
+  # This is a workaround for an issue where the segmenter master-spec had a
+  # spurious resource in it; this resource was not respected in the spec-builder
+  # and ended up crashing the saver (since it didn't really exist).
+  for component in master_spec.component:
+    del component.resource[:]
+
+  spec_builder.complete_master_spec(master_spec, None, resource_path)
+
+  # Remove '/' if it exists at the end of the export path, ensuring that
+  # path utils work correctly.
+  stripped_path = export_path.rstrip('/')
+  saver_lib.clean_output_paths(stripped_path)
+
+  short_to_original = saver_lib.shorten_resource_paths(master_spec)
+  saver_lib.export_master_spec(master_spec, graph)
+  saver_lib.export_to_graph(master_spec, params_path, stripped_path, graph,
+                            export_moving_averages)
+  saver_lib.export_assets(master_spec, short_to_original, stripped_path)
+
+
+def main(unused_argv):
+  # Run the exporter.
+  export(FLAGS.master_spec, FLAGS.params_path, FLAGS.resource_path,
+         FLAGS.export_path, FLAGS.export_moving_averages)
+  tf.logging.info('Export complete.')
+
+
+if __name__ == '__main__':
+  tf.app.run()
diff --git a/research/syntaxnet/dragnn/tools/evaluator.py b/research/syntaxnet/dragnn/tools/evaluator.py
index 58d8fbcd..75da5191 100644
--- a/research/syntaxnet/dragnn/tools/evaluator.py
+++ b/research/syntaxnet/dragnn/tools/evaluator.py
@@ -16,7 +16,7 @@
 r"""Runs a DRAGNN model on a given set of CoNLL-formatted sentences.
 
 Sample invocation:
-  bazel run -c opt <...>:dragnn_eval -- \
+  bazel run -c opt <...>:evaluator -- \
     --master_spec="/path/to/master-spec" \
     --checkpoint_file="/path/to/model/name.checkpoint" \
     --input_file="/path/to/input/documents/test.connlu"
@@ -39,9 +39,6 @@ from dragnn.python import sentence_io
 from dragnn.python import spec_builder
 from syntaxnet import sentence_pb2
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/legacy_parse_to_conll.py b/research/syntaxnet/dragnn/tools/legacy_parse_to_conll.py
new file mode 100644
index 00000000..899e9545
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/legacy_parse_to_conll.py
@@ -0,0 +1,243 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+r"""Runs a both a segmentation and parsing model on a CoNLL dataset.
+"""
+
+import re
+import time
+
+import tensorflow as tf
+
+from google.protobuf import text_format
+from tensorflow.python.client import timeline
+from tensorflow.python.platform import gfile
+
+from dragnn.protos import spec_pb2
+from dragnn.python import evaluation
+from dragnn.python import graph_builder
+from dragnn.python import sentence_io
+from dragnn.python import spec_builder
+from syntaxnet import sentence_pb2
+from syntaxnet.ops import gen_parser_ops
+from syntaxnet.util import check
+
+flags = tf.app.flags
+FLAGS = flags.FLAGS
+
+
+flags.DEFINE_string('parser_master_spec', '',
+                    'Path to text file containing a DRAGNN master spec to run.')
+flags.DEFINE_string('parser_checkpoint_file', '',
+                    'Path to trained model checkpoint.')
+flags.DEFINE_string('parser_resource_dir', '',
+                    'Optional base directory for resources in the master spec.')
+flags.DEFINE_string('segmenter_master_spec', '',
+                    'Path to text file containing a DRAGNN master spec to run.')
+flags.DEFINE_string('segmenter_checkpoint_file', '',
+                    'Path to trained model checkpoint.')
+flags.DEFINE_string('segmenter_resource_dir', '',
+                    'Optional base directory for resources in the master spec.')
+flags.DEFINE_bool('complete_master_spec', True, 'Whether the master_specs '
+                  'needs the lexicon and other resources added to them.')
+flags.DEFINE_string('input_file', '',
+                    'File of CoNLL-formatted sentences to read from.')
+flags.DEFINE_string('output_file', '',
+                    'File path to write annotated sentences to.')
+flags.DEFINE_integer('max_batch_size', 2048, 'Maximum batch size to support.')
+flags.DEFINE_string('inference_beam_size', '', 'Comma separated list of '
+                    'component_name=beam_size pairs.')
+flags.DEFINE_string('locally_normalize', '', 'Comma separated list of '
+                    'component names to do local normalization on.')
+flags.DEFINE_integer('threads', 10, 'Number of threads used for intra- and '
+                     'inter-op parallelism.')
+flags.DEFINE_string('timeline_output_file', '', 'Path to save timeline to. '
+                    'If specified, the final iteration of the evaluation loop '
+                    'will capture and save a TensorFlow timeline.')
+flags.DEFINE_bool('use_gold_segmentation', False,
+                  'Whether or not to use gold segmentation.')
+flags.DEFINE_bool('text_format', False, '')
+
+
+def main(unused_argv):
+
+  # Parse the flags containing lists, using regular expressions.
+  # This matches and extracts key=value pairs.
+  component_beam_sizes = re.findall(r'([^=,]+)=(\d+)',
+                                    FLAGS.inference_beam_size)
+  # This matches strings separated by a comma. Does not return any empty
+  # strings.
+  components_to_locally_normalize = re.findall(r'[^,]+',
+                                               FLAGS.locally_normalize)
+
+  ## SEGMENTATION ##
+
+  if not FLAGS.use_gold_segmentation:
+
+    # Reads master spec.
+    master_spec = spec_pb2.MasterSpec()
+    with gfile.FastGFile(FLAGS.segmenter_master_spec) as fin:
+      text_format.Parse(fin.read(), master_spec)
+
+    if FLAGS.complete_master_spec:
+      spec_builder.complete_master_spec(
+          master_spec, None, FLAGS.segmenter_resource_dir)
+
+    # Graph building.
+    tf.logging.info('Building the graph')
+    g = tf.Graph()
+    with g.as_default(), tf.device('/device:CPU:0'):
+      hyperparam_config = spec_pb2.GridPoint()
+      hyperparam_config.use_moving_average = True
+      builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
+      annotator = builder.add_annotation()
+      builder.add_saver()
+
+    tf.logging.info('Reading documents...')
+    if FLAGS.text_format:
+      char_corpus = sentence_io.FormatSentenceReader(
+          FLAGS.input_file, 'untokenized-text').corpus()
+    else:
+      input_corpus = sentence_io.ConllSentenceReader(FLAGS.input_file).corpus()
+      with tf.Session(graph=tf.Graph()) as tmp_session:
+        char_input = gen_parser_ops.char_token_generator(input_corpus)
+        char_corpus = tmp_session.run(char_input)
+      check.Eq(len(input_corpus), len(char_corpus))
+
+    session_config = tf.ConfigProto(
+        log_device_placement=False,
+        intra_op_parallelism_threads=FLAGS.threads,
+        inter_op_parallelism_threads=FLAGS.threads)
+
+    with tf.Session(graph=g, config=session_config) as sess:
+      tf.logging.info('Initializing variables...')
+      sess.run(tf.global_variables_initializer())
+      tf.logging.info('Loading from checkpoint...')
+      sess.run('save/restore_all',
+               {'save/Const:0': FLAGS.segmenter_checkpoint_file})
+
+      tf.logging.info('Processing sentences...')
+
+      processed = []
+      start_time = time.time()
+      run_metadata = tf.RunMetadata()
+      for start in range(0, len(char_corpus), FLAGS.max_batch_size):
+        end = min(start + FLAGS.max_batch_size, len(char_corpus))
+        feed_dict = {annotator['input_batch']: char_corpus[start:end]}
+        if FLAGS.timeline_output_file and end == len(char_corpus):
+          serialized_annotations = sess.run(
+              annotator['annotations'], feed_dict=feed_dict,
+              options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
+              run_metadata=run_metadata)
+          trace = timeline.Timeline(step_stats=run_metadata.step_stats)
+          with open(FLAGS.timeline_output_file, 'w') as trace_file:
+            trace_file.write(trace.generate_chrome_trace_format())
+        else:
+          serialized_annotations = sess.run(
+              annotator['annotations'], feed_dict=feed_dict)
+        processed.extend(serialized_annotations)
+
+      tf.logging.info('Processed %d documents in %.2f seconds.',
+                      len(char_corpus), time.time() - start_time)
+
+    input_corpus = processed
+  else:
+    input_corpus = sentence_io.ConllSentenceReader(FLAGS.input_file).corpus()
+
+  ## PARSING
+
+  # Reads master spec.
+  master_spec = spec_pb2.MasterSpec()
+  with gfile.FastGFile(FLAGS.parser_master_spec) as fin:
+    text_format.Parse(fin.read(), master_spec)
+
+  if FLAGS.complete_master_spec:
+    spec_builder.complete_master_spec(
+        master_spec, None, FLAGS.parser_resource_dir)
+
+  # Graph building.
+  tf.logging.info('Building the graph')
+  g = tf.Graph()
+  with g.as_default(), tf.device('/device:CPU:0'):
+    hyperparam_config = spec_pb2.GridPoint()
+    hyperparam_config.use_moving_average = True
+    builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
+    annotator = builder.add_annotation()
+    builder.add_saver()
+
+  tf.logging.info('Reading documents...')
+
+  session_config = tf.ConfigProto(
+      log_device_placement=False,
+      intra_op_parallelism_threads=FLAGS.threads,
+      inter_op_parallelism_threads=FLAGS.threads)
+
+  with tf.Session(graph=g, config=session_config) as sess:
+    tf.logging.info('Initializing variables...')
+    sess.run(tf.global_variables_initializer())
+
+    tf.logging.info('Loading from checkpoint...')
+    sess.run('save/restore_all', {'save/Const:0': FLAGS.parser_checkpoint_file})
+
+    tf.logging.info('Processing sentences...')
+
+    processed = []
+    start_time = time.time()
+    run_metadata = tf.RunMetadata()
+    for start in range(0, len(input_corpus), FLAGS.max_batch_size):
+      end = min(start + FLAGS.max_batch_size, len(input_corpus))
+      feed_dict = {annotator['input_batch']: input_corpus[start:end]}
+      for comp, beam_size in component_beam_sizes:
+        feed_dict['%s/InferenceBeamSize:0' % comp] = beam_size
+      for comp in components_to_locally_normalize:
+        feed_dict['%s/LocallyNormalize:0' % comp] = True
+      if FLAGS.timeline_output_file and end == len(input_corpus):
+        serialized_annotations = sess.run(
+            annotator['annotations'], feed_dict=feed_dict,
+            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
+            run_metadata=run_metadata)
+        trace = timeline.Timeline(step_stats=run_metadata.step_stats)
+        with open(FLAGS.timeline_output_file, 'w') as trace_file:
+          trace_file.write(trace.generate_chrome_trace_format())
+      else:
+        serialized_annotations = sess.run(
+            annotator['annotations'], feed_dict=feed_dict)
+      processed.extend(serialized_annotations)
+
+    tf.logging.info('Processed %d documents in %.2f seconds.',
+                    len(input_corpus), time.time() - start_time)
+    _, uas, las = evaluation.calculate_parse_metrics(input_corpus, processed)
+    tf.logging.info('UAS: %.2f', uas)
+    tf.logging.info('LAS: %.2f', las)
+
+    if FLAGS.output_file:
+      with gfile.GFile(FLAGS.output_file, 'w') as f:
+        f.write('## tf:{}\n'.format(FLAGS.text_format))
+        f.write('## gs:{}\n'.format(FLAGS.use_gold_segmentation))
+        for serialized_sentence in processed:
+          sentence = sentence_pb2.Sentence()
+          sentence.ParseFromString(serialized_sentence)
+          f.write('# text = {}\n'.format(sentence.text.encode('utf-8')))
+          for i, token in enumerate(sentence.token):
+            head = token.head + 1
+            f.write('%s\t%s\t_\t_\t_\t_\t%d\t%s\t_\t_\n'%(
+                i + 1,
+                token.word.encode('utf-8'), head,
+                token.label.encode('utf-8')))
+          f.write('\n')
+
+
+if __name__ == '__main__':
+  tf.app.run()
diff --git a/research/syntaxnet/dragnn/tools/model_trainer.py b/research/syntaxnet/dragnn/tools/model_trainer.py
index 724122a0..da8d6fb7 100755
--- a/research/syntaxnet/dragnn/tools/model_trainer.py
+++ b/research/syntaxnet/dragnn/tools/model_trainer.py
@@ -55,9 +55,6 @@ from dragnn.python import trainer_lib
 from syntaxnet.ops import gen_parser_ops
 from syntaxnet.util import check
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/oss_setup.py b/research/syntaxnet/dragnn/tools/oss_setup.py
index ea7c57c7..fa749b82 100644
--- a/research/syntaxnet/dragnn/tools/oss_setup.py
+++ b/research/syntaxnet/dragnn/tools/oss_setup.py
@@ -56,7 +56,7 @@ setuptools.setup(
     version='0.2',
     description='SyntaxNet: Neural Models of Syntax',
     long_description='',
-    url='https://github.com/tensorflow/models/tree/master/research/syntaxnet',
+    url='https://github.com/tensorflow/models/tree/master/syntaxnet',
     author='Google Inc.',
     author_email='opensource@google.com',
 
diff --git a/research/syntaxnet/dragnn/tools/parse-to-conll.py b/research/syntaxnet/dragnn/tools/parse-to-conll.py
index c4cfdd87..11f4a3b1 100644
--- a/research/syntaxnet/dragnn/tools/parse-to-conll.py
+++ b/research/syntaxnet/dragnn/tools/parse-to-conll.py
@@ -33,9 +33,6 @@ from syntaxnet import sentence_pb2
 from syntaxnet.ops import gen_parser_ops
 from syntaxnet.util import check
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/parse_to_conll.py b/research/syntaxnet/dragnn/tools/parse_to_conll.py
new file mode 100644
index 00000000..76268b7d
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/parse_to_conll.py
@@ -0,0 +1,283 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+r"""Runs a both a segmentation and parsing model on a CoNLL dataset.
+"""
+
+import re
+import time
+import tensorflow as tf
+
+from tensorflow.python.client import timeline
+from tensorflow.python.platform import gfile
+
+# The following line is necessary to load custom ops into the library.
+from dragnn.python import dragnn_ops
+
+from dragnn.python import evaluation
+from dragnn.python import sentence_io
+from syntaxnet import sentence_pb2
+
+# The following line is necessary to load custom ops into the library.
+from syntaxnet import syntaxnet_ops
+
+from syntaxnet.ops import gen_parser_ops
+from syntaxnet.util import check
+
+flags = tf.app.flags
+FLAGS = flags.FLAGS
+
+flags.DEFINE_string(
+    'segmenter_saved_model', None,
+    'Path to segmenter saved model. If not provided, gold segmentation is used.'
+)
+flags.DEFINE_string('parser_saved_model', None, 'Path to parser saved model.')
+
+flags.DEFINE_string('input_file', '',
+                    'File of CoNLL-formatted sentences to read from.')
+flags.DEFINE_string('output_file', '',
+                    'File path to write annotated sentences to.')
+flags.DEFINE_bool('text_format', False, '')
+
+flags.DEFINE_integer('max_batch_size', 2048, 'Maximum batch size to support.')
+flags.DEFINE_string('inference_beam_size', '', 'Comma separated list of '
+                    'component_name=beam_size pairs.')
+flags.DEFINE_string('locally_normalize', '', 'Comma separated list of '
+                    'component names to do local normalization on.')
+
+flags.DEFINE_integer('threads', 10, 'Number of threads used for intra- and '
+                     'inter-op parallelism.')
+flags.DEFINE_string('timeline_output_file', '', 'Path to save timeline to. '
+                    'If specified, the final iteration of the evaluation loop '
+                    'will capture and save a TensorFlow timeline.')
+
+
+def get_segmenter_corpus(input_data_path, use_text_format):
+  """Reads in a character corpus for segmenting."""
+  # Read in the documents.
+  tf.logging.info('Reading documents...')
+  if use_text_format:
+    char_corpus = sentence_io.FormatSentenceReader(input_data_path,
+                                                   'untokenized-text').corpus()
+  else:
+    input_corpus = sentence_io.ConllSentenceReader(input_data_path).corpus()
+    with tf.Session(graph=tf.Graph()) as tmp_session:
+      char_input = gen_parser_ops.char_token_generator(input_corpus)
+      char_corpus = tmp_session.run(char_input)
+    check.Eq(len(input_corpus), len(char_corpus))
+
+  return char_corpus
+
+
+def run_segmenter(input_data, segmenter_model, session_config, max_batch_size,
+                  timeline_output_file=None):
+  """Runs the provided segmenter model on the provided character corpus.
+
+  Args:
+    input_data: Character input corpus to segment.
+    segmenter_model: Path to a SavedModel file containing the segmenter graph.
+    session_config: A session configuration object.
+    max_batch_size: The maximum batch size to use.
+    timeline_output_file: Filepath for timeline export. Does not export if None.
+
+  Returns:
+    A list of segmented sentences suitable for parsing.
+  """
+  # Create the session and graph, and load the SavedModel.
+  g = tf.Graph()
+  with tf.Session(graph=g, config=session_config) as sess:
+    tf.logging.info('Initializing segmentation model...')
+    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING],
+                               segmenter_model)
+
+    # Use the graph to segment the sentences.
+    tf.logging.info('Segmenting sentences...')
+    processed = []
+    start_time = time.time()
+    run_metadata = tf.RunMetadata()
+    for start in range(0, len(input_data), max_batch_size):
+      # Prepare the inputs.
+      end = min(start + max_batch_size, len(input_data))
+      feed_dict = {
+          'annotation/ComputeSession/InputBatch:0': input_data[start:end]
+      }
+      output_node = 'annotation/annotations:0'
+
+      # Process.
+      tf.logging.info('Processing examples %d to %d' % (start, end))
+      if timeline_output_file and end == len(input_data):
+        serialized_annotations = sess.run(
+            output_node,
+            feed_dict=feed_dict,
+            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
+            run_metadata=run_metadata)
+        trace = timeline.Timeline(step_stats=run_metadata.step_stats)
+        with open(timeline_output_file, 'w') as trace_file:
+          trace_file.write(trace.generate_chrome_trace_format())
+      else:
+        serialized_annotations = sess.run(output_node, feed_dict=feed_dict)
+
+      # Save the outputs.
+      processed.extend(serialized_annotations)
+
+  # Report statistics.
+  tf.logging.info('Segmented %d documents in %.2f seconds.',
+                  len(input_data), time.time() - start_time)
+
+  # Once all sentences are segmented, the processed data can be used in the
+  # parsers.
+  return processed
+
+
+def run_parser(input_data, parser_model, session_config, beam_sizes,
+               locally_normalized_components, max_batch_size,
+               timeline_output_file):
+  """Runs the provided segmenter model on the provided character corpus.
+
+  Args:
+    input_data: Input corpus to parse.
+    parser_model: Path to a SavedModel file containing the parser graph.
+    session_config: A session configuration object.
+    beam_sizes: A dict of component names : beam sizes (optional).
+    locally_normalized_components: A list of components to normalize (optional).
+    max_batch_size: The maximum batch size to use.
+    timeline_output_file: Filepath for timeline export. Does not export if None.
+
+  Returns:
+    A list of parsed sentences.
+  """
+  parser_graph = tf.Graph()
+  with tf.Session(graph=parser_graph, config=session_config) as sess:
+    tf.logging.info('Initializing parser model...')
+    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING],
+                               parser_model)
+
+    tf.logging.info('Parsing sentences...')
+
+    processed = []
+    start_time = time.time()
+    run_metadata = tf.RunMetadata()
+    tf.logging.info('Corpus length is %d' % len(input_data))
+    for start in range(0, len(input_data), max_batch_size):
+      # Set up the input and output.
+      end = min(start + max_batch_size, len(input_data))
+      feed_dict = {
+          'annotation/ComputeSession/InputBatch:0': input_data[start:end]
+      }
+      for comp, beam_size in beam_sizes:
+        feed_dict['%s/InferenceBeamSize:0' % comp] = beam_size
+      for comp in locally_normalized_components:
+        feed_dict['%s/LocallyNormalize:0' % comp] = True
+      output_node = 'annotation/annotations:0'
+
+      # Process.
+      tf.logging.info('Processing examples %d to %d' % (start, end))
+      if timeline_output_file and end == len(input_data):
+        serialized_annotations = sess.run(
+            output_node,
+            feed_dict=feed_dict,
+            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
+            run_metadata=run_metadata)
+        trace = timeline.Timeline(step_stats=run_metadata.step_stats)
+        with open(timeline_output_file, 'w') as trace_file:
+          trace_file.write(trace.generate_chrome_trace_format())
+      else:
+        serialized_annotations = sess.run(output_node, feed_dict=feed_dict)
+
+      processed.extend(serialized_annotations)
+
+    tf.logging.info('Processed %d documents in %.2f seconds.',
+                    len(input_data), time.time() - start_time)
+    _, uas, las = evaluation.calculate_parse_metrics(input_data, processed)
+    tf.logging.info('UAS: %.2f', uas)
+    tf.logging.info('LAS: %.2f', las)
+
+  return processed
+
+
+def print_output(output_file, use_text_format, use_gold_segmentation, output):
+  """Writes a set of sentences in CoNLL format.
+
+  Args:
+    output_file: The file to write to.
+    use_text_format: Whether this computation used text-format input.
+    use_gold_segmentation: Whether this computation used gold segmentation.
+    output: A list of sentences to write to the output file.
+  """
+  with gfile.GFile(output_file, 'w') as f:
+    f.write('## tf:{}\n'.format(use_text_format))
+    f.write('## gs:{}\n'.format(use_gold_segmentation))
+    for serialized_sentence in output:
+      sentence = sentence_pb2.Sentence()
+      sentence.ParseFromString(serialized_sentence)
+      f.write('# text = {}\n'.format(sentence.text.encode('utf-8')))
+      for i, token in enumerate(sentence.token):
+        head = token.head + 1
+        f.write('%s\t%s\t_\t_\t_\t_\t%d\t%s\t_\t_\n' %
+                (i + 1, token.word.encode('utf-8'), head,
+                 token.label.encode('utf-8')))
+      f.write('\n')
+
+
+def main(unused_argv):
+  # Validate that we have a parser saved model passed to this script.
+  if FLAGS.parser_saved_model is None:
+    tf.logging.fatal('A parser saved model must be provided.')
+
+  # Parse the flags containint lists, using regular expressions.
+  # This matches and extracts key=value pairs.
+  component_beam_sizes = re.findall(r'([^=,]+)=(\d+)',
+                                    FLAGS.inference_beam_size)
+  tf.logging.info('Found beam size dict %s' % component_beam_sizes)
+
+  # This matches strings separated by a comma. Does not return any empty
+  # strings.
+  components_to_locally_normalize = re.findall(r'[^,]+',
+                                               FLAGS.locally_normalize)
+  tf.logging.info(
+      'Found local normalization dict %s' % components_to_locally_normalize)
+
+  # Create a session config with the requested number of threads.
+  session_config = tf.ConfigProto(
+      log_device_placement=False,
+      intra_op_parallelism_threads=FLAGS.threads,
+      inter_op_parallelism_threads=FLAGS.threads)
+
+  # Get the segmented input data for the parser, either by running the
+  # segmenter ourselves or by simply reading it from the CoNLL file.
+  if FLAGS.segmenter_saved_model is None:
+    # If no segmenter was provided, we must use the data from the CONLL file.
+    input_file = FLAGS.input_file
+    parser_input = sentence_io.ConllSentenceReader(input_file).corpus()
+    use_gold_segmentation = True
+  else:
+    # If the segmenter was provided, use it.
+    segmenter_input = get_segmenter_corpus(FLAGS.input_file, FLAGS.text_format)
+    parser_input = run_segmenter(segmenter_input, FLAGS.segmenter_saved_model,
+                                 session_config, FLAGS.max_batch_size,
+                                 FLAGS.timeline_output_file)
+    use_gold_segmentation = False
+
+  # Now that we have parser input data, parse.
+  processed = run_parser(parser_input, FLAGS.parser_saved_model, session_config,
+                         component_beam_sizes, components_to_locally_normalize,
+                         FLAGS.max_batch_size, FLAGS.timeline_output_file)
+
+  if FLAGS.output_file:
+    print_output(FLAGS.output_file, FLAGS.text_format, use_gold_segmentation,
+                 processed)
+
+
+if __name__ == '__main__':
+  tf.app.run()
diff --git a/research/syntaxnet/dragnn/tools/parser_trainer.py b/research/syntaxnet/dragnn/tools/parser_trainer.py
index 0c0c009f..1ab37b63 100644
--- a/research/syntaxnet/dragnn/tools/parser_trainer.py
+++ b/research/syntaxnet/dragnn/tools/parser_trainer.py
@@ -40,9 +40,6 @@ from dragnn.python import sentence_io
 from dragnn.python import spec_builder
 from dragnn.python import trainer_lib
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/segmenter-evaluator.py b/research/syntaxnet/dragnn/tools/segmenter-evaluator.py
index ce0558a9..3256017c 100644
--- a/research/syntaxnet/dragnn/tools/segmenter-evaluator.py
+++ b/research/syntaxnet/dragnn/tools/segmenter-evaluator.py
@@ -42,9 +42,6 @@ from syntaxnet import sentence_pb2
 from syntaxnet.ops import gen_parser_ops
 from syntaxnet.util import check
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/segmenter_trainer.py b/research/syntaxnet/dragnn/tools/segmenter_trainer.py
index 7c1e6dd0..d227da15 100644
--- a/research/syntaxnet/dragnn/tools/segmenter_trainer.py
+++ b/research/syntaxnet/dragnn/tools/segmenter_trainer.py
@@ -42,9 +42,6 @@ from dragnn.python import lexicon
 from dragnn.python import spec_builder
 from dragnn.python import trainer_lib
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/trainer.py b/research/syntaxnet/dragnn/tools/trainer.py
index ba59b615..3952d62e 100644
--- a/research/syntaxnet/dragnn/tools/trainer.py
+++ b/research/syntaxnet/dragnn/tools/trainer.py
@@ -45,9 +45,6 @@ from dragnn.python import trainer_lib
 
 from syntaxnet.util import check
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/viz/node_info.tsx b/research/syntaxnet/dragnn/viz/node_info.tsx
new file mode 100644
index 00000000..0185caea
--- /dev/null
+++ b/research/syntaxnet/dragnn/viz/node_info.tsx
@@ -0,0 +1,212 @@
+
+/**
+ * Template for node info.
+ */
+goog.module('nlp.saft.opensource.dragnn.viz.node_info');
+import preact from 'preact';
+import _ from 'lodash';
+
+const normalCell = {
+  'border': 0,
+  'border-collapse': 'separate',
+  'padding': '2px',
+};
+
+/**
+ * Style definitions which are directly injected (see README.md comments).
+ */
+const style = {
+  featuresTable: {
+    'background-color': 'rgba(255, 255, 255, 0.9)',
+    'border': '1px solid #dddddd',
+    'border-spacing': '2px',
+    'border-collapse': 'separate',
+    'font-family': 'roboto, helvectica, arial, sans-serif',
+    // Sometimes state strings (`stateHtml`) get long, and because this is an
+    // absolutely-positioned box, we need to make them wrap around.
+    'max-width': '600px',
+    'position': 'absolute',
+  },
+
+  heading: {
+    'background-color': '#ebf5fb',
+    'font-weight': 'bold',
+    'text-align': 'center',
+    ...normalCell
+  },
+
+  normalCell: normalCell,
+
+  featureGroup: (componentColor) => ({
+    'background-color': componentColor,
+    'font-weight': 'bold',
+    ...normalCell
+  }),
+
+  normalRow: {
+    'border': 0,
+    'border-collapse': 'separate',
+  },
+};
+
+/**
+ * Creates table rows that negate IPython/Jupyter notebook styling.
+ *
+ * @param {?XML|?Array<XML>} children Child nodes. (Recall Preact handles
+ *     null/undefined gracefully).
+ * @param {!Object} props Any additional properties.
+ * @return {!XML} React-y element, representing a table row.
+ */
+const Row = ({children, ...props}) => (
+  <tr style={style.normalRow} {...props}>{children}</tr>);
+
+/**
+ * Creates table cells that negate IPython/Jupyter notebook styling.
+ *
+ * @param {?XML|?Array<XML>} children Child nodes. (Recall Preact handles
+ *     null/undefined gracefully).
+ * @param {!Object} props Any additional properties.
+ * @return {!XML} React-y element, representing a table cell.
+ */
+const Cell = ({children, ...props}) => (
+  <td style={style.normalCell} {...props}>{children}</td>);
+
+/**
+ * Construct a table "multi-row" with a shared "header" cell.
+ *
+ * In ASCII-art,
+ *
+ * ------------------------------
+ *        | row1
+ * header | row2
+ *        | row3
+ * ------------------------------
+ *
+ * @param {string} headerText Text for the header cell
+ * @param {string} headerColor Color of the header cell
+ * @param {!Array<XML>} rowsCells Row cells (<td> React-y elements).
+ * @return {!Array<XML>} Array of React-y elements.
+ */
+const featureGroup = (headerText, headerColor, rowsCells) => {
+  const headerCell = (
+    <td rowspan={rowsCells.length} style={style.featureGroup(headerColor)}>
+      {headerText}
+    </td>
+  );
+  return _.map(rowsCells, (cells, i) => {
+    return <Row>{i == 0 ? headerCell : null}{cells}</Row>;
+  });
+};
+
+/**
+ * Mini helper to intersperse line breaks with a list of elements.
+ *
+ * This just replicates previous behavior and looks OK; we could also try spans
+ * with `display: 'block'` or such.
+ *
+ * @param {!Array<XML>} elements React-y elements.
+ * @return {!Array<XML>} React-y elements with line breaks.
+ */
+const intersperseLineBreaks = (elements) => _.tail(_.flatten(_.map(
+  elements, (v) => [<br />, v]
+)));
+
+export default class NodeInfo extends preact.Component {
+  /**
+   * Obligatory Preact render() function.
+   *
+   * It might be worthwhile converting some of the intermediate variables into
+   * stateless functional components, like Cell and Row.
+   *
+   * @param {?Object} selected Cytoscape node selected (null if no selection).
+   * @param {?Object} mousePosition Mouse position, if a node is selected.
+   * @return {!XML} Preact components to render.
+   */
+  render({selected, mousePosition}) {
+    const visible = selected != null;
+    const stateHtml = visible && selected.data('stateInfo');
+
+    // Generates elements for fixed features.
+    const fixedFeatures = visible ? selected.data('fixedFeatures') : [];
+    const fixedFeatureElements = _.map(fixedFeatures, (feature) => {
+      if (feature.value_trace.length == 0) {
+        // Preact will just prune this out.
+        return null;
+      } else {
+        const rowsCells = _.map(feature.value_trace, (value) => {
+          // Recall `value_name` is a list of strings (representing feature
+          // values), but this is OK because strings are valid react elements.
+          const valueCells = intersperseLineBreaks(value.value_name);
+          return [<Cell>{value.feature_name}</Cell>, <Cell>{valueCells}</Cell>];
+        });
+        return featureGroup(feature.name, '#cccccc', _.map(rowsCells));
+      }
+    });
+
+    /**
+     * Generates linked feature info from an edge.
+     *
+     * @param {!Object} edge Cytoscape JS Element representing a linked feature.
+     * @return {[XML,XML]} Linked feature information, as table elements.
+     */
+    const linkedFeatureInfoFromEdge = (edge) => {
+      return [
+        <Cell>{edge.data('featureName')}</Cell>,
+        <Cell>
+          value {edge.data('featureValue')} from
+          step {edge.source().data('stepIdx')}
+        </Cell>
+      ];
+    };
+
+    const linkedFeatureElements = _.flatten(
+      _.map(this.edgeStatesByComponent(), (edges, componentName) => {
+        // Because edges are generated by `incomers`, it is guaranteed to be
+        // non-empty.
+        const color = _.head(edges).source().parent().data('componentColor');
+        const rowsCells = _.map(edges, linkedFeatureInfoFromEdge);
+        return featureGroup(componentName, color, rowsCells);
+      }));
+
+    let positionOrHiddenStyle;
+    if (visible) {
+      positionOrHiddenStyle = {
+        left: mousePosition.x + 20,
+        top: mousePosition.y + 10,
+      };
+    } else {
+      positionOrHiddenStyle = {display: 'none'};
+    }
+
+    return (
+      <table style={_.defaults(positionOrHiddenStyle, style.featuresTable)}>
+        <Row>
+          <td colspan="3" style={style.heading}>State</td>
+        </Row>
+        <Row>
+          <Cell colspan="3">{stateHtml}</Cell>
+        </Row>
+        <Row>
+          <td colspan="3" style={style.heading}>Features</td>
+        </Row>
+        {fixedFeatureElements}
+        {linkedFeatureElements}
+      </table>
+    );
+  }
+
+  /**
+   * Gets a list of incoming edges, grouped by their component name.
+   *
+   * @return {!Object<string, !Array<!Object>>} Map from component name to list
+   *     of edges.
+   */
+  edgeStatesByComponent() {
+    if (this.props.selected == null) {
+      return [];
+    }
+    const incoming = this.props.selected.incomers();  // edges and nodes
+    return _.groupBy(incoming.edges(), (edge) => edge.source().parent().id());
+  }
+}
+
diff --git a/research/syntaxnet/g3doc/METADATA b/research/syntaxnet/g3doc/METADATA
deleted file mode 100644
index fbb76fcd..00000000
--- a/research/syntaxnet/g3doc/METADATA
+++ /dev/null
@@ -1,13 +0,0 @@
-# Format: google3/devtools/metadata/metadata.proto (go/google3metadata)
-name: "syntaxnet"
-# Use "base" template
-g3doc {
-    headerfooter {
-      path_regexp: ".*\\.md$"
-      name: "base"
-    }
-    navbar_file : "/company/teams/saft/navbar.md"
-    logo : "/company/teams/saft/images/logo.png"
-    favicon : "/company/teams/saft/images/saft-favicon.png"
-}
-teams_product_id: 7805219680
diff --git a/research/syntaxnet/g3doc/dragnn_ops.md b/research/syntaxnet/g3doc/dragnn_ops.md
index 9c92ab52..2355cee6 100644
--- a/research/syntaxnet/g3doc/dragnn_ops.md
+++ b/research/syntaxnet/g3doc/dragnn_ops.md
@@ -3,7 +3,7 @@
 ### Module `dragnn_ops`
 
 Defined in
-[`tensorflow/dragnn/python/dragnn_ops.py`](https://github.com/tensorflow/models/blob/master/research/syntaxnet/dragnn/python/dragnn_ops.py).
+[`tensorflow/dragnn/python/dragnn_ops.py`](https://github.com/tensorflow/models/blob/master/syntaxnet/dragnn/python/dragnn_ops.py).
 
 Groups the DRAGNN TensorFlow ops in one module.
 
diff --git a/research/syntaxnet/g3doc/dragnn_ops/google3.md b/research/syntaxnet/g3doc/dragnn_ops/google3.md
deleted file mode 100644
index 95a0abbc..00000000
--- a/research/syntaxnet/g3doc/dragnn_ops/google3.md
+++ /dev/null
@@ -1,9 +0,0 @@
-# Module: dragnn_ops.google3
-
-### Module `dragnn_ops.google3`
-
-This is the root of the google3 tree.
-
-Code in here is built by the Google3 build system.
-
-## Members
diff --git a/research/syntaxnet/g3doc/syntaxnet-tutorial.md b/research/syntaxnet/g3doc/syntaxnet-tutorial.md
index 4794e93b..56f66bdd 100644
--- a/research/syntaxnet/g3doc/syntaxnet-tutorial.md
+++ b/research/syntaxnet/g3doc/syntaxnet-tutorial.md
@@ -87,7 +87,8 @@ Note that `stack` here means "words we have already tagged." Thus, this feature
 spec uses three types of features: words, suffixes, and prefixes. The features
 are grouped into blocks that share an embedding matrix, concatenated together,
 and fed into a chain of hidden layers. This structure is based upon the model
-proposed by [Chen and Manning (2014)](http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf).
+proposed by [Chen and Manning (2014)]
+(http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf).
 
 We show this layout in the schematic below: the state of the system (a stack and
 a buffer, visualized below for both the POS and the dependency parsing task) is
diff --git a/research/syntaxnet/syntaxnet/BUILD b/research/syntaxnet/syntaxnet/BUILD
index aafd1695..9f60f42c 100644
--- a/research/syntaxnet/syntaxnet/BUILD
+++ b/research/syntaxnet/syntaxnet/BUILD
@@ -331,6 +331,8 @@ cc_library(
         "binary_segment_state.cc",
         "binary_segment_transitions.cc",
         "char_shift_transitions.cc",
+        "head_label_transitions.cc",
+        "head_label_transitions.h",
         "head_transitions.cc",
         "head_transitions.h",
         "label_transitions.cc",
@@ -353,6 +355,7 @@ cc_library(
     deps = [
         ":base",
         ":feature_extractor",
+        ":generic_features",
         ":morphology_label_set",
         ":registry",
         ":segmenter_utils",
@@ -399,6 +402,16 @@ cc_library(
     ],
 )
 
+cc_library(
+    name = "generic_features",
+    srcs = ["generic_features.cc"],
+    hdrs = ["generic_features.h"],
+    deps = [
+        ":feature_extractor",
+        ":registry",
+    ],
+)
+
 cc_library(
     name = "sentence_batch",
     srcs = ["sentence_batch.cc"],
@@ -510,6 +523,7 @@ filegroup(
     srcs = [
         "testdata/context.pbtxt",
         "testdata/document",
+        "testdata/hello.txt",
         "testdata/mini-training-set",
     ],
 )
@@ -572,6 +586,17 @@ cc_test(
     ],
 )
 
+cc_test(
+    name = "generic_features_test",
+    srcs = ["generic_features_test.cc"],
+    deps = [
+        ":generic_features",
+        ":registry",
+        ":task_context",
+        ":test_main",
+    ],
+)
+
 cc_test(
     name = "sentence_features_test",
     size = "medium",
@@ -712,6 +737,20 @@ cc_test(
     ],
 )
 
+cc_test(
+    name = "head_label_transitions_test",
+    size = "small",
+    srcs = ["head_label_transitions_test.cc"],
+    deps = [
+        ":base",
+        ":parser_transitions",
+        ":sentence_proto",
+        ":task_context",
+        ":term_frequency_map",
+        ":test_main",
+    ],
+)
+
 cc_test(
     name = "parser_features_test",
     size = "small",
@@ -750,8 +789,8 @@ py_library(
     name = "syntaxnet_ops",
     srcs = ["syntaxnet_ops.py"],
     deps = [
-        ":parser_ops",
         ":load_parser_ops_py",
+        ":parser_ops",
     ],
 )
 
diff --git a/research/syntaxnet/syntaxnet/arc_standard_transitions.cc b/research/syntaxnet/syntaxnet/arc_standard_transitions.cc
index 24b94dbf..8feebe1a 100644
--- a/research/syntaxnet/syntaxnet/arc_standard_transitions.cc
+++ b/research/syntaxnet/syntaxnet/arc_standard_transitions.cc
@@ -269,7 +269,9 @@ class ArcStandardTransitionSystem : public ParserTransitionSystem {
   void PerformRightArc(ParserState *state, int label) const {
     DCHECK(IsAllowedRightArc(*state));
     int s0 = state->Pop();
-    state->AddArc(s0, state->Top(), label);
+    int s1 = state->Pop();
+    state->AddArc(s0, s1, label);
+    state->Push(s1);
   }
 
   // We are in a deterministic state when we either reached the end of the input
diff --git a/research/syntaxnet/syntaxnet/base.h b/research/syntaxnet/syntaxnet/base.h
index d77c6b9b..a60bce3b 100644
--- a/research/syntaxnet/syntaxnet/base.h
+++ b/research/syntaxnet/syntaxnet/base.h
@@ -21,6 +21,7 @@ limitations under the License.
 #include <unordered_map>
 #include <unordered_set>
 #include <vector>
+
 #include "tensorflow/core/lib/core/status.h"
 #include "tensorflow/core/lib/strings/strcat.h"
 #include "tensorflow/core/lib/strings/stringprintf.h"
@@ -30,11 +31,14 @@ limitations under the License.
 
 
 
+using tensorflow::int8;
+using tensorflow::int16;
 using tensorflow::int32;
 using tensorflow::int64;
+using tensorflow::uint8;
+using tensorflow::uint16;
 using tensorflow::uint64;
 using tensorflow::uint32;
-using tensorflow::uint32;
 using tensorflow::protobuf::TextFormat;
 using tensorflow::mutex_lock;
 using tensorflow::mutex;
@@ -48,6 +52,7 @@ typedef signed int char32;
 using tensorflow::StringPiece;
 using std::string;
 
+
   // namespace syntaxnet
 
 #endif  // SYNTAXNET_BASE_H_
diff --git a/research/syntaxnet/syntaxnet/binary_segment_transitions.cc b/research/syntaxnet/syntaxnet/binary_segment_transitions.cc
index 5fa44958..6fddfced 100644
--- a/research/syntaxnet/syntaxnet/binary_segment_transitions.cc
+++ b/research/syntaxnet/syntaxnet/binary_segment_transitions.cc
@@ -28,8 +28,7 @@ namespace syntaxnet {
 //  -MERGE: adds the token at state.input to its prevous word, and also advances
 //          state.input.
 //
-// Also see nlp/saft/components/segmentation/transition/binary-segment-state.h
-// for examples on handling spaces.
+// Also see binary_segment_state.h for examples on handling spaces.
 class BinarySegmentTransitionSystem : public ParserTransitionSystem {
  public:
   BinarySegmentTransitionSystem() {}
diff --git a/research/syntaxnet/syntaxnet/char_properties.cc b/research/syntaxnet/syntaxnet/char_properties.cc
index 8ac9f87d..cd514616 100644
--- a/research/syntaxnet/syntaxnet/char_properties.cc
+++ b/research/syntaxnet/syntaxnet/char_properties.cc
@@ -203,8 +203,8 @@ void CharProperty::AddAsciiPredicate(AsciiPredicate *pred) {
 
 void CharProperty::AddCharProperty(const char *propname) {
   const CharProperty *prop = CharProperty::Lookup(propname);
-  CHECK(prop != NULL) << ": unknown char property \"" << propname
-                      << "\" in " << name_;
+  CHECK(prop != nullptr) << ": unknown char property \"" << propname << "\" in "
+                         << name_;
   int c = -1;
   while ((c = prop->NextElementAfter(c)) >= 0) {
     AddChar(c);
@@ -268,10 +268,10 @@ const CharProperty *CharProperty::Lookup(const char *subclass) {
   // the CharProperty it provides.
   std::unique_ptr<CharPropertyWrapper> wrapper(
       CharPropertyWrapper::Create(subclass));
-  if (wrapper.get() == NULL) {
+  if (wrapper == nullptr) {
     LOG(ERROR) << "CharPropertyWrapper not found for subclass: "
                << "\"" << subclass << "\"";
-    return NULL;
+    return nullptr;
   }
   return wrapper->GetCharProperty();
 }
diff --git a/research/syntaxnet/syntaxnet/char_properties.h b/research/syntaxnet/syntaxnet/char_properties.h
index cfb007f7..9980922a 100644
--- a/research/syntaxnet/syntaxnet/char_properties.h
+++ b/research/syntaxnet/syntaxnet/char_properties.h
@@ -357,6 +357,8 @@ DECLARE_CHAR_PROPERTY(directional_formatting_code);
 // just those listed in our code. See the definitions in char_properties.cc.
 DECLARE_CHAR_PROPERTY(punctuation_or_symbol);
 
+DECLARE_SYNTAXNET_CLASS_REGISTRY("char property wrapper", CharPropertyWrapper);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_CHAR_PROPERTIES_H_
diff --git a/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc b/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc
index 65beb516..b5b874ed 100644
--- a/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc
+++ b/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc
@@ -118,6 +118,7 @@ class CharShiftTransitionTest : public ::testing::Test {
  protected:
   string MultiFeatureString(const FeatureVector &result) {
     std::vector<string> values;
+    values.reserve(result.size());
     for (int i = 0; i < result.size(); ++i) {
       values.push_back(result.type(i)->GetFeatureValueName(result.value(i)));
     }
diff --git a/research/syntaxnet/syntaxnet/document_format.h b/research/syntaxnet/syntaxnet/document_format.h
index 85d44cf5..115a6377 100644
--- a/research/syntaxnet/syntaxnet/document_format.h
+++ b/research/syntaxnet/syntaxnet/document_format.h
@@ -60,6 +60,9 @@ class DocumentFormat : public RegisterableClass<DocumentFormat> {
 #define REGISTER_SYNTAXNET_DOCUMENT_FORMAT(type, component) \
   REGISTER_SYNTAXNET_CLASS_COMPONENT(DocumentFormat, type, component)
 
+// Component registry for document formatters.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("document format", DocumentFormat);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_DOCUMENT_FORMAT_H__
diff --git a/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc b/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc
index c753bda3..4d79ec42 100644
--- a/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc
+++ b/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc
@@ -94,7 +94,7 @@ GenericEmbeddingFeatureExtractor::ConvertExample(
     for (int j = 0; j < feature_vectors[i].size(); ++j) {
       const FeatureType &feature_type = *feature_vectors[i].type(j);
       const FeatureValue value = feature_vectors[i].value(j);
-      const bool is_continuous = feature_type.name().find("continuous") == 0;
+      const bool is_continuous = feature_type.is_continuous();
       const int64 id = is_continuous ? FloatFeatureValue(value).id : value;
       const int base = feature_type.base();
       if (id >= 0) {
diff --git a/research/syntaxnet/syntaxnet/feature_extractor.h b/research/syntaxnet/syntaxnet/feature_extractor.h
index 28a26da6..17f15a71 100644
--- a/research/syntaxnet/syntaxnet/feature_extractor.h
+++ b/research/syntaxnet/syntaxnet/feature_extractor.h
@@ -80,6 +80,42 @@ class FeatureVector {
   // Returns the number of elements in the feature vector.
   int size() const { return features_.size(); }
 
+  // Truncates the feature vector.  Requires that new_size <= size().
+  void Truncate(int new_size) {
+    DCHECK_GE(new_size, 0);
+    DCHECK_LE(new_size, size());
+    features_.resize(new_size);
+  }
+
+  // Returns string representation of feature vector.
+  string ToString() const {
+    string str;
+
+    str.append("[");
+    for (int i = 0; i < size(); ++i) {
+      if (i > 0) str.append(",");
+      if (!type(i)->name().empty()) {
+        // Get the name and erase any quotation characters.
+        string name_str = type(i)->name();
+        auto it = name_str.begin();
+        while (it != name_str.end()) {
+          if (*it == '"') {
+            it = name_str.erase(it);
+          } else {
+            ++it;
+          }
+        }
+        str.append(name_str);
+        str.append("=");
+      }
+      str.append(type(i)->GetFeatureValueName(value(i)));
+    }
+
+    str.append("]");
+
+    return str;
+  }
+
   // Reserves space in the underlying feature vector.
   void reserve(int n) { features_.reserve(n); }
 
diff --git a/research/syntaxnet/syntaxnet/feature_types.h b/research/syntaxnet/syntaxnet/feature_types.h
index 3912ef13..4d419037 100644
--- a/research/syntaxnet/syntaxnet/feature_types.h
+++ b/research/syntaxnet/syntaxnet/feature_types.h
@@ -40,9 +40,14 @@ class FeatureType {
  public:
   // Initializes a feature type.
   explicit FeatureType(const string &name)
-      : name_(name), base_(0) {}
+      : name_(name),
+        base_(0),
+        is_continuous_(name.find("continuous") != string::npos) {
+    // TODO(googleuser): Switch to explicitly setting is_continuous.
+    VLOG(2) << "Feature: " << name << ":" << is_continuous_;
+  }
 
-  virtual ~FeatureType() {}
+  virtual ~FeatureType() = default;
 
   // Converts a feature value to a name.
   virtual string GetFeatureValueName(FeatureValue value) const = 0;
@@ -56,12 +61,21 @@ class FeatureType {
   Predicate base() const { return base_; }
   void set_base(Predicate base) { base_ = base; }
 
+  // True if the underlying feature is continuous.
+  bool is_continuous() const { return is_continuous_; }
+
+  // Sets whenther the underlying feature should be represented as continuous.
+  void set_is_continuous(bool is_continuous) { is_continuous_ = is_continuous; }
+
  private:
   // Feature type name.
   string name_;
 
   // "Base" feature value: i.e. a "slot" in a global ordering of features.
   Predicate base_;
+
+  // True if this feature is continuous.
+  bool is_continuous_;
 };
 
 // Templated generic resource based feature type. This feature type delegates
@@ -73,7 +87,7 @@ class FeatureType {
 // successfully for values ONLY in the range [0, Resource->NumValues()) Any
 // feature value not in the extra value map and not in the above range of
 // Resource will result in a ERROR and return of "<INVALID>".
-template<class Resource>
+template <class Resource>
 class ResourceBasedFeatureType : public FeatureType {
  public:
   // Creates a new type with given name, resource object, and a mapping of
@@ -85,8 +99,8 @@ class ResourceBasedFeatureType : public FeatureType {
       : FeatureType(name), resource_(resource), values_(values) {
     max_value_ = resource->NumValues() - 1;
     for (const auto &pair : values) {
-      CHECK_GE(pair.first, resource->NumValues()) << "Invalid extra value: "
-               << pair.first << "," << pair.second;
+      CHECK_GE(pair.first, resource->NumValues())
+          << "Invalid extra value: " << pair.first << "," << pair.second;
       max_value_ = pair.first > max_value_ ? pair.first : max_value_;
     }
   }
@@ -152,8 +166,7 @@ class EnumFeatureType : public FeatureType {
   string GetFeatureValueName(FeatureValue value) const override {
     auto it = value_names_.find(value);
     if (it == value_names_.end()) {
-      LOG(ERROR)
-          << "Invalid feature value " << value << " for " << name();
+      LOG(ERROR) << "Invalid feature value " << value << " for " << name();
       return "<INVALID>";
     }
     return it->second;
diff --git a/research/syntaxnet/syntaxnet/generic_features.cc b/research/syntaxnet/syntaxnet/generic_features.cc
new file mode 100644
index 00000000..5dd6bcc2
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/generic_features.cc
@@ -0,0 +1,103 @@
+/* Copyright 2016 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "syntaxnet/generic_features.h"
+
+#include <limits>
+#include <string>
+
+#include "syntaxnet/base.h"
+
+using tensorflow::strings::StrAppend;
+using tensorflow::strings::StrCat;
+namespace syntaxnet {
+
+GenericFeatureTypes::TupleFeatureTypeBase::TupleFeatureTypeBase(
+    const string &prefix, const std::vector<FeatureType *> &sub_types)
+    : FeatureType(CreateTypeName(prefix, sub_types)),
+      types_(sub_types.begin(), sub_types.end()) {
+  CHECK(!types_.empty());
+}
+
+string GenericFeatureTypes::TupleFeatureTypeBase::GetFeatureValueName(
+    FeatureValue value) const {
+  if (value < 0 || value >= size_) return "<INVALID>";
+  string name = "(";
+  for (uint32 i = 0; i < types_.size(); ++i) {
+    const FeatureType *sub_type = types_[i];
+    const FeatureValue sub_size = sub_type->GetDomainSize();
+    const FeatureValue sub_value = value % sub_size;
+    const string sub_name = sub_type->GetFeatureValueName(sub_value);
+    const string delimiter = i + 1 < types_.size() ? "," : ")";
+    StrAppend(&name, sub_name, delimiter);
+    value /= sub_size;
+  }
+  return name;
+}
+
+FeatureValue GenericFeatureTypes::TupleFeatureTypeBase::GetDomainSize() const {
+  return size_;
+}
+
+void GenericFeatureTypes::TupleFeatureTypeBase::InitDomainSizes(
+    vector<FeatureValue> *sizes) {
+  CHECK_EQ(sizes->size(), types_.size());
+
+  // Populate sub-sizes.
+  for (uint32 i = 0; i < types_.size(); ++i) {
+    sizes->at(i) = types_[i]->GetDomainSize();
+  }
+
+  // Compute the cardinality of the tuple.
+  size_ = 1;
+  double real_size = 1.0;  // for overflow detection
+  for (const FeatureValue sub_size : *sizes) {
+    size_ *= sub_size;
+    real_size *= static_cast<double>(sub_size);
+  }
+
+  // Check for overflow.
+  if (real_size > std::numeric_limits<FeatureValue>::max()) {
+    string message;
+    for (uint32 i = 0; i < types_.size(); ++i) {
+      StrAppend(&message, "\n  ", types_[i]->name(), ")=", sizes->at(i));
+    }
+    LOG(FATAL) << "Feature space overflow in feature " << name() << message;
+  }
+}
+
+string GenericFeatureTypes::TupleFeatureTypeBase::CreateTypeName(
+    const string &prefix, const std::vector<FeatureType *> &sub_types) {
+  string prefix_to_strip = prefix.empty() ? "" : StrCat(prefix, ".");
+  string name = StrCat(prefix, " {");
+  for (const FeatureType *type : sub_types) {
+    string stripped_name = type->name();
+    if (stripped_name.find_first_of(prefix_to_strip) == 0) {
+      stripped_name = stripped_name.substr(prefix_to_strip.length());
+    }
+    StrAppend(&name, " ", stripped_name);
+  }
+  StrAppend(&name, " }");
+  return name;
+}
+
+GenericFeatureTypes::DynamicTupleFeatureType::DynamicTupleFeatureType(
+    const string &prefix, const std::vector<FeatureType *> &sub_types)
+    : TupleFeatureTypeBase(prefix, sub_types), sizes_(sub_types.size()) {
+  CHECK_GE(sizes_.size(), 2);
+  InitDomainSizes(&sizes_);
+}
+
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/generic_features.h b/research/syntaxnet/syntaxnet/generic_features.h
new file mode 100644
index 00000000..ad441d1a
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/generic_features.h
@@ -0,0 +1,856 @@
+/* Copyright 2016 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+// Generic feature functions. These feature functions are independent of the
+// feature function template types.
+//
+// The generic features should be instantiated and registered using the
+// REGISTER_SYNTAXNET_GENERIC_FEATURES() macro:
+//
+// typedef GenericFeatures<Foo, int> GenericFooFeatures;
+// REGISTER_SYNTAXNET_GENERIC_FEATURES(GenericFooFeatures);
+//
+
+#ifndef SYNTAXNET_GENERIC_FEATURES_H_
+#define SYNTAXNET_GENERIC_FEATURES_H_
+
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "syntaxnet/base.h"
+#include "syntaxnet/feature_extractor.h"
+
+namespace syntaxnet {
+
+class TaskContext;
+class WorkspaceSet;
+
+// A class encapsulating all generic feature types.
+class GenericFeatureTypes {
+ public:
+  // Base class for tuple feature types.
+  class TupleFeatureTypeBase : public FeatureType {
+   public:
+    // Creates a tuple whose elements are defined by the sub-types.  This does
+    // not take ownership of the sub-types, which must remain live while this
+    // is in use.
+    TupleFeatureTypeBase(const string &prefix,
+                         const std::vector<FeatureType *> &sub_types);
+
+    // Returns a string representation of the tuple value.
+    string GetFeatureValueName(FeatureValue value) const override;
+
+    // Returns the domain size of this feature.
+    FeatureValue GetDomainSize() const override;
+
+   protected:
+    // Sets the feature domain sizes and computes the total domain size of the
+    // tuple.  Derived classes should call this method from their constructor.
+    void InitDomainSizes(vector<FeatureValue> *sizes);
+
+   private:
+    // Returns a string name for a type using the prefix and sub-types.
+    static string CreateTypeName(const string &prefix,
+                                 const std::vector<FeatureType *> &sub_types);
+
+    // The types of the sub-features.  Not owned.
+    const std::vector<const FeatureType *> types_;
+
+    // The domain size of the tuple.
+    FeatureValue size_ = 0;
+  };
+
+  // Feature type for tuples of fixed size.
+  template <int kNumElements>
+  class StaticTupleFeatureType : public TupleFeatureTypeBase {
+   public:
+    static_assert(kNumElements >= 2, "At least two elements required");
+
+    // Creates a fixed-size tuple of sub-types.  This does not take ownership
+    // of the sub-types, which must remain live while this is in use.
+    StaticTupleFeatureType(const string &prefix,
+                           const std::vector<FeatureType *> &sub_types)
+        : TupleFeatureTypeBase(prefix, sub_types) {
+      CHECK_EQ(sub_types.size(), kNumElements);
+      sizes_.resize(kNumElements);
+      InitDomainSizes(&sizes_);
+    }
+
+    // Returns the conjoined tuple value for a list of sub-values.  The range
+    // values[0,kNumElements) must be valid and non-absent.
+    FeatureValue Conjoin(const FeatureValue *values) const {
+      DCHECK_GE(values[kNumElements - 1], 0);
+      DCHECK_LT(values[kNumElements - 1], sizes_[kNumElements - 1]);
+      DCHECK_NE(values[kNumElements - 1], GenericFeatureFunction::kNone);
+      FeatureValue conjoined = values[kNumElements - 1];
+      for (int i = kNumElements - 2; i >= 0; --i) {
+        DCHECK_GE(values[i], 0);
+        DCHECK_LT(values[i], sizes_[i]);
+        DCHECK_NE(values[i], GenericFeatureFunction::kNone);
+        conjoined = values[i] + conjoined * sizes_[i];
+      }
+      return conjoined;
+    }
+
+   private:
+    // The domain sizes of the sub-types.
+    vector<FeatureValue> sizes_;
+  };
+
+  // Feature type for tuples of dynamic size.
+  class DynamicTupleFeatureType : public TupleFeatureTypeBase {
+   public:
+    // Creates a tuple of sub-types.  This does not take ownership of the
+    // sub-types, which must remain live while this is in use.
+    DynamicTupleFeatureType(const string &prefix,
+                            const std::vector<FeatureType *> &sub_types);
+
+    // Returns the conjoined tuple value for a list of sub-values, which must
+    // be the same size as the number of elements and non-absent.
+    FeatureValue Conjoin(const std::vector<FeatureValue> &values) const {
+      DCHECK_EQ(values.size(), sizes_.size());
+      DCHECK_GE(values.back(), 0);
+      DCHECK_LT(values.back(), sizes_.back());
+      DCHECK_NE(values.back(), GenericFeatureFunction::kNone);
+      FeatureValue conjoined = values.back();
+      for (int i = static_cast<int>(sizes_.size()) - 2; i >= 0; --i) {
+        DCHECK_GE(values[i], 0);
+        DCHECK_LT(values[i], sizes_[i]);
+        DCHECK_NE(values[i], GenericFeatureFunction::kNone);
+        conjoined = values[i] + conjoined * sizes_[i];
+      }
+      return conjoined;
+    }
+
+   private:
+    // The domain sizes of the sub-types.
+    std::vector<FeatureValue> sizes_;
+  };
+
+  // A wrapper which simply delegates to the sub-type.  This does not take
+  // ownership of the sub-type, which must remain live while this is in use.
+  class WrappedFeatureType : public FeatureType {
+   public:
+    explicit WrappedFeatureType(FeatureType *sub_type)
+        : FeatureType(sub_type->name()), sub_type_(sub_type) {}
+
+    string GetFeatureValueName(FeatureValue value) const override {
+      return sub_type_->GetFeatureValueName(value);
+    }
+
+    FeatureValue GetDomainSize() const override {
+      return sub_type_->GetDomainSize();
+    }
+
+   private:
+    FeatureType *sub_type_;
+  };
+};
+
+// A class encapsulating all generic feature functions.
+template <class OBJ, class... ARGS>
+class GenericFeatures {
+ public:
+  // Base class for feature functions.
+  typedef FeatureFunction<OBJ, ARGS...> Base;
+
+  // Base class for nested feature functions: these still have their own feature
+  // type, so make sure not to pass to the nested ones.
+  class MetaBase : public MetaFeatureFunction<OBJ, ARGS...> {
+   public:
+    // Don't use the nested logic for feature types by default.
+    void GetFeatureTypes(std::vector<FeatureType *> *types) const override {
+      GenericFeatureFunction::GetFeatureTypes(types);
+    }
+  };
+
+  // Feature function that adds a bias value to the feature vector.
+  class Bias : public Base {
+    enum BiasFeatureValue { ON };
+
+   public:
+    // Initializes the feature.
+    void Init(TaskContext *context) override {
+      this->set_feature_type(
+          new EnumFeatureType(this->name(), {{BiasFeatureValue::ON, "ON"}}));
+    }
+
+    // Returns the bias value.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      return 0;
+    }
+  };
+
+  // Feature function that returns a constant value.
+  class Constant : public Base {
+   public:
+    // Initializes the feature.
+    void Init(TaskContext *context) override {
+      value_ = this->GetIntParameter("value", 0);
+      this->set_feature_type(new NumericFeatureType(this->name(), value_ + 1));
+    }
+
+    // Returns the constant's value.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      return value_;
+    }
+
+   private:
+    int value_ = 0;
+  };
+
+  // A feature function that tests equality between two nested features.  This
+  // can be used, for example, to check morphological agreement.
+  class Equals : public MetaBase {
+    enum EqualsFeatureValue { DIFFERENT, EQUAL };
+
+   public:
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      const auto &nested = this->nested();
+      CHECK_EQ(nested.size(), 2)
+          << "The 'equals' feature requires two nested features.";
+      this->set_feature_type(new EnumFeatureType(
+          this->name(), {{EqualsFeatureValue::DIFFERENT, "DIFFERENT"},
+                         {EqualsFeatureValue::EQUAL, "EQUAL"}}));
+    }
+
+    // Returns the equality value, or kNone if either value is absent.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      const auto &nested = this->nested();
+      const FeatureValue a =
+          nested[0]->Compute(workspaces, object, args..., fv);
+      if (a == Base::kNone) return Base::kNone;
+      const FeatureValue b =
+          nested[1]->Compute(workspaces, object, args..., fv);
+      if (b == Base::kNone) return Base::kNone;
+      return a == b ? 1 : 0;
+    }
+  };
+
+  // Abstract base class for features that compare a nested feature's value
+  // to a target value (specified via the 'value' parameter).
+  //
+  // Subclasses must implement InitTypes() and ComputeValue().
+  class CompareValue : public MetaBase {
+   public:
+    // Initialize the type information.
+    virtual void InitTypes() = 0;
+
+    // Compute the feature value given the nested feature value and the target
+    // value (i.e., what was passed as the 'value' parameter).
+    virtual FeatureValue ComputeValue(FeatureValue nested_feature_value,
+                                      FeatureValue target_value) const = 0;
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      string value_str = this->GetParameter("value");
+      CHECK_GT(value_str.size(), 0)
+          << "The '" << this->FunctionName()
+          << "' feature requires a 'value' parameter.";
+
+      const auto &nested = this->nested();
+      CHECK_EQ(nested.size(), 1) << "The '" << this->FunctionName()
+                                 << "' feature requires one nested feature.";
+
+      // Only allow nested features with exactly one feature type.
+      FeatureType *nested_feature_type =
+          CHECK_NOTNULL(nested.front()->GetFeatureType());
+
+      for (int i = 0; i < nested_feature_type->GetDomainSize(); ++i) {
+        if (nested_feature_type->GetFeatureValueName(i) == value_str) {
+          value_ = i;
+          break;
+        }
+      }
+
+      CHECK_NE(value_, -1) << "Unknown feature value specified: " << value_str
+                           << ".";
+
+      InitTypes();
+    }
+
+    // Extracts the nested feature value, and delegates computation of the
+    // final feature value to ComputeValue().
+    // Returns kNone if the nested feature value is absent.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      const auto &nested = this->nested();
+      FeatureValue feature_value =
+          nested.front()->Compute(workspaces, object, args..., fv);
+      if (feature_value == Base::kNone) return Base::kNone;
+      return ComputeValue(feature_value, value_);
+    }
+
+   private:
+    // The value to compare the feature against.
+    int value_ = -1;
+  };
+
+  // A feature function that fires if and only if the nested feature has the
+  // given value.
+  class Filter : public CompareValue {
+    enum FilterFeatureValue { ON };
+
+   public:
+    void InitTypes() override {
+      this->set_feature_type(
+          new EnumFeatureType(this->name(), {{FilterFeatureValue::ON, "ON"}}));
+    }
+
+    FeatureValue ComputeValue(FeatureValue nested_feature_value,
+                              FeatureValue target_value) const override {
+      return nested_feature_value == target_value ? 0 : Base::kNone;
+    }
+  };
+
+  // A feature function that tests equality between a feature and a value.
+  class Is : public CompareValue {
+    enum IsFeatureValue { FALSE, TRUE };
+
+   public:
+    void InitTypes() override {
+      this->set_feature_type(new EnumFeatureType(
+          this->name(),
+          {{IsFeatureValue::FALSE, "FALSE"}, {IsFeatureValue::TRUE, "TRUE"}}));
+    }
+
+    FeatureValue ComputeValue(FeatureValue nested_feature_value,
+                              FeatureValue target_value) const override {
+      return nested_feature_value == target_value;
+    }
+  };
+
+  // A feature function that forwards the nested feature value, unless it equals
+  // the target value (in which case, the feature doesn't fire).
+  class Ignore : public CompareValue {
+   public:
+    void InitTypes() override {
+      this->set_feature_type(new GenericFeatureTypes::WrappedFeatureType(
+          this->nested().front()->GetFeatureType()));
+    }
+
+    FeatureValue ComputeValue(FeatureValue nested_feature_value,
+                              FeatureValue target_value) const override {
+      return nested_feature_value == target_value
+                 ? GenericFeatureFunction::kNone
+                 : nested_feature_value;
+    }
+  };
+
+  // Abstract base class for features that reduce several binary values to a
+  // to a single binary value.
+  //
+  // Subclasses must implement Compute().
+  class BinaryReduce : public MetaBase {
+    enum BinaryReduceFeatureValue { FALSE, TRUE };
+
+   public:
+    // Initializes the feature.
+    // Checks that all the nested features are binary, and sets the output
+    // feature type to binary.
+    void InitNested(TaskContext *context) override {
+      for (const Base *function : this->nested()) {
+        FeatureType *nested_type = CHECK_NOTNULL(function->GetFeatureType());
+        CHECK_EQ(nested_type->GetDomainSize(), 2)
+            << this->name() << " requires nested binary feature types only.";
+      }
+      this->set_feature_type(new EnumFeatureType(
+          this->name(), {{BinaryReduceFeatureValue::FALSE, "FALSE"},
+                         {BinaryReduceFeatureValue::TRUE, "TRUE"}}));
+    }
+  };
+
+  // A feature function that takes any number of binary nested features, and
+  // returns whether they all evaluate to 1.
+  class All : public BinaryReduce {
+   public:
+    // Returns whether all nested feature values are 1, or kNone if any of them
+    // are unavailable.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      for (const Base *function : this->nested()) {
+        const FeatureValue value =
+            function->Compute(workspaces, object, args..., fv);
+        if (value == Base::kNone) return Base::kNone;
+        if (value == 0) return 0;
+      }
+      return 1;
+    }
+  };
+
+  // A feature function that takes any number of binary nested features, and
+  // returns whether any of them evaluate to 1.
+  class Any : public BinaryReduce {
+   public:
+    // Returns whether any nested feature values are 1, or kNone if any of them
+    // are unavailable.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      for (const Base *function : this->nested()) {
+        const FeatureValue value =
+            function->Compute(workspaces, object, args..., fv);
+        if (value == Base::kNone) return Base::kNone;
+        if (value == 1) return 1;
+      }
+      return 0;
+    }
+  };
+
+  // A feature function that computes a fixed-size tuple.
+  template <int kNumElements>
+  class StaticTuple : public MetaBase {
+   public:
+    // The associated fixed-size tuple type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<kNumElements> Type;
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      std::vector<FeatureType *> sub_types;
+      for (const Base *function : this->nested()) {
+        sub_types.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+      this->set_feature_type(new Type(this->SubPrefix(), sub_types));
+    }
+
+    // Returns the tuple value, or kNone if any sub-value is unavailable.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      const auto &nested = this->nested();
+      FeatureValue values[kNumElements];
+      for (int i = 0; i < kNumElements; ++i) {
+        const FeatureValue value =
+            nested[i]->Compute(workspaces, object, args..., fv);
+        if (value == Base::kNone) return Base::kNone;
+        values[i] = value;
+      }
+      return static_cast<Type *>(this->feature_type())->Conjoin(values);
+    }
+  };
+
+  // Convenience aliases for common fixed-size tuples.
+  typedef StaticTuple<2> Pair;
+  typedef StaticTuple<3> Triple;
+  typedef StaticTuple<4> Quad;
+  typedef StaticTuple<5> Quint;
+
+  // A feature function that computes a dynamically-sized tuple.
+  class Tuple : public MetaBase {
+   public:
+    // The associated tuple type.
+    typedef GenericFeatureTypes::DynamicTupleFeatureType Type;
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      std::vector<FeatureType *> sub_types;
+      for (const Base *function : this->nested()) {
+        sub_types.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+      this->set_feature_type(new Type(this->SubPrefix(), sub_types));
+    }
+
+    // Returns the tuple value, or kNone if any sub-value is unavailable.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      std::vector<FeatureValue> values;
+      for (const Base *function : this->nested()) {
+        const FeatureValue value =
+            function->Compute(workspaces, object, args..., fv);
+        if (value == Base::kNone) return Base::kNone;
+        values.push_back(value);
+      }
+      return static_cast<Type *>(this->feature_type())->Conjoin(values);
+    }
+  };
+
+  // A feature function that creates all pairs of the features extracted by the
+  // nested feature functions. All the nested feature functions must return
+  // single valued features.
+  //
+  // Parameters:
+  // bool unary (false):
+  //   If true, then unary features are also emitted.
+  class Pairs : public MetaBase {
+   public:
+    // The pair feature type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<2> Type;
+
+    // Discards the pair types.
+    ~Pairs() override {
+      for (Type *type : pairs_) delete type;
+    }
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      unary_ = this->GetParameter("unary") == "true";
+      const auto &nested = this->nested();
+      CHECK_GE(nested.size(), 2)
+          << "The 'pairs' feature requires at least two sub-features.";
+
+      // Get the types of all nested features.
+      types_.clear();
+      for (const Base *function : nested) {
+        types_.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+
+      // Initialize the pair types for all features.
+      pairs_.resize(NumPairs(nested.size()));
+      for (int right = 1; right < nested.size(); ++right) {
+        for (int left = 0; left < right; ++left) {
+          pairs_[PairIndex(left, right)] =
+              new Type(this->SubPrefix(), {types_[left], types_[right]});
+        }
+      }
+    }
+
+    // Produces all feature types.
+    void GetFeatureTypes(std::vector<FeatureType *> *types) const override {
+      if (unary_) types->insert(types->end(), types_.begin(), types_.end());
+      types->insert(types->end(), pairs_.begin(), pairs_.end());
+    }
+
+    // Evaluates the feature.
+    void Evaluate(const WorkspaceSet &workspaces, const OBJ &object,
+                  ARGS... args, FeatureVector *result) const override {
+      const auto &nested = this->nested();
+
+      // Collect all active feature sub-values.
+      std::vector<FeatureValue> values(nested.size());
+      std::vector<int> active_indices;
+      active_indices.reserve(nested.size());
+      for (int i = 0; i < nested.size(); ++i) {
+        values[i] = nested[i]->Compute(workspaces, object, args..., result);
+        if (values[i] != Base::kNone) active_indices.push_back(i);
+      }
+
+      // Optionally generate unary features.
+      if (unary_) {
+        for (int index : active_indices) {
+          result->add(types_[index], values[index]);
+        }
+      }
+
+      // Generate all feature pairs.
+      FeatureValue pair_values[2];
+      for (int right = 1; right < active_indices.size(); ++right) {
+        int right_index = active_indices[right];
+        pair_values[1] = values[right_index];
+        for (int left = 0; left < right; ++left) {
+          int left_index = active_indices[left];
+          pair_values[0] = values[left_index];
+          Type *type = pairs_[PairIndex(left_index, right_index)];
+          result->add(type, type->Conjoin(pair_values));
+        }
+      }
+    }
+
+   private:
+    // Returns the number of pairs (i,j) where 0 <= i < j < size.
+    static int NumPairs(int size) {
+      DCHECK_GE(size, 0);
+      return (size * (size - 1)) / 2;
+    }
+
+    // Returns the index for a pair (left,right) where left < right.  The
+    // indices are suitable for densely linearizing pairs into an array.
+    static int PairIndex(int left, int right) {
+      DCHECK_LE(0, left);
+      DCHECK_LT(left, right);
+      return left + NumPairs(right);
+    }
+
+    // Whether to also emit unary features.
+    bool unary_ = false;
+
+    // Feature types for all nested features.  Not owned.
+    std::vector<FeatureType *> types_;
+
+    // Feature types for all pairs.  Indexed according to PairIndex().  Owned.
+    std::vector<Type *> pairs_;
+  };
+
+  // Feature function for conjoining the first sub-feature with each of the
+  // rest of the sub-features.
+  //
+  // Parameters:
+  // bool unary (false):
+  //   If true, then unary features are also emitted.
+  class Conjoin : public MetaBase {
+   public:
+    // The pair feature type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<2> Type;
+
+    // Discards the pair types.
+    ~Conjoin() override {
+      for (Type *type : pairs_) delete type;
+    }
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      unary_ = this->GetParameter("unary") == "true";
+      const auto &nested = this->nested();
+      CHECK_GE(nested.size(), 2)
+          << "The 'conjoin' feature requires at least two sub-features.";
+
+      // Get the types of the rest of the nested features.
+      types_.clear();
+      for (const Base *function : nested) {
+        types_.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+
+      // Initialize the pair types.
+      pairs_.assign(1, nullptr);
+      for (int i = 1; i < types_.size(); ++i) {
+        pairs_.push_back(new Type(this->SubPrefix(), {types_[0], types_[i]}));
+      }
+    }
+
+    // Produces all feature types.
+    void GetFeatureTypes(std::vector<FeatureType *> *types) const override {
+      if (unary_) types->insert(types->end(), types_.begin() + 1, types_.end());
+      types->insert(types->end(), pairs_.begin() + 1, pairs_.end());
+    }
+
+    // Evaluates the feature.
+    void Evaluate(const WorkspaceSet &workspaces, const OBJ &object,
+                  ARGS... args, FeatureVector *result) const override {
+      const auto &nested = this->nested();
+      FeatureValue values[2];
+      values[0] = nested[0]->Compute(workspaces, object, args..., result);
+
+      // Stop early if the first feature is absent.
+      if (values[0] == Base::kNone) {
+        if (unary_) {
+          for (int i = 1; i < nested.size(); ++i) {
+            values[1] = nested[i]->Compute(workspaces, object, args..., result);
+            if (values[1] == Base::kNone) continue;
+            result->add(types_[i], values[1]);
+          }
+        }
+        return;
+      }
+
+      // Otherwise, the first feature exists; conjoin it with the rest.
+      for (int i = 1; i < nested.size(); ++i) {
+        values[1] = nested[i]->Compute(workspaces, object, args..., result);
+        if (values[1] == Base::kNone) continue;
+        if (unary_) result->add(types_[i], values[1]);
+        result->add(pairs_[i], pairs_[i]->Conjoin(values));
+      }
+    }
+
+   private:
+    // Whether to also emit unary features.
+    bool unary_ = false;
+
+    // Feature types for all nested features.  Not owned.
+    std::vector<FeatureType *> types_;
+
+    // Feature types for all pairs.  The first element is null, in order to
+    // align this list with types_.  Owned.
+    std::vector<Type *> pairs_;
+  };
+
+  // Feature function for creating pairs of multi-valued features.  By default,
+  // the feature computes the Cartesian product of the extracted sub-features,
+  // but a parallel product can be specified via the options.
+  //
+  // Parameters:
+  // bool parallel (false):
+  //   If true, output features for parallel pairs, like a dot product.  The
+  //   two sub-features must produce identical numbers of features.
+  class MultiPair : public MetaBase {
+   public:
+    // The pair feature type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<2> Type;
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      parallel_ = this->GetParameter("parallel") == "true";
+      std::vector<FeatureType *> sub_types;
+      for (const Base *function : this->nested()) {
+        sub_types.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+      this->set_feature_type(new Type(this->SubPrefix(), sub_types));
+    }
+
+    // Evaluates the feature.
+    void Evaluate(const WorkspaceSet &workspaces, const OBJ &object,
+                  ARGS... args, FeatureVector *result) const override {
+      const auto &nested = this->nested();
+      const int orig_size = result->size();
+
+      // Extract features from left half.  Values are extracted directly into
+      // the result so that optimized variable references are handled properly.
+      nested[0]->Evaluate(workspaces, object, args..., result);
+      if (orig_size == result->size()) return;  // no left features
+      std::vector<FeatureValue> left;
+      for (int i = orig_size; i < result->size(); ++i) {
+        left.push_back(result->value(i));
+      }
+      result->Truncate(orig_size);
+
+      // Extract features from right half.
+      nested[1]->Evaluate(workspaces, object, args..., result);
+      if (orig_size == result->size()) return;  // no right features
+      std::vector<FeatureValue> right;
+      for (int i = orig_size; i < result->size(); ++i) {
+        right.push_back(result->value(i));
+      }
+      result->Truncate(orig_size);
+
+      // Compute the pair values.
+      FeatureValue values[2];
+      Type *type = static_cast<Type *>(this->feature_type());
+      if (parallel_) {
+        // Produce parallel pairs.
+        CHECK_EQ(left.size(), right.size());
+        for (int i = 0; i < left.size(); ++i) {
+          values[0] = left[i];
+          values[1] = right[i];
+          result->add(type, type->Conjoin(values));
+        }
+      } else {
+        // Produce all pairs.
+        for (const FeatureValue left_value : left) {
+          values[0] = left_value;
+          for (const FeatureValue right_value : right) {
+            values[1] = right_value;
+            result->add(type, type->Conjoin(values));
+          }
+        }
+      }
+    }
+
+   private:
+    // Whether to do a parallel product instead of a Cartesian product.
+    bool parallel_ = false;
+  };
+
+  // Feature function for conjoining the first multi-valued sub-feature with
+  // each of the rest of the multi-valued sub-features.
+  class MultiConjoin : public MetaBase {
+   public:
+    // The pair feature type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<2> Type;
+
+    // Discards the pair types.
+    ~MultiConjoin() override {
+      for (Type *type : pairs_) delete type;
+    }
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      const auto &nested = this->nested();
+      CHECK_GE(nested.size(), 2)
+          << "The 'multiconjoin' feature requires at least two sub-features.";
+
+      // Get the types of the rest of the nested features.
+      std::vector<FeatureType *> types;
+      types.reserve(nested.size());
+      for (const Base *function : nested) {
+        types.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+
+      // Initialize the pair types.
+      pairs_.clear();
+      for (int i = 1; i < types.size(); ++i) {
+        pairs_.push_back(new Type(this->SubPrefix(), {types[0], types[i]}));
+      }
+    }
+
+    // Produces all feature types.
+    void GetFeatureTypes(std::vector<FeatureType *> *types) const override {
+      types->insert(types->end(), pairs_.begin(), pairs_.end());
+    }
+
+    // Evaluates the feature.
+    void Evaluate(const WorkspaceSet &workspaces, const OBJ &object,
+                  ARGS... args, FeatureVector *result) const override {
+      const auto &nested = this->nested();
+      const int orig_size = result->size();
+
+      // Gather the lists of sub-values for each nested feature.  Sub-values
+      // are extracted directly into the result so that optimized variable
+      // references are handled properly.
+      std::vector<std::vector<FeatureValue> > sub_values(nested.size());
+      for (int i = 0; i < nested.size(); ++i) {
+        nested[i]->Evaluate(workspaces, object, args..., result);
+        if (orig_size == result->size()) {
+          if (i == 0) {
+            return;  // no first values; nothing will be extracted
+          } else {
+            continue;  // no non-first values; skip to next feature
+          }
+        }
+        std::vector<FeatureValue> &values = sub_values[i];
+        for (int j = orig_size; j < result->size(); ++j) {
+          values.push_back(result->value(j));
+        }
+        result->Truncate(orig_size);
+      }
+
+      // Produce conjoined features.
+      const std::vector<FeatureValue> &first_values = sub_values[0];
+      FeatureValue values[2];
+      for (int i = 1; i < sub_values.size(); ++i) {
+        const std::vector<FeatureValue> &other_values = sub_values[i];
+        if (other_values.empty()) continue;
+        Type *type = pairs_[i - 1];
+        for (const FeatureValue first_value : first_values) {
+          values[0] = first_value;
+          for (const FeatureValue other_value : other_values) {
+            values[1] = other_value;
+            result->add(type, type->Conjoin(values));
+          }
+        }
+      }
+    }
+
+   private:
+    // Feature types for all pairs.  Owned.
+    std::vector<Type *> pairs_;
+  };
+};
+
+#define REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, name, type) \
+  typedef generics::type __##type##generics;                     \
+  REGISTER_SYNTAXNET_FEATURE_FUNCTION(generics::Base, name, __##type##generics)
+
+#define REGISTER_SYNTAXNET_GENERIC_FEATURES(generics)                   \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "bias", Bias);           \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "constant", Constant);   \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "equals", Equals);       \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "filter", Filter);       \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "is", Is);               \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "all", All);             \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "any", Any);             \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "pair", Pair);           \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "triple", Triple);       \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "quad", Quad);           \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "quint", Quint);         \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "tuple", Tuple);         \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "pairs", Pairs);         \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "conjoin", Conjoin);     \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "multipair", MultiPair); \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "ignore", Ignore);       \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "multiconjoin", MultiConjoin)
+
+}  // namespace syntaxnet
+
+#endif  // SYNTAXNET_GENERIC_FEATURES_H_
diff --git a/research/syntaxnet/syntaxnet/generic_features_test.cc b/research/syntaxnet/syntaxnet/generic_features_test.cc
new file mode 100644
index 00000000..01a68963
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/generic_features_test.cc
@@ -0,0 +1,387 @@
+/* Copyright 2016 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "syntaxnet/generic_features.h"
+
+#include <map>
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "syntaxnet/registry.h"
+#include "syntaxnet/task_context.h"
+#include <gmock/gmock.h>
+
+namespace syntaxnet {
+
+// Test feature extractor.
+class TestFeatureExtractor : public FeatureExtractor<std::vector<int>, int> {};
+
+// Registration macro.
+#define REGISTER_TEST_FEATURE_FUNCTION(name, component)                     \
+  REGISTER_SYNTAXNET_FEATURE_FUNCTION(TestFeatureExtractor::Function, name, \
+                                      component)
+
+// The registry must be declared in the global namespace.
+REGISTER_SYNTAXNET_CLASS_REGISTRY("syntaxnet test feature function",
+                                  syntaxnet::TestFeatureExtractor::Function);
+
+typedef GenericFeatures<std::vector<int>, int> GenericTestFeatures;
+REGISTER_SYNTAXNET_GENERIC_FEATURES(GenericTestFeatures);
+
+class TestVectorFeatureFunction : public TestFeatureExtractor::Function {
+ public:
+  // Initializes the feature.
+  void Init(TaskContext *context) override {
+    int arg = argument();
+    while (arg > 0) {
+      offsets_.push_back(arg % 10);
+      arg /= 10;
+    }
+    std::reverse(offsets_.begin(), offsets_.end());
+    if (offsets_.empty()) offsets_.push_back(0);
+    set_feature_type(new NumericFeatureType(name(), 10));
+  }
+
+  // Evaluates the feature.
+  void Evaluate(const WorkspaceSet &workspace, const std::vector<int> &object,
+                int focus, FeatureVector *features) const override {
+    for (const uint32 offset : offsets_) {
+      const uint32 index = focus + offset;
+      if (index >= object.size()) continue;
+      features->add(feature_type(), object[index]);
+    }
+  }
+
+  // Returns the first extracted feature, if available.
+  FeatureValue Compute(const WorkspaceSet &workspace,
+                       const std::vector<int> &object, int focus,
+                       const FeatureVector *fv) const override {
+    CHECK_EQ(1, offsets_.size());
+    FeatureVector features;
+    Evaluate(workspace, object, focus, &features);
+    return features.size() == 0 ? kNone : features.value(0);
+  }
+
+ private:
+  // A list of offsets extracted from the feature's argument.
+  std::vector<uint32> offsets_;
+};
+
+REGISTER_TEST_FEATURE_FUNCTION("f", TestVectorFeatureFunction);
+
+class TestParityFeatureFunction : public TestFeatureExtractor::Function {
+ public:
+  // Initializes the feature.
+  void Init(TaskContext *context) override {
+    // "even" corresponds to feature value 0, "odd" to 1.
+    enum ParityFeatureValue { EVEN, ODD };
+    set_feature_type(
+        new EnumFeatureType(name(), {{EVEN, "even"}, {ODD, "odd"}}));
+
+    // Check the "offset" parameter.
+    for (const auto &param : this->descriptor()->parameter()) {
+      if (param.name() == "offset") {
+        offset_ = std::stoi(param.value());
+        CHECK(&offset_);
+      }
+    }
+  }
+
+  // Evaluates the feature.
+  void Evaluate(const WorkspaceSet &workspace, const std::vector<int> &object,
+                int focus, FeatureVector *features) const override {
+    uint32 offset_focus = focus += offset_;
+    if (offset_focus < object.size()) {
+      features->add(feature_type(), object[offset_focus] & 1);
+    }
+  }
+
+  // Returns the first extracted feature, if available.
+  FeatureValue Compute(const WorkspaceSet &workspace,
+                       const std::vector<int> &object, int focus,
+                       const FeatureVector *fv) const override {
+    FeatureVector features;
+    Evaluate(workspace, object, focus, &features);
+    return features.size() == 0 ? kNone : features.value(0);
+  }
+
+ private:
+  int offset_ = 0;
+};
+
+REGISTER_TEST_FEATURE_FUNCTION("parity", TestParityFeatureFunction);
+
+// Testing rig.
+class GenericFeaturesTest : public ::testing::Test {
+ public:
+  // Deallocates test state.
+  void TearDown() override {
+    object_.reset();
+    extractor_.reset();
+    context_.reset();
+  }
+
+  // Initializes the test.
+  void Init(const string &spec, const std::vector<int> &object) {
+    context_.reset(new TaskContext());
+    extractor_.reset(new TestFeatureExtractor());
+    extractor_->Parse(spec);
+    extractor_->Setup(context_.get());
+    extractor_->Init(context_.get());
+    object_.reset(new std::vector<int>(object));
+  }
+
+  // Tests extraction on the current object.
+  void TestExtract(int focus, const string &feature_string) const {
+    FeatureVector features;
+    WorkspaceSet workspace;
+    extractor_->Preprocess(&workspace, object_.get());
+    extractor_->ExtractFeatures(workspace, *object_, focus, &features);
+    EXPECT_EQ(feature_string, features.ToString());
+  }
+
+ private:
+  // The task context for tests.
+  std::unique_ptr<TaskContext> context_;
+
+  // Feature extractor for tests.
+  std::unique_ptr<TestFeatureExtractor> extractor_;
+
+  // Object for tests.
+  std::unique_ptr<std::vector<int> > object_;
+};
+
+TEST_F(GenericFeaturesTest, Singleton) {
+  Init("f", {5, 3, 2, 4, 6});
+  TestExtract(0, "[f=5]");
+  TestExtract(1, "[f=3]");
+  TestExtract(4, "[f=6]");
+  TestExtract(5, "[]");
+}
+
+TEST_F(GenericFeaturesTest, TwoFeatures) {
+  Init("f(0) f(1)", {5, 3, 2, 4, 6});
+  TestExtract(0, "[f=5,f(1)=3]");
+}
+
+TEST_F(GenericFeaturesTest, Bias) {
+  Init("bias", {0, 1});
+  TestExtract(0, "[bias=ON]");
+}
+
+TEST_F(GenericFeaturesTest, Constant) {
+  Init("constant(value=2)", {0, 1});
+
+  TestExtract(0, "[constant(value=2)=2]");
+}
+
+TEST_F(GenericFeaturesTest, Equals) {
+  Init("equals { f(0) f(1) }", {0, 1, 0});
+  TestExtract(0, "[equals { f f(1) }=DIFFERENT]");
+  Init("equals { f(0) f(2) }", {0, 1, 0});
+  TestExtract(0, "[equals { f f(2) }=EQUAL]");
+}
+
+TEST_F(GenericFeaturesTest, Filter) {
+  Init("filter(value=5).f", {3, 5});
+  TestExtract(0, "[]");
+  TestExtract(1, "[filter(value=5).f=ON]");
+
+  // Check that we are actually parsing feature value names.
+  Init("filter(value=odd).parity", {3, 4});
+  TestExtract(0, "[filter(value=odd).parity=ON]");
+  TestExtract(1, "[]");
+  Init("filter(value=even).parity", {3, 4});
+  TestExtract(0, "[]");
+  TestExtract(1, "[filter(value=even).parity=ON]");
+}
+
+TEST_F(GenericFeaturesTest, Is) {
+  Init("is(value=5).f", {3, 5});
+  TestExtract(0, "[is(value=5).f=FALSE]");
+  TestExtract(1, "[is(value=5).f=TRUE]");
+
+  // Check that we are actually parsing feature value names.
+  Init("is(value=odd).parity", {3, 4});
+  TestExtract(0, "[is(value=odd).parity=TRUE]");
+  TestExtract(1, "[is(value=odd).parity=FALSE]");
+  Init("is(value=even).parity", {3, 4});
+  TestExtract(0, "[is(value=even).parity=FALSE]");
+  TestExtract(1, "[is(value=even).parity=TRUE]");
+}
+
+TEST_F(GenericFeaturesTest, Ignore) {
+  Init("ignore(value=5).f", {3, 5});
+  TestExtract(0, "[ignore(value=5).f=3]");
+  TestExtract(1, "[]");
+
+  // Check that we are actually parsing feature value names.
+  Init("ignore(value=odd).parity", {3, 4});
+  TestExtract(0, "[]");
+  TestExtract(1, "[ignore(value=odd).parity=even]");
+  Init("ignore(value=even).parity", {3, 4});
+  TestExtract(0, "[ignore(value=even).parity=odd]");
+  TestExtract(1, "[]");
+}
+
+TEST_F(GenericFeaturesTest, All) {
+  Init("all { parity parity(offset=1) }", {2, 2});
+  TestExtract(0, "[all { parity parity(offset=1) }=FALSE]");
+
+  Init("all { parity parity(offset=1) }", {2, 3});
+  TestExtract(0, "[all { parity parity(offset=1) }=FALSE]");
+
+  Init("all { parity parity(offset=1) }", {3, 2});
+  TestExtract(0, "[all { parity parity(offset=1) }=FALSE]");
+
+  Init("all { parity parity(offset=1) }", {3, 3});
+  TestExtract(0, "[all { parity parity(offset=1) }=TRUE]");
+}
+
+TEST_F(GenericFeaturesTest, Any) {
+  Init("any { parity parity(offset=1) }", {2, 2});
+  TestExtract(0, "[any { parity parity(offset=1) }=FALSE]");
+
+  Init("any { parity parity(offset=1) }", {2, 3});
+  TestExtract(0, "[any { parity parity(offset=1) }=TRUE]");
+
+  Init("any { parity parity(offset=1) }", {3, 2});
+  TestExtract(0, "[any { parity parity(offset=1) }=TRUE]");
+
+  Init("any { parity parity(offset=1) }", {3, 3});
+  TestExtract(0, "[any { parity parity(offset=1) }=TRUE]");
+}
+
+TEST_F(GenericFeaturesTest, Pair) {
+  Init("pair { f(0) f(1) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[pair { f f(1) }=(5,3)]");
+}
+
+TEST_F(GenericFeaturesTest, NestedPair) {
+  Init("pair { pair { f(0) f(1) } pair { f(2) f(3) } }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[pair { pair { f f(1) } pair { f(2) f(3) } }=((5,3),(2,4))]");
+}
+
+TEST_F(GenericFeaturesTest, Triple) {
+  Init("triple { f(0) f(1) f(2) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[triple { f f(1) f(2) }=(5,3,2)]");
+}
+
+TEST_F(GenericFeaturesTest, Quad) {
+  Init("quad { f(0) f(1) f(2) f(3) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[quad { f f(1) f(2) f(3) }=(5,3,2,4)]");
+}
+
+TEST_F(GenericFeaturesTest, Quint) {
+  Init("quint { f(0) f(1) f(2) f(3) f(4) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[quint { f f(1) f(2) f(3) f(4) }=(5,3,2,4,6)]");
+}
+
+TEST_F(GenericFeaturesTest, Tuple) {
+  Init("tuple { f(0) f(1) f(2) f(3) f(4) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[tuple { f f(1) f(2) f(3) f(4) }=(5,3,2,4,6)]");
+}
+
+TEST_F(GenericFeaturesTest, Pairs) {
+  Init("pairs { f(0) f(1) f(2) f(3) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[pairs { f f(1) }=(0,1)"
+              ",pairs { f f(2) }=(0,2)"
+              ",pairs { f(1) f(2) }=(1,2)"
+              ",pairs { f f(3) }=(0,3)"
+              ",pairs { f(1) f(3) }=(1,3)"
+              ",pairs { f(2) f(3) }=(2,3)]");
+}
+
+TEST_F(GenericFeaturesTest, PairsWithUnary) {
+  Init("pairs(unary=true) { f(0) f(1) f(2) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[pairs(unary=true).f=0"
+              ",pairs(unary=true).f(1)=1"
+              ",pairs(unary=true).f(2)=2"
+              ",pairs(unary=true) { f f(1) }=(0,1)"
+              ",pairs(unary=true) { f f(2) }=(0,2)"
+              ",pairs(unary=true) { f(1) f(2) }=(1,2)]");
+}
+
+TEST_F(GenericFeaturesTest, Conjoin) {
+  Init("conjoin { f(0) f(1) f(2) f(3) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[conjoin { f f(1) }=(0,1)"
+              ",conjoin { f f(2) }=(0,2)"
+              ",conjoin { f f(3) }=(0,3)]");
+}
+
+TEST_F(GenericFeaturesTest, ConjoinWithUnary) {
+  Init("conjoin(unary=true) { f(0) f(1) f(2) f(3) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[conjoin(unary=true).f(1)=1"
+              ",conjoin(unary=true) { f f(1) }=(0,1)"
+              ",conjoin(unary=true).f(2)=2"
+              ",conjoin(unary=true) { f f(2) }=(0,2)"
+              ",conjoin(unary=true).f(3)=3"
+              ",conjoin(unary=true) { f f(3) }=(0,3)]");
+}
+
+TEST_F(GenericFeaturesTest, SingletonMultiValue) {
+  Init("f(12)", {0, 1, 2, 3, 4});
+  TestExtract(0, "[f(12)=1,f(12)=2]");
+}
+
+TEST_F(GenericFeaturesTest, MultiPairOneSided) {
+  Init("multipair { f(12) f(3) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multipair { f(12) f(3) }=(1,3)"
+              ",multipair { f(12) f(3) }=(2,3)]");
+}
+
+TEST_F(GenericFeaturesTest, MultiPairTwoSided) {
+  Init("multipair { f(12) f(34) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multipair { f(12) f(34) }=(1,3)"
+              ",multipair { f(12) f(34) }=(1,4)"
+              ",multipair { f(12) f(34) }=(2,3)"
+              ",multipair { f(12) f(34) }=(2,4)]");
+}
+
+TEST_F(GenericFeaturesTest, MultiPairParallel) {
+  Init("multipair(parallel=true) { f(12) f(34) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multipair(parallel=true) { f(12) f(34) }=(1,3)"
+              ",multipair(parallel=true) { f(12) f(34) }=(2,4)]");
+}
+
+TEST_F(GenericFeaturesTest, MultiConjoinFirstOnly) {
+  Init("multiconjoin { f(12) f(3) f(0) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multiconjoin { f(12) f(3) }=(1,3)"
+              ",multiconjoin { f(12) f(3) }=(2,3)"
+              ",multiconjoin { f(12) f }=(1,0)"
+              ",multiconjoin { f(12) f }=(2,0)]");
+}
+
+TEST_F(GenericFeaturesTest, MultiConjoinFirstAndRest) {
+  Init("multiconjoin { f(12) f(34) f(0) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multiconjoin { f(12) f(34) }=(1,3)"
+              ",multiconjoin { f(12) f(34) }=(1,4)"
+              ",multiconjoin { f(12) f(34) }=(2,3)"
+              ",multiconjoin { f(12) f(34) }=(2,4)"
+              ",multiconjoin { f(12) f }=(1,0)"
+              ",multiconjoin { f(12) f }=(2,0)]");
+}
+
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/graph_builder.py b/research/syntaxnet/syntaxnet/graph_builder.py
index 595d796e..58e41017 100644
--- a/research/syntaxnet/syntaxnet/graph_builder.py
+++ b/research/syntaxnet/syntaxnet/graph_builder.py
@@ -485,6 +485,7 @@ class GreedyParser(object):
           vectors=embeddings_path,
           task_context=task_context,
           embedding_init=self._embedding_init,
+          cache_vectors_locally=False,
           seed=seed1,
           seed2=seed2)
 
diff --git a/research/syntaxnet/syntaxnet/head_label_transitions.cc b/research/syntaxnet/syntaxnet/head_label_transitions.cc
new file mode 100644
index 00000000..a5bce36d
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/head_label_transitions.cc
@@ -0,0 +1,148 @@
+/* Copyright 2017 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "syntaxnet/head_label_transitions.h"
+
+#include "syntaxnet/base.h"
+
+using tensorflow::strings::StrAppend;
+using tensorflow::strings::StrCat;
+
+namespace syntaxnet {
+
+// Parser transition state for head & label transitions.
+class HeadLabelTransitionSystem::State : public ParserTransitionState {
+ public:
+  // Returns a copy of this state.
+  State *Clone() const override { return new State(*this); }
+
+  // Does nothing; no need for additional initialization.
+  void Init(ParserState *state) override {}
+
+  // Copies the selected heads to the |sentence|.
+  void AddParseToDocument(const ParserState &state, bool rewrite_root_labels,
+                          Sentence *sentence) const override {
+    for (int i = 0; i < state.NumTokens(); ++i) {
+      Token *token = sentence->mutable_token(i);
+      token->set_head(state.Head(i));
+      token->set_label(state.LabelAsString(state.Label(i)));
+      if (rewrite_root_labels && state.Head(i) == -1) {
+        token->set_label(state.LabelAsString(state.RootLabel()));
+      }
+    }
+  }
+
+  // Returns true if the head and gold head match.
+  bool IsTokenCorrect(const ParserState &state, int index) const override {
+    return state.GoldHead(index) == state.Head(index);
+  }
+
+  // Returns a string representation of the |state|.
+  string ToString(const ParserState &state) const override {
+    string str = "[";
+    for (int i = 0; i < state.NumTokens(); ++i) {
+      StrAppend(&str, i == 0 ? "" : " ", state.Head(i));
+    }
+    StrAppend(&str, "]");
+    return str;
+  }
+};
+
+ParserAction HeadLabelTransitionSystem::GetDefaultAction(
+    const ParserState &state) const {
+  const int default_head = state.Next();
+  const int default_label = state.RootLabel();
+  return EncodeActionWithState(default_head, default_label, state);
+}
+
+ParserAction HeadLabelTransitionSystem::GetNextGoldAction(
+    const ParserState &state) const {
+  if (state.EndOfInput()) {
+    LOG(ERROR) << "Oracle called on invalid state: " << state.ToString();
+    return 0;
+  }
+  const int current = state.Next();
+  int head = state.GoldHead(current);
+  const int label = state.GoldLabel(current);
+
+  // In syntaxnet.Sentence, root arcs are token.head() == -1, whereas
+  // here, we use a self-loop to represent roots. So we need to convert here.
+  head = head == -1 ? current : head;
+  return EncodeActionWithState(head, label, state);
+}
+
+void HeadLabelTransitionSystem::PerformActionWithoutHistory(
+    ParserAction action, ParserState *state) const {
+  CHECK(IsAllowedAction(action, *state))
+      << "Illegal action " << action << " at state: " << state->ToString();
+
+  const int current = state->Next();
+  int head, label;
+  DecodeActionWithState(action, *state, &head, &label);
+
+  VLOG(2) << "Adding arc: " << label << " (" << current << " <- " << head
+          << ")";
+  state->AddArc(current, head == current ? -1 : head, label);
+  state->Advance();
+}
+
+bool HeadLabelTransitionSystem::IsAllowedAction(
+    ParserAction action, const ParserState &state) const {
+  if (state.EndOfInput()) return false;
+
+  // Unlike the labels transition system, we allow root tokens to receive
+  // non-root dependency labels and vice versa.
+  return action >= 0 && action < state.NumTokens() * state.NumLabels();
+}
+
+bool HeadLabelTransitionSystem::IsFinalState(const ParserState &state) const {
+  return state.EndOfInput();
+}
+
+string HeadLabelTransitionSystem::ActionAsString(
+    ParserAction action, const ParserState &state) const {
+  if (!IsAllowedAction(action, state)) return StrCat("INVALID:", action);
+
+  const auto &sentence = state.sentence();
+  const int current = state.Next();
+  int head, label;
+  DecodeActionWithState(action, state, &head, &label);
+  return StrCat(state.LabelAsString(label), "(",
+                sentence.token(current).word(), "<-",
+                head == current ? "ROOT" : sentence.token(head).word(), ")");
+}
+
+ParserTransitionState *HeadLabelTransitionSystem::NewTransitionState(
+    bool training_mode) const {
+  return new State();
+}
+
+void HeadLabelTransitionSystem::DecodeActionWithState(ParserAction action,
+                                                      const ParserState &state,
+                                                      ParserAction *base_action,
+                                                      int *label) const {
+  const int num_labels = state.NumLabels();
+  *base_action = action / num_labels;
+  *label = action % num_labels;
+}
+
+ParserAction HeadLabelTransitionSystem::EncodeActionWithState(
+    ParserAction base_action, int label, const ParserState &state) const {
+  return base_action * state.NumLabels() + label;
+}
+
+REGISTER_TRANSITION_SYSTEM("heads_labels", HeadLabelTransitionSystem);
+
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/head_label_transitions.h b/research/syntaxnet/syntaxnet/head_label_transitions.h
new file mode 100644
index 00000000..d1d0dec1
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/head_label_transitions.h
@@ -0,0 +1,96 @@
+/* Copyright 2017 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef SYNTAXNET_HEAD_LABEL_TRANSITIONS_H_
+#define SYNTAXNET_HEAD_LABEL_TRANSITIONS_H_
+
+#include "syntaxnet/parser_state.h"
+#include "syntaxnet/parser_transitions.h"
+
+namespace syntaxnet {
+
+// Heads and labels transition system. Predicts the syntactic heads and labels
+// of a sentence directly.
+//
+// In this transition system actions encode heads and their labels, so the
+// space of actions is num_labels*N (for a sentence with N tokens.) A token
+// that points to itself is interpreted as a root. Unlike the heads transition
+// system followed by labels, we allow root arcs to receive non-root
+// dependency labels and vice versa since, unlike in the labels transition
+// system, it is unclear whether the arc or label prediction should take
+// precedence.
+//
+// Actions are interpreted as follows:
+//
+// For input pointer at position i:
+//   head  = A / num_labels
+//   label = A % num_labels
+//   if head == i  : Add a root arc to token i (with given label)
+//   if head != i  : Add an arc head -> i (with given label)
+//
+// Note that in syntaxnet.Sentence, root arcs are token.head() == -1, whereas
+// here, we use a self-loop to represent roots.
+class HeadLabelTransitionSystem : public ParserTransitionSystem {
+ public:
+  class State;  // defined in the .cc file
+
+  int NumActionTypes() const override { return 1; }
+  int NumActions(int num_labels) const override { return kDynamicNumActions; }
+
+  // The default action is to assign itself as root.
+  ParserAction GetDefaultAction(const ParserState &state) const override;
+
+  // Returns the next gold action for a given state according to the
+  // underlying annotated sentence.
+  ParserAction GetNextGoldAction(const ParserState &state) const override;
+
+  // Checks if the action is allowed in a given parser state.
+  bool IsAllowedAction(ParserAction action,
+                       const ParserState &state) const override;
+
+  // Performs the specified action on a given parser state, without adding the
+  // action to the state's history.
+  void PerformActionWithoutHistory(ParserAction action,
+                                   ParserState *state) const override;
+
+  // Returns true if the state is at the end of the input.
+  bool IsFinalState(const ParserState &state) const override;
+
+  // Returns a string representation of a parser action.
+  string ActionAsString(ParserAction action,
+                        const ParserState &state) const override;
+
+  // Returns a new transition state to be used to enhance the parser state.
+  ParserTransitionState *NewTransitionState(bool training_mode) const override;
+
+  // Returns false, since no states are deterministic.
+  bool IsDeterministicState(const ParserState &state) const override {
+    return false;
+  }
+
+ private:
+  // Given a ParseState, decodes an action into a base action and a label.
+  void DecodeActionWithState(ParserAction action, const ParserState &state,
+                             ParserAction *base_action, int *label) const;
+
+  // Given a ParseState, encodes a base action and a label into a single-valued
+  // function.
+  ParserAction EncodeActionWithState(ParserAction base_action, int label,
+                                     const ParserState &state) const;
+};
+
+}  // namespace syntaxnet
+
+#endif  // SYNTAXNET_HEAD_LABEL_TRANSITIONS_H_
diff --git a/research/syntaxnet/syntaxnet/head_label_transitions_test.cc b/research/syntaxnet/syntaxnet/head_label_transitions_test.cc
new file mode 100644
index 00000000..aebb0811
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/head_label_transitions_test.cc
@@ -0,0 +1,105 @@
+/* Copyright 2017 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include <memory>
+
+#include "syntaxnet/base.h"
+#include "syntaxnet/parser_state.h"
+#include "syntaxnet/parser_transitions.h"
+#include "syntaxnet/sentence.pb.h"
+#include "syntaxnet/task_context.h"
+#include "syntaxnet/term_frequency_map.h"
+#include "tensorflow/core/platform/test.h"
+
+namespace syntaxnet {
+namespace {
+
+const char kSentence[] = R"(
+  text: 'I saw a man with a telescope.'
+  token { word: 'I' start: 0 end: 0 tag: 'PRP' category: 'PRON'
+          head: 1 label: 'nsubj' break_level: NO_BREAK }
+  token { word: 'saw' start: 2 end: 4 tag: 'VBD' category: 'VERB'
+          label: 'ROOT' break_level: SPACE_BREAK }
+  token { word: 'a' start: 6 end: 6 tag: 'DT' category: 'DET'
+          head: 3 label: 'det' break_level: SPACE_BREAK }
+  token { word: 'man' start: 8 end: 10 tag: 'NN' category: 'NOUN'
+          head: 1 label: 'dobj' break_level: SPACE_BREAK }
+  token { word: 'with' start: 12 end: 15 tag: 'IN' category: 'ADP'
+          head: 1 label: 'prep' break_level: SPACE_BREAK }
+  token { word: 'a' start: 17 end: 17 tag: 'DT' category: 'DET'
+          head: 6 label: 'det' break_level: SPACE_BREAK }
+  token { word: 'telescope' start: 19 end: 27 tag: 'NN' category: 'NOUN'
+          head: 4 label: 'pobj'  break_level: SPACE_BREAK }
+  token { word: '.' start: 28 end: 28 tag: '.' category: '.'
+          head: 1 label: 'p' break_level: NO_BREAK }
+)";
+
+class HeadLabelTransitionTest : public ::testing::Test {
+ public:
+  HeadLabelTransitionTest() {
+    transition_system_->Setup(&context_);
+    transition_system_->Init(&context_);
+    CHECK(TextFormat::ParseFromString(kSentence, &sentence_));
+    for (auto &token : sentence_.token()) label_map_.Increment(token.label());
+    state_.reset(new ParserState(
+        &sentence_, transition_system_->NewTransitionState(true), &label_map_));
+  }
+ protected:
+  TermFrequencyMap label_map_;
+  TaskContext context_;
+  std::unique_ptr<ParserTransitionSystem> transition_system_{
+      ParserTransitionSystem::Create("heads_labels")};
+  Sentence sentence_;
+  std::unique_ptr<ParserState> state_;
+};
+
+TEST_F(HeadLabelTransitionTest, TestPerformActionSelfRoot) {
+  const int current = state_->Next();
+  const int head = current;
+  const int label = state_->RootLabel();
+  const int action = head * state_->NumLabels() + label;
+  transition_system_->PerformActionWithoutHistory(action, state_.get());
+  EXPECT_EQ(state_->Head(current), -1);
+  EXPECT_EQ(state_->Label(current), label);
+}
+
+TEST_F(HeadLabelTransitionTest, TestPerformActionAssignRootOtherLabel) {
+  const int label = label_map_.LookupIndex("det", -1);
+  const int current = state_->Next();
+  const int head = current;
+  const int action = head * state_->NumLabels() + label;
+  transition_system_->PerformActionWithoutHistory(action, state_.get());
+  EXPECT_EQ(state_->Head(current), -1);
+  EXPECT_EQ(state_->Label(current), label);
+}
+
+TEST_F(HeadLabelTransitionTest, GoldParsesCorrectly) {
+  LOG(INFO) << "Initial parser state: " << state_->ToString();
+  while (!transition_system_->IsFinalState(*state_)) {
+    ParserAction action = transition_system_->GetNextGoldAction(*state_);
+    EXPECT_TRUE(transition_system_->IsAllowedAction(action, *state_));
+    LOG(INFO) << "Performing action " << action << ": "
+              << transition_system_->ActionAsString(action, *state_);
+    transition_system_->PerformActionWithoutHistory(action, state_.get());
+    LOG(INFO) << "Parser state: " << state_->ToString();
+  }
+  for (int i = 0; i < state_->NumTokens(); ++i) {
+    EXPECT_EQ(state_->GoldHead(i), state_->Head(i));
+    EXPECT_EQ(state_->GoldLabel(i), state_->Label(i));
+  }
+}
+
+}  // namespace
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/head_transitions.h b/research/syntaxnet/syntaxnet/head_transitions.h
index fe4b1d85..4f36bbbb 100644
--- a/research/syntaxnet/syntaxnet/head_transitions.h
+++ b/research/syntaxnet/syntaxnet/head_transitions.h
@@ -30,17 +30,14 @@ namespace syntaxnet {
 //   Action A == i  : Add a root arc to token i.
 //   Action A != i  : Add an arc A -> i.
 //
-// Note that in nlp_saft.Document, root arcs are token.head() == -1, whereas
+// Note that in the Sentence proto, root arcs are token.head() == -1, whereas
 // here, we use a self-loop to represent roots.
 class HeadTransitionSystem : public ParserTransitionSystem {
  public:
   class State;  // defined in the .cc file
 
-  // Returns 1 for number of actions. This is because each action should be
-  // scored separately; e.g. instead of a fixed output set, we have a single
-  // scoring function.
   int NumActionTypes() const override { return 1; }
-  int NumActions(int num_labels) const override { return 1; }
+  int NumActions(int num_labels) const override { return kDynamicNumActions; }
 
   // Returns the default action, which is to assign itself as root.
   ParserAction GetDefaultAction(const ParserState &state) const override;
diff --git a/research/syntaxnet/syntaxnet/head_transitions_test.cc b/research/syntaxnet/syntaxnet/head_transitions_test.cc
index dcd95818..8cc0d995 100644
--- a/research/syntaxnet/syntaxnet/head_transitions_test.cc
+++ b/research/syntaxnet/syntaxnet/head_transitions_test.cc
@@ -68,7 +68,8 @@ class HeadTransitionSystemTest : public ::testing::Test {
 
 TEST_F(HeadTransitionSystemTest, Characteristics) {
   EXPECT_EQ(1, transition_system_->NumActionTypes());
-  EXPECT_EQ(1, transition_system_->NumActions(10));
+  EXPECT_EQ(ParserTransitionSystem::kDynamicNumActions,
+            transition_system_->NumActions(10));
 }
 
 TEST_F(HeadTransitionSystemTest, GoldParsesCorrectly) {
diff --git a/research/syntaxnet/syntaxnet/lexicon_builder.cc b/research/syntaxnet/syntaxnet/lexicon_builder.cc
index 29370d72..2536968e 100644
--- a/research/syntaxnet/syntaxnet/lexicon_builder.cc
+++ b/research/syntaxnet/syntaxnet/lexicon_builder.cc
@@ -26,6 +26,7 @@ limitations under the License.
 #include "syntaxnet/utils.h"
 #include "tensorflow/core/framework/op_kernel.h"
 #include "tensorflow/core/lib/core/status.h"
+#include "tensorflow/core/lib/strings/str_util.h"
 #include "tensorflow/core/platform/env.h"
 
 // A task that collects term statistics over a corpus and saves a set of
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/context-tokenize-zh.pbtxt b/research/syntaxnet/syntaxnet/models/parsey_universal/context-tokenize-zh.pbtxt
deleted file mode 100644
index 5660bb52..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/context-tokenize-zh.pbtxt
+++ /dev/null
@@ -1,64 +0,0 @@
-Parameter {
-  name: "brain_tokenizer_zh_embedding_dims"
-  value: "32;32"
-}
-Parameter {
-  name: "brain_tokenizer_zh_embedding_names"
-  value: "chars;words"
-}
-Parameter {
-  name: "brain_tokenizer_zh_features"
-  value: "input.char "
-         "input(1).char "
-         "input(2).char "
-         "input(3).char "
-         "input(-1).char "
-         "input(-2).char "
-         "input(-3).char "
-         "stack.char "
-         "stack.offset(1).char "
-         "stack.offset(-1).char "
-         "stack(1).char "
-         "stack(1).offset(1).char "
-         "stack(1).offset(-1).char "
-         "stack(2).char; "
-         "last-word(1,min-freq=2) "
-         "last-word(2,min-freq=2) "
-         "last-word(3,min-freq=2)"
-}
-Parameter {
-  name: "brain_tokenizer_zh_transition_system"
-  value: "binary-segment-transitions"
-}
-input {
-  name: "word-map"
-  Part {
-    file_pattern: "last-word-map"
-  }
-}
-input {
-  name: "char-map"
-  Part {
-    file_pattern: "char-map"
-  }
-}
-input {
-  name: "label-map"
-  Part {
-    file_pattern: "label-map"
-  }
-}
-input {
-  name: 'stdin-untoken'
-  record_format: 'untokenized-text'
-  Part {
-    file_pattern: '-'
-  }
-}
-input {
-  name: 'stdout-conll'
-  record_format: 'conll-sentence'
-  Part {
-    file_pattern: '-'
-  }
-}
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/context.pbtxt b/research/syntaxnet/syntaxnet/models/parsey_universal/context.pbtxt
deleted file mode 100644
index 14f611d0..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/context.pbtxt
+++ /dev/null
@@ -1,362 +0,0 @@
-Parameter {
-  name: "brain_tokenizer_embedding_dims"
-  value: "16;16;16"
-}
-Parameter {
-  name: "brain_tokenizer_embedding_names"
-  value: "chars;digits;puncts"
-}
-Parameter {
-  name: "brain_tokenizer_features"
-  value:  "input.char "
-          "input(-1).char "
-          "input(1).char; "
-          "input.digit "
-          "input(-1).digit "
-          "input(1).digit; "
-          "input.punctuation-amount "
-          "input(-1).punctuation-amount "
-          "input(1).punctuation-amount "
-}
-Parameter {
-  name: "brain_tokenizer_transition_system"
-  value: "binary-segment-transitions"
-}
-Parameter {
-  name: "brain_morpher_embedding_dims"
-  value: "2;16;8;16;16;16;16;16;64"
-}
-Parameter {
-  name: "brain_morpher_embedding_names"
-  value: "capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words"
-}
-Parameter {
-  name: "brain_morpher_features"
-  value: "input.capitalization "
-         "input(1).capitalization "
-         "input(2).capitalization "
-         "input(3).capitalization "
-         "input(-1).capitalization "
-         "input(-2).capitalization "
-         "input(-3).capitalization "
-         "input(-4).capitalization; "
-         "input.token.char-ngram "
-         "input(1).token.char-ngram "
-         "input(2).token.char-ngram "
-         "input(3).token.char-ngram "
-         "input(-1).token.char-ngram "
-         "input(-2).token.char-ngram "
-         "input(-3).token.char-ngram "
-         "input(-4).token.char-ngram; "
-         "input.digit "
-         "input.hyphen "
-         "input.token.punctuation-amount "
-         "input.token.quote; "
-         "input.token.prefix(length=2) "
-         "input(1).token.prefix(length=2) "
-         "input(2).token.prefix(length=2) "
-         "input(3).token.prefix(length=2) "
-         "input(-1).token.prefix(length=2) "
-         "input(-2).token.prefix(length=2) "
-         "input(-3).token.prefix(length=2) "
-         "input(-4).token.prefix(length=2); "
-         "input.token.prefix(length=3) "
-         "input(1).token.prefix(length=3) "
-         "input(2).token.prefix(length=3) "
-         "input(3).token.prefix(length=3) "
-         "input(-1).token.prefix(length=3) "
-         "input(-2).token.prefix(length=3) "
-         "input(-3).token.prefix(length=3) "
-         "input(-4).token.prefix(length=3); "
-         "input.token.suffix(length=2) "
-         "input(1).token.suffix(length=2) "
-         "input(2).token.suffix(length=2) "
-         "input(3).token.suffix(length=2) "
-         "input(-1).token.suffix(length=2) "
-         "input(-2).token.suffix(length=2) "
-         "input(-3).token.suffix(length=2) "
-         "input(-4).token.suffix(length=2); "
-         "input.token.suffix(length=3) "
-         "input(1).token.suffix(length=3) "
-         "input(2).token.suffix(length=3) "
-         "input(3).token.suffix(length=3) "
-         "input(-1).token.suffix(length=3) "
-         "input(-2).token.suffix(length=3) "
-         "input(-3).token.suffix(length=3) "
-         "input(-4).token.suffix(length=3); "
-         "input(-1).pred-morph-tag "
-         "input(-2).pred-morph-tag "
-         "input(-3).pred-morph-tag "
-         "input(-4).pred-morph-tag; "
-         "input.token.word "
-         "input(1).token.word "
-         "input(2).token.word "
-         "input(3).token.word "
-         "input(-1).token.word "
-         "input(-2).token.word "
-         "input(-3).token.word "
-         "input(-4).token.word"
-}
-Parameter {
-  name: "brain_morpher_transition_system"
-  value: "morpher"
-}
-Parameter {
-  name: "brain_tagger_embedding_dims"
-  value: "2;16;8;16;16;16;16;16;64"
-}
-Parameter {
-  name: "brain_tagger_embedding_names"
-  value: "capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words"
-}
-Parameter {
-  name: "brain_tagger_features"
-  value: "input.capitalization "
-         "input(1).capitalization "
-         "input(2).capitalization "
-         "input(3).capitalization "
-         "input(-1).capitalization "
-         "input(-2).capitalization "
-         "input(-3).capitalization "
-         "input(-4).capitalization; "
-         "input.token.char-ngram "
-         "input(1).token.char-ngram "
-         "input(2).token.char-ngram "
-         "input(3).token.char-ngram "
-         "input(-1).token.char-ngram "
-         "input(-2).token.char-ngram "
-         "input(-3).token.char-ngram "
-         "input(-4).token.char-ngram; "
-         "input.digit "
-         "input.hyphen "
-         "input.token.punctuation-amount "
-         "input.token.quote; "
-         "input.token.prefix(length=2) "
-         "input(1).token.prefix(length=2) "
-         "input(2).token.prefix(length=2) "
-         "input(3).token.prefix(length=2) "
-         "input(-1).token.prefix(length=2) "
-         "input(-2).token.prefix(length=2) "
-         "input(-3).token.prefix(length=2) "
-         "input(-4).token.prefix(length=2); "
-         "input.token.prefix(length=3) "
-         "input(1).token.prefix(length=3) "
-         "input(2).token.prefix(length=3) "
-         "input(3).token.prefix(length=3) "
-         "input(-1).token.prefix(length=3) "
-         "input(-2).token.prefix(length=3) "
-         "input(-3).token.prefix(length=3) "
-         "input(-4).token.prefix(length=3); "
-         "input.token.suffix(length=2) "
-         "input(1).token.suffix(length=2) "
-         "input(2).token.suffix(length=2) "
-         "input(3).token.suffix(length=2) "
-         "input(-1).token.suffix(length=2) "
-         "input(-2).token.suffix(length=2) "
-         "input(-3).token.suffix(length=2) "
-         "input(-4).token.suffix(length=2); "
-         "input.token.suffix(length=3) "
-         "input(1).token.suffix(length=3) "
-         "input(2).token.suffix(length=3) "
-         "input(3).token.suffix(length=3) "
-         "input(-1).token.suffix(length=3) "
-         "input(-2).token.suffix(length=3) "
-         "input(-3).token.suffix(length=3) "
-         "input(-4).token.suffix(length=3); "
-         "input(-1).pred-tag "
-         "input(-2).pred-tag "
-         "input(-3).pred-tag "
-         "input(-4).pred-tag; "
-         "input.token.word "
-         "input(1).token.word "
-         "input(2).token.word "
-         "input(3).token.word "
-         "input(-1).token.word "
-         "input(-2).token.word "
-         "input(-3).token.word "
-         "input(-4).token.word"
-}
-Parameter {
-  name: "brain_tagger_transition_system"
-  value: "tagger"
-}
-Parameter {
-  name: "brain_parser_embedding_dims"
-  value: "32;32;32;64"
-}
-Parameter {
-  name: "brain_parser_embedding_names"
-  value: "labels;morphology;tags;words"
-}
-Parameter {
-  name: "brain_parser_features"
-  value: "stack.child(1).label "
-         "stack.child(1).sibling(-1).label "
-         "stack.child(-1).label "
-         "stack.child(-1).sibling(1).label "
-         "stack.child(2).label "
-         "stack.child(-2).label "
-         "stack(1).child(1).label "
-         "stack(1).child(1).sibling(-1).label "
-         "stack(1).child(-1).label "
-         "stack(1).child(-1).sibling(1).label "
-         "stack(1).child(2).label "
-         "stack(1).child(-2).label; "
-         "input.token.morphology-set "
-         "input(1).token.morphology-set "
-         "input(2).token.morphology-set "
-         "input(3).token.morphology-set "
-         "stack.token.morphology-set "
-         "stack.child(1).token.morphology-set "
-         "stack.child(1).sibling(-1).token.morphology-set "
-         "stack.child(-1).token.morphology-set "
-         "stack.child(-1).sibling(1).token.morphology-set "
-         "stack.child(2).token.morphology-set "
-         "stack.child(-2).token.morphology-set "
-         "stack(1).token.morphology-set "
-         "stack(1).child(1).token.morphology-set "
-         "stack(1).child(1).sibling(-1).token.morphology-set "
-         "stack(1).child(-1).token.morphology-set "
-         "stack(1).child(-1).sibling(1).token.morphology-set "
-         "stack(1).child(2).token.morphology-set "
-         "stack(1).child(-2).token.morphology-set "
-         "stack(2).token.morphology-set "
-         "stack(3).token.morphology-set; "
-         "input.token.tag "
-         "input(1).token.tag "
-         "input(2).token.tag "
-         "input(3).token.tag "
-         "stack.token.tag "
-         "stack.child(1).token.tag "
-         "stack.child(1).sibling(-1).token.tag "
-         "stack.child(-1).token.tag "
-         "stack.child(-1).sibling(1).token.tag "
-         "stack.child(2).token.tag "
-         "stack.child(-2).token.tag "
-         "stack(1).token.tag "
-         "stack(1).child(1).token.tag "
-         "stack(1).child(1).sibling(-1).token.tag "
-         "stack(1).child(-1).token.tag "
-         "stack(1).child(-1).sibling(1).token.tag "
-         "stack(1).child(2).token.tag "
-         "stack(1).child(-2).token.tag "
-         "stack(2).token.tag "
-         "stack(3).token.tag; "
-         "input.token.word "
-         "input(1).token.word "
-         "input(2).token.word "
-         "input(3).token.word "
-         "stack.token.word "
-         "stack.child(1).token.word "
-         "stack.child(1).sibling(-1).token.word "
-         "stack.child(-1).token.word "
-         "stack.child(-1).sibling(1).token.word "
-         "stack.child(2).token.word "
-         "stack.child(-2).token.word "
-         "stack(1).token.word "
-         "stack(1).child(1).token.word "
-         "stack(1).child(1).sibling(-1).token.word "
-         "stack(1).child(-1).token.word "
-         "stack(1).child(-1).sibling(1).token.word "
-         "stack(1).child(2).token.word "
-         "stack(1).child(-2).token.word "
-         "stack(2).token.word "
-         "stack(3).token.word "
-}
-Parameter {
-  name: "brain_parser_transition_system"
-  value: "arc-standard"
-}
-Parameter {
-  name: "join_category_to_pos"
-  value: "true"
-}
-input {
-  name: "word-map"
-  Part {
-    file_pattern: "word-map"
-  }
-}
-input {
-  name: "char-map"
-  Part {
-    file_pattern: "char-map"
-  }
-}
-input {
-  name: "tag-map"
-  Part {
-    file_pattern: "tag-map"
-  }
-}
-
-input {
-  name: "tag-to-category"
-  Part {
-    file_pattern: "tag-to-category"
-  }
-}
-input {
-  name: "label-map"
-  Part {
-    file_pattern: "label-map"
-  }
-}
-input {
-  name: "char-ngram-map"
-  Part {
-    file_pattern: "char-ngram-map"
-  }
-}
-input {
-  name: "prefix-table"
-  Part {
-    file_pattern: "prefix-table"
-  }
-}
-input {
-  name: "suffix-table"
-  Part {
-    file_pattern: "suffix-table"
-  }
-}
-input {
-  name: "morph-label-set"
-  Part {
-    file_pattern: "morph-label-set"
-  }
-}
-input {
-  name: "morphology-map"
-  Part {
-    file_pattern: "morphology-map"
-  }
-}
-input {
-  name: 'stdin'
-  record_format: 'tokenized-text'
-  Part {
-    file_pattern: '-'
-  }
-}
-input {
-  name: 'stdin-conll'
-  record_format: 'conll-sentence'
-  Part {
-    file_pattern: '-'
-  }
-}
-input {
-  name: 'stdin-untoken'
-  record_format: 'untokenized-text'
-  Part {
-    file_pattern: '-'
-  }
-}
-input {
-  name: 'stdout-conll'
-  record_format: 'conll-sentence'
-  Part {
-    file_pattern: '-'
-  }
-}
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/parse.sh b/research/syntaxnet/syntaxnet/models/parsey_universal/parse.sh
deleted file mode 100755
index 2478d926..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/parse.sh
+++ /dev/null
@@ -1,68 +0,0 @@
-# A script that runs a morphological analyzer, a part-of-speech tagger and a
-# dependency parser on a text file, with one sentence per line.
-#
-# Example usage:
-#  bazel build syntaxnet:parser_eval
-#  cat sentences.txt |
-#    syntaxnet/models/parsey_universal/parse.sh \
-#    $MODEL_DIRECTORY > output.conll
-#
-# To run on a conll formatted file, add the --conll command line argument:
-#  cat sentences.conll |
-#    syntaxnet/models/parsey_universal/parse.sh \
-#    --conll $MODEL_DIRECTORY > output.conll
-#
-# Models can be downloaded from
-#  http://download.tensorflow.org/models/parsey_universal/<language>.zip
-# for the languages listed at
-#  https://github.com/tensorflow/models/blob/master/research/syntaxnet/universal.md
-#
-
-PARSER_EVAL=bazel-bin/syntaxnet/parser_eval
-CONTEXT=syntaxnet/models/parsey_universal/context.pbtxt
-if [[ "$1" == "--conll" ]]; then
-  INPUT_FORMAT=stdin-conll
-  shift
-else
-  INPUT_FORMAT=stdin
-fi
-MODEL_DIR=$1
-
-$PARSER_EVAL \
-  --input=$INPUT_FORMAT \
-  --output=stdout-conll \
-  --hidden_layer_sizes=64 \
-  --arg_prefix=brain_morpher \
-  --graph_builder=structured \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/morpher-params \
-  --slim_model \
-  --batch_size=1024 \
-  --alsologtostderr \
-  | \
-  $PARSER_EVAL \
-  --input=stdin-conll \
-  --output=stdout-conll \
-  --hidden_layer_sizes=64 \
-  --arg_prefix=brain_tagger \
-  --graph_builder=structured \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/tagger-params \
-  --slim_model \
-  --batch_size=1024 \
-  --alsologtostderr \
-  | \
-  $PARSER_EVAL \
-  --input=stdin-conll \
-  --output=stdout-conll \
-  --hidden_layer_sizes=512,512 \
-  --arg_prefix=brain_parser \
-  --graph_builder=structured \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/parser-params \
-  --slim_model \
-  --batch_size=1024 \
-  --alsologtostderr
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize.sh b/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize.sh
deleted file mode 100755
index 7c81e0fa..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize.sh
+++ /dev/null
@@ -1,31 +0,0 @@
-# A script that runs a tokenizer on a text file with one sentence per line.
-#
-# Example usage:
-#  bazel build syntaxnet:parser_eval
-#  cat untokenized-sentences.txt |
-#    syntaxnet/models/parsey_universal/tokenize.sh \
-#    $MODEL_DIRECTORY > output.conll
-#
-# Models can be downloaded from
-#  http://download.tensorflow.org/models/parsey_universal/<language>.zip
-# for the languages listed at
-#  https://github.com/tensorflow/models/blob/master/research/syntaxnet/universal.md
-#
-
-PARSER_EVAL=bazel-bin/syntaxnet/parser_eval
-CONTEXT=syntaxnet/models/parsey_universal/context.pbtxt
-INPUT_FORMAT=stdin-untoken
-MODEL_DIR=$1
-
-$PARSER_EVAL \
-  --input=$INPUT_FORMAT \
-  --output=stdin-untoken \
-  --hidden_layer_sizes=128,128 \
-  --arg_prefix=brain_tokenizer \
-  --graph_builder=greedy \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/tokenizer-params \
-  --batch_size=32 \
-  --alsologtostderr \
-  --slim_model
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize_zh.sh b/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize_zh.sh
deleted file mode 100755
index bc6cd431..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize_zh.sh
+++ /dev/null
@@ -1,30 +0,0 @@
-# A script that runs a traditional Chinese tokenizer on a text file with one
-# sentence per line.
-#
-# Example usage:
-#  bazel build syntaxnet:parser_eval
-#  cat untokenized-sentences.txt |
-#    syntaxnet/models/parsey_universal/tokenize_zh.sh \
-#    $MODEL_DIRECTORY > output.conll
-#
-# The traditional Chinese model can be downloaded from
-#  http://download.tensorflow.org/models/parsey_universal/Chinese.zip
-#
-
-PARSER_EVAL=bazel-bin/syntaxnet/parser_eval
-CONTEXT=syntaxnet/models/parsey_universal/context-tokenize-zh.pbtxt
-INPUT_FORMAT=stdin-untoken
-MODEL_DIR=$1
-
-$PARSER_EVAL \
-  --input=$INPUT_FORMAT \
-  --output=stdin-untoken \
-  --hidden_layer_sizes=256,256 \
-  --arg_prefix=brain_tokenizer_zh \
-  --graph_builder=structured \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/tokenizer-params \
-  --batch_size=1024 \
-  --alsologtostderr \
-  --slim_model
diff --git a/research/syntaxnet/syntaxnet/morphology_label_set.h b/research/syntaxnet/syntaxnet/morphology_label_set.h
index eb309b5e..7d4601f8 100644
--- a/research/syntaxnet/syntaxnet/morphology_label_set.h
+++ b/research/syntaxnet/syntaxnet/morphology_label_set.h
@@ -43,8 +43,7 @@ class MorphologyLabelSet {
   int Add(const TokenMorphology &morph);
 
   // Look up an existing TokenMorphology. If it is not present, return -1.
-  // Note: This is slow, and should not be called outside of training workflow
-  // or init.
+  // Note: This is slow, and should not be called outside of training or init.
   int LookupExisting(const TokenMorphology &morph) const;
 
   // Return the TokenMorphology at position i. The input i should be in the
diff --git a/research/syntaxnet/syntaxnet/ops/parser_ops.cc b/research/syntaxnet/syntaxnet/ops/parser_ops.cc
index 9dddf04b..7695093e 100644
--- a/research/syntaxnet/syntaxnet/ops/parser_ops.cc
+++ b/research/syntaxnet/syntaxnet/ops/parser_ops.cc
@@ -258,7 +258,7 @@ REGISTER_OP("WordEmbeddingInitializer")
 Reads word embeddings from an sstable of dist_belief.TokenEmbedding protos for
 every word specified in a text vocabulary file.
 
-word_embeddings: a tensor containing word embeddings from the specified table.
+word_embeddings: a tensor containing word embeddings from the specified sstable.
 vectors: path to TF record file of word embedding vectors.
 task_context: file path at which to read the task context, for its "word-map"
   input.  Exactly one of `task_context` or `vocabulary` must be specified.
diff --git a/research/syntaxnet/syntaxnet/parser_features.cc b/research/syntaxnet/syntaxnet/parser_features.cc
index 35591bf3..4cda1bd2 100644
--- a/research/syntaxnet/syntaxnet/parser_features.cc
+++ b/research/syntaxnet/syntaxnet/parser_features.cc
@@ -17,8 +17,10 @@ limitations under the License.
 
 #include <string>
 
+#include "syntaxnet/generic_features.h"
 #include "syntaxnet/registry.h"
 #include "syntaxnet/sentence_features.h"
+#include "syntaxnet/whole_sentence_features.h"
 #include "syntaxnet/workspace.h"
 
 namespace syntaxnet {
@@ -347,4 +349,8 @@ class Constant : public ParserFeatureFunction {
 
 REGISTER_PARSER_FEATURE_FUNCTION("constant", Constant);
 
+// Register the generic parser features.
+typedef GenericFeatures<ParserState> GenericParserFeature;
+REGISTER_SYNTAXNET_GENERIC_FEATURES(GenericParserFeature);
+
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/parser_features.h b/research/syntaxnet/syntaxnet/parser_features.h
index 79176229..fed3ead4 100644
--- a/research/syntaxnet/syntaxnet/parser_features.h
+++ b/research/syntaxnet/syntaxnet/parser_features.h
@@ -146,6 +146,14 @@ class BasicParserSentenceFeatureFunction :
   }
 };
 
+// Registry for the parser feature functions.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("parser feature function",
+                                 ParserFeatureFunction);
+
+// Registry for the parser state + token index feature functions.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("parser+index feature function",
+                                 ParserIndexFeatureFunction);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_PARSER_FEATURES_H_
diff --git a/research/syntaxnet/syntaxnet/parser_features_test.cc b/research/syntaxnet/syntaxnet/parser_features_test.cc
index 66a046c4..42fe8904 100644
--- a/research/syntaxnet/syntaxnet/parser_features_test.cc
+++ b/research/syntaxnet/syntaxnet/parser_features_test.cc
@@ -84,7 +84,6 @@ class ParserFeatureFunctionTest : public ::testing::Test {
   // Prepares a feature for computations.
   string ExtractFeature(const string &feature_name) {
     context_.mutable_spec()->mutable_input()->Clear();
-    context_.mutable_spec()->mutable_output()->Clear();
     feature_extractor_.reset(new ParserFeatureExtractor());
     feature_extractor_->Parse(feature_name);
     feature_extractor_->Setup(&context_);
@@ -152,4 +151,10 @@ TEST_F(ParserFeatureFunctionTest, GoldHeadFeatureFunction) {
   EXPECT_EQ("1", ExtractFeature("input(7).gold-head"));
 }
 
+TEST_F(ParserFeatureFunctionTest, PairFeatureFunction) {
+  EXPECT_EQ("(1,PRP)", ExtractFeature("pair { input.gold-head input.tag }"));
+  EXPECT_EQ("(1,PRP,ROOT)",
+            ExtractFeature("triple { input.gold-head input.tag input.label }"));
+}
+
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/parser_transitions.cc b/research/syntaxnet/syntaxnet/parser_transitions.cc
index 53bc16e0..e5607e0a 100644
--- a/research/syntaxnet/syntaxnet/parser_transitions.cc
+++ b/research/syntaxnet/syntaxnet/parser_transitions.cc
@@ -22,6 +22,8 @@ namespace syntaxnet {
 // Transition system registry.
 REGISTER_SYNTAXNET_CLASS_REGISTRY("transition system", ParserTransitionSystem);
 
+constexpr int ParserTransitionSystem::kDynamicNumActions;
+
 void ParserTransitionSystem::PerformAction(ParserAction action,
                                            ParserState *state) const {
   if (state->keep_history()) {
diff --git a/research/syntaxnet/syntaxnet/parser_transitions.h b/research/syntaxnet/syntaxnet/parser_transitions.h
index 7c545885..f1ab6d82 100644
--- a/research/syntaxnet/syntaxnet/parser_transitions.h
+++ b/research/syntaxnet/syntaxnet/parser_transitions.h
@@ -74,6 +74,9 @@ class ParserTransitionState {
 class ParserTransitionSystem
     : public RegisterableClass<ParserTransitionSystem> {
  public:
+  // Sentinel value that represents a dynamic action set.
+  static constexpr int kDynamicNumActions = -1;
+
   // Construction and cleanup.
   ParserTransitionSystem() {}
   virtual ~ParserTransitionSystem() {}
@@ -94,7 +97,8 @@ class ParserTransitionSystem
   // Returns the number of action types.
   virtual int NumActionTypes() const = 0;
 
-  // Returns the number of actions.
+  // Returns the number of actions, or |kDynamicNumActions| if the action set is
+  // dynamic (i.e., varies per instance).
   virtual int NumActions(int num_labels) const = 0;
 
   // Internally creates the set of outcomes (when transition systems support a
@@ -196,6 +200,9 @@ class ParserTransitionSystem
 #define REGISTER_TRANSITION_SYSTEM(type, component) \
   REGISTER_SYNTAXNET_CLASS_COMPONENT(ParserTransitionSystem, type, component)
 
+// Transition system registry.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("transition system", ParserTransitionSystem);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_PARSER_TRANSITIONS_H_
diff --git a/research/syntaxnet/syntaxnet/proto_io.h b/research/syntaxnet/syntaxnet/proto_io.h
index a3f0e8e2..b18378c5 100644
--- a/research/syntaxnet/syntaxnet/proto_io.h
+++ b/research/syntaxnet/syntaxnet/proto_io.h
@@ -66,6 +66,8 @@ class ProtoRecordReader {
       CHECK(proto->ParseFromString(buffer));
       return tensorflow::Status::OK();
     } else {
+      CHECK_EQ(status.code(), tensorflow::error::OUT_OF_RANGE)
+          << "Non-OK and non-out-of-range (EOF) status: " << status;
       return status;
     }
   }
diff --git a/research/syntaxnet/syntaxnet/reader_ops_test.py b/research/syntaxnet/syntaxnet/reader_ops_test.py
index d7fadaac..f95119e8 100644
--- a/research/syntaxnet/syntaxnet/reader_ops_test.py
+++ b/research/syntaxnet/syntaxnet/reader_ops_test.py
@@ -15,7 +15,6 @@
 
 """Tests for reader_ops."""
 
-# pylint: disable=no-name-in-module,unused-import,g-bad-import-order,maybe-no-member,no-member,g-importing-member
 
 import os.path
 import numpy as np
@@ -30,6 +29,7 @@ from syntaxnet import graph_builder
 from syntaxnet import sparse_pb2
 from syntaxnet.ops import gen_parser_ops
 
+
 FLAGS = tf.app.flags.FLAGS
 if not hasattr(FLAGS, 'test_srcdir'):
   FLAGS.test_srcdir = ''
diff --git a/research/syntaxnet/syntaxnet/registry.h b/research/syntaxnet/syntaxnet/registry.h
index 8ec033db..dd4c6655 100644
--- a/research/syntaxnet/syntaxnet/registry.h
+++ b/research/syntaxnet/syntaxnet/registry.h
@@ -229,6 +229,10 @@ class RegisterableInstance {
   classname::Registry RegisterableClass<classname>::registry_ = { \
       type, #classname, __FILE__, __LINE__, NULL}
 
+#define DECLARE_SYNTAXNET_CLASS_REGISTRY(type, classname) \
+  template <>                                             \
+  classname::Registry RegisterableClass<classname>::registry_;
+
 #define REGISTER_SYNTAXNET_INSTANCE_COMPONENT(base, type, component) \
   static base::Registry::Registrar __##component##__##registrar(     \
       base::registry(), type, #component, __FILE__, __LINE__, new component)
@@ -238,6 +242,10 @@ class RegisterableInstance {
   classname::Registry RegisterableInstance<classname>::registry_ = { \
       type, #classname, __FILE__, __LINE__, NULL}
 
+#define DECLARE_SYNTAXNET_INSTANCE_REGISTRY(type, classname) \
+  template <>                                                \
+  classname::Registry RegisterableInstance<classname>::registry_;
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_REGISTRY_H_
diff --git a/research/syntaxnet/syntaxnet/sentence_features.h b/research/syntaxnet/syntaxnet/sentence_features.h
index e7e2bf9c..c6985840 100644
--- a/research/syntaxnet/syntaxnet/sentence_features.h
+++ b/research/syntaxnet/syntaxnet/sentence_features.h
@@ -663,6 +663,10 @@ typedef FeatureExtractor<Sentence, int> SentenceExtractor;
 #define REGISTER_SENTENCE_IDX_FEATURE(name, type) \
   REGISTER_SYNTAXNET_FEATURE_FUNCTION(SentenceFeature, name, type)
 
+// Registry for the Sentence + token index feature functions.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("sentence+index feature function",
+                                 SentenceFeature);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_SENTENCE_FEATURES_H_
diff --git a/research/syntaxnet/syntaxnet/sentence_features_test.cc b/research/syntaxnet/syntaxnet/sentence_features_test.cc
index 1945988d..3049e086 100644
--- a/research/syntaxnet/syntaxnet/sentence_features_test.cc
+++ b/research/syntaxnet/syntaxnet/sentence_features_test.cc
@@ -51,7 +51,6 @@ class SentenceFeaturesTest : public ::testing::Test {
   // anything in info_ field into the LexiFuse repository.
   virtual void PrepareFeature(const string &fml) {
     context_.mutable_spec()->mutable_input()->Clear();
-    context_.mutable_spec()->mutable_output()->Clear();
     extractor_.reset(new SentenceExtractor());
     extractor_->Parse(fml);
     extractor_->Setup(&context_);
@@ -78,6 +77,7 @@ class SentenceFeaturesTest : public ::testing::Test {
     FeatureVector result;
     extractor_->ExtractFeatures(workspaces_, sentence_, index,
                                 &result);
+    values.reserve(result.size());
     for (int i = 0; i < result.size(); ++i) {
       values.push_back(result.type(i)->GetFeatureValueName(result.value(i)));
     }
@@ -99,6 +99,7 @@ class SentenceFeaturesTest : public ::testing::Test {
   void CheckVectorWorkspace(const VectorIntWorkspace &workspace,
                             std::vector<int> target) {
     std::vector<int> src;
+    src.reserve(workspace.size());
     for (int i = 0; i < workspace.size(); ++i) {
       src.push_back(workspace.element(i));
     }
diff --git a/research/syntaxnet/syntaxnet/syntaxnet_ops.py b/research/syntaxnet/syntaxnet/syntaxnet_ops.py
index 1de0390c..6194e6f8 100644
--- a/research/syntaxnet/syntaxnet/syntaxnet_ops.py
+++ b/research/syntaxnet/syntaxnet/syntaxnet_ops.py
@@ -16,6 +16,6 @@
 """Imports the SyntaxNet ops and their C++ implementations."""
 
 
-from syntaxnet.ops.gen_parser_ops import *  # pylint: disable=wildcard-import
+from syntaxnet.ops.gen_parser_ops import *
 
 import syntaxnet.load_parser_ops
diff --git a/research/syntaxnet/syntaxnet/task_spec.proto b/research/syntaxnet/syntaxnet/task_spec.proto
index ecc9ab72..e690827e 100644
--- a/research/syntaxnet/syntaxnet/task_spec.proto
+++ b/research/syntaxnet/syntaxnet/task_spec.proto
@@ -35,39 +35,8 @@ message TaskInput {
   }
 }
 
-// Task output descriptor.
-message TaskOutput {
-  // Name of output resource.
-  required string name = 1;
-
-  // File format for output resource.
-  optional string file_format = 2;
-
-  // Record format for output resource.
-  optional string record_format = 3;
-
-  // Number of shards in output. If it is different from zero this output is
-  // sharded. If the number of shards is set to -1 this means that the output is
-  // sharded, but the number of shard is unknown. The files are then named
-  // 'base-*-of-*'.
-  optional int32 shards = 4 [default = 0];
-
-  // Base file name for output resource. If this is not set by the task
-  // component it is set to a default value by the workflow engine.
-  optional string file_base = 5;
-
-  // Optional extension added to the file name.
-  optional string file_extension = 6;
-}
-
 // A task specification is used for describing executing parameters.
 message TaskSpec {
-  // Name of task.
-  optional string task_name = 1;
-
-  // Workflow task type.
-  optional string task_type = 2;
-
   // Task parameters.
   repeated group Parameter = 3 {
     required string name = 4;
@@ -77,6 +46,6 @@ message TaskSpec {
   // Task inputs.
   repeated TaskInput input = 6;
 
-  // Task outputs.
-  repeated TaskOutput output = 7;
+  reserved 1, 2, 7;
+  reserved "task_name", "task_type", "output";
 }
diff --git a/research/syntaxnet/syntaxnet/term_frequency_map.cc b/research/syntaxnet/syntaxnet/term_frequency_map.cc
index 00891c19..f638ba43 100644
--- a/research/syntaxnet/syntaxnet/term_frequency_map.cc
+++ b/research/syntaxnet/syntaxnet/term_frequency_map.cc
@@ -68,7 +68,8 @@ void TermFrequencyMap::Load(const string &filename, int min_frequency,
   string line;
   TF_CHECK_OK(buffer.ReadLine(&line));
   int32 total = -1;
-  CHECK(utils::ParseInt32(line.c_str(), &total));
+  CHECK(utils::ParseInt32(line.c_str(), &total))
+      << "Unable to parse from " << filename;
   CHECK_GE(total, 0);
 
   // Read the mapping.
diff --git a/research/syntaxnet/syntaxnet/testdata/hello.txt b/research/syntaxnet/syntaxnet/testdata/hello.txt
new file mode 100644
index 00000000..3b18e512
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/testdata/hello.txt
@@ -0,0 +1 @@
+hello world
diff --git a/research/syntaxnet/syntaxnet/text_formats.cc b/research/syntaxnet/syntaxnet/text_formats.cc
index 93d1b785..0ea2cc75 100644
--- a/research/syntaxnet/syntaxnet/text_formats.cc
+++ b/research/syntaxnet/syntaxnet/text_formats.cc
@@ -157,7 +157,12 @@ class CoNLLSyntaxFormat : public DocumentFormat {
       const int start = text.size();
       const int end = start + word.size() - 1;
       text.append(word);
-      add_space_to_text = fields[9] != "SpaceAfter=No";
+
+      // Determine whether a space should be added to sentence text.
+      std::vector<string> sub_fields = utils::Split(fields[9], '|');
+      auto no_space = [](const string &str) { return str == "SpaceAfter=No"; };
+      add_space_to_text =
+          !std::any_of(sub_fields.begin(), sub_fields.end(), no_space);
 
       // Add token to sentence.
       Token *token = sentence->add_token();
@@ -329,28 +334,28 @@ REGISTER_SYNTAXNET_DOCUMENT_FORMAT("conll-sentence", CoNLLSyntaxFormat);
 //
 // Examples:
 // To create a training example for sentence with raw text:
-//   That's a good point.
+//   "That's a good point."
 // and the corresponding gold segmentation:
-//   That 's a good point .
+//   "That" "\'s" "a" "good" "point" "."
 // Then the correct input is:
-// That	NO_SPACE
-// 's	SPACE
-// a	SPACE
-// good	SPACE
-// point	NO_SPACE
-// .	NO_SPACE
+// "That\tNO_SPACE"
+// "'s\tSPACE"
+// "a\tSPACE"
+// "good\tSPACE"
+// "point\tNO_SPACE"
+// ".\tNO_SPACE"
 //
 // Yet another example:
 // To create a training example for sentence with raw text:
-//   
+//   ""
 // and the corresponding gold segmentation:
-//       
+//   "" "" "" "" ""
 // Then the correct input is:
-// 	NO_SPACE
-// 	NO_SPACE
-// 	NO_SPACE
-// 	NO_SPACE
-// 	NO_SPACE
+// "\tNO_SPACE"
+// "\tNO_SPACE"
+// "\tNO_SPACE"
+// "\tNO_SPACE"
+// "\tNO_SPACE"
 class SegmentationTrainingDataFormat : public CoNLLSyntaxFormat {
  public:
   // Converts to segmentation training data by breaking those word in the input
diff --git a/research/syntaxnet/syntaxnet/text_formats_test.py b/research/syntaxnet/syntaxnet/text_formats_test.py
index e9a45e16..4a408cd3 100644
--- a/research/syntaxnet/syntaxnet/text_formats_test.py
+++ b/research/syntaxnet/syntaxnet/text_formats_test.py
@@ -113,13 +113,13 @@ class TextFormatsTest(test_util.TensorFlowTestCase):
     # This test sentence includes a multiword token and an empty node,
     # both of which are to be ignored.
     test_sentence = """
-1-2	We've	_
-1	We	we	PRON	PRP	Case=Nom	3	nsubj	_	SpaceAfter=No
-2	've	have	AUX	VBP	Mood=Ind	3	aux	_	_
-3	moved	move	VERB	VBN	Tense=Past	0	root	_	_
-4	on	on	ADV	RB	_	3	advmod	_	SpaceAfter=No
-4.1	ignored	ignore	VERB	VBN	Tense=Past	0	_	_	_
-5	.	.	PUNCT	.	_	3	punct	_	_
+1-2\tWe've\t_
+1\tWe\twe\tPRON\tPRP\tCase=Nom\t3\tnsubj\t_\tSpaceAfter=No
+2\t've\thave\tAUX\tVBP\tMood=Ind\t3\taux\t_\t_
+3\tmoved\tmove\tVERB\tVBN\tTense=Past\t0\troot\t_\t_
+4\ton\ton\tADV\tRB\t_\t3\tadvmod\t_\tSpaceAfter=No|foobar=baz
+4.1\tignored\tignore\tVERB\tVBN\tTense=Past\t0\t_\t_\t_
+5\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\t_
 """
 
     # Prepare test sentence.
@@ -191,13 +191,13 @@ token {
       self.assertEqual(expected_ends, [t.end for t in sentence_doc.token])
 
   def testSegmentationTrainingData(self):
-    doc1_lines = ['	NO_SPACE\n', '	NO_SPACE\n', '	NO_SPACE']
+    doc1_lines = ['\tNO_SPACE\n', '\tNO_SPACE\n', '\tNO_SPACE']
     doc1_text = ''
     doc1_tokens = ['', '', '', '', '']
     doc1_break_levles = [1, 0, 1, 1, 0]
     doc2_lines = [
-        'That	NO_SPACE\n', '\'s	SPACE\n', 'a	SPACE\n', 'good	SPACE\n',
-        'point	NO_SPACE\n', '.	NO_SPACE'
+        'That\tNO_SPACE\n', '\'s\tSPACE\n', 'a\tSPACE\n', 'good\tSPACE\n',
+        'point\tNO_SPACE\n', '.\tNO_SPACE'
     ]
     doc2_text = 'That\'s a good point.'
     doc2_tokens = [
diff --git a/research/syntaxnet/syntaxnet/util/BUILD b/research/syntaxnet/syntaxnet/util/BUILD
index be58d249..39867e5f 100644
--- a/research/syntaxnet/syntaxnet/util/BUILD
+++ b/research/syntaxnet/syntaxnet/util/BUILD
@@ -16,6 +16,14 @@ py_library(
     srcs = ["check.py"],
 )
 
+py_library(
+    name = "resources",
+    srcs = ["resources.py"],
+    visibility = ["//visibility:public"],
+    deps = [
+    ],
+)
+
 py_library(
     name = "pyregistry_test_base",
     testonly = 1,
@@ -56,3 +64,15 @@ py_test(
         "@org_tensorflow//tensorflow/core:protos_all_py",
     ],
 )
+
+py_test(
+    name = "resources_test",
+    srcs = ["resources_test.py"],
+    data = [
+        "//syntaxnet:testdata/hello.txt",
+    ],
+    deps = [
+        ":resources",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+    ],
+)
diff --git a/research/syntaxnet/syntaxnet/util/registry.py b/research/syntaxnet/syntaxnet/util/registry.py
index b413c02a..4dc87d9b 100644
--- a/research/syntaxnet/syntaxnet/util/registry.py
+++ b/research/syntaxnet/syntaxnet/util/registry.py
@@ -1,13 +1,28 @@
-"""A component registry, similar to nlp_saft::RegisteredClass<>.
-
-Like nlp_saft::RegisteredClass<>, one does not need to explicitly import the
-module containing each subclass.  It is sufficient to add subclasses as build
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""A component registry, similar to RegisterableClass<>.
+
+Like RegisterableClass<>, one does not need to explicitly import the module
+containing each subclass.  It is sufficient to add subclasses as build
 dependencies.
 
-Unlike nlp_saft::RegisteredClass<>, which allows subclasses to be registered
-under arbitrary names, subclasses must be looked up based on their type name.
-This restriction allows the registry to dynamically import the module containing
-the desired subclass.
+Unlike RegisterableClass<>, which allows subclasses to be registered under
+arbitrary names, subclasses must be looked up based on their type name.  This
+restriction allows the registry to dynamically import the module containing the
+desired subclass.
 
 Example usage:
 
@@ -82,7 +97,7 @@ def _GetClass(name):
 
   # Need at least "module.Class".
   if len(elements) < 2:
-    logging.debug('Malformed type: "%s"', name)
+    logging.info('Malformed type: "%s"', name)
     return None
   module_path = '.'.join(elements[:-1])
   class_name = elements[-1]
@@ -91,20 +106,19 @@ def _GetClass(name):
   try:
     __import__(module_path)
   except ImportError as e:
-    logging.debug('Unable to find module "%s": "%s"', module_path, e)
+    logging.info('Unable to find module "%s": "%s"', module_path, e)
     return None
   module = sys.modules[module_path]
 
   # Look up the class.
   if not hasattr(module, class_name):
-    logging.debug('Name "%s" not found in module: "%s"', class_name,
-                  module_path)
+    logging.info('Name "%s" not found in module: "%s"', class_name, module_path)
     return None
   class_obj = getattr(module, class_name)
 
   # Check that it is actually a class.
   if not inspect.isclass(class_obj):
-    logging.debug('Name does not refer to a class: "%s"', name)
+    logging.info('Name does not refer to a class: "%s"', name)
     return None
   return class_obj
 
@@ -125,8 +139,8 @@ def _Create(baseclass, subclass_name, *args, **kwargs):
   if subclass is None:
     return None  # _GetClass() already logged an error
   if not issubclass(subclass, baseclass):
-    logging.debug('Class "%s" is not a subclass of "%s"', subclass_name,
-                  baseclass.__name__)
+    logging.info('Class "%s" is not a subclass of "%s"', subclass_name,
+                 baseclass.__name__)
     return None
   return subclass(*args, **kwargs)
 
@@ -135,13 +149,13 @@ def _ResolveAndCreate(baseclass, path, subclass_name, *args, **kwargs):
   """Resolves the name of a subclass and creates an instance of it.
 
   The subclass is resolved with respect to a package path in an inside-out
-  manner.  For example, if |path| is 'google3.foo.bar' and |subclass_name| is
+  manner.  For example, if |path| is 'syntaxnet.foo.bar' and |subclass_name| is
   'baz.ClassName', then attempts are made to create instances of the following
   fully-qualified class names:
 
-    'google3.foo.bar.baz.ClassName'
-    'google3.foo.baz.ClassName'
-    'google3.baz.ClassName'
+    'syntaxnet.foo.bar.baz.ClassName'
+    'syntaxnet.foo.baz.ClassName'
+    'syntaxnet.baz.ClassName'
     'baz.ClassName'
 
   An instance corresponding to the first successful attempt is returned.
@@ -163,9 +177,12 @@ def _ResolveAndCreate(baseclass, path, subclass_name, *args, **kwargs):
   elements = path.split('.')
   while True:
     resolved_subclass_name = '.'.join(elements + [subclass_name])
+    logging.info('Attempting to instantiate "%s"', resolved_subclass_name)
     subclass = _Create(baseclass, resolved_subclass_name, *args, **kwargs)
-    if subclass: return subclass  # success
-    if not elements: break  # no more paths to try
+    if subclass:
+      return subclass  # success
+    if not elements:
+      break  # no more paths to try
     elements.pop()  # try resolving against the next-outer path
   raise ValueError(
       'Failed to create subclass "%s" of base class %s using path %s' %
diff --git a/research/syntaxnet/syntaxnet/util/registry_test.py b/research/syntaxnet/syntaxnet/util/registry_test.py
index 53d337e9..90ff0286 100644
--- a/research/syntaxnet/syntaxnet/util/registry_test.py
+++ b/research/syntaxnet/syntaxnet/util/registry_test.py
@@ -1,3 +1,18 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
 """Tests for registry system.
 
 This test uses two other modules:
@@ -104,9 +119,11 @@ class RegistryTest(googletest.TestCase):
   def testCannotResolveRelativeName(self):
     """Tests that Create fails if a relative path cannot be resolved."""
     for name in [
-        'nlp.saft.opensource.syntaxnet.util.registry_test_base.Impl',
-        'saft.bad.registry_test_impl.Impl', 'missing.registry_test_impl.Impl',
-        'registry_test_impl.Bad', 'Impl'
+        'bad.syntaxnet.util.registry_test_base.Impl',
+        'syntaxnet.bad.registry_test_impl.Impl',
+        'missing.registry_test_impl.Impl',
+        'registry_test_impl.Bad',
+        'Impl'
     ]:
       with self.assertRaisesRegexp(ValueError, 'Failed to create'):
         registry_test_base.Base.Create(name, 'hello world')
diff --git a/research/syntaxnet/syntaxnet/util/resources.py b/research/syntaxnet/syntaxnet/util/resources.py
new file mode 100644
index 00000000..cc1831a3
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/util/resources.py
@@ -0,0 +1,74 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+"""Utils for loading resources (data files) from the SyntaxNet source tree.
+
+The resources must be data dependencies of the relevant py_*() build target.
+
+Example usage:
+
+from syntaxnet.util import resources
+
+data_blob = resources.GetSyntaxNetResource(
+    'syntaxnet/testdata/context.pbtxt')
+"""
+
+import os
+
+# Absolute path to the root directory holding syntaxnet.  Resource paths are
+# interpreted relative to this path.
+
+_ROOT_DIR = os.path.dirname(              # .../
+    os.path.dirname(                      # .../syntaxnet/
+        os.path.dirname(                  # .../syntaxnet/util/
+            os.path.abspath(__file__))))  # .../syntaxnet/util/resources.py
+
+
+def GetSyntaxNetResourceAsFile(path):
+  """Returns a resource as an opened read-only file.
+
+  Args:
+    path: Relative path to the resource, which must be a Bazel data dependency.
+
+  Returns:
+    Opened read-only file pointing to resource data.
+
+  Raises:
+    IOError: If the resource cannot be loaded.
+  """
+  path = os.path.join(_ROOT_DIR, path)
+  if os.path.isdir(path):
+    raise IOError('Resource "{}" is not a file'.format(path))
+  if not os.path.isfile(path):
+    raise IOError(
+        'Resource "{}" not found; is it a data dependency?'.format(path))
+  return open(path, 'rb')
+
+
+def GetSyntaxNetResource(path):
+  """Returns the content of a resource.
+
+  Args:
+    path: Relative path to the resource, which must be a Bazel data dependency.
+
+  Returns:
+    Raw content of the resource.
+
+  Raises:
+    IOError: If the resource cannot be loaded.
+  """
+  with GetSyntaxNetResourceAsFile(path) as resource_file:
+    return resource_file.read()
+
+
diff --git a/research/syntaxnet/syntaxnet/util/resources_test.py b/research/syntaxnet/syntaxnet/util/resources_test.py
new file mode 100644
index 00000000..d63ff26c
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/util/resources_test.py
@@ -0,0 +1,44 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+"""Tests for resources."""
+
+from tensorflow.python.platform import googletest
+
+from syntaxnet.util import resources
+
+
+class ResourcesTest(googletest.TestCase):
+  """Testing rig."""
+
+  def testInvalidResource(self):
+    for path in [
+        'bad/path/to/no/file',
+        'syntaxnet/testdata',
+        'syntaxnet/testdata/context.pbtxt',
+    ]:
+      with self.assertRaises(IOError):
+        resources.GetSyntaxNetResource(path)
+      with self.assertRaises(IOError):
+        resources.GetSyntaxNetResourceAsFile(path)
+
+  def testValidResource(self):
+    path = 'syntaxnet/testdata/hello.txt'
+    self.assertEqual('hello world\n', resources.GetSyntaxNetResource(path))
+    with resources.GetSyntaxNetResourceAsFile(path) as resource_file:
+      self.assertEqual('hello world\n', resource_file.read())
+
+
+if __name__ == '__main__':
+  googletest.main()
diff --git a/research/syntaxnet/syntaxnet/whole_sentence_features.h b/research/syntaxnet/syntaxnet/whole_sentence_features.h
index 5a5829a1..e42cc556 100644
--- a/research/syntaxnet/syntaxnet/whole_sentence_features.h
+++ b/research/syntaxnet/syntaxnet/whole_sentence_features.h
@@ -16,11 +16,12 @@ limitations under the License.
 // Features for whole Sentence objects.  Contrast with SentenceFeature, which
 // operates on tokens within Sentences.
 
-#include "syntaxnet/feature_extractor.h"
-
 #ifndef SYNTAXNET_WHOLE_SENTENCE_FEATURES_H_
 #define SYNTAXNET_WHOLE_SENTENCE_FEATURES_H_
 
+#include "syntaxnet/feature_extractor.h"
+#include "syntaxnet/registry.h"
+
 namespace syntaxnet {
 
 // Type of feature functions whose focus is a whole sentence.
@@ -30,6 +31,9 @@ typedef FeatureFunction<Sentence> WholeSentenceFeatureFunction;
 #define REGISTER_WHOLE_SENTENCE_FEATURE_FUNCTION(name, type) \
   REGISTER_SYNTAXNET_FEATURE_FUNCTION(WholeSentenceFeatureFunction, name, type)
 
+DECLARE_SYNTAXNET_CLASS_REGISTRY("whole sentence feature function",
+                                 WholeSentenceFeatureFunction);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_WHOLE_SENTENCE_FEATURES_H_
diff --git a/research/syntaxnet/tensorflow b/research/syntaxnet/tensorflow
index 90267567..c52cdc03 160000
--- a/research/syntaxnet/tensorflow
+++ b/research/syntaxnet/tensorflow
@@ -1 +1 @@
-Subproject commit 9026756727e7c6782ab89c181c80b2117bf78c05
+Subproject commit c52cdc03a67ceae9ecc8c00025d3c60f54833e2d
diff --git a/research/syntaxnet/third_party/utf/LICENSE b/research/syntaxnet/third_party/utf/LICENSE
new file mode 100644
index 00000000..ad76cd52
--- /dev/null
+++ b/research/syntaxnet/third_party/utf/LICENSE
@@ -0,0 +1,13 @@
+/*
+ * The authors of this software are Rob Pike and Ken Thompson.
+ *              Copyright (c) 1998-2002 by Lucent Technologies.
+ * Permission to use, copy, modify, and distribute this software for any
+ * purpose without fee is hereby granted, provided that this entire notice
+ * is included in all copies of any software which is or includes a copy
+ * or modification of this software and in all copies of the supporting
+ * documentation for such software.
+ * THIS SOFTWARE IS BEING PROVIDED "AS IS", WITHOUT ANY EXPRESS OR IMPLIED
+ * WARRANTY.  IN PARTICULAR, NEITHER THE AUTHORS NOR LUCENT TECHNOLOGIES MAKE ANY
+ * REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY
+ * OF THIS SOFTWARE OR ITS FITNESS FOR ANY PARTICULAR PURPOSE.
+ */
diff --git a/research/syntaxnet/tools/bazel.rc b/research/syntaxnet/tools/bazel.rc
index 3bf93af5..d4732657 100644
--- a/research/syntaxnet/tools/bazel.rc
+++ b/research/syntaxnet/tools/bazel.rc
@@ -1,3 +1,5 @@
+import %workspace%/tensorflow/.tf_configure.bazelrc
+
 build:cuda --crosstool_top=@local_config_cuda//crosstool:toolchain
 build:cuda --define=using_cuda=true --define=using_cuda_nvcc=true
 build:win-cuda --define=using_cuda=true --define=using_cuda_nvcc=true
