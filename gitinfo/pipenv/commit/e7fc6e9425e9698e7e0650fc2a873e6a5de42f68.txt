commit e7fc6e9425e9698e7e0650fc2a873e6a5de42f68
Author: Dan Ryan <dan.ryan@canonical.com>
Date:   Wed Mar 25 19:30:16 2020 -0400

    Re-vendor dependencies
    
    - Update tomlkit => 0.5.11
    
    Signed-off-by: Dan Ryan <dan.ryan@canonical.com>

diff --git a/Pipfile.lock b/Pipfile.lock
index 924c988a..69e46128 100644
--- a/Pipfile.lock
+++ b/Pipfile.lock
@@ -5,11 +5,13 @@
         },
         "pipfile-spec": 6,
         "requires": {},
-        "sources": [{
+        "sources": [
+            {
             "name": "pypi",
             "url": "https://pypi.org/simple",
             "verify_ssl": true
-        }]
+            }
+        ]
     },
     "default": {},
     "develop": {
@@ -37,10 +39,10 @@
         },
         "arpeggio": {
             "hashes": [
-                "sha256:a5258b84f76661d558492fa87e42db634df143685a0e51802d59cae7daad8732",
-                "sha256:dc5c0541e7cc2c6033dc0338133436abfac53655624784736e9bc8bd35e56583"
+                "sha256:948ce06163a48a72c97f4fe79ad3d1c1330b6fec4f22ece182fb60ef60bd022b",
+                "sha256:b9178917594bb9758002faed31e1e1c968b5ea7f2a8f78fd4a5b8fecaccfcfcd"
             ],
-            "version": "==1.9.0"
+            "version": "==1.9.2"
         },
         "atomicwrites": {
             "hashes": [
@@ -51,51 +53,51 @@
         },
         "attrs": {
             "hashes": [
-                "sha256:69c0dbf2ed392de1cb5ec704444b08a5ef81680a61cb899dc08127123af36a79",
-                "sha256:f0b870f674851ecbfbbbd364d6b5cbdff9dcedbc7f3f5e18a6891057f21fe399"
+                "sha256:08a96c641c3a74e44eb59afb61a24f2cb9f4d7188748e76ba4bb5edfa3cb7d1c",
+                "sha256:f7b7ce16570fe9965acd6d30101a28f62fb4a7f9e926b3bbc9b61f8b04247e72"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==19.1.0"
+            "version": "==19.3.0"
         },
         "babel": {
             "hashes": [
-                "sha256:af92e6106cb7c55286b25b38ad7695f8b4efb36a90ba483d7f7a6628c46158ab",
-                "sha256:e86135ae101e31e2c8ec20a4e0c5220f4eed12487d5cf3f78be7e98d3a57fc28"
+                "sha256:1aac2ae2d0d8ea368fa90906567f5c08463d98ade155c0c4bfedd6a0f7160e38",
+                "sha256:d670ea0b10f8b723672d3a6abeb87b565b244da220d76b4dba1b66269ec152d4"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==2.7.0"
+            "version": "==2.8.0"
         },
         "backports.functools-lru-cache": {
             "hashes": [
-                "sha256:9d98697f088eb1b0fa451391f91afb5e3ebde16bbdb272819fd091151fda4f1a",
-                "sha256:f0b0e4eba956de51238e17573b7087e852dfe9854afd2e9c873f73fc0ca0a6dd"
+                "sha256:0bada4c2f8a43d533e4ecb7a12214d9420e66eb206d54bf2d682581ca4b80848",
+                "sha256:8fde5f188da2d593bd5bc0be98d9abc46c95bb8a9dde93429570192ee6cc2d4a"
             ],
-            "markers": "python_version < '3'",
-            "version": "==1.5"
+            "markers": "python_version < '3.2'",
+            "version": "==1.6.1"
         },
         "beautifulsoup4": {
             "hashes": [
-                "sha256:034740f6cb549b4e932ae1ab975581e6103ac8f942200a0e9759065984391858",
-                "sha256:945065979fb8529dd2f37dbb58f00b661bdbcbebf954f93b32fdf5263ef35348",
-                "sha256:ba6d5c59906a85ac23dadfe5c88deaf3e179ef565f4898671253e50a78680718"
+                "sha256:05fd825eb01c290877657a56df4c6e4c311b3965bda790c613a3d6fb01a5462a",
+                "sha256:9fbb4d6e48ecd30bcacc5b63b94088192dcda178513b2ae3c394229f8911b887",
+                "sha256:e1505eeed31b0f4ce2dbb3bc8eb256c04cc2b3b72af7d551a4ab6efd5cbe5dae"
             ],
-            "version": "==4.7.1"
+            "version": "==4.8.2"
         },
         "black": {
             "hashes": [
-                "sha256:09a9dcb7c46ed496a9850b76e4e825d6049ecd38b611f1224857a79bd985a8cf",
-                "sha256:68950ffd4d9169716bcb8719a56c07a2f4485354fec061cdd5910aa07369731c"
+                "sha256:1b30e59be925fafc1ee4565e5e08abef6b03fe455102883820fe5ee2e4734e0b",
+                "sha256:c2edb73a08e9e0e6f65a0e6af18b059b8b1cdd5bef997d7a0b181df93dc81539"
             ],
             "markers": "python_version >= '3.6'",
-            "version": "==19.3b0"
+            "version": "==19.10b0"
         },
         "bleach": {
             "hashes": [
-                "sha256:213336e49e102af26d9cde77dd2d0397afabc5a6bf2fed985dc35b5d1e285a16",
-                "sha256:3fdf7f77adcf649c9911387df51254b813185e32b2c6619f690b593a617e19fa"
+                "sha256:cc8da25076a1fe56c3ac63671e2194458e0c4d9c7becfd52ca251650d517903c",
+                "sha256:e78e426105ac07026ba098f04de8abe9b6e3e98b5befbf89b51a5ef0a4292b03"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==3.1.0"
+            "version": "==3.1.4"
         },
         "bs4": {
             "hashes": [
@@ -105,10 +107,43 @@
         },
         "certifi": {
             "hashes": [
-                "sha256:046832c04d4e752f37383b628bc601a7ea7211496b4638f6514d0e5b9acc4939",
-                "sha256:945e3ba63a0b9f577b1395204e13c3a231f9bc0223888be653286534e5873695"
-            ],
-            "version": "==2019.6.16"
+                "sha256:017c25db2a153ce562900032d5bc68e9f191e44e9a0f762f373977de9df1fbb3",
+                "sha256:25b64c7da4cd7479594d035c08c2d809eb4aab3a26e5a990ea98cc450c320f1f"
+            ],
+            "version": "==2019.11.28"
+        },
+        "cffi": {
+            "hashes": [
+                "sha256:001bf3242a1bb04d985d63e138230802c6c8d4db3668fb545fb5005ddf5bb5ff",
+                "sha256:00789914be39dffba161cfc5be31b55775de5ba2235fe49aa28c148236c4e06b",
+                "sha256:028a579fc9aed3af38f4892bdcc7390508adabc30c6af4a6e4f611b0c680e6ac",
+                "sha256:14491a910663bf9f13ddf2bc8f60562d6bc5315c1f09c704937ef17293fb85b0",
+                "sha256:1cae98a7054b5c9391eb3249b86e0e99ab1e02bb0cc0575da191aedadbdf4384",
+                "sha256:2089ed025da3919d2e75a4d963d008330c96751127dd6f73c8dc0c65041b4c26",
+                "sha256:2d384f4a127a15ba701207f7639d94106693b6cd64173d6c8988e2c25f3ac2b6",
+                "sha256:337d448e5a725bba2d8293c48d9353fc68d0e9e4088d62a9571def317797522b",
+                "sha256:399aed636c7d3749bbed55bc907c3288cb43c65c4389964ad5ff849b6370603e",
+                "sha256:3b911c2dbd4f423b4c4fcca138cadde747abdb20d196c4a48708b8a2d32b16dd",
+                "sha256:3d311bcc4a41408cf5854f06ef2c5cab88f9fded37a3b95936c9879c1640d4c2",
+                "sha256:62ae9af2d069ea2698bf536dcfe1e4eed9090211dbaafeeedf5cb6c41b352f66",
+                "sha256:66e41db66b47d0d8672d8ed2708ba91b2f2524ece3dee48b5dfb36be8c2f21dc",
+                "sha256:675686925a9fb403edba0114db74e741d8181683dcf216be697d208857e04ca8",
+                "sha256:7e63cbcf2429a8dbfe48dcc2322d5f2220b77b2e17b7ba023d6166d84655da55",
+                "sha256:8a6c688fefb4e1cd56feb6c511984a6c4f7ec7d2a1ff31a10254f3c817054ae4",
+                "sha256:8c0ffc886aea5df6a1762d0019e9cb05f825d0eec1f520c51be9d198701daee5",
+                "sha256:95cd16d3dee553f882540c1ffe331d085c9e629499ceadfbda4d4fde635f4b7d",
+                "sha256:99f748a7e71ff382613b4e1acc0ac83bf7ad167fb3802e35e90d9763daba4d78",
+                "sha256:b8c78301cefcf5fd914aad35d3c04c2b21ce8629b5e4f4e45ae6812e461910fa",
+                "sha256:c420917b188a5582a56d8b93bdd8e0f6eca08c84ff623a4c16e809152cd35793",
+                "sha256:c43866529f2f06fe0edc6246eb4faa34f03fe88b64a0a9a942561c8e22f4b71f",
+                "sha256:cab50b8c2250b46fe738c77dbd25ce017d5e6fb35d3407606e7a4180656a5a6a",
+                "sha256:cef128cb4d5e0b3493f058f10ce32365972c554572ff821e175dbc6f8ff6924f",
+                "sha256:cf16e3cf6c0a5fdd9bc10c21687e19d29ad1fe863372b5543deaec1039581a30",
+                "sha256:e56c744aa6ff427a607763346e4170629caf7e48ead6921745986db3692f987f",
+                "sha256:e577934fc5f8779c554639376beeaa5657d54349096ef24abe8c74c5d9c117c3",
+                "sha256:f2b0fa0c01d8a0c7483afd9f31d7ecf2d71760ca24499c8697aeb5ca37dc090c"
+            ],
+            "version": "==1.14.0"
         },
         "chardet": {
             "hashes": [
@@ -127,34 +162,61 @@
         },
         "click": {
             "hashes": [
-                "sha256:2335065e6395b9e67ca716de5f7526736bfa6ceead690adf616d925bdc622b13",
-                "sha256:5b94b49521f6456670fdb30cd82a4eca9412788a93fa6dd6df72c94d5a8ff2d7"
+                "sha256:8a18b4ea89d8820c5d0c7da8a64b2c324b4dabb695804dbfea19b9be9d88c0cc",
+                "sha256:e345d143d80bf5ee7534056164e5e112ea5e22716bbb1ce727941f4c8b471b9a"
             ],
             "index": "pypi",
-            "version": "==7.0"
+            "version": "==7.1.1"
         },
         "colorama": {
             "hashes": [
-                "sha256:05eed71e2e327246ad6b38c540c4a3117230b19679b875190486ddd2d721422d",
-                "sha256:f8ac84de7840f5b9c4e3347b3c1eaa50f7e49c2b07596221daec5edaabbd7c48"
+                "sha256:7d73d2a99753107a36ac6b455ee49046802e59d9d076ef8e47b61499fa29afff",
+                "sha256:e96da0d330793e2cb9485e9ddfd918d456036c7149416295932478192f4436a1"
             ],
-            "version": "==0.4.1"
+            "version": "==0.4.3"
         },
         "configparser": {
             "hashes": [
-                "sha256:8be81d89d6e7b4c0d4e44bcc525845f6da25821de80cb5e06e7e0238a2899e32",
-                "sha256:da60d0014fd8c55eb48c1c5354352e363e2d30bbf7057e5e171a468390184c75"
+                "sha256:254c1d9c79f60c45dfde850850883d5aaa7f19a23f13561243a050d5a7c3fe4c",
+                "sha256:c7d282687a5308319bf3d2e7706e575c635b0a470342641c93bea0ea3b5331df"
             ],
-            "markers": "python_version < '3'",
-            "version": "==3.7.4"
+            "markers": "python_version < '3.2'",
+            "version": "==4.0.2"
         },
         "contextlib2": {
             "hashes": [
-                "sha256:509f9419ee91cdd00ba34443217d5ca51f5a364a404e1dce9e8979cea969ca48",
-                "sha256:f5260a6e679d2ff42ec91ec5252f4eeffdcf21053db9113bd0a8e4d953769c00"
+                "sha256:01f490098c18b19d2bd5bb5dc445b2054d2fa97f09a4280ba2c5f3c394c8162e",
+                "sha256:3355078a159fbb44ee60ea80abd0d87b80b78c248643b49aa6d94673b413609b"
             ],
             "markers": "python_version < '3'",
-            "version": "==0.5.5"
+            "version": "==0.6.0.post1"
+        },
+        "cryptography": {
+            "hashes": [
+                "sha256:02079a6addc7b5140ba0825f542c0869ff4df9a69c360e339ecead5baefa843c",
+                "sha256:1df22371fbf2004c6f64e927668734070a8953362cd8370ddd336774d6743595",
+                "sha256:369d2346db5934345787451504853ad9d342d7f721ae82d098083e1f49a582ad",
+                "sha256:3cda1f0ed8747339bbdf71b9f38ca74c7b592f24f65cdb3ab3765e4b02871651",
+                "sha256:44ff04138935882fef7c686878e1c8fd80a723161ad6a98da31e14b7553170c2",
+                "sha256:4b1030728872c59687badcca1e225a9103440e467c17d6d1730ab3d2d64bfeff",
+                "sha256:58363dbd966afb4f89b3b11dfb8ff200058fbc3b947507675c19ceb46104b48d",
+                "sha256:6ec280fb24d27e3d97aa731e16207d58bd8ae94ef6eab97249a2afe4ba643d42",
+                "sha256:7270a6c29199adc1297776937a05b59720e8a782531f1f122f2eb8467f9aab4d",
+                "sha256:73fd30c57fa2d0a1d7a49c561c40c2f79c7d6c374cc7750e9ac7c99176f6428e",
+                "sha256:7f09806ed4fbea8f51585231ba742b58cbcfbfe823ea197d8c89a5e433c7e912",
+                "sha256:90df0cc93e1f8d2fba8365fb59a858f51a11a394d64dbf3ef844f783844cc793",
+                "sha256:971221ed40f058f5662a604bd1ae6e4521d84e6cad0b7b170564cc34169c8f13",
+                "sha256:a518c153a2b5ed6b8cc03f7ae79d5ffad7315ad4569b2d5333a13c38d64bd8d7",
+                "sha256:b0de590a8b0979649ebeef8bb9f54394d3a41f66c5584fff4220901739b6b2f0",
+                "sha256:b43f53f29816ba1db8525f006fa6f49292e9b029554b3eb56a189a70f2a40879",
+                "sha256:d31402aad60ed889c7e57934a03477b572a03af7794fa8fb1780f21ea8f6551f",
+                "sha256:de96157ec73458a7f14e3d26f17f8128c959084931e8997b9e655a39c8fde9f9",
+                "sha256:df6b4dca2e11865e6cfbfb708e800efb18370f5a46fd601d3755bc7f85b3a8a2",
+                "sha256:ecadccc7ba52193963c0475ac9f6fa28ac01e01349a2ca48509667ef41ffd2cf",
+                "sha256:fb81c17e0ebe3358486cd8cc3ad78adbae58af12fc2bf2bc0bb84e8090fa5ce8"
+            ],
+            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
+            "version": "==2.8"
         },
         "decorator": {
             "hashes": [
@@ -163,13 +225,19 @@
             ],
             "version": "==4.4.0"
         },
+        "distlib": {
+            "hashes": [
+                "sha256:2e166e231a26b36d6dfe35a48c4464346620f8645ed0ace01ee31822b288de21"
+            ],
+            "version": "==0.3.0"
+        },
         "docutils": {
             "hashes": [
-                "sha256:02aec4bd92ab067f6ff27a38a38a41173bf01bed8f89157768c1573f53e474a6",
-                "sha256:51e64ef2ebfb29cae1faa133b3710143496eca21c530f3f71424d77687764274",
-                "sha256:7a4bd47eaf6596e1295ecb11361139febe29b084a87bf005bf899f9a42edc3c6"
+                "sha256:0c5b78adfbf7762415433f5515cd5c9e762339e23369dbe8000d84a4bf4ab3af",
+                "sha256:c2de3a60e9e7d07be26b7f2b00ca0309c207e06c100f9cc2a94931fc75a478fc"
             ],
-            "version": "==0.14"
+            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
+            "version": "==0.16"
         },
         "entrypoints": {
             "hashes": [
@@ -181,51 +249,58 @@
         },
         "enum34": {
             "hashes": [
-                "sha256:2d81cbbe0e73112bdfe6ef8576f2238f2ba27dd0d55752a776c41d38b7da2850",
-                "sha256:644837f692e5f550741432dd3f223bbb9852018674981b1664e5dc339387588a",
-                "sha256:6bd0f6ad48ec2aa117d3d141940d484deccda84d4fcd884f5c3d93c23ecd8c79",
-                "sha256:8ad8c4783bf61ded74527bffb48ed9b54166685e4230386a9ed9b1279e2df5b1"
+                "sha256:a98a201d6de3f2ab3db284e70a33b0f896fbf35f8086594e8c9e74b909058d53",
+                "sha256:c3858660960c984d6ab0ebad691265180da2b43f07e061c0f8dca9ef3cffd328",
+                "sha256:cce6a7477ed816bd2542d03d53db9f0db935dd013b70f336a95c73979289f248"
             ],
-            "markers": "python_version < '3'",
-            "version": "==1.1.6"
+            "markers": "python_version < '3.0'",
+            "version": "==1.1.10"
         },
         "execnet": {
             "hashes": [
-                "sha256:027ee5d961afa01e97b90d6ccc34b4ed976702bc58e7f092b3c513ea288cb6d2",
-                "sha256:752a3786f17416d491f833a29217dda3ea4a471fc5269c492eebcee8cc4772d3"
+                "sha256:cacb9df31c9680ec5f95553976c4da484d407e85e41c83cb812aa014f0eddc50",
+                "sha256:d4efd397930c46415f62f8a31388d6be4f27a91d7550eb79bc64a756e0056547"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==1.6.0"
+            "version": "==1.7.1"
+        },
+        "filelock": {
+            "hashes": [
+                "sha256:18d82244ee114f543149c66a6e0c14e9c4f8a1044b5cdaadd0f82159d6a6ff59",
+                "sha256:929b7d63ec5b7d6b71b0fa5ac14e030b3f70b75747cef1b10da9b879fef15836"
+            ],
+            "version": "==3.0.12"
         },
         "flake8": {
             "hashes": [
-                "sha256:859996073f341f2670741b51ec1e67a01da142831aa1fdc6242dbf88dffbe661",
-                "sha256:a796a115208f5c03b18f332f7c11729812c8c3ded6c46319c59b53efd3819da8"
+                "sha256:45681a117ecc81e870cbf1262835ae4af5e7a8b08e40b944a8a6e6b895914cfb",
+                "sha256:49356e766643ad15072a789a20915d3c91dc89fd313ccd71802303fd67e4deca"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==3.7.7"
+            "version": "==3.7.9"
         },
         "flaky": {
             "hashes": [
-                "sha256:12bd5e41f372b2190e8d754b6e5829c2f11dbc764e10b30f57e59f829c9ca1da",
-                "sha256:a94931c46a33469ec26f09b652bc88f55a8f5cc77807b90ca7bbafef1108fd7d"
+                "sha256:5471615b32b0f8086573de924475b1f0d31e0e8655a089eb9c38a0fbff3f11aa",
+                "sha256:8cd5455bb00c677f787da424eaf8c4a58a922d0e97126d3085db5b279a98b698"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==3.5.3"
+            "version": "==3.6.1"
         },
         "flask": {
             "hashes": [
-                "sha256:ad7c6d841e64296b962296c2c2dabc6543752985727af86a975072dea984b6f3",
-                "sha256:e7d32475d1de5facaa55e3958bc4ec66d3762076b074296aa50ef8fdc5b9df61"
+                "sha256:13f9f196f330c7c2c5d7a5cf91af894110ca0215ac051b5844701f2bfd934d52",
+                "sha256:45eb5a6fd193d6cf7e0cf5d8a5b31f83d5faae0293695626f539a823e93b13f6"
             ],
-            "version": "==1.0.3"
+            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
+            "version": "==1.1.1"
         },
         "funcsigs": {
             "hashes": [
                 "sha256:330cc27ccbf7f1e992e69fef78261dc7c6569012cf397db8d3de0234e6c937ca",
                 "sha256:a7bb0f2cf3a3fd1ab2732cb49eba4252c2af4240442415b4abce3b87022a8f50"
             ],
-            "markers": "python_version < '3.0'",
+            "markers": "python_version < '3.3'",
             "version": "==1.0.2"
         },
         "functools32": {
@@ -245,34 +320,43 @@
         },
         "futures": {
             "hashes": [
-                "sha256:9ec02aa7d674acb8618afb127e27fde7fc68994c0437ad759fa094a574adb265",
-                "sha256:ec0a6cb848cc212002b9828c3e34c675e0c9ff6741dc445cab6fdd4e1085d1f1"
+                "sha256:49b3f5b064b6e3afc3316421a3f25f66c137ae88f068abbf72830170033c5e16",
+                "sha256:7e033af76a5e35f58e56da7a91e687706faf4e7bdfb2cbc3f2cca6b9bcda9794"
             ],
             "markers": "python_version < '3.2'",
-            "version": "==3.2.0"
+            "version": "==3.3.0"
         },
         "idna": {
             "hashes": [
-                "sha256:c357b3f628cf53ae2c4c05627ecc484553142ca23264e593d327bcde5e9c3407",
-                "sha256:ea8b7f6188e6fa117537c3df7da9fc686d485087abf6ac197f9c46432f7e4a3c"
+                "sha256:7588d1c14ae4c77d74036e8c22ff447b26d0fde8f007354fd48a7814db15b7cb",
+                "sha256:a068a21ceac8a4d63dbfd964670474107f541babbd2250d61922f029858365fa"
             ],
-            "version": "==2.8"
+            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
+            "version": "==2.9"
         },
         "imagesize": {
             "hashes": [
-                "sha256:3f349de3eb99145973fefb7dbe38554414e5c30abd0c8e4b970a7c9d09f3a1d8",
-                "sha256:f3832918bc3c66617f92e35f5d70729187676313caa60c187eb0f28b8fe5e3b5"
+                "sha256:6965f19a6a2039c7d48bca7dba2473069ff854c36ae6f19d2cde309d998228a1",
+                "sha256:b1f6b5a4eab1f73479a50fb79fcf729514a900c341d8503d62a62dbc4127a2b1"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==1.1.0"
+            "version": "==1.2.0"
         },
         "importlib-metadata": {
             "hashes": [
-                "sha256:6dfd58dfe281e8d240937776065dd3624ad5469c835248219bd16cf2e12dbeb7",
-                "sha256:cb6ee23b46173539939964df59d3d72c3e0c1b5d54b84f1d8a7e912fe43612db"
+                "sha256:298a914c82144c6b3b06c568a8973b89ad2176685f43cd1ea9ba968307300fa9",
+                "sha256:dfc83688553a91a786c6c91eeb5f3b1d31f24d71877bbd94ecbf5484e57690a2"
             ],
-            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==0.18"
+            "markers": "python_version < '3.8'",
+            "version": "==1.5.2"
+        },
+        "importlib-resources": {
+            "hashes": [
+                "sha256:4019b6a9082d8ada9def02bece4a76b131518866790d58fdda0b5f8c603b36c2",
+                "sha256:dd98ceeef3f5ad2ef4cc287b8586da4ebad15877f351e9688987ad663a0a29b8"
+            ],
+            "markers": "python_version < '3.7'",
+            "version": "==1.4.0"
         },
         "incremental": {
             "hashes": [
@@ -283,19 +367,19 @@
         },
         "invoke": {
             "hashes": [
-                "sha256:4f4de934b15c2276caa4fbc5a3b8a61c0eb0b234f2be1780d2b793321995c2d6",
-                "sha256:dc492f8f17a0746e92081aec3f86ae0b4750bf41607ea2ad87e5a7b5705121b7",
-                "sha256:eb6f9262d4d25b40330fb21d1e99bf0f85011ccc3526980f8a3eaedd4b43892e"
+                "sha256:87b3ef9d72a1667e104f89b159eaf8a514dbf2f3576885b2bbdefe74c3fb2132",
+                "sha256:93e12876d88130c8e0d7fd6618dd5387d6b36da55ad541481dfa5e001656f134",
+                "sha256:de3f23bfe669e3db1085789fd859eb8ca8e0c5d9c20811e2407fa042e8a5e15d"
             ],
-            "version": "==1.2.0"
+            "version": "==1.4.1"
         },
         "isort": {
             "hashes": [
-                "sha256:c40744b6bc5162bbb39c1257fe298b7a393861d50978b565f3ccd9cb9de0182a",
-                "sha256:f57abacd059dc3bd666258d1efb0377510a89777fda3e3274e3c01f7c03ae22d"
+                "sha256:54da7e92468955c4fceacd0c86bd0ec997b0e1ee80d97f67c35a78b719dccab1",
+                "sha256:6e811fcb295968434526407adb8796944f1988c5b65e8139058f2014cbe100fd"
             ],
             "index": "pypi",
-            "version": "==4.3.20"
+            "version": "==4.3.21"
         },
         "itsdangerous": {
             "hashes": [
@@ -307,18 +391,19 @@
         },
         "jedi": {
             "hashes": [
-                "sha256:2bb0603e3506f708e792c7f4ad8fc2a7a9d9c2d292a358fbbd58da531695595b",
-                "sha256:2c6bcd9545c7d6440951b12b44d373479bf18123a401a52025cf98563fbd826c"
+                "sha256:b4f4052551025c6b0b0b193b29a6ff7bdb74c52450631206c262aef9f7159ad2",
+                "sha256:d5c871cb9360b414f981e7072c52c33258d598305280fef91c6cae34739d65d5"
             ],
             "index": "pypi",
-            "version": "==0.13.3"
+            "version": "==0.16.0"
         },
         "jinja2": {
             "hashes": [
-                "sha256:065c4f02ebe7f7cf559e49ee5a95fb800a9e4528727aec6f24402a5374c65013",
-                "sha256:14dd6caf1527abb21f08f86c784eac40853ba93edb79552aa1e4b8aef1b61c7b"
+                "sha256:93187ffbc7808079673ef52771baa950426fd664d3aad1d0fa3e95644360e250",
+                "sha256:b0eaf100007721b5c16c1fc1eecb87409464edc10469ddc9a22a27a99123be49"
             ],
-            "version": "==2.10.1"
+            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
+            "version": "==2.11.1"
         },
         "markupsafe": {
             "hashes": [
@@ -326,13 +411,16 @@
                 "sha256:09027a7803a62ca78792ad89403b1b7a73a01c8cb65909cd876f7fcebd79b161",
                 "sha256:09c4b7f37d6c648cb13f9230d847adf22f8171b1ccc4d5682398e77f40309235",
                 "sha256:1027c282dad077d0bae18be6794e6b6b8c91d58ed8a8d89a89d59693b9131db5",
+                "sha256:13d3144e1e340870b25e7b10b98d779608c02016d5184cfb9927a9f10c689f42",
                 "sha256:24982cc2533820871eba85ba648cd53d8623687ff11cbb805be4ff7b4c971aff",
                 "sha256:29872e92839765e546828bb7754a68c418d927cd064fd4708fab9fe9c8bb116b",
                 "sha256:43a55c2930bbc139570ac2452adf3d70cdbb3cfe5912c71cdce1c2c6bbd9c5d1",
                 "sha256:46c99d2de99945ec5cb54f23c8cd5689f6d7177305ebff350a58ce5f8de1669e",
                 "sha256:500d4957e52ddc3351cabf489e79c91c17f6e0899158447047588650b5e69183",
                 "sha256:535f6fc4d397c1563d08b88e485c3496cf5784e927af890fb3c3aac7f933ec66",
+                "sha256:596510de112c685489095da617b5bcbbac7dd6384aeebeda4df6025d0256a81b",
                 "sha256:62fe6c95e3ec8a7fad637b7f3d372c15ec1caa01ab47926cfdf7a75b40e0eac1",
+                "sha256:6788b695d50a51edb699cb55e35487e430fa21f1ed838122d722e0ff0ac5ba15",
                 "sha256:6dd73240d2af64df90aa7c4e7481e23825ea70af4b4922f8ede5b9e35f78a3b1",
                 "sha256:717ba8fe3ae9cc0006d7c451f0bb265ee07739daf76355d06366154ee68d221e",
                 "sha256:79855e1c5b8da654cf486b830bd42c06e8780cea587384cf6545b7d9ac013a0b",
@@ -349,7 +437,9 @@
                 "sha256:ba59edeaa2fc6114428f1637ffff42da1e311e29382d81b339c1817d37ec93c6",
                 "sha256:c8716a48d94b06bb3b2524c2b77e055fb313aeb4ea620c8dd03a105574ba704f",
                 "sha256:cd5df75523866410809ca100dc9681e301e3c27567cf498077e8551b6d20e42f",
-                "sha256:e249096428b3ae81b08327a63a485ad0878de3fb939049038579ac0ef61e17e7"
+                "sha256:cdb132fc825c38e1aeec2c8aa9338310d29d337bebbd7baa06889d09a60a1fa2",
+                "sha256:e249096428b3ae81b08327a63a485ad0878de3fb939049038579ac0ef61e17e7",
+                "sha256:e8313f01ba26fbbe36c7be1966a7b7424942f670f38e666995b88d012765b9be"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
             "version": "==1.1.1"
@@ -386,46 +476,54 @@
         },
         "packaging": {
             "hashes": [
-                "sha256:0c98a5d0be38ed775798ece1b9727178c4469d9c3b4ada66e8e6b7849f8732af",
-                "sha256:9e1cbf8c12b1f1ce0bb5344b8d7ecf66a6f8a6e91bcb0c84593ed6d3ab5c4ab3"
+                "sha256:3c292b474fda1671ec57d46d739d072bfd495a4f51ad01a055121d81e952b7a3",
+                "sha256:82f77b9bee21c1bafbf35a84905d604d5d1223801d639cf3ed140bd651c08752"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==19.0"
+            "version": "==20.3"
         },
         "parso": {
             "hashes": [
-                "sha256:5052bb33be034cba784193e74b1cde6ebf29ae8b8c1e4ad94df0c4209bfc4826",
-                "sha256:db5881df1643bf3e66c097bfd8935cf03eae73f4cb61ae4433c9ea4fb6613446"
+                "sha256:0c5659e0c6eba20636f99a04f469798dca8da279645ce5c387315b2c23912157",
+                "sha256:8515fc12cfca6ee3aa59138741fc5624d62340c97e401c74875769948d4f2995"
             ],
-            "version": "==0.5.0"
+            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
+            "version": "==0.6.2"
         },
         "parver": {
             "hashes": [
-                "sha256:1b37a691af145a3a193eff269d53ba5b2ab16dfbb65d47d85360755919f5fe4b",
-                "sha256:72d056b8f8883ac90eef5554a9c8a47fac39d3b66479f3d2c8d5bc21b849cdba"
+                "sha256:b57d94e6f389f9db399bfc3ee4c4066f4cfb374ffef5727d5ae6a9c04eb8d228",
+                "sha256:bb9d19637c17819e276b5cf04e2dbfb81c4e2136da8873cc70dcd0e4fd3d14a3"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==0.2.1"
+            "version": "==0.3.0"
         },
         "passa": {
             "git": "https://github.com/sarugaku/passa.git",
-            "ref": "a2ba0b30c86339cae5ef3a03046fc9c583452c40",
+            "ref": "2ac00f16cd5a8f07d679a3ab02b7cc13c6f42bee",
             "version": "==0.3.1.dev0"
         },
         "pathlib2": {
             "hashes": [
-                "sha256:25199318e8cc3c25dcb45cbe084cc061051336d5a9ea2a12448d3d8cb748f742",
-                "sha256:5887121d7f7df3603bca2f710e7219f3eca0eb69e0b7cc6e0a022e155ac931a7"
+                "sha256:0ec8205a157c80d7acc301c0b18fbd5d44fe655968f5d947b6ecef5290fc35db",
+                "sha256:6cd9a47b597b37cc57de1c05e56fb1a1c9cc9fab04fe78c29acd090418529868"
             ],
-            "markers": "python_version < '3.6'",
-            "version": "==2.3.3"
+            "markers": "python_version < '3'",
+            "version": "==2.3.5"
+        },
+        "pathspec": {
+            "hashes": [
+                "sha256:163b0632d4e31cef212976cf57b43d9fd6b0bac6e67c26015d611a647d5e7424",
+                "sha256:562aa70af2e0d434367d9790ad37aed893de47f1693e4201fd1d3dca15d19b96"
+            ],
+            "version": "==0.7.0"
         },
         "pbr": {
             "hashes": [
-                "sha256:9181e2a34d80f07a359ff1d0504fad3a47e00e1cf2c475b0aa7dcb030af54c40",
-                "sha256:94bdc84da376b3dd5061aa0c3b6faffe943ee2e56fa4ff9bd63e1643932f34fc"
+                "sha256:139d2625547dbfa5fb0b81daebb39601c478c21956dc57e2e07b74450a8c506b",
+                "sha256:61aa52a0f18b71c5cc58232d2cf8f8d09cd67fcad60b742a60124cb8d6951488"
             ],
-            "version": "==5.3.1"
+            "version": "==5.4.4"
         },
         "pipenv": {
             "editable": true,
@@ -444,19 +542,19 @@
         },
         "pluggy": {
             "hashes": [
-                "sha256:0825a152ac059776623854c1543d65a4ad408eb3d33ee114dff91e57ec6ae6fc",
-                "sha256:b9817417e95936bf75d85d3f8767f7df6cdde751fc40aed3bb3074cbcb77757c"
+                "sha256:15b2acde666561e1298d71b523007ed7364de07029219b604cf808bfa1c765b0",
+                "sha256:966c145cd83c96502c3c3868f50408687b38434af77734af1e9ca461a4081d2d"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==0.12.0"
+            "version": "==0.13.1"
         },
         "py": {
             "hashes": [
-                "sha256:64f65755aee5b381cea27766a3a147c3f15b9b6b9ac88676de66ba2ae36793fa",
-                "sha256:dc639b046a6e2cff5bbe40194ad65936d6ba360b52b3c3fe1d08a82dd50b5e53"
+                "sha256:5e27081401262157467ad6e7f851b7aa402c5852dbcb3dae06768434de5752aa",
+                "sha256:c20fdd83a5dbc0af9efd622bee9a5564e278f6380fffcacc43ba6f43db2813b0"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==1.8.0"
+            "version": "==1.8.1"
         },
         "pycodestyle": {
             "hashes": [
@@ -466,6 +564,14 @@
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
             "version": "==2.5.0"
         },
+        "pycparser": {
+            "hashes": [
+                "sha256:2d475327684562c3a96cc71adf7dc8c4f0565175cf86b6d7a404ff4c771f15f0",
+                "sha256:7582ad22678f0fcd81102833f60ef8d0e57288b6b5fb00323d101be910e35705"
+            ],
+            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
+            "version": "==2.20"
+        },
         "pyflakes": {
             "hashes": [
                 "sha256:17dbeb2e3f4d772725c777fabc446d5634d1038f234e77343108ce445ea69ce0",
@@ -476,34 +582,35 @@
         },
         "pygments": {
             "hashes": [
-                "sha256:71e430bc85c88a430f000ac1d9b331d2407f681d6f6aec95e8bcfbc3df5b0127",
-                "sha256:881c4c157e45f30af185c1ffe8d549d48ac9127433f2c380c24b84572ad66297"
+                "sha256:2a3fe295e54a20164a9df49c75fa58526d3be48e14aceba6d6b1e8ac0bfd6f1b",
+                "sha256:98c8aa5a9f778fcd1026a17361ddaf7330d1b7c62ae97c3bb0ae73e0b9b6b0fe"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==2.4.2"
+            "version": "==2.5.2"
         },
         "pyparsing": {
             "hashes": [
-                "sha256:1873c03321fc118f4e9746baf201ff990ceb915f433f23b395f5580d1840cb2a",
-                "sha256:9b6323ef4ab914af344ba97510e966d64ba91055d6b9afa6b30799340e89cc03"
+                "sha256:4c830582a84fb022400b85429791bc551f1f4871c33f23e44f353119e92f969f",
+                "sha256:c342dccb5250c08d45fd6f8b4a559613ca603b57498511740e65cd11a2e7dcec"
             ],
             "markers": "python_version >= '2.6' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==2.4.0"
+            "version": "==2.4.6"
         },
         "pytest": {
             "hashes": [
-                "sha256:4a784f1d4f2ef198fe9b7aef793e9fa1a3b2f84e822d9b3a64a181293a572d45",
-                "sha256:926855726d8ae8371803f7b2e6ec0a69953d9c6311fa7c3b6c1b929ff92d27da"
+                "sha256:19e8f75eac01dd3f211edd465b39efbcbdc8fc5f7866d7dd49fedb30d8adf339",
+                "sha256:c77a5f30a90e0ce24db9eaa14ddfd38d4afb5ea159309bdd2dae55b931bc9324"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==4.6.3"
+            "version": "==4.6.9"
         },
         "pytest-forked": {
             "hashes": [
-                "sha256:5fe33fbd07d7b1302c95310803a5e5726a4ff7f19d5a542b7ce57c76fed8135f",
-                "sha256:d352aaced2ebd54d42a65825722cb433004b4446ab5d2044851d9cc7a00c9e38"
+                "sha256:1805699ed9c9e60cb7a8179b8d4fa2b8898098e82d229b0825d8095f0f261100",
+                "sha256:1ae25dba8ee2e56fb47311c9638f9e58552691da87e82d25b0ce0e4bf52b7d87"
             ],
-            "version": "==1.0.2"
+            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
+            "version": "==1.1.3"
         },
         "pytest-pypi": {
             "editable": true,
@@ -511,40 +618,66 @@
         },
         "pytest-tap": {
             "hashes": [
-                "sha256:3b05ec931424bbe44e944726b68f7ef185bb6d25ce9ce21ac52c9af7ffa9b506",
-                "sha256:ca063de56298034302f3cbce55c87a27d7bfa7af7de591cdb9ec6ce45fea5467"
+                "sha256:7de72c291dfc8de944a137366acd1e5877e21029868bd536dedaa8a61af7d2b4",
+                "sha256:87503e7496f9f5505aa603fc6a7b48cf224e9f6be0206958b1ee276810a2fe8a"
             ],
-            "version": "==2.3"
+            "version": "==3.1"
         },
         "pytest-xdist": {
             "hashes": [
-                "sha256:3489d91516d7847db5eaecff7a2e623dba68984835dbe6cedb05ae126c4fb17f",
-                "sha256:501795cb99e567746f30fe78850533d4cd500c93794128e6ab9988e92a17b1f8"
+                "sha256:0f46020d3d9619e6d17a65b5b989c1ebbb58fc7b1da8fb126d70f4bac4dfeed1",
+                "sha256:7dc0d027d258cd0defc618fb97055fbd1002735ca7a6d17037018cf870e24011"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==1.29.0"
+            "version": "==1.31.0"
         },
         "pytz": {
             "hashes": [
-                "sha256:303879e36b721603cc54604edcac9d20401bdbe31e1e4fdee5b9f98d5d31dfda",
-                "sha256:d747dd3d23d77ef44c6a3526e274af6efeb0a6f1afd5a69ba4d5be4098c8e141"
+                "sha256:1c557d7d0e871de1f5ccd5833f60fb2550652da6be2693c1e02300743d21500d",
+                "sha256:b02c06db6cf09c12dd25137e563b31700d3b80fcc4ad23abb7a315f2789819be"
             ],
-            "version": "==2019.1"
+            "version": "==2019.3"
         },
         "readme-renderer": {
             "hashes": [
-                "sha256:bb16f55b259f27f75f640acf5e00cf897845a8b3e4731b5c1a436e4b8529202f",
-                "sha256:c8532b79afc0375a85f10433eca157d6b50f7d6990f337fa498c96cd4bfc203d"
-            ],
-            "version": "==24.0"
+                "sha256:1b6d8dd1673a0b293766b4106af766b6eff3654605f9c4f239e65de6076bc222",
+                "sha256:e67d64242f0174a63c3b727801a2fff4c1f38ebe5d71d95ff7ece081945a6cd4"
+            ],
+            "version": "==25.0"
+        },
+        "regex": {
+            "hashes": [
+                "sha256:01b2d70cbaed11f72e57c1cfbaca71b02e3b98f739ce33f5f26f71859ad90431",
+                "sha256:046e83a8b160aff37e7034139a336b660b01dbfe58706f9d73f5cdc6b3460242",
+                "sha256:113309e819634f499d0006f6200700c8209a2a8bf6bd1bdc863a4d9d6776a5d1",
+                "sha256:200539b5124bc4721247a823a47d116a7a23e62cc6695744e3eb5454a8888e6d",
+                "sha256:25f4ce26b68425b80a233ce7b6218743c71cf7297dbe02feab1d711a2bf90045",
+                "sha256:269f0c5ff23639316b29f31df199f401e4cb87529eafff0c76828071635d417b",
+                "sha256:5de40649d4f88a15c9489ed37f88f053c15400257eeb18425ac7ed0a4e119400",
+                "sha256:7f78f963e62a61e294adb6ff5db901b629ef78cb2a1cfce3cf4eeba80c1c67aa",
+                "sha256:82469a0c1330a4beb3d42568f82dffa32226ced006e0b063719468dcd40ffdf0",
+                "sha256:8c2b7fa4d72781577ac45ab658da44c7518e6d96e2a50d04ecb0fd8f28b21d69",
+                "sha256:974535648f31c2b712a6b2595969f8ab370834080e00ab24e5dbb9d19b8bfb74",
+                "sha256:99272d6b6a68c7ae4391908fc15f6b8c9a6c345a46b632d7fdb7ef6c883a2bbb",
+                "sha256:9b64a4cc825ec4df262050c17e18f60252cdd94742b4ba1286bcfe481f1c0f26",
+                "sha256:9e9624440d754733eddbcd4614378c18713d2d9d0dc647cf9c72f64e39671be5",
+                "sha256:9ff16d994309b26a1cdf666a6309c1ef51ad4f72f99d3392bcd7b7139577a1f2",
+                "sha256:b33ebcd0222c1d77e61dbcd04a9fd139359bded86803063d3d2d197b796c63ce",
+                "sha256:bba52d72e16a554d1894a0cc74041da50eea99a8483e591a9edf1025a66843ab",
+                "sha256:bed7986547ce54d230fd8721aba6fd19459cdc6d315497b98686d0416efaff4e",
+                "sha256:c7f58a0e0e13fb44623b65b01052dae8e820ed9b8b654bb6296bc9c41f571b70",
+                "sha256:d58a4fa7910102500722defbde6e2816b0372a4fcc85c7e239323767c74f5cbc",
+                "sha256:f1ac2dc65105a53c1c2d72b1d3e98c2464a133b4067a51a3d2477b28449709a0"
+            ],
+            "version": "==2020.2.20"
         },
         "requests": {
             "hashes": [
-                "sha256:11e007a8a2aa0323f5a921e9e6a2d7e4e67d9877e85773fba9ba6419025cbeb4",
-                "sha256:9cf5292fcd0f598c671cfc1e0d7d1a7f13bb8085e9a590f48c010551dc6c4b31"
+                "sha256:43999036bfa82904b6af1d99e4882b560e5e2c68e5c4b0aa03b655f3d7d73fee",
+                "sha256:b3f43d496c6daba4493e7c431722aeb7dbc6288f52a6e04e7b6023b0247817e6"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==2.22.0"
+            "version": "==2.23.0"
         },
         "requests-toolbelt": {
             "hashes": [
@@ -562,12 +695,12 @@
         },
         "rope": {
             "hashes": [
-                "sha256:6b728fdc3e98a83446c27a91fc5d56808a004f8beab7a31ab1d7224cecc7d969",
-                "sha256:c5c5a6a87f7b1a2095fb311135e2a3d1f194f5ecb96900fdd0a9100881f48aaf",
-                "sha256:f0dcf719b63200d492b85535ebe5ea9b29e0d0b8aebeb87fe03fc1a65924fdaf"
+                "sha256:52423a7eebb5306a6d63bdc91a7c657db51ac9babfb8341c9a1440831ecf3203",
+                "sha256:ae1fa2fd56f64f4cc9be46493ce54bed0dd12dee03980c61a4393d89d84029ad",
+                "sha256:d2830142c2e046f5fc26a022fe680675b6f48f81c7fc1f03a950706e746e9dfe"
             ],
             "index": "pypi",
-            "version": "==0.14.0"
+            "version": "==0.16.0"
         },
         "scandir": {
             "hashes": [
@@ -586,27 +719,35 @@
             "markers": "python_version < '3.5'",
             "version": "==1.10.0"
         },
+        "singledispatch": {
+            "hashes": [
+                "sha256:5b06af87df13818d14f08a028e42f566640aef80805c3b50c5056b086e3c2b9c",
+                "sha256:833b46966687b3de7f438c761ac475213e53b306740f1abfaa86e1d1aae56aa8"
+            ],
+            "markers": "python_version < '3.4'",
+            "version": "==3.4.0.3"
+        },
         "six": {
             "hashes": [
-                "sha256:3350809f0555b11f552448330d0b52d5f24c91a322ea4a15ef22629740f3761c",
-                "sha256:d16a0141ec1a18405cd4ce8b4613101da75da0e9a7aec5bdd4fa804d0e0eba73"
+                "sha256:236bdbdce46e6e6a3d61a337c0f8b763ca1e8717c03b369e87a7ec7ce1319c0a",
+                "sha256:8f3cd2e254d8f793e7f3d6d9df77b92252b52637291d0f0da013c76ea2724b6c"
             ],
-            "markers": "python_version >= '2.6' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==1.12.0"
+            "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
+            "version": "==1.14.0"
         },
         "snowballstemmer": {
             "hashes": [
-                "sha256:919f26a68b2c17a7634da993d91339e288964f93c274f1343e3bbbe2096e1128",
-                "sha256:9f3bcd3c401c3e862ec0ebe6d2c069ebc012ce142cce209c098ccb5b09136e89"
+                "sha256:209f257d7533fdb3cb73bdbd24f436239ca3b2fa67d56f6ff88e86be08cc5ef0",
+                "sha256:df3bac3df4c2c01363f3dd2cfa78cce2840a79b9f1c2d2de9ce8d31683992f52"
             ],
-            "version": "==1.2.1"
+            "version": "==2.0.0"
         },
         "soupsieve": {
             "hashes": [
-                "sha256:72b5f1aea9101cf720a36bb2327ede866fd6f1a07b1e87c92a1cc18113cbc946",
-                "sha256:e4e9c053d59795e440163733a7fec6c5972210e1790c507e4c7b051d6c5259de"
+                "sha256:bdb0d917b03a1369ce964056fc195cfdff8819c40de04695a80bc813c3cfa1f5",
+                "sha256:e2c1c5dee4a1c36bcb790e0fabd5492d874b8ebd4617622c4f6a731701060dda"
             ],
-            "version": "==1.9.2"
+            "version": "==1.9.5"
         },
         "sphinx": {
             "hashes": [
@@ -618,11 +759,11 @@
         },
         "sphinx-click": {
             "hashes": [
-                "sha256:2c7847607d07bc0ddf28acff3aa639b2660d06c5d95d1efe89eca6494fc750de",
-                "sha256:814b2463b576dfafaf4a6f8ed9585f6d9696073ed5e4cca5b59d2dc9d29d3bc0"
+                "sha256:793c68b41c4a9435f953e2a27f9bf5883729037b7431f32b2776257c2966bd1b",
+                "sha256:8c6274666730686a65efbae0b4465879b030372333de3114aeb63c44204da32e"
             ],
             "index": "pypi",
-            "version": "==2.2.0"
+            "version": "==2.3.1"
         },
         "sphinxcontrib-websupport": {
             "hashes": [
@@ -634,17 +775,17 @@
         },
         "stdeb": {
             "hashes": [
-                "sha256:0ed2c2cc6b8ba21da7d646c6f37ca60b22e9e4950e3cec6bcd9c2e7e57e3747e"
+                "sha256:4d8351209dda2d26066980222e0d1855a315a68f9af48f0c10d743089afe7d4b"
             ],
             "markers": "sys_platform == 'linux'",
-            "version": "==0.8.5"
+            "version": "==0.9.0"
         },
         "tap.py": {
             "hashes": [
-                "sha256:8ad62ba6898fcef4913c67d468d0c4beae3109b74c03363538145e31b1840b29",
-                "sha256:f6532fd7483c5fdc2ed13575fa4494e7d037f797f8a2c6f8809a859be61271f5"
+                "sha256:a598bfaa2e224d71f2e86147c2ef822c18ff2e1b8ef006397e5056b08f92f699",
+                "sha256:f5eeeeebfd64e53d32661752bb4c288589a3babbb96db3f391a4ec29f1359c70"
             ],
-            "version": "==2.5"
+            "version": "==3.0"
         },
         "termcolor": {
             "hashes": [
@@ -669,44 +810,70 @@
         },
         "tqdm": {
             "hashes": [
-                "sha256:14a285392c32b6f8222ecfbcd217838f88e11630affe9006cd0e94c7eff3cb61",
-                "sha256:25d4c0ea02a305a688e7e9c2cdc8f862f989ef2a4701ab28ee963295f5b109ab"
+                "sha256:0d8b5afb66e23d80433102e9bd8b5c8b65d34c2a2255b2de58d97bd2ea8170fd",
+                "sha256:f35fb121bafa030bd94e74fcfd44f3c2830039a2ddef7fc87ef1c2d205237b24"
             ],
             "markers": "python_version >= '2.6' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==4.32.2"
+            "version": "==4.43.0"
         },
         "twine": {
             "hashes": [
-                "sha256:0fb0bfa3df4f62076cab5def36b1a71a2e4acb4d1fa5c97475b048117b1a6446",
-                "sha256:d6c29c933ecfc74e9b1d9fa13aa1f87c5d5770e119f5a4ce032092f0ff5b14dc"
+                "sha256:630fadd6e342e725930be6c696537e3f9ccc54331742b16245dab292a17d0460",
+                "sha256:a3d22aab467b4682a22de4a422632e79d07eebd07ff2a7079effb13f8a693787"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==1.13.0"
+            "version": "==1.15.0"
+        },
+        "typed-ast": {
+            "hashes": [
+                "sha256:0666aa36131496aed8f7be0410ff974562ab7eeac11ef351def9ea6fa28f6355",
+                "sha256:0c2c07682d61a629b68433afb159376e24e5b2fd4641d35424e462169c0a7919",
+                "sha256:249862707802d40f7f29f6e1aad8d84b5aa9e44552d2cc17384b209f091276aa",
+                "sha256:24995c843eb0ad11a4527b026b4dde3da70e1f2d8806c99b7b4a7cf491612652",
+                "sha256:269151951236b0f9a6f04015a9004084a5ab0d5f19b57de779f908621e7d8b75",
+                "sha256:4083861b0aa07990b619bd7ddc365eb7fa4b817e99cf5f8d9cf21a42780f6e01",
+                "sha256:498b0f36cc7054c1fead3d7fc59d2150f4d5c6c56ba7fb150c013fbc683a8d2d",
+                "sha256:4e3e5da80ccbebfff202a67bf900d081906c358ccc3d5e3c8aea42fdfdfd51c1",
+                "sha256:6daac9731f172c2a22ade6ed0c00197ee7cc1221aa84cfdf9c31defeb059a907",
+                "sha256:715ff2f2df46121071622063fc7543d9b1fd19ebfc4f5c8895af64a77a8c852c",
+                "sha256:73d785a950fc82dd2a25897d525d003f6378d1cb23ab305578394694202a58c3",
+                "sha256:8c8aaad94455178e3187ab22c8b01a3837f8ee50e09cf31f1ba129eb293ec30b",
+                "sha256:8ce678dbaf790dbdb3eba24056d5364fb45944f33553dd5869b7580cdbb83614",
+                "sha256:aaee9905aee35ba5905cfb3c62f3e83b3bec7b39413f0a7f19be4e547ea01ebb",
+                "sha256:bcd3b13b56ea479b3650b82cabd6b5343a625b0ced5429e4ccad28a8973f301b",
+                "sha256:c9e348e02e4d2b4a8b2eedb48210430658df6951fa484e59de33ff773fbd4b41",
+                "sha256:d205b1b46085271b4e15f670058ce182bd1199e56b317bf2ec004b6a44f911f6",
+                "sha256:d43943ef777f9a1c42bf4e552ba23ac77a6351de620aa9acf64ad54933ad4d34",
+                "sha256:d5d33e9e7af3b34a40dc05f498939f0ebf187f07c385fd58d591c533ad8562fe",
+                "sha256:fc0fea399acb12edbf8a628ba8d2312f583bdbdb3335635db062fa98cf71fca4",
+                "sha256:fe460b922ec15dd205595c9b5b99e2f056fd98ae8f9f56b888e7a17dc2b757e7"
+            ],
+            "version": "==1.4.1"
         },
         "typing": {
             "hashes": [
-                "sha256:4027c5f6127a6267a435201981ba156de91ad0d1d98e9ddc2aa173453453492d",
-                "sha256:57dcf675a99b74d64dacf6fba08fb17cf7e3d5fdff53d4a30ea2a5e7e52543d4",
-                "sha256:a4c8473ce11a65999c8f59cb093e70686b6c84c98df58c1dae9b3b196089858a"
+                "sha256:91dfe6f3f706ee8cc32d38edbbf304e9b7583fb37108fef38229617f8b3eba23",
+                "sha256:c8cabb5ab8945cd2f54917be357d134db9cc1eb039e59d1606dc1e60cb1d9d36",
+                "sha256:f38d83c5a7a7086543a0f649564d661859c5146a85775ab90c0d2f93ffaa9714"
             ],
             "markers": "python_version < '3.5'",
-            "version": "==3.6.6"
+            "version": "==3.7.4.1"
         },
         "urllib3": {
             "hashes": [
-                "sha256:b246607a25ac80bedac05c6f282e3cdaf3afb65420fd024ac94435cabe6e18d1",
-                "sha256:dbe59173209418ae49d485b87d1681aefa36252ee85884c31346debd19463232"
+                "sha256:2f3db8b19923a873b3e5256dc9c2dedfa883e33d87c690d9c7913e1f40673cdc",
+                "sha256:87716c2d2a7121198ebcb7ce7cccf6ce5e9ba539041cfbaeecfb641dc0bf6acc"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3' and python_version < '4'",
-            "version": "==1.25.3"
+            "version": "==1.25.8"
         },
         "virtualenv": {
             "hashes": [
-                "sha256:6cb2e4c18d22dbbe283d0a0c31bb7d90771a606b2cb3415323eea008eaee6a9d",
-                "sha256:909fe0d3f7c9151b2df0a2cb53e55bdb7b0d61469353ff7a49fd47b0f0ab9285"
+                "sha256:6f4c2882a943d20714076679f8dcc5675e953d6c29bfea3bc5d08bb6cdea5d36",
+                "sha256:cb1dab893f9e39b3e68d9118c555dcd86526d531c128c3f72e1551939723b72f"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==16.7.2"
+            "version": "==20.0.14"
         },
         "virtualenv-clone": {
             "hashes": [
@@ -718,10 +885,10 @@
         },
         "wcwidth": {
             "hashes": [
-                "sha256:3df37372226d6e63e1b1e1eda15c594bca98a22d33a23832a90998faa96bc65e",
-                "sha256:f4ebe71925af7b40a864553f761ed559b43544f8f71746c2d756c7fe788ade7c"
+                "sha256:cafe2186b3c009a04067022ce1dcd79cb38d8d65ee4f4791b8888d6599d1bbe1",
+                "sha256:ee73862862a156bf77ff92b09034fc4825dd3af9cf81bc5b360668d425f3c5f1"
             ],
-            "version": "==0.1.7"
+            "version": "==0.1.9"
         },
         "webencodings": {
             "hashes": [
@@ -732,19 +899,19 @@
         },
         "werkzeug": {
             "hashes": [
-                "sha256:865856ebb55c4dcd0630cdd8f3331a1847a819dda7e8c750d3db6f2aa6c0209c",
-                "sha256:a0b915f0815982fb2a09161cb8f31708052d0951c3ba433ccc5e1aa276507ca6"
+                "sha256:169ba8a33788476292d04186ab33b01d6add475033dfc07215e6d219cc077096",
+                "sha256:6dc65cf9091cf750012f56f2cad759fa9e879f511b5ff8685e456b4e3bf90d16"
             ],
             "markers": "python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'",
-            "version": "==0.15.4"
+            "version": "==1.0.0"
         },
         "zipp": {
             "hashes": [
-                "sha256:8c1019c6aad13642199fbe458275ad6a84907634cc9f0989877ccc4a2840139d",
-                "sha256:ca943a7e809cc12257001ccfb99e3563da9af99d52f261725e96dfe0f9275bc3"
+                "sha256:c70410551488251b0fee67b460fb9a536af8d6f9f008ad10ac51f615b6a521b1",
+                "sha256:e0d9e63797e483a30d27e09fffd308c59a700d365ec34e93cc100844168bf921"
             ],
-            "markers": "python_version >= '2.7'",
-            "version": "==0.5.1"
+            "markers": "python_version < '3.8'",
+            "version": "==1.2.0"
         }
     }
 }
diff --git a/pipenv/patched/piptools/repositories/pypi.py b/pipenv/patched/piptools/repositories/pypi.py
index a0ea5647..a56cc6e6 100644
--- a/pipenv/patched/piptools/repositories/pypi.py
+++ b/pipenv/patched/piptools/repositories/pypi.py
@@ -5,7 +5,6 @@ import collections
 import copy
 import hashlib
 import os
-import sys
 from contextlib import contextmanager
 from functools import partial
 from shutil import rmtree
diff --git a/pipenv/patched/safety/__init__.py b/pipenv/patched/safety/__init__.py
index 69563274..e9a6e965 100644
--- a/pipenv/patched/safety/__init__.py
+++ b/pipenv/patched/safety/__init__.py
@@ -2,4 +2,4 @@
 
 __author__ = """pyup.io"""
 __email__ = 'support@pyup.io'
-__version__ = '1.8.5'
+__version__ = '1.8.7'
diff --git a/pipenv/patched/safety/safety.py b/pipenv/patched/safety/safety.py
index 871bd775..2fca3eb2 100644
--- a/pipenv/patched/safety/safety.py
+++ b/pipenv/patched/safety/safety.py
@@ -137,7 +137,7 @@ def check(packages, key, db_mirror, cached, ignore_ids, proxy):
                 spec_set = SpecifierSet(specifiers=specifier)
                 if spec_set.contains(pkg.version):
                     if not db_full:
-                        db_full = fetch_database(full=True, key=key, db=db_mirror)
+                        db_full = fetch_database(full=True, key=key, db=db_mirror, cached=cached, proxy=proxy)
                     for data in get_vulnerabilities(pkg=name, spec=specifier, db=db_full):
                         vuln_id = data.get("id").replace("pyup.io-", "")
                         if vuln_id and vuln_id not in ignore_ids:
diff --git a/pipenv/vendor/click/LICENSE.rst b/pipenv/vendor/click/LICENSE.rst
index 87ce152a..d12a8491 100644
--- a/pipenv/vendor/click/LICENSE.rst
+++ b/pipenv/vendor/click/LICENSE.rst
@@ -1,39 +1,28 @@
-Copyright  2014 by the Pallets team.
+Copyright 2014 Pallets
 
-Some rights reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
 
-Redistribution and use in source and binary forms of the software as
-well as documentation, with or without modification, are permitted
-provided that the following conditions are met:
-
--   Redistributions of source code must retain the above copyright
+1.  Redistributions of source code must retain the above copyright
     notice, this list of conditions and the following disclaimer.
 
--   Redistributions in binary form must reproduce the above copyright
+2.  Redistributions in binary form must reproduce the above copyright
     notice, this list of conditions and the following disclaimer in the
     documentation and/or other materials provided with the distribution.
 
--   Neither the name of the copyright holder nor the names of its
+3.  Neither the name of the copyright holder nor the names of its
     contributors may be used to endorse or promote products derived from
     this software without specific prior written permission.
 
-THIS SOFTWARE AND DOCUMENTATION IS PROVIDED BY THE COPYRIGHT HOLDERS AND
-CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
-BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
-FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
-COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
-INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
-NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
-USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
-ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
-THIS SOFTWARE AND DOCUMENTATION, EVEN IF ADVISED OF THE POSSIBILITY OF
-SUCH DAMAGE.
-
-----
-
-Click uses parts of optparse written by Gregory P. Ward and maintained
-by the Python Software Foundation. This is limited to code in parser.py.
-
-Copyright  2001-2006 Gregory P. Ward. All rights reserved.
-Copyright  2002-2006 Python Software Foundation. All rights reserved.
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
+PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/pipenv/vendor/click/__init__.py b/pipenv/vendor/click/__init__.py
index d3c33660..3910b803 100644
--- a/pipenv/vendor/click/__init__.py
+++ b/pipenv/vendor/click/__init__.py
@@ -1,97 +1,79 @@
-# -*- coding: utf-8 -*-
 """
-click
-~~~~~
-
 Click is a simple Python module inspired by the stdlib optparse to make
 writing command line scripts fun. Unlike other modules, it's based
 around a simple API that does not come with too much magic and is
 composable.
-
-:copyright:  2014 by the Pallets team.
-:license: BSD, see LICENSE.rst for more details.
 """
-
-# Core classes
-from .core import Context, BaseCommand, Command, MultiCommand, Group, \
-     CommandCollection, Parameter, Option, Argument
-
-# Globals
+from .core import Argument
+from .core import BaseCommand
+from .core import Command
+from .core import CommandCollection
+from .core import Context
+from .core import Group
+from .core import MultiCommand
+from .core import Option
+from .core import Parameter
+from .decorators import argument
+from .decorators import command
+from .decorators import confirmation_option
+from .decorators import group
+from .decorators import help_option
+from .decorators import make_pass_decorator
+from .decorators import option
+from .decorators import pass_context
+from .decorators import pass_obj
+from .decorators import password_option
+from .decorators import version_option
+from .exceptions import Abort
+from .exceptions import BadArgumentUsage
+from .exceptions import BadOptionUsage
+from .exceptions import BadParameter
+from .exceptions import ClickException
+from .exceptions import FileError
+from .exceptions import MissingParameter
+from .exceptions import NoSuchOption
+from .exceptions import UsageError
+from .formatting import HelpFormatter
+from .formatting import wrap_text
 from .globals import get_current_context
-
-# Decorators
-from .decorators import pass_context, pass_obj, make_pass_decorator, \
-     command, group, argument, option, confirmation_option, \
-     password_option, version_option, help_option
-
-# Types
-from .types import ParamType, File, Path, Choice, IntRange, Tuple, \
-     DateTime, STRING, INT, FLOAT, BOOL, UUID, UNPROCESSED, FloatRange
-
-# Utilities
-from .utils import echo, get_binary_stream, get_text_stream, open_file, \
-     format_filename, get_app_dir, get_os_args
-
-# Terminal functions
-from .termui import prompt, confirm, get_terminal_size, echo_via_pager, \
-     progressbar, clear, style, unstyle, secho, edit, launch, getchar, \
-     pause
-
-# Exceptions
-from .exceptions import ClickException, UsageError, BadParameter, \
-     FileError, Abort, NoSuchOption, BadOptionUsage, BadArgumentUsage, \
-     MissingParameter
-
-# Formatting
-from .formatting import HelpFormatter, wrap_text
-
-# Parsing
 from .parser import OptionParser
-
-
-__all__ = [
-    # Core classes
-    'Context', 'BaseCommand', 'Command', 'MultiCommand', 'Group',
-    'CommandCollection', 'Parameter', 'Option', 'Argument',
-
-    # Globals
-    'get_current_context',
-
-    # Decorators
-    'pass_context', 'pass_obj', 'make_pass_decorator', 'command', 'group',
-    'argument', 'option', 'confirmation_option', 'password_option',
-    'version_option', 'help_option',
-
-    # Types
-    'ParamType', 'File', 'Path', 'Choice', 'IntRange', 'Tuple',
-    'DateTime', 'STRING', 'INT', 'FLOAT', 'BOOL', 'UUID', 'UNPROCESSED',
-    'FloatRange',
-
-    # Utilities
-    'echo', 'get_binary_stream', 'get_text_stream', 'open_file',
-    'format_filename', 'get_app_dir', 'get_os_args',
-
-    # Terminal functions
-    'prompt', 'confirm', 'get_terminal_size', 'echo_via_pager',
-    'progressbar', 'clear', 'style', 'unstyle', 'secho', 'edit', 'launch',
-    'getchar', 'pause',
-
-    # Exceptions
-    'ClickException', 'UsageError', 'BadParameter', 'FileError',
-    'Abort', 'NoSuchOption', 'BadOptionUsage', 'BadArgumentUsage',
-    'MissingParameter',
-
-    # Formatting
-    'HelpFormatter', 'wrap_text',
-
-    # Parsing
-    'OptionParser',
-]
-
+from .termui import clear
+from .termui import confirm
+from .termui import echo_via_pager
+from .termui import edit
+from .termui import get_terminal_size
+from .termui import getchar
+from .termui import launch
+from .termui import pause
+from .termui import progressbar
+from .termui import prompt
+from .termui import secho
+from .termui import style
+from .termui import unstyle
+from .types import BOOL
+from .types import Choice
+from .types import DateTime
+from .types import File
+from .types import FLOAT
+from .types import FloatRange
+from .types import INT
+from .types import IntRange
+from .types import ParamType
+from .types import Path
+from .types import STRING
+from .types import Tuple
+from .types import UNPROCESSED
+from .types import UUID
+from .utils import echo
+from .utils import format_filename
+from .utils import get_app_dir
+from .utils import get_binary_stream
+from .utils import get_os_args
+from .utils import get_text_stream
+from .utils import open_file
 
 # Controls if click should emit the warning about the use of unicode
 # literals.
 disable_unicode_literals_warning = False
 
-
-__version__ = '7.0'
+__version__ = "7.1.1"
diff --git a/pipenv/vendor/click/_bashcomplete.py b/pipenv/vendor/click/_bashcomplete.py
index a5f1084c..8bca2448 100644
--- a/pipenv/vendor/click/_bashcomplete.py
+++ b/pipenv/vendor/click/_bashcomplete.py
@@ -2,20 +2,22 @@ import copy
 import os
 import re
 
-from .utils import echo
+from .core import Argument
+from .core import MultiCommand
+from .core import Option
 from .parser import split_arg_string
-from .core import MultiCommand, Option, Argument
 from .types import Choice
+from .utils import echo
 
 try:
     from collections import abc
 except ImportError:
     import collections as abc
 
-WORDBREAK = '='
+WORDBREAK = "="
 
 # Note, only BASH version 4.4 and later have the nosort option.
-COMPLETION_SCRIPT_BASH = '''
+COMPLETION_SCRIPT_BASH = """
 %(complete_func)s() {
     local IFS=$'\n'
     COMPREPLY=( $( env COMP_WORDS="${COMP_WORDS[*]}" \\
@@ -28,7 +30,8 @@ COMPLETION_SCRIPT_BASH = '''
     local COMPLETION_OPTIONS=""
     local BASH_VERSION_ARR=(${BASH_VERSION//./ })
     # Only BASH version 4.4 and later have the nosort option.
-    if [ ${BASH_VERSION_ARR[0]} -gt 4 ] || ([ ${BASH_VERSION_ARR[0]} -eq 4 ] && [ ${BASH_VERSION_ARR[1]} -ge 4 ]); then
+    if [ ${BASH_VERSION_ARR[0]} -gt 4 ] || ([ ${BASH_VERSION_ARR[0]} -eq 4 ] \
+&& [ ${BASH_VERSION_ARR[1]} -ge 4 ]); then
         COMPLETION_OPTIONS="-o nosort"
     fi
 
@@ -36,13 +39,17 @@ COMPLETION_SCRIPT_BASH = '''
 }
 
 %(complete_func)setup
-'''
+"""
+
+COMPLETION_SCRIPT_ZSH = """
+#compdef %(script_names)s
 
-COMPLETION_SCRIPT_ZSH = '''
 %(complete_func)s() {
     local -a completions
     local -a completions_with_descriptions
     local -a response
+    (( ! $+commands[%(script_names)s] )) && return 1
+
     response=("${(@f)$( env COMP_WORDS=\"${words[*]}\" \\
                         COMP_CWORD=$((CURRENT-1)) \\
                         %(autocomplete_var)s=\"complete_zsh\" \\
@@ -57,34 +64,51 @@ COMPLETION_SCRIPT_ZSH = '''
     done
 
     if [ -n "$completions_with_descriptions" ]; then
-        _describe -V unsorted completions_with_descriptions -U -Q
+        _describe -V unsorted completions_with_descriptions -U
     fi
 
     if [ -n "$completions" ]; then
-        compadd -U -V unsorted -Q -a completions
+        compadd -U -V unsorted -a completions
     fi
     compstate[insert]="automenu"
 }
 
 compdef %(complete_func)s %(script_names)s
-'''
+"""
+
+COMPLETION_SCRIPT_FISH = (
+    "complete --no-files --command %(script_names)s --arguments"
+    ' "(env %(autocomplete_var)s=complete_fish'
+    " COMP_WORDS=(commandline -cp) COMP_CWORD=(commandline -t)"
+    ' %(script_names)s)"'
+)
+
+_completion_scripts = {
+    "bash": COMPLETION_SCRIPT_BASH,
+    "zsh": COMPLETION_SCRIPT_ZSH,
+    "fish": COMPLETION_SCRIPT_FISH,
+}
 
-_invalid_ident_char_re = re.compile(r'[^a-zA-Z0-9_]')
+_invalid_ident_char_re = re.compile(r"[^a-zA-Z0-9_]")
 
 
 def get_completion_script(prog_name, complete_var, shell):
-    cf_name = _invalid_ident_char_re.sub('', prog_name.replace('-', '_'))
-    script = COMPLETION_SCRIPT_ZSH if shell == 'zsh' else COMPLETION_SCRIPT_BASH
-    return (script % {
-        'complete_func': '_%s_completion' % cf_name,
-        'script_names': prog_name,
-        'autocomplete_var': complete_var,
-    }).strip() + ';'
+    cf_name = _invalid_ident_char_re.sub("", prog_name.replace("-", "_"))
+    script = _completion_scripts.get(shell, COMPLETION_SCRIPT_BASH)
+    return (
+        script
+        % {
+            "complete_func": "_{}_completion".format(cf_name),
+            "script_names": prog_name,
+            "autocomplete_var": complete_var,
+        }
+    ).strip() + ";"
 
 
 def resolve_ctx(cli, prog_name, args):
-    """
-    Parse into a hierarchy of contexts. Contexts are connected through the parent variable.
+    """Parse into a hierarchy of contexts. Contexts are connected
+    through the parent variable.
+
     :param cli: command definition
     :param prog_name: the program that is running
     :param args: full list of args
@@ -98,8 +122,9 @@ def resolve_ctx(cli, prog_name, args):
                 cmd_name, cmd, args = ctx.command.resolve_command(ctx, args)
                 if cmd is None:
                     return ctx
-                ctx = cmd.make_context(cmd_name, args, parent=ctx,
-                                       resilient_parsing=True)
+                ctx = cmd.make_context(
+                    cmd_name, args, parent=ctx, resilient_parsing=True
+                )
                 args = ctx.protected_args + ctx.args
             else:
                 # Walk chained subcommand contexts saving the last one.
@@ -107,10 +132,14 @@ def resolve_ctx(cli, prog_name, args):
                     cmd_name, cmd, args = ctx.command.resolve_command(ctx, args)
                     if cmd is None:
                         return ctx
-                    sub_ctx = cmd.make_context(cmd_name, args, parent=ctx,
-                                               allow_extra_args=True,
-                                               allow_interspersed_args=False,
-                                               resilient_parsing=True)
+                    sub_ctx = cmd.make_context(
+                        cmd_name,
+                        args,
+                        parent=ctx,
+                        allow_extra_args=True,
+                        allow_interspersed_args=False,
+                        resilient_parsing=True,
+                    )
                     args = sub_ctx.args
                 ctx = sub_ctx
                 args = sub_ctx.protected_args + sub_ctx.args
@@ -122,25 +151,29 @@ def resolve_ctx(cli, prog_name, args):
 def start_of_option(param_str):
     """
     :param param_str: param_str to check
-    :return: whether or not this is the start of an option declaration (i.e. starts "-" or "--")
+    :return: whether or not this is the start of an option declaration
+        (i.e. starts "-" or "--")
     """
-    return param_str and param_str[:1] == '-'
+    return param_str and param_str[:1] == "-"
 
 
 def is_incomplete_option(all_args, cmd_param):
     """
     :param all_args: the full original list of args supplied
     :param cmd_param: the current command paramter
-    :return: whether or not the last option declaration (i.e. starts "-" or "--") is incomplete and
-    corresponds to this cmd_param. In other words whether this cmd_param option can still accept
-    values
+    :return: whether or not the last option declaration (i.e. starts
+        "-" or "--") is incomplete and corresponds to this cmd_param. In
+        other words whether this cmd_param option can still accept
+        values
     """
     if not isinstance(cmd_param, Option):
         return False
     if cmd_param.is_flag:
         return False
     last_option = None
-    for index, arg_str in enumerate(reversed([arg for arg in all_args if arg != WORDBREAK])):
+    for index, arg_str in enumerate(
+        reversed([arg for arg in all_args if arg != WORDBREAK])
+    ):
         if index + 1 > cmd_param.nargs:
             break
         if start_of_option(arg_str):
@@ -151,10 +184,12 @@ def is_incomplete_option(all_args, cmd_param):
 
 def is_incomplete_argument(current_params, cmd_param):
     """
-    :param current_params: the current params and values for this argument as already entered
+    :param current_params: the current params and values for this
+        argument as already entered
     :param cmd_param: the current command parameter
-    :return: whether or not the last argument is incomplete and corresponds to this cmd_param. In
-    other words whether or not the this cmd_param argument can still accept values
+    :return: whether or not the last argument is incomplete and
+        corresponds to this cmd_param. In other words whether or not the
+        this cmd_param argument can still accept values
     """
     if not isinstance(cmd_param, Argument):
         return False
@@ -163,8 +198,11 @@ def is_incomplete_argument(current_params, cmd_param):
         return True
     if cmd_param.nargs == -1:
         return True
-    if isinstance(current_param_values, abc.Iterable) \
-            and cmd_param.nargs > 1 and len(current_param_values) < cmd_param.nargs:
+    if (
+        isinstance(current_param_values, abc.Iterable)
+        and cmd_param.nargs > 1
+        and len(current_param_values) < cmd_param.nargs
+    ):
         return True
     return False
 
@@ -180,14 +218,16 @@ def get_user_autocompletions(ctx, args, incomplete, cmd_param):
     results = []
     if isinstance(cmd_param.type, Choice):
         # Choices don't support descriptions.
-        results = [(c, None)
-                   for c in cmd_param.type.choices if str(c).startswith(incomplete)]
+        results = [
+            (c, None) for c in cmd_param.type.choices if str(c).startswith(incomplete)
+        ]
     elif cmd_param.autocompletion is not None:
-        dynamic_completions = cmd_param.autocompletion(ctx=ctx,
-                                                       args=args,
-                                                       incomplete=incomplete)
-        results = [c if isinstance(c, tuple) else (c, None)
-                   for c in dynamic_completions]
+        dynamic_completions = cmd_param.autocompletion(
+            ctx=ctx, args=args, incomplete=incomplete
+        )
+        results = [
+            c if isinstance(c, tuple) else (c, None) for c in dynamic_completions
+        ]
     return results
 
 
@@ -208,15 +248,25 @@ def add_subcommand_completions(ctx, incomplete, completions_out):
     # Add subcommand completions.
     if isinstance(ctx.command, MultiCommand):
         completions_out.extend(
-            [(c.name, c.get_short_help_str()) for c in get_visible_commands_starting_with(ctx, incomplete)])
-
-    # Walk up the context list and add any other completion possibilities from chained commands
+            [
+                (c.name, c.get_short_help_str())
+                for c in get_visible_commands_starting_with(ctx, incomplete)
+            ]
+        )
+
+    # Walk up the context list and add any other completion
+    # possibilities from chained commands
     while ctx.parent is not None:
         ctx = ctx.parent
         if isinstance(ctx.command, MultiCommand) and ctx.command.chain:
-            remaining_commands = [c for c in get_visible_commands_starting_with(ctx, incomplete)
-                                  if c.name not in ctx.protected_args]
-            completions_out.extend([(c.name, c.get_short_help_str()) for c in remaining_commands])
+            remaining_commands = [
+                c
+                for c in get_visible_commands_starting_with(ctx, incomplete)
+                if c.name not in ctx.protected_args
+            ]
+            completions_out.extend(
+                [(c.name, c.get_short_help_str()) for c in remaining_commands]
+            )
 
 
 def get_choices(cli, prog_name, args, incomplete):
@@ -233,23 +283,30 @@ def get_choices(cli, prog_name, args, incomplete):
     if ctx is None:
         return []
 
-    # In newer versions of bash long opts with '='s are partitioned, but it's easier to parse
-    # without the '='
+    has_double_dash = "--" in all_args
+
+    # In newer versions of bash long opts with '='s are partitioned, but
+    # it's easier to parse without the '='
     if start_of_option(incomplete) and WORDBREAK in incomplete:
         partition_incomplete = incomplete.partition(WORDBREAK)
         all_args.append(partition_incomplete[0])
         incomplete = partition_incomplete[2]
     elif incomplete == WORDBREAK:
-        incomplete = ''
+        incomplete = ""
 
     completions = []
-    if start_of_option(incomplete):
+    if not has_double_dash and start_of_option(incomplete):
         # completions for partial options
         for param in ctx.command.params:
             if isinstance(param, Option) and not param.hidden:
-                param_opts = [param_opt for param_opt in param.opts +
-                              param.secondary_opts if param_opt not in all_args or param.multiple]
-                completions.extend([(o, param.help) for o in param_opts if o.startswith(incomplete)])
+                param_opts = [
+                    param_opt
+                    for param_opt in param.opts + param.secondary_opts
+                    if param_opt not in all_args or param.multiple
+                ]
+                completions.extend(
+                    [(o, param.help) for o in param_opts if o.startswith(incomplete)]
+                )
         return completions
     # completion for option values from user supplied values
     for param in ctx.command.params:
@@ -266,28 +323,53 @@ def get_choices(cli, prog_name, args, incomplete):
 
 
 def do_complete(cli, prog_name, include_descriptions):
-    cwords = split_arg_string(os.environ['COMP_WORDS'])
-    cword = int(os.environ['COMP_CWORD'])
+    cwords = split_arg_string(os.environ["COMP_WORDS"])
+    cword = int(os.environ["COMP_CWORD"])
     args = cwords[1:cword]
     try:
         incomplete = cwords[cword]
     except IndexError:
-        incomplete = ''
+        incomplete = ""
 
     for item in get_choices(cli, prog_name, args, incomplete):
         echo(item[0])
         if include_descriptions:
-            # ZSH has trouble dealing with empty array parameters when returned from commands, so use a well defined character '_' to indicate no description is present.
-            echo(item[1] if item[1] else '_')
+            # ZSH has trouble dealing with empty array parameters when
+            # returned from commands, use '_' to indicate no description
+            # is present.
+            echo(item[1] if item[1] else "_")
+
+    return True
+
+
+def do_complete_fish(cli, prog_name):
+    cwords = split_arg_string(os.environ["COMP_WORDS"])
+    incomplete = os.environ["COMP_CWORD"]
+    args = cwords[1:]
+
+    for item in get_choices(cli, prog_name, args, incomplete):
+        if item[1]:
+            echo("{arg}\t{desc}".format(arg=item[0], desc=item[1]))
+        else:
+            echo(item[0])
 
     return True
 
 
 def bashcomplete(cli, prog_name, complete_var, complete_instr):
-    if complete_instr.startswith('source'):
-        shell = 'zsh' if complete_instr == 'source_zsh' else 'bash'
+    if "_" in complete_instr:
+        command, shell = complete_instr.split("_", 1)
+    else:
+        command = complete_instr
+        shell = "bash"
+
+    if command == "source":
         echo(get_completion_script(prog_name, complete_var, shell))
         return True
-    elif complete_instr == 'complete' or complete_instr == 'complete_zsh':
-        return do_complete(cli, prog_name, complete_instr == 'complete_zsh')
+    elif command == "complete":
+        if shell == "fish":
+            return do_complete_fish(cli, prog_name)
+        elif shell in {"bash", "zsh"}:
+            return do_complete(cli, prog_name, shell == "zsh")
+
     return False
diff --git a/pipenv/vendor/click/_compat.py b/pipenv/vendor/click/_compat.py
index 937e2301..ed57a18f 100644
--- a/pipenv/vendor/click/_compat.py
+++ b/pipenv/vendor/click/_compat.py
@@ -1,67 +1,80 @@
-import re
+# flake8: noqa
+import codecs
 import io
 import os
+import re
 import sys
-import codecs
 from weakref import WeakKeyDictionary
 
-
 PY2 = sys.version_info[0] == 2
-CYGWIN = sys.platform.startswith('cygwin')
+CYGWIN = sys.platform.startswith("cygwin")
+MSYS2 = sys.platform.startswith("win") and ("GCC" in sys.version)
 # Determine local App Engine environment, per Google's own suggestion
-APP_ENGINE = ('APPENGINE_RUNTIME' in os.environ and
-              'Development/' in os.environ['SERVER_SOFTWARE'])
-WIN = sys.platform.startswith('win') and not APP_ENGINE
+APP_ENGINE = "APPENGINE_RUNTIME" in os.environ and "Development/" in os.environ.get(
+    "SERVER_SOFTWARE", ""
+)
+WIN = sys.platform.startswith("win") and not APP_ENGINE and not MSYS2
 DEFAULT_COLUMNS = 80
 
 
-_ansi_re = re.compile(r'\033\[((?:\d|;)*)([a-zA-Z])')
+_ansi_re = re.compile(r"\033\[[;?0-9]*[a-zA-Z]")
 
 
 def get_filesystem_encoding():
     return sys.getfilesystemencoding() or sys.getdefaultencoding()
 
 
-def _make_text_stream(stream, encoding, errors,
-                      force_readable=False, force_writable=False):
+def _make_text_stream(
+    stream, encoding, errors, force_readable=False, force_writable=False
+):
     if encoding is None:
         encoding = get_best_encoding(stream)
     if errors is None:
-        errors = 'replace'
-    return _NonClosingTextIOWrapper(stream, encoding, errors,
-                                    line_buffering=True,
-                                    force_readable=force_readable,
-                                    force_writable=force_writable)
+        errors = "replace"
+    return _NonClosingTextIOWrapper(
+        stream,
+        encoding,
+        errors,
+        line_buffering=True,
+        force_readable=force_readable,
+        force_writable=force_writable,
+    )
 
 
 def is_ascii_encoding(encoding):
     """Checks if a given encoding is ascii."""
     try:
-        return codecs.lookup(encoding).name == 'ascii'
+        return codecs.lookup(encoding).name == "ascii"
     except LookupError:
         return False
 
 
 def get_best_encoding(stream):
     """Returns the default stream encoding if not found."""
-    rv = getattr(stream, 'encoding', None) or sys.getdefaultencoding()
+    rv = getattr(stream, "encoding", None) or sys.getdefaultencoding()
     if is_ascii_encoding(rv):
-        return 'utf-8'
+        return "utf-8"
     return rv
 
 
 class _NonClosingTextIOWrapper(io.TextIOWrapper):
-
-    def __init__(self, stream, encoding, errors,
-                 force_readable=False, force_writable=False, **extra):
-        self._stream = stream = _FixupStream(stream, force_readable,
-                                             force_writable)
+    def __init__(
+        self,
+        stream,
+        encoding,
+        errors,
+        force_readable=False,
+        force_writable=False,
+        **extra
+    ):
+        self._stream = stream = _FixupStream(stream, force_readable, force_writable)
         io.TextIOWrapper.__init__(self, stream, encoding, errors, **extra)
 
     # The io module is a place where the Python 3 text behavior
     # was forced upon Python 2, so we need to unbreak
     # it to look like Python 2.
     if PY2:
+
         def write(self, x):
             if isinstance(x, str) or is_bytes(x):
                 try:
@@ -105,7 +118,7 @@ class _FixupStream(object):
         return getattr(self._stream, name)
 
     def read1(self, size):
-        f = getattr(self._stream, 'read1', None)
+        f = getattr(self._stream, "read1", None)
         if f is not None:
             return f(size)
         # We only dispatch to readline instead of read in Python 2 as we
@@ -118,7 +131,7 @@ class _FixupStream(object):
     def readable(self):
         if self._force_readable:
             return True
-        x = getattr(self._stream, 'readable', None)
+        x = getattr(self._stream, "readable", None)
         if x is not None:
             return x()
         try:
@@ -130,20 +143,20 @@ class _FixupStream(object):
     def writable(self):
         if self._force_writable:
             return True
-        x = getattr(self._stream, 'writable', None)
+        x = getattr(self._stream, "writable", None)
         if x is not None:
             return x()
         try:
-            self._stream.write('')
+            self._stream.write("")
         except Exception:
             try:
-                self._stream.write(b'')
+                self._stream.write(b"")
             except Exception:
                 return False
         return True
 
     def seekable(self):
-        x = getattr(self._stream, 'seekable', None)
+        x = getattr(self._stream, "seekable", None)
         if x is not None:
             return x()
         try:
@@ -155,17 +168,18 @@ class _FixupStream(object):
 
 if PY2:
     text_type = unicode
-    bytes = str
     raw_input = raw_input
     string_types = (str, unicode)
     int_types = (int, long)
     iteritems = lambda x: x.iteritems()
     range_type = xrange
 
+    from pipes import quote as shlex_quote
+
     def is_bytes(x):
         return isinstance(x, (buffer, bytearray))
 
-    _identifier_re = re.compile(r'^[a-zA-Z_][a-zA-Z0-9_]*$')
+    _identifier_re = re.compile(r"^[a-zA-Z_][a-zA-Z0-9_]*$")
 
     # For Windows, we need to force stdout/stdin/stderr to binary if it's
     # fetched for that.  This obviously is not the most correct way to do
@@ -193,6 +207,7 @@ if PY2:
     except ImportError:
         pass
     else:
+
         def set_binary_mode(f):
             try:
                 fileno = f.fileno()
@@ -207,6 +222,7 @@ if PY2:
     except ImportError:
         pass
     else:
+
         def set_binary_mode(f):
             try:
                 fileno = f.fileno()
@@ -224,42 +240,42 @@ if PY2:
         return set_binary_mode(sys.stdin)
 
     def get_binary_stdout():
-        _wrap_std_stream('stdout')
+        _wrap_std_stream("stdout")
         return set_binary_mode(sys.stdout)
 
     def get_binary_stderr():
-        _wrap_std_stream('stderr')
+        _wrap_std_stream("stderr")
         return set_binary_mode(sys.stderr)
 
     def get_text_stdin(encoding=None, errors=None):
         rv = _get_windows_console_stream(sys.stdin, encoding, errors)
         if rv is not None:
             return rv
-        return _make_text_stream(sys.stdin, encoding, errors,
-                                 force_readable=True)
+        return _make_text_stream(sys.stdin, encoding, errors, force_readable=True)
 
     def get_text_stdout(encoding=None, errors=None):
-        _wrap_std_stream('stdout')
+        _wrap_std_stream("stdout")
         rv = _get_windows_console_stream(sys.stdout, encoding, errors)
         if rv is not None:
             return rv
-        return _make_text_stream(sys.stdout, encoding, errors,
-                                 force_writable=True)
+        return _make_text_stream(sys.stdout, encoding, errors, force_writable=True)
 
     def get_text_stderr(encoding=None, errors=None):
-        _wrap_std_stream('stderr')
+        _wrap_std_stream("stderr")
         rv = _get_windows_console_stream(sys.stderr, encoding, errors)
         if rv is not None:
             return rv
-        return _make_text_stream(sys.stderr, encoding, errors,
-                                 force_writable=True)
+        return _make_text_stream(sys.stderr, encoding, errors, force_writable=True)
 
     def filename_to_ui(value):
         if isinstance(value, bytes):
-            value = value.decode(get_filesystem_encoding(), 'replace')
+            value = value.decode(get_filesystem_encoding(), "replace")
         return value
+
+
 else:
     import io
+
     text_type = str
     raw_input = input
     string_types = (str,)
@@ -268,6 +284,8 @@ else:
     isidentifier = lambda x: x.isidentifier()
     iteritems = lambda x: iter(x.items())
 
+    from shlex import quote as shlex_quote
+
     def is_bytes(x):
         return isinstance(x, (bytes, memoryview, bytearray))
 
@@ -281,10 +299,10 @@ else:
 
     def _is_binary_writer(stream, default=False):
         try:
-            stream.write(b'')
+            stream.write(b"")
         except Exception:
             try:
-                stream.write('')
+                stream.write("")
                 return False
             except Exception:
                 pass
@@ -299,7 +317,7 @@ else:
         if _is_binary_reader(stream, False):
             return stream
 
-        buf = getattr(stream, 'buffer', None)
+        buf = getattr(stream, "buffer", None)
 
         # Same situation here; this time we assume that the buffer is
         # actually binary in case it's closed.
@@ -314,7 +332,7 @@ else:
         if _is_binary_writer(stream, False):
             return stream
 
-        buf = getattr(stream, 'buffer', None)
+        buf = getattr(stream, "buffer", None)
 
         # Same situation here; this time we assume that the buffer is
         # actually binary in case it's closed.
@@ -327,136 +345,142 @@ else:
         # to ASCII.  This appears to happen in certain unittest
         # environments.  It's not quite clear what the correct behavior is
         # but this at least will force Click to recover somehow.
-        return is_ascii_encoding(getattr(stream, 'encoding', None) or 'ascii')
+        return is_ascii_encoding(getattr(stream, "encoding", None) or "ascii")
 
-    def _is_compatible_text_stream(stream, encoding, errors):
-        stream_encoding = getattr(stream, 'encoding', None)
-        stream_errors = getattr(stream, 'errors', None)
+    def _is_compat_stream_attr(stream, attr, value):
+        """A stream attribute is compatible if it is equal to the
+        desired value or the desired value is unset and the attribute
+        has a value.
+        """
+        stream_value = getattr(stream, attr, None)
+        return stream_value == value or (value is None and stream_value is not None)
 
-        # Perfect match.
-        if stream_encoding == encoding and stream_errors == errors:
-            return True
-
-        # Otherwise, it's only a compatible stream if we did not ask for
-        # an encoding.
-        if encoding is None:
-            return stream_encoding is not None
-
-        return False
-
-    def _force_correct_text_reader(text_reader, encoding, errors,
-                                   force_readable=False):
-        if _is_binary_reader(text_reader, False):
-            binary_reader = text_reader
+    def _is_compatible_text_stream(stream, encoding, errors):
+        """Check if a stream's encoding and errors attributes are
+        compatible with the desired values.
+        """
+        return _is_compat_stream_attr(
+            stream, "encoding", encoding
+        ) and _is_compat_stream_attr(stream, "errors", errors)
+
+    def _force_correct_text_stream(
+        text_stream,
+        encoding,
+        errors,
+        is_binary,
+        find_binary,
+        force_readable=False,
+        force_writable=False,
+    ):
+        if is_binary(text_stream, False):
+            binary_reader = text_stream
         else:
-            # If there is no target encoding set, we need to verify that the
-            # reader is not actually misconfigured.
-            if encoding is None and not _stream_is_misconfigured(text_reader):
-                return text_reader
-
-            if _is_compatible_text_stream(text_reader, encoding, errors):
-                return text_reader
-
-            # If the reader has no encoding, we try to find the underlying
-            # binary reader for it.  If that fails because the environment is
-            # misconfigured, we silently go with the same reader because this
-            # is too common to happen.  In that case, mojibake is better than
-            # exceptions.
-            binary_reader = _find_binary_reader(text_reader)
+            # If the stream looks compatible, and won't default to a
+            # misconfigured ascii encoding, return it as-is.
+            if _is_compatible_text_stream(text_stream, encoding, errors) and not (
+                encoding is None and _stream_is_misconfigured(text_stream)
+            ):
+                return text_stream
+
+            # Otherwise, get the underlying binary reader.
+            binary_reader = find_binary(text_stream)
+
+            # If that's not possible, silently use the original reader
+            # and get mojibake instead of exceptions.
             if binary_reader is None:
-                return text_reader
+                return text_stream
 
-        # At this point, we default the errors to replace instead of strict
-        # because nobody handles those errors anyways and at this point
-        # we're so fundamentally fucked that nothing can repair it.
-        if errors is None:
-            errors = 'replace'
-        return _make_text_stream(binary_reader, encoding, errors,
-                                 force_readable=force_readable)
-
-    def _force_correct_text_writer(text_writer, encoding, errors,
-                                   force_writable=False):
-        if _is_binary_writer(text_writer, False):
-            binary_writer = text_writer
-        else:
-            # If there is no target encoding set, we need to verify that the
-            # writer is not actually misconfigured.
-            if encoding is None and not _stream_is_misconfigured(text_writer):
-                return text_writer
-
-            if _is_compatible_text_stream(text_writer, encoding, errors):
-                return text_writer
-
-            # If the writer has no encoding, we try to find the underlying
-            # binary writer for it.  If that fails because the environment is
-            # misconfigured, we silently go with the same writer because this
-            # is too common to happen.  In that case, mojibake is better than
-            # exceptions.
-            binary_writer = _find_binary_writer(text_writer)
-            if binary_writer is None:
-                return text_writer
-
-        # At this point, we default the errors to replace instead of strict
-        # because nobody handles those errors anyways and at this point
-        # we're so fundamentally fucked that nothing can repair it.
+        # Default errors to replace instead of strict in order to get
+        # something that works.
         if errors is None:
-            errors = 'replace'
-        return _make_text_stream(binary_writer, encoding, errors,
-                                 force_writable=force_writable)
+            errors = "replace"
+
+        # Wrap the binary stream in a text stream with the correct
+        # encoding parameters.
+        return _make_text_stream(
+            binary_reader,
+            encoding,
+            errors,
+            force_readable=force_readable,
+            force_writable=force_writable,
+        )
+
+    def _force_correct_text_reader(text_reader, encoding, errors, force_readable=False):
+        return _force_correct_text_stream(
+            text_reader,
+            encoding,
+            errors,
+            _is_binary_reader,
+            _find_binary_reader,
+            force_readable=force_readable,
+        )
+
+    def _force_correct_text_writer(text_writer, encoding, errors, force_writable=False):
+        return _force_correct_text_stream(
+            text_writer,
+            encoding,
+            errors,
+            _is_binary_writer,
+            _find_binary_writer,
+            force_writable=force_writable,
+        )
 
     def get_binary_stdin():
         reader = _find_binary_reader(sys.stdin)
         if reader is None:
-            raise RuntimeError('Was not able to determine binary '
-                               'stream for sys.stdin.')
+            raise RuntimeError("Was not able to determine binary stream for sys.stdin.")
         return reader
 
     def get_binary_stdout():
         writer = _find_binary_writer(sys.stdout)
         if writer is None:
-            raise RuntimeError('Was not able to determine binary '
-                               'stream for sys.stdout.')
+            raise RuntimeError(
+                "Was not able to determine binary stream for sys.stdout."
+            )
         return writer
 
     def get_binary_stderr():
         writer = _find_binary_writer(sys.stderr)
         if writer is None:
-            raise RuntimeError('Was not able to determine binary '
-                               'stream for sys.stderr.')
+            raise RuntimeError(
+                "Was not able to determine binary stream for sys.stderr."
+            )
         return writer
 
     def get_text_stdin(encoding=None, errors=None):
         rv = _get_windows_console_stream(sys.stdin, encoding, errors)
         if rv is not None:
             return rv
-        return _force_correct_text_reader(sys.stdin, encoding, errors,
-                                          force_readable=True)
+        return _force_correct_text_reader(
+            sys.stdin, encoding, errors, force_readable=True
+        )
 
     def get_text_stdout(encoding=None, errors=None):
         rv = _get_windows_console_stream(sys.stdout, encoding, errors)
         if rv is not None:
             return rv
-        return _force_correct_text_writer(sys.stdout, encoding, errors,
-                                          force_writable=True)
+        return _force_correct_text_writer(
+            sys.stdout, encoding, errors, force_writable=True
+        )
 
     def get_text_stderr(encoding=None, errors=None):
         rv = _get_windows_console_stream(sys.stderr, encoding, errors)
         if rv is not None:
             return rv
-        return _force_correct_text_writer(sys.stderr, encoding, errors,
-                                          force_writable=True)
+        return _force_correct_text_writer(
+            sys.stderr, encoding, errors, force_writable=True
+        )
 
     def filename_to_ui(value):
         if isinstance(value, bytes):
-            value = value.decode(get_filesystem_encoding(), 'replace')
+            value = value.decode(get_filesystem_encoding(), "replace")
         else:
-            value = value.encode('utf-8', 'surrogateescape') \
-                .decode('utf-8', 'replace')
+            value = value.encode("utf-8", "surrogateescape").decode("utf-8", "replace")
         return value
 
 
 def get_streerror(e, default=None):
-    if hasattr(e, 'strerror'):
+    if hasattr(e, "strerror"):
         msg = e.strerror
     else:
         if default is not None:
@@ -464,60 +488,107 @@ def get_streerror(e, default=None):
         else:
             msg = str(e)
     if isinstance(msg, bytes):
-        msg = msg.decode('utf-8', 'replace')
+        msg = msg.decode("utf-8", "replace")
     return msg
 
 
-def open_stream(filename, mode='r', encoding=None, errors='strict',
-                atomic=False):
+def _wrap_io_open(file, mode, encoding, errors):
+    """On Python 2, :func:`io.open` returns a text file wrapper that
+    requires passing ``unicode`` to ``write``. Need to open the file in
+    binary mode then wrap it in a subclass that can write ``str`` and
+    ``unicode``.
+
+    Also handles not passing ``encoding`` and ``errors`` in binary mode.
+    """
+    binary = "b" in mode
+
+    if binary:
+        kwargs = {}
+    else:
+        kwargs = {"encoding": encoding, "errors": errors}
+
+    if not PY2 or binary:
+        return io.open(file, mode, **kwargs)
+
+    f = io.open(file, "{}b".format(mode.replace("t", "")))
+    return _make_text_stream(f, **kwargs)
+
+
+def open_stream(filename, mode="r", encoding=None, errors="strict", atomic=False):
+    binary = "b" in mode
+
     # Standard streams first.  These are simple because they don't need
     # special handling for the atomic flag.  It's entirely ignored.
-    if filename == '-':
-        if any(m in mode for m in ['w', 'a', 'x']):
-            if 'b' in mode:
+    if filename == "-":
+        if any(m in mode for m in ["w", "a", "x"]):
+            if binary:
                 return get_binary_stdout(), False
             return get_text_stdout(encoding=encoding, errors=errors), False
-        if 'b' in mode:
+        if binary:
             return get_binary_stdin(), False
         return get_text_stdin(encoding=encoding, errors=errors), False
 
     # Non-atomic writes directly go out through the regular open functions.
     if not atomic:
-        if encoding is None:
-            return open(filename, mode), True
-        return io.open(filename, mode, encoding=encoding, errors=errors), True
+        return _wrap_io_open(filename, mode, encoding, errors), True
 
     # Some usability stuff for atomic writes
-    if 'a' in mode:
+    if "a" in mode:
         raise ValueError(
-            'Appending to an existing file is not supported, because that '
-            'would involve an expensive `copy`-operation to a temporary '
-            'file. Open the file in normal `w`-mode and copy explicitly '
-            'if that\'s what you\'re after.'
+            "Appending to an existing file is not supported, because that"
+            " would involve an expensive `copy`-operation to a temporary"
+            " file. Open the file in normal `w`-mode and copy explicitly"
+            " if that's what you're after."
         )
-    if 'x' in mode:
-        raise ValueError('Use the `overwrite`-parameter instead.')
-    if 'w' not in mode:
-        raise ValueError('Atomic writes only make sense with `w`-mode.')
+    if "x" in mode:
+        raise ValueError("Use the `overwrite`-parameter instead.")
+    if "w" not in mode:
+        raise ValueError("Atomic writes only make sense with `w`-mode.")
 
     # Atomic writes are more complicated.  They work by opening a file
     # as a proxy in the same folder and then using the fdopen
     # functionality to wrap it in a Python file.  Then we wrap it in an
     # atomic file that moves the file over on close.
-    import tempfile
-    fd, tmp_filename = tempfile.mkstemp(dir=os.path.dirname(filename),
-                                        prefix='.__atomic-write')
+    import errno
+    import random
 
-    if encoding is not None:
-        f = io.open(fd, mode, encoding=encoding, errors=errors)
-    else:
-        f = os.fdopen(fd, mode)
+    try:
+        perm = os.stat(filename).st_mode
+    except OSError:
+        perm = None
+
+    flags = os.O_RDWR | os.O_CREAT | os.O_EXCL
+
+    if binary:
+        flags |= getattr(os, "O_BINARY", 0)
 
+    while True:
+        tmp_filename = os.path.join(
+            os.path.dirname(filename),
+            ".__atomic-write{:08x}".format(random.randrange(1 << 32)),
+        )
+        try:
+            fd = os.open(tmp_filename, flags, 0o666 if perm is None else perm)
+            break
+        except OSError as e:
+            if e.errno == errno.EEXIST or (
+                os.name == "nt"
+                and e.errno == errno.EACCES
+                and os.path.isdir(e.filename)
+                and os.access(e.filename, os.W_OK)
+            ):
+                continue
+            raise
+
+    if perm is not None:
+        os.chmod(tmp_filename, perm)  # in case perm includes bits in umask
+
+    f = _wrap_io_open(fd, mode, encoding, errors)
     return _AtomicFile(f, tmp_filename, os.path.realpath(filename)), True
 
 
 # Used in a destructor call, needs extra protection from interpreter cleanup.
-if hasattr(os, 'replace'):
+if hasattr(os, "replace"):
     _replace = os.replace
     _can_replace = True
 else:
@@ -526,7 +597,6 @@ else:
 
 
 class _AtomicFile(object):
-
     def __init__(self, f, tmp_filename, real_filename):
         self._f = f
         self._tmp_filename = tmp_filename
@@ -568,14 +638,26 @@ get_winterm_size = None
 
 
 def strip_ansi(value):
-    return _ansi_re.sub('', value)
+    return _ansi_re.sub("", value)
+
+
+def _is_jupyter_kernel_output(stream):
+    if WIN:
+        # TODO: Couldn't test on Windows, should't try to support until
+        # someone tests the details wrt colorama.
+        return
+
+    while isinstance(stream, (_FixupStream, _NonClosingTextIOWrapper)):
+        stream = stream._stream
+
+    return stream.__class__.__module__.startswith("ipykernel.")
 
 
 def should_strip_ansi(stream=None, color=None):
     if color is None:
         if stream is None:
             stream = sys.stdin
-        return not isatty(stream)
+        return not isatty(stream) and not _is_jupyter_kernel_output(stream)
     return not color
 
 
@@ -590,16 +672,18 @@ if WIN:
 
     def _get_argv_encoding():
         import locale
+
         return locale.getpreferredencoding()
 
     if PY2:
-        def raw_input(prompt=''):
+
+        def raw_input(prompt=""):
             sys.stderr.flush()
             if prompt:
                 stdout = _default_text_stdout()
                 stdout.write(prompt)
             stdin = _default_text_stdin()
-            return stdin.readline().rstrip('\r\n')
+            return stdin.readline().rstrip("\r\n")
 
     try:
         import colorama
@@ -641,11 +725,15 @@ if WIN:
 
         def get_winterm_size():
             win = colorama.win32.GetConsoleScreenBufferInfo(
-                colorama.win32.STDOUT).srWindow
+                colorama.win32.STDOUT
+            ).srWindow
             return win.Right - win.Left, win.Bottom - win.Top
+
+
 else:
+
     def _get_argv_encoding():
-        return getattr(sys.stdin, 'encoding', None) or get_filesystem_encoding()
+        return getattr(sys.stdin, "encoding", None) or get_filesystem_encoding()
 
     _get_windows_console_stream = lambda *x: None
     _wrap_std_stream = lambda *x: None
@@ -664,6 +752,7 @@ def isatty(stream):
 
 def _make_cached_stream_func(src_func, wrapper_func):
     cache = WeakKeyDictionary()
+
     def func():
         stream = src_func()
         try:
@@ -679,25 +768,23 @@ def _make_cached_stream_func(src_func, wrapper_func):
         except Exception:
             pass
         return rv
+
     return func
 
 
-_default_text_stdin = _make_cached_stream_func(
-    lambda: sys.stdin, get_text_stdin)
-_default_text_stdout = _make_cached_stream_func(
-    lambda: sys.stdout, get_text_stdout)
-_default_text_stderr = _make_cached_stream_func(
-    lambda: sys.stderr, get_text_stderr)
+_default_text_stdin = _make_cached_stream_func(lambda: sys.stdin, get_text_stdin)
+_default_text_stdout = _make_cached_stream_func(lambda: sys.stdout, get_text_stdout)
+_default_text_stderr = _make_cached_stream_func(lambda: sys.stderr, get_text_stderr)
 
 
 binary_streams = {
-    'stdin': get_binary_stdin,
-    'stdout': get_binary_stdout,
-    'stderr': get_binary_stderr,
+    "stdin": get_binary_stdin,
+    "stdout": get_binary_stdout,
+    "stderr": get_binary_stderr,
 }
 
 text_streams = {
-    'stdin': get_text_stdin,
-    'stdout': get_text_stdout,
-    'stderr': get_text_stderr,
+    "stdin": get_text_stdin,
+    "stdout": get_text_stdout,
+    "stderr": get_text_stderr,
 }
diff --git a/pipenv/vendor/click/_termui_impl.py b/pipenv/vendor/click/_termui_impl.py
index 00a8e5ef..c6e86cc0 100644
--- a/pipenv/vendor/click/_termui_impl.py
+++ b/pipenv/vendor/click/_termui_impl.py
@@ -1,34 +1,35 @@
 # -*- coding: utf-8 -*-
 """
-click._termui_impl
-~~~~~~~~~~~~~~~~~~
-
 This module contains implementations for the termui module. To keep the
 import time of Click down, some infrequently used functionality is
 placed in this module and only imported as needed.
-
-:copyright:  2014 by the Pallets team.
-:license: BSD, see LICENSE.rst for more details.
 """
-
+import contextlib
+import math
 import os
 import sys
 import time
-import math
-import contextlib
-from ._compat import _default_text_stdout, range_type, PY2, isatty, \
-     open_stream, strip_ansi, term_len, get_best_encoding, WIN, int_types, \
-     CYGWIN
-from .utils import echo
-from .exceptions import ClickException
 
+from ._compat import _default_text_stdout
+from ._compat import CYGWIN
+from ._compat import get_best_encoding
+from ._compat import int_types
+from ._compat import isatty
+from ._compat import open_stream
+from ._compat import range_type
+from ._compat import shlex_quote
+from ._compat import strip_ansi
+from ._compat import term_len
+from ._compat import WIN
+from .exceptions import ClickException
+from .utils import echo
 
-if os.name == 'nt':
-    BEFORE_BAR = '\r'
-    AFTER_BAR = '\n'
+if os.name == "nt":
+    BEFORE_BAR = "\r"
+    AFTER_BAR = "\n"
 else:
-    BEFORE_BAR = '\r\033[?25l'
-    AFTER_BAR = '\033[?25h\n'
+    BEFORE_BAR = "\r\033[?25l"
+    AFTER_BAR = "\033[?25h\n"
 
 
 def _length_hint(obj):
@@ -44,19 +45,29 @@ def _length_hint(obj):
             hint = get_hint(obj)
         except TypeError:
             return None
-        if hint is NotImplemented or \
-           not isinstance(hint, int_types) or \
-           hint < 0:
+        if hint is NotImplemented or not isinstance(hint, int_types) or hint < 0:
             return None
         return hint
 
 
 class ProgressBar(object):
-
-    def __init__(self, iterable, length=None, fill_char='#', empty_char=' ',
-                 bar_template='%(bar)s', info_sep='  ', show_eta=True,
-                 show_percent=None, show_pos=False, item_show_func=None,
-                 label=None, file=None, color=None, width=30):
+    def __init__(
+        self,
+        iterable,
+        length=None,
+        fill_char="#",
+        empty_char=" ",
+        bar_template="%(bar)s",
+        info_sep="  ",
+        show_eta=True,
+        show_percent=None,
+        show_pos=False,
+        item_show_func=None,
+        label=None,
+        file=None,
+        color=None,
+        width=30,
+    ):
         self.fill_char = fill_char
         self.empty_char = empty_char
         self.bar_template = bar_template
@@ -65,7 +76,7 @@ class ProgressBar(object):
         self.show_percent = show_percent
         self.show_pos = show_pos
         self.item_show_func = item_show_func
-        self.label = label or ''
+        self.label = label or ""
         if file is None:
             file = _default_text_stdout()
         self.file = file
@@ -77,7 +88,7 @@ class ProgressBar(object):
             length = _length_hint(iterable)
         if iterable is None:
             if length is None:
-                raise TypeError('iterable or length is required')
+                raise TypeError("iterable or length is required")
             iterable = range_type(length)
         self.iter = iter(iterable)
         self.length = length
@@ -104,10 +115,21 @@ class ProgressBar(object):
 
     def __iter__(self):
         if not self.entered:
-            raise RuntimeError('You need to use progress bars in a with block.')
+            raise RuntimeError("You need to use progress bars in a with block.")
         self.render_progress()
         return self.generator()
 
+    def __next__(self):
+        # Iteration is defined in terms of a generator function,
+        # returned by iter(self); use that to define next(). This works
+        # because `self.iter` is an iterable consumed by that generator,
+        # so it is re-entry safe. Calling `next(self.generator())`
+        # twice works and does "what you want".
+        return next(iter(self))
+
+    # Python 2 compat
+    next = __next__
+
     def is_fast(self):
         return time.time() - self.start <= self.short_limit
 
@@ -145,20 +167,19 @@ class ProgressBar(object):
             hours = t % 24
             t //= 24
             if t > 0:
-                days = t
-                return '%dd %02d:%02d:%02d' % (days, hours, minutes, seconds)
+                return "{}d {:02}:{:02}:{:02}".format(t, hours, minutes, seconds)
             else:
-                return '%02d:%02d:%02d' % (hours, minutes, seconds)
-        return ''
+                return "{:02}:{:02}:{:02}".format(hours, minutes, seconds)
+        return ""
 
     def format_pos(self):
         pos = str(self.pos)
         if self.length_known:
-            pos += '/%s' % self.length
+            pos += "/{}".format(self.length)
         return pos
 
     def format_pct(self):
-        return ('% 4d%%' % int(self.pct * 100))[1:]
+        return "{: 4}%".format(int(self.pct * 100))[1:]
 
     def format_bar(self):
         if self.length_known:
@@ -170,9 +191,13 @@ class ProgressBar(object):
         else:
             bar = list(self.empty_char * (self.width or 1))
             if self.time_per_iteration != 0:
-                bar[int((math.cos(self.pos * self.time_per_iteration)
-                    / 2.0 + 0.5) * self.width)] = self.fill_char
-            bar = ''.join(bar)
+                bar[
+                    int(
+                        (math.cos(self.pos * self.time_per_iteration) / 2.0 + 0.5)
+                        * self.width
+                    )
+                ] = self.fill_char
+            bar = "".join(bar)
         return bar
 
     def format_progress_line(self):
@@ -193,11 +218,14 @@ class ProgressBar(object):
             if item_info is not None:
                 info_bits.append(item_info)
 
-        return (self.bar_template % {
-            'label': self.label,
-            'bar': self.format_bar(),
-            'info': self.info_sep.join(info_bits)
-        }).rstrip()
+        return (
+            self.bar_template
+            % {
+                "label": self.label,
+                "bar": self.format_bar(),
+                "info": self.info_sep.join(info_bits),
+            }
+        ).rstrip()
 
     def render_progress(self):
         from .termui import get_terminal_size
@@ -214,7 +242,7 @@ class ProgressBar(object):
             new_width = max(0, get_terminal_size()[0] - clutter_length)
             if new_width < old_width:
                 buf.append(BEFORE_BAR)
-                buf.append(' ' * self.max_width)
+                buf.append(" " * self.max_width)
                 self.max_width = new_width
             self.width = new_width
 
@@ -229,8 +257,8 @@ class ProgressBar(object):
             self.max_width = line_len
 
         buf.append(line)
-        buf.append(' ' * (clear_width - line_len))
-        line = ''.join(buf)
+        buf.append(" " * (clear_width - line_len))
+        line = "".join(buf)
         # Render the line only if it changed.
 
         if line != self._last_line and not self.is_fast():
@@ -270,13 +298,19 @@ class ProgressBar(object):
         self.finished = True
 
     def generator(self):
+        """Return a generator which yields the items added to the bar
+        during construction, and updates the progress bar *after* the
+        yielded block returns.
         """
-        Returns a generator which yields the items added to the bar during
-        construction, and updates the progress bar *after* the yielded block
-        returns.
-        """
+        # WARNING: the iterator interface for `ProgressBar` relies on
+        # this and only works because this is a simple generator which
+        # doesn't create or manage additional state. If this function
+        # changes, the impact should be evaluated both against
+        # `iter(bar)` and `next(bar)`. `next()` in particular may call
+        # `self.generator()` repeatedly, and this must remain safe in
+        # order for that interface to work.
         if not self.entered:
-            raise RuntimeError('You need to use progress bars in a with block.')
+            raise RuntimeError("You need to use progress bars in a with block.")
 
         if self.is_hidden:
             for rv in self.iter:
@@ -295,24 +329,28 @@ def pager(generator, color=None):
     stdout = _default_text_stdout()
     if not isatty(sys.stdin) or not isatty(stdout):
         return _nullpager(stdout, generator, color)
-    pager_cmd = (os.environ.get('PAGER', None) or '').strip()
+    pager_cmd = (os.environ.get("PAGER", None) or "").strip()
     if pager_cmd:
         if WIN:
             return _tempfilepager(generator, pager_cmd, color)
         return _pipepager(generator, pager_cmd, color)
-    if os.environ.get('TERM') in ('dumb', 'emacs'):
+    if os.environ.get("TERM") in ("dumb", "emacs"):
         return _nullpager(stdout, generator, color)
-    if WIN or sys.platform.startswith('os2'):
-        return _tempfilepager(generator, 'more <', color)
-    if hasattr(os, 'system') and os.system('(less) 2>/dev/null') == 0:
-        return _pipepager(generator, 'less', color)
+    if WIN or sys.platform.startswith("os2"):
+        return _tempfilepager(generator, "more <", color)
+    if hasattr(os, "system") and os.system("(less) 2>/dev/null") == 0:
+        return _pipepager(generator, "less", color)
 
     import tempfile
+
     fd, filename = tempfile.mkstemp()
     os.close(fd)
     try:
-        if hasattr(os, 'system') and os.system('more "%s"' % filename) == 0:
-            return _pipepager(generator, 'more', color)
+        if (
+            hasattr(os, "system")
+            and os.system("more {}".format(shlex_quote(filename))) == 0
+        ):
+            return _pipepager(generator, "more", color)
         return _nullpager(stdout, generator, color)
     finally:
         os.unlink(filename)
@@ -323,28 +361,28 @@ def _pipepager(generator, cmd, color):
     pager through this might support colors.
     """
     import subprocess
+
     env = dict(os.environ)
 
     # If we're piping to less we might support colors under the
     # condition that
-    cmd_detail = cmd.rsplit('/', 1)[-1].split()
-    if color is None and cmd_detail[0] == 'less':
-        less_flags = os.environ.get('LESS', '') + ' '.join(cmd_detail[1:])
+    cmd_detail = cmd.rsplit("/", 1)[-1].split()
+    if color is None and cmd_detail[0] == "less":
+        less_flags = "{}{}".format(os.environ.get("LESS", ""), " ".join(cmd_detail[1:]))
         if not less_flags:
-            env['LESS'] = '-R'
+            env["LESS"] = "-R"
             color = True
-        elif 'r' in less_flags or 'R' in less_flags:
+        elif "r" in less_flags or "R" in less_flags:
             color = True
 
-    c = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE,
-                         env=env)
+    c = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, env=env)
     encoding = get_best_encoding(c.stdin)
     try:
         for text in generator:
             if not color:
                 text = strip_ansi(text)
 
-            c.stdin.write(text.encode(encoding, 'replace'))
+            c.stdin.write(text.encode(encoding, "replace"))
     except (IOError, KeyboardInterrupt):
         pass
     else:
@@ -370,16 +408,17 @@ def _pipepager(generator, cmd, color):
 def _tempfilepager(generator, cmd, color):
     """Page through text by invoking a program on a temporary file."""
     import tempfile
+
     filename = tempfile.mktemp()
     # TODO: This never terminates if the passed generator never terminates.
     text = "".join(generator)
     if not color:
         text = strip_ansi(text)
     encoding = get_best_encoding(sys.stdout)
-    with open_stream(filename, 'wb')[0] as f:
+    with open_stream(filename, "wb")[0] as f:
         f.write(text.encode(encoding))
     try:
-        os.system(cmd + ' "' + filename + '"')
+        os.system("{} {}".format(shlex_quote(cmd), shlex_quote(filename)))
     finally:
         os.unlink(filename)
 
@@ -393,9 +432,7 @@ def _nullpager(stream, generator, color):
 
 
 class Editor(object):
-
-    def __init__(self, editor=None, env=None, require_save=True,
-                 extension='.txt'):
+    def __init__(self, editor=None, env=None, require_save=True, extension=".txt"):
         self.editor = editor
         self.env = env
         self.require_save = require_save
@@ -404,19 +441,20 @@ class Editor(object):
     def get_editor(self):
         if self.editor is not None:
             return self.editor
-        for key in 'VISUAL', 'EDITOR':
+        for key in "VISUAL", "EDITOR":
             rv = os.environ.get(key)
             if rv:
                 return rv
         if WIN:
-            return 'notepad'
-        for editor in 'vim', 'nano':
-            if os.system('which %s >/dev/null 2>&1' % editor) == 0:
+            return "notepad"
+        for editor in "sensible-editor", "vim", "nano":
+            if os.system("which {} >/dev/null 2>&1".format(editor)) == 0:
                 return editor
-        return 'vi'
+        return "vi"
 
     def edit_file(self, filename):
         import subprocess
+
         editor = self.get_editor()
         if self.env:
             environ = os.environ.copy()
@@ -424,47 +462,49 @@ class Editor(object):
         else:
             environ = None
         try:
-            c = subprocess.Popen('%s "%s"' % (editor, filename),
-                                 env=environ, shell=True)
+            c = subprocess.Popen(
+                "{} {}".format(shlex_quote(editor), shlex_quote(filename)),
+                env=environ,
+                shell=True,
+            )
             exit_code = c.wait()
             if exit_code != 0:
-                raise ClickException('%s: Editing failed!' % editor)
+                raise ClickException("{}: Editing failed!".format(editor))
         except OSError as e:
-            raise ClickException('%s: Editing failed: %s' % (editor, e))
+            raise ClickException("{}: Editing failed: {}".format(editor, e))
 
     def edit(self, text):
         import tempfile
 
-        text = text or ''
-        if text and not text.endswith('\n'):
-            text += '\n'
+        text = text or ""
+        if text and not text.endswith("\n"):
+            text += "\n"
 
-        fd, name = tempfile.mkstemp(prefix='editor-', suffix=self.extension)
+        fd, name = tempfile.mkstemp(prefix="editor-", suffix=self.extension)
         try:
             if WIN:
-                encoding = 'utf-8-sig'
-                text = text.replace('\n', '\r\n')
+                encoding = "utf-8-sig"
+                text = text.replace("\n", "\r\n")
             else:
-                encoding = 'utf-8'
+                encoding = "utf-8"
             text = text.encode(encoding)
 
-            f = os.fdopen(fd, 'wb')
+            f = os.fdopen(fd, "wb")
             f.write(text)
             f.close()
             timestamp = os.path.getmtime(name)
 
             self.edit_file(name)
 
-            if self.require_save \
-               and os.path.getmtime(name) == timestamp:
+            if self.require_save and os.path.getmtime(name) == timestamp:
                 return None
 
-            f = open(name, 'rb')
+            f = open(name, "rb")
             try:
                 rv = f.read()
             finally:
                 f.close()
-            return rv.decode('utf-8-sig').replace('\r\n', '\n')
+            return rv.decode("utf-8-sig").replace("\r\n", "\n")
         finally:
             os.unlink(name)
 
@@ -477,18 +517,18 @@ def open_url(url, wait=False, locate=False):
             import urllib
         except ImportError:
             import urllib
-        if url.startswith('file://'):
+        if url.startswith("file://"):
             url = urllib.unquote(url[7:])
         return url
 
-    if sys.platform == 'darwin':
-        args = ['open']
+    if sys.platform == "darwin":
+        args = ["open"]
         if wait:
-            args.append('-W')
+            args.append("-W")
         if locate:
-            args.append('-R')
+            args.append("-R")
         args.append(_unquote_file(url))
-        null = open('/dev/null', 'w')
+        null = open("/dev/null", "w")
         try:
             return subprocess.Popen(args, stderr=null).wait()
         finally:
@@ -496,44 +536,42 @@ def open_url(url, wait=False, locate=False):
     elif WIN:
         if locate:
             url = _unquote_file(url)
-            args = 'explorer /select,"%s"' % _unquote_file(
-                url.replace('"', ''))
+            args = "explorer /select,{}".format(shlex_quote(url))
         else:
-            args = 'start %s "" "%s"' % (
-                wait and '/WAIT' or '', url.replace('"', ''))
+            args = 'start {} "" {}'.format("/WAIT" if wait else "", shlex_quote(url))
         return os.system(args)
     elif CYGWIN:
         if locate:
             url = _unquote_file(url)
-            args = 'cygstart "%s"' % (os.path.dirname(url).replace('"', ''))
+            args = "cygstart {}".format(shlex_quote(os.path.dirname(url)))
         else:
-            args = 'cygstart %s "%s"' % (
-                wait and '-w' or '', url.replace('"', ''))
+            args = "cygstart {} {}".format("-w" if wait else "", shlex_quote(url))
         return os.system(args)
 
     try:
         if locate:
-            url = os.path.dirname(_unquote_file(url)) or '.'
+            url = os.path.dirname(_unquote_file(url)) or "."
         else:
             url = _unquote_file(url)
-        c = subprocess.Popen(['xdg-open', url])
+        c = subprocess.Popen(["xdg-open", url])
         if wait:
             return c.wait()
         return 0
     except OSError:
-        if url.startswith(('http://', 'https://')) and not locate and not wait:
+        if url.startswith(("http://", "https://")) and not locate and not wait:
             import webbrowser
+
             webbrowser.open(url)
             return 0
         return 1
 
 
 def _translate_ch_to_exc(ch):
-    if ch == u'\x03':
+    if ch == u"\x03":
         raise KeyboardInterrupt()
-    if ch == u'\x04' and not WIN:  # Unix-like, Ctrl+D
+    if ch == u"\x04" and not WIN:  # Unix-like, Ctrl+D
         raise EOFError()
-    if ch == u'\x1a' and WIN:      # Windows, Ctrl+Z
+    if ch == u"\x1a" and WIN:  # Windows, Ctrl+Z
         raise EOFError()
 
 
@@ -580,12 +618,14 @@ if WIN:
             func = msvcrt.getwch
 
         rv = func()
-        if rv in (u'\x00', u'\xe0'):
+        if rv in (u"\x00", u"\xe0"):
             # \x00 and \xe0 are control characters that indicate special key,
             # see above.
             rv += func()
         _translate_ch_to_exc(rv)
         return rv
+
+
 else:
     import tty
     import termios
@@ -593,7 +633,7 @@ else:
     @contextlib.contextmanager
     def raw_terminal():
         if not isatty(sys.stdin):
-            f = open('/dev/tty')
+            f = open("/dev/tty")
             fd = f.fileno()
         else:
             fd = sys.stdin.fileno()
@@ -614,7 +654,7 @@ else:
     def getchar(echo):
         with raw_terminal() as fd:
             ch = os.read(fd, 32)
-            ch = ch.decode(get_best_encoding(sys.stdin), 'replace')
+            ch = ch.decode(get_best_encoding(sys.stdin), "replace")
             if echo and isatty(sys.stdout):
                 sys.stdout.write(ch)
             _translate_ch_to_exc(ch)
diff --git a/pipenv/vendor/click/_textwrap.py b/pipenv/vendor/click/_textwrap.py
index 7e776031..6959087b 100644
--- a/pipenv/vendor/click/_textwrap.py
+++ b/pipenv/vendor/click/_textwrap.py
@@ -3,7 +3,6 @@ from contextlib import contextmanager
 
 
 class TextWrapper(textwrap.TextWrapper):
-
     def _handle_long_word(self, reversed_chunks, cur_line, cur_len, width):
         space_left = max(width - cur_len, 1)
 
@@ -35,4 +34,4 @@ class TextWrapper(textwrap.TextWrapper):
             if idx > 0:
                 indent = self.subsequent_indent
             rv.append(indent + line)
-        return '\n'.join(rv)
+        return "\n".join(rv)
diff --git a/pipenv/vendor/click/_unicodefun.py b/pipenv/vendor/click/_unicodefun.py
index 620edff3..781c3652 100644
--- a/pipenv/vendor/click/_unicodefun.py
+++ b/pipenv/vendor/click/_unicodefun.py
@@ -1,25 +1,19 @@
+import codecs
 import os
 import sys
-import codecs
 
 from ._compat import PY2
 
 
-# If someone wants to vendor click, we want to ensure the
-# correct package is discovered.  Ideally we could use a
-# relative import here but unfortunately Python does not
-# support that.
-click = sys.modules[__name__.rsplit('.', 1)[0]]
-
-
 def _find_unicode_literals_frame():
     import __future__
-    if not hasattr(sys, '_getframe'):  # not all Python implementations have it
+
+    if not hasattr(sys, "_getframe"):  # not all Python implementations have it
         return 0
     frm = sys._getframe(1)
     idx = 1
     while frm is not None:
-        if frm.f_globals.get('__name__', '').startswith('click.'):
+        if frm.f_globals.get("__name__", "").startswith("click."):
             frm = frm.f_back
             idx += 1
         elif frm.f_code.co_flags & __future__.unicode_literals.compiler_flag:
@@ -32,19 +26,27 @@ def _find_unicode_literals_frame():
 def _check_for_unicode_literals():
     if not __debug__:
         return
-    if not PY2 or click.disable_unicode_literals_warning:
+
+    from . import disable_unicode_literals_warning
+
+    if not PY2 or disable_unicode_literals_warning:
         return
     bad_frame = _find_unicode_literals_frame()
     if bad_frame <= 0:
         return
     from warnings import warn
-    warn(Warning('Click detected the use of the unicode_literals '
-                 '__future__ import.  This is heavily discouraged '
-                 'because it can introduce subtle bugs in your '
-                 'code.  You should instead use explicit u"" literals '
-                 'for your unicode strings.  For more information see '
-                 'https://click.palletsprojects.com/python3/'),
-         stacklevel=bad_frame)
+
+    warn(
+        Warning(
+            "Click detected the use of the unicode_literals __future__"
+            " import. This is heavily discouraged because it can"
+            " introduce subtle bugs in your code. You should instead"
+            ' use explicit u"" literals for your unicode strings. For'
+            " more information see"
+            " https://click.palletsprojects.com/python3/"
+        ),
+        stacklevel=bad_frame,
+    )
 
 
 def _verify_python3_env():
@@ -53,73 +55,77 @@ def _verify_python3_env():
         return
     try:
         import locale
+
         fs_enc = codecs.lookup(locale.getpreferredencoding()).name
     except Exception:
-        fs_enc = 'ascii'
-    if fs_enc != 'ascii':
+        fs_enc = "ascii"
+    if fs_enc != "ascii":
         return
 
-    extra = ''
-    if os.name == 'posix':
+    extra = ""
+    if os.name == "posix":
         import subprocess
+
         try:
-            rv = subprocess.Popen(['locale', '-a'], stdout=subprocess.PIPE,
-                                  stderr=subprocess.PIPE).communicate()[0]
+            rv = subprocess.Popen(
+                ["locale", "-a"], stdout=subprocess.PIPE, stderr=subprocess.PIPE
+            ).communicate()[0]
         except OSError:
-            rv = b''
+            rv = b""
         good_locales = set()
         has_c_utf8 = False
 
         # Make sure we're operating on text here.
         if isinstance(rv, bytes):
-            rv = rv.decode('ascii', 'replace')
+            rv = rv.decode("ascii", "replace")
 
         for line in rv.splitlines():
             locale = line.strip()
-            if locale.lower().endswith(('.utf-8', '.utf8')):
+            if locale.lower().endswith((".utf-8", ".utf8")):
                 good_locales.add(locale)
-                if locale.lower() in ('c.utf8', 'c.utf-8'):
+                if locale.lower() in ("c.utf8", "c.utf-8"):
                     has_c_utf8 = True
 
-        extra += '\n\n'
+        extra += "\n\n"
         if not good_locales:
             extra += (
-                'Additional information: on this system no suitable UTF-8\n'
-                'locales were discovered.  This most likely requires resolving\n'
-                'by reconfiguring the locale system.'
+                "Additional information: on this system no suitable"
+                " UTF-8 locales were discovered. This most likely"
+                " requires resolving by reconfiguring the locale"
+                " system."
             )
         elif has_c_utf8:
             extra += (
-                'This system supports the C.UTF-8 locale which is recommended.\n'
-                'You might be able to resolve your issue by exporting the\n'
-                'following environment variables:\n\n'
-                '    export LC_ALL=C.UTF-8\n'
-                '    export LANG=C.UTF-8'
+                "This system supports the C.UTF-8 locale which is"
+                " recommended. You might be able to resolve your issue"
+                " by exporting the following environment variables:\n\n"
+                "    export LC_ALL=C.UTF-8\n"
+                "    export LANG=C.UTF-8"
             )
         else:
             extra += (
-                'This system lists a couple of UTF-8 supporting locales that\n'
-                'you can pick from.  The following suitable locales were\n'
-                'discovered: %s'
-            ) % ', '.join(sorted(good_locales))
+                "This system lists a couple of UTF-8 supporting locales"
+                " that you can pick from. The following suitable"
+                " locales were discovered: {}".format(", ".join(sorted(good_locales)))
+            )
 
         bad_locale = None
-        for locale in os.environ.get('LC_ALL'), os.environ.get('LANG'):
-            if locale and locale.lower().endswith(('.utf-8', '.utf8')):
+        for locale in os.environ.get("LC_ALL"), os.environ.get("LANG"):
+            if locale and locale.lower().endswith((".utf-8", ".utf8")):
                 bad_locale = locale
             if locale is not None:
                 break
         if bad_locale is not None:
             extra += (
-                '\n\nClick discovered that you exported a UTF-8 locale\n'
-                'but the locale system could not pick up from it because\n'
-                'it does not exist.  The exported locale is "%s" but it\n'
-                'is not supported'
-            ) % bad_locale
+                "\n\nClick discovered that you exported a UTF-8 locale"
+                " but the locale system could not pick up from it"
+                " because it does not exist. The exported locale is"
+                " '{}' but it is not supported".format(bad_locale)
+            )
 
     raise RuntimeError(
-        'Click will abort further execution because Python 3 was'
-        ' configured to use ASCII as encoding for the environment.'
-        ' Consult https://click.palletsprojects.com/en/7.x/python3/ for'
-        ' mitigation steps.' + extra
+        "Click will abort further execution because Python 3 was"
+        " configured to use ASCII as encoding for the environment."
+        " Consult https://click.palletsprojects.com/python3/ for"
+        " mitigation steps.{}".format(extra)
     )
diff --git a/pipenv/vendor/click/_winconsole.py b/pipenv/vendor/click/_winconsole.py
index bbb080dd..b6c4274a 100644
--- a/pipenv/vendor/click/_winconsole.py
+++ b/pipenv/vendor/click/_winconsole.py
@@ -7,24 +7,42 @@
 # compared to the original patches as we do not need to patch
 # the entire interpreter but just work in our little world of
 # echo and prmopt.
-
+import ctypes
 import io
 import os
 import sys
-import zlib
 import time
-import ctypes
+import zlib
+from ctypes import byref
+from ctypes import c_char
+from ctypes import c_char_p
+from ctypes import c_int
+from ctypes import c_ssize_t
+from ctypes import c_ulong
+from ctypes import c_void_p
+from ctypes import POINTER
+from ctypes import py_object
+from ctypes import windll
+from ctypes import WinError
+from ctypes import WINFUNCTYPE
+from ctypes.wintypes import DWORD
+from ctypes.wintypes import HANDLE
+from ctypes.wintypes import LPCWSTR
+from ctypes.wintypes import LPWSTR
+
 import msvcrt
-from ._compat import _NonClosingTextIOWrapper, text_type, PY2
-from ctypes import byref, POINTER, c_int, c_char, c_char_p, \
-     c_void_p, py_object, c_ssize_t, c_ulong, windll, WINFUNCTYPE
+
+from ._compat import _NonClosingTextIOWrapper
+from ._compat import PY2
+from ._compat import text_type
+
 try:
     from ctypes import pythonapi
+
     PyObject_GetBuffer = pythonapi.PyObject_GetBuffer
     PyBuffer_Release = pythonapi.PyBuffer_Release
 except ImportError:
     pythonapi = None
-from ctypes.wintypes import LPWSTR, LPCWSTR
 
 
 c_ssize_p = POINTER(c_ssize_t)
@@ -33,12 +51,15 @@ kernel32 = windll.kernel32
 GetStdHandle = kernel32.GetStdHandle
 ReadConsoleW = kernel32.ReadConsoleW
 WriteConsoleW = kernel32.WriteConsoleW
+GetConsoleMode = kernel32.GetConsoleMode
 GetLastError = kernel32.GetLastError
-GetCommandLineW = WINFUNCTYPE(LPWSTR)(
-    ('GetCommandLineW', windll.kernel32))
-CommandLineToArgvW = WINFUNCTYPE(
-    POINTER(LPWSTR), LPCWSTR, POINTER(c_int))(
-        ('CommandLineToArgvW', windll.shell32))
+GetCommandLineW = WINFUNCTYPE(LPWSTR)(("GetCommandLineW", windll.kernel32))
+CommandLineToArgvW = WINFUNCTYPE(POINTER(LPWSTR), LPCWSTR, POINTER(c_int))(
+    ("CommandLineToArgvW", windll.shell32)
+)
+LocalFree = WINFUNCTYPE(ctypes.c_void_p, ctypes.c_void_p)(
+    ("LocalFree", windll.kernel32)
+)
 
 
 STDIN_HANDLE = GetStdHandle(-10)
@@ -57,27 +78,27 @@ STDIN_FILENO = 0
 STDOUT_FILENO = 1
 STDERR_FILENO = 2
 
-EOF = b'\x1a'
+EOF = b"\x1a"
 MAX_BYTES_WRITTEN = 32767
 
 
 class Py_buffer(ctypes.Structure):
     _fields_ = [
-        ('buf', c_void_p),
-        ('obj', py_object),
-        ('len', c_ssize_t),
-        ('itemsize', c_ssize_t),
-        ('readonly', c_int),
-        ('ndim', c_int),
-        ('format', c_char_p),
-        ('shape', c_ssize_p),
-        ('strides', c_ssize_p),
-        ('suboffsets', c_ssize_p),
-        ('internal', c_void_p)
+        ("buf", c_void_p),
+        ("obj", py_object),
+        ("len", c_ssize_t),
+        ("itemsize", c_ssize_t),
+        ("readonly", c_int),
+        ("ndim", c_int),
+        ("format", c_char_p),
+        ("shape", c_ssize_p),
+        ("strides", c_ssize_p),
+        ("suboffsets", c_ssize_p),
+        ("internal", c_void_p),
     ]
 
     if PY2:
-        _fields_.insert(-1, ('smalltable', c_ssize_t * 2))
+        _fields_.insert(-1, ("smalltable", c_ssize_t * 2))
 
 
 # On PyPy we cannot get buffers so our ability to operate here is
@@ -85,6 +106,7 @@ class Py_buffer(ctypes.Structure):
 if pythonapi is None:
     get_buffer = None
 else:
+
     def get_buffer(obj, writable=False):
         buf = Py_buffer()
         flags = PyBUF_WRITABLE if writable else PyBUF_SIMPLE
@@ -97,7 +119,6 @@ else:
 
 
 class _WindowsConsoleRawIOBase(io.RawIOBase):
-
     def __init__(self, handle):
         self.handle = handle
 
@@ -107,7 +128,6 @@ class _WindowsConsoleRawIOBase(io.RawIOBase):
 
 
 class _WindowsConsoleReader(_WindowsConsoleRawIOBase):
-
     def readable(self):
         return True
 
@@ -116,20 +136,26 @@ class _WindowsConsoleReader(_WindowsConsoleRawIOBase):
         if not bytes_to_be_read:
             return 0
         elif bytes_to_be_read % 2:
-            raise ValueError('cannot read odd number of bytes from '
-                             'UTF-16-LE encoded console')
+            raise ValueError(
+                "cannot read odd number of bytes from UTF-16-LE encoded console"
+            )
 
         buffer = get_buffer(b, writable=True)
         code_units_to_be_read = bytes_to_be_read // 2
         code_units_read = c_ulong()
 
-        rv = ReadConsoleW(self.handle, buffer, code_units_to_be_read,
-                          byref(code_units_read), None)
+        rv = ReadConsoleW(
+            HANDLE(self.handle),
+            buffer,
+            code_units_to_be_read,
+            byref(code_units_read),
+            None,
+        )
         if GetLastError() == ERROR_OPERATION_ABORTED:
             # wait for KeyboardInterrupt
             time.sleep(0.1)
         if not rv:
-            raise OSError('Windows error: %s' % GetLastError())
+            raise OSError("Windows error: {}".format(GetLastError()))
 
         if buffer[0] == EOF:
             return 0
@@ -137,27 +163,30 @@ class _WindowsConsoleReader(_WindowsConsoleRawIOBase):
 
 
 class _WindowsConsoleWriter(_WindowsConsoleRawIOBase):
-
     def writable(self):
         return True
 
     @staticmethod
     def _get_error_message(errno):
         if errno == ERROR_SUCCESS:
-            return 'ERROR_SUCCESS'
+            return "ERROR_SUCCESS"
         elif errno == ERROR_NOT_ENOUGH_MEMORY:
-            return 'ERROR_NOT_ENOUGH_MEMORY'
-        return 'Windows error %s' % errno
+            return "ERROR_NOT_ENOUGH_MEMORY"
+        return "Windows error {}".format(errno)
 
     def write(self, b):
         bytes_to_be_written = len(b)
         buf = get_buffer(b)
-        code_units_to_be_written = min(bytes_to_be_written,
-                                       MAX_BYTES_WRITTEN) // 2
+        code_units_to_be_written = min(bytes_to_be_written, MAX_BYTES_WRITTEN) // 2
         code_units_written = c_ulong()
 
-        WriteConsoleW(self.handle, buf, code_units_to_be_written,
-                      byref(code_units_written), None)
+        WriteConsoleW(
+            HANDLE(self.handle),
+            buf,
+            code_units_to_be_written,
+            byref(code_units_written),
+            None,
+        )
         bytes_written = 2 * code_units_written.value
 
         if bytes_written == 0 and bytes_to_be_written > 0:
@@ -166,7 +195,6 @@ class _WindowsConsoleWriter(_WindowsConsoleRawIOBase):
 
 
 class ConsoleStream(object):
-
     def __init__(self, text_stream, byte_stream):
         self._text_stream = text_stream
         self.buffer = byte_stream
@@ -195,9 +223,8 @@ class ConsoleStream(object):
         return self.buffer.isatty()
 
     def __repr__(self):
-        return '<ConsoleStream name=%r encoding=%r>' % (
-            self.name,
-            self.encoding,
+        return "<ConsoleStream name={!r} encoding={!r}>".format(
+            self.name, self.encoding
         )
 
 
@@ -207,6 +234,7 @@ class WindowsChunkedWriter(object):
     attribute access apart from method 'write()' which we wrap to write in
     limited chunks due to a Windows limitation on binary console streams.
     """
+
     def __init__(self, wrapped):
         # double-underscore everything to prevent clashes with names of
         # attributes on the wrapped stream object.
@@ -221,7 +249,7 @@ class WindowsChunkedWriter(object):
 
         while written < total_to_write:
             to_write = min(total_to_write - written, MAX_BYTES_WRITTEN)
-            self.__wrapped.write(text[written:written+to_write])
+            self.__wrapped.write(text[written : written + to_write])
             written += to_write
 
 
@@ -230,7 +258,11 @@ _wrapped_std_streams = set()
 
 def _wrap_std_stream(name):
     # Python 2 & Windows 7 and below
-    if PY2 and sys.getwindowsversion()[:2] <= (6, 1) and name not in _wrapped_std_streams:
+    if (
+        PY2
+        and sys.getwindowsversion()[:2] <= (6, 1)
+        and name not in _wrapped_std_streams
+    ):
         setattr(sys, name, WindowsChunkedWriter(getattr(sys, name)))
         _wrapped_std_streams.add(name)
 
@@ -238,43 +270,59 @@ def _wrap_std_stream(name):
 def _get_text_stdin(buffer_stream):
     text_stream = _NonClosingTextIOWrapper(
         io.BufferedReader(_WindowsConsoleReader(STDIN_HANDLE)),
-        'utf-16-le', 'strict', line_buffering=True)
+        "utf-16-le",
+        "strict",
+        line_buffering=True,
+    )
     return ConsoleStream(text_stream, buffer_stream)
 
 
 def _get_text_stdout(buffer_stream):
     text_stream = _NonClosingTextIOWrapper(
         io.BufferedWriter(_WindowsConsoleWriter(STDOUT_HANDLE)),
-        'utf-16-le', 'strict', line_buffering=True)
+        "utf-16-le",
+        "strict",
+        line_buffering=True,
+    )
     return ConsoleStream(text_stream, buffer_stream)
 
 
 def _get_text_stderr(buffer_stream):
     text_stream = _NonClosingTextIOWrapper(
         io.BufferedWriter(_WindowsConsoleWriter(STDERR_HANDLE)),
-        'utf-16-le', 'strict', line_buffering=True)
+        "utf-16-le",
+        "strict",
+        line_buffering=True,
+    )
     return ConsoleStream(text_stream, buffer_stream)
 
 
 if PY2:
+
     def _hash_py_argv():
-        return zlib.crc32('\x00'.join(sys.argv[1:]))
+        return zlib.crc32("\x00".join(sys.argv[1:]))
 
     _initial_argv_hash = _hash_py_argv()
 
     def _get_windows_argv():
         argc = c_int(0)
         argv_unicode = CommandLineToArgvW(GetCommandLineW(), byref(argc))
-        argv = [argv_unicode[i] for i in range(0, argc.value)]
+        if not argv_unicode:
+            raise WinError()
+        try:
+            argv = [argv_unicode[i] for i in range(0, argc.value)]
+        finally:
+            LocalFree(argv_unicode)
+            del argv_unicode
 
-        if not hasattr(sys, 'frozen'):
+        if not hasattr(sys, "frozen"):
             argv = argv[1:]
             while len(argv) > 0:
                 arg = argv[0]
-                if not arg.startswith('-') or arg == '-':
+                if not arg.startswith("-") or arg == "-":
                     break
                 argv = argv[1:]
-                if arg.startswith(('-c', '-m')):
+                if arg.startswith(("-c", "-m")):
                     break
 
         return argv[1:]
@@ -287,15 +335,30 @@ _stream_factories = {
 }
 
 
+def _is_console(f):
+    if not hasattr(f, "fileno"):
+        return False
+
+    try:
+        fileno = f.fileno()
+    except OSError:
+        return False
+
+    handle = msvcrt.get_osfhandle(fileno)
+    return bool(GetConsoleMode(handle, byref(DWORD())))
+
+
 def _get_windows_console_stream(f, encoding, errors):
-    if get_buffer is not None and \
-       encoding in ('utf-16-le', None) \
-       and errors in ('strict', None) and \
-       hasattr(f, 'isatty') and f.isatty():
+    if (
+        get_buffer is not None
+        and encoding in ("utf-16-le", None)
+        and errors in ("strict", None)
+        and _is_console(f)
+    ):
         func = _stream_factories.get(f.fileno())
         if func is not None:
             if not PY2:
-                f = getattr(f, 'buffer', None)
+                f = getattr(f, "buffer", None)
                 if f is None:
                     return None
             else:
diff --git a/pipenv/vendor/click/core.py b/pipenv/vendor/click/core.py
index 7a1e3422..f58bf26d 100644
--- a/pipenv/vendor/click/core.py
+++ b/pipenv/vendor/click/core.py
@@ -3,37 +3,51 @@ import inspect
 import os
 import sys
 from contextlib import contextmanager
-from itertools import repeat
 from functools import update_wrapper
+from itertools import repeat
 
-from .types import convert_type, IntRange, BOOL
-from .utils import PacifyFlushWrapper, make_str, make_default_short_help, \
-     echo, get_os_args
-from .exceptions import ClickException, UsageError, BadParameter, Abort, \
-     MissingParameter, Exit
-from .termui import prompt, confirm, style
-from .formatting import HelpFormatter, join_options
-from .parser import OptionParser, split_opt
-from .globals import push_context, pop_context
-
-from ._compat import PY2, isidentifier, iteritems, string_types
-from ._unicodefun import _check_for_unicode_literals, _verify_python3_env
-
+from ._compat import isidentifier
+from ._compat import iteritems
+from ._compat import PY2
+from ._compat import string_types
+from ._unicodefun import _check_for_unicode_literals
+from ._unicodefun import _verify_python3_env
+from .exceptions import Abort
+from .exceptions import BadParameter
+from .exceptions import ClickException
+from .exceptions import Exit
+from .exceptions import MissingParameter
+from .exceptions import UsageError
+from .formatting import HelpFormatter
+from .formatting import join_options
+from .globals import pop_context
+from .globals import push_context
+from .parser import OptionParser
+from .parser import split_opt
+from .termui import confirm
+from .termui import prompt
+from .termui import style
+from .types import BOOL
+from .types import convert_type
+from .types import IntRange
+from .utils import echo
+from .utils import get_os_args
+from .utils import make_default_short_help
+from .utils import make_str
+from .utils import PacifyFlushWrapper
 
 _missing = object()
 
+SUBCOMMAND_METAVAR = "COMMAND [ARGS]..."
+SUBCOMMANDS_METAVAR = "COMMAND1 [ARGS]... [COMMAND2 [ARGS]...]..."
 
-SUBCOMMAND_METAVAR = 'COMMAND [ARGS]...'
-SUBCOMMANDS_METAVAR = 'COMMAND1 [ARGS]... [COMMAND2 [ARGS]...]...'
-
-DEPRECATED_HELP_NOTICE = ' (DEPRECATED)'
-DEPRECATED_INVOKE_NOTICE = 'DeprecationWarning: ' + \
-                           'The command %(name)s is deprecated.'
+DEPRECATED_HELP_NOTICE = " (DEPRECATED)"
+DEPRECATED_INVOKE_NOTICE = "DeprecationWarning: The command %(name)s is deprecated."
 
 
 def _maybe_show_deprecated_notice(cmd):
     if cmd.deprecated:
-        echo(style(DEPRECATED_INVOKE_NOTICE % {'name': cmd.name}, fg='red'), err=True)
+        echo(style(DEPRECATED_INVOKE_NOTICE % {"name": cmd.name}, fg="red"), err=True)
 
 
 def fast_exit(code):
@@ -48,12 +62,13 @@ def fast_exit(code):
 def _bashcomplete(cmd, prog_name, complete_var=None):
     """Internal handler for the bash completion support."""
     if complete_var is None:
-        complete_var = '_%s_COMPLETE' % (prog_name.replace('-', '_')).upper()
+        complete_var = "_{}_COMPLETE".format(prog_name.replace("-", "_").upper())
     complete_instr = os.environ.get(complete_var)
     if not complete_instr:
         return
 
     from ._bashcomplete import bashcomplete
+
     if bashcomplete(cmd, prog_name, complete_var, complete_instr):
         fast_exit(1)
 
@@ -62,19 +77,28 @@ def _check_multicommand(base_command, cmd_name, cmd, register=False):
     if not base_command.chain or not isinstance(cmd, MultiCommand):
         return
     if register:
-        hint = 'It is not possible to add multi commands as children to ' \
-               'another multi command that is in chain mode'
+        hint = (
+            "It is not possible to add multi commands as children to"
+            " another multi command that is in chain mode."
+        )
     else:
-        hint = 'Found a multi command as subcommand to a multi command ' \
-               'that is in chain mode.  This is not supported'
-    raise RuntimeError('%s.  Command "%s" is set to chain and "%s" was '
-                       'added as subcommand but it in itself is a '
-                       'multi command.  ("%s" is a %s within a chained '
-                       '%s named "%s").' % (
-                           hint, base_command.name, cmd_name,
-                           cmd_name, cmd.__class__.__name__,
-                           base_command.__class__.__name__,
-                           base_command.name))
+        hint = (
+            "Found a multi command as subcommand to a multi command"
+            " that is in chain mode. This is not supported."
+        )
+    raise RuntimeError(
+        "{}. Command '{}' is set to chain and '{}' was added as"
+        " subcommand but it in itself is a multi command. ('{}' is a {}"
+        " within a chained {} named '{}').".format(
+            hint,
+            base_command.name,
+            cmd_name,
+            cmd_name,
+            cmd.__class__.__name__,
+            base_command.__class__.__name__,
+            base_command.name,
+        )
+    )
 
 
 def batch(iterable, batch_size):
@@ -82,25 +106,26 @@ def batch(iterable, batch_size):
 
 
 def invoke_param_callback(callback, ctx, param, value):
-    code = getattr(callback, '__code__', None)
-    args = getattr(code, 'co_argcount', 3)
+    code = getattr(callback, "__code__", None)
+    args = getattr(code, "co_argcount", 3)
 
     if args < 3:
-        # This will become a warning in Click 3.0:
         from warnings import warn
-        warn(Warning('Invoked legacy parameter callback "%s".  The new '
-                     'signature for such callbacks starting with '
-                     'click 2.0 is (ctx, param, value).'
-                     % callback), stacklevel=3)
+
+        warn(
+            "Parameter callbacks take 3 args, (ctx, param, value). The"
+            " 2-arg style is deprecated and will be removed in 8.0.".format(callback),
+            DeprecationWarning,
+            stacklevel=3,
+        )
         return callback(ctx, value)
+
     return callback(ctx, param, value)
 
 
 @contextmanager
 def augment_usage_errors(ctx, param=None):
-    """Context manager that attaches extra information to exceptions that
-    fly.
-    """
+    """Context manager that attaches extra information to exceptions."""
     try:
         yield
     except BadParameter as e:
@@ -120,11 +145,12 @@ def iter_params_for_processing(invocation_order, declaration_order):
     for processing and an iterable of parameters that exist, this returns
     a list in the correct order as they should be processed.
     """
+
     def sort_key(item):
         try:
             idx = invocation_order.index(item)
         except ValueError:
-            idx = float('inf')
+            idx = float("inf")
         return (not item.is_eager, idx)
 
     return sorted(declaration_order, key=sort_key)
@@ -154,6 +180,9 @@ class Context(object):
        Added the `color`, `ignore_unknown_options`, and
        `max_content_width` parameters.
 
+    .. versionadded:: 7.1
+       Added the `show_default` parameter.
+
     :param command: the command class for this context.
     :param parent: the parent context.
     :param info_name: the info name for this invocation.  Generally this
@@ -208,15 +237,30 @@ class Context(object):
                   codes are used in texts that Click prints which is by
                   default not the case.  This for instance would affect
                   help output.
+    :param show_default: if True, shows defaults for all options.
+                    Even if an option is later created with show_default=False,
+                    this command-level setting overrides it.
     """
 
-    def __init__(self, command, parent=None, info_name=None, obj=None,
-                 auto_envvar_prefix=None, default_map=None,
-                 terminal_width=None, max_content_width=None,
-                 resilient_parsing=False, allow_extra_args=None,
-                 allow_interspersed_args=None,
-                 ignore_unknown_options=None, help_option_names=None,
-                 token_normalize_func=None, color=None):
+    def __init__(
+        self,
+        command,
+        parent=None,
+        info_name=None,
+        obj=None,
+        auto_envvar_prefix=None,
+        default_map=None,
+        terminal_width=None,
+        max_content_width=None,
+        resilient_parsing=False,
+        allow_extra_args=None,
+        allow_interspersed_args=None,
+        ignore_unknown_options=None,
+        help_option_names=None,
+        token_normalize_func=None,
+        color=None,
+        show_default=None,
+    ):
         #: the parent context or `None` if none exists.
         self.parent = parent
         #: the :class:`Command` for this context.
@@ -237,12 +281,14 @@ class Context(object):
             obj = parent.obj
         #: the user object stored.
         self.obj = obj
-        self._meta = getattr(parent, 'meta', {})
+        self._meta = getattr(parent, "meta", {})
 
         #: A dictionary (-like object) with defaults for parameters.
-        if default_map is None \
-           and parent is not None \
-           and parent.default_map is not None:
+        if (
+            default_map is None
+            and parent is not None
+            and parent.default_map is not None
+        ):
             default_map = parent.default_map.get(info_name)
         self.default_map = default_map
 
@@ -301,7 +347,7 @@ class Context(object):
             if parent is not None:
                 help_option_names = parent.help_option_names
             else:
-                help_option_names = ['--help']
+                help_option_names = ["--help"]
 
         #: The names for the help options.
         self.help_option_names = help_option_names
@@ -322,13 +368,18 @@ class Context(object):
         # the command on this level has a name, we can expand the envvar
         # prefix automatically.
         if auto_envvar_prefix is None:
-            if parent is not None \
-               and parent.auto_envvar_prefix is not None and \
-               self.info_name is not None:
-                auto_envvar_prefix = '%s_%s' % (parent.auto_envvar_prefix,
-                                           self.info_name.upper())
+            if (
+                parent is not None
+                and parent.auto_envvar_prefix is not None
+                and self.info_name is not None
+            ):
+                auto_envvar_prefix = "{}_{}".format(
+                    parent.auto_envvar_prefix, self.info_name.upper()
+                )
         else:
             auto_envvar_prefix = auto_envvar_prefix.upper()
+        if auto_envvar_prefix is not None:
+            auto_envvar_prefix = auto_envvar_prefix.replace("-", "_")
         self.auto_envvar_prefix = auto_envvar_prefix
 
         if color is None and parent is not None:
@@ -337,6 +388,8 @@ class Context(object):
         #: Controls if styling output is wanted or not.
         self.color = color
 
+        self.show_default = show_default
+
         self._close_callbacks = []
         self._depth = 0
 
@@ -404,7 +457,7 @@ class Context(object):
 
         Example usage::
 
-            LANG_KEY = __name__ + '.lang'
+            LANG_KEY = f'{__name__}.lang'
 
             def set_language(value):
                 ctx = get_current_context()
@@ -419,8 +472,9 @@ class Context(object):
 
     def make_formatter(self):
         """Creates the formatter for the help and usage output."""
-        return HelpFormatter(width=self.terminal_width,
-                             max_width=self.max_content_width)
+        return HelpFormatter(
+            width=self.terminal_width, max_width=self.max_content_width
+        )
 
     def call_on_close(self, f):
         """This decorator remembers a function as callback that should be
@@ -446,11 +500,11 @@ class Context(object):
         information on the help page.  It's automatically created by
         combining the info names of the chain of contexts to the root.
         """
-        rv = ''
+        rv = ""
         if self.info_name is not None:
             rv = self.info_name
         if self.parent is not None:
-            rv = self.parent.command_path + ' ' + rv
+            rv = "{} {}".format(self.parent.command_path, rv)
         return rv.lstrip()
 
     def find_root(self):
@@ -515,7 +569,7 @@ class Context(object):
         """
         return self.command.get_help(self)
 
-    def invoke(*args, **kwargs):
+    def invoke(*args, **kwargs):  # noqa: B902
         """Invokes a command callback in exactly the way it expects.  There
         are two ways to invoke this method:
 
@@ -542,8 +596,9 @@ class Context(object):
             callback = other_cmd.callback
             ctx = Context(other_cmd, info_name=other_cmd.name, parent=self)
             if callback is None:
-                raise TypeError('The given command does not have a '
-                                'callback that can be invoked.')
+                raise TypeError(
+                    "The given command does not have a callback that can be invoked."
+                )
 
             for param in other_cmd.params:
                 if param.name not in kwargs and param.expose_value:
@@ -554,7 +609,7 @@ class Context(object):
             with ctx:
                 return callback(*args, **kwargs)
 
-    def forward(*args, **kwargs):
+    def forward(*args, **kwargs):  # noqa: B902
         """Similar to :meth:`invoke` but fills in default keyword
         arguments from the current context if the other command expects
         it.  This cannot invoke callbacks directly, only other commands.
@@ -564,7 +619,7 @@ class Context(object):
         # It's also possible to invoke another command which might or
         # might not have a callback.
         if not isinstance(cmd, Command):
-            raise TypeError('Callback is not a command.')
+            raise TypeError("Callback is not a command.")
 
         for param in self.params:
             if param not in kwargs:
@@ -594,6 +649,7 @@ class BaseCommand(object):
     :param context_settings: an optional dictionary with defaults that are
                              passed to the context object.
     """
+
     #: the default for the :attr:`Context.allow_extra_args` flag.
     allow_extra_args = False
     #: the default for the :attr:`Context.allow_interspersed_args` flag.
@@ -612,11 +668,14 @@ class BaseCommand(object):
         #: an optional dictionary with defaults passed to the context.
         self.context_settings = context_settings
 
+    def __repr__(self):
+        return "<{} {}>".format(self.__class__.__name__, self.name)
+
     def get_usage(self, ctx):
-        raise NotImplementedError('Base commands cannot get usage')
+        raise NotImplementedError("Base commands cannot get usage")
 
     def get_help(self, ctx):
-        raise NotImplementedError('Base commands cannot get help')
+        raise NotImplementedError("Base commands cannot get help")
 
     def make_context(self, info_name, args, parent=None, **extra):
         """This function when given an info name and arguments will kick
@@ -646,17 +705,22 @@ class BaseCommand(object):
         and parses the arguments, then modifies the context as necessary.
         This is automatically invoked by :meth:`make_context`.
         """
-        raise NotImplementedError('Base commands do not know how to parse '
-                                  'arguments.')
+        raise NotImplementedError("Base commands do not know how to parse arguments.")
 
     def invoke(self, ctx):
         """Given a context, this invokes the command.  The default
         implementation is raising a not implemented error.
         """
-        raise NotImplementedError('Base commands are not invokable by default')
-
-    def main(self, args=None, prog_name=None, complete_var=None,
-             standalone_mode=True, **extra):
+        raise NotImplementedError("Base commands are not invokable by default")
+
+    def main(
+        self,
+        args=None,
+        prog_name=None,
+        complete_var=None,
+        standalone_mode=True,
+        **extra
+    ):
         """This is the way to invoke a script with all the bells and
         whistles as a command line application.  This will always terminate
         the application after a call.  If this is not wanted, ``SystemExit``
@@ -703,8 +767,9 @@ class BaseCommand(object):
             args = list(args)
 
         if prog_name is None:
-            prog_name = make_str(os.path.basename(
-                sys.argv and sys.argv[0] or __file__))
+            prog_name = make_str(
+                os.path.basename(sys.argv[0] if sys.argv else __file__)
+            )
 
         # Hook for the Bash completion.  This only activates if the Bash
         # completion is actually enabled, otherwise this is quite a fast
@@ -756,7 +821,7 @@ class BaseCommand(object):
         except Abort:
             if not standalone_mode:
                 raise
-            echo('Aborted!', file=sys.stderr)
+            echo("Aborted!", file=sys.stderr)
             sys.exit(1)
 
     def __call__(self, *args, **kwargs):
@@ -771,6 +836,8 @@ class Command(BaseCommand):
 
     .. versionchanged:: 2.0
        Added the `context_settings` parameter.
+    .. versionchanged:: 7.1
+       Added the `no_args_is_help` parameter.
 
     :param name: the name of the command to use unless a group overrides it.
     :param context_settings: an optional dictionary with defaults that are
@@ -785,16 +852,31 @@ class Command(BaseCommand):
                        shown on the command listing of the parent command.
     :param add_help_option: by default each command registers a ``--help``
                             option.  This can be disabled by this parameter.
+    :param no_args_is_help: this controls what happens if no arguments are
+                            provided.  This option is disabled by default.
+                            If enabled this will add ``--help`` as argument
+                            if no arguments are passed
     :param hidden: hide this command from help outputs.
 
     :param deprecated: issues a message indicating that
                              the command is deprecated.
     """
 
-    def __init__(self, name, context_settings=None, callback=None,
-                 params=None, help=None, epilog=None, short_help=None,
-                 options_metavar='[OPTIONS]', add_help_option=True,
-                 hidden=False, deprecated=False):
+    def __init__(
+        self,
+        name,
+        context_settings=None,
+        callback=None,
+        params=None,
+        help=None,
+        epilog=None,
+        short_help=None,
+        options_metavar="[OPTIONS]",
+        add_help_option=True,
+        no_args_is_help=False,
+        hidden=False,
+        deprecated=False,
+    ):
         BaseCommand.__init__(self, name, context_settings)
         #: the callback to execute when the command fires.  This might be
         #: `None` in which case nothing happens.
@@ -805,20 +887,25 @@ class Command(BaseCommand):
         self.params = params or []
         # if a form feed (page break) is found in the help text, truncate help
         # text to the content preceding the first form feed
-        if help and '\f' in help:
-            help = help.split('\f', 1)[0]
+        if help and "\f" in help:
+            help = help.split("\f", 1)[0]
         self.help = help
         self.epilog = epilog
         self.options_metavar = options_metavar
         self.short_help = short_help
         self.add_help_option = add_help_option
+        self.no_args_is_help = no_args_is_help
         self.hidden = hidden
         self.deprecated = deprecated
 
     def get_usage(self, ctx):
+        """Formats the usage line into a string and returns it.
+
+        Calls :meth:`format_usage` internally.
+        """
         formatter = ctx.make_formatter()
         self.format_usage(ctx, formatter)
-        return formatter.getvalue().rstrip('\n')
+        return formatter.getvalue().rstrip("\n")
 
     def get_params(self, ctx):
         rv = self.params
@@ -828,9 +915,12 @@ class Command(BaseCommand):
         return rv
 
     def format_usage(self, ctx, formatter):
-        """Writes the usage line into the formatter."""
+        """Writes the usage line into the formatter.
+
+        This is a low-level method called by :meth:`get_usage`.
+        """
         pieces = self.collect_usage_pieces(ctx)
-        formatter.write_usage(ctx.command_path, ' '.join(pieces))
+        formatter.write_usage(ctx.command_path, " ".join(pieces))
 
     def collect_usage_pieces(self, ctx):
         """Returns all the pieces that go into the usage line and returns
@@ -859,10 +949,15 @@ class Command(BaseCommand):
             if value and not ctx.resilient_parsing:
                 echo(ctx.get_help(), color=ctx.color)
                 ctx.exit()
-        return Option(help_options, is_flag=True,
-                      is_eager=True, expose_value=False,
-                      callback=show_help,
-                      help='Show this message and exit.')
+
+        return Option(
+            help_options,
+            is_flag=True,
+            is_eager=True,
+            expose_value=False,
+            callback=show_help,
+            help="Show this message and exit.",
+        )
 
     def make_parser(self, ctx):
         """Creates the underlying option parser for this command."""
@@ -872,21 +967,31 @@ class Command(BaseCommand):
         return parser
 
     def get_help(self, ctx):
-        """Formats the help into a string and returns it.  This creates a
-        formatter and will call into the following formatting methods:
+        """Formats the help into a string and returns it.
+
+        Calls :meth:`format_help` internally.
         """
         formatter = ctx.make_formatter()
         self.format_help(ctx, formatter)
-        return formatter.getvalue().rstrip('\n')
+        return formatter.getvalue().rstrip("\n")
 
     def get_short_help_str(self, limit=45):
-        """Gets short help for the command or makes it by shortening the long help string."""
-        return self.short_help or self.help and make_default_short_help(self.help, limit) or ''
+        """Gets short help for the command or makes it by shortening the
+        long help string.
+        """
+        return (
+            self.short_help
+            or self.help
+            and make_default_short_help(self.help, limit)
+            or ""
+        )
 
     def format_help(self, ctx, formatter):
         """Writes the help into the formatter if it exists.
 
-        This calls into the following methods:
+        This is a low-level method called by :meth:`get_help`.
+
+        This calls the following methods:
 
         -   :meth:`format_usage`
         -   :meth:`format_help_text`
@@ -921,7 +1026,7 @@ class Command(BaseCommand):
                 opts.append(rv)
 
         if opts:
-            with formatter.section('Options'):
+            with formatter.section("Options"):
                 formatter.write_dl(opts)
 
     def format_epilog(self, ctx, formatter):
@@ -932,17 +1037,22 @@ class Command(BaseCommand):
                 formatter.write_text(self.epilog)
 
     def parse_args(self, ctx, args):
+        if not args and self.no_args_is_help and not ctx.resilient_parsing:
+            echo(ctx.get_help(), color=ctx.color)
+            ctx.exit()
+
         parser = self.make_parser(ctx)
         opts, args, param_order = parser.parse_args(args=args)
 
-        for param in iter_params_for_processing(
-                param_order, self.get_params(ctx)):
+        for param in iter_params_for_processing(param_order, self.get_params(ctx)):
             value, args = param.handle_parse_result(ctx, opts, args)
 
         if args and not ctx.allow_extra_args and not ctx.resilient_parsing:
-            ctx.fail('Got unexpected extra argument%s (%s)'
-                     % (len(args) != 1 and 's' or '',
-                        ' '.join(map(make_str, args))))
+            ctx.fail(
+                "Got unexpected extra argument{} ({})".format(
+                    "s" if len(args) != 1 else "", " ".join(map(make_str, args))
+                )
+            )
 
         ctx.args = args
         return args
@@ -979,12 +1089,20 @@ class MultiCommand(Command):
     :param result_callback: the result callback to attach to this multi
                             command.
     """
+
     allow_extra_args = True
     allow_interspersed_args = False
 
-    def __init__(self, name=None, invoke_without_command=False,
-                 no_args_is_help=None, subcommand_metavar=None,
-                 chain=False, result_callback=None, **attrs):
+    def __init__(
+        self,
+        name=None,
+        invoke_without_command=False,
+        no_args_is_help=None,
+        subcommand_metavar=None,
+        chain=False,
+        result_callback=None,
+        **attrs
+    ):
         Command.__init__(self, name, **attrs)
         if no_args_is_help is None:
             no_args_is_help = not invoke_without_command
@@ -1004,8 +1122,10 @@ class MultiCommand(Command):
         if self.chain:
             for param in self.params:
                 if isinstance(param, Argument) and not param.required:
-                    raise RuntimeError('Multi commands in chain mode cannot '
-                                       'have optional arguments.')
+                    raise RuntimeError(
+                        "Multi commands in chain mode cannot have"
+                        " optional arguments."
+                    )
 
     def collect_usage_pieces(self, ctx):
         rv = Command.collect_usage_pieces(self, ctx)
@@ -1041,16 +1161,19 @@ class MultiCommand(Command):
         :param replace: if set to `True` an already existing result
                         callback will be removed.
         """
+
         def decorator(f):
             old_callback = self.result_callback
             if old_callback is None or replace:
                 self.result_callback = f
                 return f
+
             def function(__value, *args, **kwargs):
-                return f(old_callback(__value, *args, **kwargs),
-                         *args, **kwargs)
+                return f(old_callback(__value, *args, **kwargs), *args, **kwargs)
+
             self.result_callback = rv = update_wrapper(function, f)
             return rv
+
         return decorator
 
     def format_commands(self, ctx, formatter):
@@ -1078,7 +1201,7 @@ class MultiCommand(Command):
                 rows.append((subcommand, help))
 
             if rows:
-                with formatter.section('Commands'):
+                with formatter.section("Commands"):
                     formatter.write_dl(rows)
 
     def parse_args(self, ctx, args):
@@ -1098,8 +1221,7 @@ class MultiCommand(Command):
     def invoke(self, ctx):
         def _process_result(value):
             if self.result_callback is not None:
-                value = ctx.invoke(self.result_callback, value,
-                                   **ctx.params)
+                value = ctx.invoke(self.result_callback, value, **ctx.params)
             return value
 
         if not ctx.protected_args:
@@ -1115,7 +1237,7 @@ class MultiCommand(Command):
                 with ctx:
                     Command.invoke(self, ctx)
                     return _process_result([])
-            ctx.fail('Missing command.')
+            ctx.fail("Missing command.")
 
         # Fetch args back out
         args = ctx.protected_args + ctx.args
@@ -1142,7 +1264,7 @@ class MultiCommand(Command):
         # set to ``*`` to inform the command that subcommands are executed
         # but nothing else.
         with ctx:
-            ctx.invoked_subcommand = args and '*' or None
+            ctx.invoked_subcommand = "*" if args else None
             Command.invoke(self, ctx)
 
             # Otherwise we make every single context and invoke them in a
@@ -1151,9 +1273,13 @@ class MultiCommand(Command):
             contexts = []
             while args:
                 cmd_name, cmd, args = self.resolve_command(ctx, args)
-                sub_ctx = cmd.make_context(cmd_name, args, parent=ctx,
-                                           allow_extra_args=True,
-                                           allow_interspersed_args=False)
+                sub_ctx = cmd.make_context(
+                    cmd_name,
+                    args,
+                    parent=ctx,
+                    allow_extra_args=True,
+                    allow_interspersed_args=False,
+                )
                 contexts.append(sub_ctx)
                 args, sub_ctx.args = sub_ctx.args, []
 
@@ -1185,7 +1311,7 @@ class MultiCommand(Command):
         if cmd is None and not ctx.resilient_parsing:
             if split_opt(cmd_name)[0]:
                 self.parse_args(ctx, ctx.args)
-            ctx.fail('No such command "%s".' % original_cmd_name)
+            ctx.fail("No such command '{}'.".format(original_cmd_name))
 
         return cmd_name, cmd, args[1:]
 
@@ -1220,7 +1346,7 @@ class Group(MultiCommand):
         """
         name = name or cmd.name
         if name is None:
-            raise TypeError('Command has no name.')
+            raise TypeError("Command has no name.")
         _check_multicommand(self, name, cmd, register=True)
         self.commands[name] = cmd
 
@@ -1230,10 +1356,13 @@ class Group(MultiCommand):
         immediately registers the created command with this instance by
         calling into :meth:`add_command`.
         """
+        from .decorators import command
+
         def decorator(f):
             cmd = command(*args, **kwargs)(f)
             self.add_command(cmd)
             return cmd
+
         return decorator
 
     def group(self, *args, **kwargs):
@@ -1242,10 +1371,13 @@ class Group(MultiCommand):
         immediately registers the created command with this instance by
         calling into :meth:`add_command`.
         """
+        from .decorators import group
+
         def decorator(f):
             cmd = group(*args, **kwargs)(f)
             self.add_command(cmd)
             return cmd
+
         return decorator
 
     def get_command(self, ctx, cmd_name):
@@ -1294,12 +1426,6 @@ class Parameter(object):
 
     Some settings are supported by both options and arguments.
 
-    .. versionchanged:: 2.0
-       Changed signature for parameter callback to also be passed the
-       parameter.  In Click 2.0, the old callback format will still work,
-       but it will raise a warning to give you change to migrate the
-       code easier.
-
     :param param_decls: the parameter declarations for this option or
                         argument.  This is a list of flags or argument
                         names.
@@ -1312,8 +1438,7 @@ class Parameter(object):
                     without any arguments.
     :param callback: a callback that should be executed after the parameter
                      was matched.  This is called as ``fn(ctx, param,
-                     value)`` and needs to return the value.  Before Click
-                     2.0, the signature was ``(ctx, value)``.
+                     value)`` and needs to return the value.
     :param nargs: the number of arguments to match.  If not ``1`` the return
                   value is a tuple instead of single value.  The default for
                   nargs is ``1`` (except if the type is a tuple, then it's
@@ -1327,15 +1452,36 @@ class Parameter(object):
                      order of processing.
     :param envvar: a string or list of strings that are environment variables
                    that should be checked.
-    """
-    param_type_name = 'parameter'
 
-    def __init__(self, param_decls=None, type=None, required=False,
-                 default=None, callback=None, nargs=None, metavar=None,
-                 expose_value=True, is_eager=False, envvar=None,
-                 autocompletion=None):
-        self.name, self.opts, self.secondary_opts = \
-            self._parse_decls(param_decls or (), expose_value)
+    .. versionchanged:: 7.1
+        Empty environment variables are ignored rather than taking the
+        empty string value. This makes it possible for scripts to clear
+        variables if they can't unset them.
+
+    .. versionchanged:: 2.0
+        Changed signature for parameter callback to also be passed the
+        parameter. The old callback format will still work, but it will
+        raise a warning to give you a chance to migrate the code easier.
+    """
+    param_type_name = "parameter"
+
+    def __init__(
+        self,
+        param_decls=None,
+        type=None,
+        required=False,
+        default=None,
+        callback=None,
+        nargs=None,
+        metavar=None,
+        expose_value=True,
+        is_eager=False,
+        envvar=None,
+        autocompletion=None,
+    ):
+        self.name, self.opts, self.secondary_opts = self._parse_decls(
+            param_decls or (), expose_value
+        )
 
         self.type = convert_type(type, default)
 
@@ -1358,6 +1504,9 @@ class Parameter(object):
         self.envvar = envvar
         self.autocompletion = autocompletion
 
+    def __repr__(self):
+        return "<{} {}>".format(self.__class__.__name__, self.name)
+
     @property
     def human_readable_name(self):
         """Returns the human readable name of this parameter.  This is the
@@ -1372,7 +1521,7 @@ class Parameter(object):
         if metavar is None:
             metavar = self.type.name.upper()
         if self.nargs != 1:
-            metavar += '...'
+            metavar += "..."
         return metavar
 
     def get_default(self, ctx):
@@ -1402,10 +1551,11 @@ class Parameter(object):
         """
         if self.type.is_composite:
             if self.nargs <= 1:
-                raise TypeError('Attempted to invoke composite type '
-                                'but nargs has been set to %s.  This is '
-                                'not supported; nargs needs to be set to '
-                                'a fixed value > 1.' % self.nargs)
+                raise TypeError(
+                    "Attempted to invoke composite type but nargs has"
+                    " been set to {}. This is not supported; nargs"
+                    " needs to be set to a fixed value > 1.".format(self.nargs)
+                )
             if self.multiple:
                 return tuple(self.type(x or (), self, ctx) for x in value or ())
             return self.type(value or (), self, ctx)
@@ -1414,6 +1564,7 @@ class Parameter(object):
             if level == 0:
                 return self.type(value, self, ctx)
             return tuple(_convert(x, level - 1) for x in value or ())
+
         return _convert(value, (self.nargs != 1) + bool(self.multiple))
 
     def process_value(self, ctx, value):
@@ -1454,7 +1605,10 @@ class Parameter(object):
                 if rv is not None:
                     return rv
         else:
-            return os.environ.get(self.envvar)
+            rv = os.environ.get(self.envvar)
+
+            if rv != "":
+                return rv
 
     def value_from_envvar(self, ctx):
         rv = self.resolve_envvar_value(ctx)
@@ -1473,8 +1627,7 @@ class Parameter(object):
                 value = None
             if self.callback is not None:
                 try:
-                    value = invoke_param_callback(
-                        self.callback, ctx, self, value)
+                    value = invoke_param_callback(self.callback, ctx, self, value)
                 except Exception:
                     if not ctx.resilient_parsing:
                         raise
@@ -1494,7 +1647,7 @@ class Parameter(object):
         indicate which param caused the error.
         """
         hint_list = self.opts or [self.human_readable_name]
-        return ' / '.join('"%s"' % x for x in hint_list)
+        return " / ".join(repr(x) for x in hint_list)
 
 
 class Option(Parameter):
@@ -1535,19 +1688,33 @@ class Option(Parameter):
     :param help: the help string.
     :param hidden: hide this option from help outputs.
     """
-    param_type_name = 'option'
-
-    def __init__(self, param_decls=None, show_default=False,
-                 prompt=False, confirmation_prompt=False,
-                 hide_input=False, is_flag=None, flag_value=None,
-                 multiple=False, count=False, allow_from_autoenv=True,
-                 type=None, help=None, hidden=False, show_choices=True,
-                 show_envvar=False, **attrs):
-        default_is_missing = attrs.get('default', _missing) is _missing
+
+    param_type_name = "option"
+
+    def __init__(
+        self,
+        param_decls=None,
+        show_default=False,
+        prompt=False,
+        confirmation_prompt=False,
+        hide_input=False,
+        is_flag=None,
+        flag_value=None,
+        multiple=False,
+        count=False,
+        allow_from_autoenv=True,
+        type=None,
+        help=None,
+        hidden=False,
+        show_choices=True,
+        show_envvar=False,
+        **attrs
+    ):
+        default_is_missing = attrs.get("default", _missing) is _missing
         Parameter.__init__(self, param_decls, type=type, **attrs)
 
         if prompt is True:
-            prompt_text = self.name.replace('_', ' ').capitalize()
+            prompt_text = self.name.replace("_", " ").capitalize()
         elif prompt is False:
             prompt_text = None
         else:
@@ -1569,8 +1736,7 @@ class Option(Parameter):
             flag_value = not self.default
         self.is_flag = is_flag
         self.flag_value = flag_value
-        if self.is_flag and isinstance(self.flag_value, bool) \
-           and type is None:
+        if self.is_flag and isinstance(self.flag_value, bool) and type in [None, bool]:
             self.type = BOOL
             self.is_bool_flag = True
         else:
@@ -1594,22 +1760,22 @@ class Option(Parameter):
         # Sanity check for stuff we don't support
         if __debug__:
             if self.nargs < 0:
-                raise TypeError('Options cannot have nargs < 0')
+                raise TypeError("Options cannot have nargs < 0")
             if self.prompt and self.is_flag and not self.is_bool_flag:
-                raise TypeError('Cannot prompt for flags that are not bools.')
+                raise TypeError("Cannot prompt for flags that are not bools.")
             if not self.is_bool_flag and self.secondary_opts:
-                raise TypeError('Got secondary option for non boolean flag.')
-            if self.is_bool_flag and self.hide_input \
-               and self.prompt is not None:
-                raise TypeError('Hidden input does not work with boolean '
-                                'flag prompts.')
+                raise TypeError("Got secondary option for non boolean flag.")
+            if self.is_bool_flag and self.hide_input and self.prompt is not None:
+                raise TypeError("Hidden input does not work with boolean flag prompts.")
             if self.count:
                 if self.multiple:
-                    raise TypeError('Options cannot be multiple and count '
-                                    'at the same time.')
+                    raise TypeError(
+                        "Options cannot be multiple and count at the same time."
+                    )
                 elif self.is_flag:
-                    raise TypeError('Options cannot be count and flags at '
-                                    'the same time.')
+                    raise TypeError(
+                        "Options cannot be count and flags at the same time."
+                    )
 
     def _parse_decls(self, decls, expose_value):
         opts = []
@@ -1620,10 +1786,10 @@ class Option(Parameter):
         for decl in decls:
             if isidentifier(decl):
                 if name is not None:
-                    raise TypeError('Name defined twice')
+                    raise TypeError("Name defined twice")
                 name = decl
             else:
-                split_char = decl[:1] == '/' and ';' or '/'
+                split_char = ";" if decl[:1] == "/" else "/"
                 if split_char in decl:
                     first, second = decl.split(split_char, 1)
                     first = first.rstrip()
@@ -1639,49 +1805,51 @@ class Option(Parameter):
 
         if name is None and possible_names:
             possible_names.sort(key=lambda x: -len(x[0]))  # group long options first
-            name = possible_names[0][1].replace('-', '_').lower()
+            name = possible_names[0][1].replace("-", "_").lower()
             if not isidentifier(name):
                 name = None
 
         if name is None:
             if not expose_value:
                 return None, opts, secondary_opts
-            raise TypeError('Could not determine name for option')
+            raise TypeError("Could not determine name for option")
 
         if not opts and not secondary_opts:
-            raise TypeError('No options defined but a name was passed (%s). '
-                            'Did you mean to declare an argument instead '
-                            'of an option?' % name)
+            raise TypeError(
+                "No options defined but a name was passed ({}). Did you"
+                " mean to declare an argument instead of an option?".format(name)
+            )
 
         return name, opts, secondary_opts
 
     def add_to_parser(self, parser, ctx):
         kwargs = {
-            'dest': self.name,
-            'nargs': self.nargs,
-            'obj': self,
+            "dest": self.name,
+            "nargs": self.nargs,
+            "obj": self,
         }
 
         if self.multiple:
-            action = 'append'
+            action = "append"
         elif self.count:
-            action = 'count'
+            action = "count"
         else:
-            action = 'store'
+            action = "store"
 
         if self.is_flag:
-            kwargs.pop('nargs', None)
+            kwargs.pop("nargs", None)
+            action_const = "{}_const".format(action)
             if self.is_bool_flag and self.secondary_opts:
-                parser.add_option(self.opts, action=action + '_const',
-                                  const=True, **kwargs)
-                parser.add_option(self.secondary_opts, action=action +
-                                  '_const', const=False, **kwargs)
+                parser.add_option(self.opts, action=action_const, const=True, **kwargs)
+                parser.add_option(
+                    self.secondary_opts, action=action_const, const=False, **kwargs
+                )
             else:
-                parser.add_option(self.opts, action=action + '_const',
-                                  const=self.flag_value,
-                                  **kwargs)
+                parser.add_option(
+                    self.opts, action=action_const, const=self.flag_value, **kwargs
+                )
         else:
-            kwargs['action'] = action
+            kwargs["action"] = action
             parser.add_option(self.opts, **kwargs)
 
     def get_help_record(self, ctx):
@@ -1694,46 +1862,50 @@ class Option(Parameter):
             if any_slashes:
                 any_prefix_is_slash[:] = [True]
             if not self.is_flag and not self.count:
-                rv += ' ' + self.make_metavar()
+                rv += " {}".format(self.make_metavar())
             return rv
 
         rv = [_write_opts(self.opts)]
         if self.secondary_opts:
             rv.append(_write_opts(self.secondary_opts))
 
-        help = self.help or ''
+        help = self.help or ""
         extra = []
         if self.show_envvar:
             envvar = self.envvar
             if envvar is None:
-                if self.allow_from_autoenv and \
-                    ctx.auto_envvar_prefix is not None:
-                    envvar = '%s_%s' % (ctx.auto_envvar_prefix, self.name.upper())
+                if self.allow_from_autoenv and ctx.auto_envvar_prefix is not None:
+                    envvar = "{}_{}".format(ctx.auto_envvar_prefix, self.name.upper())
             if envvar is not None:
-              extra.append('env var: %s' % (
-                           ', '.join('%s' % d for d in envvar)
-                           if isinstance(envvar, (list, tuple))
-                           else envvar, ))
-        if self.default is not None and self.show_default:
+                extra.append(
+                    "env var: {}".format(
+                        ", ".join(str(d) for d in envvar)
+                        if isinstance(envvar, (list, tuple))
+                        else envvar
+                    )
+                )
+        if self.default is not None and (self.show_default or ctx.show_default):
             if isinstance(self.show_default, string_types):
-                default_string = '({})'.format(self.show_default)
+                default_string = "({})".format(self.show_default)
             elif isinstance(self.default, (list, tuple)):
-                default_string = ', '.join('%s' % d for d in self.default)
+                default_string = ", ".join(str(d) for d in self.default)
             elif inspect.isfunction(self.default):
                 default_string = "(dynamic)"
             else:
                 default_string = self.default
-            extra.append('default: {}'.format(default_string))
+            extra.append("default: {}".format(default_string))
 
         if self.required:
-            extra.append('required')
+            extra.append("required")
         if extra:
-            help = '%s[%s]' % (help and help + '  ' or '', '; '.join(extra))
+            help = "{}[{}]".format(
+                "{}  ".format(help) if help else "", "; ".join(extra)
+            )
 
-        return ((any_prefix_is_slash and '; ' or ' / ').join(rv), help)
+        return ("; " if any_prefix_is_slash else " / ").join(rv), help
 
     def get_default(self, ctx):
-        # If we're a non boolean flag out default is more complex because
+        # If we're a non boolean flag our default is more complex because
         # we need to look at all flags in the same group to figure out
         # if we're the the default one in which case we return the flag
         # value as default.
@@ -1758,18 +1930,22 @@ class Option(Parameter):
         if self.is_bool_flag:
             return confirm(self.prompt, default)
 
-        return prompt(self.prompt, default=default, type=self.type,
-                      hide_input=self.hide_input, show_choices=self.show_choices,
-                      confirmation_prompt=self.confirmation_prompt,
-                      value_proc=lambda x: self.process_value(ctx, x))
+        return prompt(
+            self.prompt,
+            default=default,
+            type=self.type,
+            hide_input=self.hide_input,
+            show_choices=self.show_choices,
+            confirmation_prompt=self.confirmation_prompt,
+            value_proc=lambda x: self.process_value(ctx, x),
+        )
 
     def resolve_envvar_value(self, ctx):
         rv = Parameter.resolve_envvar_value(self, ctx)
         if rv is not None:
             return rv
-        if self.allow_from_autoenv and \
-           ctx.auto_envvar_prefix is not None:
-            envvar = '%s_%s' % (ctx.auto_envvar_prefix, self.name.upper())
+        if self.allow_from_autoenv and ctx.auto_envvar_prefix is not None:
+            envvar = "{}_{}".format(ctx.auto_envvar_prefix, self.name.upper())
             return os.environ.get(envvar)
 
     def value_from_envvar(self, ctx):
@@ -1784,8 +1960,7 @@ class Option(Parameter):
         return rv
 
     def full_process_value(self, ctx, value):
-        if value is None and self.prompt is not None \
-           and not ctx.resilient_parsing:
+        if value is None and self.prompt is not None and not ctx.resilient_parsing:
             return self.prompt_for_value(ctx)
         return Parameter.full_process_value(self, ctx, value)
 
@@ -1797,18 +1972,20 @@ class Argument(Parameter):
 
     All parameters are passed onwards to the parameter constructor.
     """
-    param_type_name = 'argument'
+
+    param_type_name = "argument"
 
     def __init__(self, param_decls, required=None, **attrs):
         if required is None:
-            if attrs.get('default') is not None:
+            if attrs.get("default") is not None:
                 required = False
             else:
-                required = attrs.get('nargs', 1) > 0
+                required = attrs.get("nargs", 1) > 0
         Parameter.__init__(self, param_decls, required=required, **attrs)
         if self.default is not None and self.nargs < 0:
-            raise TypeError('nargs=-1 in combination with a default value '
-                            'is not supported.')
+            raise TypeError(
+                "nargs=-1 in combination with a default value is not supported."
+            )
 
     @property
     def human_readable_name(self):
@@ -1823,34 +2000,31 @@ class Argument(Parameter):
         if not var:
             var = self.name.upper()
         if not self.required:
-            var = '[%s]' % var
+            var = "[{}]".format(var)
         if self.nargs != 1:
-            var += '...'
+            var += "..."
         return var
 
     def _parse_decls(self, decls, expose_value):
         if not decls:
             if not expose_value:
                 return None, [], []
-            raise TypeError('Could not determine name for argument')
+            raise TypeError("Could not determine name for argument")
         if len(decls) == 1:
             name = arg = decls[0]
-            name = name.replace('-', '_').lower()
+            name = name.replace("-", "_").lower()
         else:
-            raise TypeError('Arguments take exactly one '
-                            'parameter declaration, got %d' % len(decls))
+            raise TypeError(
+                "Arguments take exactly one parameter declaration, got"
+                " {}".format(len(decls))
+            )
         return name, [arg], []
 
     def get_usage_pieces(self, ctx):
         return [self.make_metavar()]
 
     def get_error_hint(self, ctx):
-        return '"%s"' % self.make_metavar()
+        return repr(self.make_metavar())
 
     def add_to_parser(self, parser, ctx):
-        parser.add_argument(dest=self.name, nargs=self.nargs,
-                            obj=self)
-
-
-# Circular dependency between decorators and core
-from .decorators import command, group
+        parser.add_argument(dest=self.name, nargs=self.nargs, obj=self)
diff --git a/pipenv/vendor/click/decorators.py b/pipenv/vendor/click/decorators.py
index c57c5308..c7b5af6c 100644
--- a/pipenv/vendor/click/decorators.py
+++ b/pipenv/vendor/click/decorators.py
@@ -1,20 +1,25 @@
-import sys
 import inspect
-
+import sys
 from functools import update_wrapper
 
 from ._compat import iteritems
 from ._unicodefun import _check_for_unicode_literals
-from .utils import echo
+from .core import Argument
+from .core import Command
+from .core import Group
+from .core import Option
 from .globals import get_current_context
+from .utils import echo
 
 
 def pass_context(f):
     """Marks a callback as wanting to receive the current context
     object as first argument.
     """
+
     def new_func(*args, **kwargs):
         return f(get_current_context(), *args, **kwargs)
+
     return update_wrapper(new_func, f)
 
 
@@ -23,8 +28,10 @@ def pass_obj(f):
     context onwards (:attr:`Context.obj`).  This is useful if that object
     represents the state of a nested system.
     """
+
     def new_func(*args, **kwargs):
         return f(get_current_context().obj, *args, **kwargs)
+
     return update_wrapper(new_func, f)
 
 
@@ -50,6 +57,7 @@ def make_pass_decorator(object_type, ensure=False):
     :param ensure: if set to `True`, a new object will be created and
                    remembered on the context if it's not there yet.
     """
+
     def decorator(f):
         def new_func(*args, **kwargs):
             ctx = get_current_context()
@@ -58,35 +66,41 @@ def make_pass_decorator(object_type, ensure=False):
             else:
                 obj = ctx.find_object(object_type)
             if obj is None:
-                raise RuntimeError('Managed to invoke callback without a '
-                                   'context object of type %r existing'
-                                   % object_type.__name__)
+                raise RuntimeError(
+                    "Managed to invoke callback without a context"
+                    " object of type '{}' existing".format(object_type.__name__)
+                )
             return ctx.invoke(f, obj, *args, **kwargs)
+
         return update_wrapper(new_func, f)
+
     return decorator
 
 
 def _make_command(f, name, attrs, cls):
     if isinstance(f, Command):
-        raise TypeError('Attempted to convert a callback into a '
-                        'command twice.')
+        raise TypeError("Attempted to convert a callback into a command twice.")
     try:
         params = f.__click_params__
         params.reverse()
         del f.__click_params__
     except AttributeError:
         params = []
-    help = attrs.get('help')
+    help = attrs.get("help")
     if help is None:
         help = inspect.getdoc(f)
         if isinstance(help, bytes):
-            help = help.decode('utf-8')
+            help = help.decode("utf-8")
     else:
         help = inspect.cleandoc(help)
-    attrs['help'] = help
+    attrs["help"] = help
     _check_for_unicode_literals()
-    return cls(name=name or f.__name__.lower().replace('_', '-'),
-               callback=f, params=params, **attrs)
+    return cls(
+        name=name or f.__name__.lower().replace("_", "-"),
+        callback=f,
+        params=params,
+        **attrs
+    )
 
 
 def command(name=None, cls=None, **attrs):
@@ -94,9 +108,9 @@ def command(name=None, cls=None, **attrs):
     callback.  This will also automatically attach all decorated
     :func:`option`\s and :func:`argument`\s as parameters to the command.
 
-    The name of the command defaults to the name of the function.  If you
-    want to change that, you can pass the intended name as the first
-    argument.
+    The name of the command defaults to the name of the function with
+    underscores replaced by dashes.  If you want to change that, you can
+    pass the intended name as the first argument.
 
     All keyword arguments are forwarded to the underlying command class.
 
@@ -111,10 +125,12 @@ def command(name=None, cls=None, **attrs):
     """
     if cls is None:
         cls = Command
+
     def decorator(f):
         cmd = _make_command(f, name, attrs, cls)
         cmd.__doc__ = f.__doc__
         return cmd
+
     return decorator
 
 
@@ -123,7 +139,7 @@ def group(name=None, **attrs):
     works otherwise the same as :func:`command` just that the `cls`
     parameter is set to :class:`Group`.
     """
-    attrs.setdefault('cls', Group)
+    attrs.setdefault("cls", Group)
     return command(name, **attrs)
 
 
@@ -131,7 +147,7 @@ def _param_memo(f, param):
     if isinstance(f, Command):
         f.params.append(param)
     else:
-        if not hasattr(f, '__click_params__'):
+        if not hasattr(f, "__click_params__"):
             f.__click_params__ = []
         f.__click_params__.append(param)
 
@@ -146,10 +162,12 @@ def argument(*param_decls, **attrs):
     :param cls: the argument class to instantiate.  This defaults to
                 :class:`Argument`.
     """
+
     def decorator(f):
-        ArgumentClass = attrs.pop('cls', Argument)
+        ArgumentClass = attrs.pop("cls", Argument)
         _param_memo(f, ArgumentClass(param_decls, **attrs))
         return f
+
     return decorator
 
 
@@ -163,15 +181,17 @@ def option(*param_decls, **attrs):
     :param cls: the option class to instantiate.  This defaults to
                 :class:`Option`.
     """
+
     def decorator(f):
         # Issue 926, copy attrs, so pre-defined options can re-use the same cls=
         option_attrs = attrs.copy()
 
-        if 'help' in option_attrs:
-            option_attrs['help'] = inspect.cleandoc(option_attrs['help'])
-        OptionClass = option_attrs.pop('cls', Option)
+        if "help" in option_attrs:
+            option_attrs["help"] = inspect.cleandoc(option_attrs["help"])
+        OptionClass = option_attrs.pop("cls", Option)
         _param_memo(f, OptionClass(param_decls, **option_attrs))
         return f
+
     return decorator
 
 
@@ -192,16 +212,19 @@ def confirmation_option(*param_decls, **attrs):
         def dropdb():
             pass
     """
+
     def decorator(f):
         def callback(ctx, param, value):
             if not value:
                 ctx.abort()
-        attrs.setdefault('is_flag', True)
-        attrs.setdefault('callback', callback)
-        attrs.setdefault('expose_value', False)
-        attrs.setdefault('prompt', 'Do you want to continue?')
-        attrs.setdefault('help', 'Confirm the action without prompting.')
-        return option(*(param_decls or ('--yes',)), **attrs)(f)
+
+        attrs.setdefault("is_flag", True)
+        attrs.setdefault("callback", callback)
+        attrs.setdefault("expose_value", False)
+        attrs.setdefault("prompt", "Do you want to continue?")
+        attrs.setdefault("help", "Confirm the action without prompting.")
+        return option(*(param_decls or ("--yes",)), **attrs)(f)
+
     return decorator
 
 
@@ -217,11 +240,13 @@ def password_option(*param_decls, **attrs):
         def changeadmin(password):
             pass
     """
+
     def decorator(f):
-        attrs.setdefault('prompt', True)
-        attrs.setdefault('confirmation_prompt', True)
-        attrs.setdefault('hide_input', True)
-        return option(*(param_decls or ('--password',)), **attrs)(f)
+        attrs.setdefault("prompt", True)
+        attrs.setdefault("confirmation_prompt", True)
+        attrs.setdefault("hide_input", True)
+        return option(*(param_decls or ("--password",)), **attrs)(f)
+
     return decorator
 
 
@@ -238,14 +263,14 @@ def version_option(version=None, *param_decls, **attrs):
     :param others: everything else is forwarded to :func:`option`.
     """
     if version is None:
-        if hasattr(sys, '_getframe'):
-            module = sys._getframe(1).f_globals.get('__name__')
+        if hasattr(sys, "_getframe"):
+            module = sys._getframe(1).f_globals.get("__name__")
         else:
-            module = ''
+            module = ""
 
     def decorator(f):
-        prog_name = attrs.pop('prog_name', None)
-        message = attrs.pop('message', '%(prog)s, version %(version)s')
+        prog_name = attrs.pop("prog_name", None)
+        message = attrs.pop("message", "%(prog)s, version %(version)s")
 
         def callback(ctx, param, value):
             if not value or ctx.resilient_parsing:
@@ -261,25 +286,23 @@ def version_option(version=None, *param_decls, **attrs):
                     pass
                 else:
                     for dist in pkg_resources.working_set:
-                        scripts = dist.get_entry_map().get('console_scripts') or {}
-                        for script_name, entry_point in iteritems(scripts):
+                        scripts = dist.get_entry_map().get("console_scripts") or {}
+                        for _, entry_point in iteritems(scripts):
                             if entry_point.module_name == module:
                                 ver = dist.version
                                 break
                 if ver is None:
-                    raise RuntimeError('Could not determine version')
-            echo(message % {
-                'prog': prog,
-                'version': ver,
-            }, color=ctx.color)
+                    raise RuntimeError("Could not determine version")
+            echo(message % {"prog": prog, "version": ver}, color=ctx.color)
             ctx.exit()
 
-        attrs.setdefault('is_flag', True)
-        attrs.setdefault('expose_value', False)
-        attrs.setdefault('is_eager', True)
-        attrs.setdefault('help', 'Show the version and exit.')
-        attrs['callback'] = callback
-        return option(*(param_decls or ('--version',)), **attrs)(f)
+        attrs.setdefault("is_flag", True)
+        attrs.setdefault("expose_value", False)
+        attrs.setdefault("is_eager", True)
+        attrs.setdefault("help", "Show the version and exit.")
+        attrs["callback"] = callback
+        return option(*(param_decls or ("--version",)), **attrs)(f)
+
     return decorator
 
 
@@ -293,19 +316,18 @@ def help_option(*param_decls, **attrs):
 
     All arguments are forwarded to :func:`option`.
     """
+
     def decorator(f):
         def callback(ctx, param, value):
             if value and not ctx.resilient_parsing:
                 echo(ctx.get_help(), color=ctx.color)
                 ctx.exit()
-        attrs.setdefault('is_flag', True)
-        attrs.setdefault('expose_value', False)
-        attrs.setdefault('help', 'Show this message and exit.')
-        attrs.setdefault('is_eager', True)
-        attrs['callback'] = callback
-        return option(*(param_decls or ('--help',)), **attrs)(f)
-    return decorator
 
+        attrs.setdefault("is_flag", True)
+        attrs.setdefault("expose_value", False)
+        attrs.setdefault("help", "Show this message and exit.")
+        attrs.setdefault("is_eager", True)
+        attrs["callback"] = callback
+        return option(*(param_decls or ("--help",)), **attrs)(f)
 
-# Circular dependencies between core and decorators
-from .core import Command, Group, Argument, Option
+    return decorator
diff --git a/pipenv/vendor/click/exceptions.py b/pipenv/vendor/click/exceptions.py
index 6fa17658..592ee38f 100644
--- a/pipenv/vendor/click/exceptions.py
+++ b/pipenv/vendor/click/exceptions.py
@@ -1,10 +1,12 @@
-from ._compat import PY2, filename_to_ui, get_text_stderr
+from ._compat import filename_to_ui
+from ._compat import get_text_stderr
+from ._compat import PY2
 from .utils import echo
 
 
 def _join_param_hints(param_hint):
     if isinstance(param_hint, (tuple, list)):
-        return ' / '.join('"%s"' % x for x in param_hint)
+        return " / ".join(repr(x) for x in param_hint)
     return param_hint
 
 
@@ -18,7 +20,7 @@ class ClickException(Exception):
         ctor_msg = message
         if PY2:
             if ctor_msg is not None:
-                ctor_msg = ctor_msg.encode('utf-8')
+                ctor_msg = ctor_msg.encode("utf-8")
         Exception.__init__(self, ctor_msg)
         self.message = message
 
@@ -32,12 +34,12 @@ class ClickException(Exception):
         __unicode__ = __str__
 
         def __str__(self):
-            return self.message.encode('utf-8')
+            return self.message.encode("utf-8")
 
     def show(self, file=None):
         if file is None:
             file = get_text_stderr()
-        echo('Error: %s' % self.format_message(), file=file)
+        echo("Error: {}".format(self.format_message()), file=file)
 
 
 class UsageError(ClickException):
@@ -48,26 +50,27 @@ class UsageError(ClickException):
     :param ctx: optionally the context that caused this error.  Click will
                 fill in the context automatically in some situations.
     """
+
     exit_code = 2
 
     def __init__(self, message, ctx=None):
         ClickException.__init__(self, message)
         self.ctx = ctx
-        self.cmd = self.ctx and self.ctx.command or None
+        self.cmd = self.ctx.command if self.ctx else None
 
     def show(self, file=None):
         if file is None:
             file = get_text_stderr()
         color = None
-        hint = ''
-        if (self.cmd is not None and
-                self.cmd.get_help_option(self.ctx) is not None):
-            hint = ('Try "%s %s" for help.\n'
-                    % (self.ctx.command_path, self.ctx.help_option_names[0]))
+        hint = ""
+        if self.cmd is not None and self.cmd.get_help_option(self.ctx) is not None:
+            hint = "Try '{} {}' for help.\n".format(
+                self.ctx.command_path, self.ctx.help_option_names[0]
+            )
         if self.ctx is not None:
             color = self.ctx.color
-            echo(self.ctx.get_usage() + '\n%s' % hint, file=file, color=color)
-        echo('Error: %s' % self.format_message(), file=file, color=color)
+            echo("{}\n{}".format(self.ctx.get_usage(), hint), file=file, color=color)
+        echo("Error: {}".format(self.format_message()), file=file, color=color)
 
 
 class BadParameter(UsageError):
@@ -88,8 +91,7 @@ class BadParameter(UsageError):
                        each item is quoted and separated.
     """
 
-    def __init__(self, message, ctx=None, param=None,
-                 param_hint=None):
+    def __init__(self, message, ctx=None, param=None, param_hint=None):
         UsageError.__init__(self, message, ctx)
         self.param = param
         self.param_hint = param_hint
@@ -100,10 +102,10 @@ class BadParameter(UsageError):
         elif self.param is not None:
             param_hint = self.param.get_error_hint(self.ctx)
         else:
-            return 'Invalid value: %s' % self.message
+            return "Invalid value: {}".format(self.message)
         param_hint = _join_param_hints(param_hint)
 
-        return 'Invalid value for %s: %s' % (param_hint, self.message)
+        return "Invalid value for {}: {}".format(param_hint, self.message)
 
 
 class MissingParameter(BadParameter):
@@ -118,8 +120,9 @@ class MissingParameter(BadParameter):
                        ``'option'`` or ``'argument'``.
     """
 
-    def __init__(self, message=None, ctx=None, param=None,
-                 param_hint=None, param_type=None):
+    def __init__(
+        self, message=None, ctx=None, param=None, param_hint=None, param_type=None
+    ):
         BadParameter.__init__(self, message, ctx, param, param_hint)
         self.param_type = param_type
 
@@ -141,17 +144,30 @@ class MissingParameter(BadParameter):
             msg_extra = self.param.type.get_missing_message(self.param)
             if msg_extra:
                 if msg:
-                    msg += '.  ' + msg_extra
+                    msg += ".  {}".format(msg_extra)
                 else:
                     msg = msg_extra
 
-        return 'Missing %s%s%s%s' % (
+        return "Missing {}{}{}{}".format(
             param_type,
-            param_hint and ' %s' % param_hint or '',
-            msg and '.  ' or '.',
-            msg or '',
+            " {}".format(param_hint) if param_hint else "",
+            ".  " if msg else ".",
+            msg or "",
         )
 
+    def __str__(self):
+        if self.message is None:
+            param_name = self.param.name if self.param else None
+            return "missing parameter: {}".format(param_name)
+        else:
+            return self.message
+
+    if PY2:
+        __unicode__ = __str__
+
+        def __str__(self):
+            return self.__unicode__().encode("utf-8")
+
 
 class NoSuchOption(UsageError):
     """Raised if click attempted to handle an option that does not
@@ -160,10 +176,9 @@ class NoSuchOption(UsageError):
     .. versionadded:: 4.0
     """
 
-    def __init__(self, option_name, message=None, possibilities=None,
-                 ctx=None):
+    def __init__(self, option_name, message=None, possibilities=None, ctx=None):
         if message is None:
-            message = 'no such option: %s' % option_name
+            message = "no such option: {}".format(option_name)
         UsageError.__init__(self, message, ctx)
         self.option_name = option_name
         self.possibilities = possibilities
@@ -172,11 +187,11 @@ class NoSuchOption(UsageError):
         bits = [self.message]
         if self.possibilities:
             if len(self.possibilities) == 1:
-                bits.append('Did you mean %s?' % self.possibilities[0])
+                bits.append("Did you mean {}?".format(self.possibilities[0]))
             else:
                 possibilities = sorted(self.possibilities)
-                bits.append('(Possible options: %s)' % ', '.join(possibilities))
-        return '  '.join(bits)
+                bits.append("(Possible options: {})".format(", ".join(possibilities)))
+        return "  ".join(bits)
 
 
 class BadOptionUsage(UsageError):
@@ -212,13 +227,13 @@ class FileError(ClickException):
     def __init__(self, filename, hint=None):
         ui_filename = filename_to_ui(filename)
         if hint is None:
-            hint = 'unknown error'
+            hint = "unknown error"
         ClickException.__init__(self, hint)
         self.ui_filename = ui_filename
         self.filename = filename
 
     def format_message(self):
-        return 'Could not open file %s: %s' % (self.ui_filename, self.message)
+        return "Could not open file {}: {}".format(self.ui_filename, self.message)
 
 
 class Abort(RuntimeError):
@@ -231,5 +246,8 @@ class Exit(RuntimeError):
 
     :param code: the status code to exit with.
     """
+
+    __slots__ = ("exit_code",)
+
     def __init__(self, code=0):
         self.exit_code = code
diff --git a/pipenv/vendor/click/formatting.py b/pipenv/vendor/click/formatting.py
index a3d6a4d3..319c7f61 100644
--- a/pipenv/vendor/click/formatting.py
+++ b/pipenv/vendor/click/formatting.py
@@ -1,8 +1,8 @@
 from contextlib import contextmanager
-from .termui import get_terminal_size
-from .parser import split_opt
-from ._compat import term_len
 
+from ._compat import term_len
+from .parser import split_opt
+from .termui import get_terminal_size
 
 # Can force a width.  This is used by the test system
 FORCED_WIDTH = None
@@ -19,11 +19,12 @@ def measure_table(rows):
 def iter_rows(rows, col_count):
     for row in rows:
         row = tuple(row)
-        yield row + ('',) * (col_count - len(row))
+        yield row + ("",) * (col_count - len(row))
 
 
-def wrap_text(text, width=78, initial_indent='', subsequent_indent='',
-              preserve_paragraphs=False):
+def wrap_text(
+    text, width=78, initial_indent="", subsequent_indent="", preserve_paragraphs=False
+):
     """A helper function that intelligently wraps text.  By default, it
     assumes that it operates on a single paragraph of text but if the
     `preserve_paragraphs` parameter is provided it will intelligently
@@ -43,10 +44,14 @@ def wrap_text(text, width=78, initial_indent='', subsequent_indent='',
                                 intelligently handle paragraphs.
     """
     from ._textwrap import TextWrapper
+
     text = text.expandtabs()
-    wrapper = TextWrapper(width, initial_indent=initial_indent,
-                          subsequent_indent=subsequent_indent,
-                          replace_whitespace=False)
+    wrapper = TextWrapper(
+        width,
+        initial_indent=initial_indent,
+        subsequent_indent=subsequent_indent,
+        replace_whitespace=False,
+    )
     if not preserve_paragraphs:
         return wrapper.fill(text)
 
@@ -57,10 +62,10 @@ def wrap_text(text, width=78, initial_indent='', subsequent_indent='',
     def _flush_par():
         if not buf:
             return
-        if buf[0].strip() == '\b':
-            p.append((indent or 0, True, '\n'.join(buf[1:])))
+        if buf[0].strip() == "\b":
+            p.append((indent or 0, True, "\n".join(buf[1:])))
         else:
-            p.append((indent or 0, False, ' '.join(buf)))
+            p.append((indent or 0, False, " ".join(buf)))
         del buf[:]
 
     for line in text.splitlines():
@@ -77,13 +82,13 @@ def wrap_text(text, width=78, initial_indent='', subsequent_indent='',
 
     rv = []
     for indent, raw, text in p:
-        with wrapper.extra_indent(' ' * indent):
+        with wrapper.extra_indent(" " * indent):
             if raw:
                 rv.append(wrapper.indent_only(text))
             else:
                 rv.append(wrapper.fill(text))
 
-    return '\n\n'.join(rv)
+    return "\n\n".join(rv)
 
 
 class HelpFormatter(object):
@@ -122,53 +127,65 @@ class HelpFormatter(object):
         """Decreases the indentation."""
         self.current_indent -= self.indent_increment
 
-    def write_usage(self, prog, args='', prefix='Usage: '):
+    def write_usage(self, prog, args="", prefix="Usage: "):
         """Writes a usage line into the buffer.
 
         :param prog: the program name.
         :param args: whitespace separated list of arguments.
         :param prefix: the prefix for the first line.
         """
-        usage_prefix = '%*s%s ' % (self.current_indent, prefix, prog)
+        usage_prefix = "{:>{w}}{} ".format(prefix, prog, w=self.current_indent)
         text_width = self.width - self.current_indent
 
         if text_width >= (term_len(usage_prefix) + 20):
             # The arguments will fit to the right of the prefix.
-            indent = ' ' * term_len(usage_prefix)
-            self.write(wrap_text(args, text_width,
-                                 initial_indent=usage_prefix,
-                                 subsequent_indent=indent))
+            indent = " " * term_len(usage_prefix)
+            self.write(
+                wrap_text(
+                    args,
+                    text_width,
+                    initial_indent=usage_prefix,
+                    subsequent_indent=indent,
+                )
+            )
         else:
             # The prefix is too long, put the arguments on the next line.
             self.write(usage_prefix)
-            self.write('\n')
-            indent = ' ' * (max(self.current_indent, term_len(prefix)) + 4)
-            self.write(wrap_text(args, text_width,
-                                 initial_indent=indent,
-                                 subsequent_indent=indent))
+            self.write("\n")
+            indent = " " * (max(self.current_indent, term_len(prefix)) + 4)
+            self.write(
+                wrap_text(
+                    args, text_width, initial_indent=indent, subsequent_indent=indent
+                )
+            )
 
-        self.write('\n')
+        self.write("\n")
 
     def write_heading(self, heading):
         """Writes a heading into the buffer."""
-        self.write('%*s%s:\n' % (self.current_indent, '', heading))
+        self.write("{:>{w}}{}:\n".format("", heading, w=self.current_indent))
 
     def write_paragraph(self):
         """Writes a paragraph into the buffer."""
         if self.buffer:
-            self.write('\n')
+            self.write("\n")
 
     def write_text(self, text):
         """Writes re-indented text into the buffer.  This rewraps and
         preserves paragraphs.
         """
         text_width = max(self.width - self.current_indent, 11)
-        indent = ' ' * self.current_indent
-        self.write(wrap_text(text, text_width,
-                             initial_indent=indent,
-                             subsequent_indent=indent,
-                             preserve_paragraphs=True))
-        self.write('\n')
+        indent = " " * self.current_indent
+        self.write(
+            wrap_text(
+                text,
+                text_width,
+                initial_indent=indent,
+                subsequent_indent=indent,
+                preserve_paragraphs=True,
+            )
+        )
+        self.write("\n")
 
     def write_dl(self, rows, col_max=30, col_spacing=2):
         """Writes a definition list into the buffer.  This is how options
@@ -182,30 +199,40 @@ class HelpFormatter(object):
         rows = list(rows)
         widths = measure_table(rows)
         if len(widths) != 2:
-            raise TypeError('Expected two columns for definition list')
+            raise TypeError("Expected two columns for definition list")
 
         first_col = min(widths[0], col_max) + col_spacing
 
         for first, second in iter_rows(rows, len(widths)):
-            self.write('%*s%s' % (self.current_indent, '', first))
+            self.write("{:>{w}}{}".format("", first, w=self.current_indent))
             if not second:
-                self.write('\n')
+                self.write("\n")
                 continue
             if term_len(first) <= first_col - col_spacing:
-                self.write(' ' * (first_col - term_len(first)))
+                self.write(" " * (first_col - term_len(first)))
             else:
-                self.write('\n')
-                self.write(' ' * (first_col + self.current_indent))
+                self.write("\n")
+                self.write(" " * (first_col + self.current_indent))
 
             text_width = max(self.width - first_col - 2, 10)
-            lines = iter(wrap_text(second, text_width).splitlines())
+            wrapped_text = wrap_text(second, text_width, preserve_paragraphs=True)
+            lines = wrapped_text.splitlines()
+
             if lines:
-                self.write(next(lines) + '\n')
-                for line in lines:
-                    self.write('%*s%s\n' % (
-                        first_col + self.current_indent, '', line))
+                self.write("{}\n".format(lines[0]))
+
+                for line in lines[1:]:
+                    self.write(
+                        "{:>{w}}{}\n".format(
+                            "", line, w=first_col + self.current_indent
+                        )
+                    )
+
+                if len(lines) > 1:
+                    # separate long help from next option
+                    self.write("\n")
             else:
-                self.write('\n')
+                self.write("\n")
 
     @contextmanager
     def section(self, name):
@@ -233,7 +260,7 @@ class HelpFormatter(object):
 
     def getvalue(self):
         """Returns the buffer contents."""
-        return ''.join(self.buffer)
+        return "".join(self.buffer)
 
 
 def join_options(options):
@@ -246,11 +273,11 @@ def join_options(options):
     any_prefix_is_slash = False
     for opt in options:
         prefix = split_opt(opt)[0]
-        if prefix == '/':
+        if prefix == "/":
             any_prefix_is_slash = True
         rv.append((len(prefix), opt))
 
     rv.sort(key=lambda x: x[0])
 
-    rv = ', '.join(x[1] for x in rv)
+    rv = ", ".join(x[1] for x in rv)
     return rv, any_prefix_is_slash
diff --git a/pipenv/vendor/click/globals.py b/pipenv/vendor/click/globals.py
index 843b594a..1649f9a0 100644
--- a/pipenv/vendor/click/globals.py
+++ b/pipenv/vendor/click/globals.py
@@ -1,6 +1,5 @@
 from threading import local
 
-
 _local = local()
 
 
@@ -15,20 +14,20 @@ def get_current_context(silent=False):
 
     .. versionadded:: 5.0
 
-    :param silent: is set to `True` the return value is `None` if no context
+    :param silent: if set to `True` the return value is `None` if no context
                    is available.  The default behavior is to raise a
                    :exc:`RuntimeError`.
     """
     try:
-        return getattr(_local, 'stack')[-1]
+        return _local.stack[-1]
     except (AttributeError, IndexError):
         if not silent:
-            raise RuntimeError('There is no active click context.')
+            raise RuntimeError("There is no active click context.")
 
 
 def push_context(ctx):
     """Pushes a new context to the current stack."""
-    _local.__dict__.setdefault('stack', []).append(ctx)
+    _local.__dict__.setdefault("stack", []).append(ctx)
 
 
 def pop_context():
diff --git a/pipenv/vendor/click/parser.py b/pipenv/vendor/click/parser.py
index 1c3ae9c8..f43ebfe9 100644
--- a/pipenv/vendor/click/parser.py
+++ b/pipenv/vendor/click/parser.py
@@ -1,8 +1,5 @@
 # -*- coding: utf-8 -*-
 """
-click.parser
-~~~~~~~~~~~~
-
 This module started out as largely a copy paste from the stdlib's
 optparse module with the features removed that we do not need from
 optparse because we implement them in Click on a higher level (for
@@ -14,12 +11,20 @@ The reason this is a different module and not optparse from the stdlib
 is that there are differences in 2.x and 3.x about the error messages
 generated and optparse in the stdlib uses gettext for no good reason
 and might cause us issues.
-"""
 
+Click uses parts of optparse written by Gregory P. Ward and maintained
+by the Python Software Foundation. This is limited to code in parser.py.
+
+Copyright 2001-2006 Gregory P. Ward. All rights reserved.
+Copyright 2002-2006 Python Software Foundation. All rights reserved.
+"""
 import re
 from collections import deque
-from .exceptions import UsageError, NoSuchOption, BadOptionUsage, \
-     BadArgumentUsage
+
+from .exceptions import BadArgumentUsage
+from .exceptions import BadOptionUsage
+from .exceptions import NoSuchOption
+from .exceptions import UsageError
 
 
 def _unpack_args(args, nargs_spec):
@@ -59,7 +64,7 @@ def _unpack_args(args, nargs_spec):
             rv.append(tuple(x))
         elif nargs < 0:
             if spos is not None:
-                raise TypeError('Cannot have two nargs < 0')
+                raise TypeError("Cannot have two nargs < 0")
             spos = len(rv)
             rv.append(None)
 
@@ -68,21 +73,21 @@ def _unpack_args(args, nargs_spec):
     if spos is not None:
         rv[spos] = tuple(args)
         args = []
-        rv[spos + 1:] = reversed(rv[spos + 1:])
+        rv[spos + 1 :] = reversed(rv[spos + 1 :])
 
     return tuple(rv), list(args)
 
 
 def _error_opt_args(nargs, opt):
     if nargs == 1:
-        raise BadOptionUsage(opt, '%s option requires an argument' % opt)
-    raise BadOptionUsage(opt, '%s option requires %d arguments' % (opt, nargs))
+        raise BadOptionUsage(opt, "{} option requires an argument".format(opt))
+    raise BadOptionUsage(opt, "{} option requires {} arguments".format(opt, nargs))
 
 
 def split_opt(opt):
     first = opt[:1]
     if first.isalnum():
-        return '', opt
+        return "", opt
     if opt[1:2] == first:
         return opt[:2], opt[2:]
     return first, opt[1:]
@@ -98,13 +103,14 @@ def normalize_opt(opt, ctx):
 def split_arg_string(string):
     """Given an argument string this attempts to split it into small parts."""
     rv = []
-    for match in re.finditer(r"('([^'\\]*(?:\\.[^'\\]*)*)'"
-                             r'|"([^"\\]*(?:\\.[^"\\]*)*)"'
-                             r'|\S+)\s*', string, re.S):
+    for match in re.finditer(
+        r"('([^'\\]*(?:\\.[^'\\]*)*)'|\"([^\"\\]*(?:\\.[^\"\\]*)*)\"|\S+)\s*",
+        string,
+        re.S,
+    ):
         arg = match.group().strip()
-        if arg[:1] == arg[-1:] and arg[:1] in '"\'':
-            arg = arg[1:-1].encode('ascii', 'backslashreplace') \
-                .decode('unicode-escape')
+        if arg[:1] == arg[-1:] and arg[:1] in "\"'":
+            arg = arg[1:-1].encode("ascii", "backslashreplace").decode("unicode-escape")
         try:
             arg = type(string)(arg)
         except UnicodeError:
@@ -114,7 +120,6 @@ def split_arg_string(string):
 
 
 class Option(object):
-
     def __init__(self, opts, dest, action=None, nargs=1, const=None, obj=None):
         self._short_opts = []
         self._long_opts = []
@@ -123,8 +128,7 @@ class Option(object):
         for opt in opts:
             prefix, value = split_opt(opt)
             if not prefix:
-                raise ValueError('Invalid start character for option (%s)'
-                                 % opt)
+                raise ValueError("Invalid start character for option ({})".format(opt))
             self.prefixes.add(prefix[0])
             if len(prefix) == 1 and len(value) == 1:
                 self._short_opts.append(opt)
@@ -133,7 +137,7 @@ class Option(object):
                 self.prefixes.add(prefix)
 
         if action is None:
-            action = 'store'
+            action = "store"
 
         self.dest = dest
         self.action = action
@@ -143,26 +147,25 @@ class Option(object):
 
     @property
     def takes_value(self):
-        return self.action in ('store', 'append')
+        return self.action in ("store", "append")
 
     def process(self, value, state):
-        if self.action == 'store':
+        if self.action == "store":
             state.opts[self.dest] = value
-        elif self.action == 'store_const':
+        elif self.action == "store_const":
             state.opts[self.dest] = self.const
-        elif self.action == 'append':
+        elif self.action == "append":
             state.opts.setdefault(self.dest, []).append(value)
-        elif self.action == 'append_const':
+        elif self.action == "append_const":
             state.opts.setdefault(self.dest, []).append(self.const)
-        elif self.action == 'count':
+        elif self.action == "count":
             state.opts[self.dest] = state.opts.get(self.dest, 0) + 1
         else:
-            raise ValueError('unknown action %r' % self.action)
+            raise ValueError("unknown action '{}'".format(self.action))
         state.order.append(self.obj)
 
 
 class Argument(object):
-
     def __init__(self, dest, nargs=1, obj=None):
         self.dest = dest
         self.nargs = nargs
@@ -174,14 +177,14 @@ class Argument(object):
             if holes == len(value):
                 value = None
             elif holes != 0:
-                raise BadArgumentUsage('argument %s takes %d values'
-                                       % (self.dest, self.nargs))
+                raise BadArgumentUsage(
+                    "argument {} takes {} values".format(self.dest, self.nargs)
+                )
         state.opts[self.dest] = value
         state.order.append(self.obj)
 
 
 class ParsingState(object):
-
     def __init__(self, rargs):
         self.opts = {}
         self.largs = []
@@ -222,11 +225,10 @@ class OptionParser(object):
             self.ignore_unknown_options = ctx.ignore_unknown_options
         self._short_opt = {}
         self._long_opt = {}
-        self._opt_prefixes = set(['-', '--'])
+        self._opt_prefixes = {"-", "--"}
         self._args = []
 
-    def add_option(self, opts, dest, action=None, nargs=1, const=None,
-                   obj=None):
+    def add_option(self, opts, dest, action=None, nargs=1, const=None, obj=None):
         """Adds a new option named `dest` to the parser.  The destination
         is not inferred (unlike with optparse) and needs to be explicitly
         provided.  Action can be any of ``store``, ``store_const``,
@@ -238,8 +240,7 @@ class OptionParser(object):
         if obj is None:
             obj = dest
         opts = [normalize_opt(opt, self.ctx) for opt in opts]
-        option = Option(opts, dest, action=action, nargs=nargs,
-                        const=const, obj=obj)
+        option = Option(opts, dest, action=action, nargs=nargs, const=const, obj=obj)
         self._opt_prefixes.update(option.prefixes)
         for opt in option._short_opts:
             self._short_opt[opt] = option
@@ -273,8 +274,9 @@ class OptionParser(object):
         return state.opts, state.largs, state.order
 
     def _process_args_for_args(self, state):
-        pargs, args = _unpack_args(state.largs + state.rargs,
-                                   [x.nargs for x in self._args])
+        pargs, args = _unpack_args(
+            state.largs + state.rargs, [x.nargs for x in self._args]
+        )
 
         for idx, arg in enumerate(self._args):
             arg.process(pargs[idx], state)
@@ -288,7 +290,7 @@ class OptionParser(object):
             arglen = len(arg)
             # Double dashes always handled explicitly regardless of what
             # prefixes are valid.
-            if arg == '--':
+            if arg == "--":
                 return
             elif arg[:1] in self._opt_prefixes and arglen > 1:
                 self._process_opts(arg, state)
@@ -320,8 +322,7 @@ class OptionParser(object):
 
     def _match_long_opt(self, opt, explicit_value, state):
         if opt not in self._long_opt:
-            possibilities = [word for word in self._long_opt
-                             if word.startswith(opt)]
+            possibilities = [word for word in self._long_opt if word.startswith(opt)]
             raise NoSuchOption(opt, possibilities=possibilities, ctx=self.ctx)
 
         option = self._long_opt[opt]
@@ -343,7 +344,7 @@ class OptionParser(object):
                 del state.rargs[:nargs]
 
         elif explicit_value is not None:
-            raise BadOptionUsage(opt, '%s option does not take a value' % opt)
+            raise BadOptionUsage(opt, "{} option does not take a value".format(opt))
 
         else:
             value = None
@@ -395,15 +396,15 @@ class OptionParser(object):
         # to the state as new larg.  This way there is basic combinatorics
         # that can be achieved while still ignoring unknown arguments.
         if self.ignore_unknown_options and unknown_options:
-            state.largs.append(prefix + ''.join(unknown_options))
+            state.largs.append("{}{}".format(prefix, "".join(unknown_options)))
 
     def _process_opts(self, arg, state):
         explicit_value = None
         # Long option handling happens in two parts.  The first part is
         # supporting explicitly attached values.  In any case, we will try
         # to long match the option first.
-        if '=' in arg:
-            long_opt, explicit_value = arg.split('=', 1)
+        if "=" in arg:
+            long_opt, explicit_value = arg.split("=", 1)
         else:
             long_opt = arg
         norm_long_opt = normalize_opt(long_opt, self.ctx)
diff --git a/pipenv/vendor/click/termui.py b/pipenv/vendor/click/termui.py
index bf9a3aa1..02ef9e9f 100644
--- a/pipenv/vendor/click/termui.py
+++ b/pipenv/vendor/click/termui.py
@@ -1,60 +1,89 @@
-import os
-import sys
-import struct
 import inspect
+import io
 import itertools
+import os
+import struct
+import sys
 
-from ._compat import raw_input, text_type, string_types, \
-     isatty, strip_ansi, get_winterm_size, DEFAULT_COLUMNS, WIN
-from .utils import echo
-from .exceptions import Abort, UsageError
-from .types import convert_type, Choice, Path
+from ._compat import DEFAULT_COLUMNS
+from ._compat import get_winterm_size
+from ._compat import isatty
+from ._compat import raw_input
+from ._compat import string_types
+from ._compat import strip_ansi
+from ._compat import text_type
+from ._compat import WIN
+from .exceptions import Abort
+from .exceptions import UsageError
 from .globals import resolve_color_default
-
+from .types import Choice
+from .types import convert_type
+from .types import Path
+from .utils import echo
+from .utils import LazyFile
 
 # The prompt functions to use.  The doc tools currently override these
 # functions to customize how they work.
 visible_prompt_func = raw_input
 
 _ansi_colors = {
-    'black': 30,
-    'red': 31,
-    'green': 32,
-    'yellow': 33,
-    'blue': 34,
-    'magenta': 35,
-    'cyan': 36,
-    'white': 37,
-    'reset': 39,
-    'bright_black': 90,
-    'bright_red': 91,
-    'bright_green': 92,
-    'bright_yellow': 93,
-    'bright_blue': 94,
-    'bright_magenta': 95,
-    'bright_cyan': 96,
-    'bright_white': 97,
+    "black": 30,
+    "red": 31,
+    "green": 32,
+    "yellow": 33,
+    "blue": 34,
+    "magenta": 35,
+    "cyan": 36,
+    "white": 37,
+    "reset": 39,
+    "bright_black": 90,
+    "bright_red": 91,
+    "bright_green": 92,
+    "bright_yellow": 93,
+    "bright_blue": 94,
+    "bright_magenta": 95,
+    "bright_cyan": 96,
+    "bright_white": 97,
 }
-_ansi_reset_all = '\033[0m'
+_ansi_reset_all = "\033[0m"
 
 
 def hidden_prompt_func(prompt):
     import getpass
+
     return getpass.getpass(prompt)
 
 
-def _build_prompt(text, suffix, show_default=False, default=None, show_choices=True, type=None):
+def _build_prompt(
+    text, suffix, show_default=False, default=None, show_choices=True, type=None
+):
     prompt = text
     if type is not None and show_choices and isinstance(type, Choice):
-        prompt += ' (' + ", ".join(map(str, type.choices)) + ')'
+        prompt += " ({})".format(", ".join(map(str, type.choices)))
     if default is not None and show_default:
-        prompt = '%s [%s]' % (prompt, default)
+        prompt = "{} [{}]".format(prompt, _format_default(default))
     return prompt + suffix
 
 
-def prompt(text, default=None, hide_input=False, confirmation_prompt=False,
-           type=None, value_proc=None, prompt_suffix=': ', show_default=True,
-           err=False, show_choices=True):
+def _format_default(default):
+    if isinstance(default, (io.IOBase, LazyFile)) and hasattr(default, "name"):
+        return default.name
+
+    return default
+
+
+def prompt(
+    text,
+    default=None,
+    hide_input=False,
+    confirmation_prompt=False,
+    type=None,
+    value_proc=None,
+    prompt_suffix=": ",
+    show_default=True,
+    err=False,
+    show_choices=True,
+):
     """Prompts a user for input.  This is a convenience function that can
     be used to prompt a user for input later.
 
@@ -92,12 +121,12 @@ def prompt(text, default=None, hide_input=False, confirmation_prompt=False,
     result = None
 
     def prompt_func(text):
-        f = hide_input and hidden_prompt_func or visible_prompt_func
+        f = hidden_prompt_func if hide_input else visible_prompt_func
         try:
             # Write the prompt separately so that we get nice
             # coloring through colorama on Windows
             echo(text, nl=False, err=err)
-            return f('')
+            return f("")
         except (KeyboardInterrupt, EOFError):
             # getpass doesn't print a newline if the user aborts input with ^C.
             # Allegedly this behavior is inherited from getpass(3).
@@ -109,7 +138,9 @@ def prompt(text, default=None, hide_input=False, confirmation_prompt=False,
     if value_proc is None:
         value_proc = convert_type(type, default)
 
-    prompt = _build_prompt(text, prompt_suffix, show_default, default, show_choices, type)
+    prompt = _build_prompt(
+        text, prompt_suffix, show_default, default, show_choices, type
+    )
 
     while 1:
         while 1:
@@ -125,21 +156,22 @@ def prompt(text, default=None, hide_input=False, confirmation_prompt=False,
         try:
             result = value_proc(value)
         except UsageError as e:
-            echo('Error: %s' % e.message, err=err)
+            echo("Error: {}".format(e.message), err=err)  # noqa: B306
             continue
         if not confirmation_prompt:
             return result
         while 1:
-            value2 = prompt_func('Repeat for confirmation: ')
+            value2 = prompt_func("Repeat for confirmation: ")
             if value2:
                 break
         if value == value2:
             return result
-        echo('Error: the two entered values do not match', err=err)
+        echo("Error: the two entered values do not match", err=err)
 
 
-def confirm(text, default=False, abort=False, prompt_suffix=': ',
-            show_default=True, err=False):
+def confirm(
+    text, default=False, abort=False, prompt_suffix=": ", show_default=True, err=False
+):
     """Prompts for confirmation (yes/no question).
 
     If the user aborts the input by sending a interrupt signal this
@@ -157,24 +189,25 @@ def confirm(text, default=False, abort=False, prompt_suffix=': ',
     :param err: if set to true the file defaults to ``stderr`` instead of
                 ``stdout``, the same as with echo.
     """
-    prompt = _build_prompt(text, prompt_suffix, show_default,
-                           default and 'Y/n' or 'y/N')
+    prompt = _build_prompt(
+        text, prompt_suffix, show_default, "Y/n" if default else "y/N"
+    )
     while 1:
         try:
             # Write the prompt separately so that we get nice
             # coloring through colorama on Windows
             echo(prompt, nl=False, err=err)
-            value = visible_prompt_func('').lower().strip()
+            value = visible_prompt_func("").lower().strip()
         except (KeyboardInterrupt, EOFError):
             raise Abort()
-        if value in ('y', 'yes'):
+        if value in ("y", "yes"):
             rv = True
-        elif value in ('n', 'no'):
+        elif value in ("n", "no"):
             rv = False
-        elif value == '':
+        elif value == "":
             rv = default
         else:
-            echo('Error: invalid input', err=err)
+            echo("Error: invalid input", err=err)
             continue
         break
     if abort and not rv:
@@ -189,7 +222,8 @@ def get_terminal_size():
     # If shutil has get_terminal_size() (Python 3.3 and later) use that
     if sys.version_info >= (3, 3):
         import shutil
-        shutil_get_terminal_size = getattr(shutil, 'get_terminal_size', None)
+
+        shutil_get_terminal_size = getattr(shutil, "get_terminal_size", None)
         if shutil_get_terminal_size:
             sz = shutil_get_terminal_size()
             return sz.columns, sz.lines
@@ -207,8 +241,8 @@ def get_terminal_size():
         try:
             import fcntl
             import termios
-            cr = struct.unpack(
-                'hh', fcntl.ioctl(fd, termios.TIOCGWINSZ, '1234'))
+
+            cr = struct.unpack("hh", fcntl.ioctl(fd, termios.TIOCGWINSZ, "1234"))
         except Exception:
             return
         return cr
@@ -224,8 +258,7 @@ def get_terminal_size():
         except Exception:
             pass
     if not cr or not cr[0] or not cr[1]:
-        cr = (os.environ.get('LINES', 25),
-              os.environ.get('COLUMNS', DEFAULT_COLUMNS))
+        cr = (os.environ.get("LINES", 25), os.environ.get("COLUMNS", DEFAULT_COLUMNS))
     return int(cr[1]), int(cr[0])
 
 
@@ -251,18 +284,29 @@ def echo_via_pager(text_or_generator, color=None):
         i = iter(text_or_generator)
 
     # convert every element of i to a text type if necessary
-    text_generator = (el if isinstance(el, string_types) else text_type(el)
-                      for el in i)
+    text_generator = (el if isinstance(el, string_types) else text_type(el) for el in i)
 
     from ._termui_impl import pager
+
     return pager(itertools.chain(text_generator, "\n"), color)
 
 
-def progressbar(iterable=None, length=None, label=None, show_eta=True,
-                show_percent=None, show_pos=False,
-                item_show_func=None, fill_char='#', empty_char='-',
-                bar_template='%(label)s  [%(bar)s]  %(info)s',
-                info_sep='  ', width=36, file=None, color=None):
+def progressbar(
+    iterable=None,
+    length=None,
+    label=None,
+    show_eta=True,
+    show_percent=None,
+    show_pos=False,
+    item_show_func=None,
+    fill_char="#",
+    empty_char="-",
+    bar_template="%(label)s  [%(bar)s]  %(info)s",
+    info_sep="  ",
+    width=36,
+    file=None,
+    color=None,
+):
     """This function creates an iterable context manager that can be used
     to iterate over something while showing a progress bar.  It will
     either iterate over the `iterable` or `length` items (that are counted
@@ -272,11 +316,17 @@ def progressbar(iterable=None, length=None, label=None, show_eta=True,
     will not be rendered if the file is not a terminal.
 
     The context manager creates the progress bar.  When the context
-    manager is entered the progress bar is already displayed.  With every
+    manager is entered the progress bar is already created.  With every
     iteration over the progress bar, the iterable passed to the bar is
     advanced and the bar is updated.  When the context manager exits,
     a newline is printed and the progress bar is finalized on screen.
 
+    Note: The progress bar is currently designed for use cases where the
+    total progress can be expected to take at least several seconds.
+    Because of this, the ProgressBar class object won't display
+    progress that is considered too fast, and progress where the time
+    between steps is less than a second.
+
     No printing must happen or the progress bar will be unintentionally
     destroyed.
 
@@ -342,13 +392,24 @@ def progressbar(iterable=None, length=None, label=None, show_eta=True,
                   which is not the case by default.
     """
     from ._termui_impl import ProgressBar
+
     color = resolve_color_default(color)
-    return ProgressBar(iterable=iterable, length=length, show_eta=show_eta,
-                       show_percent=show_percent, show_pos=show_pos,
-                       item_show_func=item_show_func, fill_char=fill_char,
-                       empty_char=empty_char, bar_template=bar_template,
-                       info_sep=info_sep, file=file, label=label,
-                       width=width, color=color)
+    return ProgressBar(
+        iterable=iterable,
+        length=length,
+        show_eta=show_eta,
+        show_percent=show_percent,
+        show_pos=show_pos,
+        item_show_func=item_show_func,
+        fill_char=fill_char,
+        empty_char=empty_char,
+        bar_template=bar_template,
+        info_sep=info_sep,
+        file=file,
+        label=label,
+        width=width,
+        color=color,
+    )
 
 
 def clear():
@@ -364,13 +425,22 @@ def clear():
     # clear the screen by shelling out.  Otherwise we can use an escape
     # sequence.
     if WIN:
-        os.system('cls')
+        os.system("cls")
     else:
-        sys.stdout.write('\033[2J\033[1;1H')
-
-
-def style(text, fg=None, bg=None, bold=None, dim=None, underline=None,
-          blink=None, reverse=None, reset=True):
+        sys.stdout.write("\033[2J\033[1;1H")
+
+
+def style(
+    text,
+    fg=None,
+    bg=None,
+    bold=None,
+    dim=None,
+    underline=None,
+    blink=None,
+    reverse=None,
+    reset=True,
+):
     """Styles a text with ANSI styles and returns the new string.  By
     default the styling is self contained which means that at the end
     of the string a reset code is issued.  This can be prevented by
@@ -425,28 +495,28 @@ def style(text, fg=None, bg=None, bold=None, dim=None, underline=None,
     bits = []
     if fg:
         try:
-            bits.append('\033[%dm' % (_ansi_colors[fg]))
+            bits.append("\033[{}m".format(_ansi_colors[fg]))
         except KeyError:
-            raise TypeError('Unknown color %r' % fg)
+            raise TypeError("Unknown color '{}'".format(fg))
     if bg:
         try:
-            bits.append('\033[%dm' % (_ansi_colors[bg] + 10))
+            bits.append("\033[{}m".format(_ansi_colors[bg] + 10))
         except KeyError:
-            raise TypeError('Unknown color %r' % bg)
+            raise TypeError("Unknown color '{}'".format(bg))
     if bold is not None:
-        bits.append('\033[%dm' % (1 if bold else 22))
+        bits.append("\033[{}m".format(1 if bold else 22))
     if dim is not None:
-        bits.append('\033[%dm' % (2 if dim else 22))
+        bits.append("\033[{}m".format(2 if dim else 22))
     if underline is not None:
-        bits.append('\033[%dm' % (4 if underline else 24))
+        bits.append("\033[{}m".format(4 if underline else 24))
     if blink is not None:
-        bits.append('\033[%dm' % (5 if blink else 25))
+        bits.append("\033[{}m".format(5 if blink else 25))
     if reverse is not None:
-        bits.append('\033[%dm' % (7 if reverse else 27))
+        bits.append("\033[{}m".format(7 if reverse else 27))
     bits.append(text)
     if reset:
         bits.append(_ansi_reset_all)
-    return ''.join(bits)
+    return "".join(bits)
 
 
 def unstyle(text):
@@ -478,8 +548,9 @@ def secho(message=None, file=None, nl=True, err=False, color=None, **styles):
     return echo(message, file=file, nl=nl, err=err, color=color)
 
 
-def edit(text=None, editor=None, env=None, require_save=True,
-         extension='.txt', filename=None):
+def edit(
+    text=None, editor=None, env=None, require_save=True, extension=".txt", filename=None
+):
     r"""Edits the given text in the defined editor.  If an editor is given
     (should be the full path to the executable but the regular operating
     system search path is used for finding the executable) it overrides
@@ -508,8 +579,10 @@ def edit(text=None, editor=None, env=None, require_save=True,
                      file as an indirection in that case.
     """
     from ._termui_impl import Editor
-    editor = Editor(editor=editor, env=env, require_save=require_save,
-                    extension=extension)
+
+    editor = Editor(
+        editor=editor, env=env, require_save=require_save, extension=extension
+    )
     if filename is None:
         return editor.edit(text)
     editor.edit_file(filename)
@@ -538,6 +611,7 @@ def launch(url, wait=False, locate=False):
                    the filesystem.
     """
     from ._termui_impl import open_url
+
     return open_url(url, wait=wait, locate=locate)
 
 
@@ -574,10 +648,11 @@ def getchar(echo=False):
 
 def raw_terminal():
     from ._termui_impl import raw_terminal as f
+
     return f()
 
 
-def pause(info='Press any key to continue ...', err=False):
+def pause(info="Press any key to continue ...", err=False):
     """This command stops execution and waits for the user to press any
     key to continue.  This is similar to the Windows batch "pause"
     command.  If the program is not run through a terminal, this command
diff --git a/pipenv/vendor/click/testing.py b/pipenv/vendor/click/testing.py
index 1b2924e0..a3dba3b3 100644
--- a/pipenv/vendor/click/testing.py
+++ b/pipenv/vendor/click/testing.py
@@ -1,18 +1,16 @@
+import contextlib
 import os
-import sys
+import shlex
 import shutil
+import sys
 import tempfile
-import contextlib
-import shlex
-
-from ._compat import iteritems, PY2, string_types
-
 
-# If someone wants to vendor click, we want to ensure the
-# correct package is discovered.  Ideally we could use a
-# relative import here but unfortunately Python does not
-# support that.
-clickpkg = sys.modules[__name__.rsplit('.', 1)[0]]
+from . import formatting
+from . import termui
+from . import utils
+from ._compat import iteritems
+from ._compat import PY2
+from ._compat import string_types
 
 
 if PY2:
@@ -23,7 +21,6 @@ else:
 
 
 class EchoingStdin(object):
-
     def __init__(self, input, output):
         self._input = input
         self._output = output
@@ -53,16 +50,16 @@ class EchoingStdin(object):
 
 def make_input_stream(input, charset):
     # Is already an input stream.
-    if hasattr(input, 'read'):
+    if hasattr(input, "read"):
         if PY2:
             return input
         rv = _find_binary_reader(input)
         if rv is not None:
             return rv
-        raise TypeError('Could not find binary reader for input stream.')
+        raise TypeError("Could not find binary reader for input stream.")
 
     if input is None:
-        input = b''
+        input = b""
     elif not isinstance(input, bytes):
         input = input.encode(charset)
     if PY2:
@@ -73,13 +70,14 @@ def make_input_stream(input, charset):
 class Result(object):
     """Holds the captured result of an invoked CLI script."""
 
-    def __init__(self, runner, stdout_bytes, stderr_bytes, exit_code,
-                 exception, exc_info=None):
+    def __init__(
+        self, runner, stdout_bytes, stderr_bytes, exit_code, exception, exc_info=None
+    ):
         #: The runner that created the result
         self.runner = runner
         #: The standard output as bytes.
         self.stdout_bytes = stdout_bytes
-        #: The standard error as bytes, or False(y) if not available
+        #: The standard error as bytes, or None if not available
         self.stderr_bytes = stderr_bytes
         #: The exit code as integer.
         self.exit_code = exit_code
@@ -96,22 +94,22 @@ class Result(object):
     @property
     def stdout(self):
         """The standard output as unicode string."""
-        return self.stdout_bytes.decode(self.runner.charset, 'replace') \
-            .replace('\r\n', '\n')
+        return self.stdout_bytes.decode(self.runner.charset, "replace").replace(
+            "\r\n", "\n"
+        )
 
     @property
     def stderr(self):
         """The standard error as unicode string."""
-        if not self.stderr_bytes:
+        if self.stderr_bytes is None:
             raise ValueError("stderr not separately captured")
-        return self.stderr_bytes.decode(self.runner.charset, 'replace') \
-            .replace('\r\n', '\n')
-
+        return self.stderr_bytes.decode(self.runner.charset, "replace").replace(
+            "\r\n", "\n"
+        )
 
     def __repr__(self):
-        return '<%s %s>' % (
-            type(self).__name__,
-            self.exception and repr(self.exception) or 'okay',
+        return "<{} {}>".format(
+            type(self).__name__, repr(self.exception) if self.exception else "okay"
         )
 
 
@@ -136,10 +134,9 @@ class CliRunner(object):
                        independently
     """
 
-    def __init__(self, charset=None, env=None, echo_stdin=False,
-                 mix_stderr=True):
+    def __init__(self, charset=None, env=None, echo_stdin=False, mix_stderr=True):
         if charset is None:
-            charset = 'utf-8'
+            charset = "utf-8"
         self.charset = charset
         self.env = env or {}
         self.echo_stdin = echo_stdin
@@ -150,7 +147,7 @@ class CliRunner(object):
         for it.  The default is the `name` attribute or ``"root"`` if not
         set.
         """
-        return cli.name or 'root'
+        return cli.name or "root"
 
     def make_env(self, overrides=None):
         """Returns the environment overrides for invoking a script."""
@@ -182,8 +179,8 @@ class CliRunner(object):
         old_stdin = sys.stdin
         old_stdout = sys.stdout
         old_stderr = sys.stderr
-        old_forced_width = clickpkg.formatting.FORCED_WIDTH
-        clickpkg.formatting.FORCED_WIDTH = 80
+        old_forced_width = formatting.FORCED_WIDTH
+        formatting.FORCED_WIDTH = 80
 
         env = self.make_env(env)
 
@@ -200,12 +197,10 @@ class CliRunner(object):
             if self.echo_stdin:
                 input = EchoingStdin(input, bytes_output)
             input = io.TextIOWrapper(input, encoding=self.charset)
-            sys.stdout = io.TextIOWrapper(
-                bytes_output, encoding=self.charset)
+            sys.stdout = io.TextIOWrapper(bytes_output, encoding=self.charset)
             if not self.mix_stderr:
                 bytes_error = io.BytesIO()
-                sys.stderr = io.TextIOWrapper(
-                    bytes_error, encoding=self.charset)
+                sys.stderr = io.TextIOWrapper(bytes_error, encoding=self.charset)
 
         if self.mix_stderr:
             sys.stderr = sys.stdout
@@ -213,16 +208,16 @@ class CliRunner(object):
         sys.stdin = input
 
         def visible_input(prompt=None):
-            sys.stdout.write(prompt or '')
-            val = input.readline().rstrip('\r\n')
-            sys.stdout.write(val + '\n')
+            sys.stdout.write(prompt or "")
+            val = input.readline().rstrip("\r\n")
+            sys.stdout.write("{}\n".format(val))
             sys.stdout.flush()
             return val
 
         def hidden_input(prompt=None):
-            sys.stdout.write((prompt or '') + '\n')
+            sys.stdout.write("{}\n".format(prompt or ""))
             sys.stdout.flush()
-            return input.readline().rstrip('\r\n')
+            return input.readline().rstrip("\r\n")
 
         def _getchar(echo):
             char = sys.stdin.read(1)
@@ -238,14 +233,14 @@ class CliRunner(object):
                 return not default_color
             return not color
 
-        old_visible_prompt_func = clickpkg.termui.visible_prompt_func
-        old_hidden_prompt_func = clickpkg.termui.hidden_prompt_func
-        old__getchar_func = clickpkg.termui._getchar
-        old_should_strip_ansi = clickpkg.utils.should_strip_ansi
-        clickpkg.termui.visible_prompt_func = visible_input
-        clickpkg.termui.hidden_prompt_func = hidden_input
-        clickpkg.termui._getchar = _getchar
-        clickpkg.utils.should_strip_ansi = should_strip_ansi
+        old_visible_prompt_func = termui.visible_prompt_func
+        old_hidden_prompt_func = termui.hidden_prompt_func
+        old__getchar_func = termui._getchar
+        old_should_strip_ansi = utils.should_strip_ansi
+        termui.visible_prompt_func = visible_input
+        termui.hidden_prompt_func = hidden_input
+        termui._getchar = _getchar
+        utils.should_strip_ansi = should_strip_ansi
 
         old_env = {}
         try:
@@ -271,14 +266,22 @@ class CliRunner(object):
             sys.stdout = old_stdout
             sys.stderr = old_stderr
             sys.stdin = old_stdin
-            clickpkg.termui.visible_prompt_func = old_visible_prompt_func
-            clickpkg.termui.hidden_prompt_func = old_hidden_prompt_func
-            clickpkg.termui._getchar = old__getchar_func
-            clickpkg.utils.should_strip_ansi = old_should_strip_ansi
-            clickpkg.formatting.FORCED_WIDTH = old_forced_width
-
-    def invoke(self, cli, args=None, input=None, env=None,
-               catch_exceptions=True, color=False, mix_stderr=False, **extra):
+            termui.visible_prompt_func = old_visible_prompt_func
+            termui.hidden_prompt_func = old_hidden_prompt_func
+            termui._getchar = old__getchar_func
+            utils.should_strip_ansi = old_should_strip_ansi
+            formatting.FORCED_WIDTH = old_forced_width
+
+    def invoke(
+        self,
+        cli,
+        args=None,
+        input=None,
+        env=None,
+        catch_exceptions=True,
+        color=False,
+        **extra
+    ):
         """Invokes a command in an isolated environment.  The arguments are
         forwarded directly to the command line script, the `extra` keyword
         arguments are passed to the :meth:`~clickpkg.Command.main` function of
@@ -335,7 +338,7 @@ class CliRunner(object):
 
                 if not isinstance(exit_code, int):
                     sys.stdout.write(str(exit_code))
-                    sys.stdout.write('\n')
+                    sys.stdout.write("\n")
                     exit_code = 1
 
             except Exception as e:
@@ -347,14 +350,19 @@ class CliRunner(object):
             finally:
                 sys.stdout.flush()
                 stdout = outstreams[0].getvalue()
-                stderr = outstreams[1] and outstreams[1].getvalue()
-
-        return Result(runner=self,
-                      stdout_bytes=stdout,
-                      stderr_bytes=stderr,
-                      exit_code=exit_code,
-                      exception=exception,
-                      exc_info=exc_info)
+                if self.mix_stderr:
+                    stderr = None
+                else:
+                    stderr = outstreams[1].getvalue()
+
+        return Result(
+            runner=self,
+            stdout_bytes=stdout,
+            stderr_bytes=stderr,
+            exit_code=exit_code,
+            exception=exception,
+            exc_info=exc_info,
+        )
 
     @contextlib.contextmanager
     def isolated_filesystem(self):
@@ -370,5 +378,5 @@ class CliRunner(object):
             os.chdir(cwd)
             try:
                 shutil.rmtree(t)
-            except (OSError, IOError):
+            except (OSError, IOError):  # noqa: B014
                 pass
diff --git a/pipenv/vendor/click/types.py b/pipenv/vendor/click/types.py
index 1f88032f..505c39f8 100644
--- a/pipenv/vendor/click/types.py
+++ b/pipenv/vendor/click/types.py
@@ -2,10 +2,16 @@ import os
 import stat
 from datetime import datetime
 
-from ._compat import open_stream, text_type, filename_to_ui, \
-    get_filesystem_encoding, get_streerror, _get_argv_encoding, PY2
+from ._compat import _get_argv_encoding
+from ._compat import filename_to_ui
+from ._compat import get_filesystem_encoding
+from ._compat import get_streerror
+from ._compat import open_stream
+from ._compat import PY2
+from ._compat import text_type
 from .exceptions import BadParameter
-from .utils import safecall, LazyFile
+from .utils import LazyFile
+from .utils import safecall
 
 
 class ParamType(object):
@@ -21,6 +27,7 @@ class ParamType(object):
         This can be the case when the object is used with prompt
         inputs.
     """
+
     is_composite = False
 
     #: the descriptive name of this type
@@ -62,7 +69,7 @@ class ParamType(object):
         then leading and trailing whitespace is ignored.  Otherwise, leading
         and trailing splitters usually lead to empty items being included.
         """
-        return (rv or '').split(self.envvar_list_splitter)
+        return (rv or "").split(self.envvar_list_splitter)
 
     def fail(self, message, param=None, ctx=None):
         """Helper method to fail with an invalid value message."""
@@ -78,7 +85,6 @@ class CompositeParamType(ParamType):
 
 
 class FuncParamType(ParamType):
-
     def __init__(self, func):
         self.name = func.__name__
         self.func = func
@@ -90,22 +96,22 @@ class FuncParamType(ParamType):
             try:
                 value = text_type(value)
             except UnicodeError:
-                value = str(value).decode('utf-8', 'replace')
+                value = str(value).decode("utf-8", "replace")
             self.fail(value, param, ctx)
 
 
 class UnprocessedParamType(ParamType):
-    name = 'text'
+    name = "text"
 
     def convert(self, value, param, ctx):
         return value
 
     def __repr__(self):
-        return 'UNPROCESSED'
+        return "UNPROCESSED"
 
 
 class StringParamType(ParamType):
-    name = 'text'
+    name = "text"
 
     def convert(self, value, param, ctx):
         if isinstance(value, bytes):
@@ -118,12 +124,14 @@ class StringParamType(ParamType):
                     try:
                         value = value.decode(fs_enc)
                     except UnicodeError:
-                        value = value.decode('utf-8', 'replace')
+                        value = value.decode("utf-8", "replace")
+                else:
+                    value = value.decode("utf-8", "replace")
             return value
         return value
 
     def __repr__(self):
-        return 'STRING'
+        return "STRING"
 
 
 class Choice(ParamType):
@@ -133,54 +141,68 @@ class Choice(ParamType):
     You should only pass a list or tuple of choices. Other iterables
     (like generators) may lead to surprising results.
 
+    The resulting value will always be one of the originally passed choices
+    regardless of ``case_sensitive`` or any ``ctx.token_normalize_func``
+    being specified.
+
     See :ref:`choice-opts` for an example.
 
     :param case_sensitive: Set to false to make choices case
         insensitive. Defaults to true.
     """
 
-    name = 'choice'
+    name = "choice"
 
     def __init__(self, choices, case_sensitive=True):
         self.choices = choices
         self.case_sensitive = case_sensitive
 
     def get_metavar(self, param):
-        return '[%s]' % '|'.join(self.choices)
+        return "[{}]".format("|".join(self.choices))
 
     def get_missing_message(self, param):
-        return 'Choose from:\n\t%s.' % ',\n\t'.join(self.choices)
+        return "Choose from:\n\t{}.".format(",\n\t".join(self.choices))
 
     def convert(self, value, param, ctx):
-        # Exact match
-        if value in self.choices:
-            return value
-
         # Match through normalization and case sensitivity
         # first do token_normalize_func, then lowercase
         # preserve original `value` to produce an accurate message in
         # `self.fail`
         normed_value = value
-        normed_choices = self.choices
+        normed_choices = {choice: choice for choice in self.choices}
 
-        if ctx is not None and \
-           ctx.token_normalize_func is not None:
+        if ctx is not None and ctx.token_normalize_func is not None:
             normed_value = ctx.token_normalize_func(value)
-            normed_choices = [ctx.token_normalize_func(choice) for choice in
-                              self.choices]
+            normed_choices = {
+                ctx.token_normalize_func(normed_choice): original
+                for normed_choice, original in normed_choices.items()
+            }
 
         if not self.case_sensitive:
-            normed_value = normed_value.lower()
-            normed_choices = [choice.lower() for choice in normed_choices]
+            if PY2:
+                lower = str.lower
+            else:
+                lower = str.casefold
+
+            normed_value = lower(normed_value)
+            normed_choices = {
+                lower(normed_choice): original
+                for normed_choice, original in normed_choices.items()
+            }
 
         if normed_value in normed_choices:
-            return normed_value
+            return normed_choices[normed_value]
 
-        self.fail('invalid choice: %s. (choose from %s)' %
-                  (value, ', '.join(self.choices)), param, ctx)
+        self.fail(
+            "invalid choice: {}. (choose from {})".format(
+                value, ", ".join(self.choices)
+            ),
+            param,
+            ctx,
+        )
 
     def __repr__(self):
-        return 'Choice(%r)' % list(self.choices)
+        return "Choice('{}')".format(list(self.choices))
 
 
 class DateTime(ParamType):
@@ -203,17 +225,14 @@ class DateTime(ParamType):
                     ``'%Y-%m-%d'``, ``'%Y-%m-%dT%H:%M:%S'``,
                     ``'%Y-%m-%d %H:%M:%S'``.
     """
-    name = 'datetime'
+
+    name = "datetime"
 
     def __init__(self, formats=None):
-        self.formats = formats or [
-            '%Y-%m-%d',
-            '%Y-%m-%dT%H:%M:%S',
-            '%Y-%m-%d %H:%M:%S'
-        ]
+        self.formats = formats or ["%Y-%m-%d", "%Y-%m-%dT%H:%M:%S", "%Y-%m-%d %H:%M:%S"]
 
     def get_metavar(self, param):
-        return '[{}]'.format('|'.join(self.formats))
+        return "[{}]".format("|".join(self.formats))
 
     def _try_to_convert_date(self, value, format):
         try:
@@ -229,24 +248,26 @@ class DateTime(ParamType):
                 return dtime
 
         self.fail(
-            'invalid datetime format: {}. (choose from {})'.format(
-                value, ', '.join(self.formats)))
+            "invalid datetime format: {}. (choose from {})".format(
+                value, ", ".join(self.formats)
+            )
+        )
 
     def __repr__(self):
-        return 'DateTime'
+        return "DateTime"
 
 
 class IntParamType(ParamType):
-    name = 'integer'
+    name = "integer"
 
     def convert(self, value, param, ctx):
         try:
             return int(value)
-        except (ValueError, UnicodeError):
-            self.fail('%s is not a valid integer' % value, param, ctx)
+        except ValueError:
+            self.fail("{} is not a valid integer".format(value), param, ctx)
 
     def __repr__(self):
-        return 'INT'
+        return "INT"
 
 
 class IntRange(IntParamType):
@@ -257,7 +278,8 @@ class IntRange(IntParamType):
 
     See :ref:`ranges` for an example.
     """
-    name = 'integer range'
+
+    name = "integer range"
 
     def __init__(self, min=None, max=None, clamp=False):
         self.min = min
@@ -271,35 +293,55 @@ class IntRange(IntParamType):
                 return self.min
             if self.max is not None and rv > self.max:
                 return self.max
-        if self.min is not None and rv < self.min or \
-           self.max is not None and rv > self.max:
+        if (
+            self.min is not None
+            and rv < self.min
+            or self.max is not None
+            and rv > self.max
+        ):
             if self.min is None:
-                self.fail('%s is bigger than the maximum valid value '
-                          '%s.' % (rv, self.max), param, ctx)
+                self.fail(
+                    "{} is bigger than the maximum valid value {}.".format(
+                        rv, self.max
+                    ),
+                    param,
+                    ctx,
+                )
             elif self.max is None:
-                self.fail('%s is smaller than the minimum valid value '
-                          '%s.' % (rv, self.min), param, ctx)
+                self.fail(
+                    "{} is smaller than the minimum valid value {}.".format(
+                        rv, self.min
+                    ),
+                    param,
+                    ctx,
+                )
             else:
-                self.fail('%s is not in the valid range of %s to %s.'
-                          % (rv, self.min, self.max), param, ctx)
+                self.fail(
+                    "{} is not in the valid range of {} to {}.".format(
+                        rv, self.min, self.max
+                    ),
+                    param,
+                    ctx,
+                )
         return rv
 
     def __repr__(self):
-        return 'IntRange(%r, %r)' % (self.min, self.max)
+        return "IntRange({}, {})".format(self.min, self.max)
 
 
 class FloatParamType(ParamType):
-    name = 'float'
+    name = "float"
 
     def convert(self, value, param, ctx):
         try:
             return float(value)
-        except (UnicodeError, ValueError):
-            self.fail('%s is not a valid floating point value' %
-                      value, param, ctx)
+        except ValueError:
+            self.fail(
+                "{} is not a valid floating point value".format(value), param, ctx
+            )
 
     def __repr__(self):
-        return 'FLOAT'
+        return "FLOAT"
 
 
 class FloatRange(FloatParamType):
@@ -310,7 +352,8 @@ class FloatRange(FloatParamType):
 
     See :ref:`ranges` for an example.
     """
-    name = 'float range'
+
+    name = "float range"
 
     def __init__(self, min=None, max=None, clamp=False):
         self.min = min
@@ -324,54 +367,74 @@ class FloatRange(FloatParamType):
                 return self.min
             if self.max is not None and rv > self.max:
                 return self.max
-        if self.min is not None and rv < self.min or \
-           self.max is not None and rv > self.max:
+        if (
+            self.min is not None
+            and rv < self.min
+            or self.max is not None
+            and rv > self.max
+        ):
             if self.min is None:
-                self.fail('%s is bigger than the maximum valid value '
-                          '%s.' % (rv, self.max), param, ctx)
+                self.fail(
+                    "{} is bigger than the maximum valid value {}.".format(
+                        rv, self.max
+                    ),
+                    param,
+                    ctx,
+                )
             elif self.max is None:
-                self.fail('%s is smaller than the minimum valid value '
-                          '%s.' % (rv, self.min), param, ctx)
+                self.fail(
+                    "{} is smaller than the minimum valid value {}.".format(
+                        rv, self.min
+                    ),
+                    param,
+                    ctx,
+                )
             else:
-                self.fail('%s is not in the valid range of %s to %s.'
-                          % (rv, self.min, self.max), param, ctx)
+                self.fail(
+                    "{} is not in the valid range of {} to {}.".format(
+                        rv, self.min, self.max
+                    ),
+                    param,
+                    ctx,
+                )
         return rv
 
     def __repr__(self):
-        return 'FloatRange(%r, %r)' % (self.min, self.max)
+        return "FloatRange({}, {})".format(self.min, self.max)
 
 
 class BoolParamType(ParamType):
-    name = 'boolean'
+    name = "boolean"
 
     def convert(self, value, param, ctx):
         if isinstance(value, bool):
             return bool(value)
         value = value.lower()
-        if value in ('true', 't', '1', 'yes', 'y'):
+        if value in ("true", "t", "1", "yes", "y"):
             return True
-        elif value in ('false', 'f', '0', 'no', 'n'):
+        elif value in ("false", "f", "0", "no", "n"):
             return False
-        self.fail('%s is not a valid boolean' % value, param, ctx)
+        self.fail("{} is not a valid boolean".format(value), param, ctx)
 
     def __repr__(self):
-        return 'BOOL'
+        return "BOOL"
 
 
 class UUIDParameterType(ParamType):
-    name = 'uuid'
+    name = "uuid"
 
     def convert(self, value, param, ctx):
         import uuid
+
         try:
             if PY2 and isinstance(value, text_type):
-                value = value.encode('ascii')
+                value = value.encode("ascii")
             return uuid.UUID(value)
-        except (UnicodeError, ValueError):
-            self.fail('%s is not a valid UUID value' % value, param, ctx)
+        except ValueError:
+            self.fail("{} is not a valid UUID value".format(value), param, ctx)
 
     def __repr__(self):
-        return 'UUID'
+        return "UUID"
 
 
 class File(ParamType):
@@ -400,11 +463,13 @@ class File(ParamType):
 
     See :ref:`file-args` for more information.
     """
-    name = 'filename'
+
+    name = "filename"
     envvar_list_splitter = os.path.pathsep
 
-    def __init__(self, mode='r', encoding=None, errors='strict', lazy=None,
-                 atomic=False):
+    def __init__(
+        self, mode="r", encoding=None, errors="strict", lazy=None, atomic=False
+    ):
         self.mode = mode
         self.encoding = encoding
         self.errors = errors
@@ -414,29 +479,30 @@ class File(ParamType):
     def resolve_lazy_flag(self, value):
         if self.lazy is not None:
             return self.lazy
-        if value == '-':
+        if value == "-":
             return False
-        elif 'w' in self.mode:
+        elif "w" in self.mode:
             return True
         return False
 
     def convert(self, value, param, ctx):
         try:
-            if hasattr(value, 'read') or hasattr(value, 'write'):
+            if hasattr(value, "read") or hasattr(value, "write"):
                 return value
 
             lazy = self.resolve_lazy_flag(value)
 
             if lazy:
-                f = LazyFile(value, self.mode, self.encoding, self.errors,
-                             atomic=self.atomic)
+                f = LazyFile(
+                    value, self.mode, self.encoding, self.errors, atomic=self.atomic
+                )
                 if ctx is not None:
                     ctx.call_on_close(f.close_intelligently)
                 return f
 
-            f, should_close = open_stream(value, self.mode,
-                                          self.encoding, self.errors,
-                                          atomic=self.atomic)
+            f, should_close = open_stream(
+                value, self.mode, self.encoding, self.errors, atomic=self.atomic
+            )
             # If a context is provided, we automatically close the file
             # at the end of the context execution (or flush out).  If a
             # context does not exist, it's the caller's responsibility to
@@ -448,11 +514,14 @@ class File(ParamType):
                 else:
                     ctx.call_on_close(safecall(f.flush))
             return f
-        except (IOError, OSError) as e:
-            self.fail('Could not open file: %s: %s' % (
-                filename_to_ui(value),
-                get_streerror(e),
-            ), param, ctx)
+        except (IOError, OSError) as e:  # noqa: B014
+            self.fail(
+                "Could not open file: {}: {}".format(
+                    filename_to_ui(value), get_streerror(e)
+                ),
+                param,
+                ctx,
+            )
 
 
 class Path(ParamType):
@@ -485,11 +554,20 @@ class Path(ParamType):
                       unicode depending on what makes most sense given the
                       input data Click deals with.
     """
+
     envvar_list_splitter = os.path.pathsep
 
-    def __init__(self, exists=False, file_okay=True, dir_okay=True,
-                 writable=False, readable=True, resolve_path=False,
-                 allow_dash=False, path_type=None):
+    def __init__(
+        self,
+        exists=False,
+        file_okay=True,
+        dir_okay=True,
+        writable=False,
+        readable=True,
+        resolve_path=False,
+        allow_dash=False,
+        path_type=None,
+    ):
         self.exists = exists
         self.file_okay = file_okay
         self.dir_okay = dir_okay
@@ -500,14 +578,14 @@ class Path(ParamType):
         self.type = path_type
 
         if self.file_okay and not self.dir_okay:
-            self.name = 'file'
-            self.path_type = 'File'
+            self.name = "file"
+            self.path_type = "File"
         elif self.dir_okay and not self.file_okay:
-            self.name = 'directory'
-            self.path_type = 'Directory'
+            self.name = "directory"
+            self.path_type = "Directory"
         else:
-            self.name = 'path'
-            self.path_type = 'Path'
+            self.name = "path"
+            self.path_type = "Path"
 
     def coerce_path_result(self, rv):
         if self.type is not None and not isinstance(rv, self.type):
@@ -520,7 +598,7 @@ class Path(ParamType):
     def convert(self, value, param, ctx):
         rv = value
 
-        is_dash = self.file_okay and self.allow_dash and rv in (b'-', '-')
+        is_dash = self.file_okay and self.allow_dash and rv in (b"-", "-")
 
         if not is_dash:
             if self.resolve_path:
@@ -531,31 +609,44 @@ class Path(ParamType):
             except OSError:
                 if not self.exists:
                     return self.coerce_path_result(rv)
-                self.fail('%s "%s" does not exist.' % (
-                    self.path_type,
-                    filename_to_ui(value)
-                ), param, ctx)
+                self.fail(
+                    "{} '{}' does not exist.".format(
+                        self.path_type, filename_to_ui(value)
+                    ),
+                    param,
+                    ctx,
+                )
 
             if not self.file_okay and stat.S_ISREG(st.st_mode):
-                self.fail('%s "%s" is a file.' % (
-                    self.path_type,
-                    filename_to_ui(value)
-                ), param, ctx)
+                self.fail(
+                    "{} '{}' is a file.".format(self.path_type, filename_to_ui(value)),
+                    param,
+                    ctx,
+                )
             if not self.dir_okay and stat.S_ISDIR(st.st_mode):
-                self.fail('%s "%s" is a directory.' % (
-                    self.path_type,
-                    filename_to_ui(value)
-                ), param, ctx)
+                self.fail(
+                    "{} '{}' is a directory.".format(
+                        self.path_type, filename_to_ui(value)
+                    ),
+                    param,
+                    ctx,
+                )
             if self.writable and not os.access(value, os.W_OK):
-                self.fail('%s "%s" is not writable.' % (
-                    self.path_type,
-                    filename_to_ui(value)
-                ), param, ctx)
+                self.fail(
+                    "{} '{}' is not writable.".format(
+                        self.path_type, filename_to_ui(value)
+                    ),
+                    param,
+                    ctx,
+                )
             if self.readable and not os.access(value, os.R_OK):
-                self.fail('%s "%s" is not readable.' % (
-                    self.path_type,
-                    filename_to_ui(value)
-                ), param, ctx)
+                self.fail(
+                    "{} '{}' is not readable.".format(
+                        self.path_type, filename_to_ui(value)
+                    ),
+                    param,
+                    ctx,
+                )
 
         return self.coerce_path_result(rv)
 
@@ -579,7 +670,7 @@ class Tuple(CompositeParamType):
 
     @property
     def name(self):
-        return "<" + " ".join(ty.name for ty in self.types) + ">"
+        return "<{}>".format(" ".join(ty.name for ty in self.types))
 
     @property
     def arity(self):
@@ -587,14 +678,16 @@ class Tuple(CompositeParamType):
 
     def convert(self, value, param, ctx):
         if len(value) != len(self.types):
-            raise TypeError('It would appear that nargs is set to conflict '
-                            'with the composite type arity.')
+            raise TypeError(
+                "It would appear that nargs is set to conflict with the"
+                " composite type arity."
+            )
         return tuple(ty(x, param, ctx) for ty, x in zip(self.types, value))
 
 
 def convert_type(ty, default=None):
-    """Converts a callable or python ty into the most appropriate param
-    ty.
+    """Converts a callable or python type into the most appropriate
+    param type.
     """
     guessed_type = False
     if ty is None and default is not None:
@@ -627,8 +720,9 @@ def convert_type(ty, default=None):
     if __debug__:
         try:
             if issubclass(ty, ParamType):
-                raise AssertionError('Attempted to use an uninstantiated '
-                                     'parameter type (%s).' % ty)
+                raise AssertionError(
+                    "Attempted to use an uninstantiated parameter type ({}).".format(ty)
+                )
         except TypeError:
             pass
     return FuncParamType(ty)
diff --git a/pipenv/vendor/click/utils.py b/pipenv/vendor/click/utils.py
index fc84369f..79265e73 100644
--- a/pipenv/vendor/click/utils.py
+++ b/pipenv/vendor/click/utils.py
@@ -1,34 +1,47 @@
 import os
 import sys
 
+from ._compat import _default_text_stderr
+from ._compat import _default_text_stdout
+from ._compat import auto_wrap_for_ansi
+from ._compat import binary_streams
+from ._compat import filename_to_ui
+from ._compat import get_filesystem_encoding
+from ._compat import get_streerror
+from ._compat import is_bytes
+from ._compat import open_stream
+from ._compat import PY2
+from ._compat import should_strip_ansi
+from ._compat import string_types
+from ._compat import strip_ansi
+from ._compat import text_streams
+from ._compat import text_type
+from ._compat import WIN
 from .globals import resolve_color_default
 
-from ._compat import text_type, open_stream, get_filesystem_encoding, \
-    get_streerror, string_types, PY2, binary_streams, text_streams, \
-    filename_to_ui, auto_wrap_for_ansi, strip_ansi, should_strip_ansi, \
-    _default_text_stdout, _default_text_stderr, is_bytes, WIN
-
 if not PY2:
     from ._compat import _find_binary_writer
 elif WIN:
-    from ._winconsole import _get_windows_argv, \
-         _hash_py_argv, _initial_argv_hash
-
+    from ._winconsole import _get_windows_argv
+    from ._winconsole import _hash_py_argv
+    from ._winconsole import _initial_argv_hash
 
 echo_native_types = string_types + (bytes, bytearray)
 
 
 def _posixify(name):
-    return '-'.join(name.split()).lower()
+    return "-".join(name.split()).lower()
 
 
 def safecall(func):
     """Wraps a function so that it swallows exceptions."""
+
     def wrapper(*args, **kwargs):
         try:
             return func(*args, **kwargs)
         except Exception:
             pass
+
     return wrapper
 
 
@@ -38,7 +51,7 @@ def make_str(value):
         try:
             return value.decode(get_filesystem_encoding())
         except UnicodeError:
-            return value.decode('utf-8', 'replace')
+            return value.decode("utf-8", "replace")
     return text_type(value)
 
 
@@ -50,21 +63,21 @@ def make_default_short_help(help, max_length=45):
     done = False
 
     for word in words:
-        if word[-1:] == '.':
+        if word[-1:] == ".":
             done = True
-        new_length = result and 1 + len(word) or len(word)
+        new_length = 1 + len(word) if result else len(word)
         if total_length + new_length > max_length:
-            result.append('...')
+            result.append("...")
             done = True
         else:
             if result:
-                result.append(' ')
+                result.append(" ")
             result.append(word)
         if done:
             break
         total_length += new_length
 
-    return ''.join(result)
+    return "".join(result)
 
 
 class LazyFile(object):
@@ -74,19 +87,19 @@ class LazyFile(object):
     files for writing.
     """
 
-    def __init__(self, filename, mode='r', encoding=None, errors='strict',
-                 atomic=False):
+    def __init__(
+        self, filename, mode="r", encoding=None, errors="strict", atomic=False
+    ):
         self.name = filename
         self.mode = mode
         self.encoding = encoding
         self.errors = errors
         self.atomic = atomic
 
-        if filename == '-':
-            self._f, self.should_close = open_stream(filename, mode,
-                                                     encoding, errors)
+        if filename == "-":
+            self._f, self.should_close = open_stream(filename, mode, encoding, errors)
         else:
-            if 'r' in mode:
+            if "r" in mode:
                 # Open and close the file in case we're opening it for
                 # reading so that we can catch at least some errors in
                 # some cases early.
@@ -100,7 +113,7 @@ class LazyFile(object):
     def __repr__(self):
         if self._f is not None:
             return repr(self._f)
-        return '<unopened file %r %s>' % (self.name, self.mode)
+        return "<unopened file '{}' {}>".format(self.name, self.mode)
 
     def open(self):
         """Opens the file if it's not yet open.  This call might fail with
@@ -110,12 +123,12 @@ class LazyFile(object):
         if self._f is not None:
             return self._f
         try:
-            rv, self.should_close = open_stream(self.name, self.mode,
-                                                self.encoding,
-                                                self.errors,
-                                                atomic=self.atomic)
-        except (IOError, OSError) as e:
+            rv, self.should_close = open_stream(
+                self.name, self.mode, self.encoding, self.errors, atomic=self.atomic
+            )
+        except (IOError, OSError) as e:  # noqa: E402
             from .exceptions import FileError
+
             raise FileError(self.name, hint=get_streerror(e))
         self._f = rv
         return rv
@@ -144,7 +157,6 @@ class LazyFile(object):
 
 
 class KeepOpenFile(object):
-
     def __init__(self, file):
         self._file = file
 
@@ -222,11 +234,11 @@ def echo(message=None, file=None, nl=True, err=False, color=None):
         message = text_type(message)
 
     if nl:
-        message = message or u''
+        message = message or u""
         if isinstance(message, text_type):
-            message += u'\n'
+            message += u"\n"
         else:
-            message += b'\n'
+            message += b"\n"
 
     # If there is a message, and we're in Python 3, and the value looks
     # like bytes, we manually need to find the binary stream and write the
@@ -273,11 +285,11 @@ def get_binary_stream(name):
     """
     opener = binary_streams.get(name)
     if opener is None:
-        raise TypeError('Unknown standard stream %r' % name)
+        raise TypeError("Unknown standard stream '{}'".format(name))
     return opener()
 
 
-def get_text_stream(name, encoding=None, errors='strict'):
+def get_text_stream(name, encoding=None, errors="strict"):
     """Returns a system stream for text processing.  This usually returns
     a wrapped stream around a binary stream returned from
     :func:`get_binary_stream` but it also can take shortcuts on Python 3
@@ -290,12 +302,13 @@ def get_text_stream(name, encoding=None, errors='strict'):
     """
     opener = text_streams.get(name)
     if opener is None:
-        raise TypeError('Unknown standard stream %r' % name)
+        raise TypeError("Unknown standard stream '{}'".format(name))
     return opener(encoding, errors)
 
 
-def open_file(filename, mode='r', encoding=None, errors='strict',
-              lazy=False, atomic=False):
+def open_file(
+    filename, mode="r", encoding=None, errors="strict", lazy=False, atomic=False
+):
     """This is similar to how the :class:`File` works but for manual
     usage.  Files are opened non lazy by default.  This can open regular
     files as well as stdin/stdout if ``'-'`` is passed.
@@ -320,8 +333,7 @@ def open_file(filename, mode='r', encoding=None, errors='strict',
     """
     if lazy:
         return LazyFile(filename, mode, encoding, errors, atomic=atomic)
-    f, should_close = open_stream(filename, mode, encoding, errors,
-                                  atomic=atomic)
+    f, should_close = open_stream(filename, mode, encoding, errors, atomic=atomic)
     if not should_close:
         f = KeepOpenFile(f)
     return f
@@ -401,19 +413,21 @@ def get_app_dir(app_name, roaming=True, force_posix=False):
                         application support folder.
     """
     if WIN:
-        key = roaming and 'APPDATA' or 'LOCALAPPDATA'
+        key = "APPDATA" if roaming else "LOCALAPPDATA"
         folder = os.environ.get(key)
         if folder is None:
-            folder = os.path.expanduser('~')
+            folder = os.path.expanduser("~")
         return os.path.join(folder, app_name)
     if force_posix:
-        return os.path.join(os.path.expanduser('~/.' + _posixify(app_name)))
-    if sys.platform == 'darwin':
-        return os.path.join(os.path.expanduser(
-            '~/Library/Application Support'), app_name)
+        return os.path.join(os.path.expanduser("~/.{}".format(_posixify(app_name))))
+    if sys.platform == "darwin":
+        return os.path.join(
+            os.path.expanduser("~/Library/Application Support"), app_name
+        )
     return os.path.join(
-        os.environ.get('XDG_CONFIG_HOME', os.path.expanduser('~/.config')),
-        _posixify(app_name))
+        os.environ.get("XDG_CONFIG_HOME", os.path.expanduser("~/.config")),
+        _posixify(app_name),
+    )
 
 
 class PacifyFlushWrapper(object):
@@ -433,6 +447,7 @@ class PacifyFlushWrapper(object):
             self.wrapped.flush()
         except IOError as e:
             import errno
+
             if e.errno != errno.EPIPE:
                 raise
 
diff --git a/pipenv/vendor/colorama/__init__.py b/pipenv/vendor/colorama/__init__.py
index 2a3bf471..34c263cc 100644
--- a/pipenv/vendor/colorama/__init__.py
+++ b/pipenv/vendor/colorama/__init__.py
@@ -3,4 +3,4 @@ from .initialise import init, deinit, reinit, colorama_text
 from .ansi import Fore, Back, Style, Cursor
 from .ansitowin32 import AnsiToWin32
 
-__version__ = '0.4.1'
+__version__ = '0.4.3'
diff --git a/pipenv/vendor/funcsigs/LICENSE b/pipenv/vendor/funcsigs/LICENSE
new file mode 100644
index 00000000..3e563d6f
--- /dev/null
+++ b/pipenv/vendor/funcsigs/LICENSE
@@ -0,0 +1,13 @@
+Copyright 2013 Aaron Iles
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff --git a/pipenv/vendor/idna/LICENSE.rst b/pipenv/vendor/idna/LICENSE.rst
index 3ee64fba..63664b82 100644
--- a/pipenv/vendor/idna/LICENSE.rst
+++ b/pipenv/vendor/idna/LICENSE.rst
@@ -1,7 +1,9 @@
 License
 -------
 
-Copyright (c) 2013-2018, Kim Davies. All rights reserved.
+License: bsd-3-clause
+
+Copyright (c) 2013-2020, Kim Davies. All rights reserved.
 
 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are met:
@@ -30,51 +32,3 @@ modification, are permitted provided that the following conditions are met:
    (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
    USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
    DAMAGE.
-
-Portions of the codec implementation and unit tests are derived from the
-Python standard library, which carries the `Python Software Foundation
-License <https://docs.python.org/2/license.html>`_:
-
-   Copyright (c) 2001-2014 Python Software Foundation; All Rights Reserved
-
-Portions of the unit tests are derived from the Unicode standard, which 
-is subject to the Unicode, Inc. License Agreement:
-
-   Copyright (c) 1991-2014 Unicode, Inc. All rights reserved.
-   Distributed under the Terms of Use in 
-   <http://www.unicode.org/copyright.html>.
-
-   Permission is hereby granted, free of charge, to any person obtaining
-   a copy of the Unicode data files and any associated documentation
-   (the "Data Files") or Unicode software and any associated documentation
-   (the "Software") to deal in the Data Files or Software
-   without restriction, including without limitation the rights to use,
-   copy, modify, merge, publish, distribute, and/or sell copies of
-   the Data Files or Software, and to permit persons to whom the Data Files
-   or Software are furnished to do so, provided that
-   
-   (a) this copyright and permission notice appear with all copies 
-   of the Data Files or Software,
-
-   (b) this copyright and permission notice appear in associated 
-   documentation, and
-
-   (c) there is clear notice in each modified Data File or in the Software
-   as well as in the documentation associated with the Data File(s) or
-   Software that the data or software has been modified.
-
-   THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF
-   ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
-   WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
-   NONINFRINGEMENT OF THIRD PARTY RIGHTS.
-   IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED IN THIS
-   NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIAL
-   DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,
-   DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER
-   TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
-   PERFORMANCE OF THE DATA FILES OR SOFTWARE.
-
-   Except as contained in this notice, the name of a copyright holder
-   shall not be used in advertising or otherwise to promote the sale,
-   use or other dealings in these Data Files or Software without prior
-   written authorization of the copyright holder.
diff --git a/pipenv/vendor/idna/core.py b/pipenv/vendor/idna/core.py
index 104624ad..9c3bba2a 100644
--- a/pipenv/vendor/idna/core.py
+++ b/pipenv/vendor/idna/core.py
@@ -9,7 +9,7 @@ _virama_combining_class = 9
 _alabel_prefix = b'xn--'
 _unicode_dots_re = re.compile(u'[\u002e\u3002\uff0e\uff61]')
 
-if sys.version_info[0] == 3:
+if sys.version_info[0] >= 3:
     unicode = str
     unichr = chr
 
@@ -300,6 +300,8 @@ def ulabel(label):
     label = label.lower()
     if label.startswith(_alabel_prefix):
         label = label[len(_alabel_prefix):]
+        if label.decode('ascii')[-1] == '-':
+            raise IDNAError('A-label must not end with a hyphen')
     else:
         check_label(label)
         return label.decode('ascii')
diff --git a/pipenv/vendor/idna/idnadata.py b/pipenv/vendor/idna/idnadata.py
index a80c959d..2b81c522 100644
--- a/pipenv/vendor/idna/idnadata.py
+++ b/pipenv/vendor/idna/idnadata.py
@@ -1,6 +1,6 @@
 # This file is automatically generated by tools/idna-data
 
-__version__ = "11.0.0"
+__version__ = "12.1.0"
 scripts = {
     'Greek': (
         0x37000000374,
@@ -74,6 +74,7 @@ scripts = {
         0x304100003097,
         0x309d000030a0,
         0x1b0010001b11f,
+        0x1b1500001b153,
         0x1f2000001f201,
     ),
     'Katakana': (
@@ -85,6 +86,7 @@ scripts = {
         0xff660000ff70,
         0xff710000ff9e,
         0x1b0000001b001,
+        0x1b1640001b168,
     ),
 }
 joining_types = {
@@ -824,6 +826,7 @@ joining_types = {
     0x1e941: 68,
     0x1e942: 68,
     0x1e943: 68,
+    0x1e94b: 84,
 }
 codepoint_classes = {
     'PVALID': (
@@ -1258,18 +1261,11 @@ codepoint_classes = {
         0xe5000000e5a,
         0xe8100000e83,
         0xe8400000e85,
-        0xe8700000e89,
-        0xe8a00000e8b,
-        0xe8d00000e8e,
-        0xe9400000e98,
-        0xe9900000ea0,
-        0xea100000ea4,
+        0xe8600000e8b,
+        0xe8c00000ea4,
         0xea500000ea6,
-        0xea700000ea8,
-        0xeaa00000eac,
-        0xead00000eb3,
-        0xeb400000eba,
-        0xebb00000ebe,
+        0xea700000eb3,
+        0xeb400000ebe,
         0xec000000ec5,
         0xec600000ec7,
         0xec800000ece,
@@ -1370,7 +1366,7 @@ codepoint_classes = {
         0x1c4000001c4a,
         0x1c4d00001c7e,
         0x1cd000001cd3,
-        0x1cd400001cfa,
+        0x1cd400001cfb,
         0x1d0000001d2c,
         0x1d2f00001d30,
         0x1d3b00001d3c,
@@ -1727,6 +1723,10 @@ codepoint_classes = {
         0xa7b50000a7b6,
         0xa7b70000a7b8,
         0xa7b90000a7ba,
+        0xa7bb0000a7bc,
+        0xa7bd0000a7be,
+        0xa7bf0000a7c0,
+        0xa7c30000a7c4,
         0xa7f70000a7f8,
         0xa7fa0000a828,
         0xa8400000a874,
@@ -1753,7 +1753,7 @@ codepoint_classes = {
         0xab200000ab27,
         0xab280000ab2f,
         0xab300000ab5b,
-        0xab600000ab66,
+        0xab600000ab68,
         0xabc00000abeb,
         0xabec0000abee,
         0xabf00000abfa,
@@ -1830,6 +1830,7 @@ codepoint_classes = {
         0x10f0000010f1d,
         0x10f2700010f28,
         0x10f3000010f51,
+        0x10fe000010ff7,
         0x1100000011047,
         0x1106600011070,
         0x1107f000110bb,
@@ -1871,7 +1872,7 @@ codepoint_classes = {
         0x1137000011375,
         0x114000001144b,
         0x114500001145a,
-        0x1145e0001145f,
+        0x1145e00011460,
         0x11480000114c6,
         0x114c7000114c8,
         0x114d0000114da,
@@ -1881,7 +1882,7 @@ codepoint_classes = {
         0x1160000011641,
         0x1164400011645,
         0x116500001165a,
-        0x11680000116b8,
+        0x11680000116b9,
         0x116c0000116ca,
         0x117000001171b,
         0x1171d0001172c,
@@ -1889,10 +1890,13 @@ codepoint_classes = {
         0x118000001183b,
         0x118c0000118ea,
         0x118ff00011900,
+        0x119a0000119a8,
+        0x119aa000119d8,
+        0x119da000119e2,
+        0x119e3000119e5,
         0x11a0000011a3f,
         0x11a4700011a48,
-        0x11a5000011a84,
-        0x11a8600011a9a,
+        0x11a5000011a9a,
         0x11a9d00011a9e,
         0x11ac000011af9,
         0x11c0000011c09,
@@ -1931,13 +1935,16 @@ codepoint_classes = {
         0x16b6300016b78,
         0x16b7d00016b90,
         0x16e6000016e80,
-        0x16f0000016f45,
-        0x16f5000016f7f,
+        0x16f0000016f4b,
+        0x16f4f00016f88,
         0x16f8f00016fa0,
         0x16fe000016fe2,
-        0x17000000187f2,
+        0x16fe300016fe4,
+        0x17000000187f8,
         0x1880000018af3,
         0x1b0000001b11f,
+        0x1b1500001b153,
+        0x1b1640001b168,
         0x1b1700001b2fc,
         0x1bc000001bc6b,
         0x1bc700001bc7d,
@@ -1955,9 +1962,14 @@ codepoint_classes = {
         0x1e01b0001e022,
         0x1e0230001e025,
         0x1e0260001e02b,
+        0x1e1000001e12d,
+        0x1e1300001e13e,
+        0x1e1400001e14a,
+        0x1e14e0001e14f,
+        0x1e2c00001e2fa,
         0x1e8000001e8c5,
         0x1e8d00001e8d7,
-        0x1e9220001e94b,
+        0x1e9220001e94c,
         0x1e9500001e95a,
         0x200000002a6d7,
         0x2a7000002b735,
diff --git a/pipenv/vendor/idna/package_data.py b/pipenv/vendor/idna/package_data.py
index 257e8989..b5d82165 100644
--- a/pipenv/vendor/idna/package_data.py
+++ b/pipenv/vendor/idna/package_data.py
@@ -1,2 +1,2 @@
-__version__ = '2.8'
+__version__ = '2.9'
 
diff --git a/pipenv/vendor/idna/uts46data.py b/pipenv/vendor/idna/uts46data.py
index a68ed4c0..2711136d 100644
--- a/pipenv/vendor/idna/uts46data.py
+++ b/pipenv/vendor/idna/uts46data.py
@@ -4,7 +4,7 @@
 """IDNA Mapping Table from UTS46."""
 
 
-__version__ = "11.0.0"
+__version__ = "12.1.0"
 def _seg_0():
     return [
     (0x0, '3'),
@@ -1272,7 +1272,7 @@ def _seg_12():
     (0xC64, 'X'),
     (0xC66, 'V'),
     (0xC70, 'X'),
-    (0xC78, 'V'),
+    (0xC77, 'V'),
     (0xC8D, 'X'),
     (0xC8E, 'V'),
     (0xC91, 'X'),
@@ -1348,33 +1348,19 @@ def _seg_12():
     (0xE83, 'X'),
     (0xE84, 'V'),
     (0xE85, 'X'),
-    (0xE87, 'V'),
-    (0xE89, 'X'),
-    (0xE8A, 'V'),
+    (0xE86, 'V'),
     (0xE8B, 'X'),
-    (0xE8D, 'V'),
-    (0xE8E, 'X'),
-    (0xE94, 'V'),
-    ]
-
-def _seg_13():
-    return [
-    (0xE98, 'X'),
-    (0xE99, 'V'),
-    (0xEA0, 'X'),
-    (0xEA1, 'V'),
+    (0xE8C, 'V'),
     (0xEA4, 'X'),
     (0xEA5, 'V'),
     (0xEA6, 'X'),
     (0xEA7, 'V'),
-    (0xEA8, 'X'),
-    (0xEAA, 'V'),
-    (0xEAC, 'X'),
-    (0xEAD, 'V'),
+    ]
+
+def _seg_13():
+    return [
     (0xEB3, 'M', u''),
     (0xEB4, 'V'),
-    (0xEBA, 'X'),
-    (0xEBB, 'V'),
     (0xEBE, 'X'),
     (0xEC0, 'V'),
     (0xEC5, 'X'),
@@ -1459,10 +1445,6 @@ def _seg_13():
     (0x1260, 'V'),
     (0x1289, 'X'),
     (0x128A, 'V'),
-    ]
-
-def _seg_14():
-    return [
     (0x128E, 'X'),
     (0x1290, 'V'),
     (0x12B1, 'X'),
@@ -1477,6 +1459,10 @@ def _seg_14():
     (0x12C8, 'V'),
     (0x12D7, 'X'),
     (0x12D8, 'V'),
+    ]
+
+def _seg_14():
+    return [
     (0x1311, 'X'),
     (0x1312, 'V'),
     (0x1316, 'X'),
@@ -1563,10 +1549,6 @@ def _seg_14():
     (0x1A7F, 'V'),
     (0x1A8A, 'X'),
     (0x1A90, 'V'),
-    ]
-
-def _seg_15():
-    return [
     (0x1A9A, 'X'),
     (0x1AA0, 'V'),
     (0x1AAE, 'X'),
@@ -1581,6 +1563,10 @@ def _seg_15():
     (0x1BFC, 'V'),
     (0x1C38, 'X'),
     (0x1C3B, 'V'),
+    ]
+
+def _seg_15():
+    return [
     (0x1C4A, 'X'),
     (0x1C4D, 'V'),
     (0x1C80, 'M', u''),
@@ -1592,10 +1578,57 @@ def _seg_15():
     (0x1C87, 'M', u''),
     (0x1C88, 'M', u''),
     (0x1C89, 'X'),
+    (0x1C90, 'M', u''),
+    (0x1C91, 'M', u''),
+    (0x1C92, 'M', u''),
+    (0x1C93, 'M', u''),
+    (0x1C94, 'M', u''),
+    (0x1C95, 'M', u''),
+    (0x1C96, 'M', u''),
+    (0x1C97, 'M', u''),
+    (0x1C98, 'M', u''),
+    (0x1C99, 'M', u''),
+    (0x1C9A, 'M', u''),
+    (0x1C9B, 'M', u''),
+    (0x1C9C, 'M', u''),
+    (0x1C9D, 'M', u''),
+    (0x1C9E, 'M', u''),
+    (0x1C9F, 'M', u''),
+    (0x1CA0, 'M', u''),
+    (0x1CA1, 'M', u''),
+    (0x1CA2, 'M', u''),
+    (0x1CA3, 'M', u''),
+    (0x1CA4, 'M', u''),
+    (0x1CA5, 'M', u''),
+    (0x1CA6, 'M', u''),
+    (0x1CA7, 'M', u''),
+    (0x1CA8, 'M', u''),
+    (0x1CA9, 'M', u''),
+    (0x1CAA, 'M', u''),
+    (0x1CAB, 'M', u''),
+    (0x1CAC, 'M', u''),
+    (0x1CAD, 'M', u''),
+    (0x1CAE, 'M', u''),
+    (0x1CAF, 'M', u''),
+    (0x1CB0, 'M', u''),
+    (0x1CB1, 'M', u''),
+    (0x1CB2, 'M', u''),
+    (0x1CB3, 'M', u''),
+    (0x1CB4, 'M', u''),
+    (0x1CB5, 'M', u''),
+    (0x1CB6, 'M', u''),
+    (0x1CB7, 'M', u''),
+    (0x1CB8, 'M', u''),
+    (0x1CB9, 'M', u''),
+    (0x1CBA, 'M', u''),
+    (0x1CBB, 'X'),
+    (0x1CBD, 'M', u''),
+    (0x1CBE, 'M', u''),
+    (0x1CBF, 'M', u''),
     (0x1CC0, 'V'),
     (0x1CC8, 'X'),
     (0x1CD0, 'V'),
-    (0x1CFA, 'X'),
+    (0x1CFB, 'X'),
     (0x1D00, 'V'),
     (0x1D2C, 'M', u'a'),
     (0x1D2D, 'M', u''),
@@ -1634,6 +1667,10 @@ def _seg_15():
     (0x1D4E, 'V'),
     (0x1D4F, 'M', u'k'),
     (0x1D50, 'M', u'm'),
+    ]
+
+def _seg_16():
+    return [
     (0x1D51, 'M', u''),
     (0x1D52, 'M', u'o'),
     (0x1D53, 'M', u''),
@@ -1667,10 +1704,6 @@ def _seg_15():
     (0x1D9C, 'M', u'c'),
     (0x1D9D, 'M', u''),
     (0x1D9E, 'M', u''),
-    ]
-
-def _seg_16():
-    return [
     (0x1D9F, 'M', u''),
     (0x1DA0, 'M', u'f'),
     (0x1DA1, 'M', u''),
@@ -1738,6 +1771,10 @@ def _seg_16():
     (0x1E1C, 'M', u''),
     (0x1E1D, 'V'),
     (0x1E1E, 'M', u''),
+    ]
+
+def _seg_17():
+    return [
     (0x1E1F, 'V'),
     (0x1E20, 'M', u''),
     (0x1E21, 'V'),
@@ -1771,10 +1808,6 @@ def _seg_16():
     (0x1E3D, 'V'),
     (0x1E3E, 'M', u''),
     (0x1E3F, 'V'),
-    ]
-
-def _seg_17():
-    return [
     (0x1E40, 'M', u''),
     (0x1E41, 'V'),
     (0x1E42, 'M', u''),
@@ -1842,6 +1875,10 @@ def _seg_17():
     (0x1E80, 'M', u''),
     (0x1E81, 'V'),
     (0x1E82, 'M', u''),
+    ]
+
+def _seg_18():
+    return [
     (0x1E83, 'V'),
     (0x1E84, 'M', u''),
     (0x1E85, 'V'),
@@ -1875,10 +1912,6 @@ def _seg_17():
     (0x1EA6, 'M', u''),
     (0x1EA7, 'V'),
     (0x1EA8, 'M', u''),
-    ]
-
-def _seg_18():
-    return [
     (0x1EA9, 'V'),
     (0x1EAA, 'M', u''),
     (0x1EAB, 'V'),
@@ -1946,6 +1979,10 @@ def _seg_18():
     (0x1EE9, 'V'),
     (0x1EEA, 'M', u''),
     (0x1EEB, 'V'),
+    ]
+
+def _seg_19():
+    return [
     (0x1EEC, 'M', u''),
     (0x1EED, 'V'),
     (0x1EEE, 'M', u''),
@@ -1979,10 +2016,6 @@ def _seg_18():
     (0x1F18, 'M', u''),
     (0x1F19, 'M', u''),
     (0x1F1A, 'M', u''),
-    ]
-
-def _seg_19():
-    return [
     (0x1F1B, 'M', u''),
     (0x1F1C, 'M', u''),
     (0x1F1D, 'M', u''),
@@ -2050,6 +2083,10 @@ def _seg_19():
     (0x1F80, 'M', u''),
     (0x1F81, 'M', u''),
     (0x1F82, 'M', u''),
+    ]
+
+def _seg_20():
+    return [
     (0x1F83, 'M', u''),
     (0x1F84, 'M', u''),
     (0x1F85, 'M', u''),
@@ -2083,10 +2120,6 @@ def _seg_19():
     (0x1FA1, 'M', u''),
     (0x1FA2, 'M', u''),
     (0x1FA3, 'M', u''),
-    ]
-
-def _seg_20():
-    return [
     (0x1FA4, 'M', u''),
     (0x1FA5, 'M', u''),
     (0x1FA6, 'M', u''),
@@ -2154,6 +2187,10 @@ def _seg_20():
     (0x1FEE, '3', u' '),
     (0x1FEF, '3', u'`'),
     (0x1FF0, 'X'),
+    ]
+
+def _seg_21():
+    return [
     (0x1FF2, 'M', u''),
     (0x1FF3, 'M', u''),
     (0x1FF4, 'M', u''),
@@ -2187,10 +2224,6 @@ def _seg_20():
     (0x2035, 'V'),
     (0x2036, 'M', u''),
     (0x2037, 'M', u''),
-    ]
-
-def _seg_21():
-    return [
     (0x2038, 'V'),
     (0x203C, '3', u'!!'),
     (0x203D, 'V'),
@@ -2258,6 +2291,10 @@ def _seg_21():
     (0x20C0, 'X'),
     (0x20D0, 'V'),
     (0x20F1, 'X'),
+    ]
+
+def _seg_22():
+    return [
     (0x2100, '3', u'a/c'),
     (0x2101, '3', u'a/s'),
     (0x2102, 'M', u'c'),
@@ -2291,10 +2328,6 @@ def _seg_21():
     (0x2127, 'V'),
     (0x2128, 'M', u'z'),
     (0x2129, 'V'),
-    ]
-
-def _seg_22():
-    return [
     (0x212A, 'M', u'k'),
     (0x212B, 'M', u''),
     (0x212C, 'M', u'b'),
@@ -2362,6 +2395,10 @@ def _seg_22():
     (0x2175, 'M', u'vi'),
     (0x2176, 'M', u'vii'),
     (0x2177, 'M', u'viii'),
+    ]
+
+def _seg_23():
+    return [
     (0x2178, 'M', u'ix'),
     (0x2179, 'M', u'x'),
     (0x217A, 'M', u'xi'),
@@ -2395,10 +2432,6 @@ def _seg_22():
     (0x244B, 'X'),
     (0x2460, 'M', u'1'),
     (0x2461, 'M', u'2'),
-    ]
-
-def _seg_23():
-    return [
     (0x2462, 'M', u'3'),
     (0x2463, 'M', u'4'),
     (0x2464, 'M', u'5'),
@@ -2466,6 +2499,10 @@ def _seg_23():
     (0x24B5, '3', u'(z)'),
     (0x24B6, 'M', u'a'),
     (0x24B7, 'M', u'b'),
+    ]
+
+def _seg_24():
+    return [
     (0x24B8, 'M', u'c'),
     (0x24B9, 'M', u'd'),
     (0x24BA, 'M', u'e'),
@@ -2499,10 +2536,6 @@ def _seg_23():
     (0x24D6, 'M', u'g'),
     (0x24D7, 'M', u'h'),
     (0x24D8, 'M', u'i'),
-    ]
-
-def _seg_24():
-    return [
     (0x24D9, 'M', u'j'),
     (0x24DA, 'M', u'k'),
     (0x24DB, 'M', u'l'),
@@ -2534,9 +2567,6 @@ def _seg_24():
     (0x2B76, 'V'),
     (0x2B96, 'X'),
     (0x2B98, 'V'),
-    (0x2BC9, 'X'),
-    (0x2BCA, 'V'),
-    (0x2BFF, 'X'),
     (0x2C00, 'M', u''),
     (0x2C01, 'M', u''),
     (0x2C02, 'M', u''),
@@ -2573,6 +2603,10 @@ def _seg_24():
     (0x2C21, 'M', u''),
     (0x2C22, 'M', u''),
     (0x2C23, 'M', u''),
+    ]
+
+def _seg_25():
+    return [
     (0x2C24, 'M', u''),
     (0x2C25, 'M', u''),
     (0x2C26, 'M', u''),
@@ -2603,10 +2637,6 @@ def _seg_24():
     (0x2C6E, 'M', u''),
     (0x2C6F, 'M', u''),
     (0x2C70, 'M', u''),
-    ]
-
-def _seg_25():
-    return [
     (0x2C71, 'V'),
     (0x2C72, 'M', u''),
     (0x2C73, 'V'),
@@ -2677,6 +2707,10 @@ def _seg_25():
     (0x2CBA, 'M', u''),
     (0x2CBB, 'V'),
     (0x2CBC, 'M', u''),
+    ]
+
+def _seg_26():
+    return [
     (0x2CBD, 'V'),
     (0x2CBE, 'M', u''),
     (0x2CBF, 'V'),
@@ -2707,10 +2741,6 @@ def _seg_25():
     (0x2CD8, 'M', u''),
     (0x2CD9, 'V'),
     (0x2CDA, 'M', u''),
-    ]
-
-def _seg_26():
-    return [
     (0x2CDB, 'V'),
     (0x2CDC, 'M', u''),
     (0x2CDD, 'V'),
@@ -2757,7 +2787,7 @@ def _seg_26():
     (0x2DD8, 'V'),
     (0x2DDF, 'X'),
     (0x2DE0, 'V'),
-    (0x2E4F, 'X'),
+    (0x2E50, 'X'),
     (0x2E80, 'V'),
     (0x2E9A, 'X'),
     (0x2E9B, 'V'),
@@ -2781,6 +2811,10 @@ def _seg_26():
     (0x2F0D, 'M', u''),
     (0x2F0E, 'M', u''),
     (0x2F0F, 'M', u''),
+    ]
+
+def _seg_27():
+    return [
     (0x2F10, 'M', u''),
     (0x2F11, 'M', u''),
     (0x2F12, 'M', u''),
@@ -2811,10 +2845,6 @@ def _seg_26():
     (0x2F2B, 'M', u''),
     (0x2F2C, 'M', u''),
     (0x2F2D, 'M', u''),
-    ]
-
-def _seg_27():
-    return [
     (0x2F2E, 'M', u''),
     (0x2F2F, 'M', u''),
     (0x2F30, 'M', u''),
@@ -2885,6 +2915,10 @@ def _seg_27():
     (0x2F71, 'M', u''),
     (0x2F72, 'M', u''),
     (0x2F73, 'M', u''),
+    ]
+
+def _seg_28():
+    return [
     (0x2F74, 'M', u''),
     (0x2F75, 'M', u''),
     (0x2F76, 'M', u''),
@@ -2915,10 +2949,6 @@ def _seg_27():
     (0x2F8F, 'M', u''),
     (0x2F90, 'M', u''),
     (0x2F91, 'M', u''),
-    ]
-
-def _seg_28():
-    return [
     (0x2F92, 'M', u''),
     (0x2F93, 'M', u''),
     (0x2F94, 'M', u''),
@@ -2989,6 +3019,10 @@ def _seg_28():
     (0x2FD5, 'M', u''),
     (0x2FD6, 'X'),
     (0x3000, '3', u' '),
+    ]
+
+def _seg_29():
+    return [
     (0x3001, 'V'),
     (0x3002, 'M', u'.'),
     (0x3003, 'V'),
@@ -3019,10 +3053,6 @@ def _seg_28():
     (0x3136, 'M', u''),
     (0x3137, 'M', u''),
     (0x3138, 'M', u''),
-    ]
-
-def _seg_29():
-    return [
     (0x3139, 'M', u''),
     (0x313A, 'M', u''),
     (0x313B, 'M', u''),
@@ -3093,6 +3123,10 @@ def _seg_29():
     (0x317C, 'M', u''),
     (0x317D, 'M', u''),
     (0x317E, 'M', u''),
+    ]
+
+def _seg_30():
+    return [
     (0x317F, 'M', u''),
     (0x3180, 'M', u''),
     (0x3181, 'M', u''),
@@ -3123,10 +3157,6 @@ def _seg_29():
     (0x319B, 'M', u''),
     (0x319C, 'M', u''),
     (0x319D, 'M', u''),
-    ]
-
-def _seg_30():
-    return [
     (0x319E, 'M', u''),
     (0x319F, 'M', u''),
     (0x31A0, 'V'),
@@ -3197,6 +3227,10 @@ def _seg_30():
     (0x323C, '3', u'()'),
     (0x323D, '3', u'()'),
     (0x323E, '3', u'()'),
+    ]
+
+def _seg_31():
+    return [
     (0x323F, '3', u'()'),
     (0x3240, '3', u'()'),
     (0x3241, '3', u'()'),
@@ -3227,10 +3261,6 @@ def _seg_30():
     (0x3261, 'M', u''),
     (0x3262, 'M', u''),
     (0x3263, 'M', u''),
-    ]
-
-def _seg_31():
-    return [
     (0x3264, 'M', u''),
     (0x3265, 'M', u''),
     (0x3266, 'M', u''),
@@ -3301,6 +3331,10 @@ def _seg_31():
     (0x32A7, 'M', u''),
     (0x32A8, 'M', u''),
     (0x32A9, 'M', u''),
+    ]
+
+def _seg_32():
+    return [
     (0x32AA, 'M', u''),
     (0x32AB, 'M', u''),
     (0x32AC, 'M', u''),
@@ -3331,10 +3365,6 @@ def _seg_31():
     (0x32C5, 'M', u'6'),
     (0x32C6, 'M', u'7'),
     (0x32C7, 'M', u'8'),
-    ]
-
-def _seg_32():
-    return [
     (0x32C8, 'M', u'9'),
     (0x32C9, 'M', u'10'),
     (0x32CA, 'M', u'11'),
@@ -3390,7 +3420,7 @@ def _seg_32():
     (0x32FC, 'M', u''),
     (0x32FD, 'M', u''),
     (0x32FE, 'M', u''),
-    (0x32FF, 'X'),
+    (0x32FF, 'M', u''),
     (0x3300, 'M', u''),
     (0x3301, 'M', u''),
     (0x3302, 'M', u''),
@@ -3405,6 +3435,10 @@ def _seg_32():
     (0x330B, 'M', u''),
     (0x330C, 'M', u''),
     (0x330D, 'M', u''),
+    ]
+
+def _seg_33():
+    return [
     (0x330E, 'M', u''),
     (0x330F, 'M', u''),
     (0x3310, 'M', u''),
@@ -3435,10 +3469,6 @@ def _seg_32():
     (0x3329, 'M', u''),
     (0x332A, 'M', u''),
     (0x332B, 'M', u''),
-    ]
-
-def _seg_33():
-    return [
     (0x332C, 'M', u''),
     (0x332D, 'M', u''),
     (0x332E, 'M', u''),
@@ -3509,6 +3539,10 @@ def _seg_33():
     (0x336F, 'M', u'23'),
     (0x3370, 'M', u'24'),
     (0x3371, 'M', u'hpa'),
+    ]
+
+def _seg_34():
+    return [
     (0x3372, 'M', u'da'),
     (0x3373, 'M', u'au'),
     (0x3374, 'M', u'bar'),
@@ -3539,10 +3573,6 @@ def _seg_33():
     (0x338D, 'M', u'g'),
     (0x338E, 'M', u'mg'),
     (0x338F, 'M', u'kg'),
-    ]
-
-def _seg_34():
-    return [
     (0x3390, 'M', u'hz'),
     (0x3391, 'M', u'khz'),
     (0x3392, 'M', u'mhz'),
@@ -3613,6 +3643,10 @@ def _seg_34():
     (0x33D3, 'M', u'lx'),
     (0x33D4, 'M', u'mb'),
     (0x33D5, 'M', u'mil'),
+    ]
+
+def _seg_35():
+    return [
     (0x33D6, 'M', u'mol'),
     (0x33D7, 'M', u'ph'),
     (0x33D8, 'X'),
@@ -3643,10 +3677,6 @@ def _seg_34():
     (0x33F1, 'M', u'18'),
     (0x33F2, 'M', u'19'),
     (0x33F3, 'M', u'20'),
-    ]
-
-def _seg_35():
-    return [
     (0x33F4, 'M', u'21'),
     (0x33F5, 'M', u'22'),
     (0x33F6, 'M', u'23'),
@@ -3717,6 +3747,10 @@ def _seg_35():
     (0xA66D, 'V'),
     (0xA680, 'M', u''),
     (0xA681, 'V'),
+    ]
+
+def _seg_36():
+    return [
     (0xA682, 'M', u''),
     (0xA683, 'V'),
     (0xA684, 'M', u''),
@@ -3747,10 +3781,6 @@ def _seg_35():
     (0xA69D, 'M', u''),
     (0xA69E, 'V'),
     (0xA6F8, 'X'),
-    ]
-
-def _seg_36():
-    return [
     (0xA700, 'V'),
     (0xA722, 'M', u''),
     (0xA723, 'V'),
@@ -3821,6 +3851,10 @@ def _seg_36():
     (0xA766, 'M', u''),
     (0xA767, 'V'),
     (0xA768, 'M', u''),
+    ]
+
+def _seg_37():
+    return [
     (0xA769, 'V'),
     (0xA76A, 'M', u''),
     (0xA76B, 'V'),
@@ -3851,10 +3885,6 @@ def _seg_36():
     (0xA78E, 'V'),
     (0xA790, 'M', u''),
     (0xA791, 'V'),
-    ]
-
-def _seg_37():
-    return [
     (0xA792, 'M', u''),
     (0xA793, 'V'),
     (0xA796, 'M', u''),
@@ -3891,9 +3921,21 @@ def _seg_37():
     (0xA7B5, 'V'),
     (0xA7B6, 'M', u''),
     (0xA7B7, 'V'),
-    (0xA7B8, 'X'),
+    (0xA7B8, 'M', u''),
     (0xA7B9, 'V'),
-    (0xA7BA, 'X'),
+    (0xA7BA, 'M', u''),
+    (0xA7BB, 'V'),
+    (0xA7BC, 'M', u''),
+    (0xA7BD, 'V'),
+    (0xA7BE, 'M', u''),
+    (0xA7BF, 'V'),
+    (0xA7C0, 'X'),
+    (0xA7C2, 'M', u''),
+    (0xA7C3, 'V'),
+    (0xA7C4, 'M', u''),
+    (0xA7C5, 'M', u''),
+    (0xA7C6, 'M', u''),
+    (0xA7C7, 'X'),
     (0xA7F7, 'V'),
     (0xA7F8, 'M', u''),
     (0xA7F9, 'M', u''),
@@ -3913,6 +3955,10 @@ def _seg_37():
     (0xA97D, 'X'),
     (0xA980, 'V'),
     (0xA9CE, 'X'),
+    ]
+
+def _seg_38():
+    return [
     (0xA9CF, 'V'),
     (0xA9DA, 'X'),
     (0xA9DE, 'V'),
@@ -3943,7 +3989,7 @@ def _seg_37():
     (0xAB5E, 'M', u''),
     (0xAB5F, 'M', u''),
     (0xAB60, 'V'),
-    (0xAB66, 'X'),
+    (0xAB68, 'X'),
     (0xAB70, 'M', u''),
     (0xAB71, 'M', u''),
     (0xAB72, 'M', u''),
@@ -3955,10 +4001,6 @@ def _seg_37():
     (0xAB78, 'M', u''),
     (0xAB79, 'M', u''),
     (0xAB7A, 'M', u''),
-    ]
-
-def _seg_38():
-    return [
     (0xAB7B, 'M', u''),
     (0xAB7C, 'M', u''),
     (0xAB7D, 'M', u''),
@@ -4017,6 +4059,10 @@ def _seg_38():
     (0xABB2, 'M', u''),
     (0xABB3, 'M', u''),
     (0xABB4, 'M', u''),
+    ]
+
+def _seg_39():
+    return [
     (0xABB5, 'M', u''),
     (0xABB6, 'M', u''),
     (0xABB7, 'M', u''),
@@ -4059,10 +4105,6 @@ def _seg_38():
     (0xF913, 'M', u''),
     (0xF914, 'M', u''),
     (0xF915, 'M', u''),
-    ]
-
-def _seg_39():
-    return [
     (0xF916, 'M', u''),
     (0xF917, 'M', u''),
     (0xF918, 'M', u''),
@@ -4121,6 +4163,10 @@ def _seg_39():
     (0xF94D, 'M', u''),
     (0xF94E, 'M', u''),
     (0xF94F, 'M', u''),
+    ]
+
+def _seg_40():
+    return [
     (0xF950, 'M', u''),
     (0xF951, 'M', u''),
     (0xF952, 'M', u''),
@@ -4163,10 +4209,6 @@ def _seg_39():
     (0xF977, 'M', u''),
     (0xF978, 'M', u''),
     (0xF979, 'M', u''),
-    ]
-
-def _seg_40():
-    return [
     (0xF97A, 'M', u''),
     (0xF97B, 'M', u''),
     (0xF97C, 'M', u''),
@@ -4225,6 +4267,10 @@ def _seg_40():
     (0xF9B1, 'M', u''),
     (0xF9B2, 'M', u''),
     (0xF9B3, 'M', u''),
+    ]
+
+def _seg_41():
+    return [
     (0xF9B4, 'M', u''),
     (0xF9B5, 'M', u''),
     (0xF9B6, 'M', u''),
@@ -4267,10 +4313,6 @@ def _seg_40():
     (0xF9DB, 'M', u''),
     (0xF9DC, 'M', u''),
     (0xF9DD, 'M', u''),
-    ]
-
-def _seg_41():
-    return [
     (0xF9DE, 'M', u''),
     (0xF9DF, 'M', u''),
     (0xF9E0, 'M', u''),
@@ -4329,6 +4371,10 @@ def _seg_41():
     (0xFA17, 'M', u''),
     (0xFA18, 'M', u''),
     (0xFA19, 'M', u''),
+    ]
+
+def _seg_42():
+    return [
     (0xFA1A, 'M', u''),
     (0xFA1B, 'M', u''),
     (0xFA1C, 'M', u''),
@@ -4371,10 +4417,6 @@ def _seg_41():
     (0xFA44, 'M', u''),
     (0xFA45, 'M', u''),
     (0xFA46, 'M', u''),
-    ]
-
-def _seg_42():
-    return [
     (0xFA47, 'M', u''),
     (0xFA48, 'M', u''),
     (0xFA49, 'M', u''),
@@ -4433,6 +4475,10 @@ def _seg_42():
     (0xFA80, 'M', u''),
     (0xFA81, 'M', u''),
     (0xFA82, 'M', u''),
+    ]
+
+def _seg_43():
+    return [
     (0xFA83, 'M', u''),
     (0xFA84, 'M', u''),
     (0xFA85, 'M', u''),
@@ -4475,10 +4521,6 @@ def _seg_42():
     (0xFAAA, 'M', u''),
     (0xFAAB, 'M', u''),
     (0xFAAC, 'M', u''),
-    ]
-
-def _seg_43():
-    return [
     (0xFAAD, 'M', u''),
     (0xFAAE, 'M', u''),
     (0xFAAF, 'M', u''),
@@ -4537,6 +4579,10 @@ def _seg_43():
     (0xFB15, 'M', u''),
     (0xFB16, 'M', u''),
     (0xFB17, 'M', u''),
+    ]
+
+def _seg_44():
+    return [
     (0xFB18, 'X'),
     (0xFB1D, 'M', u''),
     (0xFB1E, 'V'),
@@ -4579,10 +4625,6 @@ def _seg_43():
     (0xFB43, 'M', u''),
     (0xFB44, 'M', u''),
     (0xFB45, 'X'),
-    ]
-
-def _seg_44():
-    return [
     (0xFB46, 'M', u''),
     (0xFB47, 'M', u''),
     (0xFB48, 'M', u''),
@@ -4641,6 +4683,10 @@ def _seg_44():
     (0xFBF0, 'M', u''),
     (0xFBF2, 'M', u''),
     (0xFBF4, 'M', u''),
+    ]
+
+def _seg_45():
+    return [
     (0xFBF6, 'M', u''),
     (0xFBF9, 'M', u''),
     (0xFBFC, 'M', u''),
@@ -4683,10 +4729,6 @@ def _seg_44():
     (0xFC24, 'M', u''),
     (0xFC25, 'M', u''),
     (0xFC26, 'M', u''),
-    ]
-
-def _seg_45():
-    return [
     (0xFC27, 'M', u''),
     (0xFC28, 'M', u''),
     (0xFC29, 'M', u''),
@@ -4745,6 +4787,10 @@ def _seg_45():
     (0xFC5E, '3', u' '),
     (0xFC5F, '3', u' '),
     (0xFC60, '3', u' '),
+    ]
+
+def _seg_46():
+    return [
     (0xFC61, '3', u' '),
     (0xFC62, '3', u' '),
     (0xFC63, '3', u' '),
@@ -4787,10 +4833,6 @@ def _seg_45():
     (0xFC88, 'M', u''),
     (0xFC89, 'M', u''),
     (0xFC8A, 'M', u''),
-    ]
-
-def _seg_46():
-    return [
     (0xFC8B, 'M', u''),
     (0xFC8C, 'M', u''),
     (0xFC8D, 'M', u''),
@@ -4849,6 +4891,10 @@ def _seg_46():
     (0xFCC2, 'M', u''),
     (0xFCC3, 'M', u''),
     (0xFCC4, 'M', u''),
+    ]
+
+def _seg_47():
+    return [
     (0xFCC5, 'M', u''),
     (0xFCC6, 'M', u''),
     (0xFCC7, 'M', u''),
@@ -4891,10 +4937,6 @@ def _seg_46():
     (0xFCEC, 'M', u''),
     (0xFCED, 'M', u''),
     (0xFCEE, 'M', u''),
-    ]
-
-def _seg_47():
-    return [
     (0xFCEF, 'M', u''),
     (0xFCF0, 'M', u''),
     (0xFCF1, 'M', u''),
@@ -4953,6 +4995,10 @@ def _seg_47():
     (0xFD26, 'M', u''),
     (0xFD27, 'M', u''),
     (0xFD28, 'M', u''),
+    ]
+
+def _seg_48():
+    return [
     (0xFD29, 'M', u''),
     (0xFD2A, 'M', u''),
     (0xFD2B, 'M', u''),
@@ -4995,10 +5041,6 @@ def _seg_47():
     (0xFD66, 'M', u''),
     (0xFD67, 'M', u''),
     (0xFD69, 'M', u''),
-    ]
-
-def _seg_48():
-    return [
     (0xFD6A, 'M', u''),
     (0xFD6C, 'M', u''),
     (0xFD6E, 'M', u''),
@@ -5057,6 +5099,10 @@ def _seg_48():
     (0xFDAD, 'M', u''),
     (0xFDAE, 'M', u''),
     (0xFDAF, 'M', u''),
+    ]
+
+def _seg_49():
+    return [
     (0xFDB0, 'M', u''),
     (0xFDB1, 'M', u''),
     (0xFDB2, 'M', u''),
@@ -5099,10 +5145,6 @@ def _seg_48():
     (0xFDFE, 'X'),
     (0xFE00, 'I'),
     (0xFE10, '3', u','),
-    ]
-
-def _seg_49():
-    return [
     (0xFE11, 'M', u''),
     (0xFE12, 'X'),
     (0xFE13, '3', u':'),
@@ -5161,6 +5203,10 @@ def _seg_49():
     (0xFE65, '3', u'>'),
     (0xFE66, '3', u'='),
     (0xFE67, 'X'),
+    ]
+
+def _seg_50():
+    return [
     (0xFE68, '3', u'\\'),
     (0xFE69, '3', u'$'),
     (0xFE6A, '3', u'%'),
@@ -5203,10 +5249,6 @@ def _seg_49():
     (0xFEB1, 'M', u''),
     (0xFEB5, 'M', u''),
     (0xFEB9, 'M', u''),
-    ]
-
-def _seg_50():
-    return [
     (0xFEBD, 'M', u''),
     (0xFEC1, 'M', u''),
     (0xFEC5, 'M', u''),
@@ -5265,6 +5307,10 @@ def _seg_50():
     (0xFF22, 'M', u'b'),
     (0xFF23, 'M', u'c'),
     (0xFF24, 'M', u'd'),
+    ]
+
+def _seg_51():
+    return [
     (0xFF25, 'M', u'e'),
     (0xFF26, 'M', u'f'),
     (0xFF27, 'M', u'g'),
@@ -5307,10 +5353,6 @@ def _seg_50():
     (0xFF4C, 'M', u'l'),
     (0xFF4D, 'M', u'm'),
     (0xFF4E, 'M', u'n'),
-    ]
-
-def _seg_51():
-    return [
     (0xFF4F, 'M', u'o'),
     (0xFF50, 'M', u'p'),
     (0xFF51, 'M', u'q'),
@@ -5369,6 +5411,10 @@ def _seg_51():
     (0xFF86, 'M', u''),
     (0xFF87, 'M', u''),
     (0xFF88, 'M', u''),
+    ]
+
+def _seg_52():
+    return [
     (0xFF89, 'M', u''),
     (0xFF8A, 'M', u''),
     (0xFF8B, 'M', u''),
@@ -5411,10 +5457,6 @@ def _seg_51():
     (0xFFB0, 'M', u''),
     (0xFFB1, 'M', u''),
     (0xFFB2, 'M', u''),
-    ]
-
-def _seg_52():
-    return [
     (0xFFB3, 'M', u''),
     (0xFFB4, 'M', u''),
     (0xFFB5, 'M', u''),
@@ -5473,6 +5515,10 @@ def _seg_52():
     (0x1000C, 'X'),
     (0x1000D, 'V'),
     (0x10027, 'X'),
+    ]
+
+def _seg_53():
+    return [
     (0x10028, 'V'),
     (0x1003B, 'X'),
     (0x1003C, 'V'),
@@ -5515,10 +5561,6 @@ def _seg_52():
     (0x103D6, 'X'),
     (0x10400, 'M', u''),
     (0x10401, 'M', u''),
-    ]
-
-def _seg_53():
-    return [
     (0x10402, 'M', u''),
     (0x10403, 'M', u''),
     (0x10404, 'M', u''),
@@ -5577,6 +5619,10 @@ def _seg_53():
     (0x104BD, 'M', u''),
     (0x104BE, 'M', u''),
     (0x104BF, 'M', u''),
+    ]
+
+def _seg_54():
+    return [
     (0x104C0, 'M', u''),
     (0x104C1, 'M', u''),
     (0x104C2, 'M', u''),
@@ -5619,10 +5665,6 @@ def _seg_53():
     (0x1080A, 'V'),
     (0x10836, 'X'),
     (0x10837, 'V'),
-    ]
-
-def _seg_54():
-    return [
     (0x10839, 'X'),
     (0x1083C, 'V'),
     (0x1083D, 'X'),
@@ -5681,6 +5723,10 @@ def _seg_54():
     (0x10BA9, 'V'),
     (0x10BB0, 'X'),
     (0x10C00, 'V'),
+    ]
+
+def _seg_55():
+    return [
     (0x10C49, 'X'),
     (0x10C80, 'M', u''),
     (0x10C81, 'M', u''),
@@ -5723,10 +5769,6 @@ def _seg_54():
     (0x10CA6, 'M', u''),
     (0x10CA7, 'M', u''),
     (0x10CA8, 'M', u''),
-    ]
-
-def _seg_55():
-    return [
     (0x10CA9, 'M', u''),
     (0x10CAA, 'M', u''),
     (0x10CAB, 'M', u''),
@@ -5750,6 +5792,8 @@ def _seg_55():
     (0x10F28, 'X'),
     (0x10F30, 'V'),
     (0x10F5A, 'X'),
+    (0x10FE0, 'V'),
+    (0x10FF7, 'X'),
     (0x11000, 'V'),
     (0x1104E, 'X'),
     (0x11052, 'V'),
@@ -5783,6 +5827,10 @@ def _seg_55():
     (0x11288, 'V'),
     (0x11289, 'X'),
     (0x1128A, 'V'),
+    ]
+
+def _seg_56():
+    return [
     (0x1128E, 'X'),
     (0x1128F, 'V'),
     (0x1129E, 'X'),
@@ -5827,11 +5875,7 @@ def _seg_55():
     (0x1145B, 'V'),
     (0x1145C, 'X'),
     (0x1145D, 'V'),
-    ]
-
-def _seg_56():
-    return [
-    (0x1145F, 'X'),
+    (0x11460, 'X'),
     (0x11480, 'V'),
     (0x114C8, 'X'),
     (0x114D0, 'V'),
@@ -5847,7 +5891,7 @@ def _seg_56():
     (0x11660, 'V'),
     (0x1166D, 'X'),
     (0x11680, 'V'),
-    (0x116B8, 'X'),
+    (0x116B9, 'X'),
     (0x116C0, 'V'),
     (0x116CA, 'X'),
     (0x11700, 'V'),
@@ -5887,6 +5931,10 @@ def _seg_56():
     (0x118BA, 'M', u''),
     (0x118BB, 'M', u''),
     (0x118BC, 'M', u''),
+    ]
+
+def _seg_57():
+    return [
     (0x118BD, 'M', u''),
     (0x118BE, 'M', u''),
     (0x118BF, 'M', u''),
@@ -5894,11 +5942,15 @@ def _seg_56():
     (0x118F3, 'X'),
     (0x118FF, 'V'),
     (0x11900, 'X'),
+    (0x119A0, 'V'),
+    (0x119A8, 'X'),
+    (0x119AA, 'V'),
+    (0x119D8, 'X'),
+    (0x119DA, 'V'),
+    (0x119E5, 'X'),
     (0x11A00, 'V'),
     (0x11A48, 'X'),
     (0x11A50, 'V'),
-    (0x11A84, 'X'),
-    (0x11A86, 'V'),
     (0x11AA3, 'X'),
     (0x11AC0, 'V'),
     (0x11AF9, 'X'),
@@ -5931,10 +5983,6 @@ def _seg_56():
     (0x11D50, 'V'),
     (0x11D5A, 'X'),
     (0x11D60, 'V'),
-    ]
-
-def _seg_57():
-    return [
     (0x11D66, 'X'),
     (0x11D67, 'V'),
     (0x11D69, 'X'),
@@ -5948,7 +5996,9 @@ def _seg_57():
     (0x11DAA, 'X'),
     (0x11EE0, 'V'),
     (0x11EF9, 'X'),
-    (0x12000, 'V'),
+    (0x11FC0, 'V'),
+    (0x11FF2, 'X'),
+    (0x11FFF, 'V'),
     (0x1239A, 'X'),
     (0x12400, 'V'),
     (0x1246F, 'X'),
@@ -5982,22 +6032,62 @@ def _seg_57():
     (0x16B78, 'X'),
     (0x16B7D, 'V'),
     (0x16B90, 'X'),
+    (0x16E40, 'M', u''),
+    (0x16E41, 'M', u''),
+    (0x16E42, 'M', u''),
+    ]
+
+def _seg_58():
+    return [
+    (0x16E43, 'M', u''),
+    (0x16E44, 'M', u''),
+    (0x16E45, 'M', u''),
+    (0x16E46, 'M', u''),
+    (0x16E47, 'M', u''),
+    (0x16E48, 'M', u''),
+    (0x16E49, 'M', u''),
+    (0x16E4A, 'M', u''),
+    (0x16E4B, 'M', u''),
+    (0x16E4C, 'M', u''),
+    (0x16E4D, 'M', u''),
+    (0x16E4E, 'M', u''),
+    (0x16E4F, 'M', u''),
+    (0x16E50, 'M', u''),
+    (0x16E51, 'M', u''),
+    (0x16E52, 'M', u''),
+    (0x16E53, 'M', u''),
+    (0x16E54, 'M', u''),
+    (0x16E55, 'M', u''),
+    (0x16E56, 'M', u''),
+    (0x16E57, 'M', u''),
+    (0x16E58, 'M', u''),
+    (0x16E59, 'M', u''),
+    (0x16E5A, 'M', u''),
+    (0x16E5B, 'M', u''),
+    (0x16E5C, 'M', u''),
+    (0x16E5D, 'M', u''),
+    (0x16E5E, 'M', u''),
+    (0x16E5F, 'M', u''),
     (0x16E60, 'V'),
     (0x16E9B, 'X'),
     (0x16F00, 'V'),
-    (0x16F45, 'X'),
-    (0x16F50, 'V'),
-    (0x16F7F, 'X'),
+    (0x16F4B, 'X'),
+    (0x16F4F, 'V'),
+    (0x16F88, 'X'),
     (0x16F8F, 'V'),
     (0x16FA0, 'X'),
     (0x16FE0, 'V'),
-    (0x16FE2, 'X'),
+    (0x16FE4, 'X'),
     (0x17000, 'V'),
-    (0x187F2, 'X'),
+    (0x187F8, 'X'),
     (0x18800, 'V'),
     (0x18AF3, 'X'),
     (0x1B000, 'V'),
     (0x1B11F, 'X'),
+    (0x1B150, 'V'),
+    (0x1B153, 'X'),
+    (0x1B164, 'V'),
+    (0x1B168, 'X'),
     (0x1B170, 'V'),
     (0x1B2FC, 'X'),
     (0x1BC00, 'V'),
@@ -6035,10 +6125,6 @@ def _seg_57():
     (0x1D1C1, 'V'),
     (0x1D1E9, 'X'),
     (0x1D200, 'V'),
-    ]
-
-def _seg_58():
-    return [
     (0x1D246, 'X'),
     (0x1D2E0, 'V'),
     (0x1D2F4, 'X'),
@@ -6053,6 +6139,10 @@ def _seg_58():
     (0x1D404, 'M', u'e'),
     (0x1D405, 'M', u'f'),
     (0x1D406, 'M', u'g'),
+    ]
+
+def _seg_59():
+    return [
     (0x1D407, 'M', u'h'),
     (0x1D408, 'M', u'i'),
     (0x1D409, 'M', u'j'),
@@ -6139,10 +6229,6 @@ def _seg_58():
     (0x1D45A, 'M', u'm'),
     (0x1D45B, 'M', u'n'),
     (0x1D45C, 'M', u'o'),
-    ]
-
-def _seg_59():
-    return [
     (0x1D45D, 'M', u'p'),
     (0x1D45E, 'M', u'q'),
     (0x1D45F, 'M', u'r'),
@@ -6157,6 +6243,10 @@ def _seg_59():
     (0x1D468, 'M', u'a'),
     (0x1D469, 'M', u'b'),
     (0x1D46A, 'M', u'c'),
+    ]
+
+def _seg_60():
+    return [
     (0x1D46B, 'M', u'd'),
     (0x1D46C, 'M', u'e'),
     (0x1D46D, 'M', u'f'),
@@ -6243,10 +6333,6 @@ def _seg_59():
     (0x1D4C1, 'M', u'l'),
     (0x1D4C2, 'M', u'm'),
     (0x1D4C3, 'M', u'n'),
-    ]
-
-def _seg_60():
-    return [
     (0x1D4C4, 'X'),
     (0x1D4C5, 'M', u'p'),
     (0x1D4C6, 'M', u'q'),
@@ -6261,6 +6347,10 @@ def _seg_60():
     (0x1D4CF, 'M', u'z'),
     (0x1D4D0, 'M', u'a'),
     (0x1D4D1, 'M', u'b'),
+    ]
+
+def _seg_61():
+    return [
     (0x1D4D2, 'M', u'c'),
     (0x1D4D3, 'M', u'd'),
     (0x1D4D4, 'M', u'e'),
@@ -6347,10 +6437,6 @@ def _seg_60():
     (0x1D526, 'M', u'i'),
     (0x1D527, 'M', u'j'),
     (0x1D528, 'M', u'k'),
-    ]
-
-def _seg_61():
-    return [
     (0x1D529, 'M', u'l'),
     (0x1D52A, 'M', u'm'),
     (0x1D52B, 'M', u'n'),
@@ -6365,6 +6451,10 @@ def _seg_61():
     (0x1D534, 'M', u'w'),
     (0x1D535, 'M', u'x'),
     (0x1D536, 'M', u'y'),
+    ]
+
+def _seg_62():
+    return [
     (0x1D537, 'M', u'z'),
     (0x1D538, 'M', u'a'),
     (0x1D539, 'M', u'b'),
@@ -6451,10 +6541,6 @@ def _seg_61():
     (0x1D58C, 'M', u'g'),
     (0x1D58D, 'M', u'h'),
     (0x1D58E, 'M', u'i'),
-    ]
-
-def _seg_62():
-    return [
     (0x1D58F, 'M', u'j'),
     (0x1D590, 'M', u'k'),
     (0x1D591, 'M', u'l'),
@@ -6469,6 +6555,10 @@ def _seg_62():
     (0x1D59A, 'M', u'u'),
     (0x1D59B, 'M', u'v'),
     (0x1D59C, 'M', u'w'),
+    ]
+
+def _seg_63():
+    return [
     (0x1D59D, 'M', u'x'),
     (0x1D59E, 'M', u'y'),
     (0x1D59F, 'M', u'z'),
@@ -6555,10 +6645,6 @@ def _seg_62():
     (0x1D5F0, 'M', u'c'),
     (0x1D5F1, 'M', u'd'),
     (0x1D5F2, 'M', u'e'),
-    ]
-
-def _seg_63():
-    return [
     (0x1D5F3, 'M', u'f'),
     (0x1D5F4, 'M', u'g'),
     (0x1D5F5, 'M', u'h'),
@@ -6573,6 +6659,10 @@ def _seg_63():
     (0x1D5FE, 'M', u'q'),
     (0x1D5FF, 'M', u'r'),
     (0x1D600, 'M', u's'),
+    ]
+
+def _seg_64():
+    return [
     (0x1D601, 'M', u't'),
     (0x1D602, 'M', u'u'),
     (0x1D603, 'M', u'v'),
@@ -6659,10 +6749,6 @@ def _seg_63():
     (0x1D654, 'M', u'y'),
     (0x1D655, 'M', u'z'),
     (0x1D656, 'M', u'a'),
-    ]
-
-def _seg_64():
-    return [
     (0x1D657, 'M', u'b'),
     (0x1D658, 'M', u'c'),
     (0x1D659, 'M', u'd'),
@@ -6677,6 +6763,10 @@ def _seg_64():
     (0x1D662, 'M', u'm'),
     (0x1D663, 'M', u'n'),
     (0x1D664, 'M', u'o'),
+    ]
+
+def _seg_65():
+    return [
     (0x1D665, 'M', u'p'),
     (0x1D666, 'M', u'q'),
     (0x1D667, 'M', u'r'),
@@ -6763,10 +6853,6 @@ def _seg_64():
     (0x1D6B9, 'M', u''),
     (0x1D6BA, 'M', u''),
     (0x1D6BB, 'M', u''),
-    ]
-
-def _seg_65():
-    return [
     (0x1D6BC, 'M', u''),
     (0x1D6BD, 'M', u''),
     (0x1D6BE, 'M', u''),
@@ -6781,6 +6867,10 @@ def _seg_65():
     (0x1D6C7, 'M', u''),
     (0x1D6C8, 'M', u''),
     (0x1D6C9, 'M', u''),
+    ]
+
+def _seg_66():
+    return [
     (0x1D6CA, 'M', u''),
     (0x1D6CB, 'M', u''),
     (0x1D6CC, 'M', u''),
@@ -6867,10 +6957,6 @@ def _seg_65():
     (0x1D71F, 'M', u''),
     (0x1D720, 'M', u''),
     (0x1D721, 'M', u''),
-    ]
-
-def _seg_66():
-    return [
     (0x1D722, 'M', u''),
     (0x1D723, 'M', u''),
     (0x1D724, 'M', u''),
@@ -6885,6 +6971,10 @@ def _seg_66():
     (0x1D72D, 'M', u''),
     (0x1D72E, 'M', u''),
     (0x1D72F, 'M', u''),
+    ]
+
+def _seg_67():
+    return [
     (0x1D730, 'M', u''),
     (0x1D731, 'M', u''),
     (0x1D732, 'M', u''),
@@ -6971,10 +7061,6 @@ def _seg_66():
     (0x1D785, 'M', u''),
     (0x1D786, 'M', u''),
     (0x1D787, 'M', u''),
-    ]
-
-def _seg_67():
-    return [
     (0x1D788, 'M', u''),
     (0x1D789, 'M', u''),
     (0x1D78A, 'M', u''),
@@ -6989,6 +7075,10 @@ def _seg_67():
     (0x1D793, 'M', u''),
     (0x1D794, 'M', u''),
     (0x1D795, 'M', u''),
+    ]
+
+def _seg_68():
+    return [
     (0x1D796, 'M', u''),
     (0x1D797, 'M', u''),
     (0x1D798, 'M', u''),
@@ -7075,10 +7165,6 @@ def _seg_67():
     (0x1D7EC, 'M', u'0'),
     (0x1D7ED, 'M', u'1'),
     (0x1D7EE, 'M', u'2'),
-    ]
-
-def _seg_68():
-    return [
     (0x1D7EF, 'M', u'3'),
     (0x1D7F0, 'M', u'4'),
     (0x1D7F1, 'M', u'5'),
@@ -7093,6 +7179,10 @@ def _seg_68():
     (0x1D7FA, 'M', u'4'),
     (0x1D7FB, 'M', u'5'),
     (0x1D7FC, 'M', u'6'),
+    ]
+
+def _seg_69():
+    return [
     (0x1D7FD, 'M', u'7'),
     (0x1D7FE, 'M', u'8'),
     (0x1D7FF, 'M', u'9'),
@@ -7112,6 +7202,18 @@ def _seg_68():
     (0x1E025, 'X'),
     (0x1E026, 'V'),
     (0x1E02B, 'X'),
+    (0x1E100, 'V'),
+    (0x1E12D, 'X'),
+    (0x1E130, 'V'),
+    (0x1E13E, 'X'),
+    (0x1E140, 'V'),
+    (0x1E14A, 'X'),
+    (0x1E14E, 'V'),
+    (0x1E150, 'X'),
+    (0x1E2C0, 'V'),
+    (0x1E2FA, 'X'),
+    (0x1E2FF, 'V'),
+    (0x1E300, 'X'),
     (0x1E800, 'V'),
     (0x1E8C5, 'X'),
     (0x1E8C7, 'V'),
@@ -7151,13 +7253,15 @@ def _seg_68():
     (0x1E920, 'M', u''),
     (0x1E921, 'M', u''),
     (0x1E922, 'V'),
-    (0x1E94B, 'X'),
+    (0x1E94C, 'X'),
     (0x1E950, 'V'),
     (0x1E95A, 'X'),
     (0x1E95E, 'V'),
     (0x1E960, 'X'),
     (0x1EC71, 'V'),
     (0x1ECB5, 'X'),
+    (0x1ED01, 'V'),
+    (0x1ED3E, 'X'),
     (0x1EE00, 'M', u''),
     (0x1EE01, 'M', u''),
     (0x1EE02, 'M', u''),
@@ -7181,7 +7285,7 @@ def _seg_68():
     (0x1EE14, 'M', u''),
     ]
 
-def _seg_69():
+def _seg_70():
     return [
     (0x1EE15, 'M', u''),
     (0x1EE16, 'M', u''),
@@ -7285,7 +7389,7 @@ def _seg_69():
     (0x1EE83, 'M', u''),
     ]
 
-def _seg_70():
+def _seg_71():
     return [
     (0x1EE84, 'M', u''),
     (0x1EE85, 'M', u''),
@@ -7389,7 +7493,7 @@ def _seg_70():
     (0x1F124, '3', u'(u)'),
     ]
 
-def _seg_71():
+def _seg_72():
     return [
     (0x1F125, '3', u'(v)'),
     (0x1F126, '3', u'(w)'),
@@ -7437,7 +7541,8 @@ def _seg_71():
     (0x1F150, 'V'),
     (0x1F16A, 'M', u'mc'),
     (0x1F16B, 'M', u'md'),
-    (0x1F16C, 'X'),
+    (0x1F16C, 'M', u'mr'),
+    (0x1F16D, 'X'),
     (0x1F170, 'V'),
     (0x1F190, 'M', u'dj'),
     (0x1F191, 'V'),
@@ -7490,11 +7595,11 @@ def _seg_71():
     (0x1F238, 'M', u''),
     (0x1F239, 'M', u''),
     (0x1F23A, 'M', u''),
-    (0x1F23B, 'M', u''),
     ]
 
-def _seg_72():
+def _seg_73():
     return [
+    (0x1F23B, 'M', u''),
     (0x1F23C, 'X'),
     (0x1F240, 'M', u''),
     (0x1F241, 'M', u''),
@@ -7512,15 +7617,17 @@ def _seg_72():
     (0x1F260, 'V'),
     (0x1F266, 'X'),
     (0x1F300, 'V'),
-    (0x1F6D5, 'X'),
+    (0x1F6D6, 'X'),
     (0x1F6E0, 'V'),
     (0x1F6ED, 'X'),
     (0x1F6F0, 'V'),
-    (0x1F6FA, 'X'),
+    (0x1F6FB, 'X'),
     (0x1F700, 'V'),
     (0x1F774, 'X'),
     (0x1F780, 'V'),
     (0x1F7D9, 'X'),
+    (0x1F7E0, 'V'),
+    (0x1F7EC, 'X'),
     (0x1F800, 'V'),
     (0x1F80C, 'X'),
     (0x1F810, 'V'),
@@ -7533,24 +7640,28 @@ def _seg_72():
     (0x1F8AE, 'X'),
     (0x1F900, 'V'),
     (0x1F90C, 'X'),
-    (0x1F910, 'V'),
-    (0x1F93F, 'X'),
-    (0x1F940, 'V'),
-    (0x1F971, 'X'),
+    (0x1F90D, 'V'),
+    (0x1F972, 'X'),
     (0x1F973, 'V'),
     (0x1F977, 'X'),
     (0x1F97A, 'V'),
-    (0x1F97B, 'X'),
-    (0x1F97C, 'V'),
     (0x1F9A3, 'X'),
-    (0x1F9B0, 'V'),
-    (0x1F9BA, 'X'),
-    (0x1F9C0, 'V'),
-    (0x1F9C3, 'X'),
-    (0x1F9D0, 'V'),
-    (0x1FA00, 'X'),
+    (0x1F9A5, 'V'),
+    (0x1F9AB, 'X'),
+    (0x1F9AE, 'V'),
+    (0x1F9CB, 'X'),
+    (0x1F9CD, 'V'),
+    (0x1FA54, 'X'),
     (0x1FA60, 'V'),
     (0x1FA6E, 'X'),
+    (0x1FA70, 'V'),
+    (0x1FA74, 'X'),
+    (0x1FA78, 'V'),
+    (0x1FA7B, 'X'),
+    (0x1FA80, 'V'),
+    (0x1FA83, 'X'),
+    (0x1FA90, 'V'),
+    (0x1FA96, 'X'),
     (0x20000, 'V'),
     (0x2A6D7, 'X'),
     (0x2A700, 'V'),
@@ -7588,6 +7699,10 @@ def _seg_72():
     (0x2F818, 'M', u''),
     (0x2F819, 'M', u''),
     (0x2F81A, 'M', u''),
+    ]
+
+def _seg_74():
+    return [
     (0x2F81B, 'M', u''),
     (0x2F81C, 'M', u''),
     (0x2F81D, 'M', u''),
@@ -7595,10 +7710,6 @@ def _seg_72():
     (0x2F81F, 'M', u''),
     (0x2F820, 'M', u''),
     (0x2F821, 'M', u''),
-    ]
-
-def _seg_73():
-    return [
     (0x2F822, 'M', u''),
     (0x2F823, 'M', u''),
     (0x2F824, 'M', u''),
@@ -7692,6 +7803,10 @@ def _seg_73():
     (0x2F880, 'M', u''),
     (0x2F881, 'M', u''),
     (0x2F882, 'M', u''),
+    ]
+
+def _seg_75():
+    return [
     (0x2F883, 'M', u''),
     (0x2F884, 'M', u''),
     (0x2F885, 'M', u''),
@@ -7699,10 +7814,6 @@ def _seg_73():
     (0x2F887, 'M', u''),
     (0x2F888, 'M', u''),
     (0x2F889, 'M', u''),
-    ]
-
-def _seg_74():
-    return [
     (0x2F88A, 'M', u''),
     (0x2F88B, 'M', u''),
     (0x2F88C, 'M', u''),
@@ -7796,6 +7907,10 @@ def _seg_74():
     (0x2F8E6, 'M', u''),
     (0x2F8E7, 'M', u''),
     (0x2F8E8, 'M', u''),
+    ]
+
+def _seg_76():
+    return [
     (0x2F8E9, 'M', u''),
     (0x2F8EA, 'M', u''),
     (0x2F8EB, 'M', u''),
@@ -7803,10 +7918,6 @@ def _seg_74():
     (0x2F8ED, 'M', u''),
     (0x2F8EE, 'M', u''),
     (0x2F8EF, 'M', u''),
-    ]
-
-def _seg_75():
-    return [
     (0x2F8F0, 'M', u''),
     (0x2F8F1, 'M', u''),
     (0x2F8F2, 'M', u''),
@@ -7900,6 +8011,10 @@ def _seg_75():
     (0x2F94C, 'M', u''),
     (0x2F94D, 'M', u''),
     (0x2F94E, 'M', u''),
+    ]
+
+def _seg_77():
+    return [
     (0x2F94F, 'M', u''),
     (0x2F950, 'M', u''),
     (0x2F951, 'M', u''),
@@ -7907,10 +8022,6 @@ def _seg_75():
     (0x2F953, 'M', u''),
     (0x2F954, 'M', u''),
     (0x2F955, 'M', u''),
-    ]
-
-def _seg_76():
-    return [
     (0x2F956, 'M', u''),
     (0x2F957, 'M', u''),
     (0x2F958, 'M', u''),
@@ -8004,6 +8115,10 @@ def _seg_76():
     (0x2F9B1, 'M', u''),
     (0x2F9B2, 'M', u''),
     (0x2F9B3, 'M', u''),
+    ]
+
+def _seg_78():
+    return [
     (0x2F9B4, 'M', u''),
     (0x2F9B5, 'M', u''),
     (0x2F9B6, 'M', u''),
@@ -8011,10 +8126,6 @@ def _seg_76():
     (0x2F9B8, 'M', u''),
     (0x2F9B9, 'M', u''),
     (0x2F9BA, 'M', u''),
-    ]
-
-def _seg_77():
-    return [
     (0x2F9BB, 'M', u''),
     (0x2F9BC, 'M', u''),
     (0x2F9BD, 'M', u''),
@@ -8108,6 +8219,10 @@ def _seg_77():
     (0x2FA16, 'M', u''),
     (0x2FA17, 'M', u''),
     (0x2FA18, 'M', u''),
+    ]
+
+def _seg_79():
+    return [
     (0x2FA19, 'M', u''),
     (0x2FA1A, 'M', u''),
     (0x2FA1B, 'M', u''),
@@ -8115,10 +8230,6 @@ def _seg_77():
     (0x2FA1D, 'M', u''),
     (0x2FA1E, 'X'),
     (0xE0100, 'I'),
-    ]
-
-def _seg_78():
-    return [
     (0xE01F0, 'X'),
     ]
 
@@ -8202,4 +8313,5 @@ uts46data = tuple(
     + _seg_76()
     + _seg_77()
     + _seg_78()
+    + _seg_79()
 )
diff --git a/pipenv/vendor/importlib_metadata/__init__.py b/pipenv/vendor/importlib_metadata/__init__.py
index 6da7fd2c..089fca97 100644
--- a/pipenv/vendor/importlib_metadata/__init__.py
+++ b/pipenv/vendor/importlib_metadata/__init__.py
@@ -10,6 +10,7 @@ import zipp
 import operator
 import functools
 import itertools
+import posixpath
 import collections
 
 from ._compat import (
@@ -23,7 +24,6 @@ from ._compat import (
     NotADirectoryError,
     PermissionError,
     pathlib,
-    PYPY_OPEN_BUG,
     ModuleNotFoundError,
     MetaPathFinder,
     email_message_from_string,
@@ -389,10 +389,6 @@ class DistributionFinder(MetaPathFinder):
             """
             return vars(self).get('path', sys.path)
 
-        @property
-        def pattern(self):
-            return '.*' if self.name is None else re.escape(self.name)
-
     @abc.abstractmethod
     def find_distributions(self, context=Context()):
         """
@@ -404,6 +400,75 @@ class DistributionFinder(MetaPathFinder):
         """
 
 
+class FastPath:
+    """
+    Micro-optimized class for searching a path for
+    children.
+    """
+
+    def __init__(self, root):
+        self.root = root
+        self.base = os.path.basename(root).lower()
+
+    def joinpath(self, child):
+        return pathlib.Path(self.root, child)
+
+    def children(self):
+        with suppress(Exception):
+            return os.listdir(self.root or '')
+        with suppress(Exception):
+            return self.zip_children()
+        return []
+
+    def zip_children(self):
+        zip_path = zipp.Path(self.root)
+        names = zip_path.root.namelist()
+        self.joinpath = zip_path.joinpath
+
+        return (
+            posixpath.split(child)[0]
+            for child in names
+            )
+
+    def is_egg(self, search):
+        base = self.base
+        return (
+            base == search.versionless_egg_name
+            or base.startswith(search.prefix)
+            and base.endswith('.egg'))
+
+    def search(self, name):
+        for child in self.children():
+            n_low = child.lower()
+            if (n_low in name.exact_matches
+                    or n_low.startswith(name.prefix)
+                    and n_low.endswith(name.suffixes)
+                    # legacy case:
+                    or self.is_egg(name) and n_low == 'egg-info'):
+                yield self.joinpath(child)
+
+
+class Prepared:
+    """
+    A prepared search for metadata on a possibly-named package.
+    """
+    normalized = ''
+    prefix = ''
+    suffixes = '.dist-info', '.egg-info'
+    exact_matches = [''][:0]
+    versionless_egg_name = ''
+
+    def __init__(self, name):
+        self.name = name
+        if name is None:
+            return
+        self.normalized = name.lower().replace('-', '_')
+        self.prefix = self.normalized + '-'
+        self.exact_matches = [
+            self.normalized + suffix for suffix in self.suffixes]
+        self.versionless_egg_name = self.normalized + '.egg'
+
+
 @install
 class MetadataPathFinder(NullFinder, DistributionFinder):
     """A degenerate finder for distribution packages on the file system.
@@ -421,45 +486,17 @@ class MetadataPathFinder(NullFinder, DistributionFinder):
         (or all names if ``None`` indicated) along the paths in the list
         of directories ``context.path``.
         """
-        found = self._search_paths(context.pattern, context.path)
+        found = self._search_paths(context.name, context.path)
         return map(PathDistribution, found)
 
     @classmethod
-    def _search_paths(cls, pattern, paths):
+    def _search_paths(cls, name, paths):
         """Find metadata directories in paths heuristically."""
         return itertools.chain.from_iterable(
-            cls._search_path(path, pattern)
-            for path in map(cls._switch_path, paths)
+            path.search(Prepared(name))
+            for path in map(FastPath, paths)
             )
 
-    @staticmethod
-    def _switch_path(path):
-        if not PYPY_OPEN_BUG or os.path.isfile(path):  # pragma: no branch
-            with suppress(Exception):
-                return zipp.Path(path)
-        return pathlib.Path(path)
-
-    @classmethod
-    def _matches_info(cls, normalized, item):
-        template = r'{pattern}(-.*)?\.(dist|egg)-info'
-        manifest = template.format(pattern=normalized)
-        return re.match(manifest, item.name, flags=re.IGNORECASE)
-
-    @classmethod
-    def _matches_legacy(cls, normalized, item):
-        template = r'{pattern}-.*\.egg[\\/]EGG-INFO'
-        manifest = template.format(pattern=normalized)
-        return re.search(manifest, str(item), flags=re.IGNORECASE)
-
-    @classmethod
-    def _search_path(cls, root, pattern):
-        if not root.is_dir():
-            return ()
-        normalized = pattern.replace('-', '_')
-        return (item for item in root.iterdir()
-                if cls._matches_info(normalized, item)
-                or cls._matches_legacy(normalized, item))
-
 
 class PathDistribution(Distribution):
     def __init__(self, path):
diff --git a/pipenv/vendor/importlib_metadata/_compat.py b/pipenv/vendor/importlib_metadata/_compat.py
index 3fd65ffd..99b4005e 100644
--- a/pipenv/vendor/importlib_metadata/_compat.py
+++ b/pipenv/vendor/importlib_metadata/_compat.py
@@ -9,7 +9,7 @@ import email
 if sys.version_info > (3,):  # pragma: nocover
     import builtins
     from configparser import ConfigParser
-    from contextlib import suppress
+    import contextlib
     FileNotFoundError = builtins.FileNotFoundError
     IsADirectoryError = builtins.IsADirectoryError
     NotADirectoryError = builtins.NotADirectoryError
@@ -18,12 +18,14 @@ if sys.version_info > (3,):  # pragma: nocover
 else:  # pragma: nocover
     from backports.configparser import ConfigParser
     from itertools import imap as map  # type: ignore
-    from contextlib2 import suppress  # noqa
+    import contextlib2 as contextlib
     FileNotFoundError = IOError, OSError
     IsADirectoryError = IOError, OSError
     NotADirectoryError = IOError, OSError
     PermissionError = IOError, OSError
 
+suppress = contextlib.suppress
+
 if sys.version_info > (3, 5):  # pragma: nocover
     import pathlib
 else:  # pragma: nocover
@@ -73,7 +75,7 @@ def disable_stdlib_finder():
     """
     def matches(finder):
         return (
-            finder.__module__ == '_frozen_importlib_external'
+            getattr(finder, '__module__', None) == '_frozen_importlib_external'
             and hasattr(finder, 'find_distributions')
             )
     for finder in filter(matches, sys.meta_path):  # pragma: nocover
@@ -111,9 +113,6 @@ email_message_from_string = (
     email.message_from_string
     )
 
-# https://bitbucket.org/pypy/pypy/issues/3021/ioopen-directory-leaks-a-file-descriptor
-PYPY_OPEN_BUG = getattr(sys, 'pypy_version_info', (9, 9, 9))[:3] <= (7, 1, 1)
-
 
 class PyPy_repr:
     """
diff --git a/pipenv/vendor/importlib_metadata/docs/changelog.rst b/pipenv/vendor/importlib_metadata/docs/changelog.rst
index d38b36f2..9dbaf96a 100644
--- a/pipenv/vendor/importlib_metadata/docs/changelog.rst
+++ b/pipenv/vendor/importlib_metadata/docs/changelog.rst
@@ -2,6 +2,33 @@
  importlib_metadata NEWS
 =========================
 
+v1.5.1
+======
+
+* Improve reliability and consistency of compatibility
+  imports for contextlib and pathlib when running tests.
+  Closes #116.
+
+v1.5.0
+======
+
+* Additional performance optimizations in FastPath now
+  saves an additional 20% on a typical call.
+* Correct for issue where PyOxidizer finder has no
+  ``__module__`` attribute. Closes #110.
+
+v1.4.0
+======
+
+* Through careful optimization, ``distribution()`` is
+  3-4x faster. Thanks to Antony Lee for the
+  contribution. Closes #95.
+
+* When searching through ``sys.path``, if any error
+  occurs attempting to list a path entry, that entry
+  is skipped, making the system much more lenient
+  to errors. Closes #94.
+
 v1.3.0
 ======
 
diff --git a/pipenv/vendor/importlib_metadata/docs/conf.py b/pipenv/vendor/importlib_metadata/docs/conf.py
index af9f0e26..129a7a4e 100644
--- a/pipenv/vendor/importlib_metadata/docs/conf.py
+++ b/pipenv/vendor/importlib_metadata/docs/conf.py
@@ -166,6 +166,9 @@ texinfo_documents = [
 # Example configuration for intersphinx: refer to the Python standard library.
 intersphinx_mapping = {
     'python': ('https://docs.python.org/3', None),
+    'importlib_resources': (
+        'https://importlib-resources.readthedocs.io/en/latest/', None
+        ),
     }
 
 
diff --git a/pipenv/vendor/importlib_metadata/docs/index.rst b/pipenv/vendor/importlib_metadata/docs/index.rst
index 91e815c0..530197cf 100644
--- a/pipenv/vendor/importlib_metadata/docs/index.rst
+++ b/pipenv/vendor/importlib_metadata/docs/index.rst
@@ -3,15 +3,15 @@
 ===============================
 
 ``importlib_metadata`` is a library which provides an API for accessing an
-installed package's `metadata`_, such as its entry points or its top-level
+installed package's metadata (see :pep:`566`), such as its entry points or its top-level
 name.  This functionality intends to replace most uses of ``pkg_resources``
-`entry point API`_ and `metadata API`_.  Along with ``importlib.resources`` in
-`Python 3.7 and newer`_ (backported as `importlib_resources`_ for older
+`entry point API`_ and `metadata API`_.  Along with :mod:`importlib.resources` in
+Python 3.7 and newer (backported as :doc:`importlib_resources <importlib_resources:index>` for older
 versions of Python), this can eliminate the need to use the older and less
 efficient ``pkg_resources`` package.
 
 ``importlib_metadata`` is a backport of Python 3.8's standard library
-`importlib.metadata`_ module for Python 2.7, and 3.4 through 3.7.  Users of
+:doc:`importlib.metadata <library/importlib.metadata>` module for Python 2.7, and 3.4 through 3.7.  Users of
 Python 3.8 and beyond are encouraged to use the standard library module.
 When imported on Python 3.8 and later, ``importlib_metadata`` replaces the
 DistributionFinder behavior from the stdlib, but leaves the API in tact.
@@ -46,9 +46,5 @@ Indices and tables
 * :ref:`search`
 
 
-.. _`metadata`: https://www.python.org/dev/peps/pep-0566/
 .. _`entry point API`: https://setuptools.readthedocs.io/en/latest/pkg_resources.html#entry-points
 .. _`metadata API`: https://setuptools.readthedocs.io/en/latest/pkg_resources.html#metadata-api
-.. _`Python 3.7 and newer`: https://docs.python.org/3/library/importlib.html#module-importlib.resources
-.. _`importlib_resources`: https://importlib-resources.readthedocs.io/en/latest/index.html
-.. _`importlib.metadata`: https://docs.python.org/3/library/importlib.metadata.html
diff --git a/pipenv/vendor/importlib_metadata/docs/using.rst b/pipenv/vendor/importlib_metadata/docs/using.rst
index bd733394..6da2bb1c 100644
--- a/pipenv/vendor/importlib_metadata/docs/using.rst
+++ b/pipenv/vendor/importlib_metadata/docs/using.rst
@@ -1,15 +1,15 @@
 .. _using:
 
-==========================
- Using importlib_metadata
-==========================
+=================================
+ Using :mod:`!importlib_metadata`
+=================================
 
 ``importlib_metadata`` is a library that provides for access to installed
 package metadata.  Built in part on Python's import system, this library
 intends to replace similar functionality in the `entry point
 API`_ and `metadata API`_ of ``pkg_resources``.  Along with
-``importlib.resources`` in `Python 3.7
-and newer`_ (backported as `importlib_resources`_ for older versions of
+:mod:`importlib.resources` in Python 3.7
+and newer (backported as :doc:`importlib_resources <importlib_resources:index>` for older versions of
 Python), this can eliminate the need to use the older and less efficient
 ``pkg_resources`` package.
 
@@ -17,9 +17,9 @@ By "installed package" we generally mean a third-party package installed into
 Python's ``site-packages`` directory via tools such as `pip
 <https://pypi.org/project/pip/>`_.  Specifically,
 it means a package with either a discoverable ``dist-info`` or ``egg-info``
-directory, and metadata defined by `PEP 566`_ or its older specifications.
+directory, and metadata defined by :pep:`566` or its older specifications.
 By default, package metadata can live on the file system or in zip archives on
-``sys.path``.  Through an extension mechanism, the metadata can live almost
+:data:`sys.path`.  Through an extension mechanism, the metadata can live almost
 anywhere.
 
 
@@ -127,7 +127,7 @@ Distribution files
 You can also get the full set of files contained within a distribution.  The
 ``files()`` function takes a distribution package name and returns all of the
 files installed by this distribution.  Each file object returned is a
-``PackagePath``, a `pathlib.Path`_ derived object with additional ``dist``,
+``PackagePath``, a :class:`pathlib.Path` derived object with additional ``dist``,
 ``size``, and ``hash`` properties as indicated by the metadata.  For example::
 
     >>> util = [p for p in files('wheel') if 'util.py' in str(p)][0]
@@ -196,18 +196,18 @@ instance::
     >>> d.metadata['License']
     'MIT'
 
-The full set of available metadata is not described here.  See `PEP 566
-<https://www.python.org/dev/peps/pep-0566/>`_ for additional details.
+The full set of available metadata is not described here.  See :pep:`566`
+for additional details.
 
 
 Extending the search algorithm
 ==============================
 
-Because package metadata is not available through ``sys.path`` searches, or
+Because package metadata is not available through :data:`sys.path` searches, or
 package loaders directly, the metadata for a package is found through import
 system `finders`_.  To find a distribution package's metadata,
-``importlib_metadata`` queries the list of `meta path finders`_ on
-`sys.meta_path`_.
+``importlib.metadata`` queries the list of :term:`meta path finders <meta path finder>` on
+:data:`sys.meta_path`.
 
 By default ``importlib_metadata`` installs a finder for distribution packages
 found on the file system.  This finder doesn't actually find any *packages*,
@@ -217,7 +217,7 @@ The abstract class :py:class:`importlib.abc.MetaPathFinder` defines the
 interface expected of finders by Python's import system.
 ``importlib_metadata`` extends this protocol by looking for an optional
 ``find_distributions`` callable on the finders from
-``sys.meta_path`` and presents this extended interface as the
+:data:`sys.meta_path` and presents this extended interface as the
 ``DistributionFinder`` abstract base class, which defines this abstract
 method::
 
@@ -240,20 +240,13 @@ a custom finder, return instances of this derived ``Distribution`` in the
 
 .. _`entry point API`: https://setuptools.readthedocs.io/en/latest/pkg_resources.html#entry-points
 .. _`metadata API`: https://setuptools.readthedocs.io/en/latest/pkg_resources.html#metadata-api
-.. _`Python 3.7 and newer`: https://docs.python.org/3/library/importlib.html#module-importlib.resources
-.. _`importlib_resources`: https://importlib-resources.readthedocs.io/en/latest/index.html
-.. _`PEP 566`: https://www.python.org/dev/peps/pep-0566/
 .. _`finders`: https://docs.python.org/3/reference/import.html#finders-and-loaders
-.. _`meta path finders`: https://docs.python.org/3/glossary.html#term-meta-path-finder
-.. _`sys.meta_path`: https://docs.python.org/3/library/sys.html#sys.meta_path
-.. _`pathlib.Path`: https://docs.python.org/3/library/pathlib.html#pathlib.Path
 
 
 .. rubric:: Footnotes
 
 .. [#f1] Technically, the returned distribution metadata object is an
-         `email.message.Message
-         <https://docs.python.org/3/library/email.message.html#email.message.EmailMessage>`_
+         :class:`email.message.EmailMessage`
          instance, but this is an implementation detail, and not part of the
          stable API.  You should only use dictionary-like methods and syntax
          to access the metadata contents.
diff --git a/pipenv/vendor/importlib_metadata/tests/fixtures.py b/pipenv/vendor/importlib_metadata/tests/fixtures.py
index 0b4ce18d..218b699c 100644
--- a/pipenv/vendor/importlib_metadata/tests/fixtures.py
+++ b/pipenv/vendor/importlib_metadata/tests/fixtures.py
@@ -5,17 +5,8 @@ import sys
 import shutil
 import tempfile
 import textwrap
-import contextlib
 
-try:
-    from contextlib import ExitStack
-except ImportError:
-    from contextlib2 import ExitStack
-
-try:
-    import pathlib
-except ImportError:
-    import pathlib2 as pathlib
+from .._compat import pathlib, contextlib
 
 
 __metaclass__ = type
@@ -47,14 +38,28 @@ def tempdir_as_cwd():
             yield tmp
 
 
-class SiteDir:
+@contextlib.contextmanager
+def install_finder(finder):
+    sys.meta_path.append(finder)
+    try:
+        yield
+    finally:
+        sys.meta_path.remove(finder)
+
+
+class Fixtures:
     def setUp(self):
-        self.fixtures = ExitStack()
+        self.fixtures = contextlib.ExitStack()
         self.addCleanup(self.fixtures.close)
+
+
+class SiteDir(Fixtures):
+    def setUp(self):
+        super(SiteDir, self).setUp()
         self.site_dir = self.fixtures.enter_context(tempdir())
 
 
-class OnSysPath:
+class OnSysPath(Fixtures):
     @staticmethod
     @contextlib.contextmanager
     def add_sys_path(dir):
@@ -198,3 +203,8 @@ def build_files(file_defs, prefix=pathlib.Path()):
 def DALS(str):
     "Dedent and left-strip"
     return textwrap.dedent(str).lstrip()
+
+
+class NullFinder:
+    def find_module(self, name):
+        pass
diff --git a/pipenv/vendor/importlib_metadata/tests/test_integration.py b/pipenv/vendor/importlib_metadata/tests/test_integration.py
index 11ed7dc8..c881927d 100644
--- a/pipenv/vendor/importlib_metadata/tests/test_integration.py
+++ b/pipenv/vendor/importlib_metadata/tests/test_integration.py
@@ -3,7 +3,10 @@ import packaging.requirements
 import packaging.version
 
 from . import fixtures
-from .. import version
+from .. import (
+    _compat,
+    version,
+    )
 
 
 class IntegrationTests(fixtures.DistInfoPkg, unittest.TestCase):
@@ -20,3 +23,20 @@ class IntegrationTests(fixtures.DistInfoPkg, unittest.TestCase):
         assert is_installed('distinfo-pkg==1.0')
         assert is_installed('distinfo-pkg>=1.0,<2.0')
         assert not is_installed('distinfo-pkg<1.0')
+
+
+class FinderTests(fixtures.Fixtures, unittest.TestCase):
+
+    def test_finder_without_module(self):
+        class ModuleFreeFinder(fixtures.NullFinder):
+            """
+            A finder without an __module__ attribute
+            """
+            def __getattribute__(self, name):
+                if name == '__module__':
+                    raise AttributeError(name)
+                return super().__getattribute__(name)
+
+        self.fixtures.enter_context(
+            fixtures.install_finder(ModuleFreeFinder()))
+        _compat.disable_stdlib_finder()
diff --git a/pipenv/vendor/importlib_metadata/tests/test_main.py b/pipenv/vendor/importlib_metadata/tests/test_main.py
index cc2efdac..131edcea 100644
--- a/pipenv/vendor/importlib_metadata/tests/test_main.py
+++ b/pipenv/vendor/importlib_metadata/tests/test_main.py
@@ -8,6 +8,7 @@ import textwrap
 import unittest
 import importlib
 import importlib_metadata
+import pyfakefs.fake_filesystem_unittest as ffs
 
 from . import fixtures
 from .. import (
@@ -193,6 +194,33 @@ class DirectoryTest(fixtures.OnSysPath, fixtures.SiteDir, unittest.TestCase):
                 version('foo')
 
 
+class MissingSysPath(fixtures.OnSysPath, unittest.TestCase):
+    site_dir = '/does-not-exist'
+
+    def test_discovery(self):
+        """
+        Discovering distributions should succeed even if
+        there is an invalid path on sys.path.
+        """
+        importlib_metadata.distributions()
+
+
+class InaccessibleSysPath(fixtures.OnSysPath, ffs.TestCase):
+    site_dir = '/access-denied'
+
+    def setUp(self):
+        super(InaccessibleSysPath, self).setUp()
+        self.setUpPyfakefs()
+        self.fs.create_dir(self.site_dir, perm_bits=000)
+
+    def test_discovery(self):
+        """
+        Discovering distributions should succeed even if
+        there is an invalid path on sys.path.
+        """
+        list(importlib_metadata.distributions())
+
+
 class TestEntryPoints(unittest.TestCase):
     def __init__(self, *args):
         super(TestEntryPoints, self).__init__(*args)
diff --git a/pipenv/vendor/jinja2/__init__.py b/pipenv/vendor/jinja2/__init__.py
index 0eaf7214..7f4a1c55 100644
--- a/pipenv/vendor/jinja2/__init__.py
+++ b/pipenv/vendor/jinja2/__init__.py
@@ -1,83 +1,44 @@
 # -*- coding: utf-8 -*-
+"""Jinja is a template engine written in pure Python. It provides a
+non-XML syntax that supports inline expressions and an optional
+sandboxed environment.
 """
-    jinja2
-    ~~~~~~
-
-    Jinja2 is a template engine written in pure Python.  It provides a
-    Django inspired non-XML syntax but supports inline expressions and
-    an optional sandboxed environment.
-
-    Nutshell
-    --------
-
-    Here a small example of a Jinja2 template::
-
-        {% extends 'base.html' %}
-        {% block title %}Memberlist{% endblock %}
-        {% block content %}
-          <ul>
-          {% for user in users %}
-            <li><a href="{{ user.url }}">{{ user.username }}</a></li>
-          {% endfor %}
-          </ul>
-        {% endblock %}
-
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
-__docformat__ = 'restructuredtext en'
-__version__ = "2.10.3"
-
-# high level interface
-from jinja2.environment import Environment, Template
-
-# loaders
-from jinja2.loaders import BaseLoader, FileSystemLoader, PackageLoader, \
-     DictLoader, FunctionLoader, PrefixLoader, ChoiceLoader, \
-     ModuleLoader
-
-# bytecode caches
-from jinja2.bccache import BytecodeCache, FileSystemBytecodeCache, \
-     MemcachedBytecodeCache
-
-# undefined types
-from jinja2.runtime import Undefined, DebugUndefined, StrictUndefined, \
-     make_logging_undefined
-
-# exceptions
-from jinja2.exceptions import TemplateError, UndefinedError, \
-     TemplateNotFound, TemplatesNotFound, TemplateSyntaxError, \
-     TemplateAssertionError, TemplateRuntimeError
-
-# decorators and public utilities
-from jinja2.filters import environmentfilter, contextfilter, \
-     evalcontextfilter
-from jinja2.utils import Markup, escape, clear_caches, \
-     environmentfunction, evalcontextfunction, contextfunction, \
-     is_undefined, select_autoescape
-
-__all__ = [
-    'Environment', 'Template', 'BaseLoader', 'FileSystemLoader',
-    'PackageLoader', 'DictLoader', 'FunctionLoader', 'PrefixLoader',
-    'ChoiceLoader', 'BytecodeCache', 'FileSystemBytecodeCache',
-    'MemcachedBytecodeCache', 'Undefined', 'DebugUndefined',
-    'StrictUndefined', 'TemplateError', 'UndefinedError', 'TemplateNotFound',
-    'TemplatesNotFound', 'TemplateSyntaxError', 'TemplateAssertionError',
-    'TemplateRuntimeError',
-    'ModuleLoader', 'environmentfilter', 'contextfilter', 'Markup', 'escape',
-    'environmentfunction', 'contextfunction', 'clear_caches', 'is_undefined',
-    'evalcontextfilter', 'evalcontextfunction', 'make_logging_undefined',
-    'select_autoescape',
-]
-
-
-def _patch_async():
-    from jinja2.utils import have_async_gen
-    if have_async_gen:
-        from jinja2.asyncsupport import patch_all
-        patch_all()
-
-
-_patch_async()
-del _patch_async
+from markupsafe import escape
+from markupsafe import Markup
+
+from .bccache import BytecodeCache
+from .bccache import FileSystemBytecodeCache
+from .bccache import MemcachedBytecodeCache
+from .environment import Environment
+from .environment import Template
+from .exceptions import TemplateAssertionError
+from .exceptions import TemplateError
+from .exceptions import TemplateNotFound
+from .exceptions import TemplateRuntimeError
+from .exceptions import TemplatesNotFound
+from .exceptions import TemplateSyntaxError
+from .exceptions import UndefinedError
+from .filters import contextfilter
+from .filters import environmentfilter
+from .filters import evalcontextfilter
+from .loaders import BaseLoader
+from .loaders import ChoiceLoader
+from .loaders import DictLoader
+from .loaders import FileSystemLoader
+from .loaders import FunctionLoader
+from .loaders import ModuleLoader
+from .loaders import PackageLoader
+from .loaders import PrefixLoader
+from .runtime import ChainableUndefined
+from .runtime import DebugUndefined
+from .runtime import make_logging_undefined
+from .runtime import StrictUndefined
+from .runtime import Undefined
+from .utils import clear_caches
+from .utils import contextfunction
+from .utils import environmentfunction
+from .utils import evalcontextfunction
+from .utils import is_undefined
+from .utils import select_autoescape
+
+__version__ = "2.11.1"
diff --git a/pipenv/vendor/jinja2/_compat.py b/pipenv/vendor/jinja2/_compat.py
index 4dbf6ea0..1f044954 100644
--- a/pipenv/vendor/jinja2/_compat.py
+++ b/pipenv/vendor/jinja2/_compat.py
@@ -1,22 +1,12 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2._compat
-    ~~~~~~~~~~~~~~
-
-    Some py2/py3 compatibility support based on a stripped down
-    version of six so we don't have to depend on a specific version
-    of it.
-
-    :copyright: Copyright 2013 by the Jinja team, see AUTHORS.
-    :license: BSD, see LICENSE for details.
-"""
+# flake8: noqa
+import marshal
 import sys
 
 PY2 = sys.version_info[0] == 2
-PYPY = hasattr(sys, 'pypy_translation_info')
+PYPY = hasattr(sys, "pypy_translation_info")
 _identity = lambda x: x
 
-
 if not PY2:
     unichr = chr
     range_type = range
@@ -30,6 +20,7 @@ if not PY2:
 
     import pickle
     from io import BytesIO, StringIO
+
     NativeStringIO = StringIO
 
     def reraise(tp, value, tb=None):
@@ -46,6 +37,9 @@ if not PY2:
     implements_to_string = _identity
     encode_filename = _identity
 
+    marshal_dump = marshal.dump
+    marshal_load = marshal.load
+
 else:
     unichr = unichr
     text_type = unicode
@@ -59,11 +53,13 @@ else:
 
     import cPickle as pickle
     from cStringIO import StringIO as BytesIO, StringIO
+
     NativeStringIO = BytesIO
 
-    exec('def reraise(tp, value, tb=None):\n raise tp, value, tb')
+    exec("def reraise(tp, value, tb=None):\n raise tp, value, tb")
 
     from itertools import imap, izip, ifilter
+
     intern = intern
 
     def implements_iterator(cls):
@@ -73,14 +69,25 @@ else:
 
     def implements_to_string(cls):
         cls.__unicode__ = cls.__str__
-        cls.__str__ = lambda x: x.__unicode__().encode('utf-8')
+        cls.__str__ = lambda x: x.__unicode__().encode("utf-8")
         return cls
 
     def encode_filename(filename):
         if isinstance(filename, unicode):
-            return filename.encode('utf-8')
+            return filename.encode("utf-8")
         return filename
 
+    def marshal_dump(code, f):
+        if isinstance(f, file):
+            marshal.dump(code, f)
+        else:
+            f.write(marshal.dumps(code))
+
+    def marshal_load(f):
+        if isinstance(f, file):
+            return marshal.load(f)
+        return marshal.loads(f.read())
+
 
 def with_metaclass(meta, *bases):
     """Create a base class with a metaclass."""
@@ -90,7 +97,8 @@ def with_metaclass(meta, *bases):
     class metaclass(type):
         def __new__(cls, name, this_bases, d):
             return meta(name, bases, d)
-    return type.__new__(metaclass, 'temporary_class', (), {})
+
+    return type.__new__(metaclass, "temporary_class", (), {})
 
 
 try:
@@ -103,3 +111,22 @@ try:
     from collections import abc
 except ImportError:
     import collections as abc
+
+
+try:
+    from os import fspath
+except ImportError:
+    try:
+        from pathlib import PurePath
+    except ImportError:
+        PurePath = None
+
+    def fspath(path):
+        if hasattr(path, "__fspath__"):
+            return path.__fspath__()
+
+        # Python 3.5 doesn't have __fspath__ yet, use str.
+        if PurePath is not None and isinstance(path, PurePath):
+            return str(path)
+
+        return path
diff --git a/pipenv/vendor/jinja2/_identifier.py b/pipenv/vendor/jinja2/_identifier.py
index 2eac35d5..224d5449 100644
--- a/pipenv/vendor/jinja2/_identifier.py
+++ b/pipenv/vendor/jinja2/_identifier.py
@@ -1,2 +1,6 @@
+import re
+
 # generated by scripts/generate_identifier_pattern.py
-pattern = '------------------------------------------------------------------------------------------------------------------------------------------------------------------'
+pattern = re.compile(
+    r"[\w------------------------------------------------------------------------------------------------------------------------------------------------------------------]+"  # noqa: B950
+)
diff --git a/pipenv/vendor/jinja2/asyncfilters.py b/pipenv/vendor/jinja2/asyncfilters.py
index 5c1f46d7..d29f6c62 100644
--- a/pipenv/vendor/jinja2/asyncfilters.py
+++ b/pipenv/vendor/jinja2/asyncfilters.py
@@ -1,12 +1,13 @@
 from functools import wraps
 
-from jinja2.asyncsupport import auto_aiter
-from jinja2 import filters
+from . import filters
+from .asyncsupport import auto_aiter
+from .asyncsupport import auto_await
 
 
 async def auto_to_seq(value):
     seq = []
-    if hasattr(value, '__aiter__'):
+    if hasattr(value, "__aiter__"):
         async for item in value:
             seq.append(item)
     else:
@@ -16,8 +17,7 @@ async def auto_to_seq(value):
 
 
 async def async_select_or_reject(args, kwargs, modfunc, lookup_attr):
-    seq, func = filters.prepare_select_or_reject(
-        args, kwargs, modfunc, lookup_attr)
+    seq, func = filters.prepare_select_or_reject(args, kwargs, modfunc, lookup_attr)
     if seq:
         async for item in auto_aiter(seq):
             if func(item):
@@ -26,14 +26,20 @@ async def async_select_or_reject(args, kwargs, modfunc, lookup_attr):
 
 def dualfilter(normal_filter, async_filter):
     wrap_evalctx = False
-    if getattr(normal_filter, 'environmentfilter', False):
-        is_async = lambda args: args[0].is_async
+    if getattr(normal_filter, "environmentfilter", False):
+
+        def is_async(args):
+            return args[0].is_async
+
         wrap_evalctx = False
     else:
-        if not getattr(normal_filter, 'evalcontextfilter', False) and \
-           not getattr(normal_filter, 'contextfilter', False):
+        if not getattr(normal_filter, "evalcontextfilter", False) and not getattr(
+            normal_filter, "contextfilter", False
+        ):
             wrap_evalctx = True
-        is_async = lambda args: args[0].environment.is_async
+
+        def is_async(args):
+            return args[0].environment.is_async
 
     @wraps(normal_filter)
     def wrapper(*args, **kwargs):
@@ -55,6 +61,7 @@ def dualfilter(normal_filter, async_filter):
 def asyncfiltervariant(original):
     def decorator(f):
         return dualfilter(original, f)
+
     return decorator
 
 
@@ -63,19 +70,22 @@ async def do_first(environment, seq):
     try:
         return await auto_aiter(seq).__anext__()
     except StopAsyncIteration:
-        return environment.undefined('No first item, sequence was empty.')
+        return environment.undefined("No first item, sequence was empty.")
 
 
 @asyncfiltervariant(filters.do_groupby)
 async def do_groupby(environment, value, attribute):
     expr = filters.make_attrgetter(environment, attribute)
-    return [filters._GroupTuple(key, await auto_to_seq(values))
-            for key, values in filters.groupby(sorted(
-                await auto_to_seq(value), key=expr), expr)]
+    return [
+        filters._GroupTuple(key, await auto_to_seq(values))
+        for key, values in filters.groupby(
+            sorted(await auto_to_seq(value), key=expr), expr
+        )
+    ]
 
 
 @asyncfiltervariant(filters.do_join)
-async def do_join(eval_ctx, value, d=u'', attribute=None):
+async def do_join(eval_ctx, value, d=u"", attribute=None):
     return filters.do_join(eval_ctx, await auto_to_seq(value), d, attribute)
 
 
@@ -109,7 +119,7 @@ async def do_map(*args, **kwargs):
     seq, func = filters.prepare_map(args, kwargs)
     if seq:
         async for item in auto_aiter(seq):
-            yield func(item)
+            yield await auto_await(func(item))
 
 
 @asyncfiltervariant(filters.do_sum)
@@ -118,7 +128,10 @@ async def do_sum(environment, iterable, attribute=None, start=0):
     if attribute is not None:
         func = filters.make_attrgetter(environment, attribute)
     else:
-        func = lambda x: x
+
+        def func(x):
+            return x
+
     async for item in auto_aiter(iterable):
         rv += func(item)
     return rv
@@ -130,17 +143,17 @@ async def do_slice(value, slices, fill_with=None):
 
 
 ASYNC_FILTERS = {
-    'first':        do_first,
-    'groupby':      do_groupby,
-    'join':         do_join,
-    'list':         do_list,
+    "first": do_first,
+    "groupby": do_groupby,
+    "join": do_join,
+    "list": do_list,
     # we intentionally do not support do_last because that would be
     # ridiculous
-    'reject':       do_reject,
-    'rejectattr':   do_rejectattr,
-    'map':          do_map,
-    'select':       do_select,
-    'selectattr':   do_selectattr,
-    'sum':          do_sum,
-    'slice':        do_slice,
+    "reject": do_reject,
+    "rejectattr": do_rejectattr,
+    "map": do_map,
+    "select": do_select,
+    "selectattr": do_selectattr,
+    "sum": do_sum,
+    "slice": do_slice,
 }
diff --git a/pipenv/vendor/jinja2/asyncsupport.py b/pipenv/vendor/jinja2/asyncsupport.py
index b1e7b5ce..78ba3739 100644
--- a/pipenv/vendor/jinja2/asyncsupport.py
+++ b/pipenv/vendor/jinja2/asyncsupport.py
@@ -1,29 +1,27 @@
 # -*- coding: utf-8 -*-
+"""The code for async support. Importing this patches Jinja on supported
+Python versions.
 """
-    jinja2.asyncsupport
-    ~~~~~~~~~~~~~~~~~~~
-
-    Has all the code for async support which is implemented as a patch
-    for supported Python versions.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
-import sys
 import asyncio
 import inspect
 from functools import update_wrapper
 
-from jinja2.utils import concat, internalcode, Markup
-from jinja2.environment import TemplateModule
-from jinja2.runtime import LoopContextBase, _last_iteration
+from markupsafe import Markup
+
+from .environment import TemplateModule
+from .runtime import LoopContext
+from .utils import concat
+from .utils import internalcode
+from .utils import missing
 
 
 async def concat_async(async_gen):
     rv = []
+
     async def collect():
         async for event in async_gen:
             rv.append(event)
+
     await collect()
     return concat(rv)
 
@@ -34,10 +32,7 @@ async def generate_async(self, *args, **kwargs):
         async for event in self.root_render_func(self.new_context(vars)):
             yield event
     except Exception:
-        exc_info = sys.exc_info()
-    else:
-        return
-    yield self.environment.handle_exception(exc_info, True)
+        yield self.environment.handle_exception()
 
 
 def wrap_generate_func(original_generate):
@@ -48,17 +43,18 @@ def wrap_generate_func(original_generate):
                 yield loop.run_until_complete(async_gen.__anext__())
         except StopAsyncIteration:
             pass
+
     def generate(self, *args, **kwargs):
         if not self.environment.is_async:
             return original_generate(self, *args, **kwargs)
         return _convert_generator(self, asyncio.get_event_loop(), args, kwargs)
+
     return update_wrapper(generate, original_generate)
 
 
 async def render_async(self, *args, **kwargs):
     if not self.environment.is_async:
-        raise RuntimeError('The environment was not created with async mode '
-                           'enabled.')
+        raise RuntimeError("The environment was not created with async mode enabled.")
 
     vars = dict(*args, **kwargs)
     ctx = self.new_context(vars)
@@ -66,8 +62,7 @@ async def render_async(self, *args, **kwargs):
     try:
         return await concat_async(self.root_render_func(ctx))
     except Exception:
-        exc_info = sys.exc_info()
-    return self.environment.handle_exception(exc_info, True)
+        return self.environment.handle_exception()
 
 
 def wrap_render_func(original_render):
@@ -76,6 +71,7 @@ def wrap_render_func(original_render):
             return original_render(self, *args, **kwargs)
         loop = asyncio.get_event_loop()
         return loop.run_until_complete(self.render_async(*args, **kwargs))
+
     return update_wrapper(render, original_render)
 
 
@@ -109,6 +105,7 @@ def wrap_macro_invoke(original_invoke):
         if not self._environment.is_async:
             return original_invoke(self, arguments, autoescape)
         return async_invoke(self, arguments, autoescape)
+
     return update_wrapper(_invoke, original_invoke)
 
 
@@ -124,9 +121,9 @@ def wrap_default_module(original_default_module):
     @internalcode
     def _get_default_module(self):
         if self.environment.is_async:
-            raise RuntimeError('Template module attribute is unavailable '
-                               'in async mode')
+            raise RuntimeError("Template module attribute is unavailable in async mode")
         return original_default_module(self)
+
     return _get_default_module
 
 
@@ -139,30 +136,30 @@ async def make_module_async(self, vars=None, shared=False, locals=None):
 
 
 def patch_template():
-    from jinja2 import Template
+    from . import Template
+
     Template.generate = wrap_generate_func(Template.generate)
-    Template.generate_async = update_wrapper(
-        generate_async, Template.generate_async)
-    Template.render_async = update_wrapper(
-        render_async, Template.render_async)
+    Template.generate_async = update_wrapper(generate_async, Template.generate_async)
+    Template.render_async = update_wrapper(render_async, Template.render_async)
     Template.render = wrap_render_func(Template.render)
-    Template._get_default_module = wrap_default_module(
-        Template._get_default_module)
+    Template._get_default_module = wrap_default_module(Template._get_default_module)
     Template._get_default_module_async = get_default_module_async
     Template.make_module_async = update_wrapper(
-        make_module_async, Template.make_module_async)
+        make_module_async, Template.make_module_async
+    )
 
 
 def patch_runtime():
-    from jinja2.runtime import BlockReference, Macro
-    BlockReference.__call__ = wrap_block_reference_call(
-        BlockReference.__call__)
+    from .runtime import BlockReference, Macro
+
+    BlockReference.__call__ = wrap_block_reference_call(BlockReference.__call__)
     Macro._invoke = wrap_macro_invoke(Macro._invoke)
 
 
 def patch_filters():
-    from jinja2.filters import FILTERS
-    from jinja2.asyncfilters import ASYNC_FILTERS
+    from .filters import FILTERS
+    from .asyncfilters import ASYNC_FILTERS
+
     FILTERS.update(ASYNC_FILTERS)
 
 
@@ -179,7 +176,7 @@ async def auto_await(value):
 
 
 async def auto_aiter(iterable):
-    if hasattr(iterable, '__aiter__'):
+    if hasattr(iterable, "__aiter__"):
         async for item in iterable:
             yield item
         return
@@ -187,70 +184,81 @@ async def auto_aiter(iterable):
         yield item
 
 
-class AsyncLoopContext(LoopContextBase):
-
-    def __init__(self, async_iterator, undefined, after, length, recurse=None,
-                 depth0=0):
-        LoopContextBase.__init__(self, undefined, recurse, depth0)
-        self._async_iterator = async_iterator
-        self._after = after
-        self._length = length
+class AsyncLoopContext(LoopContext):
+    _to_iterator = staticmethod(auto_aiter)
 
     @property
-    def length(self):
-        if self._length is None:
-            raise TypeError('Loop length for some iterators cannot be '
-                            'lazily calculated in async mode')
+    async def length(self):
+        if self._length is not None:
+            return self._length
+
+        try:
+            self._length = len(self._iterable)
+        except TypeError:
+            iterable = [x async for x in self._iterator]
+            self._iterator = self._to_iterator(iterable)
+            self._length = len(iterable) + self.index + (self._after is not missing)
+
         return self._length
 
-    def __aiter__(self):
-        return AsyncLoopContextIterator(self)
+    @property
+    async def revindex0(self):
+        return await self.length - self.index
 
+    @property
+    async def revindex(self):
+        return await self.length - self.index0
+
+    async def _peek_next(self):
+        if self._after is not missing:
+            return self._after
+
+        try:
+            self._after = await self._iterator.__anext__()
+        except StopAsyncIteration:
+            self._after = missing
 
-class AsyncLoopContextIterator(object):
-    __slots__ = ('context',)
+        return self._after
 
-    def __init__(self, context):
-        self.context = context
+    @property
+    async def last(self):
+        return await self._peek_next() is missing
+
+    @property
+    async def nextitem(self):
+        rv = await self._peek_next()
+
+        if rv is missing:
+            return self._undefined("there is no next item")
+
+        return rv
 
     def __aiter__(self):
         return self
 
     async def __anext__(self):
-        ctx = self.context
-        ctx.index0 += 1
-        if ctx._after is _last_iteration:
-            raise StopAsyncIteration()
-        ctx._before = ctx._current
-        ctx._current = ctx._after
-        try:
-            ctx._after = await ctx._async_iterator.__anext__()
-        except StopAsyncIteration:
-            ctx._after = _last_iteration
-        return ctx._current, ctx
+        if self._after is not missing:
+            rv = self._after
+            self._after = missing
+        else:
+            rv = await self._iterator.__anext__()
+
+        self.index0 += 1
+        self._before = self._current
+        self._current = rv
+        return rv, self
 
 
 async def make_async_loop_context(iterable, undefined, recurse=None, depth0=0):
-    # Length is more complicated and less efficient in async mode.  The
-    # reason for this is that we cannot know if length will be used
-    # upfront but because length is a property we cannot lazily execute it
-    # later.  This means that we need to buffer it up and measure :(
-    #
-    # We however only do this for actual iterators, not for async
-    # iterators as blocking here does not seem like the best idea in the
-    # world.
-    try:
-        length = len(iterable)
-    except (TypeError, AttributeError):
-        if not hasattr(iterable, '__aiter__'):
-            iterable = tuple(iterable)
-            length = len(iterable)
-        else:
-            length = None
-    async_iterator = auto_aiter(iterable)
-    try:
-        after = await async_iterator.__anext__()
-    except StopAsyncIteration:
-        after = _last_iteration
-    return AsyncLoopContext(async_iterator, undefined, after, length, recurse,
-                            depth0)
+    import warnings
+
+    warnings.warn(
+        "This template must be recompiled with at least Jinja 2.11, or"
+        " it will fail in 3.0.",
+        DeprecationWarning,
+        stacklevel=2,
+    )
+    return AsyncLoopContext(iterable, undefined, recurse, depth0)
+
+
+patch_all()
diff --git a/pipenv/vendor/jinja2/bccache.py b/pipenv/vendor/jinja2/bccache.py
index 507a9b3d..9c066103 100644
--- a/pipenv/vendor/jinja2/bccache.py
+++ b/pipenv/vendor/jinja2/bccache.py
@@ -1,60 +1,37 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.bccache
-    ~~~~~~~~~~~~~~
-
-    This module implements the bytecode cache system Jinja is optionally
-    using.  This is useful if you have very complex template situations and
-    the compiliation of all those templates slow down your application too
-    much.
-
-    Situations where this is useful are often forking web applications that
-    are initialized on the first request.
+"""The optional bytecode cache system. This is useful if you have very
+complex template situations and the compilation of all those templates
+slows down your application too much.
 
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD.
+Situations where this is useful are often forking web applications that
+are initialized on the first request.
 """
-from os import path, listdir
+import errno
+import fnmatch
 import os
-import sys
 import stat
-import errno
-import marshal
+import sys
 import tempfile
-import fnmatch
 from hashlib import sha1
-from jinja2.utils import open_if_exists
-from jinja2._compat import BytesIO, pickle, PY2, text_type
-
-
-# marshal works better on 3.x, one hack less required
-if not PY2:
-    marshal_dump = marshal.dump
-    marshal_load = marshal.load
-else:
-
-    def marshal_dump(code, f):
-        if isinstance(f, file):
-            marshal.dump(code, f)
-        else:
-            f.write(marshal.dumps(code))
-
-    def marshal_load(f):
-        if isinstance(f, file):
-            return marshal.load(f)
-        return marshal.loads(f.read())
-
-
-bc_version = 3
-
-# magic version used to only change with new jinja versions.  With 2.6
-# we change this to also take Python version changes into account.  The
-# reason for this is that Python tends to segfault if fed earlier bytecode
-# versions because someone thought it would be a good idea to reuse opcodes
-# or make Python incompatible with earlier versions.
-bc_magic = 'j2'.encode('ascii') + \
-    pickle.dumps(bc_version, 2) + \
-    pickle.dumps((sys.version_info[0] << 24) | sys.version_info[1])
+from os import listdir
+from os import path
+
+from ._compat import BytesIO
+from ._compat import marshal_dump
+from ._compat import marshal_load
+from ._compat import pickle
+from ._compat import text_type
+from .utils import open_if_exists
+
+bc_version = 4
+# Magic bytes to identify Jinja bytecode cache files. Contains the
+# Python major and minor version to avoid loading incompatible bytecode
+# if a project upgrades its Python version.
+bc_magic = (
+    b"j2"
+    + pickle.dumps(bc_version, 2)
+    + pickle.dumps((sys.version_info[0] << 24) | sys.version_info[1], 2)
+)
 
 
 class Bucket(object):
@@ -98,7 +75,7 @@ class Bucket(object):
     def write_bytecode(self, f):
         """Dump the bytecode into the file or file like object passed."""
         if self.code is None:
-            raise TypeError('can\'t write empty bucket')
+            raise TypeError("can't write empty bucket")
         f.write(bc_magic)
         pickle.dump(self.checksum, f, 2)
         marshal_dump(self.code, f)
@@ -140,7 +117,7 @@ class BytecodeCache(object):
                     bucket.write_bytecode(f)
 
     A more advanced version of a filesystem based bytecode cache is part of
-    Jinja2.
+    Jinja.
     """
 
     def load_bytecode(self, bucket):
@@ -158,24 +135,24 @@ class BytecodeCache(object):
         raise NotImplementedError()
 
     def clear(self):
-        """Clears the cache.  This method is not used by Jinja2 but should be
+        """Clears the cache.  This method is not used by Jinja but should be
         implemented to allow applications to clear the bytecode cache used
         by a particular environment.
         """
 
     def get_cache_key(self, name, filename=None):
         """Returns the unique hash key for this template name."""
-        hash = sha1(name.encode('utf-8'))
+        hash = sha1(name.encode("utf-8"))
         if filename is not None:
-            filename = '|' + filename
+            filename = "|" + filename
             if isinstance(filename, text_type):
-                filename = filename.encode('utf-8')
+                filename = filename.encode("utf-8")
             hash.update(filename)
         return hash.hexdigest()
 
     def get_source_checksum(self, source):
         """Returns a checksum for the source."""
-        return sha1(source.encode('utf-8')).hexdigest()
+        return sha1(source.encode("utf-8")).hexdigest()
 
     def get_bucket(self, environment, name, filename, source):
         """Return a cache bucket for the given template.  All arguments are
@@ -210,7 +187,7 @@ class FileSystemBytecodeCache(BytecodeCache):
     This bytecode cache supports clearing of the cache using the clear method.
     """
 
-    def __init__(self, directory=None, pattern='__jinja2_%s.cache'):
+    def __init__(self, directory=None, pattern="__jinja2_%s.cache"):
         if directory is None:
             directory = self._get_default_cache_dir()
         self.directory = directory
@@ -218,19 +195,21 @@ class FileSystemBytecodeCache(BytecodeCache):
 
     def _get_default_cache_dir(self):
         def _unsafe_dir():
-            raise RuntimeError('Cannot determine safe temp directory.  You '
-                               'need to explicitly provide one.')
+            raise RuntimeError(
+                "Cannot determine safe temp directory.  You "
+                "need to explicitly provide one."
+            )
 
         tmpdir = tempfile.gettempdir()
 
         # On windows the temporary directory is used specific unless
         # explicitly forced otherwise.  We can just use that.
-        if os.name == 'nt':
+        if os.name == "nt":
             return tmpdir
-        if not hasattr(os, 'getuid'):
+        if not hasattr(os, "getuid"):
             _unsafe_dir()
 
-        dirname = '_jinja2-cache-%d' % os.getuid()
+        dirname = "_jinja2-cache-%d" % os.getuid()
         actual_dir = os.path.join(tmpdir, dirname)
 
         try:
@@ -241,18 +220,22 @@ class FileSystemBytecodeCache(BytecodeCache):
         try:
             os.chmod(actual_dir, stat.S_IRWXU)
             actual_dir_stat = os.lstat(actual_dir)
-            if actual_dir_stat.st_uid != os.getuid() \
-               or not stat.S_ISDIR(actual_dir_stat.st_mode) \
-               or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU:
+            if (
+                actual_dir_stat.st_uid != os.getuid()
+                or not stat.S_ISDIR(actual_dir_stat.st_mode)
+                or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU
+            ):
                 _unsafe_dir()
         except OSError as e:
             if e.errno != errno.EEXIST:
                 raise
 
         actual_dir_stat = os.lstat(actual_dir)
-        if actual_dir_stat.st_uid != os.getuid() \
-           or not stat.S_ISDIR(actual_dir_stat.st_mode) \
-           or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU:
+        if (
+            actual_dir_stat.st_uid != os.getuid()
+            or not stat.S_ISDIR(actual_dir_stat.st_mode)
+            or stat.S_IMODE(actual_dir_stat.st_mode) != stat.S_IRWXU
+        ):
             _unsafe_dir()
 
         return actual_dir
@@ -261,7 +244,7 @@ class FileSystemBytecodeCache(BytecodeCache):
         return path.join(self.directory, self.pattern % bucket.key)
 
     def load_bytecode(self, bucket):
-        f = open_if_exists(self._get_cache_filename(bucket), 'rb')
+        f = open_if_exists(self._get_cache_filename(bucket), "rb")
         if f is not None:
             try:
                 bucket.load_bytecode(f)
@@ -269,7 +252,7 @@ class FileSystemBytecodeCache(BytecodeCache):
                 f.close()
 
     def dump_bytecode(self, bucket):
-        f = open(self._get_cache_filename(bucket), 'wb')
+        f = open(self._get_cache_filename(bucket), "wb")
         try:
             bucket.write_bytecode(f)
         finally:
@@ -280,7 +263,8 @@ class FileSystemBytecodeCache(BytecodeCache):
         # write access on the file system and the function does not exist
         # normally.
         from os import remove
-        files = fnmatch.filter(listdir(self.directory), self.pattern % '*')
+
+        files = fnmatch.filter(listdir(self.directory), self.pattern % "*")
         for filename in files:
             try:
                 remove(path.join(self.directory, filename))
@@ -333,8 +317,13 @@ class MemcachedBytecodeCache(BytecodeCache):
        `ignore_memcache_errors` parameter.
     """
 
-    def __init__(self, client, prefix='jinja2/bytecode/', timeout=None,
-                 ignore_memcache_errors=True):
+    def __init__(
+        self,
+        client,
+        prefix="jinja2/bytecode/",
+        timeout=None,
+        ignore_memcache_errors=True,
+    ):
         self.client = client
         self.prefix = prefix
         self.timeout = timeout
diff --git a/pipenv/vendor/jinja2/compiler.py b/pipenv/vendor/jinja2/compiler.py
index d534a827..f450ec6e 100644
--- a/pipenv/vendor/jinja2/compiler.py
+++ b/pipenv/vendor/jinja2/compiler.py
@@ -1,59 +1,62 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.compiler
-    ~~~~~~~~~~~~~~~
-
-    Compiles nodes into python code.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
+"""Compiles nodes from the parser into Python code."""
+from collections import namedtuple
+from functools import update_wrapper
 from itertools import chain
-from copy import deepcopy
 from keyword import iskeyword as is_python_keyword
-from functools import update_wrapper
-from jinja2 import nodes
-from jinja2.nodes import EvalContext
-from jinja2.visitor import NodeVisitor
-from jinja2.optimizer import Optimizer
-from jinja2.exceptions import TemplateAssertionError
-from jinja2.utils import Markup, concat, escape
-from jinja2._compat import range_type, text_type, string_types, \
-     iteritems, NativeStringIO, imap, izip
-from jinja2.idtracking import Symbols, VAR_LOAD_PARAMETER, \
-     VAR_LOAD_RESOLVE, VAR_LOAD_ALIAS, VAR_LOAD_UNDEFINED
 
+from markupsafe import escape
+from markupsafe import Markup
+
+from . import nodes
+from ._compat import imap
+from ._compat import iteritems
+from ._compat import izip
+from ._compat import NativeStringIO
+from ._compat import range_type
+from ._compat import string_types
+from ._compat import text_type
+from .exceptions import TemplateAssertionError
+from .idtracking import Symbols
+from .idtracking import VAR_LOAD_ALIAS
+from .idtracking import VAR_LOAD_PARAMETER
+from .idtracking import VAR_LOAD_RESOLVE
+from .idtracking import VAR_LOAD_UNDEFINED
+from .nodes import EvalContext
+from .optimizer import Optimizer
+from .utils import concat
+from .visitor import NodeVisitor
 
 operators = {
-    'eq':       '==',
-    'ne':       '!=',
-    'gt':       '>',
-    'gteq':     '>=',
-    'lt':       '<',
-    'lteq':     '<=',
-    'in':       'in',
-    'notin':    'not in'
+    "eq": "==",
+    "ne": "!=",
+    "gt": ">",
+    "gteq": ">=",
+    "lt": "<",
+    "lteq": "<=",
+    "in": "in",
+    "notin": "not in",
 }
 
 # what method to iterate over items do we want to use for dict iteration
 # in generated code?  on 2.x let's go with iteritems, on 3.x with items
-if hasattr(dict, 'iteritems'):
-    dict_item_iter = 'iteritems'
+if hasattr(dict, "iteritems"):
+    dict_item_iter = "iteritems"
 else:
-    dict_item_iter = 'items'
+    dict_item_iter = "items"
 
-code_features = ['division']
+code_features = ["division"]
 
 # does this python version support generator stops? (PEP 0479)
 try:
-    exec('from __future__ import generator_stop')
-    code_features.append('generator_stop')
+    exec("from __future__ import generator_stop")
+    code_features.append("generator_stop")
 except SyntaxError:
     pass
 
 # does this python version support yield from?
 try:
-    exec('def f(): yield from x()')
+    exec("def f(): yield from x()")
 except SyntaxError:
     supports_yield_from = False
 else:
@@ -68,17 +71,19 @@ def optimizeconst(f):
             if new_node != node:
                 return self.visit(new_node, frame)
         return f(self, node, frame, **kwargs)
+
     return update_wrapper(new_func, f)
 
 
-def generate(node, environment, name, filename, stream=None,
-             defer_init=False, optimized=True):
+def generate(
+    node, environment, name, filename, stream=None, defer_init=False, optimized=True
+):
     """Generate the python source for a node tree."""
     if not isinstance(node, nodes.Template):
-        raise TypeError('Can\'t compile non template nodes')
-    generator = environment.code_generator_class(environment, name, filename,
-                                                 stream, defer_init,
-                                                 optimized)
+        raise TypeError("Can't compile non template nodes")
+    generator = environment.code_generator_class(
+        environment, name, filename, stream, defer_init, optimized
+    )
     generator.visit(node)
     if stream is None:
         return generator.stream.getvalue()
@@ -119,7 +124,6 @@ def find_undeclared(nodes, names):
 
 
 class MacroRef(object):
-
     def __init__(self, node):
         self.node = node
         self.accesses_caller = False
@@ -132,8 +136,7 @@ class Frame(object):
 
     def __init__(self, eval_ctx, parent=None, level=None):
         self.eval_ctx = eval_ctx
-        self.symbols = Symbols(parent and parent.symbols or None,
-                               level=level)
+        self.symbols = Symbols(parent and parent.symbols or None, level=level)
 
         # a toplevel frame is the root + soft frames such as if conditions.
         self.toplevel = False
@@ -223,7 +226,7 @@ class UndeclaredNameVisitor(NodeVisitor):
         self.undeclared = set()
 
     def visit_Name(self, node):
-        if node.ctx == 'load' and node.name in self.names:
+        if node.ctx == "load" and node.name in self.names:
             self.undeclared.add(node.name)
             if self.undeclared == self.names:
                 raise VisitorExit()
@@ -242,9 +245,9 @@ class CompilerExit(Exception):
 
 
 class CodeGenerator(NodeVisitor):
-
-    def __init__(self, environment, name, filename, stream=None,
-                 defer_init=False, optimized=True):
+    def __init__(
+        self, environment, name, filename, stream=None, defer_init=False, optimized=True
+    ):
         if stream is None:
             stream = NativeStringIO()
         self.environment = environment
@@ -306,7 +309,7 @@ class CodeGenerator(NodeVisitor):
         self._param_def_block = []
 
         # Tracks the current context.
-        self._context_reference_stack = ['context']
+        self._context_reference_stack = ["context"]
 
     # -- Various compilation helpers
 
@@ -317,30 +320,30 @@ class CodeGenerator(NodeVisitor):
     def temporary_identifier(self):
         """Get a new unique identifier."""
         self._last_identifier += 1
-        return 't_%d' % self._last_identifier
+        return "t_%d" % self._last_identifier
 
     def buffer(self, frame):
         """Enable buffering for the frame from that point onwards."""
         frame.buffer = self.temporary_identifier()
-        self.writeline('%s = []' % frame.buffer)
+        self.writeline("%s = []" % frame.buffer)
 
     def return_buffer_contents(self, frame, force_unescaped=False):
         """Return the buffer contents of the frame."""
         if not force_unescaped:
             if frame.eval_ctx.volatile:
-                self.writeline('if context.eval_ctx.autoescape:')
+                self.writeline("if context.eval_ctx.autoescape:")
                 self.indent()
-                self.writeline('return Markup(concat(%s))' % frame.buffer)
+                self.writeline("return Markup(concat(%s))" % frame.buffer)
                 self.outdent()
-                self.writeline('else:')
+                self.writeline("else:")
                 self.indent()
-                self.writeline('return concat(%s)' % frame.buffer)
+                self.writeline("return concat(%s)" % frame.buffer)
                 self.outdent()
                 return
             elif frame.eval_ctx.autoescape:
-                self.writeline('return Markup(concat(%s))' % frame.buffer)
+                self.writeline("return Markup(concat(%s))" % frame.buffer)
                 return
-        self.writeline('return concat(%s)' % frame.buffer)
+        self.writeline("return concat(%s)" % frame.buffer)
 
     def indent(self):
         """Indent by one."""
@@ -353,14 +356,14 @@ class CodeGenerator(NodeVisitor):
     def start_write(self, frame, node=None):
         """Yield or write into the frame buffer."""
         if frame.buffer is None:
-            self.writeline('yield ', node)
+            self.writeline("yield ", node)
         else:
-            self.writeline('%s.append(' % frame.buffer, node)
+            self.writeline("%s.append(" % frame.buffer, node)
 
     def end_write(self, frame):
         """End the writing process started by `start_write`."""
         if frame.buffer is not None:
-            self.write(')')
+            self.write(")")
 
     def simple_write(self, s, frame, node=None):
         """Simple shortcut for start_write + write + end_write."""
@@ -373,7 +376,7 @@ class CodeGenerator(NodeVisitor):
         is no buffer a dummy ``if 0: yield None`` is written automatically.
         """
         try:
-            self.writeline('pass')
+            self.writeline("pass")
             for node in nodes:
                 self.visit(node, frame)
         except CompilerExit:
@@ -383,14 +386,13 @@ class CodeGenerator(NodeVisitor):
         """Write a string into the output stream."""
         if self._new_lines:
             if not self._first_write:
-                self.stream.write('\n' * self._new_lines)
+                self.stream.write("\n" * self._new_lines)
                 self.code_lineno += self._new_lines
                 if self._write_debug_info is not None:
-                    self.debug_info.append((self._write_debug_info,
-                                            self.code_lineno))
+                    self.debug_info.append((self._write_debug_info, self.code_lineno))
                     self._write_debug_info = None
             self._first_write = False
-            self.stream.write('    ' * self._indentation)
+            self.stream.write("    " * self._indentation)
             self._new_lines = 0
         self.stream.write(x)
 
@@ -410,7 +412,7 @@ class CodeGenerator(NodeVisitor):
         """Writes a function call to the stream for the current node.
         A leading comma is added automatically.  The extra keyword
         arguments may not include python keywords otherwise a syntax
-        error could occour.  The extra keyword arguments should be given
+        error could occur.  The extra keyword arguments should be given
         as python dict.
         """
         # if any of the given keyword arguments is a python keyword
@@ -422,41 +424,41 @@ class CodeGenerator(NodeVisitor):
                 break
 
         for arg in node.args:
-            self.write(', ')
+            self.write(", ")
             self.visit(arg, frame)
 
         if not kwarg_workaround:
             for kwarg in node.kwargs:
-                self.write(', ')
+                self.write(", ")
                 self.visit(kwarg, frame)
             if extra_kwargs is not None:
                 for key, value in iteritems(extra_kwargs):
-                    self.write(', %s=%s' % (key, value))
+                    self.write(", %s=%s" % (key, value))
         if node.dyn_args:
-            self.write(', *')
+            self.write(", *")
             self.visit(node.dyn_args, frame)
 
         if kwarg_workaround:
             if node.dyn_kwargs is not None:
-                self.write(', **dict({')
+                self.write(", **dict({")
             else:
-                self.write(', **{')
+                self.write(", **{")
             for kwarg in node.kwargs:
-                self.write('%r: ' % kwarg.key)
+                self.write("%r: " % kwarg.key)
                 self.visit(kwarg.value, frame)
-                self.write(', ')
+                self.write(", ")
             if extra_kwargs is not None:
                 for key, value in iteritems(extra_kwargs):
-                    self.write('%r: %s, ' % (key, value))
+                    self.write("%r: %s, " % (key, value))
             if node.dyn_kwargs is not None:
-                self.write('}, **')
+                self.write("}, **")
                 self.visit(node.dyn_kwargs, frame)
-                self.write(')')
+                self.write(")")
             else:
-                self.write('}')
+                self.write("}")
 
         elif node.dyn_kwargs is not None:
-            self.write(', **')
+            self.write(", **")
             self.visit(node.dyn_kwargs, frame)
 
     def pull_dependencies(self, nodes):
@@ -464,13 +466,14 @@ class CodeGenerator(NodeVisitor):
         visitor = DependencyFinderVisitor()
         for node in nodes:
             visitor.visit(node)
-        for dependency in 'filters', 'tests':
+        for dependency in "filters", "tests":
             mapping = getattr(self, dependency)
             for name in getattr(visitor, dependency):
                 if name not in mapping:
                     mapping[name] = self.temporary_identifier()
-                self.writeline('%s = environment.%s[%r]' %
-                               (mapping[name], dependency, name))
+                self.writeline(
+                    "%s = environment.%s[%r]" % (mapping[name], dependency, name)
+                )
 
     def enter_frame(self, frame):
         undefs = []
@@ -478,16 +481,15 @@ class CodeGenerator(NodeVisitor):
             if action == VAR_LOAD_PARAMETER:
                 pass
             elif action == VAR_LOAD_RESOLVE:
-                self.writeline('%s = %s(%r)' %
-                               (target, self.get_resolve_func(), param))
+                self.writeline("%s = %s(%r)" % (target, self.get_resolve_func(), param))
             elif action == VAR_LOAD_ALIAS:
-                self.writeline('%s = %s' % (target, param))
+                self.writeline("%s = %s" % (target, param))
             elif action == VAR_LOAD_UNDEFINED:
                 undefs.append(target)
             else:
-                raise NotImplementedError('unknown load instruction')
+                raise NotImplementedError("unknown load instruction")
         if undefs:
-            self.writeline('%s = missing' % ' = '.join(undefs))
+            self.writeline("%s = missing" % " = ".join(undefs))
 
     def leave_frame(self, frame, with_python_scope=False):
         if not with_python_scope:
@@ -495,12 +497,12 @@ class CodeGenerator(NodeVisitor):
             for target, _ in iteritems(frame.symbols.loads):
                 undefs.append(target)
             if undefs:
-                self.writeline('%s = missing' % ' = '.join(undefs))
+                self.writeline("%s = missing" % " = ".join(undefs))
 
     def func(self, name):
         if self.environment.is_async:
-            return 'async def %s' % name
-        return 'def %s' % name
+            return "async def %s" % name
+        return "def %s" % name
 
     def macro_body(self, node, frame):
         """Dump the function def of a macro or call block."""
@@ -512,16 +514,16 @@ class CodeGenerator(NodeVisitor):
         skip_special_params = set()
         args = []
         for idx, arg in enumerate(node.args):
-            if arg.name == 'caller':
+            if arg.name == "caller":
                 explicit_caller = idx
-            if arg.name in ('kwargs', 'varargs'):
+            if arg.name in ("kwargs", "varargs"):
                 skip_special_params.add(arg.name)
             args.append(frame.symbols.ref(arg.name))
 
-        undeclared = find_undeclared(node.body, ('caller', 'kwargs', 'varargs'))
+        undeclared = find_undeclared(node.body, ("caller", "kwargs", "varargs"))
 
-        if 'caller' in undeclared:
-            # In older Jinja2 versions there was a bug that allowed caller
+        if "caller" in undeclared:
+            # In older Jinja versions there was a bug that allowed caller
             # to retain the special behavior even if it was mentioned in
             # the argument list.  However thankfully this was only really
             # working if it was the last argument.  So we are explicitly
@@ -531,23 +533,26 @@ class CodeGenerator(NodeVisitor):
                 try:
                     node.defaults[explicit_caller - len(node.args)]
                 except IndexError:
-                    self.fail('When defining macros or call blocks the '
-                              'special "caller" argument must be omitted '
-                              'or be given a default.', node.lineno)
+                    self.fail(
+                        "When defining macros or call blocks the "
+                        'special "caller" argument must be omitted '
+                        "or be given a default.",
+                        node.lineno,
+                    )
             else:
-                args.append(frame.symbols.declare_parameter('caller'))
+                args.append(frame.symbols.declare_parameter("caller"))
             macro_ref.accesses_caller = True
-        if 'kwargs' in undeclared and not 'kwargs' in skip_special_params:
-            args.append(frame.symbols.declare_parameter('kwargs'))
+        if "kwargs" in undeclared and "kwargs" not in skip_special_params:
+            args.append(frame.symbols.declare_parameter("kwargs"))
             macro_ref.accesses_kwargs = True
-        if 'varargs' in undeclared and not 'varargs' in skip_special_params:
-            args.append(frame.symbols.declare_parameter('varargs'))
+        if "varargs" in undeclared and "varargs" not in skip_special_params:
+            args.append(frame.symbols.declare_parameter("varargs"))
             macro_ref.accesses_varargs = True
 
         # macros are delayed, they never require output checks
         frame.require_output_check = False
         frame.symbols.analyze_node(node)
-        self.writeline('%s(%s):' % (self.func('macro'), ', '.join(args)), node)
+        self.writeline("%s(%s):" % (self.func("macro"), ", ".join(args)), node)
         self.indent()
 
         self.buffer(frame)
@@ -556,17 +561,17 @@ class CodeGenerator(NodeVisitor):
         self.push_parameter_definitions(frame)
         for idx, arg in enumerate(node.args):
             ref = frame.symbols.ref(arg.name)
-            self.writeline('if %s is missing:' % ref)
+            self.writeline("if %s is missing:" % ref)
             self.indent()
             try:
                 default = node.defaults[idx - len(node.args)]
             except IndexError:
-                self.writeline('%s = undefined(%r, name=%r)' % (
-                    ref,
-                    'parameter %r was not provided' % arg.name,
-                    arg.name))
+                self.writeline(
+                    "%s = undefined(%r, name=%r)"
+                    % (ref, "parameter %r was not provided" % arg.name, arg.name)
+                )
             else:
-                self.writeline('%s = ' % ref)
+                self.writeline("%s = " % ref)
                 self.visit(default, frame)
             self.mark_parameter_stored(ref)
             self.outdent()
@@ -581,35 +586,46 @@ class CodeGenerator(NodeVisitor):
 
     def macro_def(self, macro_ref, frame):
         """Dump the macro definition for the def created by macro_body."""
-        arg_tuple = ', '.join(repr(x.name) for x in macro_ref.node.args)
-        name = getattr(macro_ref.node, 'name', None)
+        arg_tuple = ", ".join(repr(x.name) for x in macro_ref.node.args)
+        name = getattr(macro_ref.node, "name", None)
         if len(macro_ref.node.args) == 1:
-            arg_tuple += ','
-        self.write('Macro(environment, macro, %r, (%s), %r, %r, %r, '
-                   'context.eval_ctx.autoescape)' %
-                   (name, arg_tuple, macro_ref.accesses_kwargs,
-                    macro_ref.accesses_varargs, macro_ref.accesses_caller))
+            arg_tuple += ","
+        self.write(
+            "Macro(environment, macro, %r, (%s), %r, %r, %r, "
+            "context.eval_ctx.autoescape)"
+            % (
+                name,
+                arg_tuple,
+                macro_ref.accesses_kwargs,
+                macro_ref.accesses_varargs,
+                macro_ref.accesses_caller,
+            )
+        )
 
     def position(self, node):
         """Return a human readable position for the node."""
-        rv = 'line %d' % node.lineno
+        rv = "line %d" % node.lineno
         if self.name is not None:
-            rv += ' in ' + repr(self.name)
+            rv += " in " + repr(self.name)
         return rv
 
     def dump_local_context(self, frame):
-        return '{%s}' % ', '.join(
-            '%r: %s' % (name, target) for name, target
-            in iteritems(frame.symbols.dump_stores()))
+        return "{%s}" % ", ".join(
+            "%r: %s" % (name, target)
+            for name, target in iteritems(frame.symbols.dump_stores())
+        )
 
     def write_commons(self):
         """Writes a common preamble that is used by root and block functions.
         Primarily this sets up common local helpers and enforces a generator
         through a dead branch.
         """
-        self.writeline('resolve = context.resolve_or_missing')
-        self.writeline('undefined = environment.undefined')
-        self.writeline('if 0: yield None')
+        self.writeline("resolve = context.resolve_or_missing")
+        self.writeline("undefined = environment.undefined")
+        # always use the standard Undefined class for the implicit else of
+        # conditional expressions
+        self.writeline("cond_expr_undefined = Undefined")
+        self.writeline("if 0: yield None")
 
     def push_parameter_definitions(self, frame):
         """Pushes all parameter targets from the given frame into a local
@@ -642,12 +658,12 @@ class CodeGenerator(NodeVisitor):
 
     def get_resolve_func(self):
         target = self._context_reference_stack[-1]
-        if target == 'context':
-            return 'resolve'
-        return '%s.resolve' % target
+        if target == "context":
+            return "resolve"
+        return "%s.resolve" % target
 
     def derive_context(self, frame):
-        return '%s.derived(%s)' % (
+        return "%s.derived(%s)" % (
             self.get_context_ref(),
             self.dump_local_context(frame),
         )
@@ -669,44 +685,48 @@ class CodeGenerator(NodeVisitor):
         vars = self._assign_stack.pop()
         if not frame.toplevel or not vars:
             return
-        public_names = [x for x in vars if x[:1] != '_']
+        public_names = [x for x in vars if x[:1] != "_"]
         if len(vars) == 1:
             name = next(iter(vars))
             ref = frame.symbols.ref(name)
-            self.writeline('context.vars[%r] = %s' % (name, ref))
+            self.writeline("context.vars[%r] = %s" % (name, ref))
         else:
-            self.writeline('context.vars.update({')
+            self.writeline("context.vars.update({")
             for idx, name in enumerate(vars):
                 if idx:
-                    self.write(', ')
+                    self.write(", ")
                 ref = frame.symbols.ref(name)
-                self.write('%r: %s' % (name, ref))
-            self.write('})')
+                self.write("%r: %s" % (name, ref))
+            self.write("})")
         if public_names:
             if len(public_names) == 1:
-                self.writeline('context.exported_vars.add(%r)' %
-                               public_names[0])
+                self.writeline("context.exported_vars.add(%r)" % public_names[0])
             else:
-                self.writeline('context.exported_vars.update((%s))' %
-                               ', '.join(imap(repr, public_names)))
+                self.writeline(
+                    "context.exported_vars.update((%s))"
+                    % ", ".join(imap(repr, public_names))
+                )
 
     # -- Statement Visitors
 
     def visit_Template(self, node, frame=None):
-        assert frame is None, 'no root frame allowed'
+        assert frame is None, "no root frame allowed"
         eval_ctx = EvalContext(self.environment, self.name)
 
-        from jinja2.runtime import __all__ as exported
-        self.writeline('from __future__ import %s' % ', '.join(code_features))
-        self.writeline('from jinja2.runtime import ' + ', '.join(exported))
+        from .runtime import exported
+
+        self.writeline("from __future__ import %s" % ", ".join(code_features))
+        self.writeline("from jinja2.runtime import " + ", ".join(exported))
 
         if self.environment.is_async:
-            self.writeline('from jinja2.asyncsupport import auto_await, '
-                           'auto_aiter, make_async_loop_context')
+            self.writeline(
+                "from jinja2.asyncsupport import auto_await, "
+                "auto_aiter, AsyncLoopContext"
+            )
 
         # if we want a deferred initialization we cannot move the
         # environment into a local name
-        envenv = not self.defer_init and ', environment=environment' or ''
+        envenv = not self.defer_init and ", environment=environment" or ""
 
         # do we have an extends tag at all?  If not, we can save some
         # overhead by just not processing any inheritance code.
@@ -715,7 +735,7 @@ class CodeGenerator(NodeVisitor):
         # find all blocks
         for block in node.find_all(nodes.Block):
             if block.name in self.blocks:
-                self.fail('block %r defined twice' % block.name, block.lineno)
+                self.fail("block %r defined twice" % block.name, block.lineno)
             self.blocks[block.name] = block
 
         # find all imports and import them
@@ -723,32 +743,32 @@ class CodeGenerator(NodeVisitor):
             if import_.importname not in self.import_aliases:
                 imp = import_.importname
                 self.import_aliases[imp] = alias = self.temporary_identifier()
-                if '.' in imp:
-                    module, obj = imp.rsplit('.', 1)
-                    self.writeline('from %s import %s as %s' %
-                                   (module, obj, alias))
+                if "." in imp:
+                    module, obj = imp.rsplit(".", 1)
+                    self.writeline("from %s import %s as %s" % (module, obj, alias))
                 else:
-                    self.writeline('import %s as %s' % (imp, alias))
+                    self.writeline("import %s as %s" % (imp, alias))
 
         # add the load name
-        self.writeline('name = %r' % self.name)
+        self.writeline("name = %r" % self.name)
 
         # generate the root render function.
-        self.writeline('%s(context, missing=missing%s):' %
-                       (self.func('root'), envenv), extra=1)
+        self.writeline(
+            "%s(context, missing=missing%s):" % (self.func("root"), envenv), extra=1
+        )
         self.indent()
         self.write_commons()
 
         # process the root
         frame = Frame(eval_ctx)
-        if 'self' in find_undeclared(node.body, ('self',)):
-            ref = frame.symbols.declare_parameter('self')
-            self.writeline('%s = TemplateReference(context)' % ref)
+        if "self" in find_undeclared(node.body, ("self",)):
+            ref = frame.symbols.declare_parameter("self")
+            self.writeline("%s = TemplateReference(context)" % ref)
         frame.symbols.analyze_node(node)
         frame.toplevel = frame.rootlevel = True
         frame.require_output_check = have_extends and not self.has_known_extends
         if have_extends:
-            self.writeline('parent_template = None')
+            self.writeline("parent_template = None")
         self.enter_frame(frame)
         self.pull_dependencies(node.body)
         self.blockvisit(node.body, frame)
@@ -759,39 +779,42 @@ class CodeGenerator(NodeVisitor):
         if have_extends:
             if not self.has_known_extends:
                 self.indent()
-                self.writeline('if parent_template is not None:')
+                self.writeline("if parent_template is not None:")
             self.indent()
             if supports_yield_from and not self.environment.is_async:
-                self.writeline('yield from parent_template.'
-                               'root_render_func(context)')
+                self.writeline("yield from parent_template.root_render_func(context)")
             else:
-                self.writeline('%sfor event in parent_template.'
-                               'root_render_func(context):' %
-                               (self.environment.is_async and 'async ' or ''))
+                self.writeline(
+                    "%sfor event in parent_template."
+                    "root_render_func(context):"
+                    % (self.environment.is_async and "async " or "")
+                )
                 self.indent()
-                self.writeline('yield event')
+                self.writeline("yield event")
                 self.outdent()
             self.outdent(1 + (not self.has_known_extends))
 
         # at this point we now have the blocks collected and can visit them too.
         for name, block in iteritems(self.blocks):
-            self.writeline('%s(context, missing=missing%s):' %
-                           (self.func('block_' + name), envenv),
-                           block, 1)
+            self.writeline(
+                "%s(context, missing=missing%s):"
+                % (self.func("block_" + name), envenv),
+                block,
+                1,
+            )
             self.indent()
             self.write_commons()
             # It's important that we do not make this frame a child of the
             # toplevel template.  This would cause a variety of
             # interesting issues with identifier tracking.
             block_frame = Frame(eval_ctx)
-            undeclared = find_undeclared(block.body, ('self', 'super'))
-            if 'self' in undeclared:
-                ref = block_frame.symbols.declare_parameter('self')
-                self.writeline('%s = TemplateReference(context)' % ref)
-            if 'super' in undeclared:
-                ref = block_frame.symbols.declare_parameter('super')
-                self.writeline('%s = context.super(%r, '
-                               'block_%s)' % (ref, name, name))
+            undeclared = find_undeclared(block.body, ("self", "super"))
+            if "self" in undeclared:
+                ref = block_frame.symbols.declare_parameter("self")
+                self.writeline("%s = TemplateReference(context)" % ref)
+            if "super" in undeclared:
+                ref = block_frame.symbols.declare_parameter("super")
+                self.writeline("%s = context.super(%r, block_%s)" % (ref, name, name))
             block_frame.symbols.analyze_node(block)
             block_frame.block = name
             self.enter_frame(block_frame)
@@ -800,13 +823,15 @@ class CodeGenerator(NodeVisitor):
             self.leave_frame(block_frame, with_python_scope=True)
             self.outdent()
 
-        self.writeline('blocks = {%s}' % ', '.join('%r: block_%s' % (x, x)
-                                                   for x in self.blocks),
-                       extra=1)
+        self.writeline(
+            "blocks = {%s}" % ", ".join("%r: block_%s" % (x, x) for x in self.blocks),
+            extra=1,
+        )
 
         # add a function that returns the debug info
-        self.writeline('debug_info = %r' % '&'.join('%s=%s' % x for x
-                                                    in self.debug_info))
+        self.writeline(
+            "debug_info = %r" % "&".join("%s=%s" % x for x in self.debug_info)
+        )
 
     def visit_Block(self, node, frame):
         """Call a block and register it for the template."""
@@ -817,7 +842,7 @@ class CodeGenerator(NodeVisitor):
             if self.has_known_extends:
                 return
             if self.extends_so_far > 0:
-                self.writeline('if parent_template is None:')
+                self.writeline("if parent_template is None:")
                 self.indent()
                 level += 1
 
@@ -826,16 +851,22 @@ class CodeGenerator(NodeVisitor):
         else:
             context = self.get_context_ref()
 
-        if supports_yield_from and not self.environment.is_async and \
-           frame.buffer is None:
-            self.writeline('yield from context.blocks[%r][0](%s)' % (
-                           node.name, context), node)
+        if (
+            supports_yield_from
+            and not self.environment.is_async
+            and frame.buffer is None
+        ):
+            self.writeline(
+                "yield from context.blocks[%r][0](%s)" % (node.name, context), node
+            )
         else:
-            loop = self.environment.is_async and 'async for' or 'for'
-            self.writeline('%s event in context.blocks[%r][0](%s):' % (
-                           loop, node.name, context), node)
+            loop = self.environment.is_async and "async for" or "for"
+            self.writeline(
+                "%s event in context.blocks[%r][0](%s):" % (loop, node.name, context),
+                node,
+            )
             self.indent()
-            self.simple_write('event', frame)
+            self.simple_write("event", frame)
             self.outdent()
 
         self.outdent(level)
@@ -843,8 +874,7 @@ class CodeGenerator(NodeVisitor):
     def visit_Extends(self, node, frame):
         """Calls the extender."""
         if not frame.toplevel:
-            self.fail('cannot use extend from a non top-level scope',
-                      node.lineno)
+            self.fail("cannot use extend from a non top-level scope", node.lineno)
 
         # if the number of extends statements in general is zero so
         # far, we don't have to add a check if something extended
@@ -856,10 +886,9 @@ class CodeGenerator(NodeVisitor):
             # time too, but i welcome it not to confuse users by throwing the
             # same error at different times just "because we can".
             if not self.has_known_extends:
-                self.writeline('if parent_template is not None:')
+                self.writeline("if parent_template is not None:")
                 self.indent()
-            self.writeline('raise TemplateRuntimeError(%r)' %
-                           'extended multiple times')
+            self.writeline("raise TemplateRuntimeError(%r)" % "extended multiple times")
 
             # if we have a known extends already we don't need that code here
             # as we know that the template execution will end here.
@@ -868,14 +897,14 @@ class CodeGenerator(NodeVisitor):
             else:
                 self.outdent()
 
-        self.writeline('parent_template = environment.get_template(', node)
+        self.writeline("parent_template = environment.get_template(", node)
         self.visit(node.template, frame)
-        self.write(', %r)' % self.name)
-        self.writeline('for name, parent_block in parent_template.'
-                       'blocks.%s():' % dict_item_iter)
+        self.write(", %r)" % self.name)
+        self.writeline(
+            "for name, parent_block in parent_template.blocks.%s():" % dict_item_iter
+        )
         self.indent()
-        self.writeline('context.blocks.setdefault(name, []).'
-                       'append(parent_block)')
+        self.writeline("context.blocks.setdefault(name, []).append(parent_block)")
         self.outdent()
 
         # if this extends statement was in the root level we can take
@@ -890,52 +919,56 @@ class CodeGenerator(NodeVisitor):
     def visit_Include(self, node, frame):
         """Handles includes."""
         if node.ignore_missing:
-            self.writeline('try:')
+            self.writeline("try:")
             self.indent()
 
-        func_name = 'get_or_select_template'
+        func_name = "get_or_select_template"
         if isinstance(node.template, nodes.Const):
             if isinstance(node.template.value, string_types):
-                func_name = 'get_template'
+                func_name = "get_template"
             elif isinstance(node.template.value, (tuple, list)):
-                func_name = 'select_template'
+                func_name = "select_template"
         elif isinstance(node.template, (nodes.Tuple, nodes.List)):
-            func_name = 'select_template'
+            func_name = "select_template"
 
-        self.writeline('template = environment.%s(' % func_name, node)
+        self.writeline("template = environment.%s(" % func_name, node)
         self.visit(node.template, frame)
-        self.write(', %r)' % self.name)
+        self.write(", %r)" % self.name)
         if node.ignore_missing:
             self.outdent()
-            self.writeline('except TemplateNotFound:')
+            self.writeline("except TemplateNotFound:")
             self.indent()
-            self.writeline('pass')
+            self.writeline("pass")
             self.outdent()
-            self.writeline('else:')
+            self.writeline("else:")
             self.indent()
 
         skip_event_yield = False
         if node.with_context:
-            loop = self.environment.is_async and 'async for' or 'for'
-            self.writeline('%s event in template.root_render_func('
-                           'template.new_context(context.get_all(), True, '
-                           '%s)):' % (loop, self.dump_local_context(frame)))
+            loop = self.environment.is_async and "async for" or "for"
+            self.writeline(
+                "%s event in template.root_render_func("
+                "template.new_context(context.get_all(), True, "
+                "%s)):" % (loop, self.dump_local_context(frame))
+            )
         elif self.environment.is_async:
-            self.writeline('for event in (await '
-                           'template._get_default_module_async())'
-                           '._body_stream:')
+            self.writeline(
+                "for event in (await "
+                "template._get_default_module_async())"
+                "._body_stream:"
+            )
         else:
             if supports_yield_from:
-                self.writeline('yield from template._get_default_module()'
-                               '._body_stream')
+                self.writeline("yield from template._get_default_module()._body_stream")
                 skip_event_yield = True
             else:
-                self.writeline('for event in template._get_default_module()'
-                               '._body_stream:')
+                self.writeline(
+                    "for event in template._get_default_module()._body_stream:"
+                )
 
         if not skip_event_yield:
             self.indent()
-            self.simple_write('event', frame)
+            self.simple_write("event", frame)
             self.outdent()
 
         if node.ignore_missing:
@@ -943,40 +976,50 @@ class CodeGenerator(NodeVisitor):
 
     def visit_Import(self, node, frame):
         """Visit regular imports."""
-        self.writeline('%s = ' % frame.symbols.ref(node.target), node)
+        self.writeline("%s = " % frame.symbols.ref(node.target), node)
         if frame.toplevel:
-            self.write('context.vars[%r] = ' % node.target)
+            self.write("context.vars[%r] = " % node.target)
         if self.environment.is_async:
-            self.write('await ')
-        self.write('environment.get_template(')
+            self.write("await ")
+        self.write("environment.get_template(")
         self.visit(node.template, frame)
-        self.write(', %r).' % self.name)
+        self.write(", %r)." % self.name)
         if node.with_context:
-            self.write('make_module%s(context.get_all(), True, %s)'
-                       % (self.environment.is_async and '_async' or '',
-                          self.dump_local_context(frame)))
+            self.write(
+                "make_module%s(context.get_all(), True, %s)"
+                % (
+                    self.environment.is_async and "_async" or "",
+                    self.dump_local_context(frame),
+                )
+            )
         elif self.environment.is_async:
-            self.write('_get_default_module_async()')
+            self.write("_get_default_module_async()")
         else:
-            self.write('_get_default_module()')
-        if frame.toplevel and not node.target.startswith('_'):
-            self.writeline('context.exported_vars.discard(%r)' % node.target)
+            self.write("_get_default_module()")
+        if frame.toplevel and not node.target.startswith("_"):
+            self.writeline("context.exported_vars.discard(%r)" % node.target)
 
     def visit_FromImport(self, node, frame):
         """Visit named imports."""
         self.newline(node)
-        self.write('included_template = %senvironment.get_template('
-                   % (self.environment.is_async and 'await ' or ''))
+        self.write(
+            "included_template = %senvironment.get_template("
+            % (self.environment.is_async and "await " or "")
+        )
         self.visit(node.template, frame)
-        self.write(', %r).' % self.name)
+        self.write(", %r)." % self.name)
         if node.with_context:
-            self.write('make_module%s(context.get_all(), True, %s)'
-                       % (self.environment.is_async and '_async' or '',
-                          self.dump_local_context(frame)))
+            self.write(
+                "make_module%s(context.get_all(), True, %s)"
+                % (
+                    self.environment.is_async and "_async" or "",
+                    self.dump_local_context(frame),
+                )
+            )
         elif self.environment.is_async:
-            self.write('_get_default_module_async()')
+            self.write("_get_default_module_async()")
         else:
-            self.write('_get_default_module()')
+            self.write("_get_default_module()")
 
         var_names = []
         discarded_names = []
@@ -985,41 +1028,51 @@ class CodeGenerator(NodeVisitor):
                 name, alias = name
             else:
                 alias = name
-            self.writeline('%s = getattr(included_template, '
-                           '%r, missing)' % (frame.symbols.ref(alias), name))
-            self.writeline('if %s is missing:' % frame.symbols.ref(alias))
+            self.writeline(
+                "%s = getattr(included_template, "
+                "%r, missing)" % (frame.symbols.ref(alias), name)
+            )
+            self.writeline("if %s is missing:" % frame.symbols.ref(alias))
             self.indent()
-            self.writeline('%s = undefined(%r %% '
-                           'included_template.__name__, '
-                           'name=%r)' %
-                           (frame.symbols.ref(alias),
-                            'the template %%r (imported on %s) does '
-                            'not export the requested name %s' % (
-                                self.position(node),
-                                repr(name)
-                           ), name))
+            self.writeline(
+                "%s = undefined(%r %% "
+                "included_template.__name__, "
+                "name=%r)"
+                % (
+                    frame.symbols.ref(alias),
+                    "the template %%r (imported on %s) does "
+                    "not export the requested name %s"
+                    % (self.position(node), repr(name)),
+                    name,
+                )
+            )
             self.outdent()
             if frame.toplevel:
                 var_names.append(alias)
-                if not alias.startswith('_'):
+                if not alias.startswith("_"):
                     discarded_names.append(alias)
 
         if var_names:
             if len(var_names) == 1:
                 name = var_names[0]
-                self.writeline('context.vars[%r] = %s' %
-                               (name, frame.symbols.ref(name)))
+                self.writeline(
+                    "context.vars[%r] = %s" % (name, frame.symbols.ref(name))
+                )
             else:
-                self.writeline('context.vars.update({%s})' % ', '.join(
-                    '%r: %s' % (name, frame.symbols.ref(name)) for name in var_names
-                ))
+                self.writeline(
+                    "context.vars.update({%s})"
+                    % ", ".join(
+                        "%r: %s" % (name, frame.symbols.ref(name)) for name in var_names
+                    )
+                )
         if discarded_names:
             if len(discarded_names) == 1:
-                self.writeline('context.exported_vars.discard(%r)' %
-                               discarded_names[0])
+                self.writeline("context.exported_vars.discard(%r)" % discarded_names[0])
             else:
-                self.writeline('context.exported_vars.difference_'
-                               'update((%s))' % ', '.join(imap(repr, discarded_names)))
+                self.writeline(
+                    "context.exported_vars.difference_"
+                    "update((%s))" % ", ".join(imap(repr, discarded_names))
+                )
 
     def visit_For(self, node, frame):
         loop_frame = frame.inner()
@@ -1029,35 +1082,35 @@ class CodeGenerator(NodeVisitor):
         # try to figure out if we have an extended loop.  An extended loop
         # is necessary if the loop is in recursive mode if the special loop
         # variable is accessed in the body.
-        extended_loop = node.recursive or 'loop' in \
-                        find_undeclared(node.iter_child_nodes(
-                            only=('body',)), ('loop',))
+        extended_loop = node.recursive or "loop" in find_undeclared(
+            node.iter_child_nodes(only=("body",)), ("loop",)
+        )
 
         loop_ref = None
         if extended_loop:
-            loop_ref = loop_frame.symbols.declare_parameter('loop')
+            loop_ref = loop_frame.symbols.declare_parameter("loop")
 
-        loop_frame.symbols.analyze_node(node, for_branch='body')
+        loop_frame.symbols.analyze_node(node, for_branch="body")
         if node.else_:
-            else_frame.symbols.analyze_node(node, for_branch='else')
+            else_frame.symbols.analyze_node(node, for_branch="else")
 
         if node.test:
             loop_filter_func = self.temporary_identifier()
-            test_frame.symbols.analyze_node(node, for_branch='test')
-            self.writeline('%s(fiter):' % self.func(loop_filter_func), node.test)
+            test_frame.symbols.analyze_node(node, for_branch="test")
+            self.writeline("%s(fiter):" % self.func(loop_filter_func), node.test)
             self.indent()
             self.enter_frame(test_frame)
-            self.writeline(self.environment.is_async and 'async for ' or 'for ')
+            self.writeline(self.environment.is_async and "async for " or "for ")
             self.visit(node.target, loop_frame)
-            self.write(' in ')
-            self.write(self.environment.is_async and 'auto_aiter(fiter)' or 'fiter')
-            self.write(':')
+            self.write(" in ")
+            self.write(self.environment.is_async and "auto_aiter(fiter)" or "fiter")
+            self.write(":")
             self.indent()
-            self.writeline('if ', node.test)
+            self.writeline("if ", node.test)
             self.visit(node.test, test_frame)
-            self.write(':')
+            self.write(":")
             self.indent()
-            self.writeline('yield ')
+            self.writeline("yield ")
             self.visit(node.target, loop_frame)
             self.outdent(3)
             self.leave_frame(test_frame, with_python_scope=True)
@@ -1066,8 +1119,9 @@ class CodeGenerator(NodeVisitor):
         # variables at that point.  Because loops can be nested but the loop
         # variable is a special one we have to enforce aliasing for it.
         if node.recursive:
-            self.writeline('%s(reciter, loop_render_func, depth=0):' %
-                           self.func('loop'), node)
+            self.writeline(
+                "%s(reciter, loop_render_func, depth=0):" % self.func("loop"), node
+            )
             self.indent()
             self.buffer(loop_frame)
 
@@ -1077,57 +1131,60 @@ class CodeGenerator(NodeVisitor):
         # make sure the loop variable is a special one and raise a template
         # assertion error if a loop tries to write to loop
         if extended_loop:
-            self.writeline('%s = missing' % loop_ref)
+            self.writeline("%s = missing" % loop_ref)
 
         for name in node.find_all(nodes.Name):
-            if name.ctx == 'store' and name.name == 'loop':
-                self.fail('Can\'t assign to special loop variable '
-                          'in for-loop target', name.lineno)
+            if name.ctx == "store" and name.name == "loop":
+                self.fail(
+                    "Can't assign to special loop variable in for-loop target",
+                    name.lineno,
+                )
 
         if node.else_:
             iteration_indicator = self.temporary_identifier()
-            self.writeline('%s = 1' % iteration_indicator)
+            self.writeline("%s = 1" % iteration_indicator)
 
-        self.writeline(self.environment.is_async and 'async for ' or 'for ', node)
+        self.writeline(self.environment.is_async and "async for " or "for ", node)
         self.visit(node.target, loop_frame)
         if extended_loop:
             if self.environment.is_async:
-                self.write(', %s in await make_async_loop_context(' % loop_ref)
+                self.write(", %s in AsyncLoopContext(" % loop_ref)
             else:
-                self.write(', %s in LoopContext(' % loop_ref)
+                self.write(", %s in LoopContext(" % loop_ref)
         else:
-            self.write(' in ')
+            self.write(" in ")
 
         if node.test:
-            self.write('%s(' % loop_filter_func)
+            self.write("%s(" % loop_filter_func)
         if node.recursive:
-            self.write('reciter')
+            self.write("reciter")
         else:
             if self.environment.is_async and not extended_loop:
-                self.write('auto_aiter(')
+                self.write("auto_aiter(")
             self.visit(node.iter, frame)
             if self.environment.is_async and not extended_loop:
-                self.write(')')
+                self.write(")")
         if node.test:
-            self.write(')')
+            self.write(")")
 
         if node.recursive:
-            self.write(', undefined, loop_render_func, depth):')
+            self.write(", undefined, loop_render_func, depth):")
         else:
-            self.write(extended_loop and ', undefined):' or ':')
+            self.write(extended_loop and ", undefined):" or ":")
 
         self.indent()
         self.enter_frame(loop_frame)
 
         self.blockvisit(node.body, loop_frame)
         if node.else_:
-            self.writeline('%s = 0' % iteration_indicator)
+            self.writeline("%s = 0" % iteration_indicator)
         self.outdent()
-        self.leave_frame(loop_frame, with_python_scope=node.recursive
-                         and not node.else_)
+        self.leave_frame(
+            loop_frame, with_python_scope=node.recursive and not node.else_
+        )
 
         if node.else_:
-            self.writeline('if %s:' % iteration_indicator)
+            self.writeline("if %s:" % iteration_indicator)
             self.indent()
             self.enter_frame(else_frame)
             self.blockvisit(node.else_, else_frame)
@@ -1141,33 +1198,33 @@ class CodeGenerator(NodeVisitor):
             self.outdent()
             self.start_write(frame, node)
             if self.environment.is_async:
-                self.write('await ')
-            self.write('loop(')
+                self.write("await ")
+            self.write("loop(")
             if self.environment.is_async:
-                self.write('auto_aiter(')
+                self.write("auto_aiter(")
             self.visit(node.iter, frame)
             if self.environment.is_async:
-                self.write(')')
-            self.write(', loop)')
+                self.write(")")
+            self.write(", loop)")
             self.end_write(frame)
 
     def visit_If(self, node, frame):
         if_frame = frame.soft()
-        self.writeline('if ', node)
+        self.writeline("if ", node)
         self.visit(node.test, if_frame)
-        self.write(':')
+        self.write(":")
         self.indent()
         self.blockvisit(node.body, if_frame)
         self.outdent()
         for elif_ in node.elif_:
-            self.writeline('elif ', elif_)
+            self.writeline("elif ", elif_)
             self.visit(elif_.test, if_frame)
-            self.write(':')
+            self.write(":")
             self.indent()
             self.blockvisit(elif_.body, if_frame)
             self.outdent()
         if node.else_:
-            self.writeline('else:')
+            self.writeline("else:")
             self.indent()
             self.blockvisit(node.else_, if_frame)
             self.outdent()
@@ -1176,16 +1233,15 @@ class CodeGenerator(NodeVisitor):
         macro_frame, macro_ref = self.macro_body(node, frame)
         self.newline()
         if frame.toplevel:
-            if not node.name.startswith('_'):
-                self.write('context.exported_vars.add(%r)' % node.name)
-            ref = frame.symbols.ref(node.name)
-            self.writeline('context.vars[%r] = ' % node.name)
-        self.write('%s = ' % frame.symbols.ref(node.name))
+            if not node.name.startswith("_"):
+                self.write("context.exported_vars.add(%r)" % node.name)
+            self.writeline("context.vars[%r] = " % node.name)
+        self.write("%s = " % frame.symbols.ref(node.name))
         self.macro_def(macro_ref, macro_frame)
 
     def visit_CallBlock(self, node, frame):
         call_frame, macro_ref = self.macro_body(node, frame)
-        self.writeline('caller = ')
+        self.writeline("caller = ")
         self.macro_def(macro_ref, call_frame)
         self.start_write(frame, node)
         self.visit_Call(node.call, frame, forward_caller=True)
@@ -1206,10 +1262,10 @@ class CodeGenerator(NodeVisitor):
         with_frame = frame.inner()
         with_frame.symbols.analyze_node(node)
         self.enter_frame(with_frame)
-        for idx, (target, expr) in enumerate(izip(node.targets, node.values)):
+        for target, expr in izip(node.targets, node.values):
             self.newline()
             self.visit(target, with_frame)
-            self.write(' = ')
+            self.write(" = ")
             self.visit(expr, frame)
         self.blockvisit(node.body, with_frame)
         self.leave_frame(with_frame)
@@ -1218,156 +1274,187 @@ class CodeGenerator(NodeVisitor):
         self.newline(node)
         self.visit(node.node, frame)
 
-    def visit_Output(self, node, frame):
-        # if we have a known extends statement, we don't output anything
-        # if we are in a require_output_check section
-        if self.has_known_extends and frame.require_output_check:
-            return
+    _FinalizeInfo = namedtuple("_FinalizeInfo", ("const", "src"))
+    #: The default finalize function if the environment isn't configured
+    #: with one. Or if the environment has one, this is called on that
+    #: function's output for constants.
+    _default_finalize = text_type
+    _finalize = None
+
+    def _make_finalize(self):
+        """Build the finalize function to be used on constants and at
+        runtime. Cached so it's only created once for all output nodes.
+
+        Returns a ``namedtuple`` with the following attributes:
+
+        ``const``
+            A function to finalize constant data at compile time.
+
+        ``src``
+            Source code to output around nodes to be evaluated at
+            runtime.
+        """
+        if self._finalize is not None:
+            return self._finalize
+
+        finalize = default = self._default_finalize
+        src = None
 
-        allow_constant_finalize = True
         if self.environment.finalize:
-            func = self.environment.finalize
-            if getattr(func, 'contextfunction', False) or \
-               getattr(func, 'evalcontextfunction', False):
-                allow_constant_finalize = False
-            elif getattr(func, 'environmentfunction', False):
-                finalize = lambda x: text_type(
-                    self.environment.finalize(self.environment, x))
-            else:
-                finalize = lambda x: text_type(self.environment.finalize(x))
+            src = "environment.finalize("
+            env_finalize = self.environment.finalize
+
+            def finalize(value):
+                return default(env_finalize(value))
+
+            if getattr(env_finalize, "contextfunction", False):
+                src += "context, "
+                finalize = None  # noqa: F811
+            elif getattr(env_finalize, "evalcontextfunction", False):
+                src += "context.eval_ctx, "
+                finalize = None
+            elif getattr(env_finalize, "environmentfunction", False):
+                src += "environment, "
+
+                def finalize(value):
+                    return default(env_finalize(self.environment, value))
+
+        self._finalize = self._FinalizeInfo(finalize, src)
+        return self._finalize
+
+    def _output_const_repr(self, group):
+        """Given a group of constant values converted from ``Output``
+        child nodes, produce a string to write to the template module
+        source.
+        """
+        return repr(concat(group))
+
+    def _output_child_to_const(self, node, frame, finalize):
+        """Try to optimize a child of an ``Output`` node by trying to
+        convert it to constant, finalized data at compile time.
+
+        If :exc:`Impossible` is raised, the node is not constant and
+        will be evaluated at runtime. Any other exception will also be
+        evaluated at runtime for easier debugging.
+        """
+        const = node.as_const(frame.eval_ctx)
+
+        if frame.eval_ctx.autoescape:
+            const = escape(const)
+
+        # Template data doesn't go through finalize.
+        if isinstance(node, nodes.TemplateData):
+            return text_type(const)
+
+        return finalize.const(const)
+
+    def _output_child_pre(self, node, frame, finalize):
+        """Output extra source code before visiting a child of an
+        ``Output`` node.
+        """
+        if frame.eval_ctx.volatile:
+            self.write("(escape if context.eval_ctx.autoescape else to_string)(")
+        elif frame.eval_ctx.autoescape:
+            self.write("escape(")
         else:
-            finalize = text_type
+            self.write("to_string(")
+
+        if finalize.src is not None:
+            self.write(finalize.src)
+
+    def _output_child_post(self, node, frame, finalize):
+        """Output extra source code after visiting a child of an
+        ``Output`` node.
+        """
+        self.write(")")
+
+        if finalize.src is not None:
+            self.write(")")
 
-        # if we are inside a frame that requires output checking, we do so
-        outdent_later = False
+    def visit_Output(self, node, frame):
+        # If an extends is active, don't render outside a block.
         if frame.require_output_check:
-            self.writeline('if parent_template is None:')
+            # A top-level extends is known to exist at compile time.
+            if self.has_known_extends:
+                return
+
+            self.writeline("if parent_template is None:")
             self.indent()
-            outdent_later = True
 
-        # try to evaluate as many chunks as possible into a static
-        # string at compile time.
+        finalize = self._make_finalize()
         body = []
+
+        # Evaluate constants at compile time if possible. Each item in
+        # body will be either a list of static data or a node to be
+        # evaluated at runtime.
         for child in node.nodes:
             try:
-                if not allow_constant_finalize:
+                if not (
+                    # If the finalize function requires runtime context,
+                    # constants can't be evaluated at compile time.
+                    finalize.const
+                    # Unless it's basic template data that won't be
+                    # finalized anyway.
+                    or isinstance(child, nodes.TemplateData)
+                ):
                     raise nodes.Impossible()
-                const = child.as_const(frame.eval_ctx)
-            except nodes.Impossible:
-                body.append(child)
-                continue
-            # the frame can't be volatile here, becaus otherwise the
-            # as_const() function would raise an Impossible exception
-            # at that point.
-            try:
-                if frame.eval_ctx.autoescape:
-                    if hasattr(const, '__html__'):
-                        const = const.__html__()
-                    else:
-                        const = escape(const)
-                const = finalize(const)
-            except Exception:
-                # if something goes wrong here we evaluate the node
-                # at runtime for easier debugging
+
+                const = self._output_child_to_const(child, frame, finalize)
+            except (nodes.Impossible, Exception):
+                # The node was not constant and needs to be evaluated at
+                # runtime. Or another error was raised, which is easier
+                # to debug at runtime.
                 body.append(child)
                 continue
+
             if body and isinstance(body[-1], list):
                 body[-1].append(const)
             else:
                 body.append([const])
 
-        # if we have less than 3 nodes or a buffer we yield or extend/append
-        if len(body) < 3 or frame.buffer is not None:
-            if frame.buffer is not None:
-                # for one item we append, for more we extend
-                if len(body) == 1:
-                    self.writeline('%s.append(' % frame.buffer)
+        if frame.buffer is not None:
+            if len(body) == 1:
+                self.writeline("%s.append(" % frame.buffer)
+            else:
+                self.writeline("%s.extend((" % frame.buffer)
+
+            self.indent()
+
+        for item in body:
+            if isinstance(item, list):
+                # A group of constant data to join and output.
+                val = self._output_const_repr(item)
+
+                if frame.buffer is None:
+                    self.writeline("yield " + val)
                 else:
-                    self.writeline('%s.extend((' % frame.buffer)
-                self.indent()
-            for item in body:
-                if isinstance(item, list):
-                    val = repr(concat(item))
-                    if frame.buffer is None:
-                        self.writeline('yield ' + val)
-                    else:
-                        self.writeline(val + ',')
+                    self.writeline(val + ",")
+            else:
+                if frame.buffer is None:
+                    self.writeline("yield ", item)
                 else:
-                    if frame.buffer is None:
-                        self.writeline('yield ', item)
-                    else:
-                        self.newline(item)
-                    close = 1
-                    if frame.eval_ctx.volatile:
-                        self.write('(escape if context.eval_ctx.autoescape'
-                                   ' else to_string)(')
-                    elif frame.eval_ctx.autoescape:
-                        self.write('escape(')
-                    else:
-                        self.write('to_string(')
-                    if self.environment.finalize is not None:
-                        self.write('environment.finalize(')
-                        if getattr(self.environment.finalize,
-                                   "contextfunction", False):
-                            self.write('context, ')
-                        close += 1
-                    self.visit(item, frame)
-                    self.write(')' * close)
-                    if frame.buffer is not None:
-                        self.write(',')
-            if frame.buffer is not None:
-                # close the open parentheses
-                self.outdent()
-                self.writeline(len(body) == 1 and ')' or '))')
+                    self.newline(item)
 
-        # otherwise we create a format string as this is faster in that case
-        else:
-            format = []
-            arguments = []
-            for item in body:
-                if isinstance(item, list):
-                    format.append(concat(item).replace('%', '%%'))
-                else:
-                    format.append('%s')
-                    arguments.append(item)
-            self.writeline('yield ')
-            self.write(repr(concat(format)) + ' % (')
-            self.indent()
-            for argument in arguments:
-                self.newline(argument)
-                close = 0
-                if frame.eval_ctx.volatile:
-                    self.write('(escape if context.eval_ctx.autoescape else'
-                               ' to_string)(')
-                    close += 1
-                elif frame.eval_ctx.autoescape:
-                    self.write('escape(')
-                    close += 1
-                if self.environment.finalize is not None:
-                    self.write('environment.finalize(')
-                    if getattr(self.environment.finalize,
-                               'contextfunction', False):
-                        self.write('context, ')
-                    elif getattr(self.environment.finalize,
-                               'evalcontextfunction', False):
-                        self.write('context.eval_ctx, ')
-                    elif getattr(self.environment.finalize,
-                               'environmentfunction', False):
-                        self.write('environment, ')
-                    close += 1
-                self.visit(argument, frame)
-                self.write(')' * close + ', ')
+                # A node to be evaluated at runtime.
+                self._output_child_pre(item, frame, finalize)
+                self.visit(item, frame)
+                self._output_child_post(item, frame, finalize)
+
+                if frame.buffer is not None:
+                    self.write(",")
+
+        if frame.buffer is not None:
             self.outdent()
-            self.writeline(')')
+            self.writeline(")" if len(body) == 1 else "))")
 
-        if outdent_later:
+        if frame.require_output_check:
             self.outdent()
 
     def visit_Assign(self, node, frame):
         self.push_assign_tracking()
         self.newline(node)
         self.visit(node.target, frame)
-        self.write(' = ')
+        self.write(" = ")
         self.visit(node.node, frame)
         self.pop_assign_tracking(frame)
 
@@ -1384,20 +1471,19 @@ class CodeGenerator(NodeVisitor):
         self.blockvisit(node.body, block_frame)
         self.newline(node)
         self.visit(node.target, frame)
-        self.write(' = (Markup if context.eval_ctx.autoescape '
-                   'else identity)(')
+        self.write(" = (Markup if context.eval_ctx.autoescape else identity)(")
         if node.filter is not None:
             self.visit_Filter(node.filter, block_frame)
         else:
-            self.write('concat(%s)' % block_frame.buffer)
-        self.write(')')
+            self.write("concat(%s)" % block_frame.buffer)
+        self.write(")")
         self.pop_assign_tracking(frame)
         self.leave_frame(block_frame)
 
     # -- Expression Visitors
 
     def visit_Name(self, node, frame):
-        if node.ctx == 'store' and frame.toplevel:
+        if node.ctx == "store" and frame.toplevel:
             if self._assign_stack:
                 self._assign_stack[-1].add(node.name)
         ref = frame.symbols.ref(node.name)
@@ -1405,12 +1491,17 @@ class CodeGenerator(NodeVisitor):
         # If we are looking up a variable we might have to deal with the
         # case where it's undefined.  We can skip that case if the load
         # instruction indicates a parameter which are always defined.
-        if node.ctx == 'load':
+        if node.ctx == "load":
             load = frame.symbols.find_load(ref)
-            if not (load is not None and load[0] == VAR_LOAD_PARAMETER and \
-                    not self.parameter_is_undeclared(ref)):
-                self.write('(undefined(name=%r) if %s is missing else %s)' %
-                           (node.name, ref, ref))
+            if not (
+                load is not None
+                and load[0] == VAR_LOAD_PARAMETER
+                and not self.parameter_is_undeclared(ref)
+            ):
+                self.write(
+                    "(undefined(name=%r) if %s is missing else %s)"
+                    % (node.name, ref, ref)
+                )
                 return
 
         self.write(ref)
@@ -1420,12 +1511,14 @@ class CodeGenerator(NodeVisitor):
         # `foo.bar` notation they will be parsed as a normal attribute access
         # when used anywhere but in a `set` context
         ref = frame.symbols.ref(node.name)
-        self.writeline('if not isinstance(%s, Namespace):' % ref)
+        self.writeline("if not isinstance(%s, Namespace):" % ref)
         self.indent()
-        self.writeline('raise TemplateRuntimeError(%r)' %
-                       'cannot assign attribute on non-namespace object')
+        self.writeline(
+            "raise TemplateRuntimeError(%r)"
+            % "cannot assign attribute on non-namespace object"
+        )
         self.outdent()
-        self.writeline('%s[%r]' % (ref, node.attr))
+        self.writeline("%s[%r]" % (ref, node.attr))
 
     def visit_Const(self, node, frame):
         val = node.as_const(frame.eval_ctx)
@@ -1438,230 +1531,256 @@ class CodeGenerator(NodeVisitor):
         try:
             self.write(repr(node.as_const(frame.eval_ctx)))
         except nodes.Impossible:
-            self.write('(Markup if context.eval_ctx.autoescape else identity)(%r)'
-                       % node.data)
+            self.write(
+                "(Markup if context.eval_ctx.autoescape else identity)(%r)" % node.data
+            )
 
     def visit_Tuple(self, node, frame):
-        self.write('(')
+        self.write("(")
         idx = -1
         for idx, item in enumerate(node.items):
             if idx:
-                self.write(', ')
+                self.write(", ")
             self.visit(item, frame)
-        self.write(idx == 0 and ',)' or ')')
+        self.write(idx == 0 and ",)" or ")")
 
     def visit_List(self, node, frame):
-        self.write('[')
+        self.write("[")
         for idx, item in enumerate(node.items):
             if idx:
-                self.write(', ')
+                self.write(", ")
             self.visit(item, frame)
-        self.write(']')
+        self.write("]")
 
     def visit_Dict(self, node, frame):
-        self.write('{')
+        self.write("{")
         for idx, item in enumerate(node.items):
             if idx:
-                self.write(', ')
+                self.write(", ")
             self.visit(item.key, frame)
-            self.write(': ')
+            self.write(": ")
             self.visit(item.value, frame)
-        self.write('}')
+        self.write("}")
 
-    def binop(operator, interceptable=True):
+    def binop(operator, interceptable=True):  # noqa: B902
         @optimizeconst
         def visitor(self, node, frame):
-            if self.environment.sandboxed and \
-               operator in self.environment.intercepted_binops:
-                self.write('environment.call_binop(context, %r, ' % operator)
+            if (
+                self.environment.sandboxed
+                and operator in self.environment.intercepted_binops
+            ):
+                self.write("environment.call_binop(context, %r, " % operator)
                 self.visit(node.left, frame)
-                self.write(', ')
+                self.write(", ")
                 self.visit(node.right, frame)
             else:
-                self.write('(')
+                self.write("(")
                 self.visit(node.left, frame)
-                self.write(' %s ' % operator)
+                self.write(" %s " % operator)
                 self.visit(node.right, frame)
-            self.write(')')
+            self.write(")")
+
         return visitor
 
-    def uaop(operator, interceptable=True):
+    def uaop(operator, interceptable=True):  # noqa: B902
         @optimizeconst
         def visitor(self, node, frame):
-            if self.environment.sandboxed and \
-               operator in self.environment.intercepted_unops:
-                self.write('environment.call_unop(context, %r, ' % operator)
+            if (
+                self.environment.sandboxed
+                and operator in self.environment.intercepted_unops
+            ):
+                self.write("environment.call_unop(context, %r, " % operator)
                 self.visit(node.node, frame)
             else:
-                self.write('(' + operator)
+                self.write("(" + operator)
                 self.visit(node.node, frame)
-            self.write(')')
+            self.write(")")
+
         return visitor
 
-    visit_Add = binop('+')
-    visit_Sub = binop('-')
-    visit_Mul = binop('*')
-    visit_Div = binop('/')
-    visit_FloorDiv = binop('//')
-    visit_Pow = binop('**')
-    visit_Mod = binop('%')
-    visit_And = binop('and', interceptable=False)
-    visit_Or = binop('or', interceptable=False)
-    visit_Pos = uaop('+')
-    visit_Neg = uaop('-')
-    visit_Not = uaop('not ', interceptable=False)
+    visit_Add = binop("+")
+    visit_Sub = binop("-")
+    visit_Mul = binop("*")
+    visit_Div = binop("/")
+    visit_FloorDiv = binop("//")
+    visit_Pow = binop("**")
+    visit_Mod = binop("%")
+    visit_And = binop("and", interceptable=False)
+    visit_Or = binop("or", interceptable=False)
+    visit_Pos = uaop("+")
+    visit_Neg = uaop("-")
+    visit_Not = uaop("not ", interceptable=False)
     del binop, uaop
 
     @optimizeconst
     def visit_Concat(self, node, frame):
         if frame.eval_ctx.volatile:
-            func_name = '(context.eval_ctx.volatile and' \
-                        ' markup_join or unicode_join)'
+            func_name = "(context.eval_ctx.volatile and markup_join or unicode_join)"
         elif frame.eval_ctx.autoescape:
-            func_name = 'markup_join'
+            func_name = "markup_join"
         else:
-            func_name = 'unicode_join'
-        self.write('%s((' % func_name)
+            func_name = "unicode_join"
+        self.write("%s((" % func_name)
         for arg in node.nodes:
             self.visit(arg, frame)
-            self.write(', ')
-        self.write('))')
+            self.write(", ")
+        self.write("))")
 
     @optimizeconst
     def visit_Compare(self, node, frame):
+        self.write("(")
         self.visit(node.expr, frame)
         for op in node.ops:
             self.visit(op, frame)
+        self.write(")")
 
     def visit_Operand(self, node, frame):
-        self.write(' %s ' % operators[node.op])
+        self.write(" %s " % operators[node.op])
         self.visit(node.expr, frame)
 
     @optimizeconst
     def visit_Getattr(self, node, frame):
-        self.write('environment.getattr(')
+        if self.environment.is_async:
+            self.write("(await auto_await(")
+
+        self.write("environment.getattr(")
         self.visit(node.node, frame)
-        self.write(', %r)' % node.attr)
+        self.write(", %r)" % node.attr)
+
+        if self.environment.is_async:
+            self.write("))")
 
     @optimizeconst
     def visit_Getitem(self, node, frame):
         # slices bypass the environment getitem method.
         if isinstance(node.arg, nodes.Slice):
             self.visit(node.node, frame)
-            self.write('[')
+            self.write("[")
             self.visit(node.arg, frame)
-            self.write(']')
+            self.write("]")
         else:
-            self.write('environment.getitem(')
+            if self.environment.is_async:
+                self.write("(await auto_await(")
+
+            self.write("environment.getitem(")
             self.visit(node.node, frame)
-            self.write(', ')
+            self.write(", ")
             self.visit(node.arg, frame)
-            self.write(')')
+            self.write(")")
+
+            if self.environment.is_async:
+                self.write("))")
 
     def visit_Slice(self, node, frame):
         if node.start is not None:
             self.visit(node.start, frame)
-        self.write(':')
+        self.write(":")
         if node.stop is not None:
             self.visit(node.stop, frame)
         if node.step is not None:
-            self.write(':')
+            self.write(":")
             self.visit(node.step, frame)
 
     @optimizeconst
     def visit_Filter(self, node, frame):
         if self.environment.is_async:
-            self.write('await auto_await(')
-        self.write(self.filters[node.name] + '(')
+            self.write("await auto_await(")
+        self.write(self.filters[node.name] + "(")
         func = self.environment.filters.get(node.name)
         if func is None:
-            self.fail('no filter named %r' % node.name, node.lineno)
-        if getattr(func, 'contextfilter', False):
-            self.write('context, ')
-        elif getattr(func, 'evalcontextfilter', False):
-            self.write('context.eval_ctx, ')
-        elif getattr(func, 'environmentfilter', False):
-            self.write('environment, ')
+            self.fail("no filter named %r" % node.name, node.lineno)
+        if getattr(func, "contextfilter", False):
+            self.write("context, ")
+        elif getattr(func, "evalcontextfilter", False):
+            self.write("context.eval_ctx, ")
+        elif getattr(func, "environmentfilter", False):
+            self.write("environment, ")
 
         # if the filter node is None we are inside a filter block
         # and want to write to the current buffer
         if node.node is not None:
             self.visit(node.node, frame)
         elif frame.eval_ctx.volatile:
-            self.write('(context.eval_ctx.autoescape and'
-                       ' Markup(concat(%s)) or concat(%s))' %
-                       (frame.buffer, frame.buffer))
+            self.write(
+                "(context.eval_ctx.autoescape and"
+                " Markup(concat(%s)) or concat(%s))" % (frame.buffer, frame.buffer)
+            )
         elif frame.eval_ctx.autoescape:
-            self.write('Markup(concat(%s))' % frame.buffer)
+            self.write("Markup(concat(%s))" % frame.buffer)
         else:
-            self.write('concat(%s)' % frame.buffer)
+            self.write("concat(%s)" % frame.buffer)
         self.signature(node, frame)
-        self.write(')')
+        self.write(")")
         if self.environment.is_async:
-            self.write(')')
+            self.write(")")
 
     @optimizeconst
     def visit_Test(self, node, frame):
-        self.write(self.tests[node.name] + '(')
+        self.write(self.tests[node.name] + "(")
         if node.name not in self.environment.tests:
-            self.fail('no test named %r' % node.name, node.lineno)
+            self.fail("no test named %r" % node.name, node.lineno)
         self.visit(node.node, frame)
         self.signature(node, frame)
-        self.write(')')
+        self.write(")")
 
     @optimizeconst
     def visit_CondExpr(self, node, frame):
         def write_expr2():
             if node.expr2 is not None:
                 return self.visit(node.expr2, frame)
-            self.write('undefined(%r)' % ('the inline if-'
-                       'expression on %s evaluated to false and '
-                       'no else section was defined.' % self.position(node)))
-
-        self.write('(')
+            self.write(
+                "cond_expr_undefined(%r)"
+                % (
+                    "the inline if-"
+                    "expression on %s evaluated to false and "
+                    "no else section was defined." % self.position(node)
+                )
+            )
+
+        self.write("(")
         self.visit(node.expr1, frame)
-        self.write(' if ')
+        self.write(" if ")
         self.visit(node.test, frame)
-        self.write(' else ')
+        self.write(" else ")
         write_expr2()
-        self.write(')')
+        self.write(")")
 
     @optimizeconst
     def visit_Call(self, node, frame, forward_caller=False):
         if self.environment.is_async:
-            self.write('await auto_await(')
+            self.write("await auto_await(")
         if self.environment.sandboxed:
-            self.write('environment.call(context, ')
+            self.write("environment.call(context, ")
         else:
-            self.write('context.call(')
+            self.write("context.call(")
         self.visit(node.node, frame)
-        extra_kwargs = forward_caller and {'caller': 'caller'} or None
+        extra_kwargs = forward_caller and {"caller": "caller"} or None
         self.signature(node, frame, extra_kwargs)
-        self.write(')')
+        self.write(")")
         if self.environment.is_async:
-            self.write(')')
+            self.write(")")
 
     def visit_Keyword(self, node, frame):
-        self.write(node.key + '=')
+        self.write(node.key + "=")
         self.visit(node.value, frame)
 
     # -- Unused nodes for extensions
 
     def visit_MarkSafe(self, node, frame):
-        self.write('Markup(')
+        self.write("Markup(")
         self.visit(node.expr, frame)
-        self.write(')')
+        self.write(")")
 
     def visit_MarkSafeIfAutoescape(self, node, frame):
-        self.write('(context.eval_ctx.autoescape and Markup or identity)(')
+        self.write("(context.eval_ctx.autoescape and Markup or identity)(")
         self.visit(node.expr, frame)
-        self.write(')')
+        self.write(")")
 
     def visit_EnvironmentAttribute(self, node, frame):
-        self.write('environment.' + node.name)
+        self.write("environment." + node.name)
 
     def visit_ExtensionAttribute(self, node, frame):
-        self.write('environment.extensions[%r].%s' % (node.identifier, node.name))
+        self.write("environment.extensions[%r].%s" % (node.identifier, node.name))
 
     def visit_ImportedName(self, node, frame):
         self.write(self.import_aliases[node.importname])
@@ -1670,13 +1789,16 @@ class CodeGenerator(NodeVisitor):
         self.write(node.name)
 
     def visit_ContextReference(self, node, frame):
-        self.write('context')
+        self.write("context")
+
+    def visit_DerivedContextReference(self, node, frame):
+        self.write(self.derive_context(frame))
 
     def visit_Continue(self, node, frame):
-        self.writeline('continue', node)
+        self.writeline("continue", node)
 
     def visit_Break(self, node, frame):
-        self.writeline('break', node)
+        self.writeline("break", node)
 
     def visit_Scope(self, node, frame):
         scope_frame = frame.inner()
@@ -1687,8 +1809,8 @@ class CodeGenerator(NodeVisitor):
 
     def visit_OverlayScope(self, node, frame):
         ctx = self.temporary_identifier()
-        self.writeline('%s = %s' % (ctx, self.derive_context(frame)))
-        self.writeline('%s.vars = ' % ctx)
+        self.writeline("%s = %s" % (ctx, self.derive_context(frame)))
+        self.writeline("%s.vars = " % ctx)
         self.visit(node.context, frame)
         self.push_context_reference(ctx)
 
@@ -1701,7 +1823,7 @@ class CodeGenerator(NodeVisitor):
 
     def visit_EvalContextModifier(self, node, frame):
         for keyword in node.options:
-            self.writeline('context.eval_ctx.%s = ' % keyword.key)
+            self.writeline("context.eval_ctx.%s = " % keyword.key)
             self.visit(keyword.value, frame)
             try:
                 val = keyword.value.as_const(frame.eval_ctx)
@@ -1713,9 +1835,9 @@ class CodeGenerator(NodeVisitor):
     def visit_ScopedEvalContextModifier(self, node, frame):
         old_ctx_name = self.temporary_identifier()
         saved_ctx = frame.eval_ctx.save()
-        self.writeline('%s = context.eval_ctx.save()' % old_ctx_name)
+        self.writeline("%s = context.eval_ctx.save()" % old_ctx_name)
         self.visit_EvalContextModifier(node, frame)
         for child in node.body:
             self.visit(child, frame)
         frame.eval_ctx.revert(saved_ctx)
-        self.writeline('context.eval_ctx.revert(%s)' % old_ctx_name)
+        self.writeline("context.eval_ctx.revert(%s)" % old_ctx_name)
diff --git a/pipenv/vendor/jinja2/constants.py b/pipenv/vendor/jinja2/constants.py
index 11efd1ed..bf7f2ca7 100644
--- a/pipenv/vendor/jinja2/constants.py
+++ b/pipenv/vendor/jinja2/constants.py
@@ -1,17 +1,6 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja.constants
-    ~~~~~~~~~~~~~~~
-
-    Various constants.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
-
-
 #: list of lorem ipsum words used by the lipsum() helper function
-LOREM_IPSUM_WORDS = u'''\
+LOREM_IPSUM_WORDS = u"""\
 a ac accumsan ad adipiscing aenean aliquam aliquet amet ante aptent arcu at
 auctor augue bibendum blandit class commodo condimentum congue consectetuer
 consequat conubia convallis cras cubilia cum curabitur curae cursus dapibus
@@ -29,4 +18,4 @@ ridiculus risus rutrum sagittis sapien scelerisque sed sem semper senectus sit
 sociis sociosqu sodales sollicitudin suscipit suspendisse taciti tellus tempor
 tempus tincidunt torquent tortor tristique turpis ullamcorper ultrices
 ultricies urna ut varius vehicula vel velit venenatis vestibulum vitae vivamus
-viverra volutpat vulputate'''
+viverra volutpat vulputate"""
diff --git a/pipenv/vendor/jinja2/debug.py b/pipenv/vendor/jinja2/debug.py
index d3c1a3a8..d2c5a06b 100644
--- a/pipenv/vendor/jinja2/debug.py
+++ b/pipenv/vendor/jinja2/debug.py
@@ -1,378 +1,271 @@
-# -*- coding: utf-8 -*-
-"""
-    jinja2.debug
-    ~~~~~~~~~~~~
-
-    Implements the debug interface for Jinja.  This module does some pretty
-    ugly stuff with the Python traceback system in order to achieve tracebacks
-    with correct line numbers, locals and contents.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
 import sys
-import traceback
-from types import TracebackType, CodeType
-from jinja2.utils import missing, internal_code
-from jinja2.exceptions import TemplateSyntaxError
-from jinja2._compat import iteritems, reraise, PY2
+from types import CodeType
 
-# on pypy we can take advantage of transparent proxies
-try:
-    from __pypy__ import tproxy
-except ImportError:
-    tproxy = None
+from . import TemplateSyntaxError
+from ._compat import PYPY
+from .utils import internal_code
+from .utils import missing
 
 
-# how does the raise helper look like?
-try:
-    exec("raise TypeError, 'foo'")
-except SyntaxError:
-    raise_helper = 'raise __jinja_exception__[1]'
-except TypeError:
-    raise_helper = 'raise __jinja_exception__[0], __jinja_exception__[1]'
+def rewrite_traceback_stack(source=None):
+    """Rewrite the current exception to replace any tracebacks from
+    within compiled template code with tracebacks that look like they
+    came from the template source.
 
+    This must be called within an ``except`` block.
 
-class TracebackFrameProxy(object):
-    """Proxies a traceback frame."""
+    :param exc_info: A :meth:`sys.exc_info` tuple. If not provided,
+        the current ``exc_info`` is used.
+    :param source: For ``TemplateSyntaxError``, the original source if
+        known.
+    :return: A :meth:`sys.exc_info` tuple that can be re-raised.
+    """
+    exc_type, exc_value, tb = sys.exc_info()
 
-    def __init__(self, tb):
-        self.tb = tb
-        self._tb_next = None
+    if isinstance(exc_value, TemplateSyntaxError) and not exc_value.translated:
+        exc_value.translated = True
+        exc_value.source = source
 
-    @property
-    def tb_next(self):
-        return self._tb_next
+        try:
+            # Remove the old traceback on Python 3, otherwise the frames
+            # from the compiler still show up.
+            exc_value.with_traceback(None)
+        except AttributeError:
+            pass
 
-    def set_next(self, next):
-        if tb_set_next is not None:
-            try:
-                tb_set_next(self.tb, next and next.tb or None)
-            except Exception:
-                # this function can fail due to all the hackery it does
-                # on various python implementations.  We just catch errors
-                # down and ignore them if necessary.
-                pass
-        self._tb_next = next
-
-    @property
-    def is_jinja_frame(self):
-        return '__jinja_template__' in self.tb.tb_frame.f_globals
-
-    def __getattr__(self, name):
-        return getattr(self.tb, name)
-
-
-def make_frame_proxy(frame):
-    proxy = TracebackFrameProxy(frame)
-    if tproxy is None:
-        return proxy
-    def operation_handler(operation, *args, **kwargs):
-        if operation in ('__getattribute__', '__getattr__'):
-            return getattr(proxy, args[0])
-        elif operation == '__setattr__':
-            proxy.__setattr__(*args, **kwargs)
-        else:
-            return getattr(proxy, operation)(*args, **kwargs)
-    return tproxy(TracebackType, operation_handler)
-
-
-class ProcessedTraceback(object):
-    """Holds a Jinja preprocessed traceback for printing or reraising."""
-
-    def __init__(self, exc_type, exc_value, frames):
-        assert frames, 'no frames for this traceback?'
-        self.exc_type = exc_type
-        self.exc_value = exc_value
-        self.frames = frames
-
-        # newly concatenate the frames (which are proxies)
-        prev_tb = None
-        for tb in self.frames:
-            if prev_tb is not None:
-                prev_tb.set_next(tb)
-            prev_tb = tb
-        prev_tb.set_next(None)
-
-    def render_as_text(self, limit=None):
-        """Return a string with the traceback."""
-        lines = traceback.format_exception(self.exc_type, self.exc_value,
-                                           self.frames[0], limit=limit)
-        return ''.join(lines).rstrip()
-
-    def render_as_html(self, full=False):
-        """Return a unicode string with the traceback as rendered HTML."""
-        from jinja2.debugrenderer import render_traceback
-        return u'%s\n\n<!--\n%s\n-->' % (
-            render_traceback(self, full=full),
-            self.render_as_text().decode('utf-8', 'replace')
+        # Outside of runtime, so the frame isn't executing template
+        # code, but it still needs to point at the template.
+        tb = fake_traceback(
+            exc_value, None, exc_value.filename or "<unknown>", exc_value.lineno
         )
-
-    @property
-    def is_template_syntax_error(self):
-        """`True` if this is a template syntax error."""
-        return isinstance(self.exc_value, TemplateSyntaxError)
-
-    @property
-    def exc_info(self):
-        """Exception info tuple with a proxy around the frame objects."""
-        return self.exc_type, self.exc_value, self.frames[0]
-
-    @property
-    def standard_exc_info(self):
-        """Standard python exc_info for re-raising"""
-        tb = self.frames[0]
-        # the frame will be an actual traceback (or transparent proxy) if
-        # we are on pypy or a python implementation with support for tproxy
-        if type(tb) is not TracebackType:
-            tb = tb.tb
-        return self.exc_type, self.exc_value, tb
-
-
-def make_traceback(exc_info, source_hint=None):
-    """Creates a processed traceback object from the exc_info."""
-    exc_type, exc_value, tb = exc_info
-    if isinstance(exc_value, TemplateSyntaxError):
-        exc_info = translate_syntax_error(exc_value, source_hint)
-        initial_skip = 0
     else:
-        initial_skip = 1
-    return translate_exception(exc_info, initial_skip)
-
-
-def translate_syntax_error(error, source=None):
-    """Rewrites a syntax error to please traceback systems."""
-    error.source = source
-    error.translated = True
-    exc_info = (error.__class__, error, None)
-    filename = error.filename
-    if filename is None:
-        filename = '<unknown>'
-    return fake_exc_info(exc_info, filename, error.lineno)
+        # Skip the frame for the render function.
+        tb = tb.tb_next
 
+    stack = []
 
-def translate_exception(exc_info, initial_skip=0):
-    """If passed an exc_info it will automatically rewrite the exceptions
-    all the way down to the correct line numbers and frames.
-    """
-    tb = exc_info[2]
-    frames = []
-
-    # skip some internal frames if wanted
-    for x in range(initial_skip):
-        if tb is not None:
-            tb = tb.tb_next
-    initial_tb = tb
-
+    # Build the stack of traceback object, replacing any in template
+    # code with the source file and line information.
     while tb is not None:
-        # skip frames decorated with @internalcode.  These are internal
-        # calls we can't avoid and that are useless in template debugging
-        # output.
+        # Skip frames decorated with @internalcode. These are internal
+        # calls that aren't useful in template debugging output.
         if tb.tb_frame.f_code in internal_code:
             tb = tb.tb_next
             continue
 
-        # save a reference to the next frame if we override the current
-        # one with a faked one.
-        next = tb.tb_next
+        template = tb.tb_frame.f_globals.get("__jinja_template__")
 
-        # fake template exceptions
-        template = tb.tb_frame.f_globals.get('__jinja_template__')
         if template is not None:
             lineno = template.get_corresponding_lineno(tb.tb_lineno)
-            tb = fake_exc_info(exc_info[:2] + (tb,), template.filename,
-                               lineno)[2]
+            fake_tb = fake_traceback(exc_value, tb, template.filename, lineno)
+            stack.append(fake_tb)
+        else:
+            stack.append(tb)
 
-        frames.append(make_frame_proxy(tb))
-        tb = next
+        tb = tb.tb_next
 
-    # if we don't have any exceptions in the frames left, we have to
-    # reraise it unchanged.
-    # XXX: can we backup here?  when could this happen?
-    if not frames:
-        reraise(exc_info[0], exc_info[1], exc_info[2])
+    tb_next = None
 
-    return ProcessedTraceback(exc_info[0], exc_info[1], frames)
+    # Assign tb_next in reverse to avoid circular references.
+    for tb in reversed(stack):
+        tb_next = tb_set_next(tb, tb_next)
 
+    return exc_type, exc_value, tb_next
 
-def get_jinja_locals(real_locals):
-    ctx = real_locals.get('context')
-    if ctx:
-        locals = ctx.get_all().copy()
+
+def fake_traceback(exc_value, tb, filename, lineno):
+    """Produce a new traceback object that looks like it came from the
+    template source instead of the compiled code. The filename, line
+    number, and location name will point to the template, and the local
+    variables will be the current template context.
+
+    :param exc_value: The original exception to be re-raised to create
+        the new traceback.
+    :param tb: The original traceback to get the local variables and
+        code info from.
+    :param filename: The template filename.
+    :param lineno: The line number in the template source.
+    """
+    if tb is not None:
+        # Replace the real locals with the context that would be
+        # available at that point in the template.
+        locals = get_template_locals(tb.tb_frame.f_locals)
+        locals.pop("__jinja_exception__", None)
     else:
         locals = {}
 
+    globals = {
+        "__name__": filename,
+        "__file__": filename,
+        "__jinja_exception__": exc_value,
+    }
+    # Raise an exception at the correct line number.
+    code = compile("\n" * (lineno - 1) + "raise __jinja_exception__", filename, "exec")
+
+    # Build a new code object that points to the template file and
+    # replaces the location with a block name.
+    try:
+        location = "template"
+
+        if tb is not None:
+            function = tb.tb_frame.f_code.co_name
+
+            if function == "root":
+                location = "top-level template code"
+            elif function.startswith("block_"):
+                location = 'block "%s"' % function[6:]
+
+        # Collect arguments for the new code object. CodeType only
+        # accepts positional arguments, and arguments were inserted in
+        # new Python versions.
+        code_args = []
+
+        for attr in (
+            "argcount",
+            "posonlyargcount",  # Python 3.8
+            "kwonlyargcount",  # Python 3
+            "nlocals",
+            "stacksize",
+            "flags",
+            "code",  # codestring
+            "consts",  # constants
+            "names",
+            "varnames",
+            ("filename", filename),
+            ("name", location),
+            "firstlineno",
+            "lnotab",
+            "freevars",
+            "cellvars",
+        ):
+            if isinstance(attr, tuple):
+                # Replace with given value.
+                code_args.append(attr[1])
+                continue
+
+            try:
+                # Copy original value if it exists.
+                code_args.append(getattr(code, "co_" + attr))
+            except AttributeError:
+                # Some arguments were added later.
+                continue
+
+        code = CodeType(*code_args)
+    except Exception:
+        # Some environments such as Google App Engine don't support
+        # modifying code objects.
+        pass
+
+    # Execute the new code, which is guaranteed to raise, and return
+    # the new traceback without this frame.
+    try:
+        exec(code, globals, locals)
+    except BaseException:
+        return sys.exc_info()[2].tb_next
+
+
+def get_template_locals(real_locals):
+    """Based on the runtime locals, get the context that would be
+    available at that point in the template.
+    """
+    # Start with the current template context.
+    ctx = real_locals.get("context")
+
+    if ctx:
+        data = ctx.get_all().copy()
+    else:
+        data = {}
+
+    # Might be in a derived context that only sets local variables
+    # rather than pushing a context. Local variables follow the scheme
+    # l_depth_name. Find the highest-depth local that has a value for
+    # each name.
     local_overrides = {}
 
-    for name, value in iteritems(real_locals):
-        if not name.startswith('l_') or value is missing:
+    for name, value in real_locals.items():
+        if not name.startswith("l_") or value is missing:
+            # Not a template variable, or no longer relevant.
             continue
+
         try:
-            _, depth, name = name.split('_', 2)
+            _, depth, name = name.split("_", 2)
             depth = int(depth)
         except ValueError:
             continue
+
         cur_depth = local_overrides.get(name, (-1,))[0]
+
         if cur_depth < depth:
             local_overrides[name] = (depth, value)
 
-    for name, (_, value) in iteritems(local_overrides):
+    # Modify the context with any derived context.
+    for name, (_, value) in local_overrides.items():
         if value is missing:
-            locals.pop(name, None)
+            data.pop(name, None)
         else:
-            locals[name] = value
+            data[name] = value
 
-    return locals
+    return data
 
 
-def fake_exc_info(exc_info, filename, lineno):
-    """Helper for `translate_exception`."""
-    exc_type, exc_value, tb = exc_info
+if sys.version_info >= (3, 7):
+    # tb_next is directly assignable as of Python 3.7
+    def tb_set_next(tb, tb_next):
+        tb.tb_next = tb_next
+        return tb
 
-    # figure the real context out
-    if tb is not None:
-        locals = get_jinja_locals(tb.tb_frame.f_locals)
 
-        # if there is a local called __jinja_exception__, we get
-        # rid of it to not break the debug functionality.
-        locals.pop('__jinja_exception__', None)
-    else:
-        locals = {}
-
-    # assamble fake globals we need
-    globals = {
-        '__name__':             filename,
-        '__file__':             filename,
-        '__jinja_exception__':  exc_info[:2],
-
-        # we don't want to keep the reference to the template around
-        # to not cause circular dependencies, but we mark it as Jinja
-        # frame for the ProcessedTraceback
-        '__jinja_template__':   None
-    }
-
-    # and fake the exception
-    code = compile('\n' * (lineno - 1) + raise_helper, filename, 'exec')
-
-    # if it's possible, change the name of the code.  This won't work
-    # on some python environments such as google appengine
+elif PYPY:
+    # PyPy might have special support, and won't work with ctypes.
     try:
-        if tb is None:
-            location = 'template'
-        else:
-            function = tb.tb_frame.f_code.co_name
-            if function == 'root':
-                location = 'top-level template code'
-            elif function.startswith('block_'):
-                location = 'block "%s"' % function[6:]
-            else:
-                location = 'template'
-
-        if PY2:
-            code = CodeType(0, code.co_nlocals, code.co_stacksize,
-                            code.co_flags, code.co_code, code.co_consts,
-                            code.co_names, code.co_varnames, filename,
-                            location, code.co_firstlineno,
-                            code.co_lnotab, (), ())
-        else:
-            code = CodeType(0, code.co_kwonlyargcount,
-                            code.co_nlocals, code.co_stacksize,
-                            code.co_flags, code.co_code, code.co_consts,
-                            code.co_names, code.co_varnames, filename,
-                            location, code.co_firstlineno,
-                            code.co_lnotab, (), ())
-    except Exception as e:
-        pass
+        import tputil
+    except ImportError:
+        # Without tproxy support, use the original traceback.
+        def tb_set_next(tb, tb_next):
+            return tb
 
-    # execute the code and catch the new traceback
-    try:
-        exec(code, globals, locals)
-    except:
-        exc_info = sys.exc_info()
-        new_tb = exc_info[2].tb_next
+    else:
+        # With tproxy support, create a proxy around the traceback that
+        # returns the new tb_next.
+        def tb_set_next(tb, tb_next):
+            def controller(op):
+                if op.opname == "__getattribute__" and op.args[0] == "tb_next":
+                    return tb_next
 
-    # return without this frame
-    return exc_info[:2] + (new_tb,)
+                return op.delegate()
 
+            return tputil.make_proxy(controller, obj=tb)
 
-def _init_ugly_crap():
-    """This function implements a few ugly things so that we can patch the
-    traceback objects.  The function returned allows resetting `tb_next` on
-    any python traceback object.  Do not attempt to use this on non cpython
-    interpreters
-    """
-    import ctypes
-    from types import TracebackType
 
-    if PY2:
-        # figure out size of _Py_ssize_t for Python 2:
-        if hasattr(ctypes.pythonapi, 'Py_InitModule4_64'):
-            _Py_ssize_t = ctypes.c_int64
-        else:
-            _Py_ssize_t = ctypes.c_int
-    else:
-        # platform ssize_t on Python 3
-        _Py_ssize_t = ctypes.c_ssize_t
+else:
+    # Use ctypes to assign tb_next at the C level since it's read-only
+    # from Python.
+    import ctypes
 
-    # regular python
-    class _PyObject(ctypes.Structure):
-        pass
-    _PyObject._fields_ = [
-        ('ob_refcnt', _Py_ssize_t),
-        ('ob_type', ctypes.POINTER(_PyObject))
-    ]
-
-    # python with trace
-    if hasattr(sys, 'getobjects'):
-        class _PyObject(ctypes.Structure):
-            pass
-        _PyObject._fields_ = [
-            ('_ob_next', ctypes.POINTER(_PyObject)),
-            ('_ob_prev', ctypes.POINTER(_PyObject)),
-            ('ob_refcnt', _Py_ssize_t),
-            ('ob_type', ctypes.POINTER(_PyObject))
+    class _CTraceback(ctypes.Structure):
+        _fields_ = [
+            # Extra PyObject slots when compiled with Py_TRACE_REFS.
+            (
+                "PyObject_HEAD",
+                ctypes.c_byte * (32 if hasattr(sys, "getobjects") else 16),
+            ),
+            # Only care about tb_next as an object, not a traceback.
+            ("tb_next", ctypes.py_object),
         ]
 
-    class _Traceback(_PyObject):
-        pass
-    _Traceback._fields_ = [
-        ('tb_next', ctypes.POINTER(_Traceback)),
-        ('tb_frame', ctypes.POINTER(_PyObject)),
-        ('tb_lasti', ctypes.c_int),
-        ('tb_lineno', ctypes.c_int)
-    ]
-
-    def tb_set_next(tb, next):
-        """Set the tb_next attribute of a traceback object."""
-        if not (isinstance(tb, TracebackType) and
-                (next is None or isinstance(next, TracebackType))):
-            raise TypeError('tb_set_next arguments must be traceback objects')
-        obj = _Traceback.from_address(id(tb))
-        if tb.tb_next is not None:
-            old = _Traceback.from_address(id(tb.tb_next))
-            old.ob_refcnt -= 1
-        if next is None:
-            obj.tb_next = ctypes.POINTER(_Traceback)()
-        else:
-            next = _Traceback.from_address(id(next))
-            next.ob_refcnt += 1
-            obj.tb_next = ctypes.pointer(next)
+    def tb_set_next(tb, tb_next):
+        c_tb = _CTraceback.from_address(id(tb))
 
-    return tb_set_next
+        # Clear out the old tb_next.
+        if tb.tb_next is not None:
+            c_tb_next = ctypes.py_object(tb.tb_next)
+            c_tb.tb_next = ctypes.py_object()
+            ctypes.pythonapi.Py_DecRef(c_tb_next)
 
+        # Assign the new tb_next.
+        if tb_next is not None:
+            c_tb_next = ctypes.py_object(tb_next)
+            ctypes.pythonapi.Py_IncRef(c_tb_next)
+            c_tb.tb_next = c_tb_next
 
-# try to get a tb_set_next implementation if we don't have transparent
-# proxies.
-tb_set_next = None
-if tproxy is None:
-    # traceback.tb_next can be modified since CPython 3.7
-    if sys.version_info >= (3, 7):
-        def tb_set_next(tb, next):
-            tb.tb_next = next
-    else:
-        # On Python 3.6 and older, use ctypes
-        try:
-            tb_set_next = _init_ugly_crap()
-        except Exception:
-            pass
-del _init_ugly_crap
+        return tb
diff --git a/pipenv/vendor/jinja2/defaults.py b/pipenv/vendor/jinja2/defaults.py
index 7c93dec0..8e0e7d77 100644
--- a/pipenv/vendor/jinja2/defaults.py
+++ b/pipenv/vendor/jinja2/defaults.py
@@ -1,56 +1,44 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.defaults
-    ~~~~~~~~~~~~~~~
-
-    Jinja default filters and tags.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
-from jinja2._compat import range_type
-from jinja2.utils import generate_lorem_ipsum, Cycler, Joiner, Namespace
-
+from ._compat import range_type
+from .filters import FILTERS as DEFAULT_FILTERS  # noqa: F401
+from .tests import TESTS as DEFAULT_TESTS  # noqa: F401
+from .utils import Cycler
+from .utils import generate_lorem_ipsum
+from .utils import Joiner
+from .utils import Namespace
 
 # defaults for the parser / lexer
-BLOCK_START_STRING = '{%'
-BLOCK_END_STRING = '%}'
-VARIABLE_START_STRING = '{{'
-VARIABLE_END_STRING = '}}'
-COMMENT_START_STRING = '{#'
-COMMENT_END_STRING = '#}'
+BLOCK_START_STRING = "{%"
+BLOCK_END_STRING = "%}"
+VARIABLE_START_STRING = "{{"
+VARIABLE_END_STRING = "}}"
+COMMENT_START_STRING = "{#"
+COMMENT_END_STRING = "#}"
 LINE_STATEMENT_PREFIX = None
 LINE_COMMENT_PREFIX = None
 TRIM_BLOCKS = False
 LSTRIP_BLOCKS = False
-NEWLINE_SEQUENCE = '\n'
+NEWLINE_SEQUENCE = "\n"
 KEEP_TRAILING_NEWLINE = False
 
-
 # default filters, tests and namespace
-from jinja2.filters import FILTERS as DEFAULT_FILTERS
-from jinja2.tests import TESTS as DEFAULT_TESTS
+
 DEFAULT_NAMESPACE = {
-    'range':        range_type,
-    'dict':         dict,
-    'lipsum':       generate_lorem_ipsum,
-    'cycler':       Cycler,
-    'joiner':       Joiner,
-    'namespace':    Namespace
+    "range": range_type,
+    "dict": dict,
+    "lipsum": generate_lorem_ipsum,
+    "cycler": Cycler,
+    "joiner": Joiner,
+    "namespace": Namespace,
 }
 
-
 # default policies
 DEFAULT_POLICIES = {
-    'compiler.ascii_str':   True,
-    'urlize.rel':           'noopener',
-    'urlize.target':        None,
-    'truncate.leeway':      5,
-    'json.dumps_function':  None,
-    'json.dumps_kwargs':    {'sort_keys': True},
-    'ext.i18n.trimmed':     False,
+    "compiler.ascii_str": True,
+    "urlize.rel": "noopener",
+    "urlize.target": None,
+    "truncate.leeway": 5,
+    "json.dumps_function": None,
+    "json.dumps_kwargs": {"sort_keys": True},
+    "ext.i18n.trimmed": False,
 }
-
-
-# export all constants
-__all__ = tuple(x for x in locals().keys() if x.isupper())
diff --git a/pipenv/vendor/jinja2/environment.py b/pipenv/vendor/jinja2/environment.py
index 549d9afa..bf44b9de 100644
--- a/pipenv/vendor/jinja2/environment.py
+++ b/pipenv/vendor/jinja2/environment.py
@@ -1,60 +1,83 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.environment
-    ~~~~~~~~~~~~~~~~~~
-
-    Provides a class that holds runtime and parsing time options.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
+"""Classes for managing templates and their runtime and compile time
+options.
 """
 import os
 import sys
 import weakref
-from functools import reduce, partial
-from jinja2 import nodes
-from jinja2.defaults import BLOCK_START_STRING, \
-     BLOCK_END_STRING, VARIABLE_START_STRING, VARIABLE_END_STRING, \
-     COMMENT_START_STRING, COMMENT_END_STRING, LINE_STATEMENT_PREFIX, \
-     LINE_COMMENT_PREFIX, TRIM_BLOCKS, NEWLINE_SEQUENCE, \
-     DEFAULT_FILTERS, DEFAULT_TESTS, DEFAULT_NAMESPACE, \
-     DEFAULT_POLICIES, KEEP_TRAILING_NEWLINE, LSTRIP_BLOCKS
-from jinja2.lexer import get_lexer, TokenStream
-from jinja2.parser import Parser
-from jinja2.nodes import EvalContext
-from jinja2.compiler import generate, CodeGenerator
-from jinja2.runtime import Undefined, new_context, Context
-from jinja2.exceptions import TemplateSyntaxError, TemplateNotFound, \
-     TemplatesNotFound, TemplateRuntimeError
-from jinja2.utils import import_string, LRUCache, Markup, missing, \
-     concat, consume, internalcode, have_async_gen
-from jinja2._compat import imap, ifilter, string_types, iteritems, \
-     text_type, reraise, implements_iterator, implements_to_string, \
-     encode_filename, PY2, PYPY
-
+from functools import partial
+from functools import reduce
+
+from markupsafe import Markup
+
+from . import nodes
+from ._compat import encode_filename
+from ._compat import implements_iterator
+from ._compat import implements_to_string
+from ._compat import iteritems
+from ._compat import PY2
+from ._compat import PYPY
+from ._compat import reraise
+from ._compat import string_types
+from ._compat import text_type
+from .compiler import CodeGenerator
+from .compiler import generate
+from .defaults import BLOCK_END_STRING
+from .defaults import BLOCK_START_STRING
+from .defaults import COMMENT_END_STRING
+from .defaults import COMMENT_START_STRING
+from .defaults import DEFAULT_FILTERS
+from .defaults import DEFAULT_NAMESPACE
+from .defaults import DEFAULT_POLICIES
+from .defaults import DEFAULT_TESTS
+from .defaults import KEEP_TRAILING_NEWLINE
+from .defaults import LINE_COMMENT_PREFIX
+from .defaults import LINE_STATEMENT_PREFIX
+from .defaults import LSTRIP_BLOCKS
+from .defaults import NEWLINE_SEQUENCE
+from .defaults import TRIM_BLOCKS
+from .defaults import VARIABLE_END_STRING
+from .defaults import VARIABLE_START_STRING
+from .exceptions import TemplateNotFound
+from .exceptions import TemplateRuntimeError
+from .exceptions import TemplatesNotFound
+from .exceptions import TemplateSyntaxError
+from .exceptions import UndefinedError
+from .lexer import get_lexer
+from .lexer import TokenStream
+from .nodes import EvalContext
+from .parser import Parser
+from .runtime import Context
+from .runtime import new_context
+from .runtime import Undefined
+from .utils import concat
+from .utils import consume
+from .utils import have_async_gen
+from .utils import import_string
+from .utils import internalcode
+from .utils import LRUCache
+from .utils import missing
 
 # for direct template usage we have up to ten living environments
 _spontaneous_environments = LRUCache(10)
 
-# the function to create jinja traceback objects.  This is dynamically
-# imported on the first exception in the exception handler.
-_make_traceback = None
 
+def get_spontaneous_environment(cls, *args):
+    """Return a new spontaneous environment. A spontaneous environment
+    is used for templates created directly rather than through an
+    existing environment.
 
-def get_spontaneous_environment(*args):
-    """Return a new spontaneous environment.  A spontaneous environment is an
-    unnamed and unaccessible (in theory) environment that is used for
-    templates generated from a string and not from the file system.
+    :param cls: Environment class to create.
+    :param args: Positional arguments passed to environment.
     """
+    key = (cls, args)
+
     try:
-        env = _spontaneous_environments.get(args)
-    except TypeError:
-        return Environment(*args)
-    if env is not None:
+        return _spontaneous_environments[key]
+    except KeyError:
+        _spontaneous_environments[key] = env = cls(*args)
+        env.shared = True
         return env
-    _spontaneous_environments[args] = env = Environment(*args)
-    env.shared = True
-    return env
 
 
 def create_cache(size):
@@ -93,20 +116,25 @@ def fail_for_missing_callable(string, name):
         try:
             name._fail_with_undefined_error()
         except Exception as e:
-            msg = '%s (%s; did you forget to quote the callable name?)' % (msg, e)
+            msg = "%s (%s; did you forget to quote the callable name?)" % (msg, e)
     raise TemplateRuntimeError(msg)
 
 
 def _environment_sanity_check(environment):
     """Perform a sanity check on the environment."""
-    assert issubclass(environment.undefined, Undefined), 'undefined must ' \
-        'be a subclass of undefined because filters depend on it.'
-    assert environment.block_start_string != \
-        environment.variable_start_string != \
-        environment.comment_start_string, 'block, variable and comment ' \
-        'start strings must be different'
-    assert environment.newline_sequence in ('\r', '\r\n', '\n'), \
-        'newline_sequence set to unknown line ending string.'
+    assert issubclass(
+        environment.undefined, Undefined
+    ), "undefined must be a subclass of undefined because filters depend on it."
+    assert (
+        environment.block_start_string
+        != environment.variable_start_string
+        != environment.comment_start_string
+    ), "block, variable and comment start strings must be different"
+    assert environment.newline_sequence in (
+        "\r",
+        "\r\n",
+        "\n",
+    ), "newline_sequence set to unknown line ending string."
     return environment
 
 
@@ -191,7 +219,7 @@ class Environment(object):
         `autoescape`
             If set to ``True`` the XML/HTML autoescaping feature is enabled by
             default.  For more details about autoescaping see
-            :class:`~jinja2.utils.Markup`.  As of Jinja 2.4 this can also
+            :class:`~markupsafe.Markup`.  As of Jinja 2.4 this can also
             be a callable that is passed the template name and has to
             return ``True`` or ``False`` depending on autoescape should be
             enabled by default.
@@ -249,10 +277,6 @@ class Environment(object):
     #: must not be modified
     shared = False
 
-    #: these are currently EXPERIMENTAL undocumented features.
-    exception_handler = None
-    exception_formatter = None
-
     #: the class that is used for code generation.  See
     #: :class:`~jinja2.compiler.CodeGenerator` for more information.
     code_generator_class = CodeGenerator
@@ -261,29 +285,31 @@ class Environment(object):
     #: :class:`~jinja2.runtime.Context` for more information.
     context_class = Context
 
-    def __init__(self,
-                 block_start_string=BLOCK_START_STRING,
-                 block_end_string=BLOCK_END_STRING,
-                 variable_start_string=VARIABLE_START_STRING,
-                 variable_end_string=VARIABLE_END_STRING,
-                 comment_start_string=COMMENT_START_STRING,
-                 comment_end_string=COMMENT_END_STRING,
-                 line_statement_prefix=LINE_STATEMENT_PREFIX,
-                 line_comment_prefix=LINE_COMMENT_PREFIX,
-                 trim_blocks=TRIM_BLOCKS,
-                 lstrip_blocks=LSTRIP_BLOCKS,
-                 newline_sequence=NEWLINE_SEQUENCE,
-                 keep_trailing_newline=KEEP_TRAILING_NEWLINE,
-                 extensions=(),
-                 optimized=True,
-                 undefined=Undefined,
-                 finalize=None,
-                 autoescape=False,
-                 loader=None,
-                 cache_size=400,
-                 auto_reload=True,
-                 bytecode_cache=None,
-                 enable_async=False):
+    def __init__(
+        self,
+        block_start_string=BLOCK_START_STRING,
+        block_end_string=BLOCK_END_STRING,
+        variable_start_string=VARIABLE_START_STRING,
+        variable_end_string=VARIABLE_END_STRING,
+        comment_start_string=COMMENT_START_STRING,
+        comment_end_string=COMMENT_END_STRING,
+        line_statement_prefix=LINE_STATEMENT_PREFIX,
+        line_comment_prefix=LINE_COMMENT_PREFIX,
+        trim_blocks=TRIM_BLOCKS,
+        lstrip_blocks=LSTRIP_BLOCKS,
+        newline_sequence=NEWLINE_SEQUENCE,
+        keep_trailing_newline=KEEP_TRAILING_NEWLINE,
+        extensions=(),
+        optimized=True,
+        undefined=Undefined,
+        finalize=None,
+        autoescape=False,
+        loader=None,
+        cache_size=400,
+        auto_reload=True,
+        bytecode_cache=None,
+        enable_async=False,
+    ):
         # !!Important notice!!
         #   The constructor accepts quite a few arguments that should be
         #   passed by keyword rather than position.  However it's important to
@@ -334,6 +360,9 @@ class Environment(object):
 
         self.enable_async = enable_async
         self.is_async = self.enable_async and have_async_gen
+        if self.is_async:
+            # runs patch_all() to enable async support
+            from . import asyncsupport  # noqa: F401
 
         _environment_sanity_check(self)
 
@@ -353,15 +382,28 @@ class Environment(object):
             if not hasattr(self, key):
                 setattr(self, key, value)
 
-    def overlay(self, block_start_string=missing, block_end_string=missing,
-                variable_start_string=missing, variable_end_string=missing,
-                comment_start_string=missing, comment_end_string=missing,
-                line_statement_prefix=missing, line_comment_prefix=missing,
-                trim_blocks=missing, lstrip_blocks=missing,
-                extensions=missing, optimized=missing,
-                undefined=missing, finalize=missing, autoescape=missing,
-                loader=missing, cache_size=missing, auto_reload=missing,
-                bytecode_cache=missing):
+    def overlay(
+        self,
+        block_start_string=missing,
+        block_end_string=missing,
+        variable_start_string=missing,
+        variable_end_string=missing,
+        comment_start_string=missing,
+        comment_end_string=missing,
+        line_statement_prefix=missing,
+        line_comment_prefix=missing,
+        trim_blocks=missing,
+        lstrip_blocks=missing,
+        extensions=missing,
+        optimized=missing,
+        undefined=missing,
+        finalize=missing,
+        autoescape=missing,
+        loader=missing,
+        cache_size=missing,
+        auto_reload=missing,
+        bytecode_cache=missing,
+    ):
         """Create a new overlay environment that shares all the data with the
         current environment except for cache and the overridden attributes.
         Extensions cannot be removed for an overlayed environment.  An overlayed
@@ -374,7 +416,7 @@ class Environment(object):
         through.
         """
         args = dict(locals())
-        del args['self'], args['cache_size'], args['extensions']
+        del args["self"], args["cache_size"], args["extensions"]
 
         rv = object.__new__(self.__class__)
         rv.__dict__.update(self.__dict__)
@@ -402,8 +444,7 @@ class Environment(object):
 
     def iter_extensions(self):
         """Iterates over the extensions by priority."""
-        return iter(sorted(self.extensions.values(),
-                           key=lambda x: x.priority))
+        return iter(sorted(self.extensions.values(), key=lambda x: x.priority))
 
     def getitem(self, obj, argument):
         """Get an item or attribute of an object but prefer the item."""
@@ -435,8 +476,9 @@ class Environment(object):
         except (TypeError, LookupError, AttributeError):
             return self.undefined(obj=obj, name=attribute)
 
-    def call_filter(self, name, value, args=None, kwargs=None,
-                    context=None, eval_ctx=None):
+    def call_filter(
+        self, name, value, args=None, kwargs=None, context=None, eval_ctx=None
+    ):
         """Invokes a filter on a value the same way the compiler does it.
 
         Note that on Python 3 this might return a coroutine in case the
@@ -448,21 +490,22 @@ class Environment(object):
         """
         func = self.filters.get(name)
         if func is None:
-            fail_for_missing_callable('no filter named %r', name)
+            fail_for_missing_callable("no filter named %r", name)
         args = [value] + list(args or ())
-        if getattr(func, 'contextfilter', False):
+        if getattr(func, "contextfilter", False):
             if context is None:
-                raise TemplateRuntimeError('Attempted to invoke context '
-                                           'filter without context')
+                raise TemplateRuntimeError(
+                    "Attempted to invoke context filter without context"
+                )
             args.insert(0, context)
-        elif getattr(func, 'evalcontextfilter', False):
+        elif getattr(func, "evalcontextfilter", False):
             if eval_ctx is None:
                 if context is not None:
                     eval_ctx = context.eval_ctx
                 else:
                     eval_ctx = EvalContext(self)
             args.insert(0, eval_ctx)
-        elif getattr(func, 'environmentfilter', False):
+        elif getattr(func, "environmentfilter", False):
             args.insert(0, self)
         return func(*args, **(kwargs or {}))
 
@@ -473,7 +516,7 @@ class Environment(object):
         """
         func = self.tests.get(name)
         if func is None:
-            fail_for_missing_callable('no test named %r', name)
+            fail_for_missing_callable("no test named %r", name)
         return func(value, *(args or ()), **(kwargs or {}))
 
     @internalcode
@@ -483,14 +526,13 @@ class Environment(object):
         executable source- or bytecode.  This is useful for debugging or to
         extract information from templates.
 
-        If you are :ref:`developing Jinja2 extensions <writing-extensions>`
+        If you are :ref:`developing Jinja extensions <writing-extensions>`
         this gives you a good overview of the node tree generated.
         """
         try:
             return self._parse(source, name, filename)
         except TemplateSyntaxError:
-            exc_info = sys.exc_info()
-        self.handle_exception(exc_info, source_hint=source)
+            self.handle_exception(source=source)
 
     def _parse(self, source, name, filename):
         """Internal parsing function used by `parse` and `compile`."""
@@ -510,16 +552,18 @@ class Environment(object):
         try:
             return self.lexer.tokeniter(source, name, filename)
         except TemplateSyntaxError:
-            exc_info = sys.exc_info()
-        self.handle_exception(exc_info, source_hint=source)
+            self.handle_exception(source=source)
 
     def preprocess(self, source, name=None, filename=None):
         """Preprocesses the source with all extensions.  This is automatically
         called for all parsing and compiling methods but *not* for :meth:`lex`
         because there you usually only want the actual source tokenized.
         """
-        return reduce(lambda s, e: e.preprocess(s, name, filename),
-                      self.iter_extensions(), text_type(source))
+        return reduce(
+            lambda s, e: e.preprocess(s, name, filename),
+            self.iter_extensions(),
+            text_type(source),
+        )
 
     def _tokenize(self, source, name, filename=None, state=None):
         """Called by the parser to do the preprocessing and filtering
@@ -539,8 +583,14 @@ class Environment(object):
 
         .. versionadded:: 2.5
         """
-        return generate(source, self, name, filename, defer_init=defer_init,
-                        optimized=self.optimized)
+        return generate(
+            source,
+            self,
+            name,
+            filename,
+            defer_init=defer_init,
+            optimized=self.optimized,
+        )
 
     def _compile(self, source, filename):
         """Internal hook that can be overridden to hook a different compile
@@ -548,11 +598,10 @@ class Environment(object):
 
         .. versionadded:: 2.5
         """
-        return compile(source, filename, 'exec')
+        return compile(source, filename, "exec")
 
     @internalcode
-    def compile(self, source, name=None, filename=None, raw=False,
-                defer_init=False):
+    def compile(self, source, name=None, filename=None, raw=False, defer_init=False):
         """Compile a node or template source code.  The `name` parameter is
         the load name of the template after it was joined using
         :meth:`join_path` if necessary, not the filename on the file system.
@@ -577,18 +626,16 @@ class Environment(object):
             if isinstance(source, string_types):
                 source_hint = source
                 source = self._parse(source, name, filename)
-            source = self._generate(source, name, filename,
-                                    defer_init=defer_init)
+            source = self._generate(source, name, filename, defer_init=defer_init)
             if raw:
                 return source
             if filename is None:
-                filename = '<template>'
+                filename = "<template>"
             else:
                 filename = encode_filename(filename)
             return self._compile(source, filename)
         except TemplateSyntaxError:
-            exc_info = sys.exc_info()
-        self.handle_exception(exc_info, source_hint=source_hint)
+            self.handle_exception(source=source_hint)
 
     def compile_expression(self, source, undefined_to_none=True):
         """A handy helper method that returns a callable that accepts keyword
@@ -618,26 +665,32 @@ class Environment(object):
 
         .. versionadded:: 2.1
         """
-        parser = Parser(self, source, state='variable')
-        exc_info = None
+        parser = Parser(self, source, state="variable")
         try:
             expr = parser.parse_expression()
             if not parser.stream.eos:
-                raise TemplateSyntaxError('chunk after expression',
-                                          parser.stream.current.lineno,
-                                          None, None)
+                raise TemplateSyntaxError(
+                    "chunk after expression", parser.stream.current.lineno, None, None
+                )
             expr.set_environment(self)
         except TemplateSyntaxError:
-            exc_info = sys.exc_info()
-        if exc_info is not None:
-            self.handle_exception(exc_info, source_hint=source)
-        body = [nodes.Assign(nodes.Name('result', 'store'), expr, lineno=1)]
+            if sys.exc_info() is not None:
+                self.handle_exception(source=source)
+
+        body = [nodes.Assign(nodes.Name("result", "store"), expr, lineno=1)]
         template = self.from_string(nodes.Template(body, lineno=1))
         return TemplateExpression(template, undefined_to_none)
 
-    def compile_templates(self, target, extensions=None, filter_func=None,
-                          zip='deflated', log_function=None,
-                          ignore_errors=True, py_compile=False):
+    def compile_templates(
+        self,
+        target,
+        extensions=None,
+        filter_func=None,
+        zip="deflated",
+        log_function=None,
+        ignore_errors=True,
+        py_compile=False,
+    ):
         """Finds all the templates the loader can find, compiles them
         and stores them in `target`.  If `zip` is `None`, instead of in a
         zipfile, the templates will be stored in a directory.
@@ -660,42 +713,52 @@ class Environment(object):
 
         .. versionadded:: 2.4
         """
-        from jinja2.loaders import ModuleLoader
+        from .loaders import ModuleLoader
 
         if log_function is None:
-            log_function = lambda x: None
+
+            def log_function(x):
+                pass
 
         if py_compile:
             if not PY2 or PYPY:
-                from warnings import warn
-                warn(Warning('py_compile has no effect on pypy or Python 3'))
+                import warnings
+
+                warnings.warn(
+                    "'py_compile=True' has no effect on PyPy or Python"
+                    " 3 and will be removed in version 3.0",
+                    DeprecationWarning,
+                    stacklevel=2,
+                )
                 py_compile = False
             else:
                 import imp
                 import marshal
-                py_header = imp.get_magic() + \
-                    u'\xff\xff\xff\xff'.encode('iso-8859-15')
+
+                py_header = imp.get_magic() + u"\xff\xff\xff\xff".encode("iso-8859-15")
 
                 # Python 3.3 added a source filesize to the header
                 if sys.version_info >= (3, 3):
-                    py_header += u'\x00\x00\x00\x00'.encode('iso-8859-15')
+                    py_header += u"\x00\x00\x00\x00".encode("iso-8859-15")
 
-        def write_file(filename, data, mode):
+        def write_file(filename, data):
             if zip:
                 info = ZipInfo(filename)
                 info.external_attr = 0o755 << 16
                 zip_file.writestr(info, data)
             else:
-                f = open(os.path.join(target, filename), mode)
-                try:
+                if isinstance(data, text_type):
+                    data = data.encode("utf8")
+
+                with open(os.path.join(target, filename), "wb") as f:
                     f.write(data)
-                finally:
-                    f.close()
 
         if zip is not None:
             from zipfile import ZipFile, ZipInfo, ZIP_DEFLATED, ZIP_STORED
-            zip_file = ZipFile(target, 'w', dict(deflated=ZIP_DEFLATED,
-                                                 stored=ZIP_STORED)[zip])
+
+            zip_file = ZipFile(
+                target, "w", dict(deflated=ZIP_DEFLATED, stored=ZIP_STORED)[zip]
+            )
             log_function('Compiling into Zip archive "%s"' % target)
         else:
             if not os.path.isdir(target):
@@ -717,18 +780,16 @@ class Environment(object):
 
                 if py_compile:
                     c = self._compile(code, encode_filename(filename))
-                    write_file(filename + 'c', py_header +
-                               marshal.dumps(c), 'wb')
-                    log_function('Byte-compiled "%s" as %s' %
-                                 (name, filename + 'c'))
+                    write_file(filename + "c", py_header + marshal.dumps(c))
+                    log_function('Byte-compiled "%s" as %s' % (name, filename + "c"))
                 else:
-                    write_file(filename, code, 'w')
+                    write_file(filename, code)
                     log_function('Compiled "%s" as %s' % (name, filename))
         finally:
             if zip:
                 zip_file.close()
 
-        log_function('Finished compiling templates')
+        log_function("Finished compiling templates")
 
     def list_templates(self, extensions=None, filter_func=None):
         """Returns a list of templates for this environment.  This requires
@@ -746,38 +807,29 @@ class Environment(object):
 
         .. versionadded:: 2.4
         """
-        x = self.loader.list_templates()
+        names = self.loader.list_templates()
+
         if extensions is not None:
             if filter_func is not None:
-                raise TypeError('either extensions or filter_func '
-                                'can be passed, but not both')
-            filter_func = lambda x: '.' in x and \
-                                    x.rsplit('.', 1)[1] in extensions
+                raise TypeError(
+                    "either extensions or filter_func can be passed, but not both"
+                )
+
+            def filter_func(x):
+                return "." in x and x.rsplit(".", 1)[1] in extensions
+
         if filter_func is not None:
-            x = list(ifilter(filter_func, x))
-        return x
+            names = [name for name in names if filter_func(name)]
+
+        return names
 
-    def handle_exception(self, exc_info=None, rendered=False, source_hint=None):
+    def handle_exception(self, source=None):
         """Exception handling helper.  This is used internally to either raise
         rewritten exceptions or return a rendered traceback for the template.
         """
-        global _make_traceback
-        if exc_info is None:
-            exc_info = sys.exc_info()
-
-        # the debugging module is imported when it's used for the first time.
-        # we're doing a lot of stuff there and for applications that do not
-        # get any exceptions in template rendering there is no need to load
-        # all of that.
-        if _make_traceback is None:
-            from jinja2.debug import make_traceback as _make_traceback
-        traceback = _make_traceback(exc_info, source_hint)
-        if rendered and self.exception_formatter is not None:
-            return self.exception_formatter(traceback)
-        if self.exception_handler is not None:
-            self.exception_handler(traceback)
-        exc_type, exc_value, tb = traceback.standard_exc_info
-        reraise(exc_type, exc_value, tb)
+        from .debug import rewrite_traceback_stack
+
+        reraise(*rewrite_traceback_stack(source=source))
 
     def join_path(self, template, parent):
         """Join a template with the parent.  By default all the lookups are
@@ -794,12 +846,13 @@ class Environment(object):
     @internalcode
     def _load_template(self, name, globals):
         if self.loader is None:
-            raise TypeError('no loader for this environment specified')
+            raise TypeError("no loader for this environment specified")
         cache_key = (weakref.ref(self.loader), name)
         if self.cache is not None:
             template = self.cache.get(cache_key)
-            if template is not None and (not self.auto_reload or
-                                         template.is_up_to_date):
+            if template is not None and (
+                not self.auto_reload or template.is_up_to_date
+            ):
                 return template
         template = self.loader.load(self, name, globals)
         if self.cache is not None:
@@ -835,15 +888,24 @@ class Environment(object):
         before it fails.  If it cannot find any of the templates, it will
         raise a :exc:`TemplatesNotFound` exception.
 
-        .. versionadded:: 2.3
+        .. versionchanged:: 2.11
+            If names is :class:`Undefined`, an :exc:`UndefinedError` is
+            raised instead. If no templates were found and names
+            contains :class:`Undefined`, the message is more helpful.
 
         .. versionchanged:: 2.4
            If `names` contains a :class:`Template` object it is returned
            from the function unchanged.
+
+        .. versionadded:: 2.3
         """
+        if isinstance(names, Undefined):
+            names._fail_with_undefined_error()
+
         if not names:
-            raise TemplatesNotFound(message=u'Tried to select from an empty list '
-                                            u'of templates.')
+            raise TemplatesNotFound(
+                message=u"Tried to select from an empty list " u"of templates."
+            )
         globals = self.make_globals(globals)
         for name in names:
             if isinstance(name, Template):
@@ -852,20 +914,19 @@ class Environment(object):
                 name = self.join_path(name, parent)
             try:
                 return self._load_template(name, globals)
-            except TemplateNotFound:
+            except (TemplateNotFound, UndefinedError):
                 pass
         raise TemplatesNotFound(names)
 
     @internalcode
-    def get_or_select_template(self, template_name_or_list,
-                               parent=None, globals=None):
+    def get_or_select_template(self, template_name_or_list, parent=None, globals=None):
         """Does a typecheck and dispatches to :meth:`select_template`
         if an iterable of template names is given, otherwise to
         :meth:`get_template`.
 
         .. versionadded:: 2.3
         """
-        if isinstance(template_name_or_list, string_types):
+        if isinstance(template_name_or_list, (string_types, Undefined)):
             return self.get_template(template_name_or_list, parent, globals)
         elif isinstance(template_name_or_list, Template):
             return template_name_or_list
@@ -916,32 +977,57 @@ class Template(object):
     StopIteration
     """
 
-    def __new__(cls, source,
-                block_start_string=BLOCK_START_STRING,
-                block_end_string=BLOCK_END_STRING,
-                variable_start_string=VARIABLE_START_STRING,
-                variable_end_string=VARIABLE_END_STRING,
-                comment_start_string=COMMENT_START_STRING,
-                comment_end_string=COMMENT_END_STRING,
-                line_statement_prefix=LINE_STATEMENT_PREFIX,
-                line_comment_prefix=LINE_COMMENT_PREFIX,
-                trim_blocks=TRIM_BLOCKS,
-                lstrip_blocks=LSTRIP_BLOCKS,
-                newline_sequence=NEWLINE_SEQUENCE,
-                keep_trailing_newline=KEEP_TRAILING_NEWLINE,
-                extensions=(),
-                optimized=True,
-                undefined=Undefined,
-                finalize=None,
-                autoescape=False,
-                enable_async=False):
+    #: Type of environment to create when creating a template directly
+    #: rather than through an existing environment.
+    environment_class = Environment
+
+    def __new__(
+        cls,
+        source,
+        block_start_string=BLOCK_START_STRING,
+        block_end_string=BLOCK_END_STRING,
+        variable_start_string=VARIABLE_START_STRING,
+        variable_end_string=VARIABLE_END_STRING,
+        comment_start_string=COMMENT_START_STRING,
+        comment_end_string=COMMENT_END_STRING,
+        line_statement_prefix=LINE_STATEMENT_PREFIX,
+        line_comment_prefix=LINE_COMMENT_PREFIX,
+        trim_blocks=TRIM_BLOCKS,
+        lstrip_blocks=LSTRIP_BLOCKS,
+        newline_sequence=NEWLINE_SEQUENCE,
+        keep_trailing_newline=KEEP_TRAILING_NEWLINE,
+        extensions=(),
+        optimized=True,
+        undefined=Undefined,
+        finalize=None,
+        autoescape=False,
+        enable_async=False,
+    ):
         env = get_spontaneous_environment(
-            block_start_string, block_end_string, variable_start_string,
-            variable_end_string, comment_start_string, comment_end_string,
-            line_statement_prefix, line_comment_prefix, trim_blocks,
-            lstrip_blocks, newline_sequence, keep_trailing_newline,
-            frozenset(extensions), optimized, undefined, finalize, autoescape,
-            None, 0, False, None, enable_async)
+            cls.environment_class,
+            block_start_string,
+            block_end_string,
+            variable_start_string,
+            variable_end_string,
+            comment_start_string,
+            comment_end_string,
+            line_statement_prefix,
+            line_comment_prefix,
+            trim_blocks,
+            lstrip_blocks,
+            newline_sequence,
+            keep_trailing_newline,
+            frozenset(extensions),
+            optimized,
+            undefined,
+            finalize,
+            autoescape,
+            None,
+            0,
+            False,
+            None,
+            enable_async,
+        )
         return env.from_string(source, template_class=cls)
 
     @classmethod
@@ -949,10 +1035,7 @@ class Template(object):
         """Creates a template object from compiled code and the globals.  This
         is used by the loaders and environment to create a template object.
         """
-        namespace = {
-            'environment':  environment,
-            '__file__':     code.co_filename
-        }
+        namespace = {"environment": environment, "__file__": code.co_filename}
         exec(code, namespace)
         rv = cls._from_namespace(environment, namespace, globals)
         rv._uptodate = uptodate
@@ -972,21 +1055,21 @@ class Template(object):
         t = object.__new__(cls)
         t.environment = environment
         t.globals = globals
-        t.name = namespace['name']
-        t.filename = namespace['__file__']
-        t.blocks = namespace['blocks']
+        t.name = namespace["name"]
+        t.filename = namespace["__file__"]
+        t.blocks = namespace["blocks"]
 
         # render function and module
-        t.root_render_func = namespace['root']
+        t.root_render_func = namespace["root"]
         t._module = None
 
         # debug and loader helpers
-        t._debug_info = namespace['debug_info']
+        t._debug_info = namespace["debug_info"]
         t._uptodate = None
 
         # store the reference
-        namespace['environment'] = environment
-        namespace['__jinja_template__'] = t
+        namespace["environment"] = environment
+        namespace["__jinja_template__"] = t
 
         return t
 
@@ -1004,8 +1087,7 @@ class Template(object):
         try:
             return concat(self.root_render_func(self.new_context(vars)))
         except Exception:
-            exc_info = sys.exc_info()
-        return self.environment.handle_exception(exc_info, True)
+            self.environment.handle_exception()
 
     def render_async(self, *args, **kwargs):
         """This works similar to :meth:`render` but returns a coroutine
@@ -1017,8 +1099,9 @@ class Template(object):
             await template.render_async(knights='that say nih; asynchronously')
         """
         # see asyncsupport for the actual implementation
-        raise NotImplementedError('This feature is not available for this '
-                                  'version of Python')
+        raise NotImplementedError(
+            "This feature is not available for this version of Python"
+        )
 
     def stream(self, *args, **kwargs):
         """Works exactly like :meth:`generate` but returns a
@@ -1039,29 +1122,28 @@ class Template(object):
             for event in self.root_render_func(self.new_context(vars)):
                 yield event
         except Exception:
-            exc_info = sys.exc_info()
-        else:
-            return
-        yield self.environment.handle_exception(exc_info, True)
+            yield self.environment.handle_exception()
 
     def generate_async(self, *args, **kwargs):
         """An async version of :meth:`generate`.  Works very similarly but
         returns an async iterator instead.
         """
         # see asyncsupport for the actual implementation
-        raise NotImplementedError('This feature is not available for this '
-                                  'version of Python')
+        raise NotImplementedError(
+            "This feature is not available for this version of Python"
+        )
 
     def new_context(self, vars=None, shared=False, locals=None):
         """Create a new :class:`Context` for this template.  The vars
         provided will be passed to the template.  Per default the globals
         are added to the context.  If shared is set to `True` the data
-        is passed as it to the context without adding the globals.
+        is passed as is to the context without adding the globals.
 
         `locals` can be a dict of local variables for internal usage.
         """
-        return new_context(self.environment, self.name, self.blocks,
-                           vars, shared, self.globals, locals)
+        return new_context(
+            self.environment, self.name, self.blocks, vars, shared, self.globals, locals
+        )
 
     def make_module(self, vars=None, shared=False, locals=None):
         """This method works like the :attr:`module` attribute when called
@@ -1074,13 +1156,14 @@ class Template(object):
 
     def make_module_async(self, vars=None, shared=False, locals=None):
         """As template module creation can invoke template code for
-        asynchronous exections this method must be used instead of the
+        asynchronous executions this method must be used instead of the
         normal :meth:`make_module` one.  Likewise the module attribute
         becomes unavailable in async mode.
         """
         # see asyncsupport for the actual implementation
-        raise NotImplementedError('This feature is not available for this '
-                                  'version of Python')
+        raise NotImplementedError(
+            "This feature is not available for this version of Python"
+        )
 
     @internalcode
     def _get_default_module(self):
@@ -1124,15 +1207,16 @@ class Template(object):
     @property
     def debug_info(self):
         """The debug info mapping."""
-        return [tuple(imap(int, x.split('='))) for x in
-                self._debug_info.split('&')]
+        if self._debug_info:
+            return [tuple(map(int, x.split("="))) for x in self._debug_info.split("&")]
+        return []
 
     def __repr__(self):
         if self.name is None:
-            name = 'memory:%x' % id(self)
+            name = "memory:%x" % id(self)
         else:
             name = repr(self.name)
-        return '<%s %s>' % (self.__class__.__name__, name)
+        return "<%s %s>" % (self.__class__.__name__, name)
 
 
 @implements_to_string
@@ -1145,10 +1229,12 @@ class TemplateModule(object):
     def __init__(self, template, context, body_stream=None):
         if body_stream is None:
             if context.environment.is_async:
-                raise RuntimeError('Async mode requires a body stream '
-                                   'to be passed to a template module.  Use '
-                                   'the async methods of the API you are '
-                                   'using.')
+                raise RuntimeError(
+                    "Async mode requires a body stream "
+                    "to be passed to a template module.  Use "
+                    "the async methods of the API you are "
+                    "using."
+                )
             body_stream = list(template.root_render_func(context))
         self._body_stream = body_stream
         self.__dict__.update(context.get_exported())
@@ -1162,10 +1248,10 @@ class TemplateModule(object):
 
     def __repr__(self):
         if self.__name__ is None:
-            name = 'memory:%x' % id(self)
+            name = "memory:%x" % id(self)
         else:
             name = repr(self.__name__)
-        return '<%s %s>' % (self.__class__.__name__, name)
+        return "<%s %s>" % (self.__class__.__name__, name)
 
 
 class TemplateExpression(object):
@@ -1181,7 +1267,7 @@ class TemplateExpression(object):
     def __call__(self, *args, **kwargs):
         context = self._template.new_context(dict(*args, **kwargs))
         consume(self._template.root_render_func(context))
-        rv = context.vars['result']
+        rv = context.vars["result"]
         if self._undefined_to_none and isinstance(rv, Undefined):
             rv = None
         return rv
@@ -1203,7 +1289,7 @@ class TemplateStream(object):
         self._gen = gen
         self.disable_buffering()
 
-    def dump(self, fp, encoding=None, errors='strict'):
+    def dump(self, fp, encoding=None, errors="strict"):
         """Dump the complete stream into a file or file-like object.
         Per default unicode strings are written, if you want to encode
         before writing specify an `encoding`.
@@ -1215,15 +1301,15 @@ class TemplateStream(object):
         close = False
         if isinstance(fp, string_types):
             if encoding is None:
-                encoding = 'utf-8'
-            fp = open(fp, 'wb')
+                encoding = "utf-8"
+            fp = open(fp, "wb")
             close = True
         try:
             if encoding is not None:
                 iterable = (x.encode(encoding, errors) for x in self)
             else:
                 iterable = self
-            if hasattr(fp, 'writelines'):
+            if hasattr(fp, "writelines"):
                 fp.writelines(iterable)
             else:
                 for item in iterable:
@@ -1259,7 +1345,7 @@ class TemplateStream(object):
     def enable_buffering(self, size=5):
         """Enable buffering.  Buffer `size` items before yielding them."""
         if size <= 1:
-            raise ValueError('buffer size too small')
+            raise ValueError("buffer size too small")
 
         self.buffered = True
         self._next = partial(next, self._buffered_generator(size))
diff --git a/pipenv/vendor/jinja2/exceptions.py b/pipenv/vendor/jinja2/exceptions.py
index c018a33e..0bf2003e 100644
--- a/pipenv/vendor/jinja2/exceptions.py
+++ b/pipenv/vendor/jinja2/exceptions.py
@@ -1,23 +1,18 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.exceptions
-    ~~~~~~~~~~~~~~~~~
-
-    Jinja exceptions.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
-from jinja2._compat import imap, text_type, PY2, implements_to_string
+from ._compat import imap
+from ._compat import implements_to_string
+from ._compat import PY2
+from ._compat import text_type
 
 
 class TemplateError(Exception):
     """Baseclass for all template errors."""
 
     if PY2:
+
         def __init__(self, message=None):
             if message is not None:
-                message = text_type(message).encode('utf-8')
+                message = text_type(message).encode("utf-8")
             Exception.__init__(self, message)
 
         @property
@@ -25,11 +20,13 @@ class TemplateError(Exception):
             if self.args:
                 message = self.args[0]
                 if message is not None:
-                    return message.decode('utf-8', 'replace')
+                    return message.decode("utf-8", "replace")
 
         def __unicode__(self):
-            return self.message or u''
+            return self.message or u""
+
     else:
+
         def __init__(self, message=None):
             Exception.__init__(self, message)
 
@@ -43,16 +40,28 @@ class TemplateError(Exception):
 
 @implements_to_string
 class TemplateNotFound(IOError, LookupError, TemplateError):
-    """Raised if a template does not exist."""
+    """Raised if a template does not exist.
+
+    .. versionchanged:: 2.11
+        If the given name is :class:`Undefined` and no message was
+        provided, an :exc:`UndefinedError` is raised.
+    """
 
     # looks weird, but removes the warning descriptor that just
     # bogusly warns us about message being deprecated
     message = None
 
     def __init__(self, name, message=None):
-        IOError.__init__(self)
+        IOError.__init__(self, name)
+
         if message is None:
+            from .runtime import Undefined
+
+            if isinstance(name, Undefined):
+                name._fail_with_undefined_error()
+
             message = name
+
         self.message = message
         self.name = name
         self.templates = [name]
@@ -66,13 +75,28 @@ class TemplatesNotFound(TemplateNotFound):
     are selected.  This is a subclass of :class:`TemplateNotFound`
     exception, so just catching the base exception will catch both.
 
+    .. versionchanged:: 2.11
+        If a name in the list of names is :class:`Undefined`, a message
+        about it being undefined is shown rather than the empty string.
+
     .. versionadded:: 2.2
     """
 
     def __init__(self, names=(), message=None):
         if message is None:
-            message = u'none of the templates given were found: ' + \
-                      u', '.join(imap(text_type, names))
+            from .runtime import Undefined
+
+            parts = []
+
+            for name in names:
+                if isinstance(name, Undefined):
+                    parts.append(name._undefined_message)
+                else:
+                    parts.append(name)
+
+            message = u"none of the templates given were found: " + u", ".join(
+                imap(text_type, parts)
+            )
         TemplateNotFound.__init__(self, names and names[-1] or None, message)
         self.templates = list(names)
 
@@ -98,11 +122,11 @@ class TemplateSyntaxError(TemplateError):
             return self.message
 
         # otherwise attach some stuff
-        location = 'line %d' % self.lineno
+        location = "line %d" % self.lineno
         name = self.filename or self.name
         if name:
             location = 'File "%s", %s' % (name, location)
-        lines = [self.message, '  ' + location]
+        lines = [self.message, "  " + location]
 
         # if the source is set, add the line to the output
         if self.source is not None:
@@ -111,9 +135,16 @@ class TemplateSyntaxError(TemplateError):
             except IndexError:
                 line = None
             if line:
-                lines.append('    ' + line.strip())
+                lines.append("    " + line.strip())
+
+        return u"\n".join(lines)
 
-        return u'\n'.join(lines)
+    def __reduce__(self):
+        # https://bugs.python.org/issue1692335 Exceptions that take
+        # multiple required arguments have problems with pickling.
+        # Without this, raises TypeError: __init__() missing 1 required
+        # positional argument: 'lineno'
+        return self.__class__, (self.message, self.lineno, self.name, self.filename)
 
 
 class TemplateAssertionError(TemplateSyntaxError):
diff --git a/pipenv/vendor/jinja2/ext.py b/pipenv/vendor/jinja2/ext.py
index 0734a84f..9141be4d 100644
--- a/pipenv/vendor/jinja2/ext.py
+++ b/pipenv/vendor/jinja2/ext.py
@@ -1,42 +1,49 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.ext
-    ~~~~~~~~~~
-
-    Jinja extensions allow to add custom tags similar to the way django custom
-    tags work.  By default two example extensions exist: an i18n and a cache
-    extension.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD.
-"""
+"""Extension API for adding custom tags and behavior."""
+import pprint
 import re
-
-from jinja2 import nodes
-from jinja2.defaults import BLOCK_START_STRING, \
-     BLOCK_END_STRING, VARIABLE_START_STRING, VARIABLE_END_STRING, \
-     COMMENT_START_STRING, COMMENT_END_STRING, LINE_STATEMENT_PREFIX, \
-     LINE_COMMENT_PREFIX, TRIM_BLOCKS, NEWLINE_SEQUENCE, \
-     KEEP_TRAILING_NEWLINE, LSTRIP_BLOCKS
-from jinja2.environment import Environment
-from jinja2.runtime import concat
-from jinja2.exceptions import TemplateAssertionError, TemplateSyntaxError
-from jinja2.utils import contextfunction, import_string, Markup
-from jinja2._compat import with_metaclass, string_types, iteritems
-
+from sys import version_info
+
+from markupsafe import Markup
+
+from . import nodes
+from ._compat import iteritems
+from ._compat import string_types
+from ._compat import with_metaclass
+from .defaults import BLOCK_END_STRING
+from .defaults import BLOCK_START_STRING
+from .defaults import COMMENT_END_STRING
+from .defaults import COMMENT_START_STRING
+from .defaults import KEEP_TRAILING_NEWLINE
+from .defaults import LINE_COMMENT_PREFIX
+from .defaults import LINE_STATEMENT_PREFIX
+from .defaults import LSTRIP_BLOCKS
+from .defaults import NEWLINE_SEQUENCE
+from .defaults import TRIM_BLOCKS
+from .defaults import VARIABLE_END_STRING
+from .defaults import VARIABLE_START_STRING
+from .environment import Environment
+from .exceptions import TemplateAssertionError
+from .exceptions import TemplateSyntaxError
+from .nodes import ContextReference
+from .runtime import concat
+from .utils import contextfunction
+from .utils import import_string
 
 # the only real useful gettext functions for a Jinja template.  Note
 # that ugettext must be assigned to gettext as Jinja doesn't support
 # non unicode strings.
-GETTEXT_FUNCTIONS = ('_', 'gettext', 'ngettext')
+GETTEXT_FUNCTIONS = ("_", "gettext", "ngettext")
+
+_ws_re = re.compile(r"\s*\n\s*")
 
 
 class ExtensionRegistry(type):
     """Gives the extension an unique identifier."""
 
-    def __new__(cls, name, bases, d):
-        rv = type.__new__(cls, name, bases, d)
-        rv.identifier = rv.__module__ + '.' + rv.__name__
+    def __new__(mcs, name, bases, d):
+        rv = type.__new__(mcs, name, bases, d)
+        rv.identifier = rv.__module__ + "." + rv.__name__
         return rv
 
 
@@ -91,10 +98,6 @@ class Extension(with_metaclass(ExtensionRegistry, object)):
         to filter tokens returned.  This method has to return an iterable of
         :class:`~jinja2.lexer.Token`\\s, but it doesn't have to return a
         :class:`~jinja2.lexer.TokenStream`.
-
-        In the `ext` folder of the Jinja2 source distribution there is a file
-        called `inlinegettext.py` which implements a filter that utilizes this
-        method.
         """
         return stream
 
@@ -116,8 +119,9 @@ class Extension(with_metaclass(ExtensionRegistry, object)):
         """
         return nodes.ExtensionAttribute(self.identifier, name, lineno=lineno)
 
-    def call_method(self, name, args=None, kwargs=None, dyn_args=None,
-                    dyn_kwargs=None, lineno=None):
+    def call_method(
+        self, name, args=None, kwargs=None, dyn_args=None, dyn_kwargs=None, lineno=None
+    ):
         """Call a method of the extension.  This is a shortcut for
         :meth:`attr` + :class:`jinja2.nodes.Call`.
         """
@@ -125,13 +129,19 @@ class Extension(with_metaclass(ExtensionRegistry, object)):
             args = []
         if kwargs is None:
             kwargs = []
-        return nodes.Call(self.attr(name, lineno=lineno), args, kwargs,
-                          dyn_args, dyn_kwargs, lineno=lineno)
+        return nodes.Call(
+            self.attr(name, lineno=lineno),
+            args,
+            kwargs,
+            dyn_args,
+            dyn_kwargs,
+            lineno=lineno,
+        )
 
 
 @contextfunction
 def _gettext_alias(__context, *args, **kwargs):
-    return __context.call(__context.resolve('gettext'), *args, **kwargs)
+    return __context.call(__context.resolve("gettext"), *args, **kwargs)
 
 
 def _make_new_gettext(func):
@@ -140,24 +150,31 @@ def _make_new_gettext(func):
         rv = __context.call(func, __string)
         if __context.eval_ctx.autoescape:
             rv = Markup(rv)
+        # Always treat as a format string, even if there are no
+        # variables. This makes translation strings more consistent
+        # and predictable. This requires escaping
         return rv % variables
+
     return gettext
 
 
 def _make_new_ngettext(func):
     @contextfunction
     def ngettext(__context, __singular, __plural, __num, **variables):
-        variables.setdefault('num', __num)
+        variables.setdefault("num", __num)
         rv = __context.call(func, __singular, __plural, __num)
         if __context.eval_ctx.autoescape:
             rv = Markup(rv)
+        # Always treat as a format string, see gettext comment above.
         return rv % variables
+
     return ngettext
 
 
 class InternationalizationExtension(Extension):
-    """This extension adds gettext support to Jinja2."""
-    tags = set(['trans'])
+    """This extension adds gettext support to Jinja."""
+
+    tags = {"trans"}
 
     # TODO: the i18n extension is currently reevaluating values in a few
     # situations.  Take this example:
@@ -168,30 +185,28 @@ class InternationalizationExtension(Extension):
 
     def __init__(self, environment):
         Extension.__init__(self, environment)
-        environment.globals['_'] = _gettext_alias
+        environment.globals["_"] = _gettext_alias
         environment.extend(
             install_gettext_translations=self._install,
             install_null_translations=self._install_null,
             install_gettext_callables=self._install_callables,
             uninstall_gettext_translations=self._uninstall,
             extract_translations=self._extract,
-            newstyle_gettext=False
+            newstyle_gettext=False,
         )
 
     def _install(self, translations, newstyle=None):
-        gettext = getattr(translations, 'ugettext', None)
+        gettext = getattr(translations, "ugettext", None)
         if gettext is None:
             gettext = translations.gettext
-        ngettext = getattr(translations, 'ungettext', None)
+        ngettext = getattr(translations, "ungettext", None)
         if ngettext is None:
             ngettext = translations.ngettext
         self._install_callables(gettext, ngettext, newstyle)
 
     def _install_null(self, newstyle=None):
         self._install_callables(
-            lambda x: x,
-            lambda s, p, n: (n != 1 and (p,) or (s,))[0],
-            newstyle
+            lambda x: x, lambda s, p, n: (n != 1 and (p,) or (s,))[0], newstyle
         )
 
     def _install_callables(self, gettext, ngettext, newstyle=None):
@@ -200,13 +215,10 @@ class InternationalizationExtension(Extension):
         if self.environment.newstyle_gettext:
             gettext = _make_new_gettext(gettext)
             ngettext = _make_new_ngettext(ngettext)
-        self.environment.globals.update(
-            gettext=gettext,
-            ngettext=ngettext
-        )
+        self.environment.globals.update(gettext=gettext, ngettext=ngettext)
 
     def _uninstall(self, translations):
-        for key in 'gettext', 'ngettext':
+        for key in "gettext", "ngettext":
             self.environment.globals.pop(key, None)
 
     def _extract(self, source, gettext_functions=GETTEXT_FUNCTIONS):
@@ -226,41 +238,44 @@ class InternationalizationExtension(Extension):
         plural_expr_assignment = None
         variables = {}
         trimmed = None
-        while parser.stream.current.type != 'block_end':
+        while parser.stream.current.type != "block_end":
             if variables:
-                parser.stream.expect('comma')
+                parser.stream.expect("comma")
 
             # skip colon for python compatibility
-            if parser.stream.skip_if('colon'):
+            if parser.stream.skip_if("colon"):
                 break
 
-            name = parser.stream.expect('name')
+            name = parser.stream.expect("name")
             if name.value in variables:
-                parser.fail('translatable variable %r defined twice.' %
-                            name.value, name.lineno,
-                            exc=TemplateAssertionError)
+                parser.fail(
+                    "translatable variable %r defined twice." % name.value,
+                    name.lineno,
+                    exc=TemplateAssertionError,
+                )
 
             # expressions
-            if parser.stream.current.type == 'assign':
+            if parser.stream.current.type == "assign":
                 next(parser.stream)
                 variables[name.value] = var = parser.parse_expression()
-            elif trimmed is None and name.value in ('trimmed', 'notrimmed'):
-                trimmed = name.value == 'trimmed'
+            elif trimmed is None and name.value in ("trimmed", "notrimmed"):
+                trimmed = name.value == "trimmed"
                 continue
             else:
-                variables[name.value] = var = nodes.Name(name.value, 'load')
+                variables[name.value] = var = nodes.Name(name.value, "load")
 
             if plural_expr is None:
                 if isinstance(var, nodes.Call):
-                    plural_expr = nodes.Name('_trans', 'load')
+                    plural_expr = nodes.Name("_trans", "load")
                     variables[name.value] = plural_expr
                     plural_expr_assignment = nodes.Assign(
-                        nodes.Name('_trans', 'store'), var)
+                        nodes.Name("_trans", "store"), var
+                    )
                 else:
                     plural_expr = var
-                num_called_num = name.value == 'num'
+                num_called_num = name.value == "num"
 
-        parser.stream.expect('block_end')
+        parser.stream.expect("block_end")
 
         plural = None
         have_plural = False
@@ -271,22 +286,24 @@ class InternationalizationExtension(Extension):
         if singular_names:
             referenced.update(singular_names)
             if plural_expr is None:
-                plural_expr = nodes.Name(singular_names[0], 'load')
-                num_called_num = singular_names[0] == 'num'
+                plural_expr = nodes.Name(singular_names[0], "load")
+                num_called_num = singular_names[0] == "num"
 
         # if we have a pluralize block, we parse that too
-        if parser.stream.current.test('name:pluralize'):
+        if parser.stream.current.test("name:pluralize"):
             have_plural = True
             next(parser.stream)
-            if parser.stream.current.type != 'block_end':
-                name = parser.stream.expect('name')
+            if parser.stream.current.type != "block_end":
+                name = parser.stream.expect("name")
                 if name.value not in variables:
-                    parser.fail('unknown variable %r for pluralization' %
-                                name.value, name.lineno,
-                                exc=TemplateAssertionError)
+                    parser.fail(
+                        "unknown variable %r for pluralization" % name.value,
+                        name.lineno,
+                        exc=TemplateAssertionError,
+                    )
                 plural_expr = variables[name.value]
-                num_called_num = name.value == 'num'
-            parser.stream.expect('block_end')
+                num_called_num = name.value == "num"
+            parser.stream.expect("block_end")
             plural_names, plural = self._parse_block(parser, False)
             next(parser.stream)
             referenced.update(plural_names)
@@ -296,88 +313,97 @@ class InternationalizationExtension(Extension):
         # register free names as simple name expressions
         for var in referenced:
             if var not in variables:
-                variables[var] = nodes.Name(var, 'load')
+                variables[var] = nodes.Name(var, "load")
 
         if not have_plural:
             plural_expr = None
         elif plural_expr is None:
-            parser.fail('pluralize without variables', lineno)
+            parser.fail("pluralize without variables", lineno)
 
         if trimmed is None:
-            trimmed = self.environment.policies['ext.i18n.trimmed']
+            trimmed = self.environment.policies["ext.i18n.trimmed"]
         if trimmed:
             singular = self._trim_whitespace(singular)
             if plural:
                 plural = self._trim_whitespace(plural)
 
-        node = self._make_node(singular, plural, variables, plural_expr,
-                               bool(referenced),
-                               num_called_num and have_plural)
+        node = self._make_node(
+            singular,
+            plural,
+            variables,
+            plural_expr,
+            bool(referenced),
+            num_called_num and have_plural,
+        )
         node.set_lineno(lineno)
         if plural_expr_assignment is not None:
             return [plural_expr_assignment, node]
         else:
             return node
 
-    def _trim_whitespace(self, string, _ws_re=re.compile(r'\s*\n\s*')):
-        return _ws_re.sub(' ', string.strip())
+    def _trim_whitespace(self, string, _ws_re=_ws_re):
+        return _ws_re.sub(" ", string.strip())
 
     def _parse_block(self, parser, allow_pluralize):
         """Parse until the next block tag with a given name."""
         referenced = []
         buf = []
         while 1:
-            if parser.stream.current.type == 'data':
-                buf.append(parser.stream.current.value.replace('%', '%%'))
+            if parser.stream.current.type == "data":
+                buf.append(parser.stream.current.value.replace("%", "%%"))
                 next(parser.stream)
-            elif parser.stream.current.type == 'variable_begin':
+            elif parser.stream.current.type == "variable_begin":
                 next(parser.stream)
-                name = parser.stream.expect('name').value
+                name = parser.stream.expect("name").value
                 referenced.append(name)
-                buf.append('%%(%s)s' % name)
-                parser.stream.expect('variable_end')
-            elif parser.stream.current.type == 'block_begin':
+                buf.append("%%(%s)s" % name)
+                parser.stream.expect("variable_end")
+            elif parser.stream.current.type == "block_begin":
                 next(parser.stream)
-                if parser.stream.current.test('name:endtrans'):
+                if parser.stream.current.test("name:endtrans"):
                     break
-                elif parser.stream.current.test('name:pluralize'):
+                elif parser.stream.current.test("name:pluralize"):
                     if allow_pluralize:
                         break
-                    parser.fail('a translatable section can have only one '
-                                'pluralize section')
-                parser.fail('control structures in translatable sections are '
-                            'not allowed')
+                    parser.fail(
+                        "a translatable section can have only one pluralize section"
+                    )
+                parser.fail(
+                    "control structures in translatable sections are not allowed"
+                )
             elif parser.stream.eos:
-                parser.fail('unclosed translation block')
+                parser.fail("unclosed translation block")
             else:
-                assert False, 'internal parser error'
+                raise RuntimeError("internal parser error")
 
         return referenced, concat(buf)
 
-    def _make_node(self, singular, plural, variables, plural_expr,
-                   vars_referenced, num_called_num):
+    def _make_node(
+        self, singular, plural, variables, plural_expr, vars_referenced, num_called_num
+    ):
         """Generates a useful node from the data provided."""
         # no variables referenced?  no need to escape for old style
         # gettext invocations only if there are vars.
         if not vars_referenced and not self.environment.newstyle_gettext:
-            singular = singular.replace('%%', '%')
+            singular = singular.replace("%%", "%")
             if plural:
-                plural = plural.replace('%%', '%')
+                plural = plural.replace("%%", "%")
 
         # singular only:
         if plural_expr is None:
-            gettext = nodes.Name('gettext', 'load')
-            node = nodes.Call(gettext, [nodes.Const(singular)],
-                              [], None, None)
+            gettext = nodes.Name("gettext", "load")
+            node = nodes.Call(gettext, [nodes.Const(singular)], [], None, None)
 
         # singular and plural
         else:
-            ngettext = nodes.Name('ngettext', 'load')
-            node = nodes.Call(ngettext, [
-                nodes.Const(singular),
-                nodes.Const(plural),
-                plural_expr
-            ], [], None, None)
+            ngettext = nodes.Name("ngettext", "load")
+            node = nodes.Call(
+                ngettext,
+                [nodes.Const(singular), nodes.Const(plural), plural_expr],
+                [],
+                None,
+                None,
+            )
 
         # in case newstyle gettext is used, the method is powerful
         # enough to handle the variable expansion and autoescape
@@ -386,7 +412,7 @@ class InternationalizationExtension(Extension):
             for key, value in iteritems(variables):
                 # the function adds that later anyways in case num was
                 # called num, so just skip it.
-                if num_called_num and key == 'num':
+                if num_called_num and key == "num":
                     continue
                 node.kwargs.append(nodes.Keyword(key, value))
 
@@ -396,18 +422,24 @@ class InternationalizationExtension(Extension):
             # environment with autoescaping turned on
             node = nodes.MarkSafeIfAutoescape(node)
             if variables:
-                node = nodes.Mod(node, nodes.Dict([
-                    nodes.Pair(nodes.Const(key), value)
-                    for key, value in variables.items()
-                ]))
+                node = nodes.Mod(
+                    node,
+                    nodes.Dict(
+                        [
+                            nodes.Pair(nodes.Const(key), value)
+                            for key, value in variables.items()
+                        ]
+                    ),
+                )
         return nodes.Output([node])
 
 
 class ExprStmtExtension(Extension):
-    """Adds a `do` tag to Jinja2 that works like the print statement just
+    """Adds a `do` tag to Jinja that works like the print statement just
     that it doesn't print the return value.
     """
-    tags = set(['do'])
+
+    tags = set(["do"])
 
     def parse(self, parser):
         node = nodes.ExprStmt(lineno=next(parser.stream).lineno)
@@ -417,11 +449,12 @@ class ExprStmtExtension(Extension):
 
 class LoopControlExtension(Extension):
     """Adds break and continue to the template engine."""
-    tags = set(['break', 'continue'])
+
+    tags = set(["break", "continue"])
 
     def parse(self, parser):
         token = next(parser.stream)
-        if token.value == 'break':
+        if token.value == "break":
             return nodes.Break(lineno=token.lineno)
         return nodes.Continue(lineno=token.lineno)
 
@@ -434,8 +467,50 @@ class AutoEscapeExtension(Extension):
     pass
 
 
-def extract_from_ast(node, gettext_functions=GETTEXT_FUNCTIONS,
-                     babel_style=True):
+class DebugExtension(Extension):
+    """A ``{% debug %}`` tag that dumps the available variables,
+    filters, and tests.
+
+    .. code-block:: html+jinja
+
+        <pre>{% debug %}</pre>
+
+    .. code-block:: text
+
+        {'context': {'cycler': <class 'jinja2.utils.Cycler'>,
+                     ...,
+                     'namespace': <class 'jinja2.utils.Namespace'>},
+         'filters': ['abs', 'attr', 'batch', 'capitalize', 'center', 'count', 'd',
+                     ..., 'urlencode', 'urlize', 'wordcount', 'wordwrap', 'xmlattr'],
+         'tests': ['!=', '<', '<=', '==', '>', '>=', 'callable', 'defined',
+                   ..., 'odd', 'sameas', 'sequence', 'string', 'undefined', 'upper']}
+
+    .. versionadded:: 2.11.0
+    """
+
+    tags = {"debug"}
+
+    def parse(self, parser):
+        lineno = parser.stream.expect("name:debug").lineno
+        context = ContextReference()
+        result = self.call_method("_render", [context], lineno=lineno)
+        return nodes.Output([result], lineno=lineno)
+
+    def _render(self, context):
+        result = {
+            "context": context.get_all(),
+            "filters": sorted(self.environment.filters.keys()),
+            "tests": sorted(self.environment.tests.keys()),
+        }
+
+        # Set the depth since the intent is to show the top few names.
+        if version_info[:2] >= (3, 4):
+            return pprint.pformat(result, depth=3, compact=True)
+        else:
+            return pprint.pformat(result, depth=3)
+
+
+def extract_from_ast(node, gettext_functions=GETTEXT_FUNCTIONS, babel_style=True):
     """Extract localizable strings from the given template node.  Per
     default this function returns matches in babel style that means non string
     parameters as well as keyword arguments are returned as `None`.  This
@@ -471,19 +546,20 @@ def extract_from_ast(node, gettext_functions=GETTEXT_FUNCTIONS,
     extraction interface or extract comments yourself.
     """
     for node in node.find_all(nodes.Call):
-        if not isinstance(node.node, nodes.Name) or \
-           node.node.name not in gettext_functions:
+        if (
+            not isinstance(node.node, nodes.Name)
+            or node.node.name not in gettext_functions
+        ):
             continue
 
         strings = []
         for arg in node.args:
-            if isinstance(arg, nodes.Const) and \
-               isinstance(arg.value, string_types):
+            if isinstance(arg, nodes.Const) and isinstance(arg.value, string_types):
                 strings.append(arg.value)
             else:
                 strings.append(None)
 
-        for arg in node.kwargs:
+        for _ in node.kwargs:
             strings.append(None)
         if node.dyn_args is not None:
             strings.append(None)
@@ -517,9 +593,10 @@ class _CommentFinder(object):
 
     def find_backwards(self, offset):
         try:
-            for _, token_type, token_value in \
-                    reversed(self.tokens[self.offset:offset]):
-                if token_type in ('comment', 'linecomment'):
+            for _, token_type, token_value in reversed(
+                self.tokens[self.offset : offset]
+            ):
+                if token_type in ("comment", "linecomment"):
                     try:
                         prefix, comment = token_value.split(None, 1)
                     except ValueError:
@@ -533,7 +610,7 @@ class _CommentFinder(object):
     def find_comments(self, lineno):
         if not self.comment_tags or self.last_lineno > lineno:
             return []
-        for idx, (token_lineno, _, _) in enumerate(self.tokens[self.offset:]):
+        for idx, (token_lineno, _, _) in enumerate(self.tokens[self.offset :]):
             if token_lineno > lineno:
                 return self.find_backwards(self.offset + idx)
         return self.find_backwards(len(self.tokens))
@@ -545,7 +622,7 @@ def babel_extract(fileobj, keywords, comment_tags, options):
     .. versionchanged:: 2.3
        Basic support for translation comments was added.  If `comment_tags`
        is now set to a list of keywords for extraction, the extractor will
-       try to find the best preceeding comment that begins with one of the
+       try to find the best preceding comment that begins with one of the
        keywords.  For best results, make sure to not have more than one
        gettext call in one line of code and the matching comment in the
        same line or the line before.
@@ -568,7 +645,7 @@ def babel_extract(fileobj, keywords, comment_tags, options):
              (comments will be empty currently)
     """
     extensions = set()
-    for extension in options.get('extensions', '').split(','):
+    for extension in options.get("extensions", "").split(","):
         extension = extension.strip()
         if not extension:
             continue
@@ -577,38 +654,37 @@ def babel_extract(fileobj, keywords, comment_tags, options):
         extensions.add(InternationalizationExtension)
 
     def getbool(options, key, default=False):
-        return options.get(key, str(default)).lower() in \
-            ('1', 'on', 'yes', 'true')
+        return options.get(key, str(default)).lower() in ("1", "on", "yes", "true")
 
-    silent = getbool(options, 'silent', True)
+    silent = getbool(options, "silent", True)
     environment = Environment(
-        options.get('block_start_string', BLOCK_START_STRING),
-        options.get('block_end_string', BLOCK_END_STRING),
-        options.get('variable_start_string', VARIABLE_START_STRING),
-        options.get('variable_end_string', VARIABLE_END_STRING),
-        options.get('comment_start_string', COMMENT_START_STRING),
-        options.get('comment_end_string', COMMENT_END_STRING),
-        options.get('line_statement_prefix') or LINE_STATEMENT_PREFIX,
-        options.get('line_comment_prefix') or LINE_COMMENT_PREFIX,
-        getbool(options, 'trim_blocks', TRIM_BLOCKS),
-        getbool(options, 'lstrip_blocks', LSTRIP_BLOCKS),
+        options.get("block_start_string", BLOCK_START_STRING),
+        options.get("block_end_string", BLOCK_END_STRING),
+        options.get("variable_start_string", VARIABLE_START_STRING),
+        options.get("variable_end_string", VARIABLE_END_STRING),
+        options.get("comment_start_string", COMMENT_START_STRING),
+        options.get("comment_end_string", COMMENT_END_STRING),
+        options.get("line_statement_prefix") or LINE_STATEMENT_PREFIX,
+        options.get("line_comment_prefix") or LINE_COMMENT_PREFIX,
+        getbool(options, "trim_blocks", TRIM_BLOCKS),
+        getbool(options, "lstrip_blocks", LSTRIP_BLOCKS),
         NEWLINE_SEQUENCE,
-        getbool(options, 'keep_trailing_newline', KEEP_TRAILING_NEWLINE),
+        getbool(options, "keep_trailing_newline", KEEP_TRAILING_NEWLINE),
         frozenset(extensions),
         cache_size=0,
-        auto_reload=False
+        auto_reload=False,
     )
 
-    if getbool(options, 'trimmed'):
-        environment.policies['ext.i18n.trimmed'] = True
-    if getbool(options, 'newstyle_gettext'):
+    if getbool(options, "trimmed"):
+        environment.policies["ext.i18n.trimmed"] = True
+    if getbool(options, "newstyle_gettext"):
         environment.newstyle_gettext = True
 
-    source = fileobj.read().decode(options.get('encoding', 'utf-8'))
+    source = fileobj.read().decode(options.get("encoding", "utf-8"))
     try:
         node = environment.parse(source)
         tokens = list(environment.lex(environment.preprocess(source)))
-    except TemplateSyntaxError as e:
+    except TemplateSyntaxError:
         if not silent:
             raise
         # skip templates with syntax errors
@@ -625,3 +701,4 @@ do = ExprStmtExtension
 loopcontrols = LoopControlExtension
 with_ = WithExtension
 autoescape = AutoEscapeExtension
+debug = DebugExtension
diff --git a/pipenv/vendor/jinja2/filters.py b/pipenv/vendor/jinja2/filters.py
index 267dddda..1af7ac88 100644
--- a/pipenv/vendor/jinja2/filters.py
+++ b/pipenv/vendor/jinja2/filters.py
@@ -1,29 +1,31 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.filters
-    ~~~~~~~~~~~~~~
-
-    Bundled jinja filters.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
-import re
+"""Built-in template filters used with the ``|`` operator."""
 import math
 import random
+import re
 import warnings
-
-from itertools import groupby, chain
 from collections import namedtuple
-from jinja2.utils import Markup, escape, pformat, urlize, soft_unicode, \
-     unicode_urlencode, htmlsafe_json_dumps
-from jinja2.runtime import Undefined
-from jinja2.exceptions import FilterArgumentError
-from jinja2._compat import imap, string_types, text_type, iteritems, PY2
+from itertools import chain
+from itertools import groupby
+
+from markupsafe import escape
+from markupsafe import Markup
+from markupsafe import soft_unicode
 
+from ._compat import abc
+from ._compat import imap
+from ._compat import iteritems
+from ._compat import string_types
+from ._compat import text_type
+from .exceptions import FilterArgumentError
+from .runtime import Undefined
+from .utils import htmlsafe_json_dumps
+from .utils import pformat
+from .utils import unicode_urlencode
+from .utils import urlize
 
-_word_re = re.compile(r'\w+', re.UNICODE)
-_word_beginning_split_re = re.compile(r'([-\s\(\{\[\<]+)', re.UNICODE)
+_word_re = re.compile(r"\w+", re.UNICODE)
+_word_beginning_split_re = re.compile(r"([-\s\(\{\[\<]+)", re.UNICODE)
 
 
 def contextfilter(f):
@@ -59,23 +61,21 @@ def ignore_case(value):
     return value.lower() if isinstance(value, string_types) else value
 
 
-def make_attrgetter(environment, attribute, postprocess=None):
+def make_attrgetter(environment, attribute, postprocess=None, default=None):
     """Returns a callable that looks up the given attribute from a
     passed object with the rules of the environment.  Dots are allowed
     to access attributes of attributes.  Integer parts in paths are
     looked up as integers.
     """
-    if attribute is None:
-        attribute = []
-    elif isinstance(attribute, string_types):
-        attribute = [int(x) if x.isdigit() else x for x in attribute.split('.')]
-    else:
-        attribute = [attribute]
+    attribute = _prepare_attribute_parts(attribute)
 
     def attrgetter(item):
         for part in attribute:
             item = environment.getitem(item, part)
 
+            if default and isinstance(item, Undefined):
+                item = default
+
         if postprocess is not None:
             item = postprocess(item)
 
@@ -84,32 +84,84 @@ def make_attrgetter(environment, attribute, postprocess=None):
     return attrgetter
 
 
+def make_multi_attrgetter(environment, attribute, postprocess=None):
+    """Returns a callable that looks up the given comma separated
+    attributes from a passed object with the rules of the environment.
+    Dots are allowed to access attributes of each attribute.  Integer
+    parts in paths are looked up as integers.
+
+    The value returned by the returned callable is a list of extracted
+    attribute values.
+
+    Examples of attribute: "attr1,attr2", "attr1.inner1.0,attr2.inner2.0", etc.
+    """
+    attribute_parts = (
+        attribute.split(",") if isinstance(attribute, string_types) else [attribute]
+    )
+    attribute = [
+        _prepare_attribute_parts(attribute_part) for attribute_part in attribute_parts
+    ]
+
+    def attrgetter(item):
+        items = [None] * len(attribute)
+        for i, attribute_part in enumerate(attribute):
+            item_i = item
+            for part in attribute_part:
+                item_i = environment.getitem(item_i, part)
+
+            if postprocess is not None:
+                item_i = postprocess(item_i)
+
+            items[i] = item_i
+        return items
+
+    return attrgetter
+
+
+def _prepare_attribute_parts(attr):
+    if attr is None:
+        return []
+    elif isinstance(attr, string_types):
+        return [int(x) if x.isdigit() else x for x in attr.split(".")]
+    else:
+        return [attr]
+
+
 def do_forceescape(value):
     """Enforce HTML escaping.  This will probably double escape variables."""
-    if hasattr(value, '__html__'):
+    if hasattr(value, "__html__"):
         value = value.__html__()
     return escape(text_type(value))
 
 
 def do_urlencode(value):
-    """Escape strings for use in URLs (uses UTF-8 encoding).  It accepts both
-    dictionaries and regular strings as well as pairwise iterables.
+    """Quote data for use in a URL path or query using UTF-8.
+
+    Basic wrapper around :func:`urllib.parse.quote` when given a
+    string, or :func:`urllib.parse.urlencode` for a dict or iterable.
+
+    :param value: Data to quote. A string will be quoted directly. A
+        dict or iterable of ``(key, value)`` pairs will be joined as a
+        query string.
+
+    When given a string, "/" is not quoted. HTTP servers treat "/" and
+    "%2F" equivalently in paths. If you need quoted slashes, use the
+    ``|replace("/", "%2F")`` filter.
 
     .. versionadded:: 2.7
     """
-    itemiter = None
-    if isinstance(value, dict):
-        itemiter = iteritems(value)
-    elif not isinstance(value, string_types):
-        try:
-            itemiter = iter(value)
-        except TypeError:
-            pass
-    if itemiter is None:
+    if isinstance(value, string_types) or not isinstance(value, abc.Iterable):
         return unicode_urlencode(value)
-    return u'&'.join(unicode_urlencode(k) + '=' +
-                     unicode_urlencode(v, for_qs=True)
-                     for k, v in itemiter)
+
+    if isinstance(value, dict):
+        items = iteritems(value)
+    else:
+        items = iter(value)
+
+    return u"&".join(
+        "%s=%s" % (unicode_urlencode(k, for_qs=True), unicode_urlencode(v, for_qs=True))
+        for k, v in items
+    )
 
 
 @evalcontextfilter
@@ -132,8 +184,11 @@ def do_replace(eval_ctx, s, old, new, count=None):
         count = -1
     if not eval_ctx.autoescape:
         return text_type(s).replace(text_type(old), text_type(new), count)
-    if hasattr(old, '__html__') or hasattr(new, '__html__') and \
-       not hasattr(s, '__html__'):
+    if (
+        hasattr(old, "__html__")
+        or hasattr(new, "__html__")
+        and not hasattr(s, "__html__")
+    ):
         s = escape(s)
     else:
         s = soft_unicode(s)
@@ -174,13 +229,13 @@ def do_xmlattr(_eval_ctx, d, autospace=True):
     As you can see it automatically prepends a space in front of the item
     if the filter returned something unless the second parameter is false.
     """
-    rv = u' '.join(
+    rv = u" ".join(
         u'%s="%s"' % (escape(key), escape(value))
         for key, value in iteritems(d)
         if value is not None and not isinstance(value, Undefined)
     )
     if autospace and rv:
-        rv = u' ' + rv
+        rv = u" " + rv
     if _eval_ctx.autoescape:
         rv = Markup(rv)
     return rv
@@ -197,13 +252,16 @@ def do_title(s):
     """Return a titlecased version of the value. I.e. words will start with
     uppercase letters, all remaining characters are lowercase.
     """
-    return ''.join(
-        [item[0].upper() + item[1:].lower()
-         for item in _word_beginning_split_re.split(soft_unicode(s))
-         if item])
+    return "".join(
+        [
+            item[0].upper() + item[1:].lower()
+            for item in _word_beginning_split_re.split(soft_unicode(s))
+            if item
+        ]
+    )
 
 
-def do_dictsort(value, case_sensitive=False, by='key', reverse=False):
+def do_dictsort(value, case_sensitive=False, by="key", reverse=False):
     """Sort a dict and yield (key, value) pairs. Because python dicts are
     unsorted you may want to use this function to order them by either
     key or value:
@@ -222,14 +280,12 @@ def do_dictsort(value, case_sensitive=False, by='key', reverse=False):
         {% for item in mydict|dictsort(false, 'value') %}
             sort the dict by value, case insensitive
     """
-    if by == 'key':
+    if by == "key":
         pos = 0
-    elif by == 'value':
+    elif by == "value":
         pos = 1
     else:
-        raise FilterArgumentError(
-            'You can only sort by either "key" or "value"'
-        )
+        raise FilterArgumentError('You can only sort by either "key" or "value"')
 
     def sort_func(item):
         value = item[pos]
@@ -243,48 +299,62 @@ def do_dictsort(value, case_sensitive=False, by='key', reverse=False):
 
 
 @environmentfilter
-def do_sort(
-    environment, value, reverse=False, case_sensitive=False, attribute=None
-):
-    """Sort an iterable.  Per default it sorts ascending, if you pass it
-    true as first argument it will reverse the sorting.
+def do_sort(environment, value, reverse=False, case_sensitive=False, attribute=None):
+    """Sort an iterable using Python's :func:`sorted`.
+
+    .. sourcecode:: jinja
+
+        {% for city in cities|sort %}
+            ...
+        {% endfor %}
 
-    If the iterable is made of strings the third parameter can be used to
-    control the case sensitiveness of the comparison which is disabled by
-    default.
+    :param reverse: Sort descending instead of ascending.
+    :param case_sensitive: When sorting strings, sort upper and lower
+        case separately.
+    :param attribute: When sorting objects or dicts, an attribute or
+        key to sort by. Can use dot notation like ``"address.city"``.
+        Can be a list of attributes like ``"age,name"``.
+
+    The sort is stable, it does not change the relative order of
+    elements that compare equal. This makes it is possible to chain
+    sorts on different attributes and ordering.
 
     .. sourcecode:: jinja
 
-        {% for item in iterable|sort %}
+        {% for user in users|sort(attribute="name")
+            |sort(reverse=true, attribute="age") %}
             ...
         {% endfor %}
 
-    It is also possible to sort by an attribute (for example to sort
-    by the date of an object) by specifying the `attribute` parameter:
+    As a shortcut to chaining when the direction is the same for all
+    attributes, pass a comma separate list of attributes.
 
     .. sourcecode:: jinja
 
-        {% for item in iterable|sort(attribute='date') %}
+        {% for user users|sort(attribute="age,name") %}
             ...
         {% endfor %}
 
+    .. versionchanged:: 2.11.0
+        The ``attribute`` parameter can be a comma separated list of
+        attributes, e.g. ``"age,name"``.
+
     .. versionchanged:: 2.6
-       The `attribute` parameter was added.
+       The ``attribute`` parameter was added.
     """
-    key_func = make_attrgetter(
-        environment, attribute,
-        postprocess=ignore_case if not case_sensitive else None
+    key_func = make_multi_attrgetter(
+        environment, attribute, postprocess=ignore_case if not case_sensitive else None
     )
     return sorted(value, key=key_func, reverse=reverse)
 
 
 @environmentfilter
 def do_unique(environment, value, case_sensitive=False, attribute=None):
-    """Returns a list of unique items from the the given iterable.
+    """Returns a list of unique items from the given iterable.
 
     .. sourcecode:: jinja
 
-        {{ ['foo', 'bar', 'foobar', 'FooBar']|unique }}
+        {{ ['foo', 'bar', 'foobar', 'FooBar']|unique|list }}
             -> ['foo', 'bar', 'foobar']
 
     The unique items are yielded in the same order as their first occurrence in
@@ -294,8 +364,7 @@ def do_unique(environment, value, case_sensitive=False, attribute=None):
     :param attribute: Filter objects with unique values for this attribute.
     """
     getter = make_attrgetter(
-        environment, attribute,
-        postprocess=ignore_case if not case_sensitive else None
+        environment, attribute, postprocess=ignore_case if not case_sensitive else None
     )
     seen = set()
 
@@ -313,11 +382,10 @@ def _min_or_max(environment, value, func, case_sensitive, attribute):
     try:
         first = next(it)
     except StopIteration:
-        return environment.undefined('No aggregated item, sequence was empty.')
+        return environment.undefined("No aggregated item, sequence was empty.")
 
     key_func = make_attrgetter(
-        environment, attribute,
-        ignore_case if not case_sensitive else None
+        environment, attribute, postprocess=ignore_case if not case_sensitive else None
     )
     return func(chain([first], it), key=key_func)
 
@@ -332,7 +400,7 @@ def do_min(environment, value, case_sensitive=False, attribute=None):
             -> 1
 
     :param case_sensitive: Treat upper and lower case strings as distinct.
-    :param attribute: Get the object with the max value of this attribute.
+    :param attribute: Get the object with the min value of this attribute.
     """
     return _min_or_max(environment, value, min, case_sensitive, attribute)
 
@@ -352,7 +420,7 @@ def do_max(environment, value, case_sensitive=False, attribute=None):
     return _min_or_max(environment, value, max, case_sensitive, attribute)
 
 
-def do_default(value, default_value=u'', boolean=False):
+def do_default(value, default_value=u"", boolean=False):
     """If the value is undefined it will return the passed default value,
     otherwise the value of the variable:
 
@@ -368,6 +436,12 @@ def do_default(value, default_value=u'', boolean=False):
     .. sourcecode:: jinja
 
         {{ ''|default('the string was empty', true) }}
+
+    .. versionchanged:: 2.11
+       It's now possible to configure the :class:`~jinja2.Environment` with
+       :class:`~jinja2.ChainableUndefined` to make the `default` filter work
+       on nested elements and attributes that may contain undefined values
+       in the chain without getting an :exc:`~jinja2.UndefinedError`.
     """
     if isinstance(value, Undefined) or (boolean and not value):
         return default_value
@@ -375,7 +449,7 @@ def do_default(value, default_value=u'', boolean=False):
 
 
 @evalcontextfilter
-def do_join(eval_ctx, value, d=u'', attribute=None):
+def do_join(eval_ctx, value, d=u"", attribute=None):
     """Return a string which is the concatenation of the strings in the
     sequence. The separator between elements is an empty string per
     default, you can define it with the optional parameter:
@@ -400,17 +474,17 @@ def do_join(eval_ctx, value, d=u'', attribute=None):
     if attribute is not None:
         value = imap(make_attrgetter(eval_ctx.environment, attribute), value)
 
-    # no automatic escaping?  joining is a lot eaiser then
+    # no automatic escaping?  joining is a lot easier then
     if not eval_ctx.autoescape:
         return text_type(d).join(imap(text_type, value))
 
     # if the delimiter doesn't have an html representation we check
     # if any of the items has.  If yes we do a coercion to Markup
-    if not hasattr(d, '__html__'):
+    if not hasattr(d, "__html__"):
         value = list(value)
         do_escape = False
         for idx, item in enumerate(value):
-            if hasattr(item, '__html__'):
+            if hasattr(item, "__html__"):
                 do_escape = True
             else:
                 value[idx] = text_type(item)
@@ -435,16 +509,25 @@ def do_first(environment, seq):
     try:
         return next(iter(seq))
     except StopIteration:
-        return environment.undefined('No first item, sequence was empty.')
+        return environment.undefined("No first item, sequence was empty.")
 
 
 @environmentfilter
 def do_last(environment, seq):
-    """Return the last item of a sequence."""
+    """
+    Return the last item of a sequence.
+
+    Note: Does not work with generators. You may want to explicitly
+    convert it to a list:
+
+    .. sourcecode:: jinja
+
+        {{ data | selectattr('name', '==', 'Jinja') | list | last }}
+    """
     try:
         return next(iter(reversed(seq)))
     except StopIteration:
-        return environment.undefined('No last item, sequence was empty.')
+        return environment.undefined("No last item, sequence was empty.")
 
 
 @contextfilter
@@ -453,7 +536,7 @@ def do_random(context, seq):
     try:
         return random.choice(seq)
     except IndexError:
-        return context.environment.undefined('No random item, sequence was empty.')
+        return context.environment.undefined("No random item, sequence was empty.")
 
 
 def do_filesizeformat(value, binary=False):
@@ -465,25 +548,25 @@ def do_filesizeformat(value, binary=False):
     bytes = float(value)
     base = binary and 1024 or 1000
     prefixes = [
-        (binary and 'KiB' or 'kB'),
-        (binary and 'MiB' or 'MB'),
-        (binary and 'GiB' or 'GB'),
-        (binary and 'TiB' or 'TB'),
-        (binary and 'PiB' or 'PB'),
-        (binary and 'EiB' or 'EB'),
-        (binary and 'ZiB' or 'ZB'),
-        (binary and 'YiB' or 'YB')
+        (binary and "KiB" or "kB"),
+        (binary and "MiB" or "MB"),
+        (binary and "GiB" or "GB"),
+        (binary and "TiB" or "TB"),
+        (binary and "PiB" or "PB"),
+        (binary and "EiB" or "EB"),
+        (binary and "ZiB" or "ZB"),
+        (binary and "YiB" or "YB"),
     ]
     if bytes == 1:
-        return '1 Byte'
+        return "1 Byte"
     elif bytes < base:
-        return '%d Bytes' % bytes
+        return "%d Bytes" % bytes
     else:
         for i, prefix in enumerate(prefixes):
             unit = base ** (i + 2)
             if bytes < unit:
-                return '%.1f %s' % ((base * bytes / unit), prefix)
-        return '%.1f %s' % ((base * bytes / unit), prefix)
+                return "%.1f %s" % ((base * bytes / unit), prefix)
+        return "%.1f %s" % ((base * bytes / unit), prefix)
 
 
 def do_pprint(value, verbose=False):
@@ -496,8 +579,9 @@ def do_pprint(value, verbose=False):
 
 
 @evalcontextfilter
-def do_urlize(eval_ctx, value, trim_url_limit=None, nofollow=False,
-              target=None, rel=None):
+def do_urlize(
+    eval_ctx, value, trim_url_limit=None, nofollow=False, target=None, rel=None
+):
     """Converts URLs in plain text into clickable links.
 
     If you pass the filter an additional integer it will shorten the urls
@@ -520,22 +604,20 @@ def do_urlize(eval_ctx, value, trim_url_limit=None, nofollow=False,
        The *target* parameter was added.
     """
     policies = eval_ctx.environment.policies
-    rel = set((rel or '').split() or [])
+    rel = set((rel or "").split() or [])
     if nofollow:
-        rel.add('nofollow')
-    rel.update((policies['urlize.rel'] or '').split())
+        rel.add("nofollow")
+    rel.update((policies["urlize.rel"] or "").split())
     if target is None:
-        target = policies['urlize.target']
-    rel = ' '.join(sorted(rel)) or None
+        target = policies["urlize.target"]
+    rel = " ".join(sorted(rel)) or None
     rv = urlize(value, trim_url_limit, rel=rel, target=target)
     if eval_ctx.autoescape:
         rv = Markup(rv)
     return rv
 
 
-def do_indent(
-    s, width=4, first=False, blank=False, indentfirst=None
-):
+def do_indent(s, width=4, first=False, blank=False, indentfirst=None):
     """Return a copy of the string with each line indented by 4 spaces. The
     first line and blank lines are not indented by default.
 
@@ -549,22 +631,31 @@ def do_indent(
         Rename the ``indentfirst`` argument to ``first``.
     """
     if indentfirst is not None:
-        warnings.warn(DeprecationWarning(
-            'The "indentfirst" argument is renamed to "first".'
-        ), stacklevel=2)
+        warnings.warn(
+            "The 'indentfirst' argument is renamed to 'first' and will"
+            " be removed in version 3.0.",
+            DeprecationWarning,
+            stacklevel=2,
+        )
         first = indentfirst
 
-    s += u'\n'  # this quirk is necessary for splitlines method
-    indention = u' ' * width
+    indention = u" " * width
+    newline = u"\n"
+
+    if isinstance(s, Markup):
+        indention = Markup(indention)
+        newline = Markup(newline)
+
+    s += newline  # this quirk is necessary for splitlines method
 
     if blank:
-        rv = (u'\n' + indention).join(s.splitlines())
+        rv = (newline + indention).join(s.splitlines())
     else:
         lines = s.splitlines()
         rv = lines.pop(0)
 
         if lines:
-            rv += u'\n' + u'\n'.join(
+            rv += newline + newline.join(
                 indention + line if line else line for line in lines
             )
 
@@ -575,7 +666,7 @@ def do_indent(
 
 
 @environmentfilter
-def do_truncate(env, s, length=255, killwords=False, end='...', leeway=None):
+def do_truncate(env, s, length=255, killwords=False, end="...", leeway=None):
     """Return a truncated copy of the string. The length is specified
     with the first parameter which defaults to ``255``. If the second
     parameter is ``true`` the filter will cut the text at length. Otherwise
@@ -596,41 +687,76 @@ def do_truncate(env, s, length=255, killwords=False, end='...', leeway=None):
         {{ "foo bar baz qux"|truncate(11, False, '...', 0) }}
             -> "foo bar..."
 
-    The default leeway on newer Jinja2 versions is 5 and was 0 before but
+    The default leeway on newer Jinja versions is 5 and was 0 before but
     can be reconfigured globally.
     """
     if leeway is None:
-        leeway = env.policies['truncate.leeway']
-    assert length >= len(end), 'expected length >= %s, got %s' % (len(end), length)
-    assert leeway >= 0, 'expected leeway >= 0, got %s' % leeway
+        leeway = env.policies["truncate.leeway"]
+    assert length >= len(end), "expected length >= %s, got %s" % (len(end), length)
+    assert leeway >= 0, "expected leeway >= 0, got %s" % leeway
     if len(s) <= length + leeway:
         return s
     if killwords:
-        return s[:length - len(end)] + end
-    result = s[:length - len(end)].rsplit(' ', 1)[0]
+        return s[: length - len(end)] + end
+    result = s[: length - len(end)].rsplit(" ", 1)[0]
     return result + end
 
 
 @environmentfilter
-def do_wordwrap(environment, s, width=79, break_long_words=True,
-                wrapstring=None):
+def do_wordwrap(
+    environment,
+    s,
+    width=79,
+    break_long_words=True,
+    wrapstring=None,
+    break_on_hyphens=True,
+):
+    """Wrap a string to the given width. Existing newlines are treated
+    as paragraphs to be wrapped separately.
+
+    :param s: Original text to wrap.
+    :param width: Maximum length of wrapped lines.
+    :param break_long_words: If a word is longer than ``width``, break
+        it across lines.
+    :param break_on_hyphens: If a word contains hyphens, it may be split
+        across lines.
+    :param wrapstring: String to join each wrapped line. Defaults to
+        :attr:`Environment.newline_sequence`.
+
+    .. versionchanged:: 2.11
+        Existing newlines are treated as paragraphs wrapped separately.
+
+    .. versionchanged:: 2.11
+        Added the ``break_on_hyphens`` parameter.
+
+    .. versionchanged:: 2.7
+        Added the ``wrapstring`` parameter.
     """
-    Return a copy of the string passed to the filter wrapped after
-    ``79`` characters.  You can override this default using the first
-    parameter.  If you set the second parameter to `false` Jinja will not
-    split words apart if they are longer than `width`. By default, the newlines
-    will be the default newlines for the environment, but this can be changed
-    using the wrapstring keyword argument.
 
-    .. versionadded:: 2.7
-       Added support for the `wrapstring` parameter.
-    """
+    import textwrap
+
     if not wrapstring:
         wrapstring = environment.newline_sequence
-    import textwrap
-    return wrapstring.join(textwrap.wrap(s, width=width, expand_tabs=False,
-                                   replace_whitespace=False,
-                                   break_long_words=break_long_words))
+
+    # textwrap.wrap doesn't consider existing newlines when wrapping.
+    # If the string has a newline before width, wrap will still insert
+    # a newline at width, resulting in a short line. Instead, split and
+    # wrap each paragraph individually.
+    return wrapstring.join(
+        [
+            wrapstring.join(
+                textwrap.wrap(
+                    line,
+                    width=width,
+                    expand_tabs=False,
+                    replace_whitespace=False,
+                    break_long_words=break_long_words,
+                    break_on_hyphens=break_on_hyphens,
+                )
+            )
+            for line in s.splitlines()
+        ]
+    )
 
 
 def do_wordcount(s):
@@ -671,29 +797,40 @@ def do_float(value, default=0.0):
 
 
 def do_format(value, *args, **kwargs):
-    """
-    Apply python string formatting on an object:
+    """Apply the given values to a `printf-style`_ format string, like
+    ``string % values``.
 
     .. sourcecode:: jinja
 
-        {{ "%s - %s"|format("Hello?", "Foo!") }}
-            -> Hello? - Foo!
+        {{ "%s, %s!"|format(greeting, name) }}
+        Hello, World!
+
+    In most cases it should be more convenient and efficient to use the
+    ``%`` operator or :meth:`str.format`.
+
+    .. code-block:: text
+
+        {{ "%s, %s!" % (greeting, name) }}
+        {{ "{}, {}!".format(greeting, name) }}
+
+    .. _printf-style: https://docs.python.org/library/stdtypes.html
+        #printf-style-string-formatting
     """
     if args and kwargs:
-        raise FilterArgumentError('can\'t handle positional and keyword '
-                                  'arguments at the same time')
+        raise FilterArgumentError(
+            "can't handle positional and keyword arguments at the same time"
+        )
     return soft_unicode(value) % (kwargs or args)
 
 
-def do_trim(value):
-    """Strip leading and trailing whitespace."""
-    return soft_unicode(value).strip()
+def do_trim(value, chars=None):
+    """Strip leading and trailing characters, by default whitespace."""
+    return soft_unicode(value).strip(chars)
 
 
 def do_striptags(value):
-    """Strip SGML/XML tags and replace adjacent whitespace by one space.
-    """
-    if hasattr(value, '__html__'):
+    """Strip SGML/XML tags and replace adjacent whitespace by one space."""
+    if hasattr(value, "__html__"):
         value = value.__html__()
     return Markup(text_type(value)).striptags()
 
@@ -705,7 +842,7 @@ def do_slice(value, slices, fill_with=None):
 
     .. sourcecode:: html+jinja
 
-        <div class="columwrapper">
+        <div class="columnwrapper">
           {%- for column in items|slice(3) %}
             <ul class="column-{{ loop.index }}">
             {%- for item in column %}
@@ -765,7 +902,7 @@ def do_batch(value, linecount, fill_with=None):
         yield tmp
 
 
-def do_round(value, precision=0, method='common'):
+def do_round(value, precision=0, method="common"):
     """Round the number to a given precision. The first
     parameter specifies the precision (default is ``0``), the
     second the rounding method:
@@ -791,9 +928,9 @@ def do_round(value, precision=0, method='common'):
         {{ 42.55|round|int }}
             -> 43
     """
-    if not method in ('common', 'ceil', 'floor'):
-        raise FilterArgumentError('method must be common, ceil or floor')
-    if method == 'common':
+    if method not in {"common", "ceil", "floor"}:
+        raise FilterArgumentError("method must be common, ceil or floor")
+    if method == "common":
         return round(value, precision)
     func = getattr(math, method)
     return func(value * (10 ** precision)) / (10 ** precision)
@@ -804,52 +941,51 @@ def do_round(value, precision=0, method='common'):
 # we do not want to accidentally expose an auto generated repr in case
 # people start to print this out in comments or something similar for
 # debugging.
-_GroupTuple = namedtuple('_GroupTuple', ['grouper', 'list'])
+_GroupTuple = namedtuple("_GroupTuple", ["grouper", "list"])
 _GroupTuple.__repr__ = tuple.__repr__
 _GroupTuple.__str__ = tuple.__str__
 
+
 @environmentfilter
 def do_groupby(environment, value, attribute):
-    """Group a sequence of objects by a common attribute.
+    """Group a sequence of objects by an attribute using Python's
+    :func:`itertools.groupby`. The attribute can use dot notation for
+    nested access, like ``"address.city"``. Unlike Python's ``groupby``,
+    the values are sorted first so only one group is returned for each
+    unique value.
 
-    If you for example have a list of dicts or objects that represent persons
-    with `gender`, `first_name` and `last_name` attributes and you want to
-    group all users by genders you can do something like the following
-    snippet:
+    For example, a list of ``User`` objects with a ``city`` attribute
+    can be rendered in groups. In this example, ``grouper`` refers to
+    the ``city`` value of the group.
 
     .. sourcecode:: html+jinja
 
-        <ul>
-        {% for group in persons|groupby('gender') %}
-            <li>{{ group.grouper }}<ul>
-            {% for person in group.list %}
-                <li>{{ person.first_name }} {{ person.last_name }}</li>
-            {% endfor %}</ul></li>
-        {% endfor %}
-        </ul>
+        <ul>{% for city, items in users|groupby("city") %}
+          <li>{{ city }}
+            <ul>{% for user in items %}
+              <li>{{ user.name }}
+            {% endfor %}</ul>
+          </li>
+        {% endfor %}</ul>
 
-    Additionally it's possible to use tuple unpacking for the grouper and
-    list:
+    ``groupby`` yields namedtuples of ``(grouper, list)``, which
+    can be used instead of the tuple unpacking above. ``grouper`` is the
+    value of the attribute, and ``list`` is the items with that value.
 
     .. sourcecode:: html+jinja
 
-        <ul>
-        {% for grouper, list in persons|groupby('gender') %}
-            ...
-        {% endfor %}
-        </ul>
-
-    As you can see the item we're grouping by is stored in the `grouper`
-    attribute and the `list` contains all the objects that have this grouper
-    in common.
+        <ul>{% for group in users|groupby("city") %}
+          <li>{{ group.grouper }}: {{ group.list|join(", ") }}
+        {% endfor %}</ul>
 
     .. versionchanged:: 2.6
-       It's now possible to use dotted notation to group by the child
-       attribute of another attribute.
+        The attribute supports dot notation for nested access.
     """
     expr = make_attrgetter(environment, attribute)
-    return [_GroupTuple(key, list(values)) for key, values
-            in groupby(sorted(value, key=expr), expr)]
+    return [
+        _GroupTuple(key, list(values))
+        for key, values in groupby(sorted(value, key=expr), expr)
+    ]
 
 
 @environmentfilter
@@ -906,7 +1042,7 @@ def do_reverse(value):
             rv.reverse()
             return rv
         except TypeError:
-            raise FilterArgumentError('argument must be iterable')
+            raise FilterArgumentError("argument must be iterable")
 
 
 @environmentfilter
@@ -927,8 +1063,9 @@ def do_attr(environment, obj, name):
         except AttributeError:
             pass
         else:
-            if environment.sandboxed and not \
-               environment.is_safe_attribute(obj, name, value):
+            if environment.sandboxed and not environment.is_safe_attribute(
+                obj, name, value
+            ):
                 return environment.unsafe_undefined(obj, name)
             return value
     return environment.undefined(obj=obj, name=name)
@@ -947,6 +1084,13 @@ def do_map(*args, **kwargs):
 
         Users on this page: {{ users|map(attribute='username')|join(', ') }}
 
+    You can specify a ``default`` value to use if an object in the list
+    does not have the given attribute.
+
+    .. sourcecode:: jinja
+
+        {{ users|map(attribute="username", default="Anonymous")|join(", ") }}
+
     Alternatively you can let it invoke a filter by passing the name of the
     filter and the arguments afterwards.  A good example would be applying a
     text conversion filter on a sequence:
@@ -955,6 +1099,17 @@ def do_map(*args, **kwargs):
 
         Users on this page: {{ titles|map('lower')|join(', ') }}
 
+    Similar to a generator comprehension such as:
+
+    .. code-block:: python
+
+        (u.username for u in users)
+        (u.username or "Anonymous" for u in users)
+        (do_lower(x) for x in titles)
+
+    .. versionchanged:: 2.11.0
+        Added the ``default`` parameter.
+
     .. versionadded:: 2.7
     """
     seq, func = prepare_map(args, kwargs)
@@ -980,6 +1135,13 @@ def do_select(*args, **kwargs):
         {{ numbers|select("lessthan", 42) }}
         {{ strings|select("equalto", "mystring") }}
 
+    Similar to a generator comprehension such as:
+
+    .. code-block:: python
+
+        (n for n in numbers if test_odd(n))
+        (n for n in numbers if test_divisibleby(n, 3))
+
     .. versionadded:: 2.7
     """
     return select_or_reject(args, kwargs, lambda x: x, False)
@@ -998,6 +1160,12 @@ def do_reject(*args, **kwargs):
 
         {{ numbers|reject("odd") }}
 
+    Similar to a generator comprehension such as:
+
+    .. code-block:: python
+
+        (n for n in numbers if not test_odd(n))
+
     .. versionadded:: 2.7
     """
     return select_or_reject(args, kwargs, lambda x: not x, False)
@@ -1019,6 +1187,13 @@ def do_selectattr(*args, **kwargs):
         {{ users|selectattr("is_active") }}
         {{ users|selectattr("email", "none") }}
 
+    Similar to a generator comprehension such as:
+
+    .. code-block:: python
+
+        (u for user in users if user.is_active)
+        (u for user in users if test_none(user.email))
+
     .. versionadded:: 2.7
     """
     return select_or_reject(args, kwargs, lambda x: x, True)
@@ -1038,6 +1213,13 @@ def do_rejectattr(*args, **kwargs):
         {{ users|rejectattr("is_active") }}
         {{ users|rejectattr("email", "none") }}
 
+    Similar to a generator comprehension such as:
+
+    .. code-block:: python
+
+        (u for user in users if not user.is_active)
+        (u for user in users if not test_none(user.email))
+
     .. versionadded:: 2.7
     """
     return select_or_reject(args, kwargs, lambda x: not x, True)
@@ -1070,32 +1252,38 @@ def do_tojson(eval_ctx, value, indent=None):
     .. versionadded:: 2.9
     """
     policies = eval_ctx.environment.policies
-    dumper = policies['json.dumps_function']
-    options = policies['json.dumps_kwargs']
+    dumper = policies["json.dumps_function"]
+    options = policies["json.dumps_kwargs"]
     if indent is not None:
         options = dict(options)
-        options['indent'] = indent
+        options["indent"] = indent
     return htmlsafe_json_dumps(value, dumper=dumper, **options)
 
 
 def prepare_map(args, kwargs):
     context = args[0]
     seq = args[1]
+    default = None
 
-    if len(args) == 2 and 'attribute' in kwargs:
-        attribute = kwargs.pop('attribute')
+    if len(args) == 2 and "attribute" in kwargs:
+        attribute = kwargs.pop("attribute")
+        default = kwargs.pop("default", None)
         if kwargs:
-            raise FilterArgumentError('Unexpected keyword argument %r' %
-                next(iter(kwargs)))
-        func = make_attrgetter(context.environment, attribute)
+            raise FilterArgumentError(
+                "Unexpected keyword argument %r" % next(iter(kwargs))
+            )
+        func = make_attrgetter(context.environment, attribute, default=default)
     else:
         try:
             name = args[2]
             args = args[3:]
         except LookupError:
-            raise FilterArgumentError('map requires a filter argument')
-        func = lambda item: context.environment.call_filter(
-            name, item, args, kwargs, context=context)
+            raise FilterArgumentError("map requires a filter argument")
+
+        def func(item):
+            return context.environment.call_filter(
+                name, item, args, kwargs, context=context
+            )
 
     return seq, func
 
@@ -1107,18 +1295,22 @@ def prepare_select_or_reject(args, kwargs, modfunc, lookup_attr):
         try:
             attr = args[2]
         except LookupError:
-            raise FilterArgumentError('Missing parameter for attribute name')
+            raise FilterArgumentError("Missing parameter for attribute name")
         transfunc = make_attrgetter(context.environment, attr)
         off = 1
     else:
         off = 0
-        transfunc = lambda x: x
+
+        def transfunc(x):
+            return x
 
     try:
         name = args[2 + off]
-        args = args[3 + off:]
-        func = lambda item: context.environment.call_test(
-            name, item, args, kwargs)
+        args = args[3 + off :]
+
+        def func(item):
+            return context.environment.call_test(name, item, args, kwargs)
+
     except LookupError:
         func = bool
 
@@ -1134,57 +1326,57 @@ def select_or_reject(args, kwargs, modfunc, lookup_attr):
 
 
 FILTERS = {
-    'abs':                  abs,
-    'attr':                 do_attr,
-    'batch':                do_batch,
-    'capitalize':           do_capitalize,
-    'center':               do_center,
-    'count':                len,
-    'd':                    do_default,
-    'default':              do_default,
-    'dictsort':             do_dictsort,
-    'e':                    escape,
-    'escape':               escape,
-    'filesizeformat':       do_filesizeformat,
-    'first':                do_first,
-    'float':                do_float,
-    'forceescape':          do_forceescape,
-    'format':               do_format,
-    'groupby':              do_groupby,
-    'indent':               do_indent,
-    'int':                  do_int,
-    'join':                 do_join,
-    'last':                 do_last,
-    'length':               len,
-    'list':                 do_list,
-    'lower':                do_lower,
-    'map':                  do_map,
-    'min':                  do_min,
-    'max':                  do_max,
-    'pprint':               do_pprint,
-    'random':               do_random,
-    'reject':               do_reject,
-    'rejectattr':           do_rejectattr,
-    'replace':              do_replace,
-    'reverse':              do_reverse,
-    'round':                do_round,
-    'safe':                 do_mark_safe,
-    'select':               do_select,
-    'selectattr':           do_selectattr,
-    'slice':                do_slice,
-    'sort':                 do_sort,
-    'string':               soft_unicode,
-    'striptags':            do_striptags,
-    'sum':                  do_sum,
-    'title':                do_title,
-    'trim':                 do_trim,
-    'truncate':             do_truncate,
-    'unique':               do_unique,
-    'upper':                do_upper,
-    'urlencode':            do_urlencode,
-    'urlize':               do_urlize,
-    'wordcount':            do_wordcount,
-    'wordwrap':             do_wordwrap,
-    'xmlattr':              do_xmlattr,
-    'tojson':               do_tojson,
+    "abs": abs,
+    "attr": do_attr,
+    "batch": do_batch,
+    "capitalize": do_capitalize,
+    "center": do_center,
+    "count": len,
+    "d": do_default,
+    "default": do_default,
+    "dictsort": do_dictsort,
+    "e": escape,
+    "escape": escape,
+    "filesizeformat": do_filesizeformat,
+    "first": do_first,
+    "float": do_float,
+    "forceescape": do_forceescape,
+    "format": do_format,
+    "groupby": do_groupby,
+    "indent": do_indent,
+    "int": do_int,
+    "join": do_join,
+    "last": do_last,
+    "length": len,
+    "list": do_list,
+    "lower": do_lower,
+    "map": do_map,
+    "min": do_min,
+    "max": do_max,
+    "pprint": do_pprint,
+    "random": do_random,
+    "reject": do_reject,
+    "rejectattr": do_rejectattr,
+    "replace": do_replace,
+    "reverse": do_reverse,
+    "round": do_round,
+    "safe": do_mark_safe,
+    "select": do_select,
+    "selectattr": do_selectattr,
+    "slice": do_slice,
+    "sort": do_sort,
+    "string": soft_unicode,
+    "striptags": do_striptags,
+    "sum": do_sum,
+    "title": do_title,
+    "trim": do_trim,
+    "truncate": do_truncate,
+    "unique": do_unique,
+    "upper": do_upper,
+    "urlencode": do_urlencode,
+    "urlize": do_urlize,
+    "wordcount": do_wordcount,
+    "wordwrap": do_wordwrap,
+    "xmlattr": do_xmlattr,
+    "tojson": do_tojson,
 }
diff --git a/pipenv/vendor/jinja2/idtracking.py b/pipenv/vendor/jinja2/idtracking.py
index 491bfe08..9a0d8380 100644
--- a/pipenv/vendor/jinja2/idtracking.py
+++ b/pipenv/vendor/jinja2/idtracking.py
@@ -1,11 +1,10 @@
-from jinja2.visitor import NodeVisitor
-from jinja2._compat import iteritems
+from ._compat import iteritems
+from .visitor import NodeVisitor
 
-
-VAR_LOAD_PARAMETER = 'param'
-VAR_LOAD_RESOLVE = 'resolve'
-VAR_LOAD_ALIAS = 'alias'
-VAR_LOAD_UNDEFINED = 'undefined'
+VAR_LOAD_PARAMETER = "param"
+VAR_LOAD_RESOLVE = "resolve"
+VAR_LOAD_ALIAS = "alias"
+VAR_LOAD_UNDEFINED = "undefined"
 
 
 def find_symbols(nodes, parent_symbols=None):
@@ -23,7 +22,6 @@ def symbols_for_node(node, parent_symbols=None):
 
 
 class Symbols(object):
-
     def __init__(self, parent=None, level=None):
         if level is None:
             if parent is None:
@@ -41,7 +39,7 @@ class Symbols(object):
         visitor.visit(node, **kwargs)
 
     def _define_ref(self, name, load=None):
-        ident = 'l_%d_%s' % (self.level, name)
+        ident = "l_%d_%s" % (self.level, name)
         self.refs[name] = ident
         if load is not None:
             self.loads[ident] = load
@@ -62,8 +60,10 @@ class Symbols(object):
     def ref(self, name):
         rv = self.find_ref(name)
         if rv is None:
-            raise AssertionError('Tried to resolve a name to a reference that '
-                                 'was unknown to the frame (%r)' % name)
+            raise AssertionError(
+                "Tried to resolve a name to a reference that "
+                "was unknown to the frame (%r)" % name
+            )
         return rv
 
     def copy(self):
@@ -118,7 +118,7 @@ class Symbols(object):
             if branch_count == len(branch_symbols):
                 continue
             target = self.find_ref(name)
-            assert target is not None, 'should not happen'
+            assert target is not None, "should not happen"
 
             if self.parent is not None:
                 outer_target = self.parent.find_ref(name)
@@ -149,7 +149,6 @@ class Symbols(object):
 
 
 class RootVisitor(NodeVisitor):
-
     def __init__(self, symbols):
         self.sym_visitor = FrameSymbolVisitor(symbols)
 
@@ -157,35 +156,39 @@ class RootVisitor(NodeVisitor):
         for child in node.iter_child_nodes():
             self.sym_visitor.visit(child)
 
-    visit_Template = visit_Block = visit_Macro = visit_FilterBlock = \
-        visit_Scope = visit_If = visit_ScopedEvalContextModifier = \
-        _simple_visit
+    visit_Template = (
+        visit_Block
+    ) = (
+        visit_Macro
+    ) = (
+        visit_FilterBlock
+    ) = visit_Scope = visit_If = visit_ScopedEvalContextModifier = _simple_visit
 
     def visit_AssignBlock(self, node, **kwargs):
         for child in node.body:
             self.sym_visitor.visit(child)
 
     def visit_CallBlock(self, node, **kwargs):
-        for child in node.iter_child_nodes(exclude=('call',)):
+        for child in node.iter_child_nodes(exclude=("call",)):
             self.sym_visitor.visit(child)
 
     def visit_OverlayScope(self, node, **kwargs):
         for child in node.body:
             self.sym_visitor.visit(child)
 
-    def visit_For(self, node, for_branch='body', **kwargs):
-        if for_branch == 'body':
+    def visit_For(self, node, for_branch="body", **kwargs):
+        if for_branch == "body":
             self.sym_visitor.visit(node.target, store_as_param=True)
             branch = node.body
-        elif for_branch == 'else':
+        elif for_branch == "else":
             branch = node.else_
-        elif for_branch == 'test':
+        elif for_branch == "test":
             self.sym_visitor.visit(node.target, store_as_param=True)
             if node.test is not None:
                 self.sym_visitor.visit(node.test)
             return
         else:
-            raise RuntimeError('Unknown for branch')
+            raise RuntimeError("Unknown for branch")
         for item in branch or ():
             self.sym_visitor.visit(item)
 
@@ -196,8 +199,9 @@ class RootVisitor(NodeVisitor):
             self.sym_visitor.visit(child)
 
     def generic_visit(self, node, *args, **kwargs):
-        raise NotImplementedError('Cannot find symbols for %r' %
-                                  node.__class__.__name__)
+        raise NotImplementedError(
+            "Cannot find symbols for %r" % node.__class__.__name__
+        )
 
 
 class FrameSymbolVisitor(NodeVisitor):
@@ -208,11 +212,11 @@ class FrameSymbolVisitor(NodeVisitor):
 
     def visit_Name(self, node, store_as_param=False, **kwargs):
         """All assignments to names go through this function."""
-        if store_as_param or node.ctx == 'param':
+        if store_as_param or node.ctx == "param":
             self.symbols.declare_parameter(node.name)
-        elif node.ctx == 'store':
+        elif node.ctx == "store":
             self.symbols.store(node.name)
-        elif node.ctx == 'load':
+        elif node.ctx == "load":
             self.symbols.load(node.name)
 
     def visit_NSRef(self, node, **kwargs):
diff --git a/pipenv/vendor/jinja2/lexer.py b/pipenv/vendor/jinja2/lexer.py
index 6fd135dd..a2b44e92 100644
--- a/pipenv/vendor/jinja2/lexer.py
+++ b/pipenv/vendor/jinja2/lexer.py
@@ -1,185 +1,194 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.lexer
-    ~~~~~~~~~~~~
-
-    This module implements a Jinja / Python combination lexer. The
-    `Lexer` class provided by this module is used to do some preprocessing
-    for Jinja.
-
-    On the one hand it filters out invalid operators like the bitshift
-    operators we don't allow in templates. On the other hand it separates
-    template code and python code in expressions.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
+"""Implements a Jinja / Python combination lexer. The ``Lexer`` class
+is used to do some preprocessing. It filters out invalid operators like
+the bitshift operators we don't allow in templates. It separates
+template code and python code in expressions.
 """
 import re
+from ast import literal_eval
 from collections import deque
 from operator import itemgetter
 
-from jinja2._compat import implements_iterator, intern, iteritems, text_type
-from jinja2.exceptions import TemplateSyntaxError
-from jinja2.utils import LRUCache
+from ._compat import implements_iterator
+from ._compat import intern
+from ._compat import iteritems
+from ._compat import text_type
+from .exceptions import TemplateSyntaxError
+from .utils import LRUCache
 
 # cache for the lexers. Exists in order to be able to have multiple
 # environments with the same lexer
 _lexer_cache = LRUCache(50)
 
 # static regular expressions
-whitespace_re = re.compile(r'\s+', re.U)
-string_re = re.compile(r"('([^'\\]*(?:\\.[^'\\]*)*)'"
-                       r'|"([^"\\]*(?:\\.[^"\\]*)*)")', re.S)
-integer_re = re.compile(r'\d+')
+whitespace_re = re.compile(r"\s+", re.U)
+newline_re = re.compile(r"(\r\n|\r|\n)")
+string_re = re.compile(
+    r"('([^'\\]*(?:\\.[^'\\]*)*)'" r'|"([^"\\]*(?:\\.[^"\\]*)*)")', re.S
+)
+integer_re = re.compile(r"(\d+_)*\d+")
+float_re = re.compile(
+    r"""
+    (?<!\.)  # doesn't start with a .
+    (\d+_)*\d+  # digits, possibly _ separated
+    (
+        (\.(\d+_)*\d+)?  # optional fractional part
+        e[+\-]?(\d+_)*\d+  # exponent part
+    |
+        \.(\d+_)*\d+  # required fractional part
+    )
+    """,
+    re.IGNORECASE | re.VERBOSE,
+)
 
 try:
     # check if this Python supports Unicode identifiers
-    compile('f', '<unknown>', 'eval')
+    compile("f", "<unknown>", "eval")
 except SyntaxError:
-    # no Unicode support, use ASCII identifiers
-    name_re = re.compile(r'[a-zA-Z_][a-zA-Z0-9_]*')
+    # Python 2, no Unicode support, use ASCII identifiers
+    name_re = re.compile(r"[a-zA-Z_][a-zA-Z0-9_]*")
     check_ident = False
 else:
-    # Unicode support, build a pattern to match valid characters, and set flag
-    # to use str.isidentifier to validate during lexing
-    from jinja2 import _identifier
-    name_re = re.compile(r'[\w{0}]+'.format(_identifier.pattern))
-    check_ident = True
-    # remove the pattern from memory after building the regex
-    import sys
-    del sys.modules['jinja2._identifier']
-    import jinja2
-    del jinja2._identifier
-    del _identifier
+    # Unicode support, import generated re pattern and set flag to use
+    # str.isidentifier to validate during lexing.
+    from ._identifier import pattern as name_re
 
-float_re = re.compile(r'(?<!\.)\d+\.\d+')
-newline_re = re.compile(r'(\r\n|\r|\n)')
+    check_ident = True
 
 # internal the tokens and keep references to them
-TOKEN_ADD = intern('add')
-TOKEN_ASSIGN = intern('assign')
-TOKEN_COLON = intern('colon')
-TOKEN_COMMA = intern('comma')
-TOKEN_DIV = intern('div')
-TOKEN_DOT = intern('dot')
-TOKEN_EQ = intern('eq')
-TOKEN_FLOORDIV = intern('floordiv')
-TOKEN_GT = intern('gt')
-TOKEN_GTEQ = intern('gteq')
-TOKEN_LBRACE = intern('lbrace')
-TOKEN_LBRACKET = intern('lbracket')
-TOKEN_LPAREN = intern('lparen')
-TOKEN_LT = intern('lt')
-TOKEN_LTEQ = intern('lteq')
-TOKEN_MOD = intern('mod')
-TOKEN_MUL = intern('mul')
-TOKEN_NE = intern('ne')
-TOKEN_PIPE = intern('pipe')
-TOKEN_POW = intern('pow')
-TOKEN_RBRACE = intern('rbrace')
-TOKEN_RBRACKET = intern('rbracket')
-TOKEN_RPAREN = intern('rparen')
-TOKEN_SEMICOLON = intern('semicolon')
-TOKEN_SUB = intern('sub')
-TOKEN_TILDE = intern('tilde')
-TOKEN_WHITESPACE = intern('whitespace')
-TOKEN_FLOAT = intern('float')
-TOKEN_INTEGER = intern('integer')
-TOKEN_NAME = intern('name')
-TOKEN_STRING = intern('string')
-TOKEN_OPERATOR = intern('operator')
-TOKEN_BLOCK_BEGIN = intern('block_begin')
-TOKEN_BLOCK_END = intern('block_end')
-TOKEN_VARIABLE_BEGIN = intern('variable_begin')
-TOKEN_VARIABLE_END = intern('variable_end')
-TOKEN_RAW_BEGIN = intern('raw_begin')
-TOKEN_RAW_END = intern('raw_end')
-TOKEN_COMMENT_BEGIN = intern('comment_begin')
-TOKEN_COMMENT_END = intern('comment_end')
-TOKEN_COMMENT = intern('comment')
-TOKEN_LINESTATEMENT_BEGIN = intern('linestatement_begin')
-TOKEN_LINESTATEMENT_END = intern('linestatement_end')
-TOKEN_LINECOMMENT_BEGIN = intern('linecomment_begin')
-TOKEN_LINECOMMENT_END = intern('linecomment_end')
-TOKEN_LINECOMMENT = intern('linecomment')
-TOKEN_DATA = intern('data')
-TOKEN_INITIAL = intern('initial')
-TOKEN_EOF = intern('eof')
+TOKEN_ADD = intern("add")
+TOKEN_ASSIGN = intern("assign")
+TOKEN_COLON = intern("colon")
+TOKEN_COMMA = intern("comma")
+TOKEN_DIV = intern("div")
+TOKEN_DOT = intern("dot")
+TOKEN_EQ = intern("eq")
+TOKEN_FLOORDIV = intern("floordiv")
+TOKEN_GT = intern("gt")
+TOKEN_GTEQ = intern("gteq")
+TOKEN_LBRACE = intern("lbrace")
+TOKEN_LBRACKET = intern("lbracket")
+TOKEN_LPAREN = intern("lparen")
+TOKEN_LT = intern("lt")
+TOKEN_LTEQ = intern("lteq")
+TOKEN_MOD = intern("mod")
+TOKEN_MUL = intern("mul")
+TOKEN_NE = intern("ne")
+TOKEN_PIPE = intern("pipe")
+TOKEN_POW = intern("pow")
+TOKEN_RBRACE = intern("rbrace")
+TOKEN_RBRACKET = intern("rbracket")
+TOKEN_RPAREN = intern("rparen")
+TOKEN_SEMICOLON = intern("semicolon")
+TOKEN_SUB = intern("sub")
+TOKEN_TILDE = intern("tilde")
+TOKEN_WHITESPACE = intern("whitespace")
+TOKEN_FLOAT = intern("float")
+TOKEN_INTEGER = intern("integer")
+TOKEN_NAME = intern("name")
+TOKEN_STRING = intern("string")
+TOKEN_OPERATOR = intern("operator")
+TOKEN_BLOCK_BEGIN = intern("block_begin")
+TOKEN_BLOCK_END = intern("block_end")
+TOKEN_VARIABLE_BEGIN = intern("variable_begin")
+TOKEN_VARIABLE_END = intern("variable_end")
+TOKEN_RAW_BEGIN = intern("raw_begin")
+TOKEN_RAW_END = intern("raw_end")
+TOKEN_COMMENT_BEGIN = intern("comment_begin")
+TOKEN_COMMENT_END = intern("comment_end")
+TOKEN_COMMENT = intern("comment")
+TOKEN_LINESTATEMENT_BEGIN = intern("linestatement_begin")
+TOKEN_LINESTATEMENT_END = intern("linestatement_end")
+TOKEN_LINECOMMENT_BEGIN = intern("linecomment_begin")
+TOKEN_LINECOMMENT_END = intern("linecomment_end")
+TOKEN_LINECOMMENT = intern("linecomment")
+TOKEN_DATA = intern("data")
+TOKEN_INITIAL = intern("initial")
+TOKEN_EOF = intern("eof")
 
 # bind operators to token types
 operators = {
-    '+':            TOKEN_ADD,
-    '-':            TOKEN_SUB,
-    '/':            TOKEN_DIV,
-    '//':           TOKEN_FLOORDIV,
-    '*':            TOKEN_MUL,
-    '%':            TOKEN_MOD,
-    '**':           TOKEN_POW,
-    '~':            TOKEN_TILDE,
-    '[':            TOKEN_LBRACKET,
-    ']':            TOKEN_RBRACKET,
-    '(':            TOKEN_LPAREN,
-    ')':            TOKEN_RPAREN,
-    '{':            TOKEN_LBRACE,
-    '}':            TOKEN_RBRACE,
-    '==':           TOKEN_EQ,
-    '!=':           TOKEN_NE,
-    '>':            TOKEN_GT,
-    '>=':           TOKEN_GTEQ,
-    '<':            TOKEN_LT,
-    '<=':           TOKEN_LTEQ,
-    '=':            TOKEN_ASSIGN,
-    '.':            TOKEN_DOT,
-    ':':            TOKEN_COLON,
-    '|':            TOKEN_PIPE,
-    ',':            TOKEN_COMMA,
-    ';':            TOKEN_SEMICOLON
+    "+": TOKEN_ADD,
+    "-": TOKEN_SUB,
+    "/": TOKEN_DIV,
+    "//": TOKEN_FLOORDIV,
+    "*": TOKEN_MUL,
+    "%": TOKEN_MOD,
+    "**": TOKEN_POW,
+    "~": TOKEN_TILDE,
+    "[": TOKEN_LBRACKET,
+    "]": TOKEN_RBRACKET,
+    "(": TOKEN_LPAREN,
+    ")": TOKEN_RPAREN,
+    "{": TOKEN_LBRACE,
+    "}": TOKEN_RBRACE,
+    "==": TOKEN_EQ,
+    "!=": TOKEN_NE,
+    ">": TOKEN_GT,
+    ">=": TOKEN_GTEQ,
+    "<": TOKEN_LT,
+    "<=": TOKEN_LTEQ,
+    "=": TOKEN_ASSIGN,
+    ".": TOKEN_DOT,
+    ":": TOKEN_COLON,
+    "|": TOKEN_PIPE,
+    ",": TOKEN_COMMA,
+    ";": TOKEN_SEMICOLON,
 }
 
 reverse_operators = dict([(v, k) for k, v in iteritems(operators)])
-assert len(operators) == len(reverse_operators), 'operators dropped'
-operator_re = re.compile('(%s)' % '|'.join(re.escape(x) for x in
-                         sorted(operators, key=lambda x: -len(x))))
-
-ignored_tokens = frozenset([TOKEN_COMMENT_BEGIN, TOKEN_COMMENT,
-                            TOKEN_COMMENT_END, TOKEN_WHITESPACE,
-                            TOKEN_LINECOMMENT_BEGIN, TOKEN_LINECOMMENT_END,
-                            TOKEN_LINECOMMENT])
-ignore_if_empty = frozenset([TOKEN_WHITESPACE, TOKEN_DATA,
-                             TOKEN_COMMENT, TOKEN_LINECOMMENT])
+assert len(operators) == len(reverse_operators), "operators dropped"
+operator_re = re.compile(
+    "(%s)" % "|".join(re.escape(x) for x in sorted(operators, key=lambda x: -len(x)))
+)
+
+ignored_tokens = frozenset(
+    [
+        TOKEN_COMMENT_BEGIN,
+        TOKEN_COMMENT,
+        TOKEN_COMMENT_END,
+        TOKEN_WHITESPACE,
+        TOKEN_LINECOMMENT_BEGIN,
+        TOKEN_LINECOMMENT_END,
+        TOKEN_LINECOMMENT,
+    ]
+)
+ignore_if_empty = frozenset(
+    [TOKEN_WHITESPACE, TOKEN_DATA, TOKEN_COMMENT, TOKEN_LINECOMMENT]
+)
 
 
 def _describe_token_type(token_type):
     if token_type in reverse_operators:
         return reverse_operators[token_type]
     return {
-        TOKEN_COMMENT_BEGIN:        'begin of comment',
-        TOKEN_COMMENT_END:          'end of comment',
-        TOKEN_COMMENT:              'comment',
-        TOKEN_LINECOMMENT:          'comment',
-        TOKEN_BLOCK_BEGIN:          'begin of statement block',
-        TOKEN_BLOCK_END:            'end of statement block',
-        TOKEN_VARIABLE_BEGIN:       'begin of print statement',
-        TOKEN_VARIABLE_END:         'end of print statement',
-        TOKEN_LINESTATEMENT_BEGIN:  'begin of line statement',
-        TOKEN_LINESTATEMENT_END:    'end of line statement',
-        TOKEN_DATA:                 'template data / text',
-        TOKEN_EOF:                  'end of template'
+        TOKEN_COMMENT_BEGIN: "begin of comment",
+        TOKEN_COMMENT_END: "end of comment",
+        TOKEN_COMMENT: "comment",
+        TOKEN_LINECOMMENT: "comment",
+        TOKEN_BLOCK_BEGIN: "begin of statement block",
+        TOKEN_BLOCK_END: "end of statement block",
+        TOKEN_VARIABLE_BEGIN: "begin of print statement",
+        TOKEN_VARIABLE_END: "end of print statement",
+        TOKEN_LINESTATEMENT_BEGIN: "begin of line statement",
+        TOKEN_LINESTATEMENT_END: "end of line statement",
+        TOKEN_DATA: "template data / text",
+        TOKEN_EOF: "end of template",
     }.get(token_type, token_type)
 
 
 def describe_token(token):
     """Returns a description of the token."""
-    if token.type == 'name':
+    if token.type == TOKEN_NAME:
         return token.value
     return _describe_token_type(token.type)
 
 
 def describe_token_expr(expr):
     """Like `describe_token` but for token expressions."""
-    if ':' in expr:
-        type, value = expr.split(':', 1)
-        if type == 'name':
+    if ":" in expr:
+        type, value = expr.split(":", 1)
+        if type == TOKEN_NAME:
             return value
     else:
         type = expr
@@ -197,21 +206,39 @@ def compile_rules(environment):
     """Compiles all the rules from the environment into a list of rules."""
     e = re.escape
     rules = [
-        (len(environment.comment_start_string), 'comment',
-         e(environment.comment_start_string)),
-        (len(environment.block_start_string), 'block',
-         e(environment.block_start_string)),
-        (len(environment.variable_start_string), 'variable',
-         e(environment.variable_start_string))
+        (
+            len(environment.comment_start_string),
+            TOKEN_COMMENT_BEGIN,
+            e(environment.comment_start_string),
+        ),
+        (
+            len(environment.block_start_string),
+            TOKEN_BLOCK_BEGIN,
+            e(environment.block_start_string),
+        ),
+        (
+            len(environment.variable_start_string),
+            TOKEN_VARIABLE_BEGIN,
+            e(environment.variable_start_string),
+        ),
     ]
 
     if environment.line_statement_prefix is not None:
-        rules.append((len(environment.line_statement_prefix), 'linestatement',
-                      r'^[ \t\v]*' + e(environment.line_statement_prefix)))
+        rules.append(
+            (
+                len(environment.line_statement_prefix),
+                TOKEN_LINESTATEMENT_BEGIN,
+                r"^[ \t\v]*" + e(environment.line_statement_prefix),
+            )
+        )
     if environment.line_comment_prefix is not None:
-        rules.append((len(environment.line_comment_prefix), 'linecomment',
-                      r'(?:^|(?<=\S))[^\S\r\n]*' +
-                      e(environment.line_comment_prefix)))
+        rules.append(
+            (
+                len(environment.line_comment_prefix),
+                TOKEN_LINECOMMENT_BEGIN,
+                r"(?:^|(?<=\S))[^\S\r\n]*" + e(environment.line_comment_prefix),
+            )
+        )
 
     return [x[1:] for x in sorted(rules, reverse=True)]
 
@@ -231,6 +258,7 @@ class Failure(object):
 
 class Token(tuple):
     """Token class."""
+
     __slots__ = ()
     lineno, type, value = (property(itemgetter(x)) for x in range(3))
 
@@ -240,7 +268,7 @@ class Token(tuple):
     def __str__(self):
         if self.type in reverse_operators:
             return reverse_operators[self.type]
-        elif self.type == 'name':
+        elif self.type == "name":
             return self.value
         return self.type
 
@@ -253,8 +281,8 @@ class Token(tuple):
         # passed an iterable of not interned strings.
         if self.type == expr:
             return True
-        elif ':' in expr:
-            return expr.split(':', 1) == [self.type, self.value]
+        elif ":" in expr:
+            return expr.split(":", 1) == [self.type, self.value]
         return False
 
     def test_any(self, *iterable):
@@ -265,11 +293,7 @@ class Token(tuple):
         return False
 
     def __repr__(self):
-        return 'Token(%r, %r, %r)' % (
-            self.lineno,
-            self.type,
-            self.value
-        )
+        return "Token(%r, %r, %r)" % (self.lineno, self.type, self.value)
 
 
 @implements_iterator
@@ -306,7 +330,7 @@ class TokenStream(object):
         self.name = name
         self.filename = filename
         self.closed = False
-        self.current = Token(1, TOKEN_INITIAL, '')
+        self.current = Token(1, TOKEN_INITIAL, "")
         next(self)
 
     def __iter__(self):
@@ -314,9 +338,13 @@ class TokenStream(object):
 
     def __bool__(self):
         return bool(self._pushed) or self.current.type is not TOKEN_EOF
+
     __nonzero__ = __bool__  # py2
 
-    eos = property(lambda x: not x, doc="Are we at the end of the stream?")
+    @property
+    def eos(self):
+        """Are we at the end of the stream?"""
+        return not self
 
     def push(self, token):
         """Push a token back to the stream."""
@@ -332,7 +360,7 @@ class TokenStream(object):
 
     def skip(self, n=1):
         """Got n tokens ahead."""
-        for x in range(n):
+        for _ in range(n):
             next(self)
 
     def next_if(self, expr):
@@ -363,7 +391,7 @@ class TokenStream(object):
 
     def close(self):
         """Close the stream."""
-        self.current = Token(self.current.lineno, TOKEN_EOF, '')
+        self.current = Token(self.current.lineno, TOKEN_EOF, "")
         self._iter = None
         self.closed = True
 
@@ -374,14 +402,18 @@ class TokenStream(object):
         if not self.current.test(expr):
             expr = describe_token_expr(expr)
             if self.current.type is TOKEN_EOF:
-                raise TemplateSyntaxError('unexpected end of template, '
-                                          'expected %r.' % expr,
-                                          self.current.lineno,
-                                          self.name, self.filename)
-            raise TemplateSyntaxError("expected token %r, got %r" %
-                                      (expr, describe_token(self.current)),
-                                      self.current.lineno,
-                                      self.name, self.filename)
+                raise TemplateSyntaxError(
+                    "unexpected end of template, expected %r." % expr,
+                    self.current.lineno,
+                    self.name,
+                    self.filename,
+                )
+            raise TemplateSyntaxError(
+                "expected token %r, got %r" % (expr, describe_token(self.current)),
+                self.current.lineno,
+                self.name,
+                self.filename,
+            )
         try:
             return self.current
         finally:
@@ -390,18 +422,20 @@ class TokenStream(object):
 
 def get_lexer(environment):
     """Return a lexer which is probably cached."""
-    key = (environment.block_start_string,
-           environment.block_end_string,
-           environment.variable_start_string,
-           environment.variable_end_string,
-           environment.comment_start_string,
-           environment.comment_end_string,
-           environment.line_statement_prefix,
-           environment.line_comment_prefix,
-           environment.trim_blocks,
-           environment.lstrip_blocks,
-           environment.newline_sequence,
-           environment.keep_trailing_newline)
+    key = (
+        environment.block_start_string,
+        environment.block_end_string,
+        environment.variable_start_string,
+        environment.variable_end_string,
+        environment.comment_start_string,
+        environment.comment_end_string,
+        environment.line_statement_prefix,
+        environment.line_comment_prefix,
+        environment.trim_blocks,
+        environment.lstrip_blocks,
+        environment.newline_sequence,
+        environment.keep_trailing_newline,
+    )
     lexer = _lexer_cache.get(key)
     if lexer is None:
         lexer = Lexer(environment)
@@ -409,6 +443,19 @@ def get_lexer(environment):
     return lexer
 
 
+class OptionalLStrip(tuple):
+    """A special tuple for marking a point in the state that can have
+    lstrip applied.
+    """
+
+    __slots__ = ()
+
+    # Even though it looks like a no-op, creating instances fails
+    # without this.
+    def __new__(cls, *members, **kwargs):
+        return super(OptionalLStrip, cls).__new__(cls, members)
+
+
 class Lexer(object):
     """Class that implements a lexer for a given environment. Automatically
     created by the environment class, usually you don't have to do that.
@@ -419,9 +466,11 @@ class Lexer(object):
 
     def __init__(self, environment):
         # shortcuts
-        c = lambda x: re.compile(x, re.M | re.S)
         e = re.escape
 
+        def c(x):
+            return re.compile(x, re.M | re.S)
+
         # lexing rules for tags
         tag_rules = [
             (whitespace_re, TOKEN_WHITESPACE, None),
@@ -429,7 +478,7 @@ class Lexer(object):
             (integer_re, TOKEN_INTEGER, None),
             (name_re, TOKEN_NAME, None),
             (string_re, TOKEN_STRING, None),
-            (operator_re, TOKEN_OPERATOR, None)
+            (operator_re, TOKEN_OPERATOR, None),
         ]
 
         # assemble the root lexing rule. because "|" is ungreedy
@@ -441,108 +490,120 @@ class Lexer(object):
         root_tag_rules = compile_rules(environment)
 
         # block suffix if trimming is enabled
-        block_suffix_re = environment.trim_blocks and '\\n?' or ''
-
-        # strip leading spaces if lstrip_blocks is enabled
-        prefix_re = {}
-        if environment.lstrip_blocks:
-            # use '{%+' to manually disable lstrip_blocks behavior
-            no_lstrip_re = e('+')
-            # detect overlap between block and variable or comment strings
-            block_diff = c(r'^%s(.*)' % e(environment.block_start_string))
-            # make sure we don't mistake a block for a variable or a comment
-            m = block_diff.match(environment.comment_start_string)
-            no_lstrip_re += m and r'|%s' % e(m.group(1)) or ''
-            m = block_diff.match(environment.variable_start_string)
-            no_lstrip_re += m and r'|%s' % e(m.group(1)) or ''
-
-            # detect overlap between comment and variable strings
-            comment_diff = c(r'^%s(.*)' % e(environment.comment_start_string))
-            m = comment_diff.match(environment.variable_start_string)
-            no_variable_re = m and r'(?!%s)' % e(m.group(1)) or ''
-
-            lstrip_re = r'^[ \t]*'
-            block_prefix_re = r'%s%s(?!%s)|%s\+?' % (
-                    lstrip_re,
-                    e(environment.block_start_string),
-                    no_lstrip_re,
-                    e(environment.block_start_string),
-                    )
-            comment_prefix_re = r'%s%s%s|%s\+?' % (
-                    lstrip_re,
-                    e(environment.comment_start_string),
-                    no_variable_re,
-                    e(environment.comment_start_string),
-                    )
-            prefix_re['block'] = block_prefix_re
-            prefix_re['comment'] = comment_prefix_re
-        else:
-            block_prefix_re = '%s' % e(environment.block_start_string)
+        block_suffix_re = environment.trim_blocks and "\\n?" or ""
+
+        # If lstrip is enabled, it should not be applied if there is any
+        # non-whitespace between the newline and block.
+        self.lstrip_unless_re = c(r"[^ \t]") if environment.lstrip_blocks else None
 
         self.newline_sequence = environment.newline_sequence
         self.keep_trailing_newline = environment.keep_trailing_newline
 
         # global lexing rules
         self.rules = {
-            'root': [
+            "root": [
                 # directives
-                (c('(.*?)(?:%s)' % '|'.join(
-                    [r'(?P<raw_begin>(?:\s*%s\-|%s)\s*raw\s*(?:\-%s\s*|%s))' % (
-                        e(environment.block_start_string),
-                        block_prefix_re,
-                        e(environment.block_end_string),
-                        e(environment.block_end_string)
-                    )] + [
-                        r'(?P<%s_begin>\s*%s\-|%s)' % (n, r, prefix_re.get(n,r))
-                        for n, r in root_tag_rules
-                    ])), (TOKEN_DATA, '#bygroup'), '#bygroup'),
+                (
+                    c(
+                        "(.*?)(?:%s)"
+                        % "|".join(
+                            [
+                                r"(?P<raw_begin>%s(\-|\+|)\s*raw\s*(?:\-%s\s*|%s))"
+                                % (
+                                    e(environment.block_start_string),
+                                    e(environment.block_end_string),
+                                    e(environment.block_end_string),
+                                )
+                            ]
+                            + [
+                                r"(?P<%s>%s(\-|\+|))" % (n, r)
+                                for n, r in root_tag_rules
+                            ]
+                        )
+                    ),
+                    OptionalLStrip(TOKEN_DATA, "#bygroup"),
+                    "#bygroup",
+                ),
                 # data
-                (c('.+'), TOKEN_DATA, None)
+                (c(".+"), TOKEN_DATA, None),
             ],
             # comments
             TOKEN_COMMENT_BEGIN: [
-                (c(r'(.*?)((?:\-%s\s*|%s)%s)' % (
-                    e(environment.comment_end_string),
-                    e(environment.comment_end_string),
-                    block_suffix_re
-                )), (TOKEN_COMMENT, TOKEN_COMMENT_END), '#pop'),
-                (c('(.)'), (Failure('Missing end of comment tag'),), None)
+                (
+                    c(
+                        r"(.*?)((?:\-%s\s*|%s)%s)"
+                        % (
+                            e(environment.comment_end_string),
+                            e(environment.comment_end_string),
+                            block_suffix_re,
+                        )
+                    ),
+                    (TOKEN_COMMENT, TOKEN_COMMENT_END),
+                    "#pop",
+                ),
+                (c("(.)"), (Failure("Missing end of comment tag"),), None),
             ],
             # blocks
             TOKEN_BLOCK_BEGIN: [
-                (c(r'(?:\-%s\s*|%s)%s' % (
-                    e(environment.block_end_string),
-                    e(environment.block_end_string),
-                    block_suffix_re
-                )), TOKEN_BLOCK_END, '#pop'),
-            ] + tag_rules,
+                (
+                    c(
+                        r"(?:\-%s\s*|%s)%s"
+                        % (
+                            e(environment.block_end_string),
+                            e(environment.block_end_string),
+                            block_suffix_re,
+                        )
+                    ),
+                    TOKEN_BLOCK_END,
+                    "#pop",
+                ),
+            ]
+            + tag_rules,
             # variables
             TOKEN_VARIABLE_BEGIN: [
-                (c(r'\-%s\s*|%s' % (
-                    e(environment.variable_end_string),
-                    e(environment.variable_end_string)
-                )), TOKEN_VARIABLE_END, '#pop')
-            ] + tag_rules,
+                (
+                    c(
+                        r"\-%s\s*|%s"
+                        % (
+                            e(environment.variable_end_string),
+                            e(environment.variable_end_string),
+                        )
+                    ),
+                    TOKEN_VARIABLE_END,
+                    "#pop",
+                )
+            ]
+            + tag_rules,
             # raw block
             TOKEN_RAW_BEGIN: [
-                (c(r'(.*?)((?:\s*%s\-|%s)\s*endraw\s*(?:\-%s\s*|%s%s))' % (
-                    e(environment.block_start_string),
-                    block_prefix_re,
-                    e(environment.block_end_string),
-                    e(environment.block_end_string),
-                    block_suffix_re
-                )), (TOKEN_DATA, TOKEN_RAW_END), '#pop'),
-                (c('(.)'), (Failure('Missing end of raw directive'),), None)
+                (
+                    c(
+                        r"(.*?)((?:%s(\-|\+|))\s*endraw\s*(?:\-%s\s*|%s%s))"
+                        % (
+                            e(environment.block_start_string),
+                            e(environment.block_end_string),
+                            e(environment.block_end_string),
+                            block_suffix_re,
+                        )
+                    ),
+                    OptionalLStrip(TOKEN_DATA, TOKEN_RAW_END),
+                    "#pop",
+                ),
+                (c("(.)"), (Failure("Missing end of raw directive"),), None),
             ],
             # line statements
             TOKEN_LINESTATEMENT_BEGIN: [
-                (c(r'\s*(\n|$)'), TOKEN_LINESTATEMENT_END, '#pop')
-            ] + tag_rules,
+                (c(r"\s*(\n|$)"), TOKEN_LINESTATEMENT_END, "#pop")
+            ]
+            + tag_rules,
             # line comments
             TOKEN_LINECOMMENT_BEGIN: [
-                (c(r'(.*?)()(?=\n|$)'), (TOKEN_LINECOMMENT,
-                 TOKEN_LINECOMMENT_END), '#pop')
-            ]
+                (
+                    c(r"(.*?)()(?=\n|$)"),
+                    (TOKEN_LINECOMMENT, TOKEN_LINECOMMENT_END),
+                    "#pop",
+                )
+            ],
         }
 
     def _normalize_newlines(self, value):
@@ -550,8 +611,7 @@ class Lexer(object):
         return newline_re.sub(self.newline_sequence, value)
 
     def tokenize(self, source, name=None, filename=None, state=None):
-        """Calls tokeniter + tokenize and wraps it in a token stream.
-        """
+        """Calls tokeniter + tokenize and wraps it in a token stream."""
         stream = self.tokeniter(source, name, filename, state)
         return TokenStream(self.wrap(stream, name, filename), name, filename)
 
@@ -562,37 +622,40 @@ class Lexer(object):
         for lineno, token, value in stream:
             if token in ignored_tokens:
                 continue
-            elif token == 'linestatement_begin':
-                token = 'block_begin'
-            elif token == 'linestatement_end':
-                token = 'block_end'
+            elif token == TOKEN_LINESTATEMENT_BEGIN:
+                token = TOKEN_BLOCK_BEGIN
+            elif token == TOKEN_LINESTATEMENT_END:
+                token = TOKEN_BLOCK_END
             # we are not interested in those tokens in the parser
-            elif token in ('raw_begin', 'raw_end'):
+            elif token in (TOKEN_RAW_BEGIN, TOKEN_RAW_END):
                 continue
-            elif token == 'data':
+            elif token == TOKEN_DATA:
                 value = self._normalize_newlines(value)
-            elif token == 'keyword':
+            elif token == "keyword":
                 token = value
-            elif token == 'name':
+            elif token == TOKEN_NAME:
                 value = str(value)
                 if check_ident and not value.isidentifier():
                     raise TemplateSyntaxError(
-                        'Invalid character in identifier',
-                        lineno, name, filename)
-            elif token == 'string':
+                        "Invalid character in identifier", lineno, name, filename
+                    )
+            elif token == TOKEN_STRING:
                 # try to unescape string
                 try:
-                    value = self._normalize_newlines(value[1:-1]) \
-                        .encode('ascii', 'backslashreplace') \
-                        .decode('unicode-escape')
+                    value = (
+                        self._normalize_newlines(value[1:-1])
+                        .encode("ascii", "backslashreplace")
+                        .decode("unicode-escape")
+                    )
                 except Exception as e:
-                    msg = str(e).split(':')[-1].strip()
+                    msg = str(e).split(":")[-1].strip()
                     raise TemplateSyntaxError(msg, lineno, name, filename)
-            elif token == 'integer':
-                value = int(value)
-            elif token == 'float':
-                value = float(value)
-            elif token == 'operator':
+            elif token == TOKEN_INTEGER:
+                value = int(value.replace("_", ""))
+            elif token == TOKEN_FLOAT:
+                # remove all "_" first to support more Python versions
+                value = literal_eval(value.replace("_", ""))
+            elif token == TOKEN_OPERATOR:
                 token = operators[value]
             yield Token(lineno, token, value)
 
@@ -603,23 +666,21 @@ class Lexer(object):
         source = text_type(source)
         lines = source.splitlines()
         if self.keep_trailing_newline and source:
-            for newline in ('\r\n', '\r', '\n'):
+            for newline in ("\r\n", "\r", "\n"):
                 if source.endswith(newline):
-                    lines.append('')
+                    lines.append("")
                     break
-        source = '\n'.join(lines)
+        source = "\n".join(lines)
         pos = 0
         lineno = 1
-        stack = ['root']
-        if state is not None and state != 'root':
-            assert state in ('variable', 'block'), 'invalid state'
-            stack.append(state + '_begin')
-        else:
-            state = 'root'
+        stack = ["root"]
+        if state is not None and state != "root":
+            assert state in ("variable", "block"), "invalid state"
+            stack.append(state + "_begin")
         statetokens = self.rules[stack[-1]]
         source_length = len(source)
-
         balancing_stack = []
+        lstrip_unless_re = self.lstrip_unless_re
 
         while 1:
             # tokenizer loop
@@ -633,13 +694,46 @@ class Lexer(object):
                 # are balanced. continue parsing with the lower rule which
                 # is the operator rule. do this only if the end tags look
                 # like operators
-                if balancing_stack and \
-                   tokens in ('variable_end', 'block_end',
-                              'linestatement_end'):
+                if balancing_stack and tokens in (
+                    TOKEN_VARIABLE_END,
+                    TOKEN_BLOCK_END,
+                    TOKEN_LINESTATEMENT_END,
+                ):
                     continue
 
                 # tuples support more options
                 if isinstance(tokens, tuple):
+                    groups = m.groups()
+
+                    if isinstance(tokens, OptionalLStrip):
+                        # Rule supports lstrip. Match will look like
+                        # text, block type, whitespace control, type, control, ...
+                        text = groups[0]
+
+                        # Skipping the text and first type, every other group is the
+                        # whitespace control for each type. One of the groups will be
+                        # -, +, or empty string instead of None.
+                        strip_sign = next(g for g in groups[2::2] if g is not None)
+
+                        if strip_sign == "-":
+                            # Strip all whitespace between the text and the tag.
+                            groups = (text.rstrip(),) + groups[1:]
+                        elif (
+                            # Not marked for preserving whitespace.
+                            strip_sign != "+"
+                            # lstrip is enabled.
+                            and lstrip_unless_re is not None
+                            # Not a variable expression.
+                            and not m.groupdict().get(TOKEN_VARIABLE_BEGIN)
+                        ):
+                            # The start of text between the last newline and the tag.
+                            l_pos = text.rfind("\n") + 1
+
+                            # If there's only whitespace between the newline and the
+                            # tag, strip it.
+                            if not lstrip_unless_re.search(text, l_pos):
+                                groups = (text[:l_pos],) + groups[1:]
+
                     for idx, token in enumerate(tokens):
                         # failure group
                         if token.__class__ is Failure:
@@ -647,51 +741,54 @@ class Lexer(object):
                         # bygroup is a bit more complex, in that case we
                         # yield for the current token the first named
                         # group that matched
-                        elif token == '#bygroup':
+                        elif token == "#bygroup":
                             for key, value in iteritems(m.groupdict()):
                                 if value is not None:
                                     yield lineno, key, value
-                                    lineno += value.count('\n')
+                                    lineno += value.count("\n")
                                     break
                             else:
-                                raise RuntimeError('%r wanted to resolve '
-                                                   'the token dynamically'
-                                                   ' but no group matched'
-                                                   % regex)
+                                raise RuntimeError(
+                                    "%r wanted to resolve "
+                                    "the token dynamically"
+                                    " but no group matched" % regex
+                                )
                         # normal group
                         else:
-                            data = m.group(idx + 1)
+                            data = groups[idx]
                             if data or token not in ignore_if_empty:
                                 yield lineno, token, data
-                            lineno += data.count('\n')
+                            lineno += data.count("\n")
 
                 # strings as token just are yielded as it.
                 else:
                     data = m.group()
                     # update brace/parentheses balance
-                    if tokens == 'operator':
-                        if data == '{':
-                            balancing_stack.append('}')
-                        elif data == '(':
-                            balancing_stack.append(')')
-                        elif data == '[':
-                            balancing_stack.append(']')
-                        elif data in ('}', ')', ']'):
+                    if tokens == TOKEN_OPERATOR:
+                        if data == "{":
+                            balancing_stack.append("}")
+                        elif data == "(":
+                            balancing_stack.append(")")
+                        elif data == "[":
+                            balancing_stack.append("]")
+                        elif data in ("}", ")", "]"):
                             if not balancing_stack:
-                                raise TemplateSyntaxError('unexpected \'%s\'' %
-                                                          data, lineno, name,
-                                                          filename)
+                                raise TemplateSyntaxError(
+                                    "unexpected '%s'" % data, lineno, name, filename
+                                )
                             expected_op = balancing_stack.pop()
                             if expected_op != data:
-                                raise TemplateSyntaxError('unexpected \'%s\', '
-                                                          'expected \'%s\'' %
-                                                          (data, expected_op),
-                                                          lineno, name,
-                                                          filename)
+                                raise TemplateSyntaxError(
+                                    "unexpected '%s', "
+                                    "expected '%s'" % (data, expected_op),
+                                    lineno,
+                                    name,
+                                    filename,
+                                )
                     # yield items
                     if data or tokens not in ignore_if_empty:
                         yield lineno, tokens, data
-                    lineno += data.count('\n')
+                    lineno += data.count("\n")
 
                 # fetch new position into new variable so that we can check
                 # if there is a internal parsing error which would result
@@ -701,19 +798,20 @@ class Lexer(object):
                 # handle state changes
                 if new_state is not None:
                     # remove the uppermost state
-                    if new_state == '#pop':
+                    if new_state == "#pop":
                         stack.pop()
                     # resolve the new state by group checking
-                    elif new_state == '#bygroup':
+                    elif new_state == "#bygroup":
                         for key, value in iteritems(m.groupdict()):
                             if value is not None:
                                 stack.append(key)
                                 break
                         else:
-                            raise RuntimeError('%r wanted to resolve the '
-                                               'new state dynamically but'
-                                               ' no group matched' %
-                                               regex)
+                            raise RuntimeError(
+                                "%r wanted to resolve the "
+                                "new state dynamically but"
+                                " no group matched" % regex
+                            )
                     # direct state name given
                     else:
                         stack.append(new_state)
@@ -722,8 +820,9 @@ class Lexer(object):
                 # this means a loop without break condition, avoid that and
                 # raise error
                 elif pos2 == pos:
-                    raise RuntimeError('%r yielded empty string without '
-                                       'stack change' % regex)
+                    raise RuntimeError(
+                        "%r yielded empty string without stack change" % regex
+                    )
                 # publish new function and start again
                 pos = pos2
                 break
@@ -734,6 +833,9 @@ class Lexer(object):
                 if pos >= source_length:
                     return
                 # something went wrong
-                raise TemplateSyntaxError('unexpected char %r at %d' %
-                                          (source[pos], pos), lineno,
-                                          name, filename)
+                raise TemplateSyntaxError(
+                    "unexpected char %r at %d" % (source[pos], pos),
+                    lineno,
+                    name,
+                    filename,
+                )
diff --git a/pipenv/vendor/jinja2/loaders.py b/pipenv/vendor/jinja2/loaders.py
index 4c797937..ce5537a0 100644
--- a/pipenv/vendor/jinja2/loaders.py
+++ b/pipenv/vendor/jinja2/loaders.py
@@ -1,22 +1,23 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.loaders
-    ~~~~~~~~~~~~~~
-
-    Jinja loader classes.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
+"""API and implementations for loading templates from different data
+sources.
 """
 import os
+import pkgutil
 import sys
 import weakref
-from types import ModuleType
-from os import path
 from hashlib import sha1
-from jinja2.exceptions import TemplateNotFound
-from jinja2.utils import open_if_exists, internalcode
-from jinja2._compat import string_types, iteritems
+from importlib import import_module
+from os import path
+from types import ModuleType
+
+from ._compat import abc
+from ._compat import fspath
+from ._compat import iteritems
+from ._compat import string_types
+from .exceptions import TemplateNotFound
+from .utils import internalcode
+from .utils import open_if_exists
 
 
 def split_template_path(template):
@@ -24,12 +25,14 @@ def split_template_path(template):
     '..' in the path it will raise a `TemplateNotFound` error.
     """
     pieces = []
-    for piece in template.split('/'):
-        if path.sep in piece \
-           or (path.altsep and path.altsep in piece) or \
-           piece == path.pardir:
+    for piece in template.split("/"):
+        if (
+            path.sep in piece
+            or (path.altsep and path.altsep in piece)
+            or piece == path.pardir
+        ):
             raise TemplateNotFound(template)
-        elif piece and piece != '.':
+        elif piece and piece != ".":
             pieces.append(piece)
     return pieces
 
@@ -86,15 +89,16 @@ class BaseLoader(object):
         the template will be reloaded.
         """
         if not self.has_source_access:
-            raise RuntimeError('%s cannot provide access to the source' %
-                               self.__class__.__name__)
+            raise RuntimeError(
+                "%s cannot provide access to the source" % self.__class__.__name__
+            )
         raise TemplateNotFound(template)
 
     def list_templates(self):
         """Iterates over all templates.  If the loader does not support that
         it should raise a :exc:`TypeError` which is the default behavior.
         """
-        raise TypeError('this loader cannot iterate over all templates')
+        raise TypeError("this loader cannot iterate over all templates")
 
     @internalcode
     def load(self, environment, name, globals=None):
@@ -131,8 +135,9 @@ class BaseLoader(object):
             bucket.code = code
             bcc.set_bucket(bucket)
 
-        return environment.template_class.from_code(environment, code,
-                                                    globals, uptodate)
+        return environment.template_class.from_code(
+            environment, code, globals, uptodate
+        )
 
 
 class FileSystemLoader(BaseLoader):
@@ -153,14 +158,20 @@ class FileSystemLoader(BaseLoader):
 
     >>> loader = FileSystemLoader('/path/to/templates', followlinks=True)
 
-    .. versionchanged:: 2.8+
-       The *followlinks* parameter was added.
+    .. versionchanged:: 2.8
+       The ``followlinks`` parameter was added.
     """
 
-    def __init__(self, searchpath, encoding='utf-8', followlinks=False):
-        if isinstance(searchpath, string_types):
+    def __init__(self, searchpath, encoding="utf-8", followlinks=False):
+        if not isinstance(searchpath, abc.Iterable) or isinstance(
+            searchpath, string_types
+        ):
             searchpath = [searchpath]
-        self.searchpath = list(searchpath)
+
+        # In Python 3.5, os.path.join doesn't support Path. This can be
+        # simplified to list(searchpath) when Python 3.5 is dropped.
+        self.searchpath = [fspath(p) for p in searchpath]
+
         self.encoding = encoding
         self.followlinks = followlinks
 
@@ -183,6 +194,7 @@ class FileSystemLoader(BaseLoader):
                     return path.getmtime(filename) == mtime
                 except OSError:
                     return False
+
             return contents, filename, uptodate
         raise TemplateNotFound(template)
 
@@ -190,12 +202,14 @@ class FileSystemLoader(BaseLoader):
         found = set()
         for searchpath in self.searchpath:
             walk_dir = os.walk(searchpath, followlinks=self.followlinks)
-            for dirpath, dirnames, filenames in walk_dir:
+            for dirpath, _, filenames in walk_dir:
                 for filename in filenames:
-                    template = os.path.join(dirpath, filename) \
-                        [len(searchpath):].strip(os.path.sep) \
-                                          .replace(os.path.sep, '/')
-                    if template[:2] == './':
+                    template = (
+                        os.path.join(dirpath, filename)[len(searchpath) :]
+                        .strip(os.path.sep)
+                        .replace(os.path.sep, "/")
+                    )
+                    if template[:2] == "./":
                         template = template[2:]
                     if template not in found:
                         found.add(template)
@@ -203,66 +217,141 @@ class FileSystemLoader(BaseLoader):
 
 
 class PackageLoader(BaseLoader):
-    """Load templates from python eggs or packages.  It is constructed with
-    the name of the python package and the path to the templates in that
-    package::
+    """Load templates from a directory in a Python package.
 
-        loader = PackageLoader('mypackage', 'views')
+    :param package_name: Import name of the package that contains the
+        template directory.
+    :param package_path: Directory within the imported package that
+        contains the templates.
+    :param encoding: Encoding of template files.
 
-    If the package path is not given, ``'templates'`` is assumed.
+    The following example looks up templates in the ``pages`` directory
+    within the ``project.ui`` package.
 
-    Per default the template encoding is ``'utf-8'`` which can be changed
-    by setting the `encoding` parameter to something else.  Due to the nature
-    of eggs it's only possible to reload templates if the package was loaded
-    from the file system and not a zip file.
+    .. code-block:: python
+
+        loader = PackageLoader("project.ui", "pages")
+
+    Only packages installed as directories (standard pip behavior) or
+    zip/egg files (less common) are supported. The Python API for
+    introspecting data in packages is too limited to support other
+    installation methods the way this loader requires.
+
+    There is limited support for :pep:`420` namespace packages. The
+    template directory is assumed to only be in one namespace
+    contributor. Zip files contributing to a namespace are not
+    supported.
+
+    .. versionchanged:: 2.11.0
+        No longer uses ``setuptools`` as a dependency.
+
+    .. versionchanged:: 2.11.0
+        Limited PEP 420 namespace package support.
     """
 
-    def __init__(self, package_name, package_path='templates',
-                 encoding='utf-8'):
-        from pkg_resources import DefaultProvider, ResourceManager, \
-                                  get_provider
-        provider = get_provider(package_name)
-        self.encoding = encoding
-        self.manager = ResourceManager()
-        self.filesystem_bound = isinstance(provider, DefaultProvider)
-        self.provider = provider
+    def __init__(self, package_name, package_path="templates", encoding="utf-8"):
+        if package_path == os.path.curdir:
+            package_path = ""
+        elif package_path[:2] == os.path.curdir + os.path.sep:
+            package_path = package_path[2:]
+
+        package_path = os.path.normpath(package_path).rstrip(os.path.sep)
         self.package_path = package_path
+        self.package_name = package_name
+        self.encoding = encoding
+
+        # Make sure the package exists. This also makes namespace
+        # packages work, otherwise get_loader returns None.
+        import_module(package_name)
+        self._loader = loader = pkgutil.get_loader(package_name)
+
+        # Zip loader's archive attribute points at the zip.
+        self._archive = getattr(loader, "archive", None)
+        self._template_root = None
+
+        if hasattr(loader, "get_filename"):
+            # A standard directory package, or a zip package.
+            self._template_root = os.path.join(
+                os.path.dirname(loader.get_filename(package_name)), package_path
+            )
+        elif hasattr(loader, "_path"):
+            # A namespace package, limited support. Find the first
+            # contributor with the template directory.
+            for root in loader._path:
+                root = os.path.join(root, package_path)
+
+                if os.path.isdir(root):
+                    self._template_root = root
+                    break
+
+        if self._template_root is None:
+            raise ValueError(
+                "The %r package was not installed in a way that"
+                " PackageLoader understands." % package_name
+            )
 
     def get_source(self, environment, template):
-        pieces = split_template_path(template)
-        p = '/'.join((self.package_path,) + tuple(pieces))
-        if not self.provider.has_resource(p):
-            raise TemplateNotFound(template)
+        p = os.path.join(self._template_root, *split_template_path(template))
 
-        filename = uptodate = None
-        if self.filesystem_bound:
-            filename = self.provider.get_resource_filename(self.manager, p)
-            mtime = path.getmtime(filename)
-            def uptodate():
-                try:
-                    return path.getmtime(filename) == mtime
-                except OSError:
-                    return False
+        if self._archive is None:
+            # Package is a directory.
+            if not os.path.isfile(p):
+                raise TemplateNotFound(template)
+
+            with open(p, "rb") as f:
+                source = f.read()
+
+            mtime = os.path.getmtime(p)
+
+            def up_to_date():
+                return os.path.isfile(p) and os.path.getmtime(p) == mtime
 
-        source = self.provider.get_resource_string(self.manager, p)
-        return source.decode(self.encoding), filename, uptodate
+        else:
+            # Package is a zip file.
+            try:
+                source = self._loader.get_data(p)
+            except OSError:
+                raise TemplateNotFound(template)
+
+            # Could use the zip's mtime for all template mtimes, but
+            # would need to safely reload the module if it's out of
+            # date, so just report it as always current.
+            up_to_date = None
+
+        return source.decode(self.encoding), p, up_to_date
 
     def list_templates(self):
-        path = self.package_path
-        if path[:2] == './':
-            path = path[2:]
-        elif path == '.':
-            path = ''
-        offset = len(path)
         results = []
-        def _walk(path):
-            for filename in self.provider.resource_listdir(path):
-                fullname = path + '/' + filename
-                if self.provider.resource_isdir(fullname):
-                    _walk(fullname)
-                else:
-                    results.append(fullname[offset:].lstrip('/'))
-        _walk(path)
+
+        if self._archive is None:
+            # Package is a directory.
+            offset = len(self._template_root)
+
+            for dirpath, _, filenames in os.walk(self._template_root):
+                dirpath = dirpath[offset:].lstrip(os.path.sep)
+                results.extend(
+                    os.path.join(dirpath, name).replace(os.path.sep, "/")
+                    for name in filenames
+                )
+        else:
+            if not hasattr(self._loader, "_files"):
+                raise TypeError(
+                    "This zip import does not have the required"
+                    " metadata to list templates."
+                )
+
+            # Package is a zip file.
+            prefix = (
+                self._template_root[len(self._archive) :].lstrip(os.path.sep)
+                + os.path.sep
+            )
+            offset = len(prefix)
+
+            for name in self._loader._files.keys():
+                # Find names under the templates directory that aren't directories.
+                if name.startswith(prefix) and name[-1] != os.path.sep:
+                    results.append(name[offset:].replace(os.path.sep, "/"))
+
         results.sort()
         return results
 
@@ -334,7 +423,7 @@ class PrefixLoader(BaseLoader):
     by loading ``'app2/index.html'`` the file from the second.
     """
 
-    def __init__(self, mapping, delimiter='/'):
+    def __init__(self, mapping, delimiter="/"):
         self.mapping = mapping
         self.delimiter = delimiter
 
@@ -434,19 +523,20 @@ class ModuleLoader(BaseLoader):
     has_source_access = False
 
     def __init__(self, path):
-        package_name = '_jinja2_module_templates_%x' % id(self)
+        package_name = "_jinja2_module_templates_%x" % id(self)
 
         # create a fake module that looks for the templates in the
         # path given.
         mod = _TemplateModule(package_name)
-        if isinstance(path, string_types):
+
+        if not isinstance(path, abc.Iterable) or isinstance(path, string_types):
             path = [path]
-        else:
-            path = list(path)
-        mod.__path__ = path
 
-        sys.modules[package_name] = weakref.proxy(mod,
-            lambda x: sys.modules.pop(package_name, None))
+        mod.__path__ = [fspath(p) for p in path]
+
+        sys.modules[package_name] = weakref.proxy(
+            mod, lambda x: sys.modules.pop(package_name, None)
+        )
 
         # the only strong reference, the sys.modules entry is weak
         # so that the garbage collector can remove it once the
@@ -456,20 +546,20 @@ class ModuleLoader(BaseLoader):
 
     @staticmethod
     def get_template_key(name):
-        return 'tmpl_' + sha1(name.encode('utf-8')).hexdigest()
+        return "tmpl_" + sha1(name.encode("utf-8")).hexdigest()
 
     @staticmethod
     def get_module_filename(name):
-        return ModuleLoader.get_template_key(name) + '.py'
+        return ModuleLoader.get_template_key(name) + ".py"
 
     @internalcode
     def load(self, environment, name, globals=None):
         key = self.get_template_key(name)
-        module = '%s.%s' % (self.package_name, key)
+        module = "%s.%s" % (self.package_name, key)
         mod = getattr(self.module, module, None)
         if mod is None:
             try:
-                mod = __import__(module, None, None, ['root'])
+                mod = __import__(module, None, None, ["root"])
             except ImportError:
                 raise TemplateNotFound(name)
 
@@ -478,4 +568,5 @@ class ModuleLoader(BaseLoader):
             sys.modules.pop(module, None)
 
         return environment.template_class.from_module_dict(
-            environment, mod.__dict__, globals)
+            environment, mod.__dict__, globals
+        )
diff --git a/pipenv/vendor/jinja2/meta.py b/pipenv/vendor/jinja2/meta.py
index 7421914f..3795aace 100644
--- a/pipenv/vendor/jinja2/meta.py
+++ b/pipenv/vendor/jinja2/meta.py
@@ -1,25 +1,18 @@
 # -*- coding: utf-8 -*-
+"""Functions that expose information about templates that might be
+interesting for introspection.
 """
-    jinja2.meta
-    ~~~~~~~~~~~
-
-    This module implements various functions that exposes information about
-    templates that might be interesting for various kinds of applications.
-
-    :copyright: (c) 2017 by the Jinja Team, see AUTHORS for more details.
-    :license: BSD, see LICENSE for more details.
-"""
-from jinja2 import nodes
-from jinja2.compiler import CodeGenerator
-from jinja2._compat import string_types, iteritems
+from . import nodes
+from ._compat import iteritems
+from ._compat import string_types
+from .compiler import CodeGenerator
 
 
 class TrackingCodeGenerator(CodeGenerator):
     """We abuse the code generator for introspection."""
 
     def __init__(self, environment):
-        CodeGenerator.__init__(self, environment, '<introspection>',
-                               '<introspection>')
+        CodeGenerator.__init__(self, environment, "<introspection>", "<introspection>")
         self.undeclared_identifiers = set()
 
     def write(self, x):
@@ -29,7 +22,7 @@ class TrackingCodeGenerator(CodeGenerator):
         """Remember all undeclared identifiers."""
         CodeGenerator.enter_frame(self, frame)
         for _, (action, param) in iteritems(frame.symbols.loads):
-            if action == 'resolve':
+            if action == "resolve" and param not in self.environment.globals:
                 self.undeclared_identifiers.add(param)
 
 
@@ -72,8 +65,9 @@ def find_referenced_templates(ast):
     This function is useful for dependency tracking.  For example if you want
     to rebuild parts of the website after a layout template has changed.
     """
-    for node in ast.find_all((nodes.Extends, nodes.FromImport, nodes.Import,
-                              nodes.Include)):
+    for node in ast.find_all(
+        (nodes.Extends, nodes.FromImport, nodes.Import, nodes.Include)
+    ):
         if not isinstance(node.template, nodes.Const):
             # a tuple with some non consts in there
             if isinstance(node.template, (nodes.Tuple, nodes.List)):
@@ -96,8 +90,9 @@ def find_referenced_templates(ast):
         # a tuple or list (latter *should* not happen) made of consts,
         # yield the consts that are strings.  We could warn here for
         # non string values
-        elif isinstance(node, nodes.Include) and \
-             isinstance(node.template.value, (tuple, list)):
+        elif isinstance(node, nodes.Include) and isinstance(
+            node.template.value, (tuple, list)
+        ):
             for template_name in node.template.value:
                 if isinstance(template_name, string_types):
                     yield template_name
diff --git a/pipenv/vendor/jinja2/nativetypes.py b/pipenv/vendor/jinja2/nativetypes.py
index fe17e413..9866c962 100644
--- a/pipenv/vendor/jinja2/nativetypes.py
+++ b/pipenv/vendor/jinja2/nativetypes.py
@@ -1,19 +1,27 @@
-import sys
+import types
 from ast import literal_eval
-from itertools import islice, chain
-from jinja2 import nodes
-from jinja2._compat import text_type
-from jinja2.compiler import CodeGenerator, has_safe_repr
-from jinja2.environment import Environment, Template
-from jinja2.utils import concat, escape
-
-
-def native_concat(nodes):
-    """Return a native Python type from the list of compiled nodes. If the
-    result is a single node, its value is returned. Otherwise, the nodes are
-    concatenated as strings. If the result can be parsed with
-    :func:`ast.literal_eval`, the parsed value is returned. Otherwise, the
-    string is returned.
+from itertools import chain
+from itertools import islice
+
+from . import nodes
+from ._compat import text_type
+from .compiler import CodeGenerator
+from .compiler import has_safe_repr
+from .environment import Environment
+from .environment import Template
+
+
+def native_concat(nodes, preserve_quotes=True):
+    """Return a native Python type from the list of compiled nodes. If
+    the result is a single node, its value is returned. Otherwise, the
+    nodes are concatenated as strings. If the result can be parsed with
+    :func:`ast.literal_eval`, the parsed value is returned. Otherwise,
+    the string is returned.
+
+    :param nodes: Iterable of nodes to concatenate.
+    :param preserve_quotes: Whether to re-wrap literal strings with
+        quotes, to preserve quotes around expressions for later parsing.
+        Should be ``False`` in :meth:`NativeEnvironment.render`.
     """
     head = list(islice(nodes, 2))
 
@@ -21,200 +29,83 @@ def native_concat(nodes):
         return None
 
     if len(head) == 1:
-        out = head[0]
+        raw = head[0]
     else:
-        out = u''.join([text_type(v) for v in chain(head, nodes)])
+        if isinstance(nodes, types.GeneratorType):
+            nodes = chain(head, nodes)
+        raw = u"".join([text_type(v) for v in nodes])
 
     try:
-        return literal_eval(out)
+        literal = literal_eval(raw)
     except (ValueError, SyntaxError, MemoryError):
-        return out
+        return raw
+
+    # If literal_eval returned a string, re-wrap with the original
+    # quote character to avoid dropping quotes between expression nodes.
+    # Without this, "'{{ a }}', '{{ b }}'" results in "a, b", but should
+    # be ('a', 'b').
+    if preserve_quotes and isinstance(literal, str):
+        return "{quote}{}{quote}".format(literal, quote=raw[0])
+
+    return literal
 
 
 class NativeCodeGenerator(CodeGenerator):
-    """A code generator which avoids injecting ``to_string()`` calls around the
-    internal code Jinja uses to render templates.
+    """A code generator which renders Python types by not adding
+    ``to_string()`` around output nodes, and using :func:`native_concat`
+    to convert complex strings back to Python types if possible.
     """
 
-    def visit_Output(self, node, frame):
-        """Same as :meth:`CodeGenerator.visit_Output`, but do not call
-        ``to_string`` on output nodes in generated code.
-        """
-        if self.has_known_extends and frame.require_output_check:
-            return
-
-        finalize = self.environment.finalize
-        finalize_context = getattr(finalize, 'contextfunction', False)
-        finalize_eval = getattr(finalize, 'evalcontextfunction', False)
-        finalize_env = getattr(finalize, 'environmentfunction', False)
-
-        if finalize is not None:
-            if finalize_context or finalize_eval:
-                const_finalize = None
-            elif finalize_env:
-                def const_finalize(x):
-                    return finalize(self.environment, x)
-            else:
-                const_finalize = finalize
-        else:
-            def const_finalize(x):
-                return x
-
-        # If we are inside a frame that requires output checking, we do so.
-        outdent_later = False
-
-        if frame.require_output_check:
-            self.writeline('if parent_template is None:')
-            self.indent()
-            outdent_later = True
-
-        # Try to evaluate as many chunks as possible into a static string at
-        # compile time.
-        body = []
-
-        for child in node.nodes:
-            try:
-                if const_finalize is None:
-                    raise nodes.Impossible()
-
-                const = child.as_const(frame.eval_ctx)
-                if not has_safe_repr(const):
-                    raise nodes.Impossible()
-            except nodes.Impossible:
-                body.append(child)
-                continue
-
-            # the frame can't be volatile here, because otherwise the as_const
-            # function would raise an Impossible exception at that point
-            try:
-                if frame.eval_ctx.autoescape:
-                    if hasattr(const, '__html__'):
-                        const = const.__html__()
-                    else:
-                        const = escape(const)
-
-                const = const_finalize(const)
-            except Exception:
-                # if something goes wrong here we evaluate the node at runtime
-                # for easier debugging
-                body.append(child)
-                continue
-
-            if body and isinstance(body[-1], list):
-                body[-1].append(const)
-            else:
-                body.append([const])
-
-        # if we have less than 3 nodes or a buffer we yield or extend/append
-        if len(body) < 3 or frame.buffer is not None:
-            if frame.buffer is not None:
-                # for one item we append, for more we extend
-                if len(body) == 1:
-                    self.writeline('%s.append(' % frame.buffer)
-                else:
-                    self.writeline('%s.extend((' % frame.buffer)
-
-                self.indent()
-
-            for item in body:
-                if isinstance(item, list):
-                    val = repr(native_concat(item))
-
-                    if frame.buffer is None:
-                        self.writeline('yield ' + val)
-                    else:
-                        self.writeline(val + ',')
-                else:
-                    if frame.buffer is None:
-                        self.writeline('yield ', item)
-                    else:
-                        self.newline(item)
-
-                    close = 0
-
-                    if finalize is not None:
-                        self.write('environment.finalize(')
-
-                        if finalize_context:
-                            self.write('context, ')
-
-                        close += 1
-
-                    self.visit(item, frame)
-
-                    if close > 0:
-                        self.write(')' * close)
-
-                    if frame.buffer is not None:
-                        self.write(',')
-
-            if frame.buffer is not None:
-                # close the open parentheses
-                self.outdent()
-                self.writeline(len(body) == 1 and ')' or '))')
-
-        # otherwise we create a format string as this is faster in that case
-        else:
-            format = []
-            arguments = []
-
-            for item in body:
-                if isinstance(item, list):
-                    format.append(native_concat(item).replace('%', '%%'))
-                else:
-                    format.append('%s')
-                    arguments.append(item)
-
-            self.writeline('yield ')
-            self.write(repr(concat(format)) + ' % (')
-            self.indent()
-
-            for argument in arguments:
-                self.newline(argument)
-                close = 0
-
-                if finalize is not None:
-                    self.write('environment.finalize(')
-
-                    if finalize_context:
-                        self.write('context, ')
-                    elif finalize_eval:
-                        self.write('context.eval_ctx, ')
-                    elif finalize_env:
-                        self.write('environment, ')
-
-                    close += 1
-
-                self.visit(argument, frame)
-                self.write(')' * close + ', ')
-
-            self.outdent()
-            self.writeline(')')
+    @staticmethod
+    def _default_finalize(value):
+        return value
 
-        if outdent_later:
-            self.outdent()
+    def _output_const_repr(self, group):
+        return repr(native_concat(group))
 
+    def _output_child_to_const(self, node, frame, finalize):
+        const = node.as_const(frame.eval_ctx)
 
-class NativeTemplate(Template):
-    def render(self, *args, **kwargs):
-        """Render the template to produce a native Python type. If the result
-        is a single node, its value is returned. Otherwise, the nodes are
-        concatenated as strings. If the result can be parsed with
-        :func:`ast.literal_eval`, the parsed value is returned. Otherwise, the
-        string is returned.
-        """
-        vars = dict(*args, **kwargs)
+        if not has_safe_repr(const):
+            raise nodes.Impossible()
 
-        try:
-            return native_concat(self.root_render_func(self.new_context(vars)))
-        except Exception:
-            exc_info = sys.exc_info()
+        if isinstance(node, nodes.TemplateData):
+            return const
+
+        return finalize.const(const)
+
+    def _output_child_pre(self, node, frame, finalize):
+        if finalize.src is not None:
+            self.write(finalize.src)
 
-        return self.environment.handle_exception(exc_info, True)
+    def _output_child_post(self, node, frame, finalize):
+        if finalize.src is not None:
+            self.write(")")
 
 
 class NativeEnvironment(Environment):
     """An environment that renders templates to native Python types."""
 
     code_generator_class = NativeCodeGenerator
-    template_class = NativeTemplate
+
+
+class NativeTemplate(Template):
+    environment_class = NativeEnvironment
+
+    def render(self, *args, **kwargs):
+        """Render the template to produce a native Python type. If the
+        result is a single node, its value is returned. Otherwise, the
+        nodes are concatenated as strings. If the result can be parsed
+        with :func:`ast.literal_eval`, the parsed value is returned.
+        Otherwise, the string is returned.
+        """
+        vars = dict(*args, **kwargs)
+        try:
+            return native_concat(
+                self.root_render_func(self.new_context(vars)), preserve_quotes=False
+            )
+        except Exception:
+            return self.environment.handle_exception()
+
+
+NativeEnvironment.template_class = NativeTemplate
diff --git a/pipenv/vendor/jinja2/nodes.py b/pipenv/vendor/jinja2/nodes.py
index 4d9a01ad..9f3edc05 100644
--- a/pipenv/vendor/jinja2/nodes.py
+++ b/pipenv/vendor/jinja2/nodes.py
@@ -1,54 +1,39 @@
 # -*- coding: utf-8 -*-
+"""AST nodes generated by the parser for the compiler. Also provides
+some node tree helper functions used by the parser and compiler in order
+to normalize nodes.
 """
-    jinja2.nodes
-    ~~~~~~~~~~~~
-
-    This module implements additional nodes derived from the ast base node.
-
-    It also provides some node tree helper functions like `in_lineno` and
-    `get_nodes` used by the parser and translator in order to normalize
-    python and jinja nodes.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
-import types
 import operator
-
 from collections import deque
-from jinja2.utils import Markup
-from jinja2._compat import izip, with_metaclass, text_type, PY2
-
 
-#: the types we support for context functions
-_context_function_types = (types.FunctionType, types.MethodType)
+from markupsafe import Markup
 
+from ._compat import izip
+from ._compat import PY2
+from ._compat import text_type
+from ._compat import with_metaclass
 
 _binop_to_func = {
-    '*':        operator.mul,
-    '/':        operator.truediv,
-    '//':       operator.floordiv,
-    '**':       operator.pow,
-    '%':        operator.mod,
-    '+':        operator.add,
-    '-':        operator.sub
+    "*": operator.mul,
+    "/": operator.truediv,
+    "//": operator.floordiv,
+    "**": operator.pow,
+    "%": operator.mod,
+    "+": operator.add,
+    "-": operator.sub,
 }
 
-_uaop_to_func = {
-    'not':      operator.not_,
-    '+':        operator.pos,
-    '-':        operator.neg
-}
+_uaop_to_func = {"not": operator.not_, "+": operator.pos, "-": operator.neg}
 
 _cmpop_to_func = {
-    'eq':       operator.eq,
-    'ne':       operator.ne,
-    'gt':       operator.gt,
-    'gteq':     operator.ge,
-    'lt':       operator.lt,
-    'lteq':     operator.le,
-    'in':       lambda a, b: a in b,
-    'notin':    lambda a, b: a not in b
+    "eq": operator.eq,
+    "ne": operator.ne,
+    "gt": operator.gt,
+    "gteq": operator.ge,
+    "lt": operator.lt,
+    "lteq": operator.le,
+    "in": lambda a, b: a in b,
+    "notin": lambda a, b: a not in b,
 }
 
 
@@ -61,16 +46,16 @@ class NodeType(type):
     inheritance.  fields and attributes from the parent class are
     automatically forwarded to the child."""
 
-    def __new__(cls, name, bases, d):
-        for attr in 'fields', 'attributes':
+    def __new__(mcs, name, bases, d):
+        for attr in "fields", "attributes":
             storage = []
             storage.extend(getattr(bases[0], attr, ()))
             storage.extend(d.get(attr, ()))
-            assert len(bases) == 1, 'multiple inheritance not allowed'
-            assert len(storage) == len(set(storage)), 'layout conflict'
+            assert len(bases) == 1, "multiple inheritance not allowed"
+            assert len(storage) == len(set(storage)), "layout conflict"
             d[attr] = tuple(storage)
-        d.setdefault('abstract', False)
-        return type.__new__(cls, name, bases, d)
+        d.setdefault("abstract", False)
+        return type.__new__(mcs, name, bases, d)
 
 
 class EvalContext(object):
@@ -97,15 +82,17 @@ class EvalContext(object):
 def get_eval_context(node, ctx):
     if ctx is None:
         if node.environment is None:
-            raise RuntimeError('if no eval context is passed, the '
-                               'node must have an attached '
-                               'environment.')
+            raise RuntimeError(
+                "if no eval context is passed, the "
+                "node must have an attached "
+                "environment."
+            )
         return EvalContext(node.environment)
     return ctx
 
 
 class Node(with_metaclass(NodeType, object)):
-    """Baseclass for all Jinja2 nodes.  There are a number of nodes available
+    """Baseclass for all Jinja nodes.  There are a number of nodes available
     of different types.  There are four major types:
 
     -   :class:`Stmt`: statements
@@ -120,30 +107,32 @@ class Node(with_metaclass(NodeType, object)):
     The `environment` attribute is set at the end of the parsing process for
     all nodes automatically.
     """
+
     fields = ()
-    attributes = ('lineno', 'environment')
+    attributes = ("lineno", "environment")
     abstract = True
 
     def __init__(self, *fields, **attributes):
         if self.abstract:
-            raise TypeError('abstract nodes are not instanciable')
+            raise TypeError("abstract nodes are not instantiable")
         if fields:
             if len(fields) != len(self.fields):
                 if not self.fields:
-                    raise TypeError('%r takes 0 arguments' %
-                                    self.__class__.__name__)
-                raise TypeError('%r takes 0 or %d argument%s' % (
-                    self.__class__.__name__,
-                    len(self.fields),
-                    len(self.fields) != 1 and 's' or ''
-                ))
+                    raise TypeError("%r takes 0 arguments" % self.__class__.__name__)
+                raise TypeError(
+                    "%r takes 0 or %d argument%s"
+                    % (
+                        self.__class__.__name__,
+                        len(self.fields),
+                        len(self.fields) != 1 and "s" or "",
+                    )
+                )
             for name, arg in izip(self.fields, fields):
                 setattr(self, name, arg)
         for attr in self.attributes:
             setattr(self, attr, attributes.pop(attr, None))
         if attributes:
-            raise TypeError('unknown attribute %r' %
-                            next(iter(attributes)))
+            raise TypeError("unknown attribute %r" % next(iter(attributes)))
 
     def iter_fields(self, exclude=None, only=None):
         """This method iterates over all fields that are defined and yields
@@ -153,9 +142,11 @@ class Node(with_metaclass(NodeType, object)):
         should be sets or tuples of field names.
         """
         for name in self.fields:
-            if (exclude is only is None) or \
-               (exclude is not None and name not in exclude) or \
-               (only is not None and name in only):
+            if (
+                (exclude is only is None)
+                or (exclude is not None and name not in exclude)
+                or (only is not None and name in only)
+            ):
                 try:
                     yield name, getattr(self, name)
                 except AttributeError:
@@ -166,7 +157,7 @@ class Node(with_metaclass(NodeType, object)):
         over all fields and yields the values of they are nodes.  If the value
         of a field is a list all the nodes in that list are returned.
         """
-        for field, item in self.iter_fields(exclude, only):
+        for _, item in self.iter_fields(exclude, only):
             if isinstance(item, list):
                 for n in item:
                     if isinstance(n, Node):
@@ -200,7 +191,7 @@ class Node(with_metaclass(NodeType, object)):
         todo = deque([self])
         while todo:
             node = todo.popleft()
-            if 'ctx' in node.fields:
+            if "ctx" in node.fields:
                 node.ctx = ctx
             todo.extend(node.iter_child_nodes())
         return self
@@ -210,7 +201,7 @@ class Node(with_metaclass(NodeType, object)):
         todo = deque([self])
         while todo:
             node = todo.popleft()
-            if 'lineno' in node.attributes:
+            if "lineno" in node.attributes:
                 if node.lineno is None or override:
                     node.lineno = lineno
             todo.extend(node.iter_child_nodes())
@@ -226,8 +217,9 @@ class Node(with_metaclass(NodeType, object)):
         return self
 
     def __eq__(self, other):
-        return type(self) is type(other) and \
-               tuple(self.iter_fields()) == tuple(other.iter_fields())
+        return type(self) is type(other) and tuple(self.iter_fields()) == tuple(
+            other.iter_fields()
+        )
 
     def __ne__(self, other):
         return not self.__eq__(other)
@@ -236,10 +228,9 @@ class Node(with_metaclass(NodeType, object)):
     __hash__ = object.__hash__
 
     def __repr__(self):
-        return '%s(%s)' % (
+        return "%s(%s)" % (
             self.__class__.__name__,
-            ', '.join('%s=%r' % (arg, getattr(self, arg, None)) for
-                      arg in self.fields)
+            ", ".join("%s=%r" % (arg, getattr(self, arg, None)) for arg in self.fields),
         )
 
     def dump(self):
@@ -248,37 +239,39 @@ class Node(with_metaclass(NodeType, object)):
                 buf.append(repr(node))
                 return
 
-            buf.append('nodes.%s(' % node.__class__.__name__)
+            buf.append("nodes.%s(" % node.__class__.__name__)
             if not node.fields:
-                buf.append(')')
+                buf.append(")")
                 return
             for idx, field in enumerate(node.fields):
                 if idx:
-                    buf.append(', ')
+                    buf.append(", ")
                 value = getattr(node, field)
                 if isinstance(value, list):
-                    buf.append('[')
+                    buf.append("[")
                     for idx, item in enumerate(value):
                         if idx:
-                            buf.append(', ')
+                            buf.append(", ")
                         _dump(item)
-                    buf.append(']')
+                    buf.append("]")
                 else:
                     _dump(value)
-            buf.append(')')
+            buf.append(")")
+
         buf = []
         _dump(self)
-        return ''.join(buf)
-
+        return "".join(buf)
 
 
 class Stmt(Node):
     """Base node for all statements."""
+
     abstract = True
 
 
 class Helper(Node):
     """Nodes that exist in a specific context only."""
+
     abstract = True
 
 
@@ -286,19 +279,22 @@ class Template(Node):
     """Node that represents a template.  This must be the outermost node that
     is passed to the compiler.
     """
-    fields = ('body',)
+
+    fields = ("body",)
 
 
 class Output(Stmt):
     """A node that holds multiple expressions which are then printed out.
     This is used both for the `print` statement and the regular template data.
     """
-    fields = ('nodes',)
+
+    fields = ("nodes",)
 
 
 class Extends(Stmt):
     """Represents an extends statement."""
-    fields = ('template',)
+
+    fields = ("template",)
 
 
 class For(Stmt):
@@ -309,12 +305,14 @@ class For(Stmt):
 
     For filtered nodes an expression can be stored as `test`, otherwise `None`.
     """
-    fields = ('target', 'iter', 'body', 'else_', 'test', 'recursive')
+
+    fields = ("target", "iter", "body", "else_", "test", "recursive")
 
 
 class If(Stmt):
     """If `test` is true, `body` is rendered, else `else_`."""
-    fields = ('test', 'body', 'elif_', 'else_')
+
+    fields = ("test", "body", "elif_", "else_")
 
 
 class Macro(Stmt):
@@ -322,19 +320,22 @@ class Macro(Stmt):
     arguments and `defaults` a list of defaults if there are any.  `body` is
     a list of nodes for the macro body.
     """
-    fields = ('name', 'args', 'defaults', 'body')
+
+    fields = ("name", "args", "defaults", "body")
 
 
 class CallBlock(Stmt):
     """Like a macro without a name but a call instead.  `call` is called with
     the unnamed macro as `caller` argument this node holds.
     """
-    fields = ('call', 'args', 'defaults', 'body')
+
+    fields = ("call", "args", "defaults", "body")
 
 
 class FilterBlock(Stmt):
     """Node for filter sections."""
-    fields = ('body', 'filter')
+
+    fields = ("body", "filter")
 
 
 class With(Stmt):
@@ -343,22 +344,26 @@ class With(Stmt):
 
     .. versionadded:: 2.9.3
     """
-    fields = ('targets', 'values', 'body')
+
+    fields = ("targets", "values", "body")
 
 
 class Block(Stmt):
     """A node that represents a block."""
-    fields = ('name', 'body', 'scoped')
+
+    fields = ("name", "body", "scoped")
 
 
 class Include(Stmt):
     """A node that represents the include tag."""
-    fields = ('template', 'with_context', 'ignore_missing')
+
+    fields = ("template", "with_context", "ignore_missing")
 
 
 class Import(Stmt):
     """A node that represents the import tag."""
-    fields = ('template', 'target', 'with_context')
+
+    fields = ("template", "target", "with_context")
 
 
 class FromImport(Stmt):
@@ -372,26 +377,31 @@ class FromImport(Stmt):
 
     The list of names may contain tuples if aliases are wanted.
     """
-    fields = ('template', 'names', 'with_context')
+
+    fields = ("template", "names", "with_context")
 
 
 class ExprStmt(Stmt):
     """A statement that evaluates an expression and discards the result."""
-    fields = ('node',)
+
+    fields = ("node",)
 
 
 class Assign(Stmt):
     """Assigns an expression to a target."""
-    fields = ('target', 'node')
+
+    fields = ("target", "node")
 
 
 class AssignBlock(Stmt):
     """Assigns a block to a target."""
-    fields = ('target', 'filter', 'body')
+
+    fields = ("target", "filter", "body")
 
 
 class Expr(Node):
     """Baseclass for all expressions."""
+
     abstract = True
 
     def as_const(self, eval_ctx=None):
@@ -414,15 +424,18 @@ class Expr(Node):
 
 class BinExpr(Expr):
     """Baseclass for all binary expressions."""
-    fields = ('left', 'right')
+
+    fields = ("left", "right")
     operator = None
     abstract = True
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
         # intercepted operators cannot be folded at compile time
-        if self.environment.sandboxed and \
-           self.operator in self.environment.intercepted_binops:
+        if (
+            self.environment.sandboxed
+            and self.operator in self.environment.intercepted_binops
+        ):
             raise Impossible()
         f = _binop_to_func[self.operator]
         try:
@@ -433,15 +446,18 @@ class BinExpr(Expr):
 
 class UnaryExpr(Expr):
     """Baseclass for all unary expressions."""
-    fields = ('node',)
+
+    fields = ("node",)
     operator = None
     abstract = True
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
         # intercepted operators cannot be folded at compile time
-        if self.environment.sandboxed and \
-           self.operator in self.environment.intercepted_unops:
+        if (
+            self.environment.sandboxed
+            and self.operator in self.environment.intercepted_unops
+        ):
             raise Impossible()
         f = _uaop_to_func[self.operator]
         try:
@@ -458,16 +474,17 @@ class Name(Expr):
     -   `load`: load that name
     -   `param`: like `store` but if the name was defined as function parameter.
     """
-    fields = ('name', 'ctx')
+
+    fields = ("name", "ctx")
 
     def can_assign(self):
-        return self.name not in ('true', 'false', 'none',
-                                 'True', 'False', 'None')
+        return self.name not in ("true", "false", "none", "True", "False", "None")
 
 
 class NSRef(Expr):
     """Reference to a namespace value assignment"""
-    fields = ('name', 'attr')
+
+    fields = ("name", "attr")
 
     def can_assign(self):
         # We don't need any special checks here; NSRef assignments have a
@@ -479,6 +496,7 @@ class NSRef(Expr):
 
 class Literal(Expr):
     """Baseclass for literals."""
+
     abstract = True
 
 
@@ -488,14 +506,18 @@ class Const(Literal):
     complex values such as lists too.  Only constants with a safe
     representation (objects where ``eval(repr(x)) == x`` is true).
     """
-    fields = ('value',)
+
+    fields = ("value",)
 
     def as_const(self, eval_ctx=None):
         rv = self.value
-        if PY2 and type(rv) is text_type and \
-           self.environment.policies['compiler.ascii_str']:
+        if (
+            PY2
+            and type(rv) is text_type
+            and self.environment.policies["compiler.ascii_str"]
+        ):
             try:
-                rv = rv.encode('ascii')
+                rv = rv.encode("ascii")
             except UnicodeError:
                 pass
         return rv
@@ -507,6 +529,7 @@ class Const(Literal):
         an `Impossible` exception.
         """
         from .compiler import has_safe_repr
+
         if not has_safe_repr(value):
             raise Impossible()
         return cls(value, lineno=lineno, environment=environment)
@@ -514,7 +537,8 @@ class Const(Literal):
 
 class TemplateData(Literal):
     """A constant template string."""
-    fields = ('data',)
+
+    fields = ("data",)
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -530,7 +554,8 @@ class Tuple(Literal):
     for subscripts.  Like for :class:`Name` `ctx` specifies if the tuple
     is used for loading the names or storing.
     """
-    fields = ('items', 'ctx')
+
+    fields = ("items", "ctx")
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -545,7 +570,8 @@ class Tuple(Literal):
 
 class List(Literal):
     """Any list literal such as ``[1, 2, 3]``"""
-    fields = ('items',)
+
+    fields = ("items",)
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -556,7 +582,8 @@ class Dict(Literal):
     """Any dict literal such as ``{1: 2, 3: 4}``.  The items must be a list of
     :class:`Pair` nodes.
     """
-    fields = ('items',)
+
+    fields = ("items",)
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -565,7 +592,8 @@ class Dict(Literal):
 
 class Pair(Helper):
     """A key, value pair for dicts."""
-    fields = ('key', 'value')
+
+    fields = ("key", "value")
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -574,7 +602,8 @@ class Pair(Helper):
 
 class Keyword(Helper):
     """A key, value pair for keyword arguments where key is a string."""
-    fields = ('key', 'value')
+
+    fields = ("key", "value")
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -585,7 +614,8 @@ class CondExpr(Expr):
     """A conditional expression (inline if expression).  (``{{
     foo if bar else baz }}``)
     """
-    fields = ('test', 'expr1', 'expr2')
+
+    fields = ("test", "expr1", "expr2")
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -626,7 +656,7 @@ class Filter(Expr):
     filtered.  Buffers are created by macros and filter blocks.
     """
 
-    fields = ('node', 'name', 'args', 'kwargs', 'dyn_args', 'dyn_kwargs')
+    fields = ("node", "name", "args", "kwargs", "dyn_args", "dyn_kwargs")
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -636,28 +666,27 @@ class Filter(Expr):
 
         # we have to be careful here because we call filter_ below.
         # if this variable would be called filter, 2to3 would wrap the
-        # call in a list beause it is assuming we are talking about the
+        # call in a list because it is assuming we are talking about the
         # builtin filter function here which no longer returns a list in
         # python 3.  because of that, do not rename filter_ to filter!
         filter_ = self.environment.filters.get(self.name)
 
-        if filter_ is None or getattr(filter_, 'contextfilter', False):
+        if filter_ is None or getattr(filter_, "contextfilter", False):
             raise Impossible()
 
         # We cannot constant handle async filters, so we need to make sure
         # to not go down this path.
-        if (
-            eval_ctx.environment.is_async
-            and getattr(filter_, 'asyncfiltervariant', False)
+        if eval_ctx.environment.is_async and getattr(
+            filter_, "asyncfiltervariant", False
         ):
             raise Impossible()
 
         args, kwargs = args_as_const(self, eval_ctx)
         args.insert(0, self.node.as_const(eval_ctx))
 
-        if getattr(filter_, 'evalcontextfilter', False):
+        if getattr(filter_, "evalcontextfilter", False):
             args.insert(0, eval_ctx)
-        elif getattr(filter_, 'environmentfilter', False):
+        elif getattr(filter_, "environmentfilter", False):
             args.insert(0, self.environment)
 
         try:
@@ -671,7 +700,7 @@ class Test(Expr):
     rest of the fields are the same as for :class:`Call`.
     """
 
-    fields = ('node', 'name', 'args', 'kwargs', 'dyn_args', 'dyn_kwargs')
+    fields = ("node", "name", "args", "kwargs", "dyn_args", "dyn_kwargs")
 
     def as_const(self, eval_ctx=None):
         test = self.environment.tests.get(self.name)
@@ -696,20 +725,23 @@ class Call(Expr):
     node for dynamic positional (``*args``) or keyword (``**kwargs``)
     arguments.
     """
-    fields = ('node', 'args', 'kwargs', 'dyn_args', 'dyn_kwargs')
+
+    fields = ("node", "args", "kwargs", "dyn_args", "dyn_kwargs")
 
 
 class Getitem(Expr):
     """Get an attribute or item from an expression and prefer the item."""
-    fields = ('node', 'arg', 'ctx')
+
+    fields = ("node", "arg", "ctx")
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
-        if self.ctx != 'load':
+        if self.ctx != "load":
             raise Impossible()
         try:
-            return self.environment.getitem(self.node.as_const(eval_ctx),
-                                            self.arg.as_const(eval_ctx))
+            return self.environment.getitem(
+                self.node.as_const(eval_ctx), self.arg.as_const(eval_ctx)
+            )
         except Exception:
             raise Impossible()
 
@@ -721,15 +753,15 @@ class Getattr(Expr):
     """Get an attribute or item from an expression that is a ascii-only
     bytestring and prefer the attribute.
     """
-    fields = ('node', 'attr', 'ctx')
+
+    fields = ("node", "attr", "ctx")
 
     def as_const(self, eval_ctx=None):
-        if self.ctx != 'load':
+        if self.ctx != "load":
             raise Impossible()
         try:
             eval_ctx = get_eval_context(self, eval_ctx)
-            return self.environment.getattr(self.node.as_const(eval_ctx),
-                                            self.attr)
+            return self.environment.getattr(self.node.as_const(eval_ctx), self.attr)
         except Exception:
             raise Impossible()
 
@@ -741,14 +773,17 @@ class Slice(Expr):
     """Represents a slice object.  This must only be used as argument for
     :class:`Subscript`.
     """
-    fields = ('start', 'stop', 'step')
+
+    fields = ("start", "stop", "step")
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
+
         def const(obj):
             if obj is None:
                 return None
             return obj.as_const(eval_ctx)
+
         return slice(const(self.start), const(self.stop), const(self.step))
 
 
@@ -756,82 +791,103 @@ class Concat(Expr):
     """Concatenates the list of expressions provided after converting them to
     unicode.
     """
-    fields = ('nodes',)
+
+    fields = ("nodes",)
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
-        return ''.join(text_type(x.as_const(eval_ctx)) for x in self.nodes)
+        return "".join(text_type(x.as_const(eval_ctx)) for x in self.nodes)
 
 
 class Compare(Expr):
     """Compares an expression with some other expressions.  `ops` must be a
     list of :class:`Operand`\\s.
     """
-    fields = ('expr', 'ops')
+
+    fields = ("expr", "ops")
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
         result = value = self.expr.as_const(eval_ctx)
+
         try:
             for op in self.ops:
                 new_value = op.expr.as_const(eval_ctx)
                 result = _cmpop_to_func[op.op](value, new_value)
+
+                if not result:
+                    return False
+
                 value = new_value
         except Exception:
             raise Impossible()
+
         return result
 
 
 class Operand(Helper):
     """Holds an operator and an expression."""
-    fields = ('op', 'expr')
+
+    fields = ("op", "expr")
+
 
 if __debug__:
-    Operand.__doc__ += '\nThe following operators are available: ' + \
-        ', '.join(sorted('``%s``' % x for x in set(_binop_to_func) |
-                  set(_uaop_to_func) | set(_cmpop_to_func)))
+    Operand.__doc__ += "\nThe following operators are available: " + ", ".join(
+        sorted(
+            "``%s``" % x
+            for x in set(_binop_to_func) | set(_uaop_to_func) | set(_cmpop_to_func)
+        )
+    )
 
 
 class Mul(BinExpr):
     """Multiplies the left with the right node."""
-    operator = '*'
+
+    operator = "*"
 
 
 class Div(BinExpr):
     """Divides the left by the right node."""
-    operator = '/'
+
+    operator = "/"
 
 
 class FloorDiv(BinExpr):
     """Divides the left by the right node and truncates conver the
     result into an integer by truncating.
     """
-    operator = '//'
+
+    operator = "//"
 
 
 class Add(BinExpr):
     """Add the left to the right node."""
-    operator = '+'
+
+    operator = "+"
 
 
 class Sub(BinExpr):
     """Subtract the right from the left node."""
-    operator = '-'
+
+    operator = "-"
 
 
 class Mod(BinExpr):
     """Left modulo right."""
-    operator = '%'
+
+    operator = "%"
 
 
 class Pow(BinExpr):
     """Left to the power of right."""
-    operator = '**'
+
+    operator = "**"
 
 
 class And(BinExpr):
     """Short circuited AND."""
-    operator = 'and'
+
+    operator = "and"
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -840,7 +896,8 @@ class And(BinExpr):
 
 class Or(BinExpr):
     """Short circuited OR."""
-    operator = 'or'
+
+    operator = "or"
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -849,17 +906,20 @@ class Or(BinExpr):
 
 class Not(UnaryExpr):
     """Negate the expression."""
-    operator = 'not'
+
+    operator = "not"
 
 
 class Neg(UnaryExpr):
     """Make the expression negative."""
-    operator = '-'
+
+    operator = "-"
 
 
 class Pos(UnaryExpr):
     """Make the expression positive (noop for most expressions)"""
-    operator = '+'
+
+    operator = "+"
 
 
 # Helpers for extensions
@@ -869,7 +929,8 @@ class EnvironmentAttribute(Expr):
     """Loads an attribute from the environment object.  This is useful for
     extensions that want to call a callback stored on the environment.
     """
-    fields = ('name',)
+
+    fields = ("name",)
 
 
 class ExtensionAttribute(Expr):
@@ -879,7 +940,8 @@ class ExtensionAttribute(Expr):
     This node is usually constructed by calling the
     :meth:`~jinja2.ext.Extension.attr` method on an extension.
     """
-    fields = ('identifier', 'name')
+
+    fields = ("identifier", "name")
 
 
 class ImportedName(Expr):
@@ -888,7 +950,8 @@ class ImportedName(Expr):
     function from the cgi module on evaluation.  Imports are optimized by the
     compiler so there is no need to assign them to local variables.
     """
-    fields = ('importname',)
+
+    fields = ("importname",)
 
 
 class InternalName(Expr):
@@ -898,16 +961,20 @@ class InternalName(Expr):
     a new identifier for you.  This identifier is not available from the
     template and is not threated specially by the compiler.
     """
-    fields = ('name',)
+
+    fields = ("name",)
 
     def __init__(self):
-        raise TypeError('Can\'t create internal names.  Use the '
-                        '`free_identifier` method on a parser.')
+        raise TypeError(
+            "Can't create internal names.  Use the "
+            "`free_identifier` method on a parser."
+        )
 
 
 class MarkSafe(Expr):
     """Mark the wrapped expression as safe (wrap it as `Markup`)."""
-    fields = ('expr',)
+
+    fields = ("expr",)
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -920,7 +987,8 @@ class MarkSafeIfAutoescape(Expr):
 
     .. versionadded:: 2.5
     """
-    fields = ('expr',)
+
+    fields = ("expr",)
 
     def as_const(self, eval_ctx=None):
         eval_ctx = get_eval_context(self, eval_ctx)
@@ -942,6 +1010,20 @@ class ContextReference(Expr):
 
         Assign(Name('foo', ctx='store'),
                Getattr(ContextReference(), 'name'))
+
+    This is basically equivalent to using the
+    :func:`~jinja2.contextfunction` decorator when using the
+    high-level API, which causes a reference to the context to be passed
+    as the first argument to a function.
+    """
+
+
+class DerivedContextReference(Expr):
+    """Return the current template context including locals. Behaves
+    exactly like :class:`ContextReference`, but includes local
+    variables, such as from a ``for`` loop.
+
+    .. versionadded:: 2.11
     """
 
 
@@ -955,7 +1037,8 @@ class Break(Stmt):
 
 class Scope(Stmt):
     """An artificial scope."""
-    fields = ('body',)
+
+    fields = ("body",)
 
 
 class OverlayScope(Stmt):
@@ -971,7 +1054,8 @@ class OverlayScope(Stmt):
 
     .. versionadded:: 2.10
     """
-    fields = ('context', 'body')
+
+    fields = ("context", "body")
 
 
 class EvalContextModifier(Stmt):
@@ -982,7 +1066,8 @@ class EvalContextModifier(Stmt):
 
         EvalContextModifier(options=[Keyword('autoescape', Const(True))])
     """
-    fields = ('options',)
+
+    fields = ("options",)
 
 
 class ScopedEvalContextModifier(EvalContextModifier):
@@ -990,10 +1075,14 @@ class ScopedEvalContextModifier(EvalContextModifier):
     :class:`EvalContextModifier` but will only modify the
     :class:`~jinja2.nodes.EvalContext` for nodes in the :attr:`body`.
     """
-    fields = ('body',)
+
+    fields = ("body",)
 
 
 # make sure nobody creates custom nodes
 def _failing_new(*args, **kwargs):
-    raise TypeError('can\'t create custom node types')
-NodeType.__new__ = staticmethod(_failing_new); del _failing_new
+    raise TypeError("can't create custom node types")
+
+
+NodeType.__new__ = staticmethod(_failing_new)
+del _failing_new
diff --git a/pipenv/vendor/jinja2/optimizer.py b/pipenv/vendor/jinja2/optimizer.py
index 65ab3ceb..7bc78c45 100644
--- a/pipenv/vendor/jinja2/optimizer.py
+++ b/pipenv/vendor/jinja2/optimizer.py
@@ -1,23 +1,15 @@
 # -*- coding: utf-8 -*-
+"""The optimizer tries to constant fold expressions and modify the AST
+in place so that it should be faster to evaluate.
+
+Because the AST does not contain all the scoping information and the
+compiler has to find that out, we cannot do all the optimizations we
+want. For example, loop unrolling doesn't work because unrolled loops
+would have a different scope. The solution would be a second syntax tree
+that stored the scoping rules.
 """
-    jinja2.optimizer
-    ~~~~~~~~~~~~~~~~
-
-    The jinja optimizer is currently trying to constant fold a few expressions
-    and modify the AST in place so that it should be easier to evaluate it.
-
-    Because the AST does not contain all the scoping information and the
-    compiler has to find that out, we cannot do all the optimizations we
-    want.  For example loop unrolling doesn't work because unrolled loops would
-    have a different scoping.
-
-    The solution would be a second syntax tree that has the scoping rules stored.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD.
-"""
-from jinja2 import nodes
-from jinja2.visitor import NodeTransformer
+from . import nodes
+from .visitor import NodeTransformer
 
 
 def optimize(node, environment):
@@ -28,22 +20,22 @@ def optimize(node, environment):
 
 
 class Optimizer(NodeTransformer):
-
     def __init__(self, environment):
         self.environment = environment
 
-    def fold(self, node, eval_ctx=None):
-        """Do constant folding."""
-        node = self.generic_visit(node)
-        try:
-            return nodes.Const.from_untrusted(node.as_const(eval_ctx),
-                                              lineno=node.lineno,
-                                              environment=self.environment)
-        except nodes.Impossible:
-            return node
-
-    visit_Add = visit_Sub = visit_Mul = visit_Div = visit_FloorDiv = \
-    visit_Pow = visit_Mod = visit_And = visit_Or = visit_Pos = visit_Neg = \
-    visit_Not = visit_Compare = visit_Getitem = visit_Getattr = visit_Call = \
-    visit_Filter = visit_Test = visit_CondExpr = fold
-    del fold
+    def generic_visit(self, node, *args, **kwargs):
+        node = super(Optimizer, self).generic_visit(node, *args, **kwargs)
+
+        # Do constant folding. Some other nodes besides Expr have
+        # as_const, but folding them causes errors later on.
+        if isinstance(node, nodes.Expr):
+            try:
+                return nodes.Const.from_untrusted(
+                    node.as_const(args[0] if args else None),
+                    lineno=node.lineno,
+                    environment=self.environment,
+                )
+            except nodes.Impossible:
+                pass
+
+        return node
diff --git a/pipenv/vendor/jinja2/parser.py b/pipenv/vendor/jinja2/parser.py
index ed00d970..d5881066 100644
--- a/pipenv/vendor/jinja2/parser.py
+++ b/pipenv/vendor/jinja2/parser.py
@@ -1,41 +1,46 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.parser
-    ~~~~~~~~~~~~~
-
-    Implements the template parser.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
-from jinja2 import nodes
-from jinja2.exceptions import TemplateSyntaxError, TemplateAssertionError
-from jinja2.lexer import describe_token, describe_token_expr
-from jinja2._compat import imap
-
-
-_statement_keywords = frozenset(['for', 'if', 'block', 'extends', 'print',
-                                 'macro', 'include', 'from', 'import',
-                                 'set', 'with', 'autoescape'])
-_compare_operators = frozenset(['eq', 'ne', 'lt', 'lteq', 'gt', 'gteq'])
+"""Parse tokens from the lexer into nodes for the compiler."""
+from . import nodes
+from ._compat import imap
+from .exceptions import TemplateAssertionError
+from .exceptions import TemplateSyntaxError
+from .lexer import describe_token
+from .lexer import describe_token_expr
+
+_statement_keywords = frozenset(
+    [
+        "for",
+        "if",
+        "block",
+        "extends",
+        "print",
+        "macro",
+        "include",
+        "from",
+        "import",
+        "set",
+        "with",
+        "autoescape",
+    ]
+)
+_compare_operators = frozenset(["eq", "ne", "lt", "lteq", "gt", "gteq"])
 
 _math_nodes = {
-    'add': nodes.Add,
-    'sub': nodes.Sub,
-    'mul': nodes.Mul,
-    'div': nodes.Div,
-    'floordiv': nodes.FloorDiv,
-    'mod': nodes.Mod,
+    "add": nodes.Add,
+    "sub": nodes.Sub,
+    "mul": nodes.Mul,
+    "div": nodes.Div,
+    "floordiv": nodes.FloorDiv,
+    "mod": nodes.Mod,
 }
 
 
 class Parser(object):
-    """This is the central parsing class Jinja2 uses.  It's passed to
+    """This is the central parsing class Jinja uses.  It's passed to
     extensions and can be used to parse expressions or statements.
     """
 
-    def __init__(self, environment, source, name=None, filename=None,
-                 state=None):
+    def __init__(self, environment, source, name=None, filename=None, state=None):
         self.environment = environment
         self.stream = environment._tokenize(source, name, filename, state)
         self.name = name
@@ -63,31 +68,37 @@ class Parser(object):
         for exprs in end_token_stack:
             expected.extend(imap(describe_token_expr, exprs))
         if end_token_stack:
-            currently_looking = ' or '.join(
-                "'%s'" % describe_token_expr(expr)
-                for expr in end_token_stack[-1])
+            currently_looking = " or ".join(
+                "'%s'" % describe_token_expr(expr) for expr in end_token_stack[-1]
+            )
         else:
             currently_looking = None
 
         if name is None:
-            message = ['Unexpected end of template.']
+            message = ["Unexpected end of template."]
         else:
-            message = ['Encountered unknown tag \'%s\'.' % name]
+            message = ["Encountered unknown tag '%s'." % name]
 
         if currently_looking:
             if name is not None and name in expected:
-                message.append('You probably made a nesting mistake. Jinja '
-                               'is expecting this tag, but currently looking '
-                               'for %s.' % currently_looking)
+                message.append(
+                    "You probably made a nesting mistake. Jinja "
+                    "is expecting this tag, but currently looking "
+                    "for %s." % currently_looking
+                )
             else:
-                message.append('Jinja was looking for the following tags: '
-                               '%s.' % currently_looking)
+                message.append(
+                    "Jinja was looking for the following tags: "
+                    "%s." % currently_looking
+                )
 
         if self._tag_stack:
-            message.append('The innermost block that needs to be '
-                           'closed is \'%s\'.' % self._tag_stack[-1])
+            message.append(
+                "The innermost block that needs to be "
+                "closed is '%s'." % self._tag_stack[-1]
+            )
 
-        self.fail(' '.join(message), lineno)
+        self.fail(" ".join(message), lineno)
 
     def fail_unknown_tag(self, name, lineno=None):
         """Called if the parser encounters an unknown tag.  Tries to fail
@@ -105,7 +116,7 @@ class Parser(object):
 
     def is_tuple_end(self, extra_end_rules=None):
         """Are we at the end of a tuple?"""
-        if self.stream.current.type in ('variable_end', 'block_end', 'rparen'):
+        if self.stream.current.type in ("variable_end", "block_end", "rparen"):
             return True
         elif extra_end_rules is not None:
             return self.stream.current.test_any(extra_end_rules)
@@ -115,22 +126,22 @@ class Parser(object):
         """Return a new free identifier as :class:`~jinja2.nodes.InternalName`."""
         self._last_identifier += 1
         rv = object.__new__(nodes.InternalName)
-        nodes.Node.__init__(rv, 'fi%d' % self._last_identifier, lineno=lineno)
+        nodes.Node.__init__(rv, "fi%d" % self._last_identifier, lineno=lineno)
         return rv
 
     def parse_statement(self):
         """Parse a single statement."""
         token = self.stream.current
-        if token.type != 'name':
-            self.fail('tag name expected', token.lineno)
+        if token.type != "name":
+            self.fail("tag name expected", token.lineno)
         self._tag_stack.append(token.value)
         pop_tag = True
         try:
             if token.value in _statement_keywords:
-                return getattr(self, 'parse_' + self.stream.current.value)()
-            if token.value == 'call':
+                return getattr(self, "parse_" + self.stream.current.value)()
+            if token.value == "call":
                 return self.parse_call_block()
-            if token.value == 'filter':
+            if token.value == "filter":
                 return self.parse_filter_block()
             ext = self.extensions.get(token.value)
             if ext is not None:
@@ -157,16 +168,16 @@ class Parser(object):
         can be set to `True` and the end token is removed.
         """
         # the first token may be a colon for python compatibility
-        self.stream.skip_if('colon')
+        self.stream.skip_if("colon")
 
         # in the future it would be possible to add whole code sections
         # by adding some sort of end of statement token and parsing those here.
-        self.stream.expect('block_end')
+        self.stream.expect("block_end")
         result = self.subparse(end_tokens)
 
         # we reached the end of the template too early, the subparser
         # does not check for this, so we do that now
-        if self.stream.current.type == 'eof':
+        if self.stream.current.type == "eof":
             self.fail_eof(end_tokens)
 
         if drop_needle:
@@ -177,50 +188,47 @@ class Parser(object):
         """Parse an assign statement."""
         lineno = next(self.stream).lineno
         target = self.parse_assign_target(with_namespace=True)
-        if self.stream.skip_if('assign'):
+        if self.stream.skip_if("assign"):
             expr = self.parse_tuple()
             return nodes.Assign(target, expr, lineno=lineno)
         filter_node = self.parse_filter(None)
-        body = self.parse_statements(('name:endset',),
-                                     drop_needle=True)
+        body = self.parse_statements(("name:endset",), drop_needle=True)
         return nodes.AssignBlock(target, filter_node, body, lineno=lineno)
 
     def parse_for(self):
         """Parse a for loop."""
-        lineno = self.stream.expect('name:for').lineno
-        target = self.parse_assign_target(extra_end_rules=('name:in',))
-        self.stream.expect('name:in')
-        iter = self.parse_tuple(with_condexpr=False,
-                                extra_end_rules=('name:recursive',))
+        lineno = self.stream.expect("name:for").lineno
+        target = self.parse_assign_target(extra_end_rules=("name:in",))
+        self.stream.expect("name:in")
+        iter = self.parse_tuple(
+            with_condexpr=False, extra_end_rules=("name:recursive",)
+        )
         test = None
-        if self.stream.skip_if('name:if'):
+        if self.stream.skip_if("name:if"):
             test = self.parse_expression()
-        recursive = self.stream.skip_if('name:recursive')
-        body = self.parse_statements(('name:endfor', 'name:else'))
-        if next(self.stream).value == 'endfor':
+        recursive = self.stream.skip_if("name:recursive")
+        body = self.parse_statements(("name:endfor", "name:else"))
+        if next(self.stream).value == "endfor":
             else_ = []
         else:
-            else_ = self.parse_statements(('name:endfor',), drop_needle=True)
-        return nodes.For(target, iter, body, else_, test,
-                         recursive, lineno=lineno)
+            else_ = self.parse_statements(("name:endfor",), drop_needle=True)
+        return nodes.For(target, iter, body, else_, test, recursive, lineno=lineno)
 
     def parse_if(self):
         """Parse an if construct."""
-        node = result = nodes.If(lineno=self.stream.expect('name:if').lineno)
+        node = result = nodes.If(lineno=self.stream.expect("name:if").lineno)
         while 1:
             node.test = self.parse_tuple(with_condexpr=False)
-            node.body = self.parse_statements(('name:elif', 'name:else',
-                                               'name:endif'))
+            node.body = self.parse_statements(("name:elif", "name:else", "name:endif"))
             node.elif_ = []
             node.else_ = []
             token = next(self.stream)
-            if token.test('name:elif'):
+            if token.test("name:elif"):
                 node = nodes.If(lineno=self.stream.current.lineno)
                 result.elif_.append(node)
                 continue
-            elif token.test('name:else'):
-                result.else_ = self.parse_statements(('name:endif',),
-                                                     drop_needle=True)
+            elif token.test("name:else"):
+                result.else_ = self.parse_statements(("name:endif",), drop_needle=True)
             break
         return result
 
@@ -228,45 +236,42 @@ class Parser(object):
         node = nodes.With(lineno=next(self.stream).lineno)
         targets = []
         values = []
-        while self.stream.current.type != 'block_end':
-            lineno = self.stream.current.lineno
+        while self.stream.current.type != "block_end":
             if targets:
-                self.stream.expect('comma')
+                self.stream.expect("comma")
             target = self.parse_assign_target()
-            target.set_ctx('param')
+            target.set_ctx("param")
             targets.append(target)
-            self.stream.expect('assign')
+            self.stream.expect("assign")
             values.append(self.parse_expression())
         node.targets = targets
         node.values = values
-        node.body = self.parse_statements(('name:endwith',),
-                                          drop_needle=True)
+        node.body = self.parse_statements(("name:endwith",), drop_needle=True)
         return node
 
     def parse_autoescape(self):
         node = nodes.ScopedEvalContextModifier(lineno=next(self.stream).lineno)
-        node.options = [
-            nodes.Keyword('autoescape', self.parse_expression())
-        ]
-        node.body = self.parse_statements(('name:endautoescape',),
-                                            drop_needle=True)
+        node.options = [nodes.Keyword("autoescape", self.parse_expression())]
+        node.body = self.parse_statements(("name:endautoescape",), drop_needle=True)
         return nodes.Scope([node])
 
     def parse_block(self):
         node = nodes.Block(lineno=next(self.stream).lineno)
-        node.name = self.stream.expect('name').value
-        node.scoped = self.stream.skip_if('name:scoped')
+        node.name = self.stream.expect("name").value
+        node.scoped = self.stream.skip_if("name:scoped")
 
         # common problem people encounter when switching from django
         # to jinja.  we do not support hyphens in block names, so let's
         # raise a nicer error message in that case.
-        if self.stream.current.type == 'sub':
-            self.fail('Block names in Jinja have to be valid Python '
-                      'identifiers and may not contain hyphens, use an '
-                      'underscore instead.')
-
-        node.body = self.parse_statements(('name:endblock',), drop_needle=True)
-        self.stream.skip_if('name:' + node.name)
+        if self.stream.current.type == "sub":
+            self.fail(
+                "Block names in Jinja have to be valid Python "
+                "identifiers and may not contain hyphens, use an "
+                "underscore instead."
+            )
+
+        node.body = self.parse_statements(("name:endblock",), drop_needle=True)
+        self.stream.skip_if("name:" + node.name)
         return node
 
     def parse_extends(self):
@@ -275,9 +280,10 @@ class Parser(object):
         return node
 
     def parse_import_context(self, node, default):
-        if self.stream.current.test_any('name:with', 'name:without') and \
-           self.stream.look().test('name:context'):
-            node.with_context = next(self.stream).value == 'with'
+        if self.stream.current.test_any(
+            "name:with", "name:without"
+        ) and self.stream.look().test("name:context"):
+            node.with_context = next(self.stream).value == "with"
             self.stream.skip()
         else:
             node.with_context = default
@@ -286,8 +292,9 @@ class Parser(object):
     def parse_include(self):
         node = nodes.Include(lineno=next(self.stream).lineno)
         node.template = self.parse_expression()
-        if self.stream.current.test('name:ignore') and \
-           self.stream.look().test('name:missing'):
+        if self.stream.current.test("name:ignore") and self.stream.look().test(
+            "name:missing"
+        ):
             node.ignore_missing = True
             self.stream.skip(2)
         else:
@@ -297,67 +304,71 @@ class Parser(object):
     def parse_import(self):
         node = nodes.Import(lineno=next(self.stream).lineno)
         node.template = self.parse_expression()
-        self.stream.expect('name:as')
+        self.stream.expect("name:as")
         node.target = self.parse_assign_target(name_only=True).name
         return self.parse_import_context(node, False)
 
     def parse_from(self):
         node = nodes.FromImport(lineno=next(self.stream).lineno)
         node.template = self.parse_expression()
-        self.stream.expect('name:import')
+        self.stream.expect("name:import")
         node.names = []
 
         def parse_context():
-            if self.stream.current.value in ('with', 'without') and \
-               self.stream.look().test('name:context'):
-                node.with_context = next(self.stream).value == 'with'
+            if self.stream.current.value in (
+                "with",
+                "without",
+            ) and self.stream.look().test("name:context"):
+                node.with_context = next(self.stream).value == "with"
                 self.stream.skip()
                 return True
             return False
 
         while 1:
             if node.names:
-                self.stream.expect('comma')
-            if self.stream.current.type == 'name':
+                self.stream.expect("comma")
+            if self.stream.current.type == "name":
                 if parse_context():
                     break
                 target = self.parse_assign_target(name_only=True)
-                if target.name.startswith('_'):
-                    self.fail('names starting with an underline can not '
-                              'be imported', target.lineno,
-                              exc=TemplateAssertionError)
-                if self.stream.skip_if('name:as'):
+                if target.name.startswith("_"):
+                    self.fail(
+                        "names starting with an underline can not be imported",
+                        target.lineno,
+                        exc=TemplateAssertionError,
+                    )
+                if self.stream.skip_if("name:as"):
                     alias = self.parse_assign_target(name_only=True)
                     node.names.append((target.name, alias.name))
                 else:
                     node.names.append(target.name)
-                if parse_context() or self.stream.current.type != 'comma':
+                if parse_context() or self.stream.current.type != "comma":
                     break
             else:
-                self.stream.expect('name')
-        if not hasattr(node, 'with_context'):
+                self.stream.expect("name")
+        if not hasattr(node, "with_context"):
             node.with_context = False
         return node
 
     def parse_signature(self, node):
         node.args = args = []
         node.defaults = defaults = []
-        self.stream.expect('lparen')
-        while self.stream.current.type != 'rparen':
+        self.stream.expect("lparen")
+        while self.stream.current.type != "rparen":
             if args:
-                self.stream.expect('comma')
+                self.stream.expect("comma")
             arg = self.parse_assign_target(name_only=True)
-            arg.set_ctx('param')
-            if self.stream.skip_if('assign'):
+            arg.set_ctx("param")
+            if self.stream.skip_if("assign"):
                 defaults.append(self.parse_expression())
             elif defaults:
-                self.fail('non-default argument follows default argument')
+                self.fail("non-default argument follows default argument")
             args.append(arg)
-        self.stream.expect('rparen')
+        self.stream.expect("rparen")
 
     def parse_call_block(self):
         node = nodes.CallBlock(lineno=next(self.stream).lineno)
-        if self.stream.current.type == 'lparen':
+        if self.stream.current.type == "lparen":
             self.parse_signature(node)
         else:
             node.args = []
@@ -365,37 +376,40 @@ class Parser(object):
 
         node.call = self.parse_expression()
         if not isinstance(node.call, nodes.Call):
-            self.fail('expected call', node.lineno)
-        node.body = self.parse_statements(('name:endcall',), drop_needle=True)
+            self.fail("expected call", node.lineno)
+        node.body = self.parse_statements(("name:endcall",), drop_needle=True)
         return node
 
     def parse_filter_block(self):
         node = nodes.FilterBlock(lineno=next(self.stream).lineno)
         node.filter = self.parse_filter(None, start_inline=True)
-        node.body = self.parse_statements(('name:endfilter',),
-                                          drop_needle=True)
+        node.body = self.parse_statements(("name:endfilter",), drop_needle=True)
         return node
 
     def parse_macro(self):
         node = nodes.Macro(lineno=next(self.stream).lineno)
         node.name = self.parse_assign_target(name_only=True).name
         self.parse_signature(node)
-        node.body = self.parse_statements(('name:endmacro',),
-                                          drop_needle=True)
+        node.body = self.parse_statements(("name:endmacro",), drop_needle=True)
         return node
 
     def parse_print(self):
         node = nodes.Output(lineno=next(self.stream).lineno)
         node.nodes = []
-        while self.stream.current.type != 'block_end':
+        while self.stream.current.type != "block_end":
             if node.nodes:
-                self.stream.expect('comma')
+                self.stream.expect("comma")
             node.nodes.append(self.parse_expression())
         return node
 
-    def parse_assign_target(self, with_tuple=True, name_only=False,
-                            extra_end_rules=None, with_namespace=False):
-        """Parse an assignment target.  As Jinja2 allows assignments to
+    def parse_assign_target(
+        self,
+        with_tuple=True,
+        name_only=False,
+        extra_end_rules=None,
+        with_namespace=False,
+    ):
+        """Parse an assignment target.  As Jinja allows assignments to
         tuples, this function can parse all allowed assignment targets.  Per
         default assignments to tuples are parsed, that can be disable however
         by setting `with_tuple` to `False`.  If only assignments to names are
@@ -403,24 +417,26 @@ class Parser(object):
         parameter is forwarded to the tuple parsing function.  If
         `with_namespace` is enabled, a namespace assignment may be parsed.
         """
-        if with_namespace and self.stream.look().type == 'dot':
-            token = self.stream.expect('name')
+        if with_namespace and self.stream.look().type == "dot":
+            token = self.stream.expect("name")
             next(self.stream)  # dot
-            attr = self.stream.expect('name')
+            attr = self.stream.expect("name")
             target = nodes.NSRef(token.value, attr.value, lineno=token.lineno)
         elif name_only:
-            token = self.stream.expect('name')
-            target = nodes.Name(token.value, 'store', lineno=token.lineno)
+            token = self.stream.expect("name")
+            target = nodes.Name(token.value, "store", lineno=token.lineno)
         else:
             if with_tuple:
-                target = self.parse_tuple(simplified=True,
-                                          extra_end_rules=extra_end_rules)
+                target = self.parse_tuple(
+                    simplified=True, extra_end_rules=extra_end_rules
+                )
             else:
                 target = self.parse_primary()
-            target.set_ctx('store')
+            target.set_ctx("store")
         if not target.can_assign():
-            self.fail('can\'t assign to %r' % target.__class__.
-                      __name__.lower(), target.lineno)
+            self.fail(
+                "can't assign to %r" % target.__class__.__name__.lower(), target.lineno
+            )
         return target
 
     def parse_expression(self, with_condexpr=True):
@@ -435,9 +451,9 @@ class Parser(object):
     def parse_condexpr(self):
         lineno = self.stream.current.lineno
         expr1 = self.parse_or()
-        while self.stream.skip_if('name:if'):
+        while self.stream.skip_if("name:if"):
             expr2 = self.parse_or()
-            if self.stream.skip_if('name:else'):
+            if self.stream.skip_if("name:else"):
                 expr3 = self.parse_condexpr()
             else:
                 expr3 = None
@@ -448,7 +464,7 @@ class Parser(object):
     def parse_or(self):
         lineno = self.stream.current.lineno
         left = self.parse_and()
-        while self.stream.skip_if('name:or'):
+        while self.stream.skip_if("name:or"):
             right = self.parse_and()
             left = nodes.Or(left, right, lineno=lineno)
             lineno = self.stream.current.lineno
@@ -457,14 +473,14 @@ class Parser(object):
     def parse_and(self):
         lineno = self.stream.current.lineno
         left = self.parse_not()
-        while self.stream.skip_if('name:and'):
+        while self.stream.skip_if("name:and"):
             right = self.parse_not()
             left = nodes.And(left, right, lineno=lineno)
             lineno = self.stream.current.lineno
         return left
 
     def parse_not(self):
-        if self.stream.current.test('name:not'):
+        if self.stream.current.test("name:not"):
             lineno = next(self.stream).lineno
             return nodes.Not(self.parse_not(), lineno=lineno)
         return self.parse_compare()
@@ -478,12 +494,13 @@ class Parser(object):
             if token_type in _compare_operators:
                 next(self.stream)
                 ops.append(nodes.Operand(token_type, self.parse_math1()))
-            elif self.stream.skip_if('name:in'):
-                ops.append(nodes.Operand('in', self.parse_math1()))
-            elif (self.stream.current.test('name:not') and
-                  self.stream.look().test('name:in')):
+            elif self.stream.skip_if("name:in"):
+                ops.append(nodes.Operand("in", self.parse_math1()))
+            elif self.stream.current.test("name:not") and self.stream.look().test(
+                "name:in"
+            ):
                 self.stream.skip(2)
-                ops.append(nodes.Operand('notin', self.parse_math1()))
+                ops.append(nodes.Operand("notin", self.parse_math1()))
             else:
                 break
             lineno = self.stream.current.lineno
@@ -494,7 +511,7 @@ class Parser(object):
     def parse_math1(self):
         lineno = self.stream.current.lineno
         left = self.parse_concat()
-        while self.stream.current.type in ('add', 'sub'):
+        while self.stream.current.type in ("add", "sub"):
             cls = _math_nodes[self.stream.current.type]
             next(self.stream)
             right = self.parse_concat()
@@ -505,7 +522,7 @@ class Parser(object):
     def parse_concat(self):
         lineno = self.stream.current.lineno
         args = [self.parse_math2()]
-        while self.stream.current.type == 'tilde':
+        while self.stream.current.type == "tilde":
             next(self.stream)
             args.append(self.parse_math2())
         if len(args) == 1:
@@ -515,7 +532,7 @@ class Parser(object):
     def parse_math2(self):
         lineno = self.stream.current.lineno
         left = self.parse_pow()
-        while self.stream.current.type in ('mul', 'div', 'floordiv', 'mod'):
+        while self.stream.current.type in ("mul", "div", "floordiv", "mod"):
             cls = _math_nodes[self.stream.current.type]
             next(self.stream)
             right = self.parse_pow()
@@ -526,7 +543,7 @@ class Parser(object):
     def parse_pow(self):
         lineno = self.stream.current.lineno
         left = self.parse_unary()
-        while self.stream.current.type == 'pow':
+        while self.stream.current.type == "pow":
             next(self.stream)
             right = self.parse_unary()
             left = nodes.Pow(left, right, lineno=lineno)
@@ -536,10 +553,10 @@ class Parser(object):
     def parse_unary(self, with_filter=True):
         token_type = self.stream.current.type
         lineno = self.stream.current.lineno
-        if token_type == 'sub':
+        if token_type == "sub":
             next(self.stream)
             node = nodes.Neg(self.parse_unary(False), lineno=lineno)
-        elif token_type == 'add':
+        elif token_type == "add":
             next(self.stream)
             node = nodes.Pos(self.parse_unary(False), lineno=lineno)
         else:
@@ -551,40 +568,44 @@ class Parser(object):
 
     def parse_primary(self):
         token = self.stream.current
-        if token.type == 'name':
-            if token.value in ('true', 'false', 'True', 'False'):
-                node = nodes.Const(token.value in ('true', 'True'),
-                                   lineno=token.lineno)
-            elif token.value in ('none', 'None'):
+        if token.type == "name":
+            if token.value in ("true", "false", "True", "False"):
+                node = nodes.Const(token.value in ("true", "True"), lineno=token.lineno)
+            elif token.value in ("none", "None"):
                 node = nodes.Const(None, lineno=token.lineno)
             else:
-                node = nodes.Name(token.value, 'load', lineno=token.lineno)
+                node = nodes.Name(token.value, "load", lineno=token.lineno)
             next(self.stream)
-        elif token.type == 'string':
+        elif token.type == "string":
             next(self.stream)
             buf = [token.value]
             lineno = token.lineno
-            while self.stream.current.type == 'string':
+            while self.stream.current.type == "string":
                 buf.append(self.stream.current.value)
                 next(self.stream)
-            node = nodes.Const(''.join(buf), lineno=lineno)
-        elif token.type in ('integer', 'float'):
+            node = nodes.Const("".join(buf), lineno=lineno)
+        elif token.type in ("integer", "float"):
             next(self.stream)
             node = nodes.Const(token.value, lineno=token.lineno)
-        elif token.type == 'lparen':
+        elif token.type == "lparen":
             next(self.stream)
             node = self.parse_tuple(explicit_parentheses=True)
-            self.stream.expect('rparen')
-        elif token.type == 'lbracket':
+            self.stream.expect("rparen")
+        elif token.type == "lbracket":
             node = self.parse_list()
-        elif token.type == 'lbrace':
+        elif token.type == "lbrace":
             node = self.parse_dict()
         else:
             self.fail("unexpected '%s'" % describe_token(token), token.lineno)
         return node
 
-    def parse_tuple(self, simplified=False, with_condexpr=True,
-                    extra_end_rules=None, explicit_parentheses=False):
+    def parse_tuple(
+        self,
+        simplified=False,
+        with_condexpr=True,
+        extra_end_rules=None,
+        explicit_parentheses=False,
+    ):
         """Works like `parse_expression` but if multiple expressions are
         delimited by a comma a :class:`~jinja2.nodes.Tuple` node is created.
         This method could also return a regular expression instead of a tuple
@@ -609,16 +630,19 @@ class Parser(object):
         elif with_condexpr:
             parse = self.parse_expression
         else:
-            parse = lambda: self.parse_expression(with_condexpr=False)
+
+            def parse():
+                return self.parse_expression(with_condexpr=False)
+
         args = []
         is_tuple = False
         while 1:
             if args:
-                self.stream.expect('comma')
+                self.stream.expect("comma")
             if self.is_tuple_end(extra_end_rules):
                 break
             args.append(parse())
-            if self.stream.current.type == 'comma':
+            if self.stream.current.type == "comma":
                 is_tuple = True
             else:
                 break
@@ -633,46 +657,48 @@ class Parser(object):
             # nothing) in the spot of an expression would be an empty
             # tuple.
             if not explicit_parentheses:
-                self.fail('Expected an expression, got \'%s\'' %
-                          describe_token(self.stream.current))
+                self.fail(
+                    "Expected an expression, got '%s'"
+                    % describe_token(self.stream.current)
+                )
 
-        return nodes.Tuple(args, 'load', lineno=lineno)
+        return nodes.Tuple(args, "load", lineno=lineno)
 
     def parse_list(self):
-        token = self.stream.expect('lbracket')
+        token = self.stream.expect("lbracket")
         items = []
-        while self.stream.current.type != 'rbracket':
+        while self.stream.current.type != "rbracket":
             if items:
-                self.stream.expect('comma')
-            if self.stream.current.type == 'rbracket':
+                self.stream.expect("comma")
+            if self.stream.current.type == "rbracket":
                 break
             items.append(self.parse_expression())
-        self.stream.expect('rbracket')
+        self.stream.expect("rbracket")
         return nodes.List(items, lineno=token.lineno)
 
     def parse_dict(self):
-        token = self.stream.expect('lbrace')
+        token = self.stream.expect("lbrace")
         items = []
-        while self.stream.current.type != 'rbrace':
+        while self.stream.current.type != "rbrace":
             if items:
-                self.stream.expect('comma')
-            if self.stream.current.type == 'rbrace':
+                self.stream.expect("comma")
+            if self.stream.current.type == "rbrace":
                 break
             key = self.parse_expression()
-            self.stream.expect('colon')
+            self.stream.expect("colon")
             value = self.parse_expression()
             items.append(nodes.Pair(key, value, lineno=key.lineno))
-        self.stream.expect('rbrace')
+        self.stream.expect("rbrace")
         return nodes.Dict(items, lineno=token.lineno)
 
     def parse_postfix(self, node):
         while 1:
             token_type = self.stream.current.type
-            if token_type == 'dot' or token_type == 'lbracket':
+            if token_type == "dot" or token_type == "lbracket":
                 node = self.parse_subscript(node)
             # calls are valid both after postfix expressions (getattr
             # and getitem) as well as filters and tests
-            elif token_type == 'lparen':
+            elif token_type == "lparen":
                 node = self.parse_call(node)
             else:
                 break
@@ -681,13 +707,13 @@ class Parser(object):
     def parse_filter_expr(self, node):
         while 1:
             token_type = self.stream.current.type
-            if token_type == 'pipe':
+            if token_type == "pipe":
                 node = self.parse_filter(node)
-            elif token_type == 'name' and self.stream.current.value == 'is':
+            elif token_type == "name" and self.stream.current.value == "is":
                 node = self.parse_test(node)
             # calls are valid both after postfix expressions (getattr
             # and getitem) as well as filters and tests
-            elif token_type == 'lparen':
+            elif token_type == "lparen":
                 node = self.parse_call(node)
             else:
                 break
@@ -695,53 +721,54 @@ class Parser(object):
 
     def parse_subscript(self, node):
         token = next(self.stream)
-        if token.type == 'dot':
+        if token.type == "dot":
             attr_token = self.stream.current
             next(self.stream)
-            if attr_token.type == 'name':
-                return nodes.Getattr(node, attr_token.value, 'load',
-                                     lineno=token.lineno)
-            elif attr_token.type != 'integer':
-                self.fail('expected name or number', attr_token.lineno)
+            if attr_token.type == "name":
+                return nodes.Getattr(
+                    node, attr_token.value, "load", lineno=token.lineno
+                )
+            elif attr_token.type != "integer":
+                self.fail("expected name or number", attr_token.lineno)
             arg = nodes.Const(attr_token.value, lineno=attr_token.lineno)
-            return nodes.Getitem(node, arg, 'load', lineno=token.lineno)
-        if token.type == 'lbracket':
+            return nodes.Getitem(node, arg, "load", lineno=token.lineno)
+        if token.type == "lbracket":
             args = []
-            while self.stream.current.type != 'rbracket':
+            while self.stream.current.type != "rbracket":
                 if args:
-                    self.stream.expect('comma')
+                    self.stream.expect("comma")
                 args.append(self.parse_subscribed())
-            self.stream.expect('rbracket')
+            self.stream.expect("rbracket")
             if len(args) == 1:
                 arg = args[0]
             else:
-                arg = nodes.Tuple(args, 'load', lineno=token.lineno)
-            return nodes.Getitem(node, arg, 'load', lineno=token.lineno)
-        self.fail('expected subscript expression', self.lineno)
+                arg = nodes.Tuple(args, "load", lineno=token.lineno)
+            return nodes.Getitem(node, arg, "load", lineno=token.lineno)
+        self.fail("expected subscript expression", token.lineno)
 
     def parse_subscribed(self):
         lineno = self.stream.current.lineno
 
-        if self.stream.current.type == 'colon':
+        if self.stream.current.type == "colon":
             next(self.stream)
             args = [None]
         else:
             node = self.parse_expression()
-            if self.stream.current.type != 'colon':
+            if self.stream.current.type != "colon":
                 return node
             next(self.stream)
             args = [node]
 
-        if self.stream.current.type == 'colon':
+        if self.stream.current.type == "colon":
             args.append(None)
-        elif self.stream.current.type not in ('rbracket', 'comma'):
+        elif self.stream.current.type not in ("rbracket", "comma"):
             args.append(self.parse_expression())
         else:
             args.append(None)
 
-        if self.stream.current.type == 'colon':
+        if self.stream.current.type == "colon":
             next(self.stream)
-            if self.stream.current.type not in ('rbracket', 'comma'):
+            if self.stream.current.type not in ("rbracket", "comma"):
                 args.append(self.parse_expression())
             else:
                 args.append(None)
@@ -751,7 +778,7 @@ class Parser(object):
         return nodes.Slice(lineno=lineno, *args)
 
     def parse_call(self, node):
-        token = self.stream.expect('lparen')
+        token = self.stream.expect("lparen")
         args = []
         kwargs = []
         dyn_args = dyn_kwargs = None
@@ -759,91 +786,100 @@ class Parser(object):
 
         def ensure(expr):
             if not expr:
-                self.fail('invalid syntax for function call expression',
-                          token.lineno)
+                self.fail("invalid syntax for function call expression", token.lineno)
 
-        while self.stream.current.type != 'rparen':
+        while self.stream.current.type != "rparen":
             if require_comma:
-                self.stream.expect('comma')
+                self.stream.expect("comma")
                 # support for trailing comma
-                if self.stream.current.type == 'rparen':
+                if self.stream.current.type == "rparen":
                     break
-            if self.stream.current.type == 'mul':
+            if self.stream.current.type == "mul":
                 ensure(dyn_args is None and dyn_kwargs is None)
                 next(self.stream)
                 dyn_args = self.parse_expression()
-            elif self.stream.current.type == 'pow':
+            elif self.stream.current.type == "pow":
                 ensure(dyn_kwargs is None)
                 next(self.stream)
                 dyn_kwargs = self.parse_expression()
             else:
-                ensure(dyn_args is None and dyn_kwargs is None)
-                if self.stream.current.type == 'name' and \
-                   self.stream.look().type == 'assign':
+                if (
+                    self.stream.current.type == "name"
+                    and self.stream.look().type == "assign"
+                ):
+                    # Parsing a kwarg
+                    ensure(dyn_kwargs is None)
                     key = self.stream.current.value
                     self.stream.skip(2)
                     value = self.parse_expression()
-                    kwargs.append(nodes.Keyword(key, value,
-                                                lineno=value.lineno))
+                    kwargs.append(nodes.Keyword(key, value, lineno=value.lineno))
                 else:
-                    ensure(not kwargs)
+                    # Parsing an arg
+                    ensure(dyn_args is None and dyn_kwargs is None and not kwargs)
                     args.append(self.parse_expression())
 
             require_comma = True
-        self.stream.expect('rparen')
+        self.stream.expect("rparen")
 
         if node is None:
             return args, kwargs, dyn_args, dyn_kwargs
-        return nodes.Call(node, args, kwargs, dyn_args, dyn_kwargs,
-                          lineno=token.lineno)
+        return nodes.Call(node, args, kwargs, dyn_args, dyn_kwargs, lineno=token.lineno)
 
     def parse_filter(self, node, start_inline=False):
-        while self.stream.current.type == 'pipe' or start_inline:
+        while self.stream.current.type == "pipe" or start_inline:
             if not start_inline:
                 next(self.stream)
-            token = self.stream.expect('name')
+            token = self.stream.expect("name")
             name = token.value
-            while self.stream.current.type == 'dot':
+            while self.stream.current.type == "dot":
                 next(self.stream)
-                name += '.' + self.stream.expect('name').value
-            if self.stream.current.type == 'lparen':
+                name += "." + self.stream.expect("name").value
+            if self.stream.current.type == "lparen":
                 args, kwargs, dyn_args, dyn_kwargs = self.parse_call(None)
             else:
                 args = []
                 kwargs = []
                 dyn_args = dyn_kwargs = None
-            node = nodes.Filter(node, name, args, kwargs, dyn_args,
-                                dyn_kwargs, lineno=token.lineno)
+            node = nodes.Filter(
+                node, name, args, kwargs, dyn_args, dyn_kwargs, lineno=token.lineno
+            )
             start_inline = False
         return node
 
     def parse_test(self, node):
         token = next(self.stream)
-        if self.stream.current.test('name:not'):
+        if self.stream.current.test("name:not"):
             next(self.stream)
             negated = True
         else:
             negated = False
-        name = self.stream.expect('name').value
-        while self.stream.current.type == 'dot':
+        name = self.stream.expect("name").value
+        while self.stream.current.type == "dot":
             next(self.stream)
-            name += '.' + self.stream.expect('name').value
+            name += "." + self.stream.expect("name").value
         dyn_args = dyn_kwargs = None
         kwargs = []
-        if self.stream.current.type == 'lparen':
+        if self.stream.current.type == "lparen":
             args, kwargs, dyn_args, dyn_kwargs = self.parse_call(None)
-        elif (self.stream.current.type in ('name', 'string', 'integer',
-                                           'float', 'lparen', 'lbracket',
-                                           'lbrace') and not
-              self.stream.current.test_any('name:else', 'name:or',
-                                           'name:and')):
-            if self.stream.current.test('name:is'):
-                self.fail('You cannot chain multiple tests with is')
-            args = [self.parse_primary()]
+        elif self.stream.current.type in (
+            "name",
+            "string",
+            "integer",
+            "float",
+            "lparen",
+            "lbracket",
+            "lbrace",
+        ) and not self.stream.current.test_any("name:else", "name:or", "name:and"):
+            if self.stream.current.test("name:is"):
+                self.fail("You cannot chain multiple tests with is")
+            arg_node = self.parse_primary()
+            arg_node = self.parse_postfix(arg_node)
+            args = [arg_node]
         else:
             args = []
-        node = nodes.Test(node, name, args, kwargs, dyn_args,
-                          dyn_kwargs, lineno=token.lineno)
+        node = nodes.Test(
+            node, name, args, kwargs, dyn_args, dyn_kwargs, lineno=token.lineno
+        )
         if negated:
             node = nodes.Not(node, lineno=token.lineno)
         return node
@@ -865,29 +901,29 @@ class Parser(object):
         try:
             while self.stream:
                 token = self.stream.current
-                if token.type == 'data':
+                if token.type == "data":
                     if token.value:
-                        add_data(nodes.TemplateData(token.value,
-                                                    lineno=token.lineno))
+                        add_data(nodes.TemplateData(token.value, lineno=token.lineno))
                     next(self.stream)
-                elif token.type == 'variable_begin':
+                elif token.type == "variable_begin":
                     next(self.stream)
                     add_data(self.parse_tuple(with_condexpr=True))
-                    self.stream.expect('variable_end')
-                elif token.type == 'block_begin':
+                    self.stream.expect("variable_end")
+                elif token.type == "block_begin":
                     flush_data()
                     next(self.stream)
-                    if end_tokens is not None and \
-                       self.stream.current.test_any(*end_tokens):
+                    if end_tokens is not None and self.stream.current.test_any(
+                        *end_tokens
+                    ):
                         return body
                     rv = self.parse_statement()
                     if isinstance(rv, list):
                         body.extend(rv)
                     else:
                         body.append(rv)
-                    self.stream.expect('block_end')
+                    self.stream.expect("block_end")
                 else:
-                    raise AssertionError('internal parsing error')
+                    raise AssertionError("internal parsing error")
 
             flush_data()
         finally:
diff --git a/pipenv/vendor/jinja2/runtime.py b/pipenv/vendor/jinja2/runtime.py
index 5e313369..527d4b5e 100644
--- a/pipenv/vendor/jinja2/runtime.py
+++ b/pipenv/vendor/jinja2/runtime.py
@@ -1,43 +1,62 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.runtime
-    ~~~~~~~~~~~~~~
-
-    Runtime helpers.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD.
-"""
+"""The runtime functions and state used by compiled templates."""
 import sys
-
 from itertools import chain
 from types import MethodType
 
-from jinja2.nodes import EvalContext, _context_function_types
-from jinja2.utils import Markup, soft_unicode, escape, missing, concat, \
-     internalcode, object_type_repr, evalcontextfunction, Namespace
-from jinja2.exceptions import UndefinedError, TemplateRuntimeError, \
-     TemplateNotFound
-from jinja2._compat import imap, text_type, iteritems, \
-     implements_iterator, implements_to_string, string_types, PY2, \
-     with_metaclass, abc
-
+from markupsafe import escape  # noqa: F401
+from markupsafe import Markup
+from markupsafe import soft_unicode
+
+from ._compat import abc
+from ._compat import imap
+from ._compat import implements_iterator
+from ._compat import implements_to_string
+from ._compat import iteritems
+from ._compat import PY2
+from ._compat import string_types
+from ._compat import text_type
+from ._compat import with_metaclass
+from .exceptions import TemplateNotFound  # noqa: F401
+from .exceptions import TemplateRuntimeError  # noqa: F401
+from .exceptions import UndefinedError
+from .nodes import EvalContext
+from .utils import concat
+from .utils import evalcontextfunction
+from .utils import internalcode
+from .utils import missing
+from .utils import Namespace  # noqa: F401
+from .utils import object_type_repr
 
 # these variables are exported to the template runtime
-__all__ = ['LoopContext', 'TemplateReference', 'Macro', 'Markup',
-           'TemplateRuntimeError', 'missing', 'concat', 'escape',
-           'markup_join', 'unicode_join', 'to_string', 'identity',
-           'TemplateNotFound', 'Namespace']
+exported = [
+    "LoopContext",
+    "TemplateReference",
+    "Macro",
+    "Markup",
+    "TemplateRuntimeError",
+    "missing",
+    "concat",
+    "escape",
+    "markup_join",
+    "unicode_join",
+    "to_string",
+    "identity",
+    "TemplateNotFound",
+    "Namespace",
+    "Undefined",
+]
 
 #: the name of the function that is used to convert something into
 #: a string.  We can just use the text type here.
 to_string = text_type
 
-#: the identity function.  Useful for certain things in the environment
-identity = lambda x: x
 
-_first_iteration = object()
-_last_iteration = object()
+def identity(x):
+    """Returns its argument. Useful for certain things in the
+    environment.
+    """
+    return x
 
 
 def markup_join(seq):
@@ -46,8 +65,8 @@ def markup_join(seq):
     iterator = imap(soft_unicode, seq)
     for arg in iterator:
         buf.append(arg)
-        if hasattr(arg, '__html__'):
-            return Markup(u'').join(chain(buf, iterator))
+        if hasattr(arg, "__html__"):
+            return Markup(u"").join(chain(buf, iterator))
     return concat(buf)
 
 
@@ -56,9 +75,16 @@ def unicode_join(seq):
     return concat(imap(text_type, seq))
 
 
-def new_context(environment, template_name, blocks, vars=None,
-                shared=None, globals=None, locals=None):
-    """Internal helper to for context creation."""
+def new_context(
+    environment,
+    template_name,
+    blocks,
+    vars=None,
+    shared=None,
+    globals=None,
+    locals=None,
+):
+    """Internal helper for context creation."""
     if vars is None:
         vars = {}
     if shared:
@@ -73,8 +99,7 @@ def new_context(environment, template_name, blocks, vars=None,
         for key, value in iteritems(locals):
             if value is not missing:
                 parent[key] = value
-    return environment.context_class(environment, parent, template_name,
-                                     blocks)
+    return environment.context_class(environment, parent, template_name, blocks)
 
 
 class TemplateReference(object):
@@ -88,20 +113,16 @@ class TemplateReference(object):
         return BlockReference(name, self.__context, blocks, 0)
 
     def __repr__(self):
-        return '<%s %r>' % (
-            self.__class__.__name__,
-            self.__context.name
-        )
+        return "<%s %r>" % (self.__class__.__name__, self.__context.name)
 
 
 def _get_func(x):
-    return getattr(x, '__func__', x)
+    return getattr(x, "__func__", x)
 
 
 class ContextMeta(type):
-
-    def __new__(cls, name, bases, d):
-        rv = type.__new__(cls, name, bases, d)
+    def __new__(mcs, name, bases, d):
+        rv = type.__new__(mcs, name, bases, d)
         if bases == ():
             return rv
 
@@ -112,11 +133,15 @@ class ContextMeta(type):
 
         # If we have a changed resolve but no changed default or missing
         # resolve we invert the call logic.
-        if resolve is not default_resolve and \
-           resolve_or_missing is default_resolve_or_missing:
+        if (
+            resolve is not default_resolve
+            and resolve_or_missing is default_resolve_or_missing
+        ):
             rv._legacy_resolve_mode = True
-        elif resolve is default_resolve and \
-             resolve_or_missing is default_resolve_or_missing:
+        elif (
+            resolve is default_resolve
+            and resolve_or_missing is default_resolve_or_missing
+        ):
             rv._fast_resolve_mode = True
 
         return rv
@@ -149,6 +174,7 @@ class Context(with_metaclass(ContextMeta)):
     method that doesn't fail with a `KeyError` but returns an
     :class:`Undefined` object for missing variables.
     """
+
     # XXX: we want to eventually make this be a deprecation warning and
     # remove it.
     _legacy_resolve_mode = False
@@ -179,9 +205,9 @@ class Context(with_metaclass(ContextMeta)):
             index = blocks.index(current) + 1
             blocks[index]
         except LookupError:
-            return self.environment.undefined('there is no parent block '
-                                              'called %r.' % name,
-                                              name='super')
+            return self.environment.undefined(
+                "there is no parent block called %r." % name, name="super"
+            )
         return BlockReference(name, self, blocks, index)
 
     def get(self, key, default=None):
@@ -232,7 +258,7 @@ class Context(with_metaclass(ContextMeta)):
         return dict(self.parent, **self.vars)
 
     @internalcode
-    def call(__self, __obj, *args, **kwargs):
+    def call(__self, __obj, *args, **kwargs):  # noqa: B902
         """Call the callable with the arguments and keyword arguments
         provided but inject the active context or environment as first
         argument if the callable is a :func:`contextfunction` or
@@ -242,55 +268,62 @@ class Context(with_metaclass(ContextMeta)):
             __traceback_hide__ = True  # noqa
 
         # Allow callable classes to take a context
-        if hasattr(__obj, '__call__'):
+        if hasattr(__obj, "__call__"):  # noqa: B004
             fn = __obj.__call__
-            for fn_type in ('contextfunction',
-                            'evalcontextfunction',
-                            'environmentfunction'):
+            for fn_type in (
+                "contextfunction",
+                "evalcontextfunction",
+                "environmentfunction",
+            ):
                 if hasattr(fn, fn_type):
                     __obj = fn
                     break
 
-        if isinstance(__obj, _context_function_types):
-            if getattr(__obj, 'contextfunction', 0):
+        if callable(__obj):
+            if getattr(__obj, "contextfunction", 0):
                 args = (__self,) + args
-            elif getattr(__obj, 'evalcontextfunction', 0):
+            elif getattr(__obj, "evalcontextfunction", 0):
                 args = (__self.eval_ctx,) + args
-            elif getattr(__obj, 'environmentfunction', 0):
+            elif getattr(__obj, "environmentfunction", 0):
                 args = (__self.environment,) + args
         try:
             return __obj(*args, **kwargs)
         except StopIteration:
-            return __self.environment.undefined('value was undefined because '
-                                                'a callable raised a '
-                                                'StopIteration exception')
+            return __self.environment.undefined(
+                "value was undefined because "
+                "a callable raised a "
+                "StopIteration exception"
+            )
 
     def derived(self, locals=None):
         """Internal helper function to create a derived context.  This is
         used in situations where the system needs a new context in the same
         template that is independent.
         """
-        context = new_context(self.environment, self.name, {},
-                              self.get_all(), True, None, locals)
+        context = new_context(
+            self.environment, self.name, {}, self.get_all(), True, None, locals
+        )
         context.eval_ctx = self.eval_ctx
         context.blocks.update((k, list(v)) for k, v in iteritems(self.blocks))
         return context
 
-    def _all(meth):
-        proxy = lambda self: getattr(self.get_all(), meth)()
+    def _all(meth):  # noqa: B902
+        def proxy(self):
+            return getattr(self.get_all(), meth)()
+
         proxy.__doc__ = getattr(dict, meth).__doc__
         proxy.__name__ = meth
         return proxy
 
-    keys = _all('keys')
-    values = _all('values')
-    items = _all('items')
+    keys = _all("keys")
+    values = _all("values")
+    items = _all("items")
 
     # not available on python 3
     if PY2:
-        iterkeys = _all('iterkeys')
-        itervalues = _all('itervalues')
-        iteritems = _all('iteritems')
+        iterkeys = _all("iterkeys")
+        itervalues = _all("itervalues")
+        iteritems = _all("iteritems")
     del _all
 
     def __contains__(self, name):
@@ -306,10 +339,10 @@ class Context(with_metaclass(ContextMeta)):
         return item
 
     def __repr__(self):
-        return '<%s %s of %r>' % (
+        return "<%s %s of %r>" % (
             self.__class__.__name__,
             repr(self.get_all()),
-            self.name
+            self.name,
         )
 
 
@@ -329,11 +362,10 @@ class BlockReference(object):
     def super(self):
         """Super the block."""
         if self._depth + 1 >= len(self._stack):
-            return self._context.environment. \
-                undefined('there is no parent block called %r.' %
-                          self.name, name='super')
-        return BlockReference(self.name, self._context, self._stack,
-                              self._depth + 1)
+            return self._context.environment.undefined(
+                "there is no parent block called %r." % self.name, name="super"
+            )
+        return BlockReference(self.name, self._context, self._stack, self._depth + 1)
 
     @internalcode
     def __call__(self):
@@ -343,143 +375,212 @@ class BlockReference(object):
         return rv
 
 
-class LoopContextBase(object):
-    """A loop context for dynamic iteration."""
+@implements_iterator
+class LoopContext:
+    """A wrapper iterable for dynamic ``for`` loops, with information
+    about the loop and iteration.
+    """
+
+    #: Current iteration of the loop, starting at 0.
+    index0 = -1
 
-    _before = _first_iteration
-    _current = _first_iteration
-    _after = _last_iteration
     _length = None
+    _after = missing
+    _current = missing
+    _before = missing
+    _last_changed_value = missing
 
-    def __init__(self, undefined, recurse=None, depth0=0):
+    def __init__(self, iterable, undefined, recurse=None, depth0=0):
+        """
+        :param iterable: Iterable to wrap.
+        :param undefined: :class:`Undefined` class to use for next and
+            previous items.
+        :param recurse: The function to render the loop body when the
+            loop is marked recursive.
+        :param depth0: Incremented when looping recursively.
+        """
+        self._iterable = iterable
+        self._iterator = self._to_iterator(iterable)
         self._undefined = undefined
         self._recurse = recurse
-        self.index0 = -1
+        #: How many levels deep a recursive loop currently is, starting at 0.
         self.depth0 = depth0
-        self._last_checked_value = missing
 
-    def cycle(self, *args):
-        """Cycles among the arguments with the current loop index."""
-        if not args:
-            raise TypeError('no items for cycling given')
-        return args[self.index0 % len(args)]
+    @staticmethod
+    def _to_iterator(iterable):
+        return iter(iterable)
 
-    def changed(self, *value):
-        """Checks whether the value has changed since the last call."""
-        if self._last_checked_value != value:
-            self._last_checked_value = value
-            return True
-        return False
+    @property
+    def length(self):
+        """Length of the iterable.
 
-    first = property(lambda x: x.index0 == 0)
-    last = property(lambda x: x._after is _last_iteration)
-    index = property(lambda x: x.index0 + 1)
-    revindex = property(lambda x: x.length - x.index0)
-    revindex0 = property(lambda x: x.length - x.index)
-    depth = property(lambda x: x.depth0 + 1)
+        If the iterable is a generator or otherwise does not have a
+        size, it is eagerly evaluated to get a size.
+        """
+        if self._length is not None:
+            return self._length
 
-    @property
-    def previtem(self):
-        if self._before is _first_iteration:
-            return self._undefined('there is no previous item')
-        return self._before
+        try:
+            self._length = len(self._iterable)
+        except TypeError:
+            iterable = list(self._iterator)
+            self._iterator = self._to_iterator(iterable)
+            self._length = len(iterable) + self.index + (self._after is not missing)
 
-    @property
-    def nextitem(self):
-        if self._after is _last_iteration:
-            return self._undefined('there is no next item')
-        return self._after
+        return self._length
 
     def __len__(self):
         return self.length
 
-    @internalcode
-    def loop(self, iterable):
-        if self._recurse is None:
-            raise TypeError('Tried to call non recursive loop.  Maybe you '
-                            "forgot the 'recursive' modifier.")
-        return self._recurse(iterable, self._recurse, self.depth0 + 1)
+    @property
+    def depth(self):
+        """How many levels deep a recursive loop currently is, starting at 1."""
+        return self.depth0 + 1
 
-    # a nifty trick to enhance the error message if someone tried to call
-    # the the loop without or with too many arguments.
-    __call__ = loop
-    del loop
+    @property
+    def index(self):
+        """Current iteration of the loop, starting at 1."""
+        return self.index0 + 1
 
-    def __repr__(self):
-        return '<%s %r/%r>' % (
-            self.__class__.__name__,
-            self.index,
-            self.length
-        )
+    @property
+    def revindex0(self):
+        """Number of iterations from the end of the loop, ending at 0.
 
+        Requires calculating :attr:`length`.
+        """
+        return self.length - self.index
 
-class LoopContext(LoopContextBase):
+    @property
+    def revindex(self):
+        """Number of iterations from the end of the loop, ending at 1.
 
-    def __init__(self, iterable, undefined, recurse=None, depth0=0):
-        LoopContextBase.__init__(self, undefined, recurse, depth0)
-        self._iterator = iter(iterable)
+        Requires calculating :attr:`length`.
+        """
+        return self.length - self.index0
 
-        # try to get the length of the iterable early.  This must be done
-        # here because there are some broken iterators around where there
-        # __len__ is the number of iterations left (i'm looking at your
-        # listreverseiterator!).
-        try:
-            self._length = len(iterable)
-        except (TypeError, AttributeError):
-            self._length = None
-        self._after = self._safe_next()
+    @property
+    def first(self):
+        """Whether this is the first iteration of the loop."""
+        return self.index0 == 0
+
+    def _peek_next(self):
+        """Return the next element in the iterable, or :data:`missing`
+        if the iterable is exhausted. Only peeks one item ahead, caching
+        the result in :attr:`_last` for use in subsequent checks. The
+        cache is reset when :meth:`__next__` is called.
+        """
+        if self._after is not missing:
+            return self._after
+
+        self._after = next(self._iterator, missing)
+        return self._after
 
     @property
-    def length(self):
-        if self._length is None:
-            # if was not possible to get the length of the iterator when
-            # the loop context was created (ie: iterating over a generator)
-            # we have to convert the iterable into a sequence and use the
-            # length of that + the number of iterations so far.
-            iterable = tuple(self._iterator)
-            self._iterator = iter(iterable)
-            iterations_done = self.index0 + 2
-            self._length = len(iterable) + iterations_done
-        return self._length
+    def last(self):
+        """Whether this is the last iteration of the loop.
 
-    def __iter__(self):
-        return LoopContextIterator(self)
+        Causes the iterable to advance early. See
+        :func:`itertools.groupby` for issues this can cause.
+        The :func:`groupby` filter avoids that issue.
+        """
+        return self._peek_next() is missing
 
-    def _safe_next(self):
-        try:
-            return next(self._iterator)
-        except StopIteration:
-            return _last_iteration
+    @property
+    def previtem(self):
+        """The item in the previous iteration. Undefined during the
+        first iteration.
+        """
+        if self.first:
+            return self._undefined("there is no previous item")
 
+        return self._before
 
-@implements_iterator
-class LoopContextIterator(object):
-    """The iterator for a loop context."""
-    __slots__ = ('context',)
+    @property
+    def nextitem(self):
+        """The item in the next iteration. Undefined during the last
+        iteration.
 
-    def __init__(self, context):
-        self.context = context
+        Causes the iterable to advance early. See
+        :func:`itertools.groupby` for issues this can cause.
+        The :func:`groupby` filter avoids that issue.
+        """
+        rv = self._peek_next()
+
+        if rv is missing:
+            return self._undefined("there is no next item")
+
+        return rv
+
+    def cycle(self, *args):
+        """Return a value from the given args, cycling through based on
+        the current :attr:`index0`.
+
+        :param args: One or more values to cycle through.
+        """
+        if not args:
+            raise TypeError("no items for cycling given")
+
+        return args[self.index0 % len(args)]
+
+    def changed(self, *value):
+        """Return ``True`` if previously called with a different value
+        (including when called for the first time).
+
+        :param value: One or more values to compare to the last call.
+        """
+        if self._last_changed_value != value:
+            self._last_changed_value = value
+            return True
+
+        return False
 
     def __iter__(self):
         return self
 
     def __next__(self):
-        ctx = self.context
-        ctx.index0 += 1
-        if ctx._after is _last_iteration:
-            raise StopIteration()
-        ctx._before = ctx._current
-        ctx._current = ctx._after
-        ctx._after = ctx._safe_next()
-        return ctx._current, ctx
+        if self._after is not missing:
+            rv = self._after
+            self._after = missing
+        else:
+            rv = next(self._iterator)
+
+        self.index0 += 1
+        self._before = self._current
+        self._current = rv
+        return rv, self
+
+    @internalcode
+    def __call__(self, iterable):
+        """When iterating over nested data, render the body of the loop
+        recursively with the given inner iterable data.
+
+        The loop must have the ``recursive`` marker for this to work.
+        """
+        if self._recurse is None:
+            raise TypeError(
+                "The loop must have the 'recursive' marker to be called recursively."
+            )
+
+        return self._recurse(iterable, self._recurse, depth=self.depth)
+
+    def __repr__(self):
+        return "<%s %d/%d>" % (self.__class__.__name__, self.index, self.length)
 
 
 class Macro(object):
     """Wraps a macro function."""
 
-    def __init__(self, environment, func, name, arguments,
-                 catch_kwargs, catch_varargs, caller,
-                 default_autoescape=None):
+    def __init__(
+        self,
+        environment,
+        func,
+        name,
+        arguments,
+        catch_kwargs,
+        catch_varargs,
+        caller,
+        default_autoescape=None,
+    ):
         self._environment = environment
         self._func = func
         self._argument_count = len(arguments)
@@ -488,7 +589,7 @@ class Macro(object):
         self.catch_kwargs = catch_kwargs
         self.catch_varargs = catch_varargs
         self.caller = caller
-        self.explicit_caller = 'caller' in arguments
+        self.explicit_caller = "caller" in arguments
         if default_autoescape is None:
             default_autoescape = environment.autoescape
         self._default_autoescape = default_autoescape
@@ -500,9 +601,8 @@ class Macro(object):
         # decide largely based on compile-time information if a macro is
         # safe or unsafe.  While there was a volatile mode it was largely
         # unused for deciding on escaping.  This turns out to be
-        # problemtic for macros because if a macro is safe or not not so
-        # much depends on the escape mode when it was defined but when it
-        # was used.
+        # problematic for macros because whether a macro is safe depends not
+        # on the escape mode when it was defined, but rather when it was used.
         #
         # Because however we export macros from the module system and
         # there are historic callers that do not pass an eval context (and
@@ -510,7 +610,7 @@ class Macro(object):
         # check here.
         #
         # This is considered safe because an eval context is not a valid
-        # argument to callables otherwise anwyays.  Worst case here is
+        # argument to callables otherwise anyway.  Worst case here is
         # that if no eval context is passed we fall back to the compile
         # time autoescape flag.
         if args and isinstance(args[0], EvalContext):
@@ -520,7 +620,7 @@ class Macro(object):
             autoescape = self._default_autoescape
 
         # try to consume the positional arguments
-        arguments = list(args[:self._argument_count])
+        arguments = list(args[: self._argument_count])
         off = len(arguments)
 
         # For information why this is necessary refer to the handling
@@ -531,12 +631,12 @@ class Macro(object):
         # arguments expected we start filling in keyword arguments
         # and defaults.
         if off != self._argument_count:
-            for idx, name in enumerate(self.arguments[len(arguments):]):
+            for name in self.arguments[len(arguments) :]:
                 try:
                     value = kwargs.pop(name)
                 except KeyError:
                     value = missing
-                if name == 'caller':
+                if name == "caller":
                     found_caller = True
                 arguments.append(value)
         else:
@@ -546,26 +646,31 @@ class Macro(object):
         # if not also changed in the compiler's `function_scoping` method.
         # the order is caller, keyword arguments, positional arguments!
         if self.caller and not found_caller:
-            caller = kwargs.pop('caller', None)
+            caller = kwargs.pop("caller", None)
             if caller is None:
-                caller = self._environment.undefined('No caller defined',
-                                                     name='caller')
+                caller = self._environment.undefined("No caller defined", name="caller")
             arguments.append(caller)
 
         if self.catch_kwargs:
             arguments.append(kwargs)
         elif kwargs:
-            if 'caller' in kwargs:
-                raise TypeError('macro %r was invoked with two values for '
-                                'the special caller argument.  This is '
-                                'most likely a bug.' % self.name)
-            raise TypeError('macro %r takes no keyword argument %r' %
-                            (self.name, next(iter(kwargs))))
+            if "caller" in kwargs:
+                raise TypeError(
+                    "macro %r was invoked with two values for "
+                    "the special caller argument.  This is "
+                    "most likely a bug." % self.name
+                )
+            raise TypeError(
+                "macro %r takes no keyword argument %r"
+                % (self.name, next(iter(kwargs)))
+            )
         if self.catch_varargs:
-            arguments.append(args[self._argument_count:])
+            arguments.append(args[self._argument_count :])
         elif len(args) > self._argument_count:
-            raise TypeError('macro %r takes not more than %d argument(s)' %
-                            (self.name, len(self.arguments)))
+            raise TypeError(
+                "macro %r takes not more than %d argument(s)"
+                % (self.name, len(self.arguments))
+            )
 
         return self._invoke(arguments, autoescape)
 
@@ -577,16 +682,16 @@ class Macro(object):
         return rv
 
     def __repr__(self):
-        return '<%s %s>' % (
+        return "<%s %s>" % (
             self.__class__.__name__,
-            self.name is None and 'anonymous' or repr(self.name)
+            self.name is None and "anonymous" or repr(self.name),
         )
 
 
 @implements_to_string
 class Undefined(object):
     """The default undefined type.  This undefined type can be printed and
-    iterated over, but every other access will raise an :exc:`jinja2.exceptions.UndefinedError`:
+    iterated over, but every other access will raise an :exc:`UndefinedError`:
 
     >>> foo = Undefined(name='foo')
     >>> str(foo)
@@ -598,8 +703,13 @@ class Undefined(object):
       ...
     jinja2.exceptions.UndefinedError: 'foo' is undefined
     """
-    __slots__ = ('_undefined_hint', '_undefined_obj', '_undefined_name',
-                 '_undefined_exception')
+
+    __slots__ = (
+        "_undefined_hint",
+        "_undefined_obj",
+        "_undefined_name",
+        "_undefined_exception",
+    )
 
     def __init__(self, hint=None, obj=missing, name=None, exc=UndefinedError):
         self._undefined_hint = hint
@@ -607,40 +717,86 @@ class Undefined(object):
         self._undefined_name = name
         self._undefined_exception = exc
 
+    @property
+    def _undefined_message(self):
+        """Build a message about the undefined value based on how it was
+        accessed.
+        """
+        if self._undefined_hint:
+            return self._undefined_hint
+
+        if self._undefined_obj is missing:
+            return "%r is undefined" % self._undefined_name
+
+        if not isinstance(self._undefined_name, string_types):
+            return "%s has no element %r" % (
+                object_type_repr(self._undefined_obj),
+                self._undefined_name,
+            )
+
+        return "%r has no attribute %r" % (
+            object_type_repr(self._undefined_obj),
+            self._undefined_name,
+        )
+
     @internalcode
     def _fail_with_undefined_error(self, *args, **kwargs):
-        """Regular callback function for undefined objects that raises an
-        `jinja2.exceptions.UndefinedError` on call.
+        """Raise an :exc:`UndefinedError` when operations are performed
+        on the undefined value.
         """
-        if self._undefined_hint is None:
-            if self._undefined_obj is missing:
-                hint = '%r is undefined' % self._undefined_name
-            elif not isinstance(self._undefined_name, string_types):
-                hint = '%s has no element %r' % (
-                    object_type_repr(self._undefined_obj),
-                    self._undefined_name
-                )
-            else:
-                hint = '%r has no attribute %r' % (
-                    object_type_repr(self._undefined_obj),
-                    self._undefined_name
-                )
-        else:
-            hint = self._undefined_hint
-        raise self._undefined_exception(hint)
+        raise self._undefined_exception(self._undefined_message)
 
     @internalcode
     def __getattr__(self, name):
-        if name[:2] == '__':
+        if name[:2] == "__":
             raise AttributeError(name)
         return self._fail_with_undefined_error()
 
-    __add__ = __radd__ = __mul__ = __rmul__ = __div__ = __rdiv__ = \
-        __truediv__ = __rtruediv__ = __floordiv__ = __rfloordiv__ = \
-        __mod__ = __rmod__ = __pos__ = __neg__ = __call__ = \
-        __getitem__ = __lt__ = __le__ = __gt__ = __ge__ = __int__ = \
-        __float__ = __complex__ = __pow__ = __rpow__ = __sub__ = \
-        __rsub__ = _fail_with_undefined_error
+    __add__ = (
+        __radd__
+    ) = (
+        __mul__
+    ) = (
+        __rmul__
+    ) = (
+        __div__
+    ) = (
+        __rdiv__
+    ) = (
+        __truediv__
+    ) = (
+        __rtruediv__
+    ) = (
+        __floordiv__
+    ) = (
+        __rfloordiv__
+    ) = (
+        __mod__
+    ) = (
+        __rmod__
+    ) = (
+        __pos__
+    ) = (
+        __neg__
+    ) = (
+        __call__
+    ) = (
+        __getitem__
+    ) = (
+        __lt__
+    ) = (
+        __le__
+    ) = (
+        __gt__
+    ) = (
+        __ge__
+    ) = (
+        __int__
+    ) = (
+        __float__
+    ) = (
+        __complex__
+    ) = __pow__ = __rpow__ = __sub__ = __rsub__ = _fail_with_undefined_error
 
     def __eq__(self, other):
         return type(self) is type(other)
@@ -652,7 +808,7 @@ class Undefined(object):
         return id(type(self))
 
     def __str__(self):
-        return u''
+        return u""
 
     def __len__(self):
         return 0
@@ -663,10 +819,11 @@ class Undefined(object):
 
     def __nonzero__(self):
         return False
+
     __bool__ = __nonzero__
 
     def __repr__(self):
-        return 'Undefined'
+        return "Undefined"
 
 
 def make_logging_undefined(logger=None, base=None):
@@ -691,6 +848,7 @@ def make_logging_undefined(logger=None, base=None):
     """
     if logger is None:
         import logging
+
         logger = logging.getLogger(__name__)
         logger.addHandler(logging.StreamHandler(sys.stderr))
     if base is None:
@@ -699,26 +857,27 @@ def make_logging_undefined(logger=None, base=None):
     def _log_message(undef):
         if undef._undefined_hint is None:
             if undef._undefined_obj is missing:
-                hint = '%s is undefined' % undef._undefined_name
+                hint = "%s is undefined" % undef._undefined_name
             elif not isinstance(undef._undefined_name, string_types):
-                hint = '%s has no element %s' % (
+                hint = "%s has no element %s" % (
                     object_type_repr(undef._undefined_obj),
-                    undef._undefined_name)
+                    undef._undefined_name,
+                )
             else:
-                hint = '%s has no attribute %s' % (
+                hint = "%s has no attribute %s" % (
                     object_type_repr(undef._undefined_obj),
-                    undef._undefined_name)
+                    undef._undefined_name,
+                )
         else:
             hint = undef._undefined_hint
-        logger.warning('Template variable warning: %s', hint)
+        logger.warning("Template variable warning: %s", hint)
 
     class LoggingUndefined(base):
-
         def _fail_with_undefined_error(self, *args, **kwargs):
             try:
                 return base._fail_with_undefined_error(self, *args, **kwargs)
             except self._undefined_exception as e:
-                logger.error('Template variable error: %s', str(e))
+                logger.error("Template variable error: %s", str(e))
                 raise e
 
         def __str__(self):
@@ -732,6 +891,7 @@ def make_logging_undefined(logger=None, base=None):
             return rv
 
         if PY2:
+
             def __nonzero__(self):
                 rv = base.__nonzero__(self)
                 _log_message(self)
@@ -741,7 +901,9 @@ def make_logging_undefined(logger=None, base=None):
                 rv = base.__unicode__(self)
                 _log_message(self)
                 return rv
+
         else:
+
             def __bool__(self):
                 rv = base.__bool__(self)
                 _log_message(self)
@@ -750,6 +912,36 @@ def make_logging_undefined(logger=None, base=None):
     return LoggingUndefined
 
 
+# No @implements_to_string decorator here because __str__
+# is not overwritten from Undefined in this class.
+# This would cause a recursion error in Python 2.
+class ChainableUndefined(Undefined):
+    """An undefined that is chainable, where both ``__getattr__`` and
+    ``__getitem__`` return itself rather than raising an
+    :exc:`UndefinedError`.
+
+    >>> foo = ChainableUndefined(name='foo')
+    >>> str(foo.bar['baz'])
+    ''
+    >>> foo.bar['baz'] + 42
+    Traceback (most recent call last):
+      ...
+    jinja2.exceptions.UndefinedError: 'foo' is undefined
+
+    .. versionadded:: 2.11.0
+    """
+
+    __slots__ = ()
+
+    def __html__(self):
+        return self.__str__()
+
+    def __getattr__(self, _):
+        return self
+
+    __getitem__ = __getattr__
+
+
 @implements_to_string
 class DebugUndefined(Undefined):
     """An undefined that returns the debug info when printed.
@@ -764,17 +956,18 @@ class DebugUndefined(Undefined):
       ...
     jinja2.exceptions.UndefinedError: 'foo' is undefined
     """
+
     __slots__ = ()
 
     def __str__(self):
         if self._undefined_hint is None:
             if self._undefined_obj is missing:
-                return u'{{ %s }}' % self._undefined_name
-            return '{{ no such element: %s[%r] }}' % (
+                return u"{{ %s }}" % self._undefined_name
+            return "{{ no such element: %s[%r] }}" % (
                 object_type_repr(self._undefined_obj),
-                self._undefined_name
+                self._undefined_name,
             )
-        return u'{{ undefined value printed: %s }}' % self._undefined_hint
+        return u"{{ undefined value printed: %s }}" % self._undefined_hint
 
 
 @implements_to_string
@@ -797,12 +990,22 @@ class StrictUndefined(Undefined):
       ...
     jinja2.exceptions.UndefinedError: 'foo' is undefined
     """
+
     __slots__ = ()
-    __iter__ = __str__ = __len__ = __nonzero__ = __eq__ = \
-        __ne__ = __bool__ = __hash__ = \
-        Undefined._fail_with_undefined_error
+    __iter__ = (
+        __str__
+    ) = (
+        __len__
+    ) = (
+        __nonzero__
+    ) = __eq__ = __ne__ = __bool__ = __hash__ = Undefined._fail_with_undefined_error
 
 
 # remove remaining slots attributes, after the metaclass did the magic they
 # are unneeded and irritating as they contain wrong data for the subclasses.
-del Undefined.__slots__, DebugUndefined.__slots__, StrictUndefined.__slots__
+del (
+    Undefined.__slots__,
+    ChainableUndefined.__slots__,
+    DebugUndefined.__slots__,
+    StrictUndefined.__slots__,
+)
diff --git a/pipenv/vendor/jinja2/sandbox.py b/pipenv/vendor/jinja2/sandbox.py
index 08c22f4f..cfd7993a 100644
--- a/pipenv/vendor/jinja2/sandbox.py
+++ b/pipenv/vendor/jinja2/sandbox.py
@@ -1,70 +1,66 @@
 # -*- coding: utf-8 -*-
+"""A sandbox layer that ensures unsafe operations cannot be performed.
+Useful when the template itself comes from an untrusted source.
 """
-    jinja2.sandbox
-    ~~~~~~~~~~~~~~
-
-    Adds a sandbox layer to Jinja as it was the default behavior in the old
-    Jinja 1 releases.  This sandbox is slightly different from Jinja 1 as the
-    default behavior is easier to use.
-
-    The behavior can be changed by subclassing the environment.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD.
-"""
-import types
 import operator
-from jinja2.environment import Environment
-from jinja2.exceptions import SecurityError
-from jinja2._compat import string_types, PY2, abc, range_type
-from jinja2.utils import Markup
+import types
+import warnings
+from collections import deque
+from string import Formatter
 
 from markupsafe import EscapeFormatter
-from string import Formatter
+from markupsafe import Markup
 
+from ._compat import abc
+from ._compat import PY2
+from ._compat import range_type
+from ._compat import string_types
+from .environment import Environment
+from .exceptions import SecurityError
 
 #: maximum number of items a range may produce
 MAX_RANGE = 100000
 
 #: attributes of function objects that are considered unsafe.
 if PY2:
-    UNSAFE_FUNCTION_ATTRIBUTES = set(['func_closure', 'func_code', 'func_dict',
-                                      'func_defaults', 'func_globals'])
+    UNSAFE_FUNCTION_ATTRIBUTES = {
+        "func_closure",
+        "func_code",
+        "func_dict",
+        "func_defaults",
+        "func_globals",
+    }
 else:
     # On versions > python 2 the special attributes on functions are gone,
     # but they remain on methods and generators for whatever reason.
     UNSAFE_FUNCTION_ATTRIBUTES = set()
 
-
 #: unsafe method attributes.  function attributes are unsafe for methods too
-UNSAFE_METHOD_ATTRIBUTES = set(['im_class', 'im_func', 'im_self'])
+UNSAFE_METHOD_ATTRIBUTES = {"im_class", "im_func", "im_self"}
 
-#: unsafe generator attirbutes.
-UNSAFE_GENERATOR_ATTRIBUTES = set(['gi_frame', 'gi_code'])
+#: unsafe generator attributes.
+UNSAFE_GENERATOR_ATTRIBUTES = {"gi_frame", "gi_code"}
 
 #: unsafe attributes on coroutines
-UNSAFE_COROUTINE_ATTRIBUTES = set(['cr_frame', 'cr_code'])
+UNSAFE_COROUTINE_ATTRIBUTES = {"cr_frame", "cr_code"}
 
 #: unsafe attributes on async generators
-UNSAFE_ASYNC_GENERATOR_ATTRIBUTES = set(['ag_code', 'ag_frame'])
-
-import warnings
+UNSAFE_ASYNC_GENERATOR_ATTRIBUTES = {"ag_code", "ag_frame"}
 
 # make sure we don't warn in python 2.6 about stuff we don't care about
-warnings.filterwarnings('ignore', 'the sets module', DeprecationWarning,
-                        module='jinja2.sandbox')
-
-from collections import deque
+warnings.filterwarnings(
+    "ignore", "the sets module", DeprecationWarning, module=__name__
+)
 
 _mutable_set_types = (set,)
 _mutable_mapping_types = (dict,)
 _mutable_sequence_types = (list,)
 
-
 # on python 2.x we can register the user collection types
 try:
     from UserDict import UserDict, DictMixin
     from UserList import UserList
+
     _mutable_mapping_types += (UserDict, DictMixin)
     _mutable_set_types += (UserList,)
 except ImportError:
@@ -73,6 +69,7 @@ except ImportError:
 # if sets is still available, register the mutable set from there as well
 try:
     from sets import Set
+
     _mutable_set_types += (Set,)
 except ImportError:
     pass
@@ -82,22 +79,46 @@ _mutable_set_types += (abc.MutableSet,)
 _mutable_mapping_types += (abc.MutableMapping,)
 _mutable_sequence_types += (abc.MutableSequence,)
 
-
 _mutable_spec = (
-    (_mutable_set_types, frozenset([
-        'add', 'clear', 'difference_update', 'discard', 'pop', 'remove',
-        'symmetric_difference_update', 'update'
-    ])),
-    (_mutable_mapping_types, frozenset([
-        'clear', 'pop', 'popitem', 'setdefault', 'update'
-    ])),
-    (_mutable_sequence_types, frozenset([
-        'append', 'reverse', 'insert', 'sort', 'extend', 'remove'
-    ])),
-    (deque, frozenset([
-        'append', 'appendleft', 'clear', 'extend', 'extendleft', 'pop',
-        'popleft', 'remove', 'rotate'
-    ]))
+    (
+        _mutable_set_types,
+        frozenset(
+            [
+                "add",
+                "clear",
+                "difference_update",
+                "discard",
+                "pop",
+                "remove",
+                "symmetric_difference_update",
+                "update",
+            ]
+        ),
+    ),
+    (
+        _mutable_mapping_types,
+        frozenset(["clear", "pop", "popitem", "setdefault", "update"]),
+    ),
+    (
+        _mutable_sequence_types,
+        frozenset(["append", "reverse", "insert", "sort", "extend", "remove"]),
+    ),
+    (
+        deque,
+        frozenset(
+            [
+                "append",
+                "appendleft",
+                "clear",
+                "extend",
+                "extendleft",
+                "pop",
+                "popleft",
+                "remove",
+                "rotate",
+            ]
+        ),
+    ),
 )
 
 
@@ -115,7 +136,7 @@ class _MagicFormatMapping(abc.Mapping):
         self._last_index = 0
 
     def __getitem__(self, key):
-        if key == '':
+        if key == "":
             idx = self._last_index
             self._last_index += 1
             try:
@@ -133,9 +154,9 @@ class _MagicFormatMapping(abc.Mapping):
 
 
 def inspect_format_method(callable):
-    if not isinstance(callable, (types.MethodType,
-                                 types.BuiltinMethodType)) or \
-       callable.__name__ not in ('format', 'format_map'):
+    if not isinstance(
+        callable, (types.MethodType, types.BuiltinMethodType)
+    ) or callable.__name__ not in ("format", "format_map"):
         return None
     obj = callable.__self__
     if isinstance(obj, string_types):
@@ -186,24 +207,25 @@ def is_internal_attribute(obj, attr):
         if attr in UNSAFE_FUNCTION_ATTRIBUTES:
             return True
     elif isinstance(obj, types.MethodType):
-        if attr in UNSAFE_FUNCTION_ATTRIBUTES or \
-           attr in UNSAFE_METHOD_ATTRIBUTES:
+        if attr in UNSAFE_FUNCTION_ATTRIBUTES or attr in UNSAFE_METHOD_ATTRIBUTES:
             return True
     elif isinstance(obj, type):
-        if attr == 'mro':
+        if attr == "mro":
             return True
     elif isinstance(obj, (types.CodeType, types.TracebackType, types.FrameType)):
         return True
     elif isinstance(obj, types.GeneratorType):
         if attr in UNSAFE_GENERATOR_ATTRIBUTES:
             return True
-    elif hasattr(types, 'CoroutineType') and isinstance(obj, types.CoroutineType):
+    elif hasattr(types, "CoroutineType") and isinstance(obj, types.CoroutineType):
         if attr in UNSAFE_COROUTINE_ATTRIBUTES:
             return True
-    elif hasattr(types, 'AsyncGeneratorType') and isinstance(obj, types.AsyncGeneratorType):
+    elif hasattr(types, "AsyncGeneratorType") and isinstance(
+        obj, types.AsyncGeneratorType
+    ):
         if attr in UNSAFE_ASYNC_GENERATOR_ATTRIBUTES:
             return True
-    return attr.startswith('__')
+    return attr.startswith("__")
 
 
 def modifies_known_mutable(obj, attr):
@@ -244,28 +266,26 @@ class SandboxedEnvironment(Environment):
     raised.  However also other exceptions may occur during the rendering so
     the caller has to ensure that all exceptions are caught.
     """
+
     sandboxed = True
 
     #: default callback table for the binary operators.  A copy of this is
     #: available on each instance of a sandboxed environment as
     #: :attr:`binop_table`
     default_binop_table = {
-        '+':        operator.add,
-        '-':        operator.sub,
-        '*':        operator.mul,
-        '/':        operator.truediv,
-        '//':       operator.floordiv,
-        '**':       operator.pow,
-        '%':        operator.mod
+        "+": operator.add,
+        "-": operator.sub,
+        "*": operator.mul,
+        "/": operator.truediv,
+        "//": operator.floordiv,
+        "**": operator.pow,
+        "%": operator.mod,
     }
 
     #: default callback table for the unary operators.  A copy of this is
     #: available on each instance of a sandboxed environment as
     #: :attr:`unop_table`
-    default_unop_table = {
-        '+':        operator.pos,
-        '-':        operator.neg
-    }
+    default_unop_table = {"+": operator.pos, "-": operator.neg}
 
     #: a set of binary operators that should be intercepted.  Each operator
     #: that is added to this set (empty by default) is delegated to the
@@ -301,7 +321,7 @@ class SandboxedEnvironment(Environment):
     def intercept_unop(self, operator):
         """Called during template compilation with the name of a unary
         operator to check if it should be intercepted at runtime.  If this
-        method returns `True`, :meth:`call_unop` is excuted for this unary
+        method returns `True`, :meth:`call_unop` is executed for this unary
         operator.  The default implementation of :meth:`call_unop` will use
         the :attr:`unop_table` dictionary to perform the operator with the
         same logic as the builtin one.
@@ -315,10 +335,9 @@ class SandboxedEnvironment(Environment):
         """
         return False
 
-
     def __init__(self, *args, **kwargs):
         Environment.__init__(self, *args, **kwargs)
-        self.globals['range'] = safe_range
+        self.globals["range"] = safe_range
         self.binop_table = self.default_binop_table.copy()
         self.unop_table = self.default_unop_table.copy()
 
@@ -329,7 +348,7 @@ class SandboxedEnvironment(Environment):
         special attributes of internal python objects as returned by the
         :func:`is_internal_attribute` function.
         """
-        return not (attr.startswith('_') or is_internal_attribute(obj, attr))
+        return not (attr.startswith("_") or is_internal_attribute(obj, attr))
 
     def is_safe_callable(self, obj):
         """Check if an object is safely callable.  Per default a function is
@@ -337,8 +356,9 @@ class SandboxedEnvironment(Environment):
         True.  Override this method to alter the behavior, but this won't
         affect the `unsafe` decorator from this module.
         """
-        return not (getattr(obj, 'unsafe_callable', False) or
-                    getattr(obj, 'alters_data', False))
+        return not (
+            getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
+        )
 
     def call_binop(self, context, operator, left, right):
         """For intercepted binary operator calls (:meth:`intercepted_binops`)
@@ -398,11 +418,13 @@ class SandboxedEnvironment(Environment):
 
     def unsafe_undefined(self, obj, attribute):
         """Return an undefined object for unsafe attributes."""
-        return self.undefined('access to attribute %r of %r '
-                              'object is unsafe.' % (
-            attribute,
-            obj.__class__.__name__
-        ), name=attribute, obj=obj, exc=SecurityError)
+        return self.undefined(
+            "access to attribute %r of %r "
+            "object is unsafe." % (attribute, obj.__class__.__name__),
+            name=attribute,
+            obj=obj,
+            exc=SecurityError,
+        )
 
     def format_string(self, s, args, kwargs, format_func=None):
         """If a format call is detected, then this is routed through this
@@ -413,10 +435,10 @@ class SandboxedEnvironment(Environment):
         else:
             formatter = SandboxedFormatter(self)
 
-        if format_func is not None and format_func.__name__ == 'format_map':
+        if format_func is not None and format_func.__name__ == "format_map":
             if len(args) != 1 or kwargs:
                 raise TypeError(
-                    'format_map() takes exactly one argument %d given'
+                    "format_map() takes exactly one argument %d given"
                     % (len(args) + (kwargs is not None))
                 )
 
@@ -427,7 +449,7 @@ class SandboxedEnvironment(Environment):
         rv = formatter.vformat(s, args, kwargs)
         return type(s)(rv)
 
-    def call(__self, __context, __obj, *args, **kwargs):
+    def call(__self, __context, __obj, *args, **kwargs):  # noqa: B902
         """Call an object from sandboxed code."""
         fmt = inspect_format_method(__obj)
         if fmt is not None:
@@ -436,7 +458,7 @@ class SandboxedEnvironment(Environment):
         # the double prefixes are to avoid double keyword argument
         # errors when proxying the call.
         if not __self.is_safe_callable(__obj):
-            raise SecurityError('%r is not safely callable' % (__obj,))
+            raise SecurityError("%r is not safely callable" % (__obj,))
         return __context.call(__obj, *args, **kwargs)
 
 
@@ -452,16 +474,16 @@ class ImmutableSandboxedEnvironment(SandboxedEnvironment):
         return not modifies_known_mutable(obj, attr)
 
 
-# This really is not a public API apparenlty.
+# This really is not a public API apparently.
 try:
     from _string import formatter_field_name_split
 except ImportError:
+
     def formatter_field_name_split(field_name):
         return field_name._formatter_field_name_split()
 
 
 class SandboxedFormatterMixin(object):
-
     def __init__(self, env):
         self._env = env
 
@@ -475,14 +497,14 @@ class SandboxedFormatterMixin(object):
                 obj = self._env.getitem(obj, i)
         return obj, first
 
-class SandboxedFormatter(SandboxedFormatterMixin, Formatter):
 
+class SandboxedFormatter(SandboxedFormatterMixin, Formatter):
     def __init__(self, env):
         SandboxedFormatterMixin.__init__(self, env)
         Formatter.__init__(self)
 
-class SandboxedEscapeFormatter(SandboxedFormatterMixin, EscapeFormatter):
 
+class SandboxedEscapeFormatter(SandboxedFormatterMixin, EscapeFormatter):
     def __init__(self, env, escape):
         SandboxedFormatterMixin.__init__(self, env)
         EscapeFormatter.__init__(self, escape)
diff --git a/pipenv/vendor/jinja2/tests.py b/pipenv/vendor/jinja2/tests.py
index bc99d66c..fabd4ce5 100644
--- a/pipenv/vendor/jinja2/tests.py
+++ b/pipenv/vendor/jinja2/tests.py
@@ -1,23 +1,17 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.tests
-    ~~~~~~~~~~~~
-
-    Jinja test functions. Used with the "is" operator.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
+"""Built-in template tests used with the ``is`` operator."""
+import decimal
 import operator
 import re
-from jinja2.runtime import Undefined
-from jinja2._compat import text_type, string_types, integer_types, abc
-import decimal
-
-number_re = re.compile(r'^-?\d+(\.\d+)?$')
-regex_type = type(number_re)
 
+from ._compat import abc
+from ._compat import integer_types
+from ._compat import string_types
+from ._compat import text_type
+from .runtime import Undefined
 
+number_re = re.compile(r"^-?\d+(\.\d+)?$")
+regex_type = type(number_re)
 test_callable = callable
 
 
@@ -63,6 +57,48 @@ def test_none(value):
     return value is None
 
 
+def test_boolean(value):
+    """Return true if the object is a boolean value.
+
+    .. versionadded:: 2.11
+    """
+    return value is True or value is False
+
+
+def test_false(value):
+    """Return true if the object is False.
+
+    .. versionadded:: 2.11
+    """
+    return value is False
+
+
+def test_true(value):
+    """Return true if the object is True.
+
+    .. versionadded:: 2.11
+    """
+    return value is True
+
+
+# NOTE: The existing 'number' test matches booleans and floats
+def test_integer(value):
+    """Return true if the object is an integer.
+
+    .. versionadded:: 2.11
+    """
+    return isinstance(value, integer_types) and value is not True and value is not False
+
+
+# NOTE: The existing 'number' test matches booleans and integers
+def test_float(value):
+    """Return true if the object is a float.
+
+    .. versionadded:: 2.11
+    """
+    return isinstance(value, float)
+
+
 def test_lower(value):
     """Return true if the variable is lowercased."""
     return text_type(value).islower()
@@ -98,7 +134,7 @@ def test_sequence(value):
     try:
         len(value)
         value.__getitem__
-    except:
+    except Exception:
         return False
     return True
 
@@ -127,7 +163,7 @@ def test_iterable(value):
 
 def test_escaped(value):
     """Check if the value is escaped."""
-    return hasattr(value, '__html__')
+    return hasattr(value, "__html__")
 
 
 def test_in(value, seq):
@@ -139,36 +175,41 @@ def test_in(value, seq):
 
 
 TESTS = {
-    'odd':              test_odd,
-    'even':             test_even,
-    'divisibleby':      test_divisibleby,
-    'defined':          test_defined,
-    'undefined':        test_undefined,
-    'none':             test_none,
-    'lower':            test_lower,
-    'upper':            test_upper,
-    'string':           test_string,
-    'mapping':          test_mapping,
-    'number':           test_number,
-    'sequence':         test_sequence,
-    'iterable':         test_iterable,
-    'callable':         test_callable,
-    'sameas':           test_sameas,
-    'escaped':          test_escaped,
-    'in':               test_in,
-    '==':               operator.eq,
-    'eq':               operator.eq,
-    'equalto':          operator.eq,
-    '!=':               operator.ne,
-    'ne':               operator.ne,
-    '>':                operator.gt,
-    'gt':               operator.gt,
-    'greaterthan':      operator.gt,
-    'ge':               operator.ge,
-    '>=':               operator.ge,
-    '<':                operator.lt,
-    'lt':               operator.lt,
-    'lessthan':         operator.lt,
-    '<=':               operator.le,
-    'le':               operator.le,
+    "odd": test_odd,
+    "even": test_even,
+    "divisibleby": test_divisibleby,
+    "defined": test_defined,
+    "undefined": test_undefined,
+    "none": test_none,
+    "boolean": test_boolean,
+    "false": test_false,
+    "true": test_true,
+    "integer": test_integer,
+    "float": test_float,
+    "lower": test_lower,
+    "upper": test_upper,
+    "string": test_string,
+    "mapping": test_mapping,
+    "number": test_number,
+    "sequence": test_sequence,
+    "iterable": test_iterable,
+    "callable": test_callable,
+    "sameas": test_sameas,
+    "escaped": test_escaped,
+    "in": test_in,
+    "==": operator.eq,
+    "eq": operator.eq,
+    "equalto": operator.eq,
+    "!=": operator.ne,
+    "ne": operator.ne,
+    ">": operator.gt,
+    "gt": operator.gt,
+    "greaterthan": operator.gt,
+    "ge": operator.ge,
+    ">=": operator.ge,
+    "<": operator.lt,
+    "lt": operator.lt,
+    "lessthan": operator.lt,
+    "<=": operator.le,
+    "le": operator.le,
 }
diff --git a/pipenv/vendor/jinja2/utils.py b/pipenv/vendor/jinja2/utils.py
index db9c5d06..e3285e8e 100644
--- a/pipenv/vendor/jinja2/utils.py
+++ b/pipenv/vendor/jinja2/utils.py
@@ -1,44 +1,44 @@
 # -*- coding: utf-8 -*-
-"""
-    jinja2.utils
-    ~~~~~~~~~~~~
-
-    Utility functions.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD, see LICENSE for more details.
-"""
-import re
 import json
-import errno
+import os
+import re
+import warnings
 from collections import deque
+from random import choice
+from random import randrange
 from threading import Lock
-from jinja2._compat import text_type, string_types, implements_iterator, \
-     url_quote, abc
 
+from markupsafe import escape
+from markupsafe import Markup
 
-_word_split_re = re.compile(r'(\s+)')
+from ._compat import abc
+from ._compat import string_types
+from ._compat import text_type
+from ._compat import url_quote
+
+_word_split_re = re.compile(r"(\s+)")
 _punctuation_re = re.compile(
-    '^(?P<lead>(?:%s)*)(?P<middle>.*?)(?P<trail>(?:%s)*)$' % (
-        '|'.join(map(re.escape, ('(', '<', '&lt;'))),
-        '|'.join(map(re.escape, ('.', ',', ')', '>', '\n', '&gt;')))
+    "^(?P<lead>(?:%s)*)(?P<middle>.*?)(?P<trail>(?:%s)*)$"
+    % (
+        "|".join(map(re.escape, ("(", "<", "&lt;"))),
+        "|".join(map(re.escape, (".", ",", ")", ">", "\n", "&gt;"))),
     )
 )
-_simple_email_re = re.compile(r'^\S+@[a-zA-Z0-9._-]+\.[a-zA-Z0-9._-]+$')
-_striptags_re = re.compile(r'(<!--.*?-->|<[^>]*>)')
-_entity_re = re.compile(r'&([^;]+);')
-_letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
-_digits = '0123456789'
+_simple_email_re = re.compile(r"^\S+@[a-zA-Z0-9._-]+\.[a-zA-Z0-9._-]+$")
+_striptags_re = re.compile(r"(<!--.*?-->|<[^>]*>)")
+_entity_re = re.compile(r"&([^;]+);")
+_letters = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
+_digits = "0123456789"
 
 # special singleton representing missing values for the runtime
-missing = type('MissingType', (), {'__repr__': lambda x: 'missing'})()
+missing = type("MissingType", (), {"__repr__": lambda x: "missing"})()
 
 # internal code
 internal_code = set()
 
-concat = u''.join
+concat = u"".join
 
-_slash_escape = '\\/' not in json.dumps('/')
+_slash_escape = "\\/" not in json.dumps("/")
 
 
 def contextfunction(f):
@@ -98,24 +98,26 @@ def is_undefined(obj):
                 return default
             return var
     """
-    from jinja2.runtime import Undefined
+    from .runtime import Undefined
+
     return isinstance(obj, Undefined)
 
 
 def consume(iterable):
     """Consumes an iterable without doing anything with it."""
-    for event in iterable:
+    for _ in iterable:
         pass
 
 
 def clear_caches():
-    """Jinja2 keeps internal caches for environments and lexers.  These are
-    used so that Jinja2 doesn't have to recreate environments and lexers all
+    """Jinja keeps internal caches for environments and lexers.  These are
+    used so that Jinja doesn't have to recreate environments and lexers all
     the time.  Normally you don't have to care about that but if you are
     measuring memory consumption you may want to clean the caches.
     """
-    from jinja2.environment import _spontaneous_environments
-    from jinja2.lexer import _lexer_cache
+    from .environment import _spontaneous_environments
+    from .lexer import _lexer_cache
+
     _spontaneous_environments.clear()
     _lexer_cache.clear()
 
@@ -132,12 +134,10 @@ def import_string(import_name, silent=False):
     :return: imported object
     """
     try:
-        if ':' in import_name:
-            module, obj = import_name.split(':', 1)
-        elif '.' in import_name:
-            items = import_name.split('.')
-            module = '.'.join(items[:-1])
-            obj = items[-1]
+        if ":" in import_name:
+            module, obj = import_name.split(":", 1)
+        elif "." in import_name:
+            module, _, obj = import_name.rpartition(".")
         else:
             return __import__(import_name)
         return getattr(__import__(module, None, None, [obj]), obj)
@@ -146,15 +146,14 @@ def import_string(import_name, silent=False):
             raise
 
 
-def open_if_exists(filename, mode='rb'):
+def open_if_exists(filename, mode="rb"):
     """Returns a file descriptor for the filename if that file exists,
-    otherwise `None`.
+    otherwise ``None``.
     """
-    try:
-        return open(filename, mode)
-    except IOError as e:
-        if e.errno not in (errno.ENOENT, errno.EISDIR, errno.EINVAL):
-            raise
+    if not os.path.isfile(filename):
+        return None
+
+    return open(filename, mode)
 
 
 def object_type_repr(obj):
@@ -163,15 +162,15 @@ def object_type_repr(obj):
     example for `None` and `Ellipsis`).
     """
     if obj is None:
-        return 'None'
+        return "None"
     elif obj is Ellipsis:
-        return 'Ellipsis'
+        return "Ellipsis"
     # __builtin__ in 2.x, builtins in 3.x
-    if obj.__class__.__module__ in ('__builtin__', 'builtins'):
+    if obj.__class__.__module__ in ("__builtin__", "builtins"):
         name = obj.__class__.__name__
     else:
-        name = obj.__class__.__module__ + '.' + obj.__class__.__name__
-    return '%s object' % name
+        name = obj.__class__.__module__ + "." + obj.__class__.__name__
+    return "%s object" % name
 
 
 def pformat(obj, verbose=False):
@@ -180,9 +179,11 @@ def pformat(obj, verbose=False):
     """
     try:
         from pretty import pretty
+
         return pretty(obj, verbose=verbose)
     except ImportError:
         from pprint import pformat
+
         return pformat(obj)
 
 
@@ -200,45 +201,60 @@ def urlize(text, trim_url_limit=None, rel=None, target=None):
 
     If target is not None, a target attribute will be added to the link.
     """
-    trim_url = lambda x, limit=trim_url_limit: limit is not None \
-                         and (x[:limit] + (len(x) >=limit and '...'
-                         or '')) or x
+    trim_url = (
+        lambda x, limit=trim_url_limit: limit is not None
+        and (x[:limit] + (len(x) >= limit and "..." or ""))
+        or x
+    )
     words = _word_split_re.split(text_type(escape(text)))
-    rel_attr = rel and ' rel="%s"' % text_type(escape(rel)) or ''
-    target_attr = target and ' target="%s"' % escape(target) or ''
+    rel_attr = rel and ' rel="%s"' % text_type(escape(rel)) or ""
+    target_attr = target and ' target="%s"' % escape(target) or ""
 
     for i, word in enumerate(words):
         match = _punctuation_re.match(word)
         if match:
             lead, middle, trail = match.groups()
-            if middle.startswith('www.') or (
-                '@' not in middle and
-                not middle.startswith('http://') and
-                not middle.startswith('https://') and
-                len(middle) > 0 and
-                middle[0] in _letters + _digits and (
-                    middle.endswith('.org') or
-                    middle.endswith('.net') or
-                    middle.endswith('.com')
-                )):
-                middle = '<a href="http://%s"%s%s>%s</a>' % (middle,
-                    rel_attr, target_attr, trim_url(middle))
-            if middle.startswith('http://') or \
-               middle.startswith('https://'):
-                middle = '<a href="%s"%s%s>%s</a>' % (middle,
-                    rel_attr, target_attr, trim_url(middle))
-            if '@' in middle and not middle.startswith('www.') and \
-               not ':' in middle and _simple_email_re.match(middle):
+            if middle.startswith("www.") or (
+                "@" not in middle
+                and not middle.startswith("http://")
+                and not middle.startswith("https://")
+                and len(middle) > 0
+                and middle[0] in _letters + _digits
+                and (
+                    middle.endswith(".org")
+                    or middle.endswith(".net")
+                    or middle.endswith(".com")
+                )
+            ):
+                middle = '<a href="http://%s"%s%s>%s</a>' % (
+                    middle,
+                    rel_attr,
+                    target_attr,
+                    trim_url(middle),
+                )
+            if middle.startswith("http://") or middle.startswith("https://"):
+                middle = '<a href="%s"%s%s>%s</a>' % (
+                    middle,
+                    rel_attr,
+                    target_attr,
+                    trim_url(middle),
+                )
+            if (
+                "@" in middle
+                and not middle.startswith("www.")
+                and ":" not in middle
+                and _simple_email_re.match(middle)
+            ):
                 middle = '<a href="mailto:%s">%s</a>' % (middle, middle)
             if lead + middle + trail != word:
                 words[i] = lead + middle + trail
-    return u''.join(words)
+    return u"".join(words)
 
 
 def generate_lorem_ipsum(n=5, html=True, min=20, max=100):
     """Generate some lorem ipsum for the template."""
-    from jinja2.constants import LOREM_IPSUM_WORDS
-    from random import choice, randrange
+    from .constants import LOREM_IPSUM_WORDS
+
     words = LOREM_IPSUM_WORDS.split()
     result = []
 
@@ -263,43 +279,53 @@ def generate_lorem_ipsum(n=5, html=True, min=20, max=100):
             if idx - randrange(3, 8) > last_comma:
                 last_comma = idx
                 last_fullstop += 2
-                word += ','
+                word += ","
             # add end of sentences
             if idx - randrange(10, 20) > last_fullstop:
                 last_comma = last_fullstop = idx
-                word += '.'
+                word += "."
                 next_capitalized = True
             p.append(word)
 
         # ensure that the paragraph ends with a dot.
-        p = u' '.join(p)
-        if p.endswith(','):
-            p = p[:-1] + '.'
-        elif not p.endswith('.'):
-            p += '.'
+        p = u" ".join(p)
+        if p.endswith(","):
+            p = p[:-1] + "."
+        elif not p.endswith("."):
+            p += "."
         result.append(p)
 
     if not html:
-        return u'\n\n'.join(result)
-    return Markup(u'\n'.join(u'<p>%s</p>' % escape(x) for x in result))
+        return u"\n\n".join(result)
+    return Markup(u"\n".join(u"<p>%s</p>" % escape(x) for x in result))
+
 
+def unicode_urlencode(obj, charset="utf-8", for_qs=False):
+    """Quote a string for use in a URL using the given charset.
 
-def unicode_urlencode(obj, charset='utf-8', for_qs=False):
-    """URL escapes a single bytestring or unicode string with the
-    given charset if applicable to URL safe quoting under all rules
-    that need to be considered under all supported Python versions.
+    This function is misnamed, it is a wrapper around
+    :func:`urllib.parse.quote`.
 
-    If non strings are provided they are converted to their unicode
-    representation first.
+    :param obj: String or bytes to quote. Other types are converted to
+        string then encoded to bytes using the given charset.
+    :param charset: Encode text to bytes using this charset.
+    :param for_qs: Quote "/" and use "+" for spaces.
     """
     if not isinstance(obj, string_types):
         obj = text_type(obj)
+
     if isinstance(obj, text_type):
         obj = obj.encode(charset)
-    safe = not for_qs and b'/' or b''
-    rv = text_type(url_quote(obj, safe))
+
+    safe = b"" if for_qs else b"/"
+    rv = url_quote(obj, safe)
+
+    if not isinstance(rv, text_type):
+        rv = rv.decode("utf-8")
+
     if for_qs:
-        rv = rv.replace('%20', '+')
+        rv = rv.replace("%20", "+")
+
     return rv
 
 
@@ -326,9 +352,9 @@ class LRUCache(object):
 
     def __getstate__(self):
         return {
-            'capacity':     self.capacity,
-            '_mapping':     self._mapping,
-            '_queue':       self._queue
+            "capacity": self.capacity,
+            "_mapping": self._mapping,
+            "_queue": self._queue,
         }
 
     def __setstate__(self, d):
@@ -342,7 +368,7 @@ class LRUCache(object):
         """Return a shallow copy of the instance."""
         rv = self.__class__(self.capacity)
         rv._mapping.update(self._mapping)
-        rv._queue = deque(self._queue)
+        rv._queue.extend(self._queue)
         return rv
 
     def get(self, key, default=None):
@@ -356,15 +382,11 @@ class LRUCache(object):
         """Set `default` if the key is not in the cache otherwise
         leave unchanged. Return the value of this key.
         """
-        self._wlock.acquire()
         try:
-            try:
-                return self[key]
-            except KeyError:
-                self[key] = default
-                return default
-        finally:
-            self._wlock.release()
+            return self[key]
+        except KeyError:
+            self[key] = default
+            return default
 
     def clear(self):
         """Clear the cache."""
@@ -384,10 +406,7 @@ class LRUCache(object):
         return len(self._mapping)
 
     def __repr__(self):
-        return '<%s %r>' % (
-            self.__class__.__name__,
-            self._mapping
-        )
+        return "<%s %r>" % (self.__class__.__name__, self._mapping)
 
     def __getitem__(self, key):
         """Get an item from the cache. Moves the item up so that it has the
@@ -436,7 +455,6 @@ class LRUCache(object):
             try:
                 self._remove(key)
             except ValueError:
-                # __getitem__ is not locked, it might happen
                 pass
         finally:
             self._wlock.release()
@@ -449,6 +467,12 @@ class LRUCache(object):
 
     def iteritems(self):
         """Iterate over all items."""
+        warnings.warn(
+            "'iteritems()' will be removed in version 3.0. Use"
+            " 'iter(cache.items())' instead.",
+            DeprecationWarning,
+            stacklevel=2,
+        )
         return iter(self.items())
 
     def values(self):
@@ -457,6 +481,22 @@ class LRUCache(object):
 
     def itervalue(self):
         """Iterate over all values."""
+        warnings.warn(
+            "'itervalue()' will be removed in version 3.0. Use"
+            " 'iter(cache.values())' instead.",
+            DeprecationWarning,
+            stacklevel=2,
+        )
+        return iter(self.values())
+
+    def itervalues(self):
+        """Iterate over all values."""
+        warnings.warn(
+            "'itervalues()' will be removed in version 3.0. Use"
+            " 'iter(cache.values())' instead.",
+            DeprecationWarning,
+            stacklevel=2,
+        )
         return iter(self.values())
 
     def keys(self):
@@ -467,12 +507,19 @@ class LRUCache(object):
         """Iterate over all keys in the cache dict, ordered by
         the most recent usage.
         """
-        return reversed(tuple(self._queue))
+        warnings.warn(
+            "'iterkeys()' will be removed in version 3.0. Use"
+            " 'iter(cache.keys())' instead.",
+            DeprecationWarning,
+            stacklevel=2,
+        )
+        return iter(self)
 
-    __iter__ = iterkeys
+    def __iter__(self):
+        return reversed(tuple(self._queue))
 
     def __reversed__(self):
-        """Iterate over the values in the cache dict, oldest items
+        """Iterate over the keys in the cache dict, oldest items
         coming first.
         """
         return iter(tuple(self._queue))
@@ -483,10 +530,12 @@ class LRUCache(object):
 abc.MutableMapping.register(LRUCache)
 
 
-def select_autoescape(enabled_extensions=('html', 'htm', 'xml'),
-                      disabled_extensions=(),
-                      default_for_string=True,
-                      default=False):
+def select_autoescape(
+    enabled_extensions=("html", "htm", "xml"),
+    disabled_extensions=(),
+    default_for_string=True,
+    default=False,
+):
     """Intelligently sets the initial value of autoescaping based on the
     filename of the template.  This is the recommended way to configure
     autoescaping if you do not want to write a custom function yourself.
@@ -521,10 +570,9 @@ def select_autoescape(enabled_extensions=('html', 'htm', 'xml'),
 
     .. versionadded:: 2.9
     """
-    enabled_patterns = tuple('.' + x.lstrip('.').lower()
-                             for x in enabled_extensions)
-    disabled_patterns = tuple('.' + x.lstrip('.').lower()
-                              for x in disabled_extensions)
+    enabled_patterns = tuple("." + x.lstrip(".").lower() for x in enabled_extensions)
+    disabled_patterns = tuple("." + x.lstrip(".").lower() for x in disabled_extensions)
+
     def autoescape(template_name):
         if template_name is None:
             return default_for_string
@@ -534,6 +582,7 @@ def select_autoescape(enabled_extensions=('html', 'htm', 'xml'),
         if template_name.endswith(disabled_patterns):
             return False
         return default
+
     return autoescape
 
 
@@ -557,35 +606,63 @@ def htmlsafe_json_dumps(obj, dumper=None, **kwargs):
     """
     if dumper is None:
         dumper = json.dumps
-    rv = dumper(obj, **kwargs) \
-        .replace(u'<', u'\\u003c') \
-        .replace(u'>', u'\\u003e') \
-        .replace(u'&', u'\\u0026') \
-        .replace(u"'", u'\\u0027')
+    rv = (
+        dumper(obj, **kwargs)
+        .replace(u"<", u"\\u003c")
+        .replace(u">", u"\\u003e")
+        .replace(u"&", u"\\u0026")
+        .replace(u"'", u"\\u0027")
+    )
     return Markup(rv)
 
 
-@implements_iterator
 class Cycler(object):
-    """A cycle helper for templates."""
+    """Cycle through values by yield them one at a time, then restarting
+    once the end is reached. Available as ``cycler`` in templates.
+
+    Similar to ``loop.cycle``, but can be used outside loops or across
+    multiple loops. For example, render a list of folders and files in a
+    list, alternating giving them "odd" and "even" classes.
+
+    .. code-block:: html+jinja
+
+        {% set row_class = cycler("odd", "even") %}
+        <ul class="browser">
+        {% for folder in folders %}
+          <li class="folder {{ row_class.next() }}">{{ folder }}
+        {% endfor %}
+        {% for file in files %}
+          <li class="file {{ row_class.next() }}">{{ file }}
+        {% endfor %}
+        </ul>
+
+    :param items: Each positional argument will be yielded in the order
+        given for each cycle.
+
+    .. versionadded:: 2.1
+    """
 
     def __init__(self, *items):
         if not items:
-            raise RuntimeError('at least one item has to be provided')
+            raise RuntimeError("at least one item has to be provided")
         self.items = items
-        self.reset()
+        self.pos = 0
 
     def reset(self):
-        """Resets the cycle."""
+        """Resets the current item to the first item."""
         self.pos = 0
 
     @property
     def current(self):
-        """Returns the current item."""
+        """Return the current item. Equivalent to the item that will be
+        returned next time :meth:`next` is called.
+        """
         return self.items[self.pos]
 
     def next(self):
-        """Goes one item ahead and returns it."""
+        """Return the current item, then advance :attr:`current` to the
+        next item.
+        """
         rv = self.current
         self.pos = (self.pos + 1) % len(self.items)
         return rv
@@ -596,27 +673,27 @@ class Cycler(object):
 class Joiner(object):
     """A joining helper for templates."""
 
-    def __init__(self, sep=u', '):
+    def __init__(self, sep=u", "):
         self.sep = sep
         self.used = False
 
     def __call__(self):
         if not self.used:
             self.used = True
-            return u''
+            return u""
         return self.sep
 
 
 class Namespace(object):
     """A namespace object that can hold arbitrary attributes.  It may be
-    initialized from a dictionary or with keyword argments."""
+    initialized from a dictionary or with keyword arguments."""
 
-    def __init__(*args, **kwargs):
+    def __init__(*args, **kwargs):  # noqa: B902
         self, args = args[0], args[1:]
         self.__attrs = dict(*args, **kwargs)
 
     def __getattribute__(self, name):
-        if name == '_Namespace__attrs':
+        if name == "_Namespace__attrs":
             return object.__getattribute__(self, name)
         try:
             return self.__attrs[name]
@@ -627,16 +704,24 @@ class Namespace(object):
         self.__attrs[name] = value
 
     def __repr__(self):
-        return '<Namespace %r>' % self.__attrs
+        return "<Namespace %r>" % self.__attrs
 
 
 # does this python version support async for in and async generators?
 try:
-    exec('async def _():\n async for _ in ():\n  yield _')
+    exec("async def _():\n async for _ in ():\n  yield _")
     have_async_gen = True
 except SyntaxError:
     have_async_gen = False
 
 
-# Imported here because that's where it was in the past
-from markupsafe import Markup, escape, soft_unicode
+def soft_unicode(s):
+    from markupsafe import soft_unicode
+
+    warnings.warn(
+        "'jinja2.utils.soft_unicode' will be removed in version 3.0."
+        " Use 'markupsafe.soft_unicode' instead.",
+        DeprecationWarning,
+        stacklevel=2,
+    )
+    return soft_unicode(s)
diff --git a/pipenv/vendor/jinja2/visitor.py b/pipenv/vendor/jinja2/visitor.py
index ba526dfa..d1365bf1 100644
--- a/pipenv/vendor/jinja2/visitor.py
+++ b/pipenv/vendor/jinja2/visitor.py
@@ -1,14 +1,8 @@
 # -*- coding: utf-8 -*-
+"""API for traversing the AST nodes. Implemented by the compiler and
+meta introspection.
 """
-    jinja2.visitor
-    ~~~~~~~~~~~~~~
-
-    This module implements a visitor for the nodes.
-
-    :copyright: (c) 2017 by the Jinja Team.
-    :license: BSD.
-"""
-from jinja2.nodes import Node
+from .nodes import Node
 
 
 class NodeVisitor(object):
@@ -28,7 +22,7 @@ class NodeVisitor(object):
         exists for this node.  In that case the generic visit function is
         used instead.
         """
-        method = 'visit_' + node.__class__.__name__
+        method = "visit_" + node.__class__.__name__
         return getattr(self, method, None)
 
     def visit(self, node, *args, **kwargs):
diff --git a/pipenv/vendor/packaging/LICENSE.APACHE b/pipenv/vendor/packaging/LICENSE.APACHE
index 4947287f..f433b1a5 100644
--- a/pipenv/vendor/packaging/LICENSE.APACHE
+++ b/pipenv/vendor/packaging/LICENSE.APACHE
@@ -174,4 +174,4 @@
       incurred by, or claims asserted against, such Contributor by reason
       of your accepting any such warranty or additional liability.
 
-   END OF TERMS AND CONDITIONS
\ No newline at end of file
+   END OF TERMS AND CONDITIONS
diff --git a/pipenv/vendor/packaging/__about__.py b/pipenv/vendor/packaging/__about__.py
index dc95138d..5161d141 100644
--- a/pipenv/vendor/packaging/__about__.py
+++ b/pipenv/vendor/packaging/__about__.py
@@ -18,7 +18,7 @@ __title__ = "packaging"
 __summary__ = "Core utilities for Python packages"
 __uri__ = "https://github.com/pypa/packaging"
 
-__version__ = "19.2"
+__version__ = "20.3"
 
 __author__ = "Donald Stufft and individual contributors"
 __email__ = "donald@stufft.io"
diff --git a/pipenv/vendor/packaging/_compat.py b/pipenv/vendor/packaging/_compat.py
index 25da473c..a145f7ee 100644
--- a/pipenv/vendor/packaging/_compat.py
+++ b/pipenv/vendor/packaging/_compat.py
@@ -5,6 +5,11 @@ from __future__ import absolute_import, division, print_function
 
 import sys
 
+from ._typing import MYPY_CHECK_RUNNING
+
+if MYPY_CHECK_RUNNING:  # pragma: no cover
+    from typing import Any, Dict, Tuple, Type
+
 
 PY2 = sys.version_info[0] == 2
 PY3 = sys.version_info[0] == 3
@@ -18,14 +23,16 @@ else:
 
 
 def with_metaclass(meta, *bases):
+    # type: (Type[Any], Tuple[Type[Any], ...]) -> Any
     """
     Create a base class with a metaclass.
     """
     # This requires a bit of explanation: the basic idea is to make a dummy
     # metaclass for one level of class instantiation that replaces itself with
     # the actual metaclass.
-    class metaclass(meta):
+    class metaclass(meta):  # type: ignore
         def __new__(cls, name, this_bases, d):
+            # type: (Type[Any], str, Tuple[Any], Dict[Any, Any]) -> Any
             return meta(name, bases, d)
 
     return type.__new__(metaclass, "temporary_class", (), {})
diff --git a/pipenv/vendor/packaging/_structures.py b/pipenv/vendor/packaging/_structures.py
index 68dcca63..800d5c55 100644
--- a/pipenv/vendor/packaging/_structures.py
+++ b/pipenv/vendor/packaging/_structures.py
@@ -4,65 +4,83 @@
 from __future__ import absolute_import, division, print_function
 
 
-class Infinity(object):
+class InfinityType(object):
     def __repr__(self):
+        # type: () -> str
         return "Infinity"
 
     def __hash__(self):
+        # type: () -> int
         return hash(repr(self))
 
     def __lt__(self, other):
+        # type: (object) -> bool
         return False
 
     def __le__(self, other):
+        # type: (object) -> bool
         return False
 
     def __eq__(self, other):
+        # type: (object) -> bool
         return isinstance(other, self.__class__)
 
     def __ne__(self, other):
+        # type: (object) -> bool
         return not isinstance(other, self.__class__)
 
     def __gt__(self, other):
+        # type: (object) -> bool
         return True
 
     def __ge__(self, other):
+        # type: (object) -> bool
         return True
 
     def __neg__(self):
+        # type: (object) -> NegativeInfinityType
         return NegativeInfinity
 
 
-Infinity = Infinity()
+Infinity = InfinityType()
 
 
-class NegativeInfinity(object):
+class NegativeInfinityType(object):
     def __repr__(self):
+        # type: () -> str
         return "-Infinity"
 
     def __hash__(self):
+        # type: () -> int
         return hash(repr(self))
 
     def __lt__(self, other):
+        # type: (object) -> bool
         return True
 
     def __le__(self, other):
+        # type: (object) -> bool
         return True
 
     def __eq__(self, other):
+        # type: (object) -> bool
         return isinstance(other, self.__class__)
 
     def __ne__(self, other):
+        # type: (object) -> bool
         return not isinstance(other, self.__class__)
 
     def __gt__(self, other):
+        # type: (object) -> bool
         return False
 
     def __ge__(self, other):
+        # type: (object) -> bool
         return False
 
     def __neg__(self):
+        # type: (object) -> InfinityType
         return Infinity
 
 
-NegativeInfinity = NegativeInfinity()
+NegativeInfinity = NegativeInfinityType()
diff --git a/pipenv/vendor/packaging/_typing.py b/pipenv/vendor/packaging/_typing.py
new file mode 100644
index 00000000..dc6dfce7
--- /dev/null
+++ b/pipenv/vendor/packaging/_typing.py
@@ -0,0 +1,39 @@
+"""For neatly implementing static typing in packaging.
+
+`mypy` - the static type analysis tool we use - uses the `typing` module, which
+provides core functionality fundamental to mypy's functioning.
+
+Generally, `typing` would be imported at runtime and used in that fashion -
+it acts as a no-op at runtime and does not have any run-time overhead by
+design.
+
+As it turns out, `typing` is not vendorable - it uses separate sources for
+Python 2/Python 3. Thus, this codebase can not expect it to be present.
+To work around this, mypy allows the typing import to be behind a False-y
+optional to prevent it from running at runtime and type-comments can be used
+to remove the need for the types to be accessible directly during runtime.
+
+This module provides the False-y guard in a nicely named fashion so that a
+curious maintainer can reach here to read this.
+
+In packaging, all static-typing related imports should be guarded as follows:
+
+    from packaging._typing import MYPY_CHECK_RUNNING
+
+    if MYPY_CHECK_RUNNING:
+        from typing import ...
+
+Ref: https://github.com/python/mypy/issues/3216
+"""
+
+MYPY_CHECK_RUNNING = False
+
+if MYPY_CHECK_RUNNING:  # pragma: no cover
+    import typing
+
+    cast = typing.cast
+else:
+    # typing's cast() is needed at runtime, but we don't want to import typing.
+    # Thus, we use a dummy no-op version, which we tell mypy to ignore.
+    def cast(type_, value):  # type: ignore
+        return value
diff --git a/pipenv/vendor/packaging/markers.py b/pipenv/vendor/packaging/markers.py
index 3b8af324..f0174711 100644
--- a/pipenv/vendor/packaging/markers.py
+++ b/pipenv/vendor/packaging/markers.py
@@ -13,8 +13,14 @@ from pyparsing import ZeroOrMore, Group, Forward, QuotedString
 from pyparsing import Literal as L  # noqa
 
 from ._compat import string_types
+from ._typing import MYPY_CHECK_RUNNING
 from .specifiers import Specifier, InvalidSpecifier
 
+if MYPY_CHECK_RUNNING:  # pragma: no cover
+    from typing import Any, Callable, Dict, List, Optional, Tuple, Union
+
+    Operator = Callable[[str, str], bool]
+
 
 __all__ = [
     "InvalidMarker",
@@ -46,30 +52,37 @@ class UndefinedEnvironmentName(ValueError):
 
 class Node(object):
     def __init__(self, value):
+        # type: (Any) -> None
         self.value = value
 
     def __str__(self):
+        # type: () -> str
         return str(self.value)
 
     def __repr__(self):
+        # type: () -> str
         return "<{0}({1!r})>".format(self.__class__.__name__, str(self))
 
     def serialize(self):
+        # type: () -> str
         raise NotImplementedError
 
 
 class Variable(Node):
     def serialize(self):
+        # type: () -> str
         return str(self)
 
 
 class Value(Node):
     def serialize(self):
+        # type: () -> str
         return '"{0}"'.format(self)
 
 
 class Op(Node):
     def serialize(self):
+        # type: () -> str
         return str(self)
 
 
@@ -85,13 +98,13 @@ VARIABLE = (
     | L("python_version")
     | L("sys_platform")
     | L("os_name")
-    | L("os.name")
+    | L("os.name")  # PEP-345
     | L("sys.platform")  # PEP-345
     | L("platform.version")  # PEP-345
     | L("platform.machine")  # PEP-345
     | L("platform.python_implementation")  # PEP-345
-    | L("python_implementation")  # PEP-345
-    | L("extra")  # undocumented setuptools legacy
+    | L("python_implementation")  # undocumented setuptools legacy
+    | L("extra")  # PEP-508
 )
 ALIASES = {
     "os.name": "os_name",
@@ -131,6 +144,7 @@ MARKER = stringStart + MARKER_EXPR + stringEnd
 
 
 def _coerce_parse_result(results):
+    # type: (Union[ParseResults, List[Any]]) -> List[Any]
     if isinstance(results, ParseResults):
         return [_coerce_parse_result(i) for i in results]
     else:
@@ -138,6 +152,8 @@ def _coerce_parse_result(results):
 
 
 def _format_marker(marker, first=True):
+    # type: (Union[List[str], Tuple[Node, ...], str], Optional[bool]) -> str
+
     assert isinstance(marker, (list, tuple, string_types))
 
     # Sometimes we have a structure like [[...]] which is a single item list
@@ -172,10 +188,11 @@ _operators = {
     "!=": operator.ne,
     ">=": operator.ge,
     ">": operator.gt,
-}
+}  # type: Dict[str, Operator]
 
 
 def _eval_op(lhs, op, rhs):
+    # type: (str, Op, str) -> bool
     try:
         spec = Specifier("".join([op.serialize(), rhs]))
     except InvalidSpecifier:
@@ -183,7 +200,7 @@ def _eval_op(lhs, op, rhs):
     else:
         return spec.contains(lhs)
 
-    oper = _operators.get(op.serialize())
+    oper = _operators.get(op.serialize())  # type: Optional[Operator]
     if oper is None:
         raise UndefinedComparison(
             "Undefined {0!r} on {1!r} and {2!r}.".format(op, lhs, rhs)
@@ -192,13 +209,18 @@ def _eval_op(lhs, op, rhs):
     return oper(lhs, rhs)
 
 
-_undefined = object()
+class Undefined(object):
+    pass
+
+
+_undefined = Undefined()
 
 
 def _get_env(environment, name):
-    value = environment.get(name, _undefined)
+    # type: (Dict[str, str], str) -> str
+    value = environment.get(name, _undefined)  # type: Union[str, Undefined]
 
-    if value is _undefined:
+    if isinstance(value, Undefined):
         raise UndefinedEnvironmentName(
             "{0!r} does not exist in evaluation environment.".format(name)
         )
@@ -207,7 +229,8 @@ def _get_env(environment, name):
 
 
 def _evaluate_markers(markers, environment):
-    groups = [[]]
+    # type: (List[Any], Dict[str, str]) -> bool
+    groups = [[]]  # type: List[List[bool]]
 
     for marker in markers:
         assert isinstance(marker, (list, tuple, string_types))
@@ -234,6 +257,7 @@ def _evaluate_markers(markers, environment):
 
 
 def format_full_version(info):
+    # type: (sys._version_info) -> str
     version = "{0.major}.{0.minor}.{0.micro}".format(info)
     kind = info.releaselevel
     if kind != "final":
@@ -242,9 +266,13 @@ def format_full_version(info):
 
 
 def default_environment():
+    # type: () -> Dict[str, str]
     if hasattr(sys, "implementation"):
-        iver = format_full_version(sys.implementation.version)
-        implementation_name = sys.implementation.name
+        # Ignoring the `sys.implementation` reference for type checking due to
+        # mypy not liking that the attribute doesn't exist in Python 2.7 when
+        # run with the `--py27` flag.
+        iver = format_full_version(sys.implementation.version)  # type: ignore
+        implementation_name = sys.implementation.name  # type: ignore
     else:
         iver = "0"
         implementation_name = ""
@@ -266,6 +294,7 @@ def default_environment():
 
 class Marker(object):
     def __init__(self, marker):
+        # type: (str) -> None
         try:
             self._markers = _coerce_parse_result(MARKER.parseString(marker))
         except ParseException as e:
@@ -275,12 +304,15 @@ class Marker(object):
             raise InvalidMarker(err_str)
 
     def __str__(self):
+        # type: () -> str
         return _format_marker(self._markers)
 
     def __repr__(self):
+        # type: () -> str
         return "<Marker({0!r})>".format(str(self))
 
     def evaluate(self, environment=None):
+        # type: (Optional[Dict[str, str]]) -> bool
         """Evaluate a marker.
 
         Return the boolean from evaluating the given marker against the
diff --git a/pipenv/vendor/packaging/py.typed b/pipenv/vendor/packaging/py.typed
new file mode 100644
index 00000000..e69de29b
diff --git a/pipenv/vendor/packaging/requirements.py b/pipenv/vendor/packaging/requirements.py
index 4d9688b9..1b547927 100644
--- a/pipenv/vendor/packaging/requirements.py
+++ b/pipenv/vendor/packaging/requirements.py
@@ -11,9 +11,13 @@ from pyparsing import ZeroOrMore, Word, Optional, Regex, Combine
 from pyparsing import Literal as L  # noqa
 from six.moves.urllib import parse as urlparse
 
+from ._typing import MYPY_CHECK_RUNNING
 from .markers import MARKER_EXPR, Marker
 from .specifiers import LegacySpecifier, Specifier, SpecifierSet
 
+if MYPY_CHECK_RUNNING:  # pragma: no cover
+    from typing import List
+
 
 class InvalidRequirement(ValueError):
     """
@@ -89,6 +93,7 @@ class Requirement(object):
     # TODO: Can we normalize the name and extra name?
 
     def __init__(self, requirement_string):
+        # type: (str) -> None
         try:
             req = REQUIREMENT.parseString(requirement_string)
         except ParseException as e:
@@ -116,7 +121,8 @@ class Requirement(object):
         self.marker = req.marker if req.marker else None
 
     def __str__(self):
-        parts = [self.name]
+        # type: () -> str
+        parts = [self.name]  # type: List[str]
 
         if self.extras:
             parts.append("[{0}]".format(",".join(sorted(self.extras))))
@@ -135,4 +141,5 @@ class Requirement(object):
         return "".join(parts)
 
     def __repr__(self):
+        # type: () -> str
         return "<Requirement({0!r})>".format(str(self))
diff --git a/pipenv/vendor/packaging/specifiers.py b/pipenv/vendor/packaging/specifiers.py
index 743576a0..94987486 100644
--- a/pipenv/vendor/packaging/specifiers.py
+++ b/pipenv/vendor/packaging/specifiers.py
@@ -9,8 +9,26 @@ import itertools
 import re
 
 from ._compat import string_types, with_metaclass
+from ._typing import MYPY_CHECK_RUNNING
 from .version import Version, LegacyVersion, parse
 
+if MYPY_CHECK_RUNNING:  # pragma: no cover
+    from typing import (
+        List,
+        Dict,
+        Union,
+        Iterable,
+        Iterator,
+        Optional,
+        Callable,
+        Tuple,
+        FrozenSet,
+    )
+
+    ParsedVersion = Union[Version, LegacyVersion]
+    UnparsedVersion = Union[Version, LegacyVersion, str]
+    CallableOperator = Callable[[ParsedVersion, str], bool]
+
 
 class InvalidSpecifier(ValueError):
     """
@@ -18,9 +36,10 @@ class InvalidSpecifier(ValueError):
     """
 
 
-class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):
+class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):  # type: ignore
     @abc.abstractmethod
     def __str__(self):
+        # type: () -> str
         """
         Returns the str representation of this Specifier like object. This
         should be representative of the Specifier itself.
@@ -28,12 +47,14 @@ class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):
 
     @abc.abstractmethod
     def __hash__(self):
+        # type: () -> int
         """
         Returns a hash value for this Specifier like object.
         """
 
     @abc.abstractmethod
     def __eq__(self, other):
+        # type: (object) -> bool
         """
         Returns a boolean representing whether or not the two Specifier like
         objects are equal.
@@ -41,6 +62,7 @@ class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):
 
     @abc.abstractmethod
     def __ne__(self, other):
+        # type: (object) -> bool
         """
         Returns a boolean representing whether or not the two Specifier like
         objects are not equal.
@@ -48,6 +70,7 @@ class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):
 
     @abc.abstractproperty
     def prereleases(self):
+        # type: () -> Optional[bool]
         """
         Returns whether or not pre-releases as a whole are allowed by this
         specifier.
@@ -55,6 +78,7 @@ class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):
 
     @prereleases.setter
     def prereleases(self, value):
+        # type: (bool) -> None
         """
         Sets whether or not pre-releases as a whole are allowed by this
         specifier.
@@ -62,12 +86,14 @@ class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):
 
     @abc.abstractmethod
     def contains(self, item, prereleases=None):
+        # type: (str, Optional[bool]) -> bool
         """
         Determines if the given item is contained within this specifier.
         """
 
     @abc.abstractmethod
     def filter(self, iterable, prereleases=None):
+        # type: (Iterable[UnparsedVersion], Optional[bool]) -> Iterable[UnparsedVersion]
         """
         Takes an iterable of items and filters them so that only items which
         are contained within this specifier are allowed in it.
@@ -76,19 +102,24 @@ class BaseSpecifier(with_metaclass(abc.ABCMeta, object)):
 
 class _IndividualSpecifier(BaseSpecifier):
 
-    _operators = {}
+    _operators = {}  # type: Dict[str, str]
 
     def __init__(self, spec="", prereleases=None):
+        # type: (str, Optional[bool]) -> None
         match = self._regex.search(spec)
         if not match:
             raise InvalidSpecifier("Invalid specifier: '{0}'".format(spec))
 
-        self._spec = (match.group("operator").strip(), match.group("version").strip())
+        self._spec = (
+            match.group("operator").strip(),
+            match.group("version").strip(),
+        )  # type: Tuple[str, str]
 
         # Store whether or not this Specifier should accept prereleases
         self._prereleases = prereleases
 
     def __repr__(self):
+        # type: () -> str
         pre = (
             ", prereleases={0!r}".format(self.prereleases)
             if self._prereleases is not None
@@ -98,15 +129,18 @@ class _IndividualSpecifier(BaseSpecifier):
         return "<{0}({1!r}{2})>".format(self.__class__.__name__, str(self), pre)
 
     def __str__(self):
+        # type: () -> str
         return "{0}{1}".format(*self._spec)
 
     def __hash__(self):
+        # type: () -> int
         return hash(self._spec)
 
     def __eq__(self, other):
+        # type: (object) -> bool
         if isinstance(other, string_types):
             try:
-                other = self.__class__(other)
+                other = self.__class__(str(other))
             except InvalidSpecifier:
                 return NotImplemented
         elif not isinstance(other, self.__class__):
@@ -115,9 +149,10 @@ class _IndividualSpecifier(BaseSpecifier):
         return self._spec == other._spec
 
     def __ne__(self, other):
+        # type: (object) -> bool
         if isinstance(other, string_types):
             try:
-                other = self.__class__(other)
+                other = self.__class__(str(other))
             except InvalidSpecifier:
                 return NotImplemented
         elif not isinstance(other, self.__class__):
@@ -126,52 +161,67 @@ class _IndividualSpecifier(BaseSpecifier):
         return self._spec != other._spec
 
     def _get_operator(self, op):
-        return getattr(self, "_compare_{0}".format(self._operators[op]))
+        # type: (str) -> CallableOperator
+        operator_callable = getattr(
+            self, "_compare_{0}".format(self._operators[op])
+        )  # type: CallableOperator
+        return operator_callable
 
     def _coerce_version(self, version):
+        # type: (UnparsedVersion) -> ParsedVersion
         if not isinstance(version, (LegacyVersion, Version)):
             version = parse(version)
         return version
 
     @property
     def operator(self):
+        # type: () -> str
         return self._spec[0]
 
     @property
     def version(self):
+        # type: () -> str
         return self._spec[1]
 
     @property
     def prereleases(self):
+        # type: () -> Optional[bool]
         return self._prereleases
 
     @prereleases.setter
     def prereleases(self, value):
+        # type: (bool) -> None
         self._prereleases = value
 
     def __contains__(self, item):
+        # type: (str) -> bool
         return self.contains(item)
 
     def contains(self, item, prereleases=None):
+        # type: (UnparsedVersion, Optional[bool]) -> bool
+
         # Determine if prereleases are to be allowed or not.
         if prereleases is None:
             prereleases = self.prereleases
 
         # Normalize item to a Version or LegacyVersion, this allows us to have
         # a shortcut for ``"2.0" in Specifier(">=2")
-        item = self._coerce_version(item)
+        normalized_item = self._coerce_version(item)
 
         # Determine if we should be supporting prereleases in this specifier
         # or not, if we do not support prereleases than we can short circuit
         # logic if this version is a prereleases.
-        if item.is_prerelease and not prereleases:
+        if normalized_item.is_prerelease and not prereleases:
             return False
 
         # Actually do the comparison to determine if this item is contained
         # within this Specifier or not.
-        return self._get_operator(self.operator)(item, self.version)
+        operator_callable = self._get_operator(self.operator)  # type: CallableOperator
+        return operator_callable(normalized_item, self.version)
 
     def filter(self, iterable, prereleases=None):
+        # type: (Iterable[UnparsedVersion], Optional[bool]) -> Iterable[UnparsedVersion]
+
         yielded = False
         found_prereleases = []
 
@@ -230,32 +280,43 @@ class LegacySpecifier(_IndividualSpecifier):
     }
 
     def _coerce_version(self, version):
+        # type: (Union[ParsedVersion, str]) -> LegacyVersion
         if not isinstance(version, LegacyVersion):
             version = LegacyVersion(str(version))
         return version
 
     def _compare_equal(self, prospective, spec):
+        # type: (LegacyVersion, str) -> bool
         return prospective == self._coerce_version(spec)
 
     def _compare_not_equal(self, prospective, spec):
+        # type: (LegacyVersion, str) -> bool
         return prospective != self._coerce_version(spec)
 
     def _compare_less_than_equal(self, prospective, spec):
+        # type: (LegacyVersion, str) -> bool
         return prospective <= self._coerce_version(spec)
 
     def _compare_greater_than_equal(self, prospective, spec):
+        # type: (LegacyVersion, str) -> bool
         return prospective >= self._coerce_version(spec)
 
     def _compare_less_than(self, prospective, spec):
+        # type: (LegacyVersion, str) -> bool
         return prospective < self._coerce_version(spec)
 
     def _compare_greater_than(self, prospective, spec):
+        # type: (LegacyVersion, str) -> bool
         return prospective > self._coerce_version(spec)
 
 
-def _require_version_compare(fn):
+def _require_version_compare(
+    fn  # type: (Callable[[Specifier, ParsedVersion, str], bool])
+):
+    # type: (...) -> Callable[[Specifier, ParsedVersion, str], bool]
     @functools.wraps(fn)
     def wrapped(self, prospective, spec):
+        # type: (Specifier, ParsedVersion, str) -> bool
         if not isinstance(prospective, Version):
             return False
         return fn(self, prospective, spec)
@@ -373,6 +434,8 @@ class Specifier(_IndividualSpecifier):
 
     @_require_version_compare
     def _compare_compatible(self, prospective, spec):
+        # type: (ParsedVersion, str) -> bool
+
         # Compatible releases have an equivalent combination of >= and ==. That
         # is that ~=2.2 is equivalent to >=2.2,==2.*. This allows us to
         # implement this in terms of the other specifiers instead of
@@ -400,56 +463,67 @@ class Specifier(_IndividualSpecifier):
 
     @_require_version_compare
     def _compare_equal(self, prospective, spec):
+        # type: (ParsedVersion, str) -> bool
+
         # We need special logic to handle prefix matching
         if spec.endswith(".*"):
             # In the case of prefix matching we want to ignore local segment.
             prospective = Version(prospective.public)
             # Split the spec out by dots, and pretend that there is an implicit
             # dot in between a release segment and a pre-release segment.
-            spec = _version_split(spec[:-2])  # Remove the trailing .*
+            split_spec = _version_split(spec[:-2])  # Remove the trailing .*
 
             # Split the prospective version out by dots, and pretend that there
             # is an implicit dot in between a release segment and a pre-release
             # segment.
-            prospective = _version_split(str(prospective))
+            split_prospective = _version_split(str(prospective))
 
             # Shorten the prospective version to be the same length as the spec
             # so that we can determine if the specifier is a prefix of the
             # prospective version or not.
-            prospective = prospective[: len(spec)]
+            shortened_prospective = split_prospective[: len(split_spec)]
 
             # Pad out our two sides with zeros so that they both equal the same
             # length.
-            spec, prospective = _pad_version(spec, prospective)
+            padded_spec, padded_prospective = _pad_version(
+                split_spec, shortened_prospective
+            )
+
+            return padded_prospective == padded_spec
         else:
             # Convert our spec string into a Version
-            spec = Version(spec)
+            spec_version = Version(spec)
 
             # If the specifier does not have a local segment, then we want to
             # act as if the prospective version also does not have a local
             # segment.
-            if not spec.local:
+            if not spec_version.local:
                 prospective = Version(prospective.public)
 
-        return prospective == spec
+            return prospective == spec_version
 
     @_require_version_compare
     def _compare_not_equal(self, prospective, spec):
+        # type: (ParsedVersion, str) -> bool
         return not self._compare_equal(prospective, spec)
 
     @_require_version_compare
     def _compare_less_than_equal(self, prospective, spec):
+        # type: (ParsedVersion, str) -> bool
         return prospective <= Version(spec)
 
     @_require_version_compare
     def _compare_greater_than_equal(self, prospective, spec):
+        # type: (ParsedVersion, str) -> bool
         return prospective >= Version(spec)
 
     @_require_version_compare
-    def _compare_less_than(self, prospective, spec):
+    def _compare_less_than(self, prospective, spec_str):
+        # type: (ParsedVersion, str) -> bool
+
         # Convert our spec to a Version instance, since we'll want to work with
         # it as a version.
-        spec = Version(spec)
+        spec = Version(spec_str)
 
         # Check to see if the prospective version is less than the spec
         # version. If it's not we can short circuit and just return False now
@@ -471,10 +545,12 @@ class Specifier(_IndividualSpecifier):
         return True
 
     @_require_version_compare
-    def _compare_greater_than(self, prospective, spec):
+    def _compare_greater_than(self, prospective, spec_str):
+        # type: (ParsedVersion, str) -> bool
+
         # Convert our spec to a Version instance, since we'll want to work with
         # it as a version.
-        spec = Version(spec)
+        spec = Version(spec_str)
 
         # Check to see if the prospective version is greater than the spec
         # version. If it's not we can short circuit and just return False now
@@ -502,10 +578,13 @@ class Specifier(_IndividualSpecifier):
         return True
 
     def _compare_arbitrary(self, prospective, spec):
+        # type: (Version, str) -> bool
         return str(prospective).lower() == str(spec).lower()
 
     @property
     def prereleases(self):
+        # type: () -> bool
+
         # If there is an explicit prereleases set for this, then we'll just
         # blindly use that.
         if self._prereleases is not None:
@@ -530,6 +609,7 @@ class Specifier(_IndividualSpecifier):
 
     @prereleases.setter
     def prereleases(self, value):
+        # type: (bool) -> None
         self._prereleases = value
 
 
@@ -537,7 +617,8 @@ _prefix_regex = re.compile(r"^([0-9]+)((?:a|b|c|rc)[0-9]+)$")
 
 
 def _version_split(version):
-    result = []
+    # type: (str) -> List[str]
+    result = []  # type: List[str]
     for item in version.split("."):
         match = _prefix_regex.search(item)
         if match:
@@ -548,6 +629,7 @@ def _version_split(version):
 
 
 def _pad_version(left, right):
+    # type: (List[str], List[str]) -> Tuple[List[str], List[str]]
     left_split, right_split = [], []
 
     # Get the release segment of our versions
@@ -567,14 +649,16 @@ def _pad_version(left, right):
 
 class SpecifierSet(BaseSpecifier):
     def __init__(self, specifiers="", prereleases=None):
-        # Split on , to break each indidivual specifier into it's own item, and
+        # type: (str, Optional[bool]) -> None
+
+        # Split on , to break each individual specifier into it's own item, and
         # strip each item to remove leading/trailing whitespace.
-        specifiers = [s.strip() for s in specifiers.split(",") if s.strip()]
+        split_specifiers = [s.strip() for s in specifiers.split(",") if s.strip()]
 
         # Parsed each individual specifier, attempting first to make it a
         # Specifier and falling back to a LegacySpecifier.
         parsed = set()
-        for specifier in specifiers:
+        for specifier in split_specifiers:
             try:
                 parsed.add(Specifier(specifier))
             except InvalidSpecifier:
@@ -588,6 +672,7 @@ class SpecifierSet(BaseSpecifier):
         self._prereleases = prereleases
 
     def __repr__(self):
+        # type: () -> str
         pre = (
             ", prereleases={0!r}".format(self.prereleases)
             if self._prereleases is not None
@@ -597,12 +682,15 @@ class SpecifierSet(BaseSpecifier):
         return "<SpecifierSet({0!r}{1})>".format(str(self), pre)
 
     def __str__(self):
+        # type: () -> str
         return ",".join(sorted(str(s) for s in self._specs))
 
     def __hash__(self):
+        # type: () -> int
         return hash(self._specs)
 
     def __and__(self, other):
+        # type: (Union[SpecifierSet, str]) -> SpecifierSet
         if isinstance(other, string_types):
             other = SpecifierSet(other)
         elif not isinstance(other, SpecifierSet):
@@ -626,9 +714,8 @@ class SpecifierSet(BaseSpecifier):
         return specifier
 
     def __eq__(self, other):
-        if isinstance(other, string_types):
-            other = SpecifierSet(other)
-        elif isinstance(other, _IndividualSpecifier):
+        # type: (object) -> bool
+        if isinstance(other, (string_types, _IndividualSpecifier)):
             other = SpecifierSet(str(other))
         elif not isinstance(other, SpecifierSet):
             return NotImplemented
@@ -636,9 +723,8 @@ class SpecifierSet(BaseSpecifier):
         return self._specs == other._specs
 
     def __ne__(self, other):
-        if isinstance(other, string_types):
-            other = SpecifierSet(other)
-        elif isinstance(other, _IndividualSpecifier):
+        # type: (object) -> bool
+        if isinstance(other, (string_types, _IndividualSpecifier)):
             other = SpecifierSet(str(other))
         elif not isinstance(other, SpecifierSet):
             return NotImplemented
@@ -646,13 +732,17 @@ class SpecifierSet(BaseSpecifier):
         return self._specs != other._specs
 
     def __len__(self):
+        # type: () -> int
         return len(self._specs)
 
     def __iter__(self):
+        # type: () -> Iterator[FrozenSet[_IndividualSpecifier]]
         return iter(self._specs)
 
     @property
     def prereleases(self):
+        # type: () -> Optional[bool]
+
         # If we have been given an explicit prerelease modifier, then we'll
         # pass that through here.
         if self._prereleases is not None:
@@ -670,12 +760,16 @@ class SpecifierSet(BaseSpecifier):
 
     @prereleases.setter
     def prereleases(self, value):
+        # type: (bool) -> None
         self._prereleases = value
 
     def __contains__(self, item):
+        # type: (Union[ParsedVersion, str]) -> bool
         return self.contains(item)
 
     def contains(self, item, prereleases=None):
+        # type: (Union[ParsedVersion, str], Optional[bool]) -> bool
+
         # Ensure that our item is a Version or LegacyVersion instance.
         if not isinstance(item, (LegacyVersion, Version)):
             item = parse(item)
@@ -701,7 +795,13 @@ class SpecifierSet(BaseSpecifier):
         #       will always return True, this is an explicit design decision.
         return all(s.contains(item, prereleases=prereleases) for s in self._specs)
 
-    def filter(self, iterable, prereleases=None):
+    def filter(
+        self,
+        iterable,  # type: Iterable[Union[ParsedVersion, str]]
+        prereleases=None,  # type: Optional[bool]
+    ):
+        # type: (...) -> Iterable[Union[ParsedVersion, str]]
+
         # Determine if we're forcing a prerelease or not, if we're not forcing
         # one for this particular filter call, then we'll use whatever the
         # SpecifierSet thinks for whether or not we should support prereleases.
@@ -719,8 +819,8 @@ class SpecifierSet(BaseSpecifier):
         # which will filter out any pre-releases, unless there are no final
         # releases, and which will filter out LegacyVersion in general.
         else:
-            filtered = []
-            found_prereleases = []
+            filtered = []  # type: List[Union[ParsedVersion, str]]
+            found_prereleases = []  # type: List[Union[ParsedVersion, str]]
 
             for item in iterable:
                 # Ensure that we some kind of Version class for this item.
diff --git a/pipenv/vendor/packaging/tags.py b/pipenv/vendor/packaging/tags.py
index ec9942f0..300faab8 100644
--- a/pipenv/vendor/packaging/tags.py
+++ b/pipenv/vendor/packaging/tags.py
@@ -13,12 +13,37 @@ except ImportError:  # pragma: no cover
 
     EXTENSION_SUFFIXES = [x[0] for x in imp.get_suffixes()]
     del imp
+import logging
+import os
 import platform
 import re
+import struct
 import sys
 import sysconfig
 import warnings
 
+from ._typing import MYPY_CHECK_RUNNING, cast
+
+if MYPY_CHECK_RUNNING:  # pragma: no cover
+    from typing import (
+        Dict,
+        FrozenSet,
+        IO,
+        Iterable,
+        Iterator,
+        List,
+        Optional,
+        Sequence,
+        Tuple,
+        Union,
+    )
+
+    PythonVersion = Sequence[int]
+    MacVersion = Tuple[int, int]
+    GlibcVersion = Tuple[int, int]
+
+
+logger = logging.getLogger(__name__)
 
 INTERPRETER_SHORT_NAMES = {
     "python": "py",  # Generic.
@@ -26,7 +51,7 @@ INTERPRETER_SHORT_NAMES = {
     "pypy": "pp",
     "ironpython": "ip",
     "jython": "jy",
-}
+}  # type: Dict[str, str]
 
 
 _32_BIT_INTERPRETER = sys.maxsize <= 2 ** 32
@@ -37,23 +62,31 @@ class Tag(object):
     __slots__ = ["_interpreter", "_abi", "_platform"]
 
     def __init__(self, interpreter, abi, platform):
+        # type: (str, str, str) -> None
         self._interpreter = interpreter.lower()
         self._abi = abi.lower()
         self._platform = platform.lower()
 
     @property
     def interpreter(self):
+        # type: () -> str
         return self._interpreter
 
     @property
     def abi(self):
+        # type: () -> str
         return self._abi
 
     @property
     def platform(self):
+        # type: () -> str
         return self._platform
 
     def __eq__(self, other):
+        # type: (object) -> bool
+        if not isinstance(other, Tag):
+            return NotImplemented
+
         return (
             (self.platform == other.platform)
             and (self.abi == other.abi)
@@ -61,16 +94,20 @@ class Tag(object):
         )
 
     def __hash__(self):
+        # type: () -> int
         return hash((self._interpreter, self._abi, self._platform))
 
     def __str__(self):
+        # type: () -> str
         return "{}-{}-{}".format(self._interpreter, self._abi, self._platform)
 
     def __repr__(self):
+        # type: () -> str
         return "<{self} @ {self_id}>".format(self=self, self_id=id(self))
 
 
 def parse_tag(tag):
+    # type: (str) -> FrozenSet[Tag]
     tags = set()
     interpreters, abis, platforms = tag.split("-")
     for interpreter in interpreters.split("."):
@@ -80,20 +117,54 @@ def parse_tag(tag):
     return frozenset(tags)
 
 
+def _warn_keyword_parameter(func_name, kwargs):
+    # type: (str, Dict[str, bool]) -> bool
+    """
+    Backwards-compatibility with Python 2.7 to allow treating 'warn' as keyword-only.
+    """
+    if not kwargs:
+        return False
+    elif len(kwargs) > 1 or "warn" not in kwargs:
+        kwargs.pop("warn", None)
+        arg = next(iter(kwargs.keys()))
+        raise TypeError(
+            "{}() got an unexpected keyword argument {!r}".format(func_name, arg)
+        )
+    return kwargs["warn"]
+
+
+def _get_config_var(name, warn=False):
+    # type: (str, bool) -> Union[int, str, None]
+    value = sysconfig.get_config_var(name)
+    if value is None and warn:
+        logger.debug(
+            "Config variable '%s' is unset, Python ABI tag may be incorrect", name
+        )
+    return value
+
+
 def _normalize_string(string):
+    # type: (str) -> str
     return string.replace(".", "_").replace("-", "_")
 
 
-def _cpython_interpreter(py_version):
-    # TODO: Is using py_version_nodot for interpreter version critical?
-    return "cp{major}{minor}".format(major=py_version[0], minor=py_version[1])
+def _abi3_applies(python_version):
+    # type: (PythonVersion) -> bool
+    """
+    Determine if the Python version supports abi3.
+
+    PEP 384 was first implemented in Python 3.2.
+    """
+    return len(python_version) > 1 and tuple(python_version) >= (3, 2)
 
 
-def _cpython_abis(py_version):
+def _cpython_abis(py_version, warn=False):
+    # type: (PythonVersion, bool) -> List[str]
+    py_version = tuple(py_version)  # To allow for version comparison.
     abis = []
-    version = "{}{}".format(*py_version[:2])
+    version = _version_nodot(py_version[:2])
     debug = pymalloc = ucs4 = ""
-    with_debug = sysconfig.get_config_var("Py_DEBUG")
+    with_debug = _get_config_var("Py_DEBUG", warn)
     has_refcount = hasattr(sys, "gettotalrefcount")
     # Windows doesn't set Py_DEBUG, so checking for support of debug-compiled
     # extension modules is the best option.
@@ -102,11 +173,11 @@ def _cpython_abis(py_version):
     if with_debug or (with_debug is None and (has_refcount or has_ext)):
         debug = "d"
     if py_version < (3, 8):
-        with_pymalloc = sysconfig.get_config_var("WITH_PYMALLOC")
+        with_pymalloc = _get_config_var("WITH_PYMALLOC", warn)
         if with_pymalloc or with_pymalloc is None:
             pymalloc = "m"
         if py_version < (3, 3):
-            unicode_size = sysconfig.get_config_var("Py_UNICODE_SIZE")
+            unicode_size = _get_config_var("Py_UNICODE_SIZE", warn)
             if unicode_size == 4 or (
                 unicode_size is None and sys.maxunicode == 0x10FFFF
             ):
@@ -124,86 +195,148 @@ def _cpython_abis(py_version):
     return abis
 
 
-def _cpython_tags(py_version, interpreter, abis, platforms):
+def cpython_tags(
+    python_version=None,  # type: Optional[PythonVersion]
+    abis=None,  # type: Optional[Iterable[str]]
+    platforms=None,  # type: Optional[Iterable[str]]
+    **kwargs  # type: bool
+):
+    # type: (...) -> Iterator[Tag]
+    """
+    Yields the tags for a CPython interpreter.
+
+    The tags consist of:
+    - cp<python_version>-<abi>-<platform>
+    - cp<python_version>-abi3-<platform>
+    - cp<python_version>-none-<platform>
+    - cp<less than python_version>-abi3-<platform>  # Older Python versions down to 3.2.
+
+    If python_version only specifies a major version then user-provided ABIs and
+    the 'none' ABItag will be used.
+
+    If 'abi3' or 'none' are specified in 'abis' then they will be yielded at
+    their normal position and not at the beginning.
+    """
+    warn = _warn_keyword_parameter("cpython_tags", kwargs)
+    if not python_version:
+        python_version = sys.version_info[:2]
+
+    interpreter = "cp{}".format(_version_nodot(python_version[:2]))
+
+    if abis is None:
+        if len(python_version) > 1:
+            abis = _cpython_abis(python_version, warn)
+        else:
+            abis = []
+    abis = list(abis)
+    # 'abi3' and 'none' are explicitly handled later.
+    for explicit_abi in ("abi3", "none"):
+        try:
+            abis.remove(explicit_abi)
+        except ValueError:
+            pass
+
+    platforms = list(platforms or _platform_tags())
     for abi in abis:
         for platform_ in platforms:
             yield Tag(interpreter, abi, platform_)
-    for tag in (Tag(interpreter, "abi3", platform_) for platform_ in platforms):
-        yield tag
+    if _abi3_applies(python_version):
+        for tag in (Tag(interpreter, "abi3", platform_) for platform_ in platforms):
+            yield tag
     for tag in (Tag(interpreter, "none", platform_) for platform_ in platforms):
         yield tag
-    # PEP 384 was first implemented in Python 3.2.
-    for minor_version in range(py_version[1] - 1, 1, -1):
-        for platform_ in platforms:
-            interpreter = "cp{major}{minor}".format(
-                major=py_version[0], minor=minor_version
-            )
-            yield Tag(interpreter, "abi3", platform_)
 
-
-def _pypy_interpreter():
-    return "pp{py_major}{pypy_major}{pypy_minor}".format(
-        py_major=sys.version_info[0],
-        pypy_major=sys.pypy_version_info.major,
-        pypy_minor=sys.pypy_version_info.minor,
-    )
+    if _abi3_applies(python_version):
+        for minor_version in range(python_version[1] - 1, 1, -1):
+            for platform_ in platforms:
+                interpreter = "cp{version}".format(
+                    version=_version_nodot((python_version[0], minor_version))
+                )
+                yield Tag(interpreter, "abi3", platform_)
 
 
 def _generic_abi():
+    # type: () -> Iterator[str]
     abi = sysconfig.get_config_var("SOABI")
     if abi:
-        return _normalize_string(abi)
-    else:
-        return "none"
+        yield _normalize_string(abi)
 
 
-def _pypy_tags(py_version, interpreter, abi, platforms):
-    for tag in (Tag(interpreter, abi, platform) for platform in platforms):
-        yield tag
-    for tag in (Tag(interpreter, "none", platform) for platform in platforms):
-        yield tag
+def generic_tags(
+    interpreter=None,  # type: Optional[str]
+    abis=None,  # type: Optional[Iterable[str]]
+    platforms=None,  # type: Optional[Iterable[str]]
+    **kwargs  # type: bool
+):
+    # type: (...) -> Iterator[Tag]
+    """
+    Yields the tags for a generic interpreter.
 
+    The tags consist of:
+    - <interpreter>-<abi>-<platform>
 
-def _generic_tags(interpreter, py_version, abi, platforms):
-    for tag in (Tag(interpreter, abi, platform) for platform in platforms):
-        yield tag
-    if abi != "none":
-        tags = (Tag(interpreter, "none", platform_) for platform_ in platforms)
-        for tag in tags:
-            yield tag
+    The "none" ABI will be added if it was not explicitly provided.
+    """
+    warn = _warn_keyword_parameter("generic_tags", kwargs)
+    if not interpreter:
+        interp_name = interpreter_name()
+        interp_version = interpreter_version(warn=warn)
+        interpreter = "".join([interp_name, interp_version])
+    if abis is None:
+        abis = _generic_abi()
+    platforms = list(platforms or _platform_tags())
+    abis = list(abis)
+    if "none" not in abis:
+        abis.append("none")
+    for abi in abis:
+        for platform_ in platforms:
+            yield Tag(interpreter, abi, platform_)
 
 
 def _py_interpreter_range(py_version):
+    # type: (PythonVersion) -> Iterator[str]
     """
-    Yield Python versions in descending order.
+    Yields Python versions in descending order.
 
     After the latest version, the major-only version will be yielded, and then
-    all following versions up to 'end'.
+    all previous versions of that major version.
     """
-    yield "py{major}{minor}".format(major=py_version[0], minor=py_version[1])
+    if len(py_version) > 1:
+        yield "py{version}".format(version=_version_nodot(py_version[:2]))
     yield "py{major}".format(major=py_version[0])
-    for minor in range(py_version[1] - 1, -1, -1):
-        yield "py{major}{minor}".format(major=py_version[0], minor=minor)
+    if len(py_version) > 1:
+        for minor in range(py_version[1] - 1, -1, -1):
+            yield "py{version}".format(version=_version_nodot((py_version[0], minor)))
 
 
-def _independent_tags(interpreter, py_version, platforms):
+def compatible_tags(
+    python_version=None,  # type: Optional[PythonVersion]
+    interpreter=None,  # type: Optional[str]
+    platforms=None,  # type: Optional[Iterable[str]]
+):
+    # type: (...) -> Iterator[Tag]
     """
-    Return the sequence of tags that are consistent across implementations.
+    Yields the sequence of tags that are compatible with a specific version of Python.
 
     The tags consist of:
     - py*-none-<platform>
-    - <interpreter>-none-any
+    - <interpreter>-none-any  # ... if `interpreter` is provided.
     - py*-none-any
     """
-    for version in _py_interpreter_range(py_version):
+    if not python_version:
+        python_version = sys.version_info[:2]
+    platforms = list(platforms or _platform_tags())
+    for version in _py_interpreter_range(python_version):
         for platform_ in platforms:
             yield Tag(version, "none", platform_)
-    yield Tag(interpreter, "none", "any")
-    for version in _py_interpreter_range(py_version):
+    if interpreter:
+        yield Tag(interpreter, "none", "any")
+    for version in _py_interpreter_range(python_version):
         yield Tag(version, "none", "any")
 
 
 def _mac_arch(arch, is_32bit=_32_BIT_INTERPRETER):
+    # type: (str, bool) -> str
     if not is_32bit:
         return arch
 
@@ -214,6 +347,7 @@ def _mac_arch(arch, is_32bit=_32_BIT_INTERPRETER):
 
 
 def _mac_binary_formats(version, cpu_arch):
+    # type: (MacVersion, str) -> List[str]
     formats = [cpu_arch]
     if cpu_arch == "x86_64":
         if version < (10, 4):
@@ -240,32 +374,42 @@ def _mac_binary_formats(version, cpu_arch):
     return formats
 
 
-def _mac_platforms(version=None, arch=None):
-    version_str, _, cpu_arch = platform.mac_ver()
+def mac_platforms(version=None, arch=None):
+    # type: (Optional[MacVersion], Optional[str]) -> Iterator[str]
+    """
+    Yields the platform tags for a macOS system.
+
+    The `version` parameter is a two-item tuple specifying the macOS version to
+    generate platform tags for. The `arch` parameter is the CPU architecture to
+    generate platform tags for. Both parameters default to the appropriate value
+    for the current system.
+    """
+    version_str, _, cpu_arch = platform.mac_ver()  # type: ignore
     if version is None:
-        version = tuple(map(int, version_str.split(".")[:2]))
+        version = cast("MacVersion", tuple(map(int, version_str.split(".")[:2])))
+    else:
+        version = version
     if arch is None:
         arch = _mac_arch(cpu_arch)
-    platforms = []
+    else:
+        arch = arch
     for minor_version in range(version[1], -1, -1):
         compat_version = version[0], minor_version
         binary_formats = _mac_binary_formats(compat_version, arch)
         for binary_format in binary_formats:
-            platforms.append(
-                "macosx_{major}_{minor}_{binary_format}".format(
-                    major=compat_version[0],
-                    minor=compat_version[1],
-                    binary_format=binary_format,
-                )
+            yield "macosx_{major}_{minor}_{binary_format}".format(
+                major=compat_version[0],
+                minor=compat_version[1],
+                binary_format=binary_format,
             )
-    return platforms
 
 
 # From PEP 513.
 def _is_manylinux_compatible(name, glibc_version):
+    # type: (str, GlibcVersion) -> bool
     # Check for presence of _manylinux module.
     try:
-        import _manylinux
+        import _manylinux  # noqa
 
         return bool(getattr(_manylinux, name + "_compatible"))
     except (ImportError, AttributeError):
@@ -276,14 +420,50 @@ def _is_manylinux_compatible(name, glibc_version):
 
 
 def _glibc_version_string():
+    # type: () -> Optional[str]
     # Returns glibc version string, or None if not using glibc.
-    import ctypes
+    return _glibc_version_string_confstr() or _glibc_version_string_ctypes()
+
+
+def _glibc_version_string_confstr():
+    # type: () -> Optional[str]
+    """
+    Primary implementation of glibc_version_string using os.confstr.
+    """
+    # os.confstr is quite a bit faster than ctypes.DLL. It's also less likely
+    # to be broken or missing. This strategy is used in the standard library
+    # platform module.
+    # https://github.com/python/cpython/blob/fcf1d003bf4f0100c9d0921ff3d70e1127ca1b71/Lib/platform.py#L175-L183
+    try:
+        # os.confstr("CS_GNU_LIBC_VERSION") returns a string like "glibc 2.17".
+        version_string = os.confstr(  # type: ignore[attr-defined] # noqa: F821
+            "CS_GNU_LIBC_VERSION"
+        )
+        assert version_string is not None
+        _, version = version_string.split()  # type: Tuple[str, str]
+    except (AssertionError, AttributeError, OSError, ValueError):
+        # os.confstr() or CS_GNU_LIBC_VERSION not available (or a bad value)...
+        return None
+    return version
+
+
+def _glibc_version_string_ctypes():
+    # type: () -> Optional[str]
+    """
+    Fallback implementation of glibc_version_string using ctypes.
+    """
+    try:
+        import ctypes
+    except ImportError:
+        return None
 
     # ctypes.CDLL(None) internally calls dlopen(NULL), and as the dlopen
     # manpage says, "If filename is NULL, then the returned handle is for the
     # main program". This way we can let the linker do the work to figure out
     # which libc our process is actually using.
-    process_namespace = ctypes.CDLL(None)
+    #
+    # Note: typeshed is wrong here so we are ignoring this line.
+    process_namespace = ctypes.CDLL(None)  # type: ignore
     try:
         gnu_get_libc_version = process_namespace.gnu_get_libc_version
     except AttributeError:
@@ -293,7 +473,7 @@ def _glibc_version_string():
 
     # Call gnu_get_libc_version, which returns a string like "2.5"
     gnu_get_libc_version.restype = ctypes.c_char_p
-    version_str = gnu_get_libc_version()
+    version_str = gnu_get_libc_version()  # type: str
     # py2 / py3 compatibility:
     if not isinstance(version_str, str):
         version_str = version_str.decode("ascii")
@@ -303,6 +483,7 @@ def _glibc_version_string():
 
 # Separated out from have_compatible_glibc for easier unit testing.
 def _check_glibc_version(version_str, required_major, minimum_minor):
+    # type: (str, int, int) -> bool
     # Parse string and check against requested version.
     #
     # We use a regexp instead of str.split because we want to discard any
@@ -324,81 +505,235 @@ def _check_glibc_version(version_str, required_major, minimum_minor):
 
 
 def _have_compatible_glibc(required_major, minimum_minor):
+    # type: (int, int) -> bool
     version_str = _glibc_version_string()
     if version_str is None:
         return False
     return _check_glibc_version(version_str, required_major, minimum_minor)
 
 
+# Python does not provide platform information at sufficient granularity to
+# identify the architecture of the running executable in some cases, so we
+# determine it dynamically by reading the information from the running
+# process. This only applies on Linux, which uses the ELF format.
+class _ELFFileHeader(object):
+    # https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#File_header
+    class _InvalidELFFileHeader(ValueError):
+        """
+        An invalid ELF file header was found.
+        """
+
+    ELF_MAGIC_NUMBER = 0x7F454C46
+    ELFCLASS32 = 1
+    ELFCLASS64 = 2
+    ELFDATA2LSB = 1
+    ELFDATA2MSB = 2
+    EM_386 = 3
+    EM_S390 = 22
+    EM_ARM = 40
+    EM_X86_64 = 62
+    EF_ARM_ABIMASK = 0xFF000000
+    EF_ARM_ABI_VER5 = 0x05000000
+    EF_ARM_ABI_FLOAT_HARD = 0x00000400
+
+    def __init__(self, file):
+        # type: (IO[bytes]) -> None
+        def unpack(fmt):
+            # type: (str) -> int
+            try:
+                result, = struct.unpack(
+                    fmt, file.read(struct.calcsize(fmt))
+                )  # type: (int, )
+            except struct.error:
+                raise _ELFFileHeader._InvalidELFFileHeader()
+            return result
+
+        self.e_ident_magic = unpack(">I")
+        if self.e_ident_magic != self.ELF_MAGIC_NUMBER:
+            raise _ELFFileHeader._InvalidELFFileHeader()
+        self.e_ident_class = unpack("B")
+        if self.e_ident_class not in {self.ELFCLASS32, self.ELFCLASS64}:
+            raise _ELFFileHeader._InvalidELFFileHeader()
+        self.e_ident_data = unpack("B")
+        if self.e_ident_data not in {self.ELFDATA2LSB, self.ELFDATA2MSB}:
+            raise _ELFFileHeader._InvalidELFFileHeader()
+        self.e_ident_version = unpack("B")
+        self.e_ident_osabi = unpack("B")
+        self.e_ident_abiversion = unpack("B")
+        self.e_ident_pad = file.read(7)
+        format_h = "<H" if self.e_ident_data == self.ELFDATA2LSB else ">H"
+        format_i = "<I" if self.e_ident_data == self.ELFDATA2LSB else ">I"
+        format_q = "<Q" if self.e_ident_data == self.ELFDATA2LSB else ">Q"
+        format_p = format_i if self.e_ident_class == self.ELFCLASS32 else format_q
+        self.e_type = unpack(format_h)
+        self.e_machine = unpack(format_h)
+        self.e_version = unpack(format_i)
+        self.e_entry = unpack(format_p)
+        self.e_phoff = unpack(format_p)
+        self.e_shoff = unpack(format_p)
+        self.e_flags = unpack(format_i)
+        self.e_ehsize = unpack(format_h)
+        self.e_phentsize = unpack(format_h)
+        self.e_phnum = unpack(format_h)
+        self.e_shentsize = unpack(format_h)
+        self.e_shnum = unpack(format_h)
+        self.e_shstrndx = unpack(format_h)
+
+
+def _get_elf_header():
+    # type: () -> Optional[_ELFFileHeader]
+    try:
+        with open(sys.executable, "rb") as f:
+            elf_header = _ELFFileHeader(f)
+    except (IOError, OSError, TypeError, _ELFFileHeader._InvalidELFFileHeader):
+        return None
+    return elf_header
+
+
+def _is_linux_armhf():
+    # type: () -> bool
+    # hard-float ABI can be detected from the ELF header of the running
+    # process
+    # https://static.docs.arm.com/ihi0044/g/aaelf32.pdf
+    elf_header = _get_elf_header()
+    if elf_header is None:
+        return False
+    result = elf_header.e_ident_class == elf_header.ELFCLASS32
+    result &= elf_header.e_ident_data == elf_header.ELFDATA2LSB
+    result &= elf_header.e_machine == elf_header.EM_ARM
+    result &= (
+        elf_header.e_flags & elf_header.EF_ARM_ABIMASK
+    ) == elf_header.EF_ARM_ABI_VER5
+    result &= (
+        elf_header.e_flags & elf_header.EF_ARM_ABI_FLOAT_HARD
+    ) == elf_header.EF_ARM_ABI_FLOAT_HARD
+    return result
+
+
+def _is_linux_i686():
+    # type: () -> bool
+    elf_header = _get_elf_header()
+    if elf_header is None:
+        return False
+    result = elf_header.e_ident_class == elf_header.ELFCLASS32
+    result &= elf_header.e_ident_data == elf_header.ELFDATA2LSB
+    result &= elf_header.e_machine == elf_header.EM_386
+    return result
+
+
+def _have_compatible_manylinux_abi(arch):
+    # type: (str) -> bool
+    if arch == "armv7l":
+        return _is_linux_armhf()
+    if arch == "i686":
+        return _is_linux_i686()
+    return True
+
+
 def _linux_platforms(is_32bit=_32_BIT_INTERPRETER):
+    # type: (bool) -> Iterator[str]
     linux = _normalize_string(distutils.util.get_platform())
-    if linux == "linux_x86_64" and is_32bit:
-        linux = "linux_i686"
-    manylinux_support = (
-        ("manylinux2014", (2, 17)),  # CentOS 7 w/ glibc 2.17 (PEP 599)
-        ("manylinux2010", (2, 12)),  # CentOS 6 w/ glibc 2.12 (PEP 571)
-        ("manylinux1", (2, 5)),  # CentOS 5 w/ glibc 2.5 (PEP 513)
-    )
+    if is_32bit:
+        if linux == "linux_x86_64":
+            linux = "linux_i686"
+        elif linux == "linux_aarch64":
+            linux = "linux_armv7l"
+    manylinux_support = []
+    _, arch = linux.split("_", 1)
+    if _have_compatible_manylinux_abi(arch):
+        if arch in {"x86_64", "i686", "aarch64", "armv7l", "ppc64", "ppc64le", "s390x"}:
+            manylinux_support.append(
+                ("manylinux2014", (2, 17))
+            )  # CentOS 7 w/ glibc 2.17 (PEP 599)
+        if arch in {"x86_64", "i686"}:
+            manylinux_support.append(
+                ("manylinux2010", (2, 12))
+            )  # CentOS 6 w/ glibc 2.12 (PEP 571)
+            manylinux_support.append(
+                ("manylinux1", (2, 5))
+            )  # CentOS 5 w/ glibc 2.5 (PEP 513)
     manylinux_support_iter = iter(manylinux_support)
     for name, glibc_version in manylinux_support_iter:
         if _is_manylinux_compatible(name, glibc_version):
-            platforms = [linux.replace("linux", name)]
+            yield linux.replace("linux", name)
             break
-    else:
-        platforms = []
     # Support for a later manylinux implies support for an earlier version.
-    platforms += [linux.replace("linux", name) for name, _ in manylinux_support_iter]
-    platforms.append(linux)
-    return platforms
+    for name, _ in manylinux_support_iter:
+        yield linux.replace("linux", name)
+    yield linux
 
 
 def _generic_platforms():
-    platform = _normalize_string(distutils.util.get_platform())
-    return [platform]
+    # type: () -> Iterator[str]
+    yield _normalize_string(distutils.util.get_platform())
+
+
+def _platform_tags():
+    # type: () -> Iterator[str]
+    """
+    Provides the platform tags for this installation.
+    """
+    if platform.system() == "Darwin":
+        return mac_platforms()
+    elif platform.system() == "Linux":
+        return _linux_platforms()
+    else:
+        return _generic_platforms()
 
 
-def _interpreter_name():
-    name = platform.python_implementation().lower()
+def interpreter_name():
+    # type: () -> str
+    """
+    Returns the name of the running interpreter.
+    """
+    try:
+        name = sys.implementation.name  # type: ignore
+    except AttributeError:  # pragma: no cover
+        # Python 2.7 compatibility.
+        name = platform.python_implementation().lower()
     return INTERPRETER_SHORT_NAMES.get(name) or name
 
 
-def _generic_interpreter(name, py_version):
-    version = sysconfig.get_config_var("py_version_nodot")
-    if not version:
-        version = "".join(map(str, py_version[:2]))
-    return "{name}{version}".format(name=name, version=version)
+def interpreter_version(**kwargs):
+    # type: (bool) -> str
+    """
+    Returns the version of the running interpreter.
+    """
+    warn = _warn_keyword_parameter("interpreter_version", kwargs)
+    version = _get_config_var("py_version_nodot", warn=warn)
+    if version:
+        version = str(version)
+    else:
+        version = _version_nodot(sys.version_info[:2])
+    return version
+
+
+def _version_nodot(version):
+    # type: (PythonVersion) -> str
+    if any(v >= 10 for v in version):
+        sep = "_"
+    else:
+        sep = ""
+    return sep.join(map(str, version))
 
 
-def sys_tags():
+def sys_tags(**kwargs):
+    # type: (bool) -> Iterator[Tag]
     """
     Returns the sequence of tag triples for the running interpreter.
 
     The order of the sequence corresponds to priority order for the
     interpreter, from most to least important.
     """
-    py_version = sys.version_info[:2]
-    interpreter_name = _interpreter_name()
-    if platform.system() == "Darwin":
-        platforms = _mac_platforms()
-    elif platform.system() == "Linux":
-        platforms = _linux_platforms()
-    else:
-        platforms = _generic_platforms()
+    warn = _warn_keyword_parameter("sys_tags", kwargs)
 
-    if interpreter_name == "cp":
-        interpreter = _cpython_interpreter(py_version)
-        abis = _cpython_abis(py_version)
-        for tag in _cpython_tags(py_version, interpreter, abis, platforms):
-            yield tag
-    elif interpreter_name == "pp":
-        interpreter = _pypy_interpreter()
-        abi = _generic_abi()
-        for tag in _pypy_tags(py_version, interpreter, abi, platforms):
+    interp_name = interpreter_name()
+    if interp_name == "cp":
+        for tag in cpython_tags(warn=warn):
             yield tag
     else:
-        interpreter = _generic_interpreter(interpreter_name, py_version)
-        abi = _generic_abi()
-        for tag in _generic_tags(interpreter, py_version, abi, platforms):
+        for tag in generic_tags():
             yield tag
-    for tag in _independent_tags(interpreter, py_version, platforms):
+
+    for tag in compatible_tags():
         yield tag
diff --git a/pipenv/vendor/packaging/utils.py b/pipenv/vendor/packaging/utils.py
index 88418786..44f1bf98 100644
--- a/pipenv/vendor/packaging/utils.py
+++ b/pipenv/vendor/packaging/utils.py
@@ -5,28 +5,33 @@ from __future__ import absolute_import, division, print_function
 
 import re
 
+from ._typing import MYPY_CHECK_RUNNING
 from .version import InvalidVersion, Version
 
+if MYPY_CHECK_RUNNING:  # pragma: no cover
+    from typing import Union
 
 _canonicalize_regex = re.compile(r"[-_.]+")
 
 
 def canonicalize_name(name):
+    # type: (str) -> str
     # This is taken from PEP 503.
     return _canonicalize_regex.sub("-", name).lower()
 
 
-def canonicalize_version(version):
+def canonicalize_version(_version):
+    # type: (str) -> Union[Version, str]
     """
-    This is very similar to Version.__str__, but has one subtle differences
+    This is very similar to Version.__str__, but has one subtle difference
     with the way it handles the release segment.
     """
 
     try:
-        version = Version(version)
+        version = Version(_version)
     except InvalidVersion:
         # Legacy versions cannot be normalized
-        return version
+        return _version
 
     parts = []
 
diff --git a/pipenv/vendor/packaging/version.py b/pipenv/vendor/packaging/version.py
index 95157a1f..f39a2a12 100644
--- a/pipenv/vendor/packaging/version.py
+++ b/pipenv/vendor/packaging/version.py
@@ -7,8 +7,35 @@ import collections
 import itertools
 import re
 
-from ._structures import Infinity
-
+from ._structures import Infinity, NegativeInfinity
+from ._typing import MYPY_CHECK_RUNNING
+
+if MYPY_CHECK_RUNNING:  # pragma: no cover
+    from typing import Callable, Iterator, List, Optional, SupportsInt, Tuple, Union
+
+    from ._structures import InfinityType, NegativeInfinityType
+
+    InfiniteTypes = Union[InfinityType, NegativeInfinityType]
+    PrePostDevType = Union[InfiniteTypes, Tuple[str, int]]
+    SubLocalType = Union[InfiniteTypes, int, str]
+    LocalType = Union[
+        NegativeInfinityType,
+        Tuple[
+            Union[
+                SubLocalType,
+                Tuple[SubLocalType, str],
+                Tuple[NegativeInfinityType, SubLocalType],
+            ],
+            ...,
+        ],
+    ]
+    CmpKey = Tuple[
+        int, Tuple[int, ...], PrePostDevType, PrePostDevType, PrePostDevType, LocalType
+    ]
+    LegacyCmpKey = Tuple[int, Tuple[str, ...]]
+    VersionComparisonMethod = Callable[
+        [Union[CmpKey, LegacyCmpKey], Union[CmpKey, LegacyCmpKey]], bool
+    ]
 
 __all__ = ["parse", "Version", "LegacyVersion", "InvalidVersion", "VERSION_PATTERN"]
 
@@ -19,6 +46,7 @@ _Version = collections.namedtuple(
 
 
 def parse(version):
+    # type: (str) -> Union[LegacyVersion, Version]
     """
     Parse the given version string and return either a :class:`Version` object
     or a :class:`LegacyVersion` object depending on if the given version is
@@ -37,28 +65,38 @@ class InvalidVersion(ValueError):
 
 
 class _BaseVersion(object):
+    _key = None  # type: Union[CmpKey, LegacyCmpKey]
+
     def __hash__(self):
+        # type: () -> int
         return hash(self._key)
 
     def __lt__(self, other):
+        # type: (_BaseVersion) -> bool
         return self._compare(other, lambda s, o: s < o)
 
     def __le__(self, other):
+        # type: (_BaseVersion) -> bool
         return self._compare(other, lambda s, o: s <= o)
 
     def __eq__(self, other):
+        # type: (object) -> bool
         return self._compare(other, lambda s, o: s == o)
 
     def __ge__(self, other):
+        # type: (_BaseVersion) -> bool
         return self._compare(other, lambda s, o: s >= o)
 
     def __gt__(self, other):
+        # type: (_BaseVersion) -> bool
         return self._compare(other, lambda s, o: s > o)
 
     def __ne__(self, other):
+        # type: (object) -> bool
         return self._compare(other, lambda s, o: s != o)
 
     def _compare(self, other, method):
+        # type: (object, VersionComparisonMethod) -> Union[bool, NotImplemented]
         if not isinstance(other, _BaseVersion):
             return NotImplemented
 
@@ -67,57 +105,71 @@ class _BaseVersion(object):
 
 class LegacyVersion(_BaseVersion):
     def __init__(self, version):
+        # type: (str) -> None
         self._version = str(version)
         self._key = _legacy_cmpkey(self._version)
 
     def __str__(self):
+        # type: () -> str
         return self._version
 
     def __repr__(self):
+        # type: () -> str
         return "<LegacyVersion({0})>".format(repr(str(self)))
 
     @property
     def public(self):
+        # type: () -> str
         return self._version
 
     @property
     def base_version(self):
+        # type: () -> str
         return self._version
 
     @property
     def epoch(self):
+        # type: () -> int
         return -1
 
     @property
     def release(self):
+        # type: () -> None
         return None
 
     @property
     def pre(self):
+        # type: () -> None
         return None
 
     @property
     def post(self):
+        # type: () -> None
         return None
 
     @property
     def dev(self):
+        # type: () -> None
         return None
 
     @property
     def local(self):
+        # type: () -> None
         return None
 
     @property
     def is_prerelease(self):
+        # type: () -> bool
         return False
 
     @property
     def is_postrelease(self):
+        # type: () -> bool
         return False
 
     @property
     def is_devrelease(self):
+        # type: () -> bool
         return False
 
 
@@ -133,6 +185,7 @@ _legacy_version_replacement_map = {
 
 
 def _parse_version_parts(s):
+    # type: (str) -> Iterator[str]
     for part in _legacy_version_component_re.split(s):
         part = _legacy_version_replacement_map.get(part, part)
 
@@ -150,6 +203,8 @@ def _parse_version_parts(s):
 
 
 def _legacy_cmpkey(version):
+    # type: (str) -> LegacyCmpKey
+
     # We hardcode an epoch of -1 here. A PEP 440 version can only have a epoch
     # greater than or equal to 0. This will effectively put the LegacyVersion,
     # which uses the defacto standard originally implemented by setuptools,
@@ -158,7 +213,7 @@ def _legacy_cmpkey(version):
 
     # This scheme is taken from pkg_resources.parse_version setuptools prior to
     # it's adoption of the packaging library.
-    parts = []
+    parts = []  # type: List[str]
     for part in _parse_version_parts(version.lower()):
         if part.startswith("*"):
             # remove "-" before a prerelease tag
@@ -171,9 +226,8 @@ def _legacy_cmpkey(version):
                 parts.pop()
 
         parts.append(part)
-    parts = tuple(parts)
 
-    return epoch, parts
+    return epoch, tuple(parts)
 
 
 # Deliberately not anchored to the start and end of the string, to make it
@@ -215,6 +269,8 @@ class Version(_BaseVersion):
     _regex = re.compile(r"^\s*" + VERSION_PATTERN + r"\s*$", re.VERBOSE | re.IGNORECASE)
 
     def __init__(self, version):
+        # type: (str) -> None
+
         # Validate the version and parse it into pieces
         match = self._regex.search(version)
         if not match:
@@ -243,9 +299,11 @@ class Version(_BaseVersion):
         )
 
     def __repr__(self):
+        # type: () -> str
         return "<Version({0})>".format(repr(str(self)))
 
     def __str__(self):
+        # type: () -> str
         parts = []
 
         # Epoch
@@ -275,26 +333,35 @@ class Version(_BaseVersion):
 
     @property
     def epoch(self):
-        return self._version.epoch
+        # type: () -> int
+        _epoch = self._version.epoch  # type: int
+        return _epoch
 
     @property
     def release(self):
-        return self._version.release
+        # type: () -> Tuple[int, ...]
+        _release = self._version.release  # type: Tuple[int, ...]
+        return _release
 
     @property
     def pre(self):
-        return self._version.pre
+        # type: () -> Optional[Tuple[str, int]]
+        _pre = self._version.pre  # type: Optional[Tuple[str, int]]
+        return _pre
 
     @property
     def post(self):
+        # type: () -> Optional[Tuple[str, int]]
         return self._version.post[1] if self._version.post else None
 
     @property
     def dev(self):
+        # type: () -> Optional[Tuple[str, int]]
         return self._version.dev[1] if self._version.dev else None
 
     @property
     def local(self):
+        # type: () -> Optional[str]
         if self._version.local:
             return ".".join(str(x) for x in self._version.local)
         else:
@@ -302,10 +369,12 @@ class Version(_BaseVersion):
 
     @property
     def public(self):
+        # type: () -> str
         return str(self).split("+", 1)[0]
 
     @property
     def base_version(self):
+        # type: () -> str
         parts = []
 
         # Epoch
@@ -319,18 +388,41 @@ class Version(_BaseVersion):
 
     @property
     def is_prerelease(self):
+        # type: () -> bool
         return self.dev is not None or self.pre is not None
 
     @property
     def is_postrelease(self):
+        # type: () -> bool
         return self.post is not None
 
     @property
     def is_devrelease(self):
+        # type: () -> bool
         return self.dev is not None
 
+    @property
+    def major(self):
+        # type: () -> int
+        return self.release[0] if len(self.release) >= 1 else 0
+
+    @property
+    def minor(self):
+        # type: () -> int
+        return self.release[1] if len(self.release) >= 2 else 0
+
+    @property
+    def micro(self):
+        # type: () -> int
+        return self.release[2] if len(self.release) >= 3 else 0
+
+
+def _parse_letter_version(
+    letter,  # type: str
+    number,  # type: Union[str, bytes, SupportsInt]
+):
+    # type: (...) -> Optional[Tuple[str, int]]
 
-def _parse_letter_version(letter, number):
     if letter:
         # We consider there to be an implicit 0 in a pre-release if there is
         # not a numeral associated with it.
@@ -360,11 +452,14 @@ def _parse_letter_version(letter, number):
 
         return letter, int(number)
 
+    return None
+
 
 _local_version_separators = re.compile(r"[\._-]")
 
 
 def _parse_local_version(local):
+    # type: (str) -> Optional[LocalType]
     """
     Takes a string like abc.1.twelve and turns it into ("abc", 1, "twelve").
     """
@@ -373,15 +468,25 @@ def _parse_local_version(local):
             part.lower() if not part.isdigit() else int(part)
             for part in _local_version_separators.split(local)
         )
+    return None
+
 
+def _cmpkey(
+    epoch,  # type: int
+    release,  # type: Tuple[int, ...]
+    pre,  # type: Optional[Tuple[str, int]]
+    post,  # type: Optional[Tuple[str, int]]
+    dev,  # type: Optional[Tuple[str, int]]
+    local,  # type: Optional[Tuple[SubLocalType]]
+):
+    # type: (...) -> CmpKey
 
-def _cmpkey(epoch, release, pre, post, dev, local):
     # When we compare a release version, we want to compare it with all of the
     # trailing zeros removed. So we'll use a reverse the list, drop all the now
     # leading zeros until we come to something non zero, then take the rest
     # re-reverse it back into the correct order and make it a tuple and use
     # that for our sorting key.
-    release = tuple(
+    _release = tuple(
         reversed(list(itertools.dropwhile(lambda x: x == 0, reversed(release))))
     )
 
@@ -390,23 +495,31 @@ def _cmpkey(epoch, release, pre, post, dev, local):
     # if there is not a pre or a post segment. If we have one of those then
     # the normal sorting rules will handle this case correctly.
     if pre is None and post is None and dev is not None:
-        pre = -Infinity
+        _pre = NegativeInfinity  # type: PrePostDevType
     # Versions without a pre-release (except as noted above) should sort after
     # those with one.
     elif pre is None:
-        pre = Infinity
+        _pre = Infinity
+    else:
+        _pre = pre
 
     # Versions without a post segment should sort before those with one.
     if post is None:
-        post = -Infinity
+        _post = NegativeInfinity  # type: PrePostDevType
+
+    else:
+        _post = post
 
     # Versions without a development segment should sort after those with one.
     if dev is None:
-        dev = Infinity
+        _dev = Infinity  # type: PrePostDevType
+
+    else:
+        _dev = dev
 
     if local is None:
         # Versions without a local segment should sort before those with one.
-        local = -Infinity
+        _local = NegativeInfinity  # type: LocalType
     else:
         # Versions with a local segment need that segment parsed to implement
         # the sorting rules in PEP440.
@@ -415,6 +528,8 @@ def _cmpkey(epoch, release, pre, post, dev, local):
         # - Numeric segments sort numerically
         # - Shorter versions sort before longer versions when the prefixes
         #   match exactly
-        local = tuple((i, "") if isinstance(i, int) else (-Infinity, i) for i in local)
+        _local = tuple(
+            (i, "") if isinstance(i, int) else (NegativeInfinity, i) for i in local
+        )
 
-    return epoch, release, pre, post, dev, local
+    return epoch, _release, _pre, _post, _dev, _local
diff --git a/pipenv/vendor/parse.py b/pipenv/vendor/parse.py
index 1a5f9e63..9c8cae70 100644
--- a/pipenv/vendor/parse.py
+++ b/pipenv/vendor/parse.py
@@ -346,6 +346,9 @@ the pattern, the actual match represents the shortest successful match for
 
 **Version history (in brief)**:
 
+- 1.15.0 Several fixes for parsing non-base 10 numbers (thanks @vladikcomper)
+- 1.14.0 More broad acceptance of Fortran number format (thanks @purpleskyfall)
+- 1.13.1 Project metadata correction.
 - 1.13.0 Handle Fortran formatted numbers with no leading 0 before decimal
   point (thanks @purpleskyfall).
   Handle comparison of FixedTzOffset with other types of object.
@@ -421,7 +424,7 @@ See the end of the source file for the license of use.
 '''
 
 from __future__ import absolute_import
-__version__ = '1.13.0'
+__version__ = '1.15.0'
 
 # yes, I now have two problems
 import re
@@ -465,15 +468,16 @@ def with_pattern(pattern, regex_group_count=None):
     return decorator
 
 
-def int_convert(base):
+def int_convert(base=None):
     '''Convert a string to an integer.
 
     The string may start with a sign.
 
-    It may be of a base other than 10.
+    It may be of a base other than 2, 8, 10 or 16.
 
-    If may start with a base indicator, 0#nnnn, which we assume should
-    override the specified base.
+    If base isn't specified, it will be detected automatically based
+    on a string format. When string starts with a base indicator, 0#nnnn, 
+    it overrides the default base of 10.
 
     It may also have other non-numeric characters that we can ignore.
     '''
@@ -482,19 +486,28 @@ def int_convert(base):
     def f(string, match, base=base):
         if string[0] == '-':
             sign = -1
+            number_start = 1
+        elif string[0] == '+':
+            sign = 1
+            number_start = 1
         else:
             sign = 1
+            number_start = 0
 
-        if string[0] == '0' and len(string) > 2:
-            if string[1] in 'bB':
-                base = 2
-            elif string[1] in 'oO':
-                base = 8
-            elif string[1] in 'xX':
-                base = 16
-            else:
-                # just go with the base specifed
-                pass
+        # If base wasn't specified, detect it automatically
+        if base is None:
+
+          # Assume decimal number, unless different base is detected
+          base = 10
+
+          # For number formats starting with 0b, 0o, 0x, use corresponding base ...
+          if string[number_start] == '0' and len(string) - number_start > 2:
+              if string[number_start+1] in 'bB':
+                  base = 2
+              elif string[number_start+1] in 'oO':
+                  base = 8
+              elif string[number_start+1] in 'xX':
+                  base = 16
 
         chars = CHARS[:base]
         string = re.sub('[^%s]' % chars, '', string.lower())
@@ -965,7 +978,7 @@ class Parser(object):
 
         # figure type conversions, if any
         type = format['type']
-        is_numeric = type and type in 'n%fegdobh'
+        is_numeric = type and type in 'n%fegdobx'
         if type in self._extra_types:
             type_converter = self._extra_types[type]
             s = getattr(type_converter, 'pattern', r'.+?')
@@ -998,10 +1011,10 @@ class Parser(object):
             self._group_index += 1
             self._type_conversions[group] = percentage
         elif type == 'f':
-            s = r'\d+\.\d+'
+            s = r'\d*\.\d+'
             self._type_conversions[group] = lambda s, m: float(s)
         elif type == 'F':
-            s = r'\d+\.\d+'
+            s = r'\d*\.\d+'
             self._type_conversions[group] = lambda s, m: Decimal(s)
         elif type == 'e':
             s = r'\d*\.\d+[eE][-+]?\d+|nan|NAN|[-+]?inf|[-+]?INF'
@@ -1015,8 +1028,8 @@ class Parser(object):
                 width = r'{1,%s}' % int(format['width'])
             else:
                 width = '+'
-            s = r'\d{w}|0[xX][0-9a-fA-F]{w}|0[bB][01]{w}|0[oO][0-7]{w}'.format(w=width)
-            self._type_conversions[group] = int_convert(10)
+            s = r'\d{w}|[-+ ]?0[xX][0-9a-fA-F]{w}|[-+ ]?0[bB][01]{w}|[-+ ]?0[oO][0-7]{w}'.format(w=width)
+            self._type_conversions[group] = int_convert() # do not specify numeber base, determine it automatically
         elif type == 'ti':
             s = r'(\d{4}-\d\d-\d\d)((\s+|T)%s)?(Z|\s*[-+]\d\d:?\d\d)?' % \
                 TIME_PAT
@@ -1320,7 +1333,7 @@ def compile(format, extra_types=None, case_sensitive=False):
     return Parser(format, extra_types=extra_types, case_sensitive=case_sensitive)
 
 
-# Copyright (c) 2012-2019 Richard Jones <richard@python.org>
+# Copyright (c) 2012-2020 Richard Jones <richard@python.org>
 #
 # Permission is hereby granted, free of charge, to any person obtaining a copy
 # of this software and associated documentation files (the "Software"), to deal
diff --git a/pipenv/vendor/pexpect/__init__.py b/pipenv/vendor/pexpect/__init__.py
index cf7a70d0..7e304537 100644
--- a/pipenv/vendor/pexpect/__init__.py
+++ b/pipenv/vendor/pexpect/__init__.py
@@ -75,7 +75,7 @@ if sys.platform != 'win32':
     from .pty_spawn import spawn, spawnu
     from .run import run, runu
 
-__version__ = '4.7.0'
+__version__ = '4.8.0'
 __revision__ = ''
 __all__ = ['ExceptionPexpect', 'EOF', 'TIMEOUT', 'spawn', 'spawnu', 'run', 'runu',
            'which', 'split_command_line', '__version__', '__revision__']
diff --git a/pipenv/vendor/pexpect/_async.py b/pipenv/vendor/pexpect/_async.py
index ca2044e1..dfbfeef5 100644
--- a/pipenv/vendor/pexpect/_async.py
+++ b/pipenv/vendor/pexpect/_async.py
@@ -8,10 +8,7 @@ from pexpect import EOF
 def expect_async(expecter, timeout=None):
     # First process data that was previously read - if it maches, we don't need
     # async stuff.
-    previously_read = expecter.spawn.buffer
-    expecter.spawn._buffer = expecter.spawn.buffer_type()
-    expecter.spawn._before = expecter.spawn.buffer_type()
-    idx = expecter.new_data(previously_read)
+    idx = expecter.existing_data()
     if idx is not None:
         return idx
     if not expecter.spawn.async_pw_transport:
@@ -74,6 +71,7 @@ class PatternWaiter(asyncio.Protocol):
         spawn._log(s, 'read')
 
         if self.fut.done():
+            spawn._before.write(s)
             spawn._buffer.write(s)
             return
 
diff --git a/pipenv/vendor/pexpect/expect.py b/pipenv/vendor/pexpect/expect.py
index db376d59..d3409db9 100644
--- a/pipenv/vendor/pexpect/expect.py
+++ b/pipenv/vendor/pexpect/expect.py
@@ -6,45 +6,101 @@ class Expecter(object):
     def __init__(self, spawn, searcher, searchwindowsize=-1):
         self.spawn = spawn
         self.searcher = searcher
+        # A value of -1 means to use the figure from spawn, which should
+        # be None or a positive number.
         if searchwindowsize == -1:
             searchwindowsize = spawn.searchwindowsize
         self.searchwindowsize = searchwindowsize
+        self.lookback = None
+        if hasattr(searcher, 'longest_string'):
+            self.lookback = searcher.longest_string
 
-    def new_data(self, data):
+    def do_search(self, window, freshlen):
         spawn = self.spawn
         searcher = self.searcher
-
-        pos = spawn._buffer.tell()
-        spawn._buffer.write(data)
-        spawn._before.write(data)
-
-        # determine which chunk of data to search; if a windowsize is
-        # specified, this is the *new* data + the preceding <windowsize> bytes
-        if self.searchwindowsize:
-            spawn._buffer.seek(max(0, pos - self.searchwindowsize))
-            window = spawn._buffer.read(self.searchwindowsize + len(data))
-        else:
-            # otherwise, search the whole buffer (really slow for large datasets)
-            window = spawn.buffer
-        index = searcher.search(window, len(data))
+        if freshlen > len(window):
+            freshlen = len(window)
+        index = searcher.search(window, freshlen, self.searchwindowsize)
         if index >= 0:
             spawn._buffer = spawn.buffer_type()
             spawn._buffer.write(window[searcher.end:])
-            spawn.before = spawn._before.getvalue()[0:-(len(window) - searcher.start)]
+            spawn.before = spawn._before.getvalue()[
+                0:-(len(window) - searcher.start)]
             spawn._before = spawn.buffer_type()
-            spawn.after = window[searcher.start: searcher.end]
+            spawn._before.write(window[searcher.end:])
+            spawn.after = window[searcher.start:searcher.end]
             spawn.match = searcher.match
             spawn.match_index = index
             # Found a match
             return index
-        elif self.searchwindowsize:
-            spawn._buffer = spawn.buffer_type()
-            spawn._buffer.write(window)
+        elif self.searchwindowsize or self.lookback:
+            maintain = self.searchwindowsize or self.lookback
+            if spawn._buffer.tell() > maintain:
+                spawn._buffer = spawn.buffer_type()
+                spawn._buffer.write(window[-maintain:])
+
+    def existing_data(self):
+        # First call from a new call to expect_loop or expect_async.
+        # self.searchwindowsize may have changed.
+        # Treat all data as fresh.
+        spawn = self.spawn
+        before_len = spawn._before.tell()
+        buf_len = spawn._buffer.tell()
+        freshlen = before_len
+        if before_len > buf_len:
+            if not self.searchwindowsize:
+                spawn._buffer = spawn.buffer_type()
+                window = spawn._before.getvalue()
+                spawn._buffer.write(window)
+            elif buf_len < self.searchwindowsize:
+                spawn._buffer = spawn.buffer_type()
+                spawn._before.seek(
+                    max(0, before_len - self.searchwindowsize))
+                window = spawn._before.read()
+                spawn._buffer.write(window)
+            else:
+                spawn._buffer.seek(max(0, buf_len - self.searchwindowsize))
+                window = spawn._buffer.read()
+        else:
+            if self.searchwindowsize:
+                spawn._buffer.seek(max(0, buf_len - self.searchwindowsize))
+                window = spawn._buffer.read()
+            else:
+                window = spawn._buffer.getvalue()
+        return self.do_search(window, freshlen)
+
+    def new_data(self, data):
+        # A subsequent call, after a call to existing_data.
+        spawn = self.spawn
+        freshlen = len(data)
+        spawn._before.write(data)
+        if not self.searchwindowsize:
+            if self.lookback:
+                # search lookback + new data.
+                old_len = spawn._buffer.tell()
+                spawn._buffer.write(data)
+                spawn._buffer.seek(max(0, old_len - self.lookback))
+                window = spawn._buffer.read()
+            else:
+                # copy the whole buffer (really slow for large datasets).
+                spawn._buffer.write(data)
+                window = spawn.buffer
+        else:
+            if len(data) >= self.searchwindowsize or not spawn._buffer.tell():
+                window = data[-self.searchwindowsize:]
+                spawn._buffer = spawn.buffer_type()
+                spawn._buffer.write(window[-self.searchwindowsize:])
+            else:
+                spawn._buffer.write(data)
+                new_len = spawn._buffer.tell()
+                spawn._buffer.seek(max(0, new_len - self.searchwindowsize))
+                window = spawn._buffer.read()
+        return self.do_search(window, freshlen)
 
     def eof(self, err=None):
         spawn = self.spawn
 
-        spawn.before = spawn.buffer
+        spawn.before = spawn._before.getvalue()
         spawn._buffer = spawn.buffer_type()
         spawn._before = spawn.buffer_type()
         spawn.after = EOF
@@ -60,12 +116,15 @@ class Expecter(object):
             msg += '\nsearcher: %s' % self.searcher
             if err is not None:
                 msg = str(err) + '\n' + msg
-            raise EOF(msg)
-    
+
+            exc = EOF(msg)
+            exc.__cause__ = None # in Python 3.x we can use "raise exc from None"
+            raise exc
+
     def timeout(self, err=None):
         spawn = self.spawn
 
-        spawn.before = spawn.buffer
+        spawn.before = spawn._before.getvalue()
         spawn.after = TIMEOUT
         index = self.searcher.timeout_index
         if index >= 0:
@@ -79,15 +138,18 @@ class Expecter(object):
             msg += '\nsearcher: %s' % self.searcher
             if err is not None:
                 msg = str(err) + '\n' + msg
-            raise TIMEOUT(msg)
+
+            exc = TIMEOUT(msg)
+            exc.__cause__ = None    # in Python 3.x we can use "raise exc from None"
+            raise exc
 
     def errored(self):
         spawn = self.spawn
-        spawn.before = spawn.buffer
+        spawn.before = spawn._before.getvalue()
         spawn.after = None
         spawn.match = None
         spawn.match_index = None
-    
+
     def expect_loop(self, timeout=-1):
         """Blocking expect"""
         spawn = self.spawn
@@ -96,14 +158,10 @@ class Expecter(object):
             end_time = time.time() + timeout
 
         try:
-            incoming = spawn.buffer
-            spawn._buffer = spawn.buffer_type()
-            spawn._before = spawn.buffer_type()
+            idx = self.existing_data()
+            if idx is not None:
+                return idx
             while True:
-                idx = self.new_data(incoming)
-                # Keep reading until exception or return.
-                if idx is not None:
-                    return idx
                 # No match at this point
                 if (timeout is not None) and (timeout < 0):
                     return self.timeout()
@@ -111,6 +169,10 @@ class Expecter(object):
                 incoming = spawn.read_nonblocking(spawn.maxread, timeout)
                 if self.spawn.delayafterread is not None:
                     time.sleep(self.spawn.delayafterread)
+                idx = self.new_data(incoming)
+                # Keep reading until exception or return.
+                if idx is not None:
+                    return idx
                 if timeout is not None:
                     timeout = end_time - time.time()
         except EOF as e:
@@ -148,6 +210,7 @@ class searcher_string(object):
         self.eof_index = -1
         self.timeout_index = -1
         self._strings = []
+        self.longest_string = 0
         for n, s in enumerate(strings):
             if s is EOF:
                 self.eof_index = n
@@ -156,6 +219,8 @@ class searcher_string(object):
                 self.timeout_index = n
                 continue
             self._strings.append((n, s))
+            if len(s) > self.longest_string:
+                self.longest_string = len(s)
 
     def __str__(self):
         '''This returns a human-readable string that represents the state of
diff --git a/pipenv/vendor/pexpect/pty_spawn.py b/pipenv/vendor/pexpect/pty_spawn.py
index 691c2c63..8e28ca7c 100644
--- a/pipenv/vendor/pexpect/pty_spawn.py
+++ b/pipenv/vendor/pexpect/pty_spawn.py
@@ -191,6 +191,7 @@ class spawn(SpawnBase):
         self.STDIN_FILENO = pty.STDIN_FILENO
         self.STDOUT_FILENO = pty.STDOUT_FILENO
         self.STDERR_FILENO = pty.STDERR_FILENO
+        self.str_last_chars = 100
         self.cwd = cwd
         self.env = env
         self.echo = echo
@@ -212,8 +213,8 @@ class spawn(SpawnBase):
         s.append(repr(self))
         s.append('command: ' + str(self.command))
         s.append('args: %r' % (self.args,))
-        s.append('buffer (last 100 chars): %r' % self.buffer[-100:])
-        s.append('before (last 100 chars): %r' % self.before[-100:] if self.before else '')
+        s.append('buffer (last %s chars): %r' % (self.str_last_chars,self.buffer[-self.str_last_chars:]))
+        s.append('before (last %s chars): %r' % (self.str_last_chars,self.before[-self.str_last_chars:] if self.before else ''))
         s.append('after: %r' % (self.after,))
         s.append('match: %r' % (self.match,))
         s.append('match_index: ' + str(self.match_index))
@@ -752,10 +753,14 @@ class spawn(SpawnBase):
         child process in interact mode is duplicated to the given log.
 
         You may pass in optional input and output filter functions. These
-        functions should take a string and return a string. The output_filter
-        will be passed all the output from the child process. The input_filter
-        will be passed all the keyboard input from the user. The input_filter
-        is run BEFORE the check for the escape_character.
+        functions should take bytes array and return bytes array too. Even
+        with ``encoding='utf-8'`` support, meth:`interact` will always pass
+        input_filter and output_filter bytes. You may need to wrap your
+        function to decode and encode back to UTF-8.
+
+        The output_filter will be passed all the output from the child process.
+        The input_filter will be passed all the keyboard input from the user.
+        The input_filter is run BEFORE the check for the escape_character.
 
         Note that if you change the window size of the parent the SIGWINCH
         signal will not be passed through to the child. If you want the child
diff --git a/pipenv/vendor/pexpect/run.py b/pipenv/vendor/pexpect/run.py
index d9dfe76b..ff288a12 100644
--- a/pipenv/vendor/pexpect/run.py
+++ b/pipenv/vendor/pexpect/run.py
@@ -67,7 +67,7 @@ def run(command, timeout=30, withexitstatus=False, events=None,
     contains patterns and responses. Whenever one of the patterns is seen
     in the command output, run() will send the associated response string.
     So, run() in the above example can be also written as:
-    
+
         run("mencoder dvd://1 -o video.avi -oac copy -ovc copy",
             events=[(TIMEOUT,print_ticks)], timeout=5)
 
diff --git a/pipenv/vendor/pexpect/screen.py b/pipenv/vendor/pexpect/screen.py
index 5ab45b94..79f95c4e 100644
--- a/pipenv/vendor/pexpect/screen.py
+++ b/pipenv/vendor/pexpect/screen.py
@@ -90,7 +90,7 @@ class screen:
         self.encoding = encoding
         self.encoding_errors = encoding_errors
         if encoding is not None:
-            self.decoder = codecs.getincrementaldecoder(encoding)(encoding_errors)            
+            self.decoder = codecs.getincrementaldecoder(encoding)(encoding_errors)
         else:
             self.decoder = None
         self.cur_r = 1
diff --git a/pipenv/vendor/pexpect/spawnbase.py b/pipenv/vendor/pexpect/spawnbase.py
index 63c0b420..59e90576 100644
--- a/pipenv/vendor/pexpect/spawnbase.py
+++ b/pipenv/vendor/pexpect/spawnbase.py
@@ -120,6 +120,9 @@ class SpawnBase(object):
         self.async_pw_transport = None
         # This is the read buffer. See maxread.
         self._buffer = self.buffer_type()
+        # The buffer may be trimmed for efficiency reasons.  This is the
+        # untrimmed buffer, used to create the before attribute.
+        self._before = self.buffer_type()
 
     def _log(self, s, direction):
         if self.logfile is not None:
diff --git a/pipenv/vendor/pip_shims/backports.py b/pipenv/vendor/pip_shims/backports.py
deleted file mode 100644
index 9206cbe0..00000000
--- a/pipenv/vendor/pip_shims/backports.py
+++ /dev/null
@@ -1,1183 +0,0 @@
-# -*- coding=utf-8 -*-
-from __future__ import absolute_import
-
-import atexit
-import contextlib
-import functools
-import inspect
-import os
-import sys
-import types
-
-import six
-from packaging import specifiers
-from vistir.compat import TemporaryDirectory
-
-from .environment import MYPY_RUNNING
-from .utils import (
-    call_function_with_correct_args,
-    get_method_args,
-    nullcontext,
-    suppress_setattr,
-)
-
-if six.PY3:
-    from contextlib import ExitStack
-else:
-    from contextlib2 import ExitStack
-
-
-if MYPY_RUNNING:
-    from optparse import Values
-    from requests import Session
-    from typing import (
-        Any,
-        Callable,
-        Dict,
-        Generator,
-        Generic,
-        Iterator,
-        List,
-        Optional,
-        Tuple,
-        Type,
-        TypeVar,
-        Union,
-    )
-    from .utils import TShimmedPath, TShim, TShimmedFunc
-
-    TFinder = TypeVar("TFinder")
-    TResolver = TypeVar("TResolver")
-    TReqTracker = TypeVar("TReqTracker")
-    TLink = TypeVar("TLink")
-    TSession = TypeVar("TSession", bound=Session)
-    TCommand = TypeVar("TCommand", covariant=True)
-    TCommandInstance = TypeVar("TCommandInstance")
-    TCmdDict = Dict[str, Union[Tuple[str, str, str], TCommandInstance]]
-    TInstallRequirement = TypeVar("TInstallRequirement")
-    TShimmedCmdDict = Union[TShim, TCmdDict]
-    TWheelCache = TypeVar("TWheelCache")
-    TPreparer = TypeVar("TPreparer")
-
-
-class SearchScope(object):
-    def __init__(self, find_links=None, index_urls=None):
-        self.index_urls = index_urls if index_urls else []
-        self.find_links = find_links
-
-    @classmethod
-    def create(cls, find_links=None, index_urls=None):
-        if not index_urls:
-            index_urls = ["https://pypi.org/simple"]
-        return cls(find_links=find_links, index_urls=index_urls)
-
-
-class SelectionPreferences(object):
-    def __init__(
-        self,
-        allow_yanked=True,
-        allow_all_prereleases=False,
-        format_control=None,
-        prefer_binary=False,
-        ignore_requires_python=False,
-    ):
-        self.allow_yanked = allow_yanked
-        self.allow_all_prereleases = allow_all_prereleases
-        self.format_control = format_control
-        self.prefer_binary = prefer_binary
-        self.ignore_requires_python = ignore_requires_python
-
-
-class TargetPython(object):
-    fallback_get_tags = None  # type: Optional[TShimmedFunc]
-
-    def __init__(
-        self,
-        platform=None,  # type: Optional[str]
-        py_version_info=None,  # type: Optional[Tuple[int, ...]]
-        abi=None,  # type: Optional[str]
-        implementation=None,  # type: Optional[str]
-    ):
-        # type: (...) -> None
-        self._given_py_version_info = py_version_info
-        if py_version_info is None:
-            py_version_info = sys.version_info[:3]
-        elif len(py_version_info) < 3:
-            py_version_info += (3 - len(py_version_info)) * (0,)
-        else:
-            py_version_info = py_version_info[:3]
-        py_version = ".".join(map(str, py_version_info[:2]))
-        self.abi = abi
-        self.implementation = implementation
-        self.platform = platform
-        self.py_version = py_version
-        self.py_version_info = py_version_info
-        self._valid_tags = None
-
-    def get_tags(self):
-        if self._valid_tags is None and self.fallback_get_tags:
-            fallback_func = resolve_possible_shim(self.fallback_get_tags)
-            versions = None
-            if self._given_py_version_info:
-                versions = ["".join(map(str, self._given_py_version_info[:2]))]
-            self._valid_tags = fallback_func(
-                versions=versions,
-                platform=self.platform,
-                abi=self.abi,
-                impl=self.implementation,
-            )
-        return self._valid_tags
-
-
-class CandidatePreferences(object):
-    def __init__(self, prefer_binary=False, allow_all_prereleases=False):
-        self.prefer_binary = prefer_binary
-        self.allow_all_prereleases = allow_all_prereleases
-
-
-class LinkCollector(object):
-    def __init__(self, session=None, search_scope=None):
-        self.session = session
-        self.search_scope = search_scope
-
-
-class CandidateEvaluator(object):
-    @classmethod
-    def create(
-        cls,
-        project_name,  # type: str
-        target_python=None,  # type: Optional[TargetPython]
-        prefer_binary=False,  # type: bool
-        allow_all_prereleases=False,  # type: bool
-        specifier=None,  # type: Optional[specifiers.BaseSpecifier]
-        hashes=None,  # type: Optional[Any]
-    ):
-        if target_python is None:
-            target_python = TargetPython()
-        if specifier is None:
-            specifier = specifiers.SpecifierSet()
-
-        supported_tags = target_python.get_tags()
-
-        return cls(
-            project_name=project_name,
-            supported_tags=supported_tags,
-            specifier=specifier,
-            prefer_binary=prefer_binary,
-            allow_all_prereleases=allow_all_prereleases,
-            hashes=hashes,
-        )
-
-    def __init__(
-        self,
-        project_name,  # type: str
-        supported_tags,  # type: List[Any]
-        specifier,  # type: specifiers.BaseSpecifier
-        prefer_binary=False,  # type: bool
-        allow_all_prereleases=False,  # type: bool
-        hashes=None,  # type: Optional[Any]
-    ):
-        self._allow_all_prereleases = allow_all_prereleases
-        self._hashes = hashes
-        self._prefer_binary = prefer_binary
-        self._project_name = project_name
-        self._specifier = specifier
-        self._supported_tags = supported_tags
-
-
-class LinkEvaluator(object):
-    def __init__(
-        self,
-        allow_yanked,
-        project_name,
-        canonical_name,
-        formats,
-        target_python,
-        ignore_requires_python=False,
-        ignore_compatibility=True,
-    ):
-        self._allow_yanked = allow_yanked
-        self._canonical_name = canonical_name
-        self._ignore_requires_python = ignore_requires_python
-        self._formats = formats
-        self._target_python = target_python
-        self._ignore_compatibility = ignore_compatibility
-
-        self.project_name = project_name
-
-
-def resolve_possible_shim(target):
-    # type: (TShimmedFunc) -> Optional[Union[Type, Callable]]
-    if target is None:
-        return target
-    if getattr(target, "shim", None) and isinstance(
-        target.shim, (types.MethodType, types.FunctionType)
-    ):
-        return target.shim()
-    return target
-
-
-@contextlib.contextmanager
-def temp_environ():
-    """Allow the ability to set os.environ temporarily"""
-    environ = dict(os.environ)
-    try:
-        yield
-    finally:
-        os.environ.clear()
-        os.environ.update(environ)
-
-
-@contextlib.contextmanager
-def get_requirement_tracker(req_tracker_creator=None):
-    # type: (Optional[Callable]) -> Generator[Optional[TReqTracker], None, None]
-    root = os.environ.get("PIP_REQ_TRACKER")
-    if not req_tracker_creator:
-        yield None
-    else:
-        req_tracker_args = []
-        _, required_args = get_method_args(req_tracker_creator.__init__)  # type: ignore
-        with ExitStack() as ctx:
-            if root is None:
-                root = ctx.enter_context(TemporaryDirectory(prefix="req-tracker")).name
-                if root:
-                    root = str(root)
-                    ctx.enter_context(temp_environ())
-                    os.environ["PIP_REQ_TRACKER"] = root
-            if required_args is not None and "root" in required_args:
-                req_tracker_args.append(root)
-            with req_tracker_creator(*req_tracker_args) as tracker:
-                yield tracker
-
-
-@contextlib.contextmanager
-def ensure_resolution_dirs(**kwargs):
-    # type: (Any) -> Iterator[Dict[str, Any]]
-    """
-    Ensures that the proper directories are scaffolded and present in the provided kwargs
-    for performing dependency resolution via pip.
-
-    :return: A new kwargs dictionary with scaffolded directories for **build_dir**, **src_dir**,
-        **download_dir**, and **wheel_download_dir** added to the key value pairs.
-    :rtype: Dict[str, Any]
-    """
-    keys = ("build_dir", "src_dir", "download_dir", "wheel_download_dir")
-    if not any(kwargs.get(key) is None for key in keys):
-        yield kwargs
-    else:
-        with TemporaryDirectory(prefix="pip-shims-") as base_dir:
-            for key in keys:
-                if kwargs.get(key) is not None:
-                    continue
-                target = os.path.join(base_dir.name, key)
-                os.makedirs(target)
-                kwargs[key] = target
-            yield kwargs
-
-
-def partial_command(shimmed_path, cmd_mapping=None):
-    # type: (Type, Optional[TShimmedCmdDict]) -> Union[Type[TCommandInstance], functools.partial]
-    """
-    Maps a default set of arguments across all members of a
-    :class:`~pip_shims.models.ShimmedPath` instance, specifically for
-    :class:`~pip._internal.command.Command` instances which need
-    `summary` and `name` arguments.
-
-    :param :class:`~pip_shims.models.ShimmedPath` shimmed_path:  A
-        :class:`~pip_shims.models.ShimmedCollection` instance
-    :param Any cmd_mapping: A reference to use for mapping against, e.g. an
-        import that depends on pip also
-    :return: A dictionary mapping new arguments to their default values
-    :rtype: Dict[str, str]
-    """
-    basecls = shimmed_path.shim()
-    resolved_cmd_mapping = None  # type: Optional[Dict[str, Any]]
-    cmd_mapping = resolve_possible_shim(cmd_mapping)
-    if cmd_mapping is not None and isinstance(cmd_mapping, dict):
-        resolved_cmd_mapping = cmd_mapping.copy()
-    base_args = []  # type: List[str]
-    for root_cls in basecls.mro():
-        if root_cls.__name__ == "Command":
-            _, root_init_args = get_method_args(root_cls.__init__)
-            if root_init_args is not None:
-                base_args = root_init_args.args
-    needs_name_and_summary = any(arg in base_args for arg in ("name", "summary"))
-    if not needs_name_and_summary:
-        basecls.name = shimmed_path.name
-        return basecls
-    elif (
-        not resolved_cmd_mapping
-        and needs_name_and_summary
-        and getattr(functools, "partialmethod", None)
-    ):
-        new_init = functools.partial(
-            basecls.__init__, name=shimmed_path.name, summary="Summary"
-        )
-        basecls.__init__ = new_init
-    result = basecls
-    assert resolved_cmd_mapping is not None
-    for command_name, command_info in resolved_cmd_mapping.items():
-        if getattr(command_info, "class_name", None) == shimmed_path.name:
-            summary = getattr(command_info, "summary", "Command summary")
-            result = functools.partial(basecls, command_name, summary)
-            break
-    return result
-
-
-def get_session(
-    install_cmd_provider=None,  # type: Optional[TShimmedFunc]
-    install_cmd=None,  # type: TCommandInstance
-    options=None,  # type: Optional[Values]
-):
-    # type: (...) -> TSession
-    session = None  # type: Optional[TSession]
-    if install_cmd is None:
-        assert install_cmd_provider is not None
-        install_cmd_provider = resolve_possible_shim(install_cmd_provider)
-        assert isinstance(install_cmd_provider, (type, functools.partial))
-        install_cmd = install_cmd_provider()
-    if options is None:
-        options = install_cmd.parser.parse_args([])  # type: ignore
-    session = install_cmd._build_session(options)  # type: ignore
-    assert session is not None
-    atexit.register(session.close)
-    return session
-
-
-def populate_options(
-    install_command=None,  # type: TCommandInstance
-    options=None,  # type: Optional[Values]
-    **kwargs  # type: Any
-):
-    # (...) -> Tuple[Dict[str, Any], Values]
-    results = {}
-    if install_command is None and options is None:
-        raise TypeError("Must pass either options or InstallCommand to populate options")
-    if options is None and install_command is not None:
-        options, _ = install_command.parser.parse_args([])  # type: ignore
-    options_dict = options.__dict__
-    for provided_key, provided_value in kwargs.items():
-        if provided_key == "isolated":
-            options_key = "isolated_mode"
-        elif provided_key == "source_dir":
-            options_key = "src_dir"
-        else:
-            options_key = provided_key
-        if provided_key in options_dict and provided_value is not None:
-            setattr(options, options_key, provided_value)
-            results[provided_key] = provided_value
-        elif getattr(options, options_key, None) is not None:
-            results[provided_key] = getattr(options, options_key)
-        else:
-            results[provided_key] = provided_value
-    return results, options
-
-
-def get_requirement_set(
-    install_command=None,  # type: Optional[TCommandInstance]
-    req_set_provider=None,  # type: Optional[TShimmedFunc]
-    build_dir=None,  # type: Optional[str]
-    src_dir=None,  # type: Optional[str]
-    download_dir=None,  # type: Optional[str]
-    wheel_download_dir=None,  # type: Optional[str]
-    session=None,  # type: Optional[TSession]
-    wheel_cache=None,  # type: Optional[TWheelCache]
-    upgrade=False,  # type: bool
-    upgrade_strategy=None,  # type: Optional[str]
-    ignore_installed=False,  # type: bool
-    ignore_dependencies=False,  # type: bool
-    force_reinstall=False,  # type: bool
-    use_user_site=False,  # type: bool
-    isolated=False,  # type: bool
-    ignore_requires_python=False,  # type: bool
-    require_hashes=None,  # type: bool
-    cache_dir=None,  # type: Optional[str]
-    options=None,  # type: Optional[Values]
-    install_cmd_provider=None,  # type: Optional[TShimmedFunc]
-):
-    # (...) -> TRequirementSet
-    """
-    Creates a requirement set from the supplied parameters.
-
-    Not all parameters are passed through for all pip versions, but any
-    invalid parameters will be ignored if they are not needed to generate a
-    requirement set on the current pip version.
-
-    :param install_command: A :class:`~pip._internal.commands.install.InstallCommand`
-        instance which is used to generate the finder.
-    :param :class:`~pip_shims.models.ShimmedPathCollection` req_set_provider: A provider
-        to build requirement set instances.
-    :param str build_dir: The directory to build requirements in. Removed in pip 10,
-        defeaults to None
-    :param str source_dir: The directory to use for source requirements. Removed in
-        pip 10, defaults to None
-    :param str download_dir: The directory to download requirement artifacts to. Removed
-        in pip 10, defaults to None
-    :param str wheel_download_dir: The directory to download wheels to. Removed in pip
-        10, defaults ot None
-    :param :class:`~requests.Session` session: The pip session to use. Removed in pip 10,
-        defaults to None
-    :param WheelCache wheel_cache: The pip WheelCache instance to use for caching wheels.
-        Removed in pip 10, defaults to None
-    :param bool upgrade: Whether to try to upgrade existing requirements. Removed in pip
-        10, defaults to False.
-    :param str upgrade_strategy: The upgrade strategy to use, e.g. "only-if-needed".
-        Removed in pip 10, defaults to None.
-    :param bool ignore_installed: Whether to ignore installed packages when resolving.
-        Removed in pip 10, defaults to False.
-    :param bool ignore_dependencies: Whether to ignore dependencies of requirements
-        when resolving. Removed in pip 10, defaults to False.
-    :param bool force_reinstall: Whether to force reinstall of packages when resolving.
-        Removed in pip 10, defaults to False.
-    :param bool use_user_site: Whether to use user site packages when resolving. Removed
-        in pip 10, defaults to False.
-    :param bool isolated: Whether to resolve in isolation. Removed in pip 10, defaults
-        to False.
-    :param bool ignore_requires_python: Removed in pip 10, defaults to False.
-    :param bool require_hashes: Whether to require hashes when resolving. Defaults to
-        False.
-    :param Values options: An :class:`~optparse.Values` instance from an install cmd
-    :param install_cmd_provider: A shim for providing new install command instances.
-    :type install_cmd_provider: :class:`~pip_shims.models.ShimmedPathCollection`
-    :return: A new requirement set instance
-    :rtype: :class:`~pip._internal.req.req_set.RequirementSet`
-    """
-    req_set_provider = resolve_possible_shim(req_set_provider)
-    if install_command is None:
-        install_cmd_provider = resolve_possible_shim(install_cmd_provider)
-        assert isinstance(install_cmd_provider, (type, functools.partial))
-        install_command = install_cmd_provider()
-    required_args = inspect.getargs(
-        req_set_provider.__init__.__code__
-    ).args  # type: ignore
-    results, options = populate_options(
-        install_command,
-        options,
-        build_dir=build_dir,
-        src_dir=src_dir,
-        download_dir=download_dir,
-        upgrade=upgrade,
-        upgrade_strategy=upgrade_strategy,
-        ignore_installed=ignore_installed,
-        ignore_dependencies=ignore_dependencies,
-        force_reinstall=force_reinstall,
-        use_user_site=use_user_site,
-        isolated=isolated,
-        ignore_requires_python=ignore_requires_python,
-        require_hashes=require_hashes,
-        cache_dir=cache_dir,
-    )
-    if session is None and "session" in required_args:
-        session = get_session(install_cmd=install_command, options=options)
-    results["wheel_cache"] = wheel_cache
-    results["session"] = session
-    results["wheel_download_dir"] = wheel_download_dir
-    return call_function_with_correct_args(req_set_provider, **results)
-
-
-def get_package_finder(
-    install_cmd=None,  # type: Optional[TCommand]
-    options=None,  # type: Optional[Values]
-    session=None,  # type: Optional[TSession]
-    platform=None,  # type: Optional[str]
-    python_versions=None,  # type: Optional[Tuple[str, ...]]
-    abi=None,  # type: Optional[str]
-    implementation=None,  # type: Optional[str]
-    target_python=None,  # type: Optional[Any]
-    ignore_requires_python=None,  # type: Optional[bool]
-    target_python_builder=None,  # type: Optional[TShimmedFunc]
-    install_cmd_provider=None,  # type: Optional[TShimmedFunc]
-):
-    # type: (...) -> TFinder
-    """Shim for compatibility to generate package finders.
-
-    Build and return a :class:`~pip._internal.index.package_finder.PackageFinder`
-    instance using the :class:`~pip._internal.commands.install.InstallCommand` helper
-    method to construct the finder, shimmed with backports as needed for compatibility.
-
-    :param install_cmd_provider: A shim for providing new install command instances.
-    :type install_cmd_provider: :class:`~pip_shims.models.ShimmedPathCollection`
-    :param install_cmd: A :class:`~pip._internal.commands.install.InstallCommand`
-        instance which is used to generate the finder.
-    :param optparse.Values options: An optional :class:`optparse.Values` instance
-        generated by calling `install_cmd.parser.parse_args()` typically.
-    :param session: An optional session instance, can be created by the `install_cmd`.
-    :param Optional[str] platform: An optional platform string, e.g. linux_x86_64
-    :param Optional[Tuple[str, ...]] python_versions: A tuple of 2-digit strings
-        representing python versions, e.g. ("27", "35", "36", "37"...)
-    :param Optional[str] abi: The target abi to support, e.g. "cp38"
-    :param Optional[str] implementation: An optional implementation string for limiting
-        searches to a specific implementation, e.g. "cp" or "py"
-    :param target_python: A :class:`~pip._internal.models.target_python.TargetPython`
-        instance (will be translated to alternate arguments if necessary on incompatible
-        pip versions).
-    :param Optional[bool] ignore_requires_python: Whether to ignore `requires_python`
-        on resulting candidates, only valid after pip version 19.3.1
-    :param target_python_builder: A 'TargetPython' builder (e.g. the class itself,
-        uninstantiated)
-    :return: A :class:`pip._internal.index.package_finder.PackageFinder` instance
-    :rtype: :class:`pip._internal.index.package_finder.PackageFinder`
-
-    :Example:
-
-    >>> from pip_shims.shims import InstallCommand, get_package_finder
-    >>> install_cmd = InstallCommand()
-    >>> finder = get_package_finder(
-    ...     install_cmd, python_versions=("27", "35", "36", "37", "38"), implementation="
-    cp"
-    ... )
-    >>> candidates = finder.find_all_candidates("requests")
-    >>> requests_222 = next(iter(c for c in candidates if c.version.public == "2.22.0"))
-    >>> requests_222
-    <InstallationCandidate('requests', <Version('2.22.0')>, <Link https://files.pythonhos
-    ted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/r
-    equests-2.22.0-py2.py3-none-any.whl#sha256=9cf5292fcd0f598c671cfc1e0d7d1a7f13bb8085e9
-    a590f48c010551dc6c4b31 (from https://pypi.org/simple/requests/) (requires-python:>=2.
-    7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*)>)>
-    """
-    if install_cmd is None:
-        install_cmd_provider = resolve_possible_shim(install_cmd_provider)
-        assert isinstance(install_cmd_provider, (type, functools.partial))
-        install_cmd = install_cmd_provider()
-    if options is None:
-        options, _ = install_cmd.parser.parse_args([])  # type: ignore
-    if session is None:
-        session = get_session(install_cmd=install_cmd, options=options)  # type: ignore
-    builder_args = inspect.getargs(
-        install_cmd._build_package_finder.__code__
-    )  # type: ignore
-    build_kwargs = {"options": options, "session": session}
-    expects_targetpython = "target_python" in builder_args.args
-    received_python = any(arg for arg in [platform, python_versions, abi, implementation])
-    if expects_targetpython and received_python and not target_python:
-        if target_python_builder is None:
-            target_python_builder = TargetPython
-        py_version_info = None
-        if python_versions:
-            py_version_info_python = max(python_versions)
-            py_version_info = tuple([int(part) for part in py_version_info_python])
-        target_python = target_python_builder(
-            platform=platform,
-            abi=abi,
-            implementation=implementation,
-            py_version_info=py_version_info,
-        )
-        build_kwargs["target_python"] = target_python
-    elif any(
-        arg in builder_args.args
-        for arg in ["platform", "python_versions", "abi", "implementation"]
-    ):
-        if target_python and not received_python:
-            tags = target_python.get_tags()
-            version_impl = set([t[0] for t in tags])
-            # impls = set([v[:2] for v in version_impl])
-            # impls.remove("py")
-            # impl = next(iter(impls), "py") if not target_python
-            versions = set([v[2:] for v in version_impl])
-            build_kwargs.update(
-                {
-                    "platform": target_python.platform,
-                    "python_versions": versions,
-                    "abi": target_python.abi,
-                    "implementation": target_python.implementation,
-                }
-            )
-    if (
-        ignore_requires_python is not None
-        and "ignore_requires_python" in builder_args.args
-    ):
-        build_kwargs["ignore_requires_python"] = ignore_requires_python
-    return install_cmd._build_package_finder(**build_kwargs)  # type: ignore
-
-
-def shim_unpack(
-    unpack_fn,  # type: TShimmedFunc
-    download_dir,  # type str
-    ireq=None,  # type: Optional[Any]
-    link=None,  # type: Optional[Any]
-    location=None,  # type Optional[str],
-    hashes=None,  # type: Optional[Any]
-    progress_bar="off",  # type: str
-    only_download=None,  # type: Optional[bool]
-    session=None,  # type: Optional[Any]
-):
-    # (...) -> None
-    """
-    Accepts all parameters that have been valid to pass
-    to :func:`pip._internal.download.unpack_url` and selects or
-    drops parameters as needed before invoking the provided
-    callable.
-
-    :param unpack_fn: A callable or shim referring to the pip implementation
-    :type unpack_fn: Callable
-    :param str download_dir: The directory to download the file to
-    :param Optional[:class:`~pip._internal.req.req_install.InstallRequirement`] ireq:
-        an Install Requirement instance, defaults to None
-    :param Optional[:class:`~pip._internal.models.link.Link`] link: A Link instance,
-        defaults to None.
-    :param Optional[str] location: A location or source directory if the target is
-        a VCS url, defaults to None.
-    :param Optional[Any] hashes: A Hashes instance, defaults to None
-    :param str progress_bar: Indicates progress par usage during download, defatuls to
-        off.
-    :param Optional[bool] only_download: Whether to skip install, defaults to None.
-    :param Optional[`~requests.Session`] session: A PipSession instance, defaults to
-        None.
-    :return: The result of unpacking the url.
-    :rtype: None
-    """
-    unpack_fn = resolve_possible_shim(unpack_fn)
-    required_args = inspect.getargs(unpack_fn.__code__).args  # type: ignore
-    unpack_kwargs = {"download_dir": download_dir}
-    if ireq:
-        if not link and ireq.link:
-            link = ireq.link
-        if only_download is None:
-            only_download = ireq.is_wheel
-        if hashes is None:
-            hashes = ireq.hashes(True)
-        if location is None and getattr(ireq, "source_dir", None):
-            location = ireq.source_dir
-    unpack_kwargs.update({"link": link, "location": location})
-    if hashes is not None and "hashes" in required_args:
-        unpack_kwargs["hashes"] = hashes
-    if "progress_bar" in required_args:
-        unpack_kwargs["progress_bar"] = progress_bar
-    if only_download is not None and "only_download" in required_args:
-        unpack_kwargs["only_download"] = only_download
-    if session is not None and "session" in required_args:
-        unpack_kwargs["session"] = session
-    return unpack_fn(**unpack_kwargs)  # type: ignore
-
-
-@contextlib.contextmanager
-def make_preparer(
-    preparer_fn,  # type: TShimmedFunc
-    req_tracker_fn=None,  # type: Optional[TShimmedFunc]
-    build_dir=None,  # type: Optional[str]
-    src_dir=None,  # type: Optional[str]
-    download_dir=None,  # type: Optional[str]
-    wheel_download_dir=None,  # type: Optional[str]
-    progress_bar="off",  # type: str
-    build_isolation=False,  # type: bool
-    session=None,  # type: Optional[TSession]
-    finder=None,  # type: Optional[TFinder]
-    options=None,  # type: Optional[Values]
-    require_hashes=None,  # type: Optional[bool]
-    use_user_site=None,  # type: Optional[bool]
-    req_tracker=None,  # type: Optional[Union[TReqTracker, TShimmedFunc]]
-    install_cmd_provider=None,  # type: Optional[TShimmedFunc]
-    install_cmd=None,  # type: Optional[TCommandInstance]
-):
-    # (...) -> ContextManager
-    """
-    Creates a requirement preparer for preparing pip requirements.
-
-    Provides a compatibilty shim that accepts all previously valid arguments and
-    discards any that are no longer used.
-
-    :raises TypeError: No requirement tracker provided and one cannot be generated
-    :raises TypeError: No valid sessions provided and one cannot be generated
-    :raises TypeError: No valid finders provided and one cannot be generated
-    :param TShimmedFunc preparer_fn: Callable or shim for generating preparers.
-    :param Optional[TShimmedFunc] req_tracker_fn: Callable or shim for generating
-        requirement trackers, defualts to None
-    :param Optional[str] build_dir: Directory for building packages and wheels,
-        defaults to None
-    :param Optional[str] src_dir: Directory to find or extract source files, defaults
-        to None
-    :param Optional[str] download_dir: Target directory to download files, defaults to
-        None
-    :param Optional[str] wheel_download_dir: Target directoryto download wheels, defaults
-        to None
-    :param str progress_bar: Whether to display a progress bar, defaults to off
-    :param bool build_isolation: Whether to build requirements in isolation, defaults
-        to False
-    :param Optional[TSession] session: Existing session to use for getting requirements,
-        defaults to None
-    :param Optional[TFinder] finder: The package finder to use during resolution,
-        defaults to None
-    :param Optional[Values] options: Pip options to use if needed, defaults to None
-    :param Optional[bool] require_hashes: Whether to require hashes for preparation
-    :param Optional[bool] use_user_site: Whether to use the user site directory for
-        preparing requirements
-    :param Optional[Union[TReqTracker, TShimmedFunc]] req_tracker: The requirement
-        tracker to use for building packages, defaults to None
-    :param Optional[TCommandInstance] install_cmd: The install command used to create
-        the finder, session, and options if needed, defaults to None
-    :yield: A new requirement preparer instance
-    :rtype: ContextManager[:class:`~pip._internal.operations.prepare.RequirementPreparer`]
-
-    :Example:
-
-    >>> from pip_shims.shims import (
-    ...     InstallCommand, get_package_finder, make_preparer, get_requirement_tracker
-    ... )
-    >>> install_cmd = InstallCommand()
-    >>> pip_options, _ = install_cmd.parser.parse_args([])
-    >>> session = install_cmd._build_session(pip_options)
-    >>> finder = get_package_finder(
-    ...     install_cmd, session=session, options=pip_options
-    ... )
-    >>> with make_preparer(
-    ...     options=pip_options, finder=finder, session=session, install_cmd=ic
-    ... ) as preparer:
-    ...     print(preparer)
-    <pip._internal.operations.prepare.RequirementPreparer object at 0x7f8a2734be80>
-    """
-    preparer_fn = resolve_possible_shim(preparer_fn)
-    required_args = inspect.getargs(preparer_fn.__init__.__code__).args  # type: ignore
-    if not req_tracker and not req_tracker_fn and "req_tracker" in required_args:
-        raise TypeError("No requirement tracker and no req tracker generator found!")
-    req_tracker_fn = resolve_possible_shim(req_tracker_fn)
-    pip_options_created = options is None
-    session_is_required = "session" in required_args
-    finder_is_required = "finder" in required_args
-    options_map = {
-        "src_dir": src_dir,
-        "download_dir": download_dir,
-        "wheel_download_dir": wheel_download_dir,
-        "build_dir": build_dir,
-        "progress_bar": progress_bar,
-        "build_isolation": build_isolation,
-        "require_hashes": require_hashes,
-        "use_user_site": use_user_site,
-    }
-    if install_cmd is None:
-        assert install_cmd_provider is not None
-        install_cmd_provider = resolve_possible_shim(install_cmd_provider)
-        assert isinstance(install_cmd_provider, (type, functools.partial))
-        install_cmd = install_cmd_provider()
-    preparer_args, options = populate_options(install_cmd, options, **options_map)
-    if options is not None and pip_options_created:
-        for k, v in options_map.items():
-            suppress_setattr(options, k, v, filter_none=True)
-    if all([session is None, install_cmd is None, session_is_required]):
-        raise TypeError(
-            "Preparer requires a session instance which was not supplied and cannot be "
-            "created without an InstallCommand."
-        )
-    elif all([session is None, session_is_required]):
-        session = get_session(install_cmd=install_cmd, options=options)
-    if all([finder is None, install_cmd is None, finder_is_required]):
-        raise TypeError(
-            "RequirementPreparer requires a packagefinder but no InstallCommand"
-            " was provided to build one and none was passed in."
-        )
-    elif all([finder is None, finder_is_required]):
-        finder = get_package_finder(install_cmd, options=options, session=session)
-    preparer_args.update({"finder": finder, "session": session})
-    req_tracker_fn = nullcontext if not req_tracker_fn else req_tracker_fn
-    with req_tracker_fn() as tracker_ctx:
-        if "req_tracker" in required_args:
-            req_tracker = tracker_ctx if req_tracker is None else req_tracker
-            preparer_args["req_tracker"] = req_tracker
-
-        result = call_function_with_correct_args(preparer_fn, **preparer_args)
-        yield result
-
-
-def get_resolver(
-    resolver_fn,  # type: TShimmedFunc
-    install_req_provider=None,  # type: Optional[TShimmedFunc]
-    format_control_provider=None,  # type: Optional[TShimmedFunc]
-    wheel_cache_provider=None,  # type: Optional[TShimmedFunc]
-    finder=None,  # type: Optional[TFinder]
-    upgrade_strategy="to-satisfy-only",  # type: str
-    force_reinstall=None,  # type: Optional[bool]
-    ignore_dependencies=None,  # type: Optional[bool]
-    ignore_requires_python=None,  # type: Optional[bool]
-    ignore_installed=True,  # type: bool
-    use_user_site=False,  # type: bool
-    isolated=None,  # type: Optional[bool]
-    wheel_cache=None,  # type: Optional[TWheelCache]
-    preparer=None,  # type: Optional[TPreparer]
-    session=None,  # type: Optional[TSession]
-    options=None,  # type: Optional[Values]
-    make_install_req=None,  # type: Optional[Callable]
-    install_cmd_provider=None,  # type: Optional[TShimmedFunc]
-    install_cmd=None,  # type: Optional[TCommandInstance]
-):
-    # (...) -> TResolver
-    """
-    A resolver creation compatibility shim for generating a resolver.
-
-    Consumes any argument that was previously used to instantiate a
-    resolver, discards anything that is no longer valid.
-
-    .. note:: This is only valid for **pip >= 10.0.0**
-
-    :raises ValueError: A session is required but not provided and one cannot be created
-    :raises ValueError: A finder is required but not provided and one cannot be created
-    :raises ValueError: An install requirement provider is required and has not been
-        provided
-    :param TShimmedFunc resolver_fn: The resolver function used to create new resolver
-        instances.
-    :param TShimmedFunc install_req_provider: The provider function to use to generate
-        install requirements if needed.
-    :param TShimmedFunc format_control_provider: The provider function to use to generate
-        a format_control instance if needed.
-    :param TShimmedFunc wheel_cache_provider: The provider function to use to generate
-        a wheel cache if needed.
-    :param Optional[TFinder] finder: The package finder to use during resolution,
-        defaults to None.
-    :param str upgrade_strategy: Upgrade strategy to use, defaults to ``only-if-needed``.
-    :param Optional[bool] force_reinstall: Whether to simulate or assume package
-        reinstallation during resolution, defaults to None
-    :param Optional[bool] ignore_dependencies: Whether to ignore package dependencies,
-        defaults to None
-    :param Optional[bool] ignore_requires_python: Whether to ignore indicated
-        required_python versions on packages, defaults to None
-    :param bool ignore_installed: Whether to ignore installed packages during resolution,
-        defaults to True
-    :param bool use_user_site: Whether to use the user site location during resolution,
-        defaults to False
-    :param Optional[bool] isolated: Whether to isolate the resolution process, defaults
-        to None
-    :param Optional[TWheelCache] wheel_cache: The wheel cache to use, defaults to None
-    :param Optional[TPreparer] preparer: The requirement preparer to use, defaults to
-        None
-    :param Optional[TSession] session: Existing session to use for getting requirements,
-        defaults to None
-    :param Optional[Values] options: Pip options to use if needed, defaults to None
-    :param Optional[functools.partial] make_install_req: The partial function to pass in
-        to the resolver for actually generating install requirements, if necessary
-    :param Optional[TCommandInstance] install_cmd: The install command used to create
-        the finder, session, and options if needed, defaults to None.
-    :return: A new resolver instance.
-    :rtype: :class:`~pip._internal.legacy_resolve.Resolver`
-
-    :Example:
-
-    >>> import os
-    >>> from tempdir import TemporaryDirectory
-    >>> from pip_shims.shims import (
-    ...     InstallCommand, get_package_finder, make_preparer, get_requirement_tracker,
-    ...     get_resolver, InstallRequirement, RequirementSet
-    ... )
-    >>> install_cmd = InstallCommand()
-    >>> pip_options, _ = install_cmd.parser.parse_args([])
-    >>> session = install_cmd._build_session(pip_options)
-    >>> finder = get_package_finder(
-    ...     install_cmd, session=session, options=pip_options
-    ... )
-    >>> wheel_cache = WheelCache(USER_CACHE_DIR, FormatControl(None, None))
-    >>> with TemporaryDirectory() as temp_base:
-    ...     reqset = RequirementSet()
-    ...     ireq = InstallRequirement.from_line("requests")
-    ...     ireq.is_direct = True
-    ...     build_dir = os.path.join(temp_base, "build")
-    ...     src_dir = os.path.join(temp_base, "src")
-    ...     ireq.build_location(build_dir)
-    ...     with make_preparer(
-    ...         options=pip_options, finder=finder, session=session,
-    ...         build_dir=build_dir, install_cmd=install_cmd,
-    ...     ) as preparer:
-    ...         resolver = get_resolver(
-    ...             finder=finder, ignore_dependencies=False, ignore_requires_python=True,
-    ...             preparer=preparer, session=session, options=pip_options,
-    ...             install_cmd=install_cmd, wheel_cache=wheel_cache,
-    ...         )
-    ...         resolver.require_hashes = False
-    ...         reqset.add_requirement(ireq)
-    ...         results = resolver.resolve(reqset)
-    ...         #reqset.cleanup_files()
-    ...         for result_req in reqset.requirements:
-    ...             print(result_req)
-    requests
-    chardet
-    certifi
-    urllib3
-    idna
-    """
-    resolver_fn = resolve_possible_shim(resolver_fn)
-    install_req_provider = resolve_possible_shim(install_req_provider)
-    format_control_provider = resolve_possible_shim(format_control_provider)
-    wheel_cache_provider = resolve_possible_shim(wheel_cache_provider)
-    install_cmd_provider = resolve_possible_shim(install_cmd_provider)
-    required_args = inspect.getargs(resolver_fn.__init__.__code__).args  # type: ignore
-    install_cmd_dependency_map = {"session": session, "finder": finder}
-    resolver_kwargs = {}  # type: Dict[str, Any]
-    if install_cmd is None:
-        assert isinstance(install_cmd_provider, (type, functools.partial))
-        install_cmd = install_cmd_provider()
-    if options is None and install_cmd is not None:
-        options = install_cmd.parser.parse_args([])  # type: ignore
-    for arg, val in install_cmd_dependency_map.items():
-        if arg not in required_args:
-            continue
-        elif val is None and install_cmd is None:
-            raise TypeError(
-                "Preparer requires a {0} but did not receive one "
-                "and cannot generate one".format(arg)
-            )
-        elif arg == "session" and val is None:
-            val = get_session(install_cmd=install_cmd, options=options)
-        elif arg == "finder" and val is None:
-            val = get_package_finder(install_cmd, options=options, session=session)
-        resolver_kwargs[arg] = val
-    if "make_install_req" in required_args:
-        if make_install_req is None and install_req_provider is not None:
-            make_install_req = functools.partial(
-                install_req_provider,
-                isolated=isolated,
-                wheel_cache=wheel_cache,
-                # use_pep517=use_pep517,
-            )
-        assert make_install_req is not None
-        resolver_kwargs["make_install_req"] = make_install_req
-    if "isolated" in required_args:
-        resolver_kwargs["isolated"] = isolated
-    if "wheel_cache" in required_args:
-        if wheel_cache is None and wheel_cache_provider is not None:
-            cache_dir = getattr(options, "cache_dir", None)
-            format_control = getattr(
-                options,
-                "format_control",
-                format_control_provider(None, None),  # type: ignore
-            )
-            wheel_cache = wheel_cache_provider(cache_dir, format_control)
-        resolver_kwargs["wheel_cache"] = wheel_cache
-    resolver_kwargs.update(
-        {
-            "upgrade_strategy": upgrade_strategy,
-            "force_reinstall": force_reinstall,
-            "ignore_dependencies": ignore_dependencies,
-            "ignore_requires_python": ignore_requires_python,
-            "ignore_installed": ignore_installed,
-            "use_user_site": use_user_site,
-            "preparer": preparer,
-        }
-    )
-    return resolver_fn(**resolver_kwargs)  # type: ignore
-
-
-def resolve(
-    ireq,  # type: TInstallRequirement
-    reqset_provider=None,  # type: Optional[TShimmedFunc]
-    req_tracker_provider=None,  # type: Optional[TShimmedFunc]
-    install_cmd_provider=None,  # type: Optional[TShimmedFunc]
-    install_command=None,  # type: Optional[TCommand]
-    finder_provider=None,  # type: Optional[TShimmedFunc]
-    resolver_provider=None,  # type: Optional[TShimmedFunc]
-    wheel_cache_provider=None,  # type: Optional[TShimmedFunc]
-    format_control_provider=None,  # type: Optional[TShimmedFunc]
-    make_preparer_provider=None,  # type: Optional[TShimmedFunc]
-    options=None,  # type: Optional[Values]
-    session=None,  # type: Optional[TSession]
-    resolver=None,  # type: Optional[TResolver]
-    finder=None,  # type: Optional[TFinder]
-    upgrade_strategy="to-satisfy-only",  # type: str
-    force_reinstall=None,  # type: Optional[bool]
-    ignore_dependencies=None,  # type: Optional[bool]
-    ignore_requires_python=None,  # type: Optional[bool]
-    ignore_installed=True,  # type: bool
-    use_user_site=False,  # type: bool
-    isolated=None,  # type: Optional[bool]
-    build_dir=None,  # type: Optional[str]
-    source_dir=None,  # type: Optional[str]
-    download_dir=None,  # type: Optional[str]
-    cache_dir=None,  # type: Optional[str]
-    wheel_download_dir=None,  # type: Optional[str]
-    wheel_cache=None,  # type: Optional[TWheelCache]
-    require_hashes=None,  # type: bool
-):
-    # (...) -> Set[TInstallRequirement]
-    """
-    Resolves the provided **InstallRequirement**, returning a dictionary.
-
-    Maps a dictionary of names to corresponding ``InstallRequirement`` values.
-
-    :param :class:`~pip._internal.req.req_install.InstallRequirement` ireq: An
-        InstallRequirement to initiate the resolution process
-    :param :class:`~pip_shims.models.ShimmedPathCollection` reqset_provider: A provider
-        to build requirement set instances.
-    :param :class:`~pip_shims.models.ShimmedPathCollection` req_tracker_provider: A
-        provider to build requirement tracker instances
-    :param install_cmd_provider: A shim for providing new install command instances.
-    :type install_cmd_provider: :class:`~pip_shims.models.ShimmedPathCollection`
-    :param Optional[TCommandInstance] install_command:  The install command used to
-        create the finder, session, and options if needed, defaults to None.
-    :param :class:`~pip_shims.models.ShimmedPathCollection` finder_provider: A provider
-        to package finder instances.
-    :param :class:`~pip_shims.models.ShimmedPathCollection` resolver_provider: A provider
-        to build resolver instances
-    :param TShimmedFunc wheel_cache_provider: The provider function to use to generate a
-        wheel cache if needed.
-    :param TShimmedFunc format_control_provider: The provider function to use to generate
-        a format_control instance if needed.
-    :param TShimmedFunc make_preparer_provider: Callable or shim for generating preparers.
-    :param Optional[Values] options: Pip options to use if needed, defaults to None
-    :param Optional[TSession] session: Existing session to use for getting requirements,
-        defaults to None
-    :param :class:`~pip._internal.legacy_resolve.Resolver` resolver: A pre-existing
-        resolver instance to use for resolution
-    :param Optional[TFinder] finder: The package finder to use during resolution,
-        defaults to None.
-    :param str upgrade_strategy: Upgrade strategy to use, defaults to ``only-if-needed``.
-    :param Optional[bool] force_reinstall: Whether to simulate or assume package
-        reinstallation during resolution, defaults to None
-    :param Optional[bool] ignore_dependencies: Whether to ignore package dependencies,
-        defaults to None
-    :param Optional[bool] ignore_requires_python: Whether to ignore indicated
-        required_python versions on packages, defaults to None
-    :param bool ignore_installed: Whether to ignore installed packages during
-        resolution, defaults to True
-    :param bool use_user_site: Whether to use the user site location during resolution,
-        defaults to False
-    :param Optional[bool] isolated: Whether to isolate the resolution process, defaults
-        to None
-    :param Optional[str] build_dir: Directory for building packages and wheels, defaults
-        to None
-    :param str source_dir: The directory to use for source requirements. Removed in pip
-        10, defaults to None
-    :param Optional[str] download_dir: Target directory to download files, defaults to
-        None
-    :param str cache_dir: The cache directory to use for caching artifacts during
-        resolution
-    :param Optional[str] wheel_download_dir: Target directoryto download wheels, defaults
-        to None
-    :param Optional[TWheelCache] wheel_cache: The wheel cache to use, defaults to None
-    :param bool require_hashes: Whether to require hashes when resolving. Defaults to
-        False.
-    :return: A dictionary mapping requirements to corresponding
-        :class:`~pip._internal.req.req_install.InstallRequirement`s
-    :rtype: :class:`~pip._internal.req.req_install.InstallRequirement`
-
-    :Example:
-
-    >>> from pip_shims.shims import resolve, InstallRequirement
-    >>> ireq = InstallRequirement.from_line("requests>=2.20")
-    >>> results = resolve(ireq)
-    >>> for k, v in results.items():
-    ...    print("{0}: {1!r}".format(k, v))
-    requests: <InstallRequirement object: requests>=2.20 from https://files.pythonhosted.
-    org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/reque
-    sts-2.22.0-py2.py3-none-any.whl#sha256=9cf5292fcd0f598c671cfc1e0d7d1a7f13bb8085e9a590
-    f48c010551dc6c4b31 editable=False>
-    idna: <InstallRequirement object: idna<2.9,>=2.5 from https://files.pythonhosted.org/
-    packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-
-    py2.py3-none-any.whl#sha256=ea8b7f6188e6fa117537c3df7da9fc686d485087abf6ac197f9c46432
-    f7e4a3c (from requests>=2.20) editable=False>
-    urllib3: <InstallRequirement object: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 from htt
-    ps://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f19
-    3a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl#sha256=a8a318824cc77d1fd4b2bec
-    2ded92646630d7fe8619497b142c84a9e6f5a7293 (from requests>=2.20) editable=False>
-    chardet: <InstallRequirement object: chardet<3.1.0,>=3.0.2 from https://files.pythonh
-    osted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8
-    /chardet-3.0.4-py2.py3-none-any.whl#sha256=fc323ffcaeaed0e0a02bf4d117757b98aed530d9ed
-    4531e3e15460124c106691 (from requests>=2.20) editable=False>
-    certifi: <InstallRequirement object: certifi>=2017.4.17 from https://files.pythonhost
-    ed.org/packages/18/b0/8146a4f8dd402f60744fa380bc73ca47303cccf8b9190fd16a827281eac2/ce
-    rtifi-2019.9.11-py2.py3-none-any.whl#sha256=fd7c7c74727ddcf00e9acd26bba8da604ffec95bf
-    1c2144e67aff7a8b50e6cef (from requests>=2.20) editable=False>
-    """
-    reqset_provider = resolve_possible_shim(reqset_provider)
-    finder_provider = resolve_possible_shim(finder_provider)
-    resolver_provider = resolve_possible_shim(resolver_provider)
-    wheel_cache_provider = resolve_possible_shim(wheel_cache_provider)
-    format_control_provider = resolve_possible_shim(format_control_provider)
-    make_preparer_provider = resolve_possible_shim(make_preparer_provider)
-    req_tracker_provider = resolve_possible_shim(req_tracker_provider)
-    install_cmd_provider = resolve_possible_shim(install_cmd_provider)
-    if install_command is None:
-        assert isinstance(install_cmd_provider, (type, functools.partial))
-        install_command = install_cmd_provider()
-    kwarg_map = {
-        "upgrade_strategy": upgrade_strategy,
-        "force_reinstall": force_reinstall,
-        "ignore_dependencies": ignore_dependencies,
-        "ignore_requires_python": ignore_requires_python,
-        "ignore_installed": ignore_installed,
-        "use_user_site": use_user_site,
-        "isolated": isolated,
-        "build_dir": build_dir,
-        "src_dir": source_dir,
-        "download_dir": download_dir,
-        "require_hashes": require_hashes,
-        "cache_dir": cache_dir,
-    }
-    kwargs, options = populate_options(install_command, options, **kwarg_map)
-    with ExitStack() as ctx:
-        kwargs = ctx.enter_context(
-            ensure_resolution_dirs(wheel_download_dir=wheel_download_dir, **kwargs)
-        )
-        wheel_download_dir = kwargs.pop("wheel_download_dir")
-        if session is None:
-            session = get_session(install_cmd=install_command, options=options)
-        if finder is None:
-            finder = finder_provider(
-                install_command, options=options, session=session
-            )  # type: ignore
-        format_control = getattr(options, "format_control", None)
-        if not format_control:
-            format_control = format_control_provider(None, None)  # type: ignore
-        wheel_cache = wheel_cache_provider(
-            kwargs["cache_dir"], format_control
-        )  # type: ignore
-        ireq.is_direct = True  # type: ignore
-        ireq.build_location(kwargs["build_dir"])  # type: ignore
-        if reqset_provider is None:
-            raise TypeError(
-                "cannot resolve without a requirement set provider... failed!"
-            )
-        reqset = reqset_provider(
-            install_command,
-            options=options,
-            session=session,
-            wheel_download_dir=wheel_download_dir,
-            **kwargs
-        )  # type: ignore
-        if getattr(reqset, "prepare_files", None):
-            reqset.add_requirement(ireq)
-            results = reqset.prepare_files(finder)
-            result = reqset.requirements
-            reqset.cleanup_files()
-            return result
-        if make_preparer_provider is None:
-            raise TypeError("Cannot create requirement preparer, cannot resolve!")
-
-        preparer_args = {
-            "build_dir": kwargs["build_dir"],
-            "src_dir": kwargs["src_dir"],
-            "download_dir": kwargs["download_dir"],
-            "wheel_download_dir": wheel_download_dir,
-            "build_isolation": kwargs["isolated"],
-            "install_cmd": install_command,
-            "options": options,
-            "finder": finder,
-            "session": session,
-            "use_user_site": use_user_site,
-            "require_hashes": require_hashes,
-        }
-        # with req_tracker_provider() as req_tracker:
-        if isinstance(req_tracker_provider, (types.FunctionType, functools.partial)):
-            preparer_args["req_tracker"] = ctx.enter_context(req_tracker_provider())
-        resolver_keys = [
-            "upgrade_strategy",
-            "force_reinstall",
-            "ignore_dependencies",
-            "ignore_installed",
-            "use_user_site",
-            "isolated",
-            "use_user_site",
-        ]
-        resolver_args = {key: kwargs[key] for key in resolver_keys if key in kwargs}
-        if resolver_provider is None:
-            raise TypeError("Cannot resolve without a resolver provider... failed!")
-        preparer = ctx.enter_context(make_preparer_provider(**preparer_args))
-        resolver = resolver_provider(
-            finder=finder,
-            preparer=preparer,
-            session=session,
-            options=options,
-            install_cmd=install_command,
-            wheel_cache=wheel_cache,
-            **resolver_args
-        )  # type: ignore
-        reqset.add_requirement(ireq)
-        resolver.require_hashes = kwargs.get("require_hashes", False)  # type: ignore
-        resolver.resolve(reqset)  # type: ignore
-        results = reqset.requirements
-        reqset.cleanup_files()
-        return results
diff --git a/pipenv/vendor/pyparsing.py b/pipenv/vendor/pyparsing.py
index 9a2dd7bf..4d2f98e4 100644
--- a/pipenv/vendor/pyparsing.py
+++ b/pipenv/vendor/pyparsing.py
@@ -95,8 +95,8 @@ classes inherit from. Use the docstrings for examples of how to:
    namespace class
 """
 
-__version__ = "2.4.5"
-__versionTime__ = "09 Nov 2019 23:03 UTC"
+__version__ = "2.4.6"
+__versionTime__ = "24 Dec 2019 04:27 UTC"
 __author__ = "Paul McGuire <ptmcg@users.sourceforge.net>"
 
 import string
@@ -114,6 +114,7 @@ from datetime import datetime
 from operator import itemgetter
 import itertools
 from functools import wraps
+from contextlib import contextmanager
 
 try:
     # Python 3
@@ -184,6 +185,7 @@ __diag__.warn_ungrouped_named_tokens_in_collection = False
 __diag__.warn_name_set_on_empty_Forward = False
 __diag__.warn_on_multiple_string_args_to_oneof = False
 __diag__.enable_debug_on_named_expressions = False
+__diag__._all_names = [nm for nm in vars(__diag__) if nm.startswith("enable_") or nm.startswith("warn_")]
 
 def _enable_all_warnings():
     __diag__.warn_multiple_tokens_in_named_alternation = True
@@ -3630,24 +3632,24 @@ class White(Token):
         '\n': '<LF>',
         '\r': '<CR>',
         '\f': '<FF>',
-        'u\00A0': '<NBSP>',
-        'u\1680': '<OGHAM_SPACE_MARK>',
-        'u\180E': '<MONGOLIAN_VOWEL_SEPARATOR>',
-        'u\2000': '<EN_QUAD>',
-        'u\2001': '<EM_QUAD>',
-        'u\2002': '<EN_SPACE>',
-        'u\2003': '<EM_SPACE>',
-        'u\2004': '<THREE-PER-EM_SPACE>',
-        'u\2005': '<FOUR-PER-EM_SPACE>',
-        'u\2006': '<SIX-PER-EM_SPACE>',
-        'u\2007': '<FIGURE_SPACE>',
-        'u\2008': '<PUNCTUATION_SPACE>',
-        'u\2009': '<THIN_SPACE>',
-        'u\200A': '<HAIR_SPACE>',
-        'u\200B': '<ZERO_WIDTH_SPACE>',
-        'u\202F': '<NNBSP>',
-        'u\205F': '<MMSP>',
-        'u\3000': '<IDEOGRAPHIC_SPACE>',
+        u'\u00A0': '<NBSP>',
+        u'\u1680': '<OGHAM_SPACE_MARK>',
+        u'\u180E': '<MONGOLIAN_VOWEL_SEPARATOR>',
+        u'\u2000': '<EN_QUAD>',
+        u'\u2001': '<EM_QUAD>',
+        u'\u2002': '<EN_SPACE>',
+        u'\u2003': '<EM_SPACE>',
+        u'\u2004': '<THREE-PER-EM_SPACE>',
+        u'\u2005': '<FOUR-PER-EM_SPACE>',
+        u'\u2006': '<SIX-PER-EM_SPACE>',
+        u'\u2007': '<FIGURE_SPACE>',
+        u'\u2008': '<PUNCTUATION_SPACE>',
+        u'\u2009': '<THIN_SPACE>',
+        u'\u200A': '<HAIR_SPACE>',
+        u'\u200B': '<ZERO_WIDTH_SPACE>',
+        u'\u202F': '<NNBSP>',
+        u'\u205F': '<MMSP>',
+        u'\u3000': '<IDEOGRAPHIC_SPACE>',
         }
     def __init__(self, ws=" \t\r\n", min=1, max=0, exact=0):
         super(White, self).__init__()
@@ -6064,7 +6066,7 @@ def infixNotation(baseExpr, opList, lpar=Suppress('('), rpar=Suppress(')')):
                     matchExpr = _FB(lastExpr + lastExpr) + Group(lastExpr + OneOrMore(lastExpr))
             elif arity == 3:
                 matchExpr = (_FB(lastExpr + opExpr1 + lastExpr + opExpr2 + lastExpr)
-                             + Group(lastExpr + opExpr1 + lastExpr + opExpr2 + lastExpr))
+                             + Group(lastExpr + OneOrMore(opExpr1 + lastExpr + opExpr2 + lastExpr)))
             else:
                 raise ValueError("operator must be unary (1), binary (2), or ternary (3)")
         elif rightLeftAssoc == opAssoc.RIGHT:
@@ -6835,6 +6837,187 @@ if PY_3:
     setattr(pyparsing_unicode, u"", pyparsing_unicode.Devanagari)
 
 
+class pyparsing_test:
+    """
+    namespace class for classes useful in writing unit tests
+    """
+
+    class reset_pyparsing_context:
+        """
+        Context manager to be used when writing unit tests that modify pyparsing config values:
+         - packrat parsing
+         - default whitespace characters.
+         - default keyword characters
+         - literal string auto-conversion class
+         - __diag__ settings
+
+        Example:
+            with reset_pyparsing_context():
+                # test that literals used to construct a grammar are automatically suppressed
+                ParserElement.inlineLiteralsUsing(Suppress)
+
+                term = Word(alphas) | Word(nums)
+                group = Group('(' + term[...] + ')')
+
+                # assert that the '()' characters are not included in the parsed tokens
+                self.assertParseAndCheckLisst(group, "(abc 123 def)", ['abc', '123', 'def'])
+
+            # after exiting context manager, literals are converted to Literal expressions again
+        """
+
+        def __init__(self):
+            self._save_context = {}
+
+        def save(self):
+            self._save_context["default_whitespace"] = ParserElement.DEFAULT_WHITE_CHARS
+            self._save_context["default_keyword_chars"] = Keyword.DEFAULT_KEYWORD_CHARS
+            self._save_context[
+                "literal_string_class"
+            ] = ParserElement._literalStringClass
+            self._save_context["packrat_enabled"] = ParserElement._packratEnabled
+            self._save_context["packrat_parse"] = ParserElement._parse
+            self._save_context["__diag__"] = {
+                name: getattr(__diag__, name) for name in __diag__._all_names
+            }
+            self._save_context["__compat__"] = {
+                "collect_all_And_tokens": __compat__.collect_all_And_tokens
+            }
+            return self
+
+        def restore(self):
+            # reset pyparsing global state
+            if (
+                ParserElement.DEFAULT_WHITE_CHARS
+                != self._save_context["default_whitespace"]
+            ):
+                ParserElement.setDefaultWhitespaceChars(
+                    self._save_context["default_whitespace"]
+                )
+            Keyword.DEFAULT_KEYWORD_CHARS = self._save_context["default_keyword_chars"]
+            ParserElement.inlineLiteralsUsing(
+                self._save_context["literal_string_class"]
+            )
+            for name, value in self._save_context["__diag__"].items():
+                setattr(__diag__, name, value)
+            ParserElement._packratEnabled = self._save_context["packrat_enabled"]
+            ParserElement._parse = self._save_context["packrat_parse"]
+            __compat__.collect_all_And_tokens = self._save_context["__compat__"]
+
+        def __enter__(self):
+            return self.save()
+
+        def __exit__(self, *args):
+            return self.restore()
+
+    class TestParseResultsAsserts:
+        """
+        A mixin class to add parse results assertion methods to normal unittest.TestCase classes.
+        """
+        def assertParseResultsEquals(
+            self, result, expected_list=None, expected_dict=None, msg=None
+        ):
+            """
+            Unit test assertion to compare a ParseResults object with an optional expected_list,
+            and compare any defined results names with an optional expected_dict.
+            """
+            if expected_list is not None:
+                self.assertEqual(expected_list, result.asList(), msg=msg)
+            if expected_dict is not None:
+                self.assertEqual(expected_dict, result.asDict(), msg=msg)
+
+        def assertParseAndCheckList(
+            self, expr, test_string, expected_list, msg=None, verbose=True
+        ):
+            """
+            Convenience wrapper assert to test a parser element and input string, and assert that
+            the resulting ParseResults.asList() is equal to the expected_list.
+            """
+            result = expr.parseString(test_string, parseAll=True)
+            if verbose:
+                print(result.dump())
+            self.assertParseResultsEquals(result, expected_list=expected_list, msg=msg)
+
+        def assertParseAndCheckDict(
+            self, expr, test_string, expected_dict, msg=None, verbose=True
+        ):
+            """
+            Convenience wrapper assert to test a parser element and input string, and assert that
+            the resulting ParseResults.asDict() is equal to the expected_dict.
+            """
+            result = expr.parseString(test_string, parseAll=True)
+            if verbose:
+                print(result.dump())
+            self.assertParseResultsEquals(result, expected_dict=expected_dict, msg=msg)
+
+        def assertRunTestResults(
+            self, run_tests_report, expected_parse_results=None, msg=None
+        ):
+            """
+            Unit test assertion to evaluate output of ParserElement.runTests(). If a list of
+            list-dict tuples is given as the expected_parse_results argument, then these are zipped
+            with the report tuples returned by runTests and evaluated using assertParseResultsEquals.
+            Finally, asserts that the overall runTests() success value is True.
+
+            :param run_tests_report: tuple(bool, [tuple(str, ParseResults or Exception)]) returned from runTests
+            :param expected_parse_results (optional): [tuple(str, list, dict, Exception)]
+            """
+            run_test_success, run_test_results = run_tests_report
+
+            if expected_parse_results is not None:
+                merged = [
+                    (rpt[0], rpt[1], expected)
+                    for rpt, expected in zip(run_test_results, expected_parse_results)
+                ]
+                for test_string, result, expected in merged:
+                    # expected should be a tuple containing a list and/or a dict or an exception,
+                    # and optional failure message string
+                    # an empty tuple will skip any result validation
+                    fail_msg = next(
+                        (exp for exp in expected if isinstance(exp, str)), None
+                    )
+                    expected_exception = next(
+                        (
+                            exp
+                            for exp in expected
+                            if isinstance(exp, type) and issubclass(exp, Exception)
+                        ),
+                        None,
+                    )
+                    if expected_exception is not None:
+                        with self.assertRaises(
+                            expected_exception=expected_exception, msg=fail_msg or msg
+                        ):
+                            if isinstance(result, Exception):
+                                raise result
+                    else:
+                        expected_list = next(
+                            (exp for exp in expected if isinstance(exp, list)), None
+                        )
+                        expected_dict = next(
+                            (exp for exp in expected if isinstance(exp, dict)), None
+                        )
+                        if (expected_list, expected_dict) != (None, None):
+                            self.assertParseResultsEquals(
+                                result,
+                                expected_list=expected_list,
+                                expected_dict=expected_dict,
+                                msg=fail_msg or msg,
+                            )
+                        else:
+                            # warning here maybe?
+                            print("no validation for {!r}".format(test_string))
+
+            # do this last, in case some specific test results can be reported instead
+            self.assertTrue(
+                run_test_success, msg=msg if msg is not None else "failed runTests"
+            )
+
+        @contextmanager
+        def assertRaisesParseException(self, exc_type=ParseException, msg=None):
+            with self.assertRaises(exc_type, msg=msg):
+                yield
+
+
 if __name__ == "__main__":
 
     selectToken    = CaselessLiteral("select")
diff --git a/pipenv/vendor/requests/LICENSE b/pipenv/vendor/requests/LICENSE
index 841c6023..13d91ddc 100644
--- a/pipenv/vendor/requests/LICENSE
+++ b/pipenv/vendor/requests/LICENSE
@@ -1,4 +1,4 @@
-Copyright 2018 Kenneth Reitz
+Copyright 2019 Kenneth Reitz
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
diff --git a/pipenv/vendor/requests/__init__.py b/pipenv/vendor/requests/__init__.py
index 9a899df6..626247cb 100644
--- a/pipenv/vendor/requests/__init__.py
+++ b/pipenv/vendor/requests/__init__.py
@@ -9,14 +9,14 @@
 Requests HTTP Library
 ~~~~~~~~~~~~~~~~~~~~~
 
-Requests is an HTTP library, written in Python, for human beings. Basic GET
-usage:
+Requests is an HTTP library, written in Python, for human beings.
+Basic GET usage:
 
    >>> import requests
    >>> r = requests.get('https://www.python.org')
    >>> r.status_code
    200
-   >>> 'Python is a programming language' in r.content
+   >>> b'Python is a programming language' in r.content
    True
 
 ... or POST:
@@ -27,14 +27,14 @@ usage:
    {
      ...
      "form": {
-       "key2": "value2",
-       "key1": "value1"
+       "key1": "value1",
+       "key2": "value2"
      },
      ...
    }
 
 The other HTTP methods are supported - see `requests.api`. Full documentation
-is at <http://python-requests.org>.
+is at <https://requests.readthedocs.io>.
 
 :copyright: (c) 2017 by Kenneth Reitz.
 :license: Apache 2.0, see LICENSE for more details.
diff --git a/pipenv/vendor/requests/__version__.py b/pipenv/vendor/requests/__version__.py
index 9844f740..b9e7df48 100644
--- a/pipenv/vendor/requests/__version__.py
+++ b/pipenv/vendor/requests/__version__.py
@@ -4,11 +4,11 @@
 
 __title__ = 'requests'
 __description__ = 'Python HTTP for Humans.'
-__url__ = 'http://python-requests.org'
-__version__ = '2.22.0'
-__build__ = 0x022200
+__url__ = 'https://requests.readthedocs.io'
+__version__ = '2.23.0'
+__build__ = 0x022300
 __author__ = 'Kenneth Reitz'
 __author_email__ = 'me@kennethreitz.org'
 __license__ = 'Apache 2.0'
-__copyright__ = 'Copyright 2019 Kenneth Reitz'
+__copyright__ = 'Copyright 2020 Kenneth Reitz'
 __cake__ = u'\u2728 \U0001f370 \u2728'
diff --git a/pipenv/vendor/requests/api.py b/pipenv/vendor/requests/api.py
index ef71d075..e978e203 100644
--- a/pipenv/vendor/requests/api.py
+++ b/pipenv/vendor/requests/api.py
@@ -16,7 +16,7 @@ from . import sessions
 def request(method, url, **kwargs):
     """Constructs and sends a :class:`Request <Request>`.
 
-    :param method: method for the new :class:`Request` object.
+    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
     :param url: URL for the new :class:`Request` object.
     :param params: (optional) Dictionary, list of tuples or bytes to send
         in the query string for the :class:`Request`.
@@ -50,6 +50,7 @@ def request(method, url, **kwargs):
 
       >>> import requests
       >>> req = requests.request('GET', 'https://httpbin.org/get')
+      >>> req
       <Response [200]>
     """
 
@@ -92,7 +93,9 @@ def head(url, **kwargs):
     r"""Sends a HEAD request.
 
     :param url: URL for the new :class:`Request` object.
-    :param \*\*kwargs: Optional arguments that ``request`` takes.
+    :param \*\*kwargs: Optional arguments that ``request`` takes. If
+        `allow_redirects` is not provided, it will be set to `False` (as
+        opposed to the default :meth:`request` behavior).
     :return: :class:`Response <Response>` object
     :rtype: requests.Response
     """
diff --git a/pipenv/vendor/requests/auth.py b/pipenv/vendor/requests/auth.py
index bdde51c7..eeface39 100644
--- a/pipenv/vendor/requests/auth.py
+++ b/pipenv/vendor/requests/auth.py
@@ -50,7 +50,7 @@ def _basic_auth_str(username, password):
             "Non-string passwords will no longer be supported in Requests "
             "3.0.0. Please convert the object you've passed in ({!r}) to "
             "a string or bytes object in the near future to avoid "
-            "problems.".format(password),
+            "problems.".format(type(password)),
             category=DeprecationWarning,
         )
         password = str(password)
@@ -239,7 +239,7 @@ class HTTPDigestAuth(AuthBase):
         """
 
         # If response is not 4xx, do not auth
-        # See https://github.com/requests/requests/issues/3772
+        # See https://github.com/psf/requests/issues/3772
         if not 400 <= r.status_code < 500:
             self._thread_local.num_401_calls = 1
             return r
diff --git a/pipenv/vendor/requests/compat.py b/pipenv/vendor/requests/compat.py
index c44b35ef..5de0769f 100644
--- a/pipenv/vendor/requests/compat.py
+++ b/pipenv/vendor/requests/compat.py
@@ -43,6 +43,7 @@ if is_py2:
     import cookielib
     from Cookie import Morsel
     from StringIO import StringIO
+    # Keep OrderedDict for backwards compatibility.
     from collections import Callable, Mapping, MutableMapping, OrderedDict
 
 
@@ -59,6 +60,7 @@ elif is_py3:
     from http import cookiejar as cookielib
     from http.cookies import Morsel
     from io import StringIO
+    # Keep OrderedDict for backwards compatibility.
     from collections import OrderedDict
     from collections.abc import Callable, Mapping, MutableMapping
 
diff --git a/pipenv/vendor/requests/models.py b/pipenv/vendor/requests/models.py
index 62dcd0b7..35798832 100644
--- a/pipenv/vendor/requests/models.py
+++ b/pipenv/vendor/requests/models.py
@@ -12,7 +12,7 @@ import sys
 
 # Import encoding now, to avoid implicit import later.
 # Implicit import within threads may cause LookupError when standard library is in a ZIP,
-# such as in Embedded Python. See https://github.com/requests/requests/issues/3578.
+# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.
 import encodings.idna
 
 from urllib3.fields import RequestField
@@ -280,6 +280,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
       >>> import requests
       >>> req = requests.Request('GET', 'https://httpbin.org/get')
       >>> r = req.prepare()
+      >>> r
       <PreparedRequest [GET]>
 
       >>> s = requests.Session()
@@ -358,7 +359,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
         #: We're unable to blindly call unicode/str functions
         #: as this will include the bytestring indicator (b'')
         #: on python 3.x.
-        #: https://github.com/requests/requests/pull/2238
+        #: https://github.com/psf/requests/pull/2238
         if isinstance(url, bytes):
             url = url.decode('utf8')
         else:
@@ -608,7 +609,7 @@ class Response(object):
 
         #: File-like object representation of response (for advanced usage).
         #: Use of ``raw`` requires that ``stream=True`` be set on the request.
-        # This requirement does not apply for use internally to Requests.
+        #: This requirement does not apply for use internally to Requests.
         self.raw = None
 
         #: Final URL location of Response.
diff --git a/pipenv/vendor/requests/sessions.py b/pipenv/vendor/requests/sessions.py
index d73d700f..2845880b 100644
--- a/pipenv/vendor/requests/sessions.py
+++ b/pipenv/vendor/requests/sessions.py
@@ -11,9 +11,10 @@ import os
 import sys
 import time
 from datetime import timedelta
+from collections import OrderedDict
 
 from .auth import _basic_auth_str
-from .compat import cookielib, is_py3, OrderedDict, urljoin, urlparse, Mapping
+from .compat import cookielib, is_py3, urljoin, urlparse, Mapping
 from .cookies import (
     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)
 from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT
@@ -162,7 +163,7 @@ class SessionRedirectMixin(object):
                 resp.raw.read(decode_content=False)
 
             if len(resp.history) >= self.max_redirects:
-                raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=resp)
+                raise TooManyRedirects('Exceeded {} redirects.'.format(self.max_redirects), response=resp)
 
             # Release the connection back into the pool.
             resp.close()
@@ -170,7 +171,7 @@ class SessionRedirectMixin(object):
             # Handle redirection without scheme (see: RFC 1808 Section 4)
             if url.startswith('//'):
                 parsed_rurl = urlparse(resp.url)
-                url = '%s:%s' % (to_native_string(parsed_rurl.scheme), url)
+                url = ':'.join([to_native_string(parsed_rurl.scheme), url])
 
             # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)
             parsed = urlparse(url)
@@ -192,19 +193,16 @@ class SessionRedirectMixin(object):
 
             self.rebuild_method(prepared_request, resp)
 
-            # https://github.com/requests/requests/issues/1084
+            # https://github.com/psf/requests/issues/1084
             if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):
-                # https://github.com/requests/requests/issues/3490
+                # https://github.com/psf/requests/issues/3490
                 purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')
                 for header in purged_headers:
                     prepared_request.headers.pop(header, None)
                 prepared_request.body = None
 
             headers = prepared_request.headers
-            try:
-                del headers['Cookie']
-            except KeyError:
-                pass
+            headers.pop('Cookie', None)
 
             # Extract any cookies sent on the response to the cookiejar
             # in the new request. Because we've mutated our copied prepared
@@ -271,7 +269,6 @@ class SessionRedirectMixin(object):
         if new_auth is not None:
             prepared_request.prepare_auth(new_auth)
 
-        return
 
     def rebuild_proxies(self, prepared_request, proxies):
         """This method re-evaluates the proxy configuration by considering the
@@ -352,13 +349,13 @@ class Session(SessionRedirectMixin):
     Or as a context manager::
 
       >>> with requests.Session() as s:
-      >>>     s.get('https://httpbin.org/get')
+      ...     s.get('https://httpbin.org/get')
       <Response [200]>
     """
 
     __attrs__ = [
         'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',
-        'cert', 'prefetch', 'adapters', 'stream', 'trust_env',
+        'cert', 'adapters', 'stream', 'trust_env',
         'max_redirects',
     ]
 
@@ -728,7 +725,7 @@ class Session(SessionRedirectMixin):
                 return adapter
 
         # Nothing matches :-/
-        raise InvalidSchema("No connection adapters were found for '%s'" % url)
+        raise InvalidSchema("No connection adapters were found for {!r}".format(url))
 
     def close(self):
         """Closes all adapters and as such the session"""
diff --git a/pipenv/vendor/requests/status_codes.py b/pipenv/vendor/requests/status_codes.py
index 813e8c4e..d80a7cd4 100644
--- a/pipenv/vendor/requests/status_codes.py
+++ b/pipenv/vendor/requests/status_codes.py
@@ -5,12 +5,15 @@ The ``codes`` object defines a mapping from common names for HTTP statuses
 to their numerical codes, accessible either as attributes or as dictionary
 items.
 
->>> requests.codes['temporary_redirect']
-307
->>> requests.codes.teapot
-418
->>> requests.codes['\o/']
-200
+Example::
+
+    >>> import requests
+    >>> requests.codes['temporary_redirect']
+    307
+    >>> requests.codes.teapot
+    418
+    >>> requests.codes['\o/']
+    200
 
 Some codes have multiple names, and both upper- and lower-case versions of
 the names are allowed. For example, ``codes.ok``, ``codes.OK``, and
diff --git a/pipenv/vendor/requests/structures.py b/pipenv/vendor/requests/structures.py
index da930e28..8ee0ba7a 100644
--- a/pipenv/vendor/requests/structures.py
+++ b/pipenv/vendor/requests/structures.py
@@ -7,7 +7,9 @@ requests.structures
 Data structures that power Requests.
 """
 
-from .compat import OrderedDict, Mapping, MutableMapping
+from collections import OrderedDict
+
+from .compat import Mapping, MutableMapping
 
 
 class CaseInsensitiveDict(MutableMapping):
diff --git a/pipenv/vendor/requests/utils.py b/pipenv/vendor/requests/utils.py
index 8170a8d2..c1700d7f 100644
--- a/pipenv/vendor/requests/utils.py
+++ b/pipenv/vendor/requests/utils.py
@@ -19,6 +19,7 @@ import sys
 import tempfile
 import warnings
 import zipfile
+from collections import OrderedDict
 
 from .__version__ import __version__
 from . import certs
@@ -26,7 +27,7 @@ from . import certs
 from ._internal_utils import to_native_string
 from .compat import parse_http_list as _parse_list_header
 from .compat import (
-    quote, urlparse, bytes, str, OrderedDict, unquote, getproxies,
+    quote, urlparse, bytes, str, unquote, getproxies,
     proxy_bypass, urlunparse, basestring, integer_types, is_py3,
     proxy_bypass_environment, getproxies_environment, Mapping)
 from .cookies import cookiejar_from_dict
@@ -179,7 +180,7 @@ def get_netrc_auth(url, raise_errors=False):
             except KeyError:
                 # os.path.expanduser can fail when $HOME is undefined and
                 # getpwuid fails. See https://bugs.python.org/issue20164 &
-                # https://github.com/requests/requests/issues/1846
+                # https://github.com/psf/requests/issues/1846
                 return
 
             if os.path.exists(loc):
@@ -266,6 +267,8 @@ def from_key_val_list(value):
         >>> from_key_val_list([('key', 'val')])
         OrderedDict([('key', 'val')])
         >>> from_key_val_list('string')
+        Traceback (most recent call last):
+        ...
         ValueError: cannot encode objects that are not 2-tuples
         >>> from_key_val_list({'key': 'val'})
         OrderedDict([('key', 'val')])
@@ -292,7 +295,9 @@ def to_key_val_list(value):
         >>> to_key_val_list({'key': 'val'})
         [('key', 'val')]
         >>> to_key_val_list('string')
-        ValueError: cannot encode objects that are not 2-tuples.
+        Traceback (most recent call last):
+        ...
+        ValueError: cannot encode objects that are not 2-tuples
 
     :rtype: list
     """
diff --git a/pipenv/vendor/requirementslib/LICENSE b/pipenv/vendor/requirementslib/LICENSE
index 8c731e27..a6b8c96a 100644
--- a/pipenv/vendor/requirementslib/LICENSE
+++ b/pipenv/vendor/requirementslib/LICENSE
@@ -1,6 +1,6 @@
 The MIT License (MIT)
 
-Copyright 2018 Dan Ryan.
+Copyright 2019 Dan Ryan.
 
 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
diff --git a/pipenv/vendor/requirementslib/utils.py b/pipenv/vendor/requirementslib/utils.py
index b9db5d16..d76f82e9 100644
--- a/pipenv/vendor/requirementslib/utils.py
+++ b/pipenv/vendor/requirementslib/utils.py
@@ -121,7 +121,7 @@ def strip_ssh_from_git_uri(uri):
 
 def add_ssh_scheme_to_git_uri(uri):
     # type: (S) -> S
-    """Cleans VCS uris from pip format"""
+    """Cleans VCS uris from pipenv.patched.notpip format"""
     if isinstance(uri, six.string_types):
         # Add scheme for parsing purposes, this is also what pip does
         if uri.startswith("git+") and "://" not in uri:
diff --git a/pipenv/vendor/shellingham/__init__.py b/pipenv/vendor/shellingham/__init__.py
index b834b74b..2e7c0b79 100644
--- a/pipenv/vendor/shellingham/__init__.py
+++ b/pipenv/vendor/shellingham/__init__.py
@@ -4,7 +4,7 @@ import os
 from ._core import ShellDetectionFailure
 
 
-__version__ = '1.3.1'
+__version__ = '1.3.2'
 
 
 def detect_shell(pid=None, max_depth=6):
diff --git a/pipenv/vendor/shellingham/posix/__init__.py b/pipenv/vendor/shellingham/posix/__init__.py
index 923032b6..164bbc1d 100644
--- a/pipenv/vendor/shellingham/posix/__init__.py
+++ b/pipenv/vendor/shellingham/posix/__init__.py
@@ -1,4 +1,5 @@
 import os
+import re
 
 from .._core import SHELL_NAMES, ShellDetectionFailure
 from . import proc, ps
@@ -19,20 +20,16 @@ def _get_process_mapping():
     raise ShellDetectionFailure('compatible proc fs or ps utility is required')
 
 
-def _iter_process_command(mapping, pid, max_depth):
-    """Iterator to traverse up the tree, yielding `argv[0]` of each process.
+def _iter_process_args(mapping, pid, max_depth):
+    """Iterator to traverse up the tree, yielding each process's argument list.
     """
     for _ in range(max_depth):
         try:
             proc = mapping[pid]
         except KeyError:    # We've reached the root process. Give up.
             break
-        try:
-            cmd = proc.args[0]
-        except IndexError:  # Process has no name? Whatever, ignore it.
-            pass
-        else:
-            yield cmd
+        if proc.args:       # Persumably the process should always have a name?
+            yield proc.args
         pid = proc.ppid     # Go up one level.
 
 
@@ -47,15 +44,50 @@ def _get_login_shell(proc_cmd):
     return (os.path.basename(proc_cmd).lower(), proc_cmd)
 
 
+_INTERPRETER_SHELL_NAMES = [
+    (re.compile(r'^python(\d+(\.\d+)?)?$'), {'xonsh'}),
+]
+
+
+def _get_interpreter_shell(proc_name, proc_args):
+    """Get shell invoked via an interpreter.
+
+    Some shells are implemented on, and invoked with an interpreter, e.g. xonsh
+    is commonly executed with an executable Python script. This detects what
+    script the interpreter is actually running, and check whether that looks
+    like a shell.
+
+    See sarugaku/shellingham#26 for rational.
+    """
+    for pattern, shell_names in _INTERPRETER_SHELL_NAMES:
+        if not pattern.match(proc_name):
+            continue
+        for arg in proc_args:
+            name = os.path.basename(arg).lower()
+            if os.path.isfile(arg) and name in shell_names:
+                return (name, arg)
+    return None
+
+
+def _get_shell(cmd, *args):
+    if cmd.startswith('-'):     # Login shell! Let's use this.
+        return _get_login_shell(cmd)
+    name = os.path.basename(cmd).lower()
+    if name in SHELL_NAMES:     # Command looks like a shell.
+        return (name, cmd)
+    shell = _get_interpreter_shell(name, args)
+    if shell:
+        return shell
+    return None
+
+
 def get_shell(pid=None, max_depth=6):
     """Get the shell that the supplied pid or os.getpid() is running in.
     """
     pid = str(pid or os.getpid())
     mapping = _get_process_mapping()
-    for proc_cmd in _iter_process_command(mapping, pid, max_depth):
-        if proc_cmd.startswith('-'):    # Login shell! Let's use this.
-            return _get_login_shell(proc_cmd)
-        name = os.path.basename(proc_cmd).lower()
-        if name in SHELL_NAMES:     # The inner-most (non-login) shell.
-            return (name, proc_cmd)
+    for proc_args in _iter_process_args(mapping, pid, max_depth):
+        shell = _get_shell(*proc_args)
+        if shell:
+            return shell
     return None
diff --git a/pipenv/vendor/six.LICENSE b/pipenv/vendor/six.LICENSE
index 4b05a545..de663311 100644
--- a/pipenv/vendor/six.LICENSE
+++ b/pipenv/vendor/six.LICENSE
@@ -1,4 +1,4 @@
-Copyright (c) 2010-2019 Benjamin Peterson
+Copyright (c) 2010-2020 Benjamin Peterson
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of
 this software and associated documentation files (the "Software"), to deal in
diff --git a/pipenv/vendor/six.py b/pipenv/vendor/six.py
index 357e624a..5fe9f8e1 100644
--- a/pipenv/vendor/six.py
+++ b/pipenv/vendor/six.py
@@ -1,4 +1,4 @@
-# Copyright (c) 2010-2019 Benjamin Peterson
+# Copyright (c) 2010-2020 Benjamin Peterson
 #
 # Permission is hereby granted, free of charge, to any person obtaining a copy
 # of this software and associated documentation files (the "Software"), to deal
@@ -29,7 +29,7 @@ import sys
 import types
 
 __author__ = "Benjamin Peterson <benjamin@python.org>"
-__version__ = "1.13.0"
+__version__ = "1.14.0"
 
 
 # Useful for very coarse version differentiation.
@@ -259,7 +259,7 @@ _moved_attributes = [
     MovedModule("copyreg", "copy_reg"),
     MovedModule("dbm_gnu", "gdbm", "dbm.gnu"),
     MovedModule("dbm_ndbm", "dbm", "dbm.ndbm"),
-    MovedModule("_dummy_thread", "dummy_thread", "_dummy_thread"),
+    MovedModule("_dummy_thread", "dummy_thread", "_dummy_thread" if sys.version_info < (3, 9) else "_thread"),
     MovedModule("http_cookiejar", "cookielib", "http.cookiejar"),
     MovedModule("http_cookies", "Cookie", "http.cookies"),
     MovedModule("html_entities", "htmlentitydefs", "html.entities"),
@@ -644,9 +644,11 @@ if PY3:
     if sys.version_info[1] <= 1:
         _assertRaisesRegex = "assertRaisesRegexp"
         _assertRegex = "assertRegexpMatches"
+        _assertNotRegex = "assertNotRegexpMatches"
     else:
         _assertRaisesRegex = "assertRaisesRegex"
         _assertRegex = "assertRegex"
+        _assertNotRegex = "assertNotRegex"
 else:
     def b(s):
         return s
@@ -668,6 +670,7 @@ else:
     _assertCountEqual = "assertItemsEqual"
     _assertRaisesRegex = "assertRaisesRegexp"
     _assertRegex = "assertRegexpMatches"
+    _assertNotRegex = "assertNotRegexpMatches"
 _add_doc(b, """Byte literal""")
 _add_doc(u, """Text literal""")
 
@@ -684,6 +687,10 @@ def assertRegex(self, *args, **kwargs):
     return getattr(self, _assertRegex)(*args, **kwargs)
 
 
+def assertNotRegex(self, *args, **kwargs):
+    return getattr(self, _assertNotRegex)(*args, **kwargs)
+
+
 if PY3:
     exec_ = getattr(moves.builtins, "exec")
 
@@ -719,16 +726,7 @@ else:
 """)
 
 
-if sys.version_info[:2] == (3, 2):
-    exec_("""def raise_from(value, from_value):
-    try:
-        if from_value is None:
-            raise value
-        raise value from from_value
-    finally:
-        value = None
-""")
-elif sys.version_info[:2] > (3, 2):
+if sys.version_info[:2] > (3,):
     exec_("""def raise_from(value, from_value):
     try:
         raise value from from_value
@@ -808,13 +806,33 @@ if sys.version_info[:2] < (3, 3):
 _add_doc(reraise, """Reraise an exception.""")
 
 if sys.version_info[0:2] < (3, 4):
+    # This does exactly the same what the :func:`py3:functools.update_wrapper`
+    # function does on Python versions after 3.2. It sets the ``__wrapped__``
+    # attribute on ``wrapper`` object and it doesn't raise an error if any of
+    # the attributes mentioned in ``assigned`` and ``updated`` are missing on
+    # ``wrapped`` object.
+    def _update_wrapper(wrapper, wrapped,
+                        assigned=functools.WRAPPER_ASSIGNMENTS,
+                        updated=functools.WRAPPER_UPDATES):
+        for attr in assigned:
+            try:
+                value = getattr(wrapped, attr)
+            except AttributeError:
+                continue
+            else:
+                setattr(wrapper, attr, value)
+        for attr in updated:
+            getattr(wrapper, attr).update(getattr(wrapped, attr, {}))
+        wrapper.__wrapped__ = wrapped
+        return wrapper
+    _update_wrapper.__doc__ = functools.update_wrapper.__doc__
+
     def wraps(wrapped, assigned=functools.WRAPPER_ASSIGNMENTS,
               updated=functools.WRAPPER_UPDATES):
-        def wrapper(f):
-            f = functools.wraps(wrapped, assigned, updated)(f)
-            f.__wrapped__ = wrapped
-            return f
-        return wrapper
+        return functools.partial(_update_wrapper, wrapped=wrapped,
+                                 assigned=assigned, updated=updated)
+    wraps.__doc__ = functools.wraps.__doc__
+
 else:
     wraps = functools.wraps
 
@@ -919,10 +937,9 @@ def ensure_text(s, encoding='utf-8', errors='strict'):
         raise TypeError("not expecting type '%s'" % type(s))
 
 
-
 def python_2_unicode_compatible(klass):
     """
-    A decorator that defines __unicode__ and __str__ methods under Python 2.
+    A class decorator that defines __unicode__ and __str__ methods under Python 2.
     Under Python 3 it does nothing.
 
     To support Python 2 and 3 with a single code base, define a __str__ method
diff --git a/pipenv/vendor/tomlkit/__init__.py b/pipenv/vendor/tomlkit/__init__.py
index be5c373f..ab126006 100644
--- a/pipenv/vendor/tomlkit/__init__.py
+++ b/pipenv/vendor/tomlkit/__init__.py
@@ -22,4 +22,4 @@ from .api import value
 from .api import ws
 
 
-__version__ = "0.5.8"
+__version__ = "0.5.11"
diff --git a/pipenv/vendor/tomlkit/container.py b/pipenv/vendor/tomlkit/container.py
index b4e7cf2c..4b15b365 100644
--- a/pipenv/vendor/tomlkit/container.py
+++ b/pipenv/vendor/tomlkit/container.py
@@ -15,6 +15,9 @@ from .items import Whitespace
 from .items import item as _item
 
 
+_NOT_SET = object()
+
+
 class Container(dict):
     """
     A container for items within a TOMLDocument.
@@ -498,6 +501,19 @@ class Container(dict):
 
         return self[key]
 
+    def pop(self, key, default=_NOT_SET):
+        try:
+            value = self[key]
+        except KeyError:
+            if default is _NOT_SET:
+                raise
+
+            return default
+
+        del self[key]
+
+        return value
+
     def setdefault(
         self, key, default=None
     ):  # type: (Union[Key, str], Any) -> Union[Item, Container]
@@ -521,21 +537,12 @@ class Container(dict):
             raise NonExistentKey(key)
 
         if isinstance(idx, tuple):
-            container = Container(True)
-
-            for i in idx:
-                item = self._body[i][1]
-
-                if isinstance(item, Table):
-                    for k, v in item.value.body:
-                        container.append(k, v)
-                else:
-                    container.append(key, item)
-
-            return container
+            # The item we are getting is an out of order table
+            # so we need a proxy to retrieve the proper objects
+            # from the parent container
+            return OutOfOrderTableProxy(self, idx)
 
         item = self._body[idx][1]
-
         if item.is_boolean():
             return item.value
 
@@ -568,6 +575,9 @@ class Container(dict):
     def _replace_at(
         self, idx, new_key, value
     ):  # type: (Union[int, Tuple[int]], Union[Key, str], Item) -> None
+        if not isinstance(new_key, Key):
+            new_key = Key(new_key)
+
         if isinstance(idx, tuple):
             for i in idx[1:]:
                 self._body[i] = (None, Null())
@@ -577,6 +587,8 @@ class Container(dict):
         k, v = self._body[idx]
 
         self._map[new_key] = self._map.pop(k)
+        if new_key != k:
+            super(Container, self).__delitem__(k)
 
         if isinstance(self._map[new_key], tuple):
             self._map[new_key] = self._map[new_key][0]
@@ -637,3 +649,99 @@ class Container(dict):
         c._map.update(self._map)
 
         return c
+
+
+class OutOfOrderTableProxy(dict):
+    def __init__(self, container, indices):  # type: (Container, Tuple) -> None
+        self._container = container
+        self._internal_container = Container(self._container.parsing)
+        self._tables = []
+        self._tables_map = {}
+        self._map = {}
+
+        for i in indices:
+            key, item = self._container._body[i]
+
+            if isinstance(item, Table):
+                self._tables.append(item)
+                table_idx = len(self._tables) - 1
+                for k, v in item.value.body:
+                    self._internal_container.append(k, v)
+                    self._tables_map[k] = table_idx
+            else:
+                self._internal_container.append(key, item)
+                self._map[key] = i
+
+    def __getitem__(self, key):  # type: (Union[Key, str]) -> Any
+        if key not in self._internal_container:
+            raise NonExistentKey(key)
+
+        return self._internal_container[key]
+
+    def __setitem__(self, key, item):  # type: (Union[Key, str], Any) -> None
+        if key in self._map:
+            idx = self._map[key]
+            self._container._replace_at(idx, key, item)
+        elif key in self._tables_map:
+            table = self._tables[self._tables_map[key]]
+            table[key] = item
+        elif self._tables:
+            table = self._tables[0]
+            table[key] = item
+        else:
+            self._container[key] = item
+
+    def __delitem__(self, key):  # type: (Union[Key, str]) -> None
+        if key in self._map:
+            idx = self._map[key]
+            del self._container[key]
+            del self._map[key]
+        elif key in self._tables_map:
+            table = self._tables[self._tables_map[key]]
+            del table[key]
+            del self._tables_map[key]
+        else:
+            raise NonExistentKey(key)
+
+        del self._internal_container[key]
+
+    def keys(self):
+        return self._internal_container.keys()
+
+    def values(self):
+        return self._internal_container.values()
+
+    def items(self):  # type: () -> Generator[Item]
+        return self._internal_container.items()
+
+    def update(self, other):  # type: (Dict) -> None
+        self._internal_container.update(other)
+
+    def get(self, key, default=None):  # type: (Any, Optional[Any]) -> Any
+        return self._internal_container.get(key, default=default)
+
+    def pop(self, key, default=_NOT_SET):
+        return self._internal_container.pop(key, default=default)
+
+    def setdefault(
+        self, key, default=None
+    ):  # type: (Union[Key, str], Any) -> Union[Item, Container]
+        return self._internal_container.setdefault(key, default=default)
+
+    def __contains__(self, key):
+        return key in self._internal_container
+
+    def __str__(self):
+        return str(self._internal_container)
+
+    def __repr__(self):
+        return repr(self._internal_container)
+
+    def __eq__(self, other):  # type: (Dict) -> bool
+        if not isinstance(other, dict):
+            return NotImplemented
+
+        return self._internal_container == other
+
+    def __getattr__(self, attribute):
+        return getattr(self._internal_container, attribute)
diff --git a/pipenv/vendor/tomlkit/items.py b/pipenv/vendor/tomlkit/items.py
index 6588cda9..309fe1d8 100644
--- a/pipenv/vendor/tomlkit/items.py
+++ b/pipenv/vendor/tomlkit/items.py
@@ -36,6 +36,7 @@ def item(value, _parent=None):
     elif isinstance(value, float):
         return Float(value, Trivia(), str(value))
     elif isinstance(value, dict):
+        val = Table(Container(), Trivia(), False)
         if isinstance(value, InlineTableDict):
             val = InlineTable(Container(), Trivia())
         else:
diff --git a/pipenv/vendor/tomlkit/parser.py b/pipenv/vendor/tomlkit/parser.py
index 0fb50684..13fd9f98 100644
--- a/pipenv/vendor/tomlkit/parser.py
+++ b/pipenv/vendor/tomlkit/parser.py
@@ -194,7 +194,8 @@ class Parser:
         in_name = False
         current = ""
         t = KeyType.Bare
-        for c in name:
+        parts = 0
+        for c in name.strip():
             c = TOMLChar(c)
 
             if c == ".":
@@ -205,14 +206,20 @@ class Parser:
                 if not current:
                     raise self.parse_error()
 
-                yield Key(current, t=t, sep="")
+                yield Key(current.strip(), t=t, sep="")
+                parts += 1
 
                 current = ""
                 t = KeyType.Bare
                 continue
             elif c in {"'", '"'}:
                 if in_name:
-                    if t == KeyType.Literal and c == '"':
+                    if (
+                        t == KeyType.Literal
+                        and c == '"'
+                        or t == KeyType.Basic
+                        and c == "'"
+                    ):
                         current += c
                         continue
 
@@ -221,17 +228,35 @@ class Parser:
 
                     in_name = False
                 else:
+                    if current and TOMLChar(current[-1]).is_spaces() and not parts:
+                        raise self.parse_error()
+
                     in_name = True
                     t = KeyType.Literal if c == "'" else KeyType.Basic
 
                 continue
             elif in_name or c.is_bare_key_char():
+                if (
+                    not in_name
+                    and current
+                    and TOMLChar(current[-1]).is_spaces()
+                    and not parts
+                ):
+                    raise self.parse_error()
+
                 current += c
+            elif c.is_spaces():
+                # A space is only valid at this point
+                # if it's in between parts.
+                # We store it for now and will check
+                # later if it's valid
+                current += c
+                continue
             else:
                 raise self.parse_error()
 
-        if current:
-            yield Key(current, t=t, sep="")
+        if current.strip():
+            yield Key(current.strip(), t=t, sep="")
 
     def _parse_item(self):  # type: () -> Optional[Tuple[Optional[Key], Item]]
         """
@@ -904,15 +929,46 @@ class Parser:
 
             is_aot = True
 
-        # Key
+        # Consume any whitespace
         self.mark()
-        while self._current != "]" and self.inc():
-            if self.end():
-                raise self.parse_error(UnexpectedEofError)
-
+        while self._current.is_spaces() and self.inc():
             pass
 
-        name = self.extract()
+        ws_prefix = self.extract()
+
+        # Key
+        if self._current in [StringType.SLL.value, StringType.SLB.value]:
+            delimiter = (
+                StringType.SLL
+                if self._current == StringType.SLL.value
+                else StringType.SLB
+            )
+            name = self._parse_string(delimiter)
+            name = "{delimiter}{name}{delimiter}".format(
+                delimiter=delimiter.value, name=name
+            )
+
+            self.mark()
+            while self._current != "]" and self.inc():
+                if self.end():
+                    raise self.parse_error(UnexpectedEofError)
+
+                pass
+
+            ws_suffix = self.extract()
+            name += ws_suffix
+        else:
+            self.mark()
+            while self._current != "]" and self.inc():
+                if self.end():
+                    raise self.parse_error(UnexpectedEofError)
+
+                pass
+
+            name = self.extract()
+
+        name = ws_prefix + name
+
         if not name.strip():
             raise self.parse_error(EmptyTableNameError)
 
diff --git a/pipenv/vendor/tomlkit/toml_char.py b/pipenv/vendor/tomlkit/toml_char.py
index 02c55172..d649a917 100644
--- a/pipenv/vendor/tomlkit/toml_char.py
+++ b/pipenv/vendor/tomlkit/toml_char.py
@@ -4,7 +4,7 @@ from ._compat import PY2
 from ._compat import unicode
 
 if PY2:
-    from pipenv.vendor.backports.functools_lru_cache import lru_cache
+    from functools32 import lru_cache
 else:
     from functools import lru_cache
 
diff --git a/pipenv/vendor/urllib3/__init__.py b/pipenv/vendor/urllib3/__init__.py
index 96474d36..9bd8323f 100644
--- a/pipenv/vendor/urllib3/__init__.py
+++ b/pipenv/vendor/urllib3/__init__.py
@@ -22,7 +22,7 @@ from logging import NullHandler
 
 __author__ = "Andrey Petrov (andrey.petrov@shazow.net)"
 __license__ = "MIT"
-__version__ = "1.25.7"
+__version__ = "1.25.8"
 
 __all__ = (
     "HTTPConnectionPool",
diff --git a/pipenv/vendor/urllib3/connection.py b/pipenv/vendor/urllib3/connection.py
index f5c946ad..71e6790b 100644
--- a/pipenv/vendor/urllib3/connection.py
+++ b/pipenv/vendor/urllib3/connection.py
@@ -251,40 +251,6 @@ class HTTPSConnection(HTTPConnection):
         # HTTPS requests to go out as HTTP. (See Issue #356)
         self._protocol = "https"
 
-    def connect(self):
-        conn = self._new_conn()
-        self._prepare_conn(conn)
-
-        # Wrap socket using verification with the root certs in
-        # trusted_root_certs
-        default_ssl_context = False
-        if self.ssl_context is None:
-            default_ssl_context = True
-            self.ssl_context = create_urllib3_context(
-                ssl_version=resolve_ssl_version(self.ssl_version),
-                cert_reqs=resolve_cert_reqs(self.cert_reqs),
-            )
-
-        # Try to load OS default certs if none are given.
-        # Works well on Windows (requires Python3.4+)
-        context = self.ssl_context
-        if (
-            not self.ca_certs
-            and not self.ca_cert_dir
-            and default_ssl_context
-            and hasattr(context, "load_default_certs")
-        ):
-            context.load_default_certs()
-
-        self.sock = ssl_wrap_socket(
-            sock=conn,
-            keyfile=self.key_file,
-            certfile=self.cert_file,
-            key_password=self.key_password,
-            ssl_context=self.ssl_context,
-            server_hostname=self.server_hostname,
-        )
-
 
 class VerifiedHTTPSConnection(HTTPSConnection):
     """
diff --git a/pipenv/vendor/urllib3/connectionpool.py b/pipenv/vendor/urllib3/connectionpool.py
index 31696460..d42eb7be 100644
--- a/pipenv/vendor/urllib3/connectionpool.py
+++ b/pipenv/vendor/urllib3/connectionpool.py
@@ -996,10 +996,10 @@ class HTTPSConnectionPool(HTTPConnectionPool):
         if not conn.is_verified:
             warnings.warn(
                 (
-                    "Unverified HTTPS request is being made. "
+                    "Unverified HTTPS request is being made to host '%s'. "
                     "Adding certificate verification is strongly advised. See: "
                     "https://urllib3.readthedocs.io/en/latest/advanced-usage.html"
-                    "#ssl-warnings"
+                    "#ssl-warnings" % conn.host
                 ),
                 InsecureRequestWarning,
             )
diff --git a/pipenv/vendor/urllib3/contrib/_appengine_environ.py b/pipenv/vendor/urllib3/contrib/_appengine_environ.py
index 119efaee..8765b907 100644
--- a/pipenv/vendor/urllib3/contrib/_appengine_environ.py
+++ b/pipenv/vendor/urllib3/contrib/_appengine_environ.py
@@ -6,7 +6,7 @@ import os
 
 
 def is_appengine():
-    return "APPENGINE_RUNTIME" in os.environ
+    return is_local_appengine() or is_prod_appengine()
 
 
 def is_appengine_sandbox():
@@ -20,15 +20,15 @@ def is_appengine_sandbox():
 
 
 def is_local_appengine():
-    return is_appengine() and os.environ.get("SERVER_SOFTWARE", "").startswith(
-        "Development/"
-    )
+    return "APPENGINE_RUNTIME" in os.environ and os.environ.get(
+        "SERVER_SOFTWARE", ""
+    ).startswith("Development/")
 
 
 def is_prod_appengine():
-    return is_appengine() and os.environ.get("SERVER_SOFTWARE", "").startswith(
-        "Google App Engine/"
-    )
+    return "APPENGINE_RUNTIME" in os.environ and os.environ.get(
+        "SERVER_SOFTWARE", ""
+    ).startswith("Google App Engine/")
 
 
 def is_prod_appengine_mvms():
diff --git a/pipenv/vendor/urllib3/response.py b/pipenv/vendor/urllib3/response.py
index adc321e7..6090a735 100644
--- a/pipenv/vendor/urllib3/response.py
+++ b/pipenv/vendor/urllib3/response.py
@@ -792,7 +792,7 @@ class HTTPResponse(io.IOBase):
             return self._request_url
 
     def __iter__(self):
-        buffer = [b""]
+        buffer = []
         for chunk in self.stream(decode_content=True):
             if b"\n" in chunk:
                 chunk = chunk.split(b"\n")
diff --git a/pipenv/vendor/urllib3/util/ssl_.py b/pipenv/vendor/urllib3/util/ssl_.py
index 8495b775..5b363d7f 100644
--- a/pipenv/vendor/urllib3/util/ssl_.py
+++ b/pipenv/vendor/urllib3/util/ssl_.py
@@ -182,7 +182,7 @@ def resolve_cert_reqs(candidate):
     """
     Resolves the argument to a numeric constant, which can be passed to
     the wrap_socket function/method from the ssl module.
-    Defaults to :data:`ssl.CERT_NONE`.
+    Defaults to :data:`ssl.CERT_REQUIRED`.
     If given a string it is assumed to be the name of the constant in the
     :mod:`ssl` module or its abbreviation.
     (So you can specify `REQUIRED` instead of `CERT_REQUIRED`.
diff --git a/pipenv/vendor/urllib3/util/url.py b/pipenv/vendor/urllib3/util/url.py
index f7568e9d..8ef5a231 100644
--- a/pipenv/vendor/urllib3/util/url.py
+++ b/pipenv/vendor/urllib3/util/url.py
@@ -216,18 +216,15 @@ def _encode_invalid_chars(component, allowed_chars, encoding="utf-8"):
 
     component = six.ensure_text(component)
 
+    # Normalize existing percent-encoded bytes.
     # Try to see if the component we're encoding is already percent-encoded
     # so we can skip all '%' characters but still encode all others.
-    percent_encodings = PERCENT_RE.findall(component)
-
-    # Normalize existing percent-encoded bytes.
-    for enc in percent_encodings:
-        if not enc.isupper():
-            component = component.replace(enc, enc.upper())
+    component, percent_encodings = PERCENT_RE.subn(
+        lambda match: match.group(0).upper(), component
+    )
 
     uri_bytes = component.encode("utf-8", "surrogatepass")
-    is_percent_encoded = len(percent_encodings) == uri_bytes.count(b"%")
-
+    is_percent_encoded = percent_encodings == uri_bytes.count(b"%")
     encoded_component = bytearray()
 
     for i in range(0, len(uri_bytes)):
@@ -237,7 +234,7 @@ def _encode_invalid_chars(component, allowed_chars, encoding="utf-8"):
         if (is_percent_encoded and byte == b"%") or (
             byte_ord < 128 and byte.decode() in allowed_chars
         ):
-            encoded_component.extend(byte)
+            encoded_component += byte
             continue
         encoded_component.extend(b"%" + (hex(byte_ord)[2:].encode().zfill(2).upper()))
 
@@ -322,9 +319,6 @@ def _idna_encode(name):
 
 def _encode_target(target):
     """Percent-encodes a request target so that there are no invalid characters"""
-    if not target.startswith("/"):
-        return target
-
     path, query = TARGET_RE.match(target).groups()
     target = _encode_invalid_chars(path, PATH_CHARS)
     query = _encode_invalid_chars(query, QUERY_CHARS)
diff --git a/pipenv/vendor/vistir/__init__.py b/pipenv/vendor/vistir/__init__.py
index 53c1dc43..fe78c8d5 100644
--- a/pipenv/vendor/vistir/__init__.py
+++ b/pipenv/vendor/vistir/__init__.py
@@ -36,7 +36,7 @@ from .misc import (
 from .path import create_tracked_tempdir, create_tracked_tempfile, mkdir_p, rmtree
 from .spin import create_spinner
 
-__version__ = "0.5.1"
+__version__ = "0.5.0"
 
 
 __all__ = [
diff --git a/tasks/vendoring/patches/patched/piptools.patch b/tasks/vendoring/patches/patched/piptools.patch
index cb6ffab1..dba36098 100644
--- a/tasks/vendoring/patches/patched/piptools.patch
+++ b/tasks/vendoring/patches/patched/piptools.patch
@@ -247,7 +247,7 @@ index acbd680..4bd3e22 100644
 +
 +    def _get_file_hash(self, location):
 +        h = hashlib.new(FAVORITE_HASH)
-+        with open_local_or_remote_file(location, self.session) as fp:
++        with open_local_or_remote_file(location, self.session) as (fp, size):
 +            for chunk in iter(lambda: fp.read(8096), b""):
 +                h.update(chunk)
 +        return ":".join([FAVORITE_HASH, h.hexdigest()])
