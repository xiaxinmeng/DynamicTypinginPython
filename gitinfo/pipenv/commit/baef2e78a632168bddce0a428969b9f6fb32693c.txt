commit baef2e78a632168bddce0a428969b9f6fb32693c
Author: Dan Ryan <dan@danryan.co>
Date:   Fri Oct 19 20:57:20 2018 -0400

    Upgrade vendored dependencies
    
    - Upgrade pythonfinder
    - Upgrade vistir
    - Upgrade requirementslib
    - Vendor backported version of `functools.lru_cache` for performance
    - Fix editable dependency installation when markers are present
    - Fix extraneous resource warnings
    - Fix filesystem output stream encoding issues
    - Fix pythonfinder non-standard python name issues
    - Provide full interaction layer to `Pipfile` and `Pipfile.lock` in
      requirementslib
    - Fixes #3017
    - Fixes #3014
    - Fixes #3021
    - Fixes #3019
    
    Signed-off-by: Dan Ryan <dan@danryan.co>
    
    Update vendored dependencies
    
    - Update shellingham, tomlkit, requests, urllib3, certifi, vistir and
      parse
    - Fixes #2820
    - Fixes #2852
    
    Signed-off-by: Dan Ryan <dan@danryan.co>
    
    Cleanup old vendored dependencies
    
    Signed-off-by: Dan Ryan <dan@danryan.co>

diff --git a/pipenv/environments.py b/pipenv/environments.py
index 4bfd937d..e6de4f0d 100644
--- a/pipenv/environments.py
+++ b/pipenv/environments.py
@@ -8,6 +8,8 @@ from .vendor.vistir.misc import fs_str
 # I hope I can remove this one day.
 os.environ["PYTHONDONTWRITEBYTECODE"] = fs_str("1")
 
+PIPENV_IS_CI = bool("CI" in os.environ or "TF_BUILD" in os.environ)
+
 # HACK: Prevent invalid shebangs with Homebrew-installed Python:
 # https://bugs.python.org/issue22490
 os.environ.pop("__PYVENV_LAUNCHER__", None)
@@ -68,7 +70,7 @@ PIPENV_HIDE_EMOJIS = bool(os.environ.get("PIPENV_HIDE_EMOJIS"))
 
 Default is to show emojis. This is automatically set on Windows.
 """
-if os.name == "nt":
+if os.name == "nt" or PIPENV_IS_CI:
     PIPENV_HIDE_EMOJIS = True
 
 PIPENV_IGNORE_VIRTUALENVS = bool(os.environ.get("PIPENV_IGNORE_VIRTUALENVS"))
@@ -94,7 +96,7 @@ Default is 3. See also ``PIPENV_NO_INHERIT``.
 
 PIPENV_MAX_RETRIES = int(os.environ.get(
     "PIPENV_MAX_RETRIES",
-    "1" if "CI" in os.environ else "0",
+    "1" if PIPENV_IS_CI else "0",
 ))
 """Specify how many retries Pipenv should attempt for network requests.
 
@@ -128,9 +130,18 @@ PIPENV_NOSPIN = bool(os.environ.get("PIPENV_NOSPIN"))
 This can make the logs cleaner. Automatically set on Windows, and in CI
 environments.
 """
-if os.name == "nt" or "CI" in os.environ:
+if PIPENV_IS_CI:
     PIPENV_NOSPIN = True
 
+PIPENV_SPINNER = "dots"
+"""Sets the default spinner type.
+
+Spinners are identitcal to the node.js spinners and can be found at
+https://github.com/sindresorhus/cli-spinners
+"""
+if os.name == "nt":
+    PIPENV_SPINNER = "bouncingBar"
+
 PIPENV_PIPFILE = os.environ.get("PIPENV_PIPFILE")
 """If set, this specifies a custom Pipfile location.
 
diff --git a/pipenv/resolver.py b/pipenv/resolver.py
index 6526d990..8c282b71 100644
--- a/pipenv/resolver.py
+++ b/pipenv/resolver.py
@@ -80,7 +80,6 @@ def main():
         if pypi_mirror_source
         else project.pipfile_sources
     )
-    print("using sources: %s" % sources)
     results = resolve(
         packages,
         pre=do_pre,
diff --git a/pipenv/vendor/backports/functools_lru_cache.LICENSE b/pipenv/vendor/backports/functools_lru_cache.LICENSE
new file mode 100644
index 00000000..5e795a61
--- /dev/null
+++ b/pipenv/vendor/backports/functools_lru_cache.LICENSE
@@ -0,0 +1,7 @@
+Copyright Jason R. Coombs
+
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
diff --git a/pipenv/vendor/backports/functools_lru_cache.py b/pipenv/vendor/backports/functools_lru_cache.py
new file mode 100644
index 00000000..707c6c76
--- /dev/null
+++ b/pipenv/vendor/backports/functools_lru_cache.py
@@ -0,0 +1,184 @@
+from __future__ import absolute_import
+
+import functools
+from collections import namedtuple
+from threading import RLock
+
+_CacheInfo = namedtuple("CacheInfo", ["hits", "misses", "maxsize", "currsize"])
+
+
+@functools.wraps(functools.update_wrapper)
+def update_wrapper(wrapper,
+                   wrapped,
+                   assigned = functools.WRAPPER_ASSIGNMENTS,
+                   updated = functools.WRAPPER_UPDATES):
+    """
+    Patch two bugs in functools.update_wrapper.
+    """
+    # workaround for http://bugs.python.org/issue3445
+    assigned = tuple(attr for attr in assigned if hasattr(wrapped, attr))
+    wrapper = functools.update_wrapper(wrapper, wrapped, assigned, updated)
+    # workaround for https://bugs.python.org/issue17482
+    wrapper.__wrapped__ = wrapped
+    return wrapper
+
+
+class _HashedSeq(list):
+    __slots__ = 'hashvalue'
+
+    def __init__(self, tup, hash=hash):
+        self[:] = tup
+        self.hashvalue = hash(tup)
+
+    def __hash__(self):
+        return self.hashvalue
+
+
+def _make_key(args, kwds, typed,
+              kwd_mark=(object(),),
+              fasttypes=set([int, str, frozenset, type(None)]),
+              sorted=sorted, tuple=tuple, type=type, len=len):
+    'Make a cache key from optionally typed positional and keyword arguments'
+    key = args
+    if kwds:
+        sorted_items = sorted(kwds.items())
+        key += kwd_mark
+        for item in sorted_items:
+            key += item
+    if typed:
+        key += tuple(type(v) for v in args)
+        if kwds:
+            key += tuple(type(v) for k, v in sorted_items)
+    elif len(key) == 1 and type(key[0]) in fasttypes:
+        return key[0]
+    return _HashedSeq(key)
+
+
+def lru_cache(maxsize=100, typed=False):
+    """Least-recently-used cache decorator.
+
+    If *maxsize* is set to None, the LRU features are disabled and the cache
+    can grow without bound.
+
+    If *typed* is True, arguments of different types will be cached separately.
+    For example, f(3.0) and f(3) will be treated as distinct calls with
+    distinct results.
+
+    Arguments to the cached function must be hashable.
+
+    View the cache statistics named tuple (hits, misses, maxsize, currsize) with
+    f.cache_info().  Clear the cache and statistics with f.cache_clear().
+    Access the underlying function with f.__wrapped__.
+
+    See:  http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used
+
+    """
+
+    # Users should only access the lru_cache through its public API:
+    #       cache_info, cache_clear, and f.__wrapped__
+    # The internals of the lru_cache are encapsulated for thread safety and
+    # to allow the implementation to change (including a possible C version).
+
+    def decorating_function(user_function):
+
+        cache = dict()
+        stats = [0, 0]                  # make statistics updateable non-locally
+        HITS, MISSES = 0, 1             # names for the stats fields
+        make_key = _make_key
+        cache_get = cache.get           # bound method to lookup key or return None
+        _len = len                      # localize the global len() function
+        lock = RLock()                  # because linkedlist updates aren't threadsafe
+        root = []                       # root of the circular doubly linked list
+        root[:] = [root, root, None, None]      # initialize by pointing to self
+        nonlocal_root = [root]                  # make updateable non-locally
+        PREV, NEXT, KEY, RESULT = 0, 1, 2, 3    # names for the link fields
+
+        if maxsize == 0:
+
+            def wrapper(*args, **kwds):
+                # no caching, just do a statistics update after a successful call
+                result = user_function(*args, **kwds)
+                stats[MISSES] += 1
+                return result
+
+        elif maxsize is None:
+
+            def wrapper(*args, **kwds):
+                # simple caching without ordering or size limit
+                key = make_key(args, kwds, typed)
+                result = cache_get(key, root)   # root used here as a unique not-found sentinel
+                if result is not root:
+                    stats[HITS] += 1
+                    return result
+                result = user_function(*args, **kwds)
+                cache[key] = result
+                stats[MISSES] += 1
+                return result
+
+        else:
+
+            def wrapper(*args, **kwds):
+                # size limited caching that tracks accesses by recency
+                key = make_key(args, kwds, typed) if kwds or typed else args
+                with lock:
+                    link = cache_get(key)
+                    if link is not None:
+                        # record recent use of the key by moving it to the front of the list
+                        root, = nonlocal_root
+                        link_prev, link_next, key, result = link
+                        link_prev[NEXT] = link_next
+                        link_next[PREV] = link_prev
+                        last = root[PREV]
+                        last[NEXT] = root[PREV] = link
+                        link[PREV] = last
+                        link[NEXT] = root
+                        stats[HITS] += 1
+                        return result
+                result = user_function(*args, **kwds)
+                with lock:
+                    root, = nonlocal_root
+                    if key in cache:
+                        # getting here means that this same key was added to the
+                        # cache while the lock was released.  since the link
+                        # update is already done, we need only return the
+                        # computed result and update the count of misses.
+                        pass
+                    elif _len(cache) >= maxsize:
+                        # use the old root to store the new key and result
+                        oldroot = root
+                        oldroot[KEY] = key
+                        oldroot[RESULT] = result
+                        # empty the oldest link and make it the new root
+                        root = nonlocal_root[0] = oldroot[NEXT]
+                        oldkey = root[KEY]
+                        root[KEY] = root[RESULT] = None
+                        # now update the cache dictionary for the new links
+                        del cache[oldkey]
+                        cache[key] = oldroot
+                    else:
+                        # put result in a new link at the front of the list
+                        last = root[PREV]
+                        link = [last, root, key, result]
+                        last[NEXT] = root[PREV] = cache[key] = link
+                    stats[MISSES] += 1
+                return result
+
+        def cache_info():
+            """Report cache statistics"""
+            with lock:
+                return _CacheInfo(stats[HITS], stats[MISSES], maxsize, len(cache))
+
+        def cache_clear():
+            """Clear the cache and cache statistics"""
+            with lock:
+                cache.clear()
+                root = nonlocal_root[0]
+                root[:] = [root, root, None, None]
+                stats[:] = [0, 0]
+
+        wrapper.__wrapped__ = user_function
+        wrapper.cache_info = cache_info
+        wrapper.cache_clear = cache_clear
+        return update_wrapper(wrapper, user_function)
+
+    return decorating_function
diff --git a/pipenv/vendor/certifi/__init__.py b/pipenv/vendor/certifi/__init__.py
index aa329fbb..50f2e130 100644
--- a/pipenv/vendor/certifi/__init__.py
+++ b/pipenv/vendor/certifi/__init__.py
@@ -1,3 +1,3 @@
 from .core import where, old_where
 
-__version__ = "2018.08.24"
+__version__ = "2018.10.15"
diff --git a/pipenv/vendor/certifi/cacert.pem b/pipenv/vendor/certifi/cacert.pem
index 85de024e..e75d85b3 100644
--- a/pipenv/vendor/certifi/cacert.pem
+++ b/pipenv/vendor/certifi/cacert.pem
@@ -326,36 +326,6 @@ OCiNUW7dFGdTbHFcJoRNdVq2fmBWqU2t+5sel/MN2dKXVHfaPRK34B7vCAas+YWH
 QMAJKOSLakhT2+zNVVXxxvjpoixMptEmX36vWkzaH6byHCx+rgIW0lbQL1dTR+iS
 -----END CERTIFICATE-----
 
-# Issuer: CN=Visa eCommerce Root O=VISA OU=Visa International Service Association
-# Subject: CN=Visa eCommerce Root O=VISA OU=Visa International Service Association
-# Label: "Visa eCommerce Root"
-# Serial: 25952180776285836048024890241505565794
-# MD5 Fingerprint: fc:11:b8:d8:08:93:30:00:6d:23:f9:7e:eb:52:1e:02
-# SHA1 Fingerprint: 70:17:9b:86:8c:00:a4:fa:60:91:52:22:3f:9f:3e:32:bd:e0:05:62
-# SHA256 Fingerprint: 69:fa:c9:bd:55:fb:0a:c7:8d:53:bb:ee:5c:f1:d5:97:98:9f:d0:aa:ab:20:a2:51:51:bd:f1:73:3e:e7:d1:22
------BEGIN CERTIFICATE-----
-MIIDojCCAoqgAwIBAgIQE4Y1TR0/BvLB+WUF1ZAcYjANBgkqhkiG9w0BAQUFADBr
-MQswCQYDVQQGEwJVUzENMAsGA1UEChMEVklTQTEvMC0GA1UECxMmVmlzYSBJbnRl
-cm5hdGlvbmFsIFNlcnZpY2UgQXNzb2NpYXRpb24xHDAaBgNVBAMTE1Zpc2EgZUNv
-bW1lcmNlIFJvb3QwHhcNMDIwNjI2MDIxODM2WhcNMjIwNjI0MDAxNjEyWjBrMQsw
-CQYDVQQGEwJVUzENMAsGA1UEChMEVklTQTEvMC0GA1UECxMmVmlzYSBJbnRlcm5h
-dGlvbmFsIFNlcnZpY2UgQXNzb2NpYXRpb24xHDAaBgNVBAMTE1Zpc2EgZUNvbW1l
-cmNlIFJvb3QwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCvV95WHm6h
-2mCxlCfLF9sHP4CFT8icttD0b0/Pmdjh28JIXDqsOTPHH2qLJj0rNfVIsZHBAk4E
-lpF7sDPwsRROEW+1QK8bRaVK7362rPKgH1g/EkZgPI2h4H3PVz4zHvtH8aoVlwdV
-ZqW1LS7YgFmypw23RuwhY/81q6UCzyr0TP579ZRdhE2o8mCP2w4lPJ9zcc+U30rq
-299yOIzzlr3xF7zSujtFWsan9sYXiwGd/BmoKoMWuDpI/k4+oKsGGelT84ATB+0t
-vz8KPFUgOSwsAGl0lUq8ILKpeeUYiZGo3BxN77t+Nwtd/jmliFKMAGzsGHxBvfaL
-dXe6YJ2E5/4tAgMBAAGjQjBAMA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQD
-AgEGMB0GA1UdDgQWBBQVOIMPPyw/cDMezUb+B4wg4NfDtzANBgkqhkiG9w0BAQUF
-AAOCAQEAX/FBfXxcCLkr4NWSR/pnXKUTwwMhmytMiUbPWU3J/qVAtmPN3XEolWcR
-zCSs00Rsca4BIGsDoo8Ytyk6feUWYFN4PMCvFYP3j1IzJL1kk5fui/fbGKhtcbP3
-LBfQdCVp9/5rPJS+TUtBjE7ic9DjkCJzQ83z7+pzzkWKsKZJ/0x9nXGIxHYdkFsd
-7v3M9+79YKWxehZx0RbQfBI8bGmX265fOZpwLwU8GUYEmSA20GBuYQa7FkKMcPcw
-++DbZqMAAb3mLNqRX6BGi01qnD093QVG/na/oAo85ADmJ7f/hC3euiInlhBx6yLt
-398znM/jra6O1I7mT1GvFpLgXPYHDw==
------END CERTIFICATE-----
-
 # Issuer: CN=AAA Certificate Services O=Comodo CA Limited
 # Subject: CN=AAA Certificate Services O=Comodo CA Limited
 # Label: "Comodo AAA Services root"
diff --git a/pipenv/vendor/cursor/LICENSE b/pipenv/vendor/cursor/LICENSE
new file mode 100644
index 00000000..00023c80
--- /dev/null
+++ b/pipenv/vendor/cursor/LICENSE
@@ -0,0 +1,5 @@
+This work is licensed under the Creative Commons
+Attribution-ShareAlike 2.5 International License. To view a copy of 
+this license, visit http://creativecommons.org/licenses/by-sa/2.5/ or
+send a letter to Creative Commons, PO Box 1866, Mountain View, 
+CA 94042, USA.
diff --git a/pipenv/vendor/cursor/__init__.py b/pipenv/vendor/cursor/__init__.py
new file mode 100644
index 00000000..76a4f671
--- /dev/null
+++ b/pipenv/vendor/cursor/__init__.py
@@ -0,0 +1,4 @@
+from .cursor import hide, show, HiddenCursor
+
+__all__ = ["hide", "show", "HiddenCursor"]
+
diff --git a/pipenv/vendor/cursor/cursor.py b/pipenv/vendor/cursor/cursor.py
new file mode 100644
index 00000000..e4407c02
--- /dev/null
+++ b/pipenv/vendor/cursor/cursor.py
@@ -0,0 +1,57 @@
+#!/usr/bin/env python2
+# -*- coding: utf-8 -*-
+
+## Author:          James Spencer: http://stackoverflow.com/users/1375885/james-spencer
+## Packager:        Gijs TImmers:  https://github.com/GijsTimmers
+
+## Based on James Spencer's answer on StackOverflow: 
+## http://stackoverflow.com/questions/5174810/how-to-turn-off-blinking-cursor-in-command-window
+
+## Licence:         CC-BY-SA-2.5
+##                  http://creativecommons.org/licenses/by-sa/2.5/
+
+## This work is licensed under the Creative Commons
+## Attribution-ShareAlike 2.5 International License. To  view a copy of
+## this license, visit http://creativecommons.org/licenses/by-sa/2.5/ or
+## send a letter to Creative Commons, PO Box 1866, Mountain View,
+## CA 94042, USA.
+
+import sys
+import os
+
+if os.name == 'nt':
+    import ctypes
+
+    class _CursorInfo(ctypes.Structure):
+        _fields_ = [("size", ctypes.c_int),
+                    ("visible", ctypes.c_byte)]
+
+def hide(stream=sys.stdout):
+    if os.name == 'nt':
+        ci = _CursorInfo()
+        handle = ctypes.windll.kernel32.GetStdHandle(-11)
+        ctypes.windll.kernel32.GetConsoleCursorInfo(handle, ctypes.byref(ci))
+        ci.visible = False
+        ctypes.windll.kernel32.SetConsoleCursorInfo(handle, ctypes.byref(ci))
+    elif os.name == 'posix':
+        stream.write("\033[?25l")
+        stream.flush()
+
+def show(stream=sys.stdout):
+    if os.name == 'nt':
+        ci = _CursorInfo()
+        handle = ctypes.windll.kernel32.GetStdHandle(-11)
+        ctypes.windll.kernel32.GetConsoleCursorInfo(handle, ctypes.byref(ci))
+        ci.visible = True
+        ctypes.windll.kernel32.SetConsoleCursorInfo(handle, ctypes.byref(ci))
+    elif os.name == 'posix':
+        stream.write("\033[?25h")
+        stream.flush()
+        
+class HiddenCursor(object):
+    def __init__(self, stream=sys.stdout):
+        self._stream = stream
+    def __enter__(self):
+        hide(stream=self._stream)
+    def __exit__(self, type, value, traceback):
+        show(stream=self._stream)
\ No newline at end of file
diff --git a/pipenv/vendor/parse.py b/pipenv/vendor/parse.py
index ba58decb..7f9f0786 100644
--- a/pipenv/vendor/parse.py
+++ b/pipenv/vendor/parse.py
@@ -186,6 +186,19 @@ And messing about with alignment:
 Note that the "center" alignment does not test to make sure the value is
 centered - it just strips leading and trailing whitespace.
 
+Width and precision may be used to restrict the size of matched text
+from the input. Width specifies a minimum size and precision specifies
+a maximum. For example:
+
+>>> parse('{:.2}{:.2}', 'look')           # specifying precision
+<Result ('lo', 'ok') {}>
+>>> parse('{:4}{:4}', 'look at that')     # specifying width
+<Result ('look', 'at that') {}>
+>>> parse('{:4}{:.4}', 'look at that')    # specifying both
+<Result ('look at ', 'that') {}>
+>>> parse('{:2d}{:2d}', '0440')           # parsing two contiguous numbers
+<Result (4, 40) {}>
+
 Some notes for the date and time types:
 
 - the presence of the time part is optional (including ISO 8601, starting
@@ -329,6 +342,9 @@ the pattern, the actual match represents the shortest successful match for
 
 **Version history (in brief)**:
 
+- 1.9.0 We now honor precision and width specifiers when parsing numbers
+  and strings, allowing parsing of concatenated elements of fixed width
+  (thanks Julia Signell)
 - 1.8.4 Add LICENSE file at request of packagers.
   Correct handling of AM/PM to follow most common interpretation.
   Correct parsing of hexadecimal that looks like a binary prefix.
@@ -389,7 +405,7 @@ See the end of the source file for the license of use.
 '''
 
 from __future__ import absolute_import
-__version__ = '1.8.4'
+__version__ = '1.9.0'
 
 # yes, I now have two problems
 import re
@@ -977,7 +993,11 @@ class Parser(object):
             self._group_index += 2
             self._type_conversions[group] = lambda s, m: float(s)
         elif type == 'd':
-            s = r'\d+|0[xX][0-9a-fA-F]+|0[bB][01]+|0[oO][0-7]+'
+            if format.get('width'):
+                width = '{1,%s}' % int(format['width'])
+            else:
+                width = '+'
+            s = '\\d{w}|0[xX][0-9a-fA-F]{w}|0[bB][01]{w}|0[oO][0-7]{w}'.format(w=width)
             self._type_conversions[group] = int_convert(10)
         elif type == 'ti':
             s = r'(\d{4}-\d\d-\d\d)((\s+|T)%s)?(Z|\s*[-+]\d\d:?\d\d)?' % \
@@ -1038,6 +1058,13 @@ class Parser(object):
 
         elif type:
             s = r'\%s+' % type
+        elif format.get('precision'):
+            if format.get('width'):
+                s = '.{%s,%s}?' % (format['width'], format['precision'])
+            else:
+                s = '.{1,%s}?' % format['precision']
+        elif format.get('width'):
+            s = '.{%s,}?' % format['width']
         else:
             s = '.+?'
 
@@ -1053,8 +1080,6 @@ class Parser(object):
                 if not fill:
                     fill = '0'
                 s = '%s*' % fill + s
-            elif format['zero']:
-                s = '0*' + s
 
             # allow numbers to be prefixed with a sign
             s = r'[-+ ]?' + s
diff --git a/pipenv/vendor/pythonfinder/__init__.py b/pipenv/vendor/pythonfinder/__init__.py
index 672724b4..9ac6031c 100644
--- a/pipenv/vendor/pythonfinder/__init__.py
+++ b/pipenv/vendor/pythonfinder/__init__.py
@@ -1,6 +1,6 @@
 from __future__ import print_function, absolute_import
 
-__version__ = '1.1.2'
+__version__ = '1.1.3'
 
 # Add NullHandler to "pythonfinder" logger, because Python2's default root
 # logger has no handler and warnings like this would be reported:
diff --git a/pipenv/vendor/pythonfinder/cli.py b/pipenv/vendor/pythonfinder/cli.py
index b5aa7da3..1757c081 100644
--- a/pipenv/vendor/pythonfinder/cli.py
+++ b/pipenv/vendor/pythonfinder/cli.py
@@ -17,7 +17,7 @@ from .pythonfinder import Finder
 @click.option(
     "--version", is_flag=True, default=False, help="Display PythonFinder version."
 )
-@click.option("--ignore-unsupported/--no-unsupported", is_flag=True, default=True, help="Ignore unsupported python versions.")
+@click.option("--ignore-unsupported/--no-unsupported", is_flag=True, default=True, envvar="PYTHONFINDER_IGNORE_UNSUPPORTED", help="Ignore unsupported python versions.")
 @click.version_option(prog_name='pyfinder', version=__version__)
 @click.pass_context
 def cli(ctx, find=False, which=False, findall=False, version=False, ignore_unsupported=True):
@@ -36,7 +36,7 @@ def cli(ctx, find=False, which=False, findall=False, version=False, ignore_unsup
             for v in versions:
                 py = v.py_version
                 click.secho(
-                    "Python: {py.version!s} ({py.architecture!s}) @ {py.comes_from.path!s}".format(
+                    "{py.name!s}: {py.version!s} ({py.architecture!s}) @ {py.comes_from.path!s}".format(
                         py=py
                     ),
                     fg="yellow",
@@ -47,23 +47,21 @@ def cli(ctx, find=False, which=False, findall=False, version=False, ignore_unsup
                 fg="red",
             )
     if find:
-        if any([find.startswith("{0}".format(n)) for n in range(10)]):
-            found = finder.find_python_version(find.strip())
-        else:
-            found = finder.system_path.python_executables
+        click.secho("Searching for python: {0!s}".format(find.strip()), fg="yellow")
+        found = finder.find_python_version(find.strip())
         if found:
-            click.echo("Found Python Version: {0}".format(found), color="white")
+            click.secho("Found python at the following locations:", fg="green")
             sys.exit(0)
         else:
-            click.echo("Failed to find matching executable...")
+            click.secho("Failed to find matching executable...", fg="yellow")
             sys.exit(1)
     elif which:
         found = finder.system_path.which(which.strip())
         if found:
-            click.echo("Found Executable: {0}".format(found), color="white")
+            click.secho("Found Executable: {0}".format(found), fg="white")
             sys.exit(0)
         else:
-            click.echo("Failed to find matching executable...")
+            click.secho("Failed to find matching executable...", fg="yellow")
             sys.exit(1)
     else:
         click.echo("Please provide a command", color="red")
diff --git a/pipenv/vendor/pythonfinder/environment.py b/pipenv/vendor/pythonfinder/environment.py
index 2cdb5fd9..7c69b9fc 100644
--- a/pipenv/vendor/pythonfinder/environment.py
+++ b/pipenv/vendor/pythonfinder/environment.py
@@ -15,3 +15,6 @@ if sys.maxsize > 2 ** 32:
     IS_64BIT_OS = platform.machine() == "AMD64"
 else:
     IS_64BIT_OS = False
+
+
+IGNORE_UNSUPPORTED = bool(os.environ.get("PYTHONFINDER_IGNORE_UNSUPPORTED", False))
diff --git a/pipenv/vendor/pythonfinder/models/mixins.py b/pipenv/vendor/pythonfinder/models/mixins.py
index 8cbd45df..7d406548 100644
--- a/pipenv/vendor/pythonfinder/models/mixins.py
+++ b/pipenv/vendor/pythonfinder/models/mixins.py
@@ -2,12 +2,14 @@
 from __future__ import absolute_import, unicode_literals
 
 import abc
+import attr
 import operator
 import six
 
-from ..utils import KNOWN_EXTS, unnest
+from ..utils import ensure_path, KNOWN_EXTS, unnest
 
 
+@attr.s
 class BasePath(object):
     def which(self, name):
         """Search in this path for an executable.
@@ -33,7 +35,14 @@ class BasePath(object):
         return found
 
     def find_all_python_versions(
-        self, major=None, minor=None, patch=None, pre=None, dev=None, arch=None
+        self,
+        major=None,
+        minor=None,
+        patch=None,
+        pre=None,
+        dev=None,
+        arch=None,
+        name=None,
     ):
         """Search for a specific python version on the path. Return all copies
 
@@ -44,6 +53,7 @@ class BasePath(object):
         :param bool pre: Search for prereleases (default None) - prioritize releases if None
         :param bool dev: Search for devreleases (default None) - prioritize releases if None
         :param str arch: Architecture to include, e.g. '64bit', defaults to None
+        :param str name: The name of a python version, e.g. ``anaconda3-5.3.0``
         :return: A list of :class:`~pythonfinder.models.PathEntry` instances matching the version requested.
         :rtype: List[:class:`~pythonfinder.models.PathEntry`]
         """
@@ -52,7 +62,14 @@ class BasePath(object):
             "find_all_python_versions" if self.is_dir else "find_python_version"
         )
         sub_finder = operator.methodcaller(
-            call_method, major, minor=minor, patch=patch, pre=pre, dev=dev, arch=arch
+            call_method,
+            major=major,
+            minor=minor,
+            patch=patch,
+            pre=pre,
+            dev=dev,
+            arch=arch,
+            name=name,
         )
         if not self.is_dir:
             return sub_finder(self)
@@ -61,7 +78,14 @@ class BasePath(object):
         return [c for c in sorted(path_filter, key=version_sort, reverse=True)]
 
     def find_python_version(
-        self, major=None, minor=None, patch=None, pre=None, dev=None, arch=None
+        self,
+        major=None,
+        minor=None,
+        patch=None,
+        pre=None,
+        dev=None,
+        arch=None,
+        name=None,
     ):
         """Search or self for the specified Python version and return the first match.
 
@@ -72,6 +96,7 @@ class BasePath(object):
         :param bool pre: Search for prereleases (default None) - prioritize releases if None
         :param bool dev: Search for devreleases (default None) - prioritize releases if None
         :param str arch: Architecture to include, e.g. '64bit', defaults to None
+        :param str name: The name of a python version, e.g. ``anaconda3-5.3.0``
         :returns: A :class:`~pythonfinder.models.PathEntry` instance matching the version requested.
         """
 
@@ -83,12 +108,13 @@ class BasePath(object):
             pre=pre,
             dev=dev,
             arch=arch,
+            name=name,
         )
         is_py = operator.attrgetter("is_python")
         py_version = operator.attrgetter("as_python")
         if not self.is_dir:
-            if self.is_python and self.as_python and version_matcher(self.as_python):
-                return self
+            if self.is_python and self.as_python and version_matcher(self.py_version):
+                return attr.evolve(self)
             return
         finder = (
             (child, child.as_python)
diff --git a/pipenv/vendor/pythonfinder/models/path.py b/pipenv/vendor/pythonfinder/models/path.py
index c90d9be3..d54393b6 100644
--- a/pipenv/vendor/pythonfinder/models/path.py
+++ b/pipenv/vendor/pythonfinder/models/path.py
@@ -10,6 +10,7 @@ from collections import defaultdict
 from itertools import chain
 
 import attr
+import six
 
 from cached_property import cached_property
 
@@ -19,8 +20,12 @@ from .mixins import BasePath
 from ..environment import PYENV_INSTALLED, PYENV_ROOT
 from ..exceptions import InvalidPythonVersion
 from ..utils import (
-    ensure_path, filter_pythons, looks_like_python, optional_instance_of,
-    path_is_known_executable, unnest
+    ensure_path,
+    filter_pythons,
+    looks_like_python,
+    optional_instance_of,
+    path_is_known_executable,
+    unnest,
 )
 from .python import PythonVersion
 
@@ -75,7 +80,7 @@ class SystemPath(object):
                     if entry not in self._version_dict[version]:
                         self._version_dict[version].append(entry)
                     continue
-                if isinstance(entry, VersionPath):
+                if type(entry).__name__ == "VersionPath":
                     for path in entry.paths.values():
                         if path not in self._version_dict[version] and path.is_python:
                             self._version_dict[version].append(path)
@@ -130,17 +135,16 @@ class SystemPath(object):
             pyenv_index = self.path_order.index(last_pyenv)
         except ValueError:
             return
-        self.pyenv_finder = PyenvFinder.create(root=PYENV_ROOT, ignore_unsupported=self.ignore_unsupported)
-        # paths = (v.paths.values() for v in self.pyenv_finder.versions.values())
-        root_paths = (
-            p for path in self.pyenv_finder.expanded_paths for p in path if p.is_root
+        self.pyenv_finder = PyenvFinder.create(
+            root=PYENV_ROOT, ignore_unsupported=self.ignore_unsupported
         )
+        root_paths = [p for p in self.pyenv_finder.roots]
         before_path = self.path_order[: pyenv_index + 1]
         after_path = self.path_order[pyenv_index + 2 :]
         self.path_order = (
-            before_path + [p.path.as_posix() for p in root_paths] + after_path
+            before_path + [p.as_posix() for p in root_paths] + after_path
         )
-        self.paths.update({p.path: p for p in root_paths})
+        self.paths.update(self.pyenv_finder.roots)
         self._register_finder("pyenv", self.pyenv_finder)
 
     def _setup_windows(self):
@@ -155,7 +159,9 @@ class SystemPath(object):
 
     def get_path(self, path):
         path = ensure_path(path)
-        _path = self.paths.get(path.as_posix())
+        _path = self.paths.get(path)
+        if not _path:
+            _path = self.paths.get(path.as_posix())
         if not _path and path.as_posix() in self.path_order:
             _path = PathEntry.create(
                 path=path.absolute(), is_root=True, only_python=self.only_python
@@ -163,6 +169,14 @@ class SystemPath(object):
             self.paths[path.as_posix()] = _path
         return _path
 
+    def _get_paths(self):
+        return (self.get_path(k) for k in self.path_order)
+
+    @cached_property
+    def path_entries(self):
+        paths = self._get_paths()
+        return paths
+
     def find_all(self, executable):
         """Search the path for an executable. Return all copies.
 
@@ -171,8 +185,8 @@ class SystemPath(object):
         :returns: List[PathEntry]
         """
         sub_which = operator.methodcaller("which", name=executable)
-        filtered = filter(None, (sub_which(self.get_path(k)) for k in self.path_order))
-        return [f for f in filtered]
+        filtered = (sub_which(self.get_path(k)) for k in self.path_order)
+        return list(filtered)
 
     def which(self, executable):
         """Search for an executable on the path.
@@ -182,11 +196,39 @@ class SystemPath(object):
         :returns: :class:`~pythonfinder.models.PathEntry` object.
         """
         sub_which = operator.methodcaller("which", name=executable)
-        filtered = filter(None, (sub_which(self.get_path(k)) for k in self.path_order))
-        return next((f for f in filtered), None)
+        filtered = (sub_which(self.get_path(k)) for k in self.path_order)
+        return next(iter(f for f in filtered if f is not None), None)
+
+    def _filter_paths(self, finder):
+        return (
+            pth for pth in unnest(finder(p) for p in self.path_entries if p is not None)
+            if pth is not None
+        )
+
+    def _get_all_pythons(self, finder):
+        paths = {p.path.as_posix(): p for p in self._filter_paths(finder)}
+        paths.update(self.python_executables)
+        return (p for p in paths.values() if p is not None)
+
+    def get_pythons(self, finder):
+        sort_key = operator.attrgetter("as_python.version_sort")
+        return (
+            k for k in sorted(
+                (p for p in self._filter_paths(finder) if p.is_python),
+                key=sort_key,
+                reverse=True
+            ) if k is not None
+        )
 
     def find_all_python_versions(
-        self, major=None, minor=None, patch=None, pre=None, dev=None, arch=None
+        self,
+        major=None,
+        minor=None,
+        patch=None,
+        pre=None,
+        dev=None,
+        arch=None,
+        name=None,
     ):
         """Search for a specific python version on the path. Return all copies
 
@@ -197,32 +239,46 @@ class SystemPath(object):
         :param bool pre: Search for prereleases (default None) - prioritize releases if None
         :param bool dev: Search for devreleases (default None) - prioritize releases if None
         :param str arch: Architecture to include, e.g. '64bit', defaults to None
+        :param str name: The name of a python version, e.g. ``anaconda3-5.3.0``
         :return: A list of :class:`~pythonfinder.models.PathEntry` instances matching the version requested.
         :rtype: List[:class:`~pythonfinder.models.PathEntry`]
         """
 
         sub_finder = operator.methodcaller(
             "find_all_python_versions",
-            major,
+            major=major,
             minor=minor,
             patch=patch,
             pre=pre,
             dev=dev,
             arch=arch,
+            name=name,
         )
+        alternate_sub_finder = None
+        if major and not (minor or patch or pre or dev or arch or name):
+            alternate_sub_finder = operator.methodcaller(
+                "find_all_python_versions",
+                major=None,
+                name=major
+            )
         if os.name == "nt" and self.windows_finder:
             windows_finder_version = sub_finder(self.windows_finder)
             if windows_finder_version:
                 return windows_finder_version
-        paths = (self.get_path(k) for k in self.path_order)
-        path_filter = filter(
-            None, unnest((sub_finder(p) for p in paths if p is not None))
-        )
-        version_sort = operator.attrgetter("as_python.version_sort")
-        return [c for c in sorted(path_filter, key=version_sort, reverse=True)]
+        values = list(self.get_pythons(sub_finder))
+        if not values and alternate_sub_finder is not None:
+            values = list(self.get_pythons(alternate_sub_finder))
+        return values
 
     def find_python_version(
-        self, major=None, minor=None, patch=None, pre=None, dev=None, arch=None
+        self,
+        major=None,
+        minor=None,
+        patch=None,
+        pre=None,
+        dev=None,
+        arch=None,
+        name=None,
     ):
         """Search for a specific python version on the path.
 
@@ -233,10 +289,24 @@ class SystemPath(object):
         :param bool pre: Search for prereleases (default None) - prioritize releases if None
         :param bool dev: Search for devreleases (default None) - prioritize releases if None
         :param str arch: Architecture to include, e.g. '64bit', defaults to None
+        :param str name: The name of a python version, e.g. ``anaconda3-5.3.0``
         :return: A :class:`~pythonfinder.models.PathEntry` instance matching the version requested.
         :rtype: :class:`~pythonfinder.models.PathEntry`
         """
 
+        if isinstance(major, six.string_types) and not minor and not patch:
+            # Only proceed if this is in the format "x.y.z" or similar
+            if major.count(".") > 0 and major[0].isdigit():
+                version = major.split(".", 2)
+                if len(version) > 3:
+                    major, minor, patch, rest = version
+                elif len(version) == 3:
+                    major, minor, patch = version
+                else:
+                    major, minor = version
+            else:
+                name = "{0!s}".format(major)
+                major = None
         sub_finder = operator.methodcaller(
             "find_python_version",
             major,
@@ -245,7 +315,15 @@ class SystemPath(object):
             pre=pre,
             dev=dev,
             arch=arch,
+            name=name,
         )
+        alternate_sub_finder = None
+        if major and not (minor or patch or pre or dev or arch or name):
+            alternate_sub_finder = operator.methodcaller(
+                "find_all_python_versions",
+                major=None,
+                name=major
+            )
         if major and minor and patch:
             _tuple_pre = pre if pre is not None else False
             _tuple_dev = dev if dev is not None else False
@@ -255,37 +333,41 @@ class SystemPath(object):
             windows_finder_version = sub_finder(self.windows_finder)
             if windows_finder_version:
                 return windows_finder_version
-        paths = (self.get_path(k) for k in self.path_order)
-        path_filter = filter(None, (sub_finder(p) for p in paths if p is not None))
-        version_sort = operator.attrgetter("as_python.version_sort")
-        ver = next(
-            (c for c in sorted(path_filter, key=version_sort, reverse=True)), None
-        )
+        ver = next(iter(self.get_pythons(sub_finder)), None)
+        if not ver and alternate_sub_finder is not None:
+            ver = next(iter(self.get_pythons(alternate_sub_finder)), None)
         if ver:
             if ver.as_python.version_tuple[:5] in self.python_version_dict:
                 self.python_version_dict[ver.as_python.version_tuple[:5]].append(ver)
             else:
                 self.python_version_dict[ver.as_python.version_tuple[:5]] = [ver]
+            print(ver)
         return ver
 
     @classmethod
-    def create(cls, path=None, system=False, only_python=False, global_search=True, ignore_unsupported=False):
+    def create(
+        cls,
+        path=None,
+        system=False,
+        only_python=False,
+        global_search=True,
+        ignore_unsupported=True,
+    ):
         """Create a new :class:`pythonfinder.models.SystemPath` instance.
 
         :param path: Search path to prepend when searching, defaults to None
         :param path: str, optional
-        :param system: Whether to use the running python by default instead of searching, defaults to False
-        :param system: bool, optional
-        :param only_python: Whether to search only for python executables, defaults to False
-        :param only_python: bool, optional
-        :param ignore_unsupported: Whether to ignore unsupported python versions, if False, an error is raised, defaults to True
-        :param ignore_unsupported: bool, optional
+        :param bool system: Whether to use the running python by default instead of searching, defaults to False
+        :param bool only_python: Whether to search only for python executables, defaults to False
+        :param bool ignore_unsupported: Whether to ignore unsupported python versions, if False, an error is raised, defaults to True
         :return: A new :class:`pythonfinder.models.SystemPath` instance.
         :rtype: :class:`pythonfinder.models.SystemPath`
         """
 
         path_entries = defaultdict(PathEntry)
         paths = []
+        if ignore_unsupported:
+            os.environ["PYTHONFINDER_IGNORE_UNSUPPORTED"] = fs_str("1")
         if global_search:
             paths = os.environ.get("PATH").split(os.pathsep)
         if path:
@@ -316,7 +398,8 @@ class PathEntry(BasePath):
     _children = attr.ib(default=attr.Factory(dict))
     is_root = attr.ib(default=True)
     only_python = attr.ib(default=False)
-    py_version = attr.ib(default=None)
+    name = attr.ib()
+    py_version = attr.ib()
     pythons = attr.ib()
 
     def __str__(self):
@@ -329,17 +412,46 @@ class PathEntry(BasePath):
             children = self.path.iterdir()
         return children
 
+    def _gen_children(self):
+        pass_name = self.name != self.path.name
+        pass_args = {"is_root": False, "only_python": self.only_python}
+        if pass_name:
+            pass_args["name"] = self.name
+
+        if not self.is_dir:
+            yield (self.path.as_posix(), copy.deepcopy(self))
+        elif self.is_root:
+            for child in self._filter_children():
+                yield (child.as_posix(), PathEntry.create(path=child, **pass_args))
+        return
+
     @cached_property
     def children(self):
-        if not self._children and self.is_dir and self.is_root:
-            self._children = {
-                child.as_posix(): PathEntry.create(path=child, is_root=False)
-                for child in self._filter_children()
-            }
-        elif not self.is_dir:
-            self._children = {self.path.as_posix(): self}
+        if not self._children:
+            children = {}
+            for child_key, child_val in self._gen_children():
+                children[child_key] = child_val
+            self._children = children
         return self._children
 
+    @name.default
+    def get_name(self):
+        return self.path.name
+
+    @py_version.default
+    def get_py_version(self):
+        from ..environment import IGNORE_UNSUPPORTED
+        if self.is_dir:
+            return None
+        if self.is_python:
+            from .python import PythonVersion
+            try:
+                py_version = PythonVersion.from_path(path=self, name=self.name)
+            except InvalidPythonVersion:
+                py_version = None
+            return py_version
+        return
+
     @pythons.default
     def get_pythons(self):
         pythons = defaultdict()
@@ -351,56 +463,62 @@ class PathEntry(BasePath):
         else:
             if self.is_python:
                 _path = ensure_path(self.path)
-                pythons[_path.as_posix()] = copy.deepcopy(self)
+                pythons[_path.as_posix()] = self
         return pythons
 
     @cached_property
     def as_python(self):
+        py_version = None
+        if self.py_version:
+            return self.py_version
         if not self.is_dir and self.is_python:
-            if not self.py_version:
-                try:
-                    from .python import PythonVersion
-
-                    self.py_version = PythonVersion.from_path(self.path)
-                except (ValueError, InvalidPythonVersion):
-                    self.py_version = None
-        return self.py_version
+            try:
+                from .python import PythonVersion
+                py_version = PythonVersion.from_path(path=attr.evolve(self), name=self.name)
+            except (ValueError, InvalidPythonVersion):
+                py_version = None
+        return py_version
 
     @classmethod
-    def create(cls, path, is_root=False, only_python=False, pythons=None):
+    def create(cls, path, is_root=False, only_python=False, pythons=None, name=None):
         """Helper method for creating new :class:`pythonfinder.models.PathEntry` instances.
 
-        :param path: Path to the specified location.
-        :type path: str
-        :param is_root: Whether this is a root from the environment PATH variable, defaults to False
-        :param is_root: bool, optional
-        :param only_python: Whether to search only for python executables, defaults to False
-        :param only_python: bool, optional
-        :param pythons: A dictionary of existing python objects (usually from a finder), defaults to None
-        :param pythons: dict, optional
+        :param str path: Path to the specified location.
+        :param bool is_root: Whether this is a root from the environment PATH variable, defaults to False
+        :param bool only_python: Whether to search only for python executables, defaults to False
+        :param dict pythons: A dictionary of existing python objects (usually from a finder), defaults to None
+        :param str name: Name of the python version, e.g. ``anaconda3-5.3.0``
         :return: A new instance of the class.
         :rtype: :class:`pythonfinder.models.PathEntry`
         """
 
         target = ensure_path(path)
-        creation_args = {"path": target, "is_root": is_root, "only_python": only_python}
+        guessed_name = False
+        if not name:
+            guessed_name = True
+            name = target.name
+        creation_args = {"path": target, "is_root": is_root, "only_python": only_python, "name": name}
         if pythons:
             creation_args["pythons"] = pythons
         _new = cls(**creation_args)
         if pythons and only_python:
             children = {}
+            child_creation_args = {
+                "is_root": False,
+                "py_version": python,
+                "only_python": only_python
+            }
+            if not guessed_name:
+                child_creation_args["name"] = name
             for pth, python in pythons.items():
                 pth = ensure_path(pth)
                 children[pth.as_posix()] = PathEntry(
-                    path=pth, is_root=False, only_python=only_python, py_version=python
+                    path=pth,
+                    **child_creation_args
                 )
             _new._children = children
         return _new
 
-    @cached_property
-    def name(self):
-        return self.path.name
-
     @cached_property
     def is_dir(self):
         try:
@@ -416,28 +534,5 @@ class PathEntry(BasePath):
     @cached_property
     def is_python(self):
         return self.is_executable and (
-            self.py_version or looks_like_python(self.path.name)
-        )
-
-
-@attr.s
-class VersionPath(SystemPath):
-    base = attr.ib(default=None, validator=optional_instance_of(Path))
-
-    @classmethod
-    def create(cls, path, only_python=True, pythons=None):
-        """Accepts a path to a base python version directory.
-
-        Generates the pyenv version listings for it"""
-        path = ensure_path(path)
-        path_entries = defaultdict(PathEntry)
-        if not path.name.lower() in ["scripts", "bin"]:
-            bin_name = "Scripts" if os.name == "nt" else "bin"
-            bin_dir = path / bin_name
-        else:
-            bin_dir = path
-        current_entry = PathEntry.create(
-            bin_dir, is_root=True, only_python=True, pythons=pythons
+            looks_like_python(self.path.name)
         )
-        path_entries[bin_dir.as_posix()] = current_entry
-        return cls(base=bin_dir, paths=path_entries)
diff --git a/pipenv/vendor/pythonfinder/models/pyenv.py b/pipenv/vendor/pythonfinder/models/pyenv.py
index 527c5f0a..1595a963 100644
--- a/pipenv/vendor/pythonfinder/models/pyenv.py
+++ b/pipenv/vendor/pythonfinder/models/pyenv.py
@@ -2,6 +2,7 @@
 from __future__ import absolute_import, print_function
 
 import logging
+import operator
 
 from collections import defaultdict
 
@@ -10,9 +11,15 @@ import sysconfig
 
 from vistir.compat import Path
 
-from ..utils import ensure_path, optional_instance_of, get_python_version, filter_pythons
-from .mixins import BaseFinder
-from .path import VersionPath
+from ..utils import (
+    ensure_path,
+    optional_instance_of,
+    get_python_version,
+    filter_pythons,
+    unnest,
+)
+from .mixins import BaseFinder, BasePath
+from .path import SystemPath, PathEntry
 from .python import PythonVersion
 
 
@@ -20,51 +27,66 @@ logger = logging.getLogger(__name__)
 
 
 @attr.s
-class PyenvFinder(BaseFinder):
+class PyenvFinder(BaseFinder, BasePath):
     root = attr.ib(default=None, validator=optional_instance_of(Path))
-    # ignore_unsupported should come before versions, because its value is used
-    # in versions's default initializer.
-    ignore_unsupported = attr.ib(default=False)
+    #: ignore_unsupported should come before versions, because its value is used
+    #: in versions's default initializer.
+    ignore_unsupported = attr.ib(default=True)
+    paths = attr.ib(default=attr.Factory(list))
+    roots = attr.ib(default=attr.Factory(defaultdict))
     versions = attr.ib()
     pythons = attr.ib()
 
+    @property
+    def expanded_paths(self):
+        return (
+            path for path in unnest(p for p in self.versions.values())
+            if path is not None
+        )
+
     @classmethod
-    def version_from_bin_dir(cls, base_dir):
-        pythons = [py for py in filter_pythons(base_dir)]
+    def version_from_bin_dir(cls, base_dir, name=None):
         py_version = None
-        for py in pythons:
-            version = get_python_version(py.as_posix())
-            try:
-                py_version = PythonVersion.parse(version)
-            except Exception:
-                continue
-            if py_version:
-                return py_version
-        return
+        version_path = PathEntry.create(
+            path=base_dir.absolute().as_posix(),
+            only_python=True,
+            name=base_dir.parent.name,
+        )
+        py_version = next(iter(version_path.find_all_python_versions()), None)
+        return py_version
 
     @versions.default
     def get_versions(self):
-        versions = defaultdict(VersionPath)
+        versions = defaultdict()
         bin_ = sysconfig._INSTALL_SCHEMES[sysconfig._get_default_scheme()]["scripts"]
         for p in self.root.glob("versions/*"):
-            if p.parent.name == "envs":
+            if p.parent.name == "envs" or p.name == "envs":
                 continue
+            bin_dir = Path(bin_.format(base=p.as_posix()))
+            version_path = None
+            if bin_dir.exists():
+                version_path = PathEntry.create(
+                    path=bin_dir.absolute().as_posix(),
+                    only_python=False,
+                    name=p.name,
+                    is_root=True,
+                )
+            version = None
             try:
                 version = PythonVersion.parse(p.name)
             except ValueError:
-                bin_dir = Path(bin_.format(base=p.as_posix()))
-                if bin_dir.exists():
-                    version = self.version_from_bin_dir(bin_dir)
-                if not version:
-                    if not self.ignore_unsupported:
-                        raise
-                    continue
+                entry = next(iter(version_path.find_all_python_versions()), None)
+                if not entry:
+                    if self.ignore_unsupported:
+                        continue
+                    raise
+                else:
+                    version = entry.py_version.as_dict()
             except Exception:
                 if not self.ignore_unsupported:
                     raise
                 logger.warning(
-                    'Unsupported Python version %r, ignoring...',
-                    p.name, exc_info=True
+                    "Unsupported Python version %r, ignoring...", p.name, exc_info=True
                 )
                 continue
             if not version:
@@ -75,24 +97,128 @@ class PyenvFinder(BaseFinder):
                 version.get("patch"),
                 version.get("is_prerelease"),
                 version.get("is_devrelease"),
-                version.get("is_debug")
-            )
-            versions[version_tuple] = VersionPath.create(
-                path=p.resolve(), only_python=True
+                version.get("is_debug"),
             )
+            self.roots[p] = version_path
+            versions[version_tuple] = version_path
+            self.paths.append(version_path)
         return versions
 
     @pythons.default
     def get_pythons(self):
         pythons = defaultdict()
-        for v in self.versions.values():
-            for p in v.paths.values():
-                _path = ensure_path(p.path)
-                if p.is_python:
-                    pythons[_path] = p
+        for p in self.paths:
+            pythons.update(p.pythons)
         return pythons
 
     @classmethod
-    def create(cls, root, ignore_unsupported=False):
+    def create(cls, root, ignore_unsupported=True):
         root = ensure_path(root)
         return cls(root=root, ignore_unsupported=ignore_unsupported)
+
+    def find_all_python_versions(
+        self,
+        major=None,
+        minor=None,
+        patch=None,
+        pre=None,
+        dev=None,
+        arch=None,
+        name=None,
+    ):
+        """Search for a specific python version on the path. Return all copies
+
+        :param major: Major python version to search for.
+        :type major: int
+        :param int minor: Minor python version to search for, defaults to None
+        :param int patch: Patch python version to search for, defaults to None
+        :param bool pre: Search for prereleases (default None) - prioritize releases if None
+        :param bool dev: Search for devreleases (default None) - prioritize releases if None
+        :param str arch: Architecture to include, e.g. '64bit', defaults to None
+        :param str name: The name of a python version, e.g. ``anaconda3-5.3.0``
+        :return: A list of :class:`~pythonfinder.models.PathEntry` instances matching the version requested.
+        :rtype: List[:class:`~pythonfinder.models.PathEntry`]
+        """
+
+        version_matcher = operator.methodcaller(
+            "matches",
+            major=major,
+            minor=minor,
+            patch=patch,
+            pre=pre,
+            dev=dev,
+            arch=arch,
+            name=name,
+        )
+        py = operator.attrgetter("as_python")
+        pythons = (
+            py_ver for py_ver in (py(p) for p in self.pythons.values() if p is not None)
+            if py_ver is not None
+        )
+        # pythons = filter(None, [p.as_python for p in self.pythons.values()])
+        matching_versions = filter(lambda py: version_matcher(py), pythons)
+        version_sort = operator.attrgetter("version_sort")
+        return sorted(matching_versions, key=version_sort, reverse=True)
+
+    def find_python_version(
+        self,
+        major=None,
+        minor=None,
+        patch=None,
+        pre=None,
+        dev=None,
+        arch=None,
+        name=None,
+    ):
+        """Search or self for the specified Python version and return the first match.
+
+        :param major: Major version number.
+        :type major: int
+        :param int minor: Minor python version to search for, defaults to None
+        :param int patch: Patch python version to search for, defaults to None
+        :param bool pre: Search for prereleases (default None) - prioritize releases if None
+        :param bool dev: Search for devreleases (default None) - prioritize releases if None
+        :param str arch: Architecture to include, e.g. '64bit', defaults to None
+        :param str name: The name of a python version, e.g. ``anaconda3-5.3.0``
+        :returns: A :class:`~pythonfinder.models.PathEntry` instance matching the version requested.
+        """
+
+        version_matcher = operator.methodcaller(
+            "matches",
+            major=major,
+            minor=minor,
+            patch=patch,
+            pre=pre,
+            dev=dev,
+            arch=arch,
+            name=name,
+        )
+        pythons = filter(None, [p.as_python for p in self.pythons.values()])
+        matching_versions = filter(lambda py: version_matcher(py), pythons)
+        version_sort = operator.attrgetter("version_sort")
+        return next(iter(c for c in sorted(matching_versions, key=version_sort, reverse=True)), None)
+
+
+@attr.s
+class VersionPath(SystemPath):
+    base = attr.ib(default=None, validator=optional_instance_of(Path))
+    name = attr.ib(default=None)
+
+    @classmethod
+    def create(cls, path, only_python=True, pythons=None, name=None):
+        """Accepts a path to a base python version directory.
+
+        Generates the pyenv version listings for it"""
+        path = ensure_path(path)
+        path_entries = defaultdict(PathEntry)
+        bin_ = sysconfig._INSTALL_SCHEMES[sysconfig._get_default_scheme()]["scripts"]
+        if path.as_posix().endswith(Path(bin_).name):
+            path = path.parent
+        bin_dir = ensure_path(bin_.format(base=path.as_posix()))
+        if not name:
+            name = path.name
+        current_entry = PathEntry.create(
+            bin_dir, is_root=True, only_python=True, pythons=pythons, name=name
+        )
+        path_entries[bin_dir.as_posix()] = current_entry
+        return cls(name=name, base=bin_dir, paths=path_entries)
diff --git a/pipenv/vendor/pythonfinder/models/python.py b/pipenv/vendor/pythonfinder/models/python.py
index c71b9d9b..ec99afe7 100644
--- a/pipenv/vendor/pythonfinder/models/python.py
+++ b/pipenv/vendor/pythonfinder/models/python.py
@@ -13,7 +13,11 @@ from packaging.version import parse as parse_version
 
 from ..environment import SYSTEM_ARCH
 from ..utils import (
-    _filter_none, ensure_path, get_python_version, optional_instance_of
+    _filter_none,
+    ensure_path,
+    get_python_version,
+    optional_instance_of,
+    ensure_path,
 )
 
 
@@ -30,6 +34,7 @@ class PythonVersion(object):
     architecture = attr.ib(default=None)
     comes_from = attr.ib(default=None)
     executable = attr.ib(default=None)
+    name = attr.ib(default=None)
 
     @property
     def version_sort(self):
@@ -65,22 +70,37 @@ class PythonVersion(object):
             self.patch,
             self.is_prerelease,
             self.is_devrelease,
-            self.is_debug
+            self.is_debug,
         )
 
     def matches(
-        self, major=None, minor=None, patch=None, pre=False, dev=False, arch=None, debug=False
+        self,
+        major=None,
+        minor=None,
+        patch=None,
+        pre=False,
+        dev=False,
+        arch=None,
+        debug=False,
+        name=None,
     ):
-        if arch and arch.isdigit():
-            arch = "{0}bit".format(arch)
+        if arch:
+            own_arch = self.get_architecture()
+            if arch.isdigit():
+                arch = "{0}bit".format(arch)
         return (
             (major is None or self.major == major)
             and (minor is None or self.minor == minor)
             and (patch is None or self.patch == patch)
             and (pre is None or self.is_prerelease == pre)
             and (dev is None or self.is_devrelease == dev)
-            and (arch is None or self.architecture == arch)
+            and (arch is None or own_arch == arch)
             and (debug is None or self.is_debug == debug)
+            and (
+                name is None
+                or (name and self.name)
+                and (self.name == name or self.name.startswith(name))
+            )
         )
 
     def as_major(self):
@@ -93,6 +113,18 @@ class PythonVersion(object):
         self_dict.update({"patch": None})
         return self.create(**self_dict)
 
+    def as_dict(self):
+        return {
+            "major": self.major,
+            "minor": self.minor,
+            "patch": self.patch,
+            "is_prerelease": self.is_prerelease,
+            "is_postrelease": self.is_postrelease,
+            "is_devrelease": self.is_devrelease,
+            "is_debug": self.is_debug,
+            "version": self.version,
+        }
+
     @classmethod
     def parse(cls, version):
         """Parse a valid version string into a dictionary
@@ -138,8 +170,15 @@ class PythonVersion(object):
             "version": version,
         }
 
+    def get_architecture(self):
+        if self.architecture:
+            return self.architecture
+        arch, _ = platform.architecture(path.path.as_posix())
+        self.architecture = arch
+        return self.architecture
+
     @classmethod
-    def from_path(cls, path):
+    def from_path(cls, path, name=None):
         """Parses a python version from a system path.
 
         Raises:
@@ -147,29 +186,33 @@ class PythonVersion(object):
 
         :param path: A string or :class:`~pythonfinder.models.path.PathEntry`
         :type path: str or :class:`~pythonfinder.models.path.PathEntry` instance
-        :param launcher_entry: A python launcher environment object.
+        :param str name: Name of the python distribution in question
         :return: An instance of a PythonVersion.
         :rtype: :class:`~pythonfinder.models.python.PythonVersion`
         """
 
         from .path import PathEntry
+        from ..environment import IGNORE_UNSUPPORTED
 
         if not isinstance(path, PathEntry):
-            path = PathEntry.create(path, is_root=False, only_python=True)
-        if not path.is_python:
+            path = PathEntry.create(path, is_root=False, only_python=True, name=name)
+        if not path.is_python and not IGNORE_UNSUPPORTED:
             raise ValueError("Not a valid python path: %s" % path.path)
             return
-        py_version = get_python_version(str(path.path))
+        py_version = get_python_version(path.path.as_posix())
         instance_dict = cls.parse(py_version)
-        if not isinstance(instance_dict.get("version"), Version):
+        if not isinstance(instance_dict.get("version"), Version) and not IGNORE_UNSUPPORTED:
             raise ValueError("Not a valid python path: %s" % path.path)
             return
-        architecture, _ = platform.architecture(path.path.as_posix())
-        instance_dict.update({"comes_from": path, "architecture": architecture})
+        if not name:
+            name = path.name
+        instance_dict.update(
+            {"comes_from": path, "name": name}
+        )
         return cls(**instance_dict)
 
     @classmethod
-    def from_windows_launcher(cls, launcher_entry):
+    def from_windows_launcher(cls, launcher_entry, name=None):
         """Create a new PythonVersion instance from a Windows Launcher Entry
 
         :param launcher_entry: A python launcher environment object.
@@ -193,12 +236,14 @@ class PythonVersion(object):
                     launcher_entry.info, "sys_architecture", SYSTEM_ARCH
                 ),
                 "executable": exe_path,
+                "name": name
             }
         )
         py_version = cls.create(**creation_dict)
-        comes_from = PathEntry.create(exe_path, only_python=True)
+        comes_from = PathEntry.create(exe_path, only_python=True, name=name)
         comes_from.py_version = copy.deepcopy(py_version)
         py_version.comes_from = comes_from
+        py_version.name = comes_from.name
         return py_version
 
     @classmethod
diff --git a/pipenv/vendor/pythonfinder/models/windows.py b/pipenv/vendor/pythonfinder/models/windows.py
index fcb4d42a..e47bcc2c 100644
--- a/pipenv/vendor/pythonfinder/models/windows.py
+++ b/pipenv/vendor/pythonfinder/models/windows.py
@@ -22,7 +22,14 @@ class WindowsFinder(BaseFinder):
     pythons = attr.ib()
 
     def find_all_python_versions(
-        self, major=None, minor=None, patch=None, pre=None, dev=None, arch=None
+        self,
+        major=None,
+        minor=None,
+        patch=None,
+        pre=None,
+        dev=None,
+        arch=None,
+        name=None,
     ):
         version_matcher = operator.methodcaller(
             "matches",
@@ -32,6 +39,7 @@ class WindowsFinder(BaseFinder):
             pre=pre,
             dev=dev,
             arch=arch,
+            name=name,
         )
         py_filter = filter(
             None, filter(lambda c: version_matcher(c), self.version_list)
@@ -40,13 +48,26 @@ class WindowsFinder(BaseFinder):
         return [c.comes_from for c in sorted(py_filter, key=version_sort, reverse=True)]
 
     def find_python_version(
-        self, major=None, minor=None, patch=None, pre=None, dev=None, arch=None
+        self,
+        major=None,
+        minor=None,
+        patch=None,
+        pre=None,
+        dev=None,
+        arch=None,
+        name=None,
     ):
         return next(
             (
                 v
                 for v in self.find_all_python_versions(
-                    major=major, minor=minor, patch=patch, pre=pre, dev=dev, arch=arch
+                    major=major,
+                    minor=minor,
+                    patch=patch,
+                    pre=pre,
+                    dev=dev,
+                    arch=arch,
+                    name=None,
                 )
             ),
             None,
@@ -60,7 +81,7 @@ class WindowsFinder(BaseFinder):
         env_versions = pep514env.findall()
         path = None
         for version_object in env_versions:
-            install_path = getattr(version_object.info, 'install_path', None)
+            install_path = getattr(version_object.info, "install_path", None)
             if install_path is None:
                 continue
             path = ensure_path(install_path.__getattr__(""))
diff --git a/pipenv/vendor/pythonfinder/pythonfinder.py b/pipenv/vendor/pythonfinder/pythonfinder.py
index e965bb51..19a52e0a 100644
--- a/pipenv/vendor/pythonfinder/pythonfinder.py
+++ b/pipenv/vendor/pythonfinder/pythonfinder.py
@@ -7,13 +7,13 @@ from .models import SystemPath
 
 
 class Finder(object):
-    def __init__(self, path=None, system=False, global_search=True, ignore_unsupported=False):
+    def __init__(self, path=None, system=False, global_search=True, ignore_unsupported=True):
         """Finder A cross-platform Finder for locating python and other executables.
 
         Searches for python and other specified binaries starting in `path`, if supplied,
         but searching the bin path of `sys.executable` if `system=True`, and then
         searching in the `os.environ['PATH']` if `global_search=True`.  When `global_search`
-        is `False`, this search operation is restricted to the allowed locations of 
+        is `False`, this search operation is restricted to the allowed locations of
         `path` and `system`.
 
         :param path: A bin-directory search location, defaults to None
@@ -57,7 +57,7 @@ class Finder(object):
         return self.system_path.which(exe)
 
     def find_python_version(
-        self, major, minor=None, patch=None, pre=None, dev=None, arch=None
+        self, major=None, minor=None, patch=None, pre=None, dev=None, arch=None, name=None
     ):
         from .models import PythonVersion
 
@@ -69,12 +69,24 @@ class Finder(object):
             and patch is None
         ):
             if arch is None and "-" in major:
-                major, arch = major.rsplit("-", 1)
-                if not arch.isdigit():
-                    major = "{0}-{1}".format(major, arch)
+                orig_string = "{0!s}".format(major)
+                major, _, arch = major.rpartition("-")
+                if arch.startswith("x"):
+                    arch = arch.lstrip("x")
+                if arch.lower().endswith("bit"):
+                    arch = arch.lower().replace("bit", "")
+                if not (arch.isdigit() and (int(arch) & int(arch) - 1) == 0):
+                    major = orig_string
+                    arch = None
                 else:
                     arch = "{0}bit".format(arch)
-            version_dict = PythonVersion.parse(major)
+            try:
+                version_dict = PythonVersion.parse(major)
+            except ValueError:
+                if name is None:
+                    name = "{0!s}".format(major)
+                    major = None
+                version_dict = {}
             major = version_dict.get("major", major)
             minor = version_dict.get("minor", minor)
             patch = version_dict.get("patch", patch)
@@ -83,16 +95,16 @@ class Finder(object):
             arch = version_dict.get("architecture", arch) if arch is None else arch
         if os.name == "nt":
             match = self.windows_finder.find_python_version(
-                major, minor=minor, patch=patch, pre=pre, dev=dev, arch=arch
+                major=major, minor=minor, patch=patch, pre=pre, dev=dev, arch=arch, name=name
             )
             if match:
                 return match
         return self.system_path.find_python_version(
-            major=major, minor=minor, patch=patch, pre=pre, dev=dev, arch=arch
+            major=major, minor=minor, patch=patch, pre=pre, dev=dev, arch=arch, name=name
         )
 
     def find_all_python_versions(
-        self, major=None, minor=None, patch=None, pre=None, dev=None, arch=None
+        self, major=None, minor=None, patch=None, pre=None, dev=None, arch=None, name=None
     ):
         version_sort = operator.attrgetter("as_python.version_sort")
         python_version_dict = getattr(self.system_path, "python_version_dict")
@@ -109,7 +121,7 @@ class Finder(object):
             paths = sorted(paths, key=version_sort, reverse=True)
             return paths
         versions = self.system_path.find_all_python_versions(
-            major=major, minor=minor, patch=patch, pre=pre, dev=dev, arch=arch
+            major=major, minor=minor, patch=patch, pre=pre, dev=dev, arch=arch, name=name
         )
         if not isinstance(versions, list):
             versions = [versions]
diff --git a/pipenv/vendor/pythonfinder/utils.py b/pipenv/vendor/pythonfinder/utils.py
index dced9eab..2f5a860d 100644
--- a/pipenv/vendor/pythonfinder/utils.py
+++ b/pipenv/vendor/pythonfinder/utils.py
@@ -16,10 +16,15 @@ import vistir
 
 from .exceptions import InvalidPythonVersion
 
+try:
+    from functools import lru_cache
+except ImportError:
+    from backports.functools_lru_cache import lru_cache
+
 
 PYTHON_IMPLEMENTATIONS = (
     "python", "ironpython", "jython", "pypy", "anaconda", "miniconda",
-    "stackless", "activepython"
+    "stackless", "activepython", "micropython"
 )
 RULES_BASE = ["*{0}", "*{0}?", "*{0}?.?", "*{0}?.?m"]
 RULES = [rule.format(impl) for impl in PYTHON_IMPLEMENTATIONS for rule in RULES_BASE]
@@ -29,7 +34,17 @@ KNOWN_EXTS = KNOWN_EXTS | set(
     filter(None, os.environ.get("PATHEXT", "").split(os.pathsep))
 )
 
+MATCH_RULES = []
+for rule in RULES:
+    MATCH_RULES.extend(
+        [
+            "{0}.{1}".format(rule, ext) if ext else "{0}".format(rule)
+            for ext in KNOWN_EXTS
+        ]
+    )
+
 
+@lru_cache(maxsize=128)
 def get_python_version(path):
     """Get python version string using subprocess from a given path."""
     version_cmd = [path, "-c", "import sys; print(sys.version.split()[0])"]
@@ -54,6 +69,7 @@ def path_is_executable(path):
     return os.access(str(path), os.X_OK)
 
 
+@lru_cache(maxsize=1024)
 def path_is_known_executable(path):
     return (
         path_is_executable(path)
@@ -62,24 +78,19 @@ def path_is_known_executable(path):
     )
 
 
+@lru_cache(maxsize=1024)
 def looks_like_python(name):
-    match_rules = []
-    for rule in RULES:
-        match_rules.extend(
-            [
-                "{0}.{1}".format(rule, ext) if ext else "{0}".format(rule)
-                for ext in KNOWN_EXTS
-            ]
-        )
     if not any(name.lower().startswith(py_name) for py_name in PYTHON_IMPLEMENTATIONS):
         return False
-    return any(fnmatch(name, rule) for rule in match_rules)
+    return any(fnmatch(name, rule) for rule in MATCH_RULES)
 
 
+@lru_cache(maxsize=128)
 def path_is_python(path):
     return path_is_executable(path) and looks_like_python(path.name)
 
 
+@lru_cache(maxsize=1024)
 def ensure_path(path):
     """Given a path (either a string or a Path object), expand variables and return a Path object.
 
@@ -90,13 +101,9 @@ def ensure_path(path):
     """
 
     if isinstance(path, vistir.compat.Path):
-        path = path.as_posix()
+        return path
     path = vistir.compat.Path(os.path.expandvars(path))
-    try:
-        path = path.resolve()
-    except OSError:
-        path = path.absolute()
-    return path
+    return path.absolute()
 
 
 def _filter_none(k, v):
@@ -105,6 +112,7 @@ def _filter_none(k, v):
     return False
 
 
+@lru_cache(maxsize=128)
 def filter_pythons(path):
     """Return all valid pythons in a given path"""
     if not isinstance(path, vistir.compat.Path):
diff --git a/pipenv/vendor/requirementslib/__init__.py b/pipenv/vendor/requirementslib/__init__.py
index 1f3a2fcb..e0bc6746 100644
--- a/pipenv/vendor/requirementslib/__init__.py
+++ b/pipenv/vendor/requirementslib/__init__.py
@@ -1,5 +1,5 @@
 # -*- coding=utf-8 -*-
-__version__ = '1.1.9'
+__version__ = '1.1.10'
 
 
 from .exceptions import RequirementError
diff --git a/pipenv/vendor/requirementslib/models/lockfile.py b/pipenv/vendor/requirementslib/models/lockfile.py
index f9ca97b8..bd76ca01 100644
--- a/pipenv/vendor/requirementslib/models/lockfile.py
+++ b/pipenv/vendor/requirementslib/models/lockfile.py
@@ -1,17 +1,19 @@
 # -*- coding: utf-8 -*-
 from __future__ import absolute_import
 
-import json
+import copy
 import os
 
+import attr
 import plette.lockfiles
 import six
 
-from vistir.compat import Path
-from vistir.contextmanagers import atomic_open_for_write
+from vistir.compat import Path, FileNotFoundError
 
+from .project import ProjectFile
 from .requirements import Requirement
 
+from .utils import optional_instance_of
 
 DEFAULT_NEWLINES = u"\n"
 
@@ -22,47 +24,125 @@ def preferred_newlines(f):
     return DEFAULT_NEWLINES
 
 
-class Lockfile(plette.lockfiles.Lockfile):
-    def __init__(self, *args, **kwargs):
-        path = kwargs.pop("path", None)
-        self._requirements = kwargs.pop("requirements", [])
-        self._dev_requirements = kwargs.pop("dev_requirements", [])
-        self.path = Path(path) if path else None
-        self.newlines = u"\n"
-        super(Lockfile, self).__init__(*args, **kwargs)
+is_lockfile = optional_instance_of(plette.lockfiles.Lockfile)
+is_projectfile = optional_instance_of(ProjectFile)
+
+
+@attr.s(slots=True)
+class Lockfile(object):
+    path = attr.ib(validator=optional_instance_of(Path), type=Path)
+    _requirements = attr.ib(default=attr.Factory(list), type=list)
+    _dev_requirements = attr.ib(default=attr.Factory(list), type=list)
+    projectfile = attr.ib(validator=is_projectfile, type=ProjectFile)
+    _lockfile = attr.ib(validator=is_lockfile, type=plette.lockfiles.Lockfile)
+    newlines = attr.ib(default=DEFAULT_NEWLINES, type=six.text_type)
+
+    @path.default
+    def _get_path(self):
+        return Path(os.curdir).absolute()
+
+    @projectfile.default
+    def _get_projectfile(self):
+        return self.load_projectfile(self.path)
+
+    @_lockfile.default
+    def _get_lockfile(self):
+        return self.projectfile.lockfile
+
+    def __getattr__(self, k, *args, **kwargs):
+        retval = None
+        lockfile = super(Lockfile, self).__getattribute__("_lockfile")
+        try:
+            return super(Lockfile, self).__getattribute__(k)
+        except AttributeError:
+            retval = getattr(lockfile, k, None)
+        if not retval:
+            retval = super(Lockfile, self).__getattribute__(k, *args, **kwargs)
+        return retval
+
+    @classmethod
+    def read_projectfile(cls, path):
+        """Read the specified project file and provide an interface for writing/updating.
+
+        :param str path: Path to the target file.
+        :return: A project file with the model and location for interaction
+        :rtype: :class:`~requirementslib.models.project.ProjectFile`
+        """
+
+        pf = ProjectFile.read(
+            path,
+            plette.lockfiles.Lockfile,
+            invalid_ok=True
+        )
+        return pf
 
     @classmethod
-    def load(cls, path):
+    def load_projectfile(cls, path, create=True):
+        """Given a path, load or create the necessary lockfile.
+
+        :param str path: Path to the project root or lockfile
+        :param bool create: Whether to create the lockfile if not found, defaults to True
+        :raises OSError: Thrown if the project root directory doesn't exist
+        :raises FileNotFoundError: Thrown if the lockfile doesn't exist and ``create=False``
+        :return: A project file instance for the supplied project
+        :rtype: :class:`~requirementslib.models.project.ProjectFile`
+        """
+
         if not path:
             path = os.curdir
         path = Path(path).absolute()
-        if path.is_dir():
-            path = path / "Pipfile.lock"
-        elif path.name == "Pipfile":
-            path = path.parent / "Pipfile.lock"
-        if not path.exists():
-            raise OSError("Path does not exist: %s" % path)
-        return cls.create(path.parent, lockfile_name=path.name)
+        project_path = path if path.is_dir() else path.parent
+        lockfile_path = project_path / "Pipfile.lock"
+        if not project_path.exists():
+            raise OSError("Project does not exist: %s" % project_path.as_posix())
+        elif not lockfile_path.exists() and not create:
+            raise FileNotFoundError("Lockfile does not exist: %s" % lockfile_path.as_posix())
+        projectfile = cls.read_projectfile(lockfile_path.as_posix())
+        return projectfile
 
     @classmethod
-    def create(cls, project_path, lockfile_name="Pipfile.lock"):
-        """Create a new lockfile instance
+    def load(cls, path, create=True):
+        """Create a new lockfile instance.
 
         :param project_path: Path to  project root
-        :type project_path: str or :class:`~pathlib.Path`
-        :returns: List[:class:`~requirementslib.Requirement`] objects
+        :type project_path: str or :class:`pathlib.Path`
+        :param str lockfile_name: Name of the lockfile in the project root directory
+        :param pipfile_path: Path to the project pipfile
+        :type pipfile_path: :class:`pathlib.Path`
+        :returns: A new lockfile representing the supplied project paths
+        :rtype: :class:`~requirementslib.models.lockfile.Lockfile`
         """
 
-        if not isinstance(project_path, Path):
-            project_path = Path(project_path)
-        lockfile_path = project_path / lockfile_name
-        with lockfile_path.open(encoding="utf-8") as f:
-            lockfile = super(Lockfile, cls).load(f)
-            lockfile.newlines = preferred_newlines(f)
-        lockfile.path = lockfile_path
-        return lockfile
+        projectfile = cls.load_projectfile(path, create=create)
+        lockfile_path = Path(projectfile.location)
+        creation_args = {
+            "projectfile": projectfile,
+            "lockfile": projectfile.model,
+            "newlines": projectfile.line_ending,
+            "path": lockfile_path
+        }
+        return cls(**creation_args)
+
+    @classmethod
+    def create(cls, path, create=True):
+        return cls.load(path, create=create)
+
+    @property
+    def develop(self):
+        return self._lockfile.develop
+
+    @property
+    def default(self):
+        return self._lockfile.default
 
     def get_requirements(self, dev=False):
+        """Produces a generator which generates requirements from the desired section.
+
+        :param bool dev: Indicates whether to use dev requirements, defaults to False
+        :return: Requirements from the relevant the relevant pipfile
+        :rtype: :class:`~requirementslib.models.requirements.Requirement`
+        """
+
         section = self.develop if dev else self.default
         for k in section.keys():
             yield Requirement.from_pipfile(k, section[k]._data)
@@ -81,24 +161,26 @@ class Lockfile(plette.lockfiles.Lockfile):
 
     @property
     def dev_requirements_list(self):
-        return [{name: entry._data} for name, entry in self.develop.items()]
+        return [{name: entry._data} for name, entry in self._lockfile.develop.items()]
 
     @property
     def requirements_list(self):
-        return [{name: entry._data} for name, entry in self.develop.items()]
+        return [{name: entry._data} for name, entry in self._lockfile.default.items()]
 
     def write(self):
-        open_kwargs = {"newline": self.newlines}
-        with atomic_open_for_write(self.path.as_posix(), **open_kwargs) as f:
-            super(Lockfile, self).dump(f, encoding="utf-8")
+        self.projectfile.model = copy.deepcopy(self._lockfile)
+        self.projectfile.write()
 
     def as_requirements(self, include_hashes=False, dev=False):
         """Returns a list of requirements in pip-style format"""
         lines = []
         section = self.dev_requirements if dev else self.requirements
         for req in section:
-            r = req.as_line()
-            if not include_hashes:
-                r = r.split("--hash", 1)[0]
+            kwargs = {
+                "include_hashes": include_hashes,
+            }
+            if req.editable:
+                kwargs["include_markers"] = False
+            r = req.as_line(**kwargs)
             lines.append(r.strip())
         return lines
diff --git a/pipenv/vendor/requirementslib/models/pipfile.py b/pipenv/vendor/requirementslib/models/pipfile.py
index 3a6f5b1e..94e9a2a1 100644
--- a/pipenv/vendor/requirementslib/models/pipfile.py
+++ b/pipenv/vendor/requirementslib/models/pipfile.py
@@ -1,64 +1,144 @@
 # -*- coding: utf-8 -*-
-from vistir.compat import Path
+
+from __future__ import absolute_import, unicode_literals, print_function
+
+import attr
+import copy
+import os
+
+from vistir.compat import Path, FileNotFoundError
 
 from .requirements import Requirement
+from .project import ProjectFile
+from .utils import optional_instance_of
 from ..exceptions import RequirementError
 import plette.pipfiles
 
 
-class Pipfile(plette.pipfiles.Pipfile):
+is_pipfile = optional_instance_of(plette.pipfiles.Pipfile)
+is_path = optional_instance_of(Path)
+is_projectfile = optional_instance_of(ProjectFile)
+
+
+@attr.s(slots=True)
+class Pipfile(object):
+    path = attr.ib(validator=is_path, type=Path)
+    projectfile = attr.ib(validator=is_projectfile, type=ProjectFile)
+    _pipfile = attr.ib(type=plette.pipfiles.Pipfile)
+    requirements = attr.ib(default=attr.Factory(list), type=list)
+    dev_requirements = attr.ib(default=attr.Factory(list), type=list)
+
+    @path.default
+    def _get_path(self):
+        return Path(os.curdir).absolute()
+
+    @projectfile.default
+    def _get_projectfile(self):
+        return self.load_projectfile(os.curdir, create=False)
+
+    @_pipfile.default
+    def _get_pipfile(self):
+        return self.projectfile.model
+
+    def __getattr__(self, k, *args, **kwargs):
+        retval = None
+        pipfile = super(Pipfile, self).__getattribute__("_pipfile")
+        try:
+            return super(Pipfile, self).__getattribute__(k)
+        except AttributeError:
+            retval = getattr(pipfile, k, None)
+        if not retval:
+            retval = super(Pipfile, self).__getattribute__(k, *args, **kwargs)
+        return retval
 
     @property
     def requires_python(self):
-        return self.requires.requires_python
+        return self._pipfile.requires.requires_python
 
     @property
     def allow_prereleases(self):
-        return self.get("pipenv", {}).get("allow_prereleases", False)
+        return self._pipfile.get("pipenv", {}).get("allow_prereleases", False)
 
     @classmethod
-    def load(cls, path):
+    def read_projectfile(cls, path):
+        """Read the specified project file and provide an interface for writing/updating.
+
+        :param str path: Path to the target file.
+        :return: A project file with the model and location for interaction
+        :rtype: :class:`~requirementslib.models.project.ProjectFile`
+        """
+        pf = ProjectFile.read(
+            path,
+            plette.pipfiles.Pipfile,
+            invalid_ok=True
+        )
+        return pf
+
+    @classmethod
+    def load_projectfile(cls, path, create=False):
+        """Given a path, load or create the necessary pipfile.
+
+        :param str path: Path to the project root or pipfile
+        :param bool create: Whether to create the pipfile if not found, defaults to True
+        :raises OSError: Thrown if the project root directory doesn't exist
+        :raises FileNotFoundError: Thrown if the pipfile doesn't exist and ``create=False``
+        :return: A project file instance for the supplied project
+        :rtype: :class:`~requirementslib.models.project.ProjectFile`
+        """
+        if not path:
+            raise RuntimeError("Must pass a path to classmethod 'Pipfile.load'")
         if not isinstance(path, Path):
             path = Path(path)
-        pipfile_path = path / "Pipfile"
-        if not path.exists():
+        pipfile_path = path if path.name == "Pipfile" else path.joinpath("Pipfile")
+        project_path = pipfile_path.parent
+        if not project_path.exists():
             raise FileNotFoundError("%s is not a valid project path!" % path)
         elif not pipfile_path.exists() or not pipfile_path.is_file():
-            raise RequirementError("%s is not a valid Pipfile" % pipfile_path)
-        with pipfile_path.open(encoding="utf-8") as fp:
-            pipfile = super(Pipfile, cls).load(fp)
-        pipfile.dev_requirements = [
-            Requirement.from_pipfile(k, v) for k, v in pipfile.get("dev-packages", {}).items()
+            if not create:
+                raise RequirementError("%s is not a valid Pipfile" % pipfile_path)
+        return cls.read_projectfile(pipfile_path.as_posix())
+
+    @classmethod
+    def load(cls, path, create=False):
+        """Given a path, load or create the necessary pipfile.
+
+        :param str path: Path to the project root or pipfile
+        :param bool create: Whether to create the pipfile if not found, defaults to True
+        :raises OSError: Thrown if the project root directory doesn't exist
+        :raises FileNotFoundError: Thrown if the pipfile doesn't exist and ``create=False``
+        :return: A pipfile instance pointing at the supplied project
+        :rtype:: class:`~requirementslib.models.pipfile.Pipfile`
+        """
+
+        projectfile = cls.load_projectfile(path, create=create)
+        pipfile = projectfile.model
+        dev_requirements = [
+            Requirement.from_pipfile(k, v._data) for k, v in pipfile.get("dev-packages", {}).items()
         ]
-        pipfile.requirements = [
-            Requirement.from_pipfile(k, v) for k, v in pipfile.get("packages", {}).items()
+        requirements = [
+            Requirement.from_pipfile(k, v._data) for k, v in pipfile.get("packages", {}).items()
         ]
-        pipfile.path = pipfile_path
-        return pipfile
-
-    # def resolve(self):
-    # It would be nice to still use this api someday
-    #     option_sources = [s.expanded for s in self.sources]
-    #     pip_args = []
-    #     if self.pipenv.allow_prereleases:
-    #         pip_args.append('--pre')
-    #     pip_options = get_pip_options(pip_args, sources=option_sources)
-    #     finder = get_finder(sources=option_sources, pip_options=pip_options)
-    #     resolver = DependencyResolver.create(finder=finder, allow_prereleases=self.pipenv.allow_prereleases)
-    #     pkg_dict = {}
-    #     for pkg in self.dev_packages.requirements + self.packages.requirements:
-    #         pkg_dict[pkg.name] = pkg
-    #     resolver.resolve(list(pkg_dict.values()))
-    #     return resolver
+        creation_args = {
+            "projectfile": projectfile,
+            "pipfile": pipfile,
+            "dev_requirements": dev_requirements,
+            "requirements": requirements,
+            "path": Path(projectfile.location)
+        }
+        return cls(**creation_args)
+
+    def write(self):
+        self.projectfile.model = copy.deepcopy(self._pipfile)
+        self.projectfile.write()
 
     @property
     def dev_packages(self, as_requirements=True):
         if as_requirements:
             return self.dev_requirements
-        return self.get('dev-packages', {})
+        return self._pipfile.get('dev-packages', {})
 
     @property
     def packages(self, as_requirements=True):
         if as_requirements:
             return self.requirements
-        return self.get('packages', {})
+        return self._pipfile.get('packages', {})
diff --git a/pipenv/vendor/requirementslib/models/project.py b/pipenv/vendor/requirementslib/models/project.py
new file mode 100644
index 00000000..f6e037d6
--- /dev/null
+++ b/pipenv/vendor/requirementslib/models/project.py
@@ -0,0 +1,241 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, unicode_literals
+
+import collections
+import io
+import os
+
+import attr
+import packaging.markers
+import packaging.utils
+import plette
+import plette.models
+import six
+import tomlkit
+
+
+SectionDifference = collections.namedtuple("SectionDifference", [
+    "inthis", "inthat",
+])
+FileDifference = collections.namedtuple("FileDifference", [
+    "default", "develop",
+])
+
+
+def _are_pipfile_entries_equal(a, b):
+    a = {k: v for k, v in a.items() if k not in ("markers", "hashes", "hash")}
+    b = {k: v for k, v in b.items() if k not in ("markers", "hashes", "hash")}
+    if a != b:
+        return False
+    try:
+        marker_eval_a = packaging.markers.Marker(a["markers"]).evaluate()
+    except (AttributeError, KeyError, TypeError, ValueError):
+        marker_eval_a = True
+    try:
+        marker_eval_b = packaging.markers.Marker(b["markers"]).evaluate()
+    except (AttributeError, KeyError, TypeError, ValueError):
+        marker_eval_b = True
+    return marker_eval_a == marker_eval_b
+
+
+DEFAULT_NEWLINES = "\n"
+
+
+def preferred_newlines(f):
+    if isinstance(f.newlines, six.text_type):
+        return f.newlines
+    return DEFAULT_NEWLINES
+
+
+@attr.s
+class ProjectFile(object):
+    """A file in the Pipfile project.
+    """
+    location = attr.ib()
+    line_ending = attr.ib()
+    model = attr.ib()
+
+    @classmethod
+    def read(cls, location, model_cls, invalid_ok=False):
+        try:
+            with io.open(location, encoding="utf-8") as f:
+                model = model_cls.load(f)
+                line_ending = preferred_newlines(f)
+        except Exception:
+            if not invalid_ok:
+                raise
+            model = None
+            line_ending = DEFAULT_NEWLINES
+        return cls(location=location, line_ending=line_ending, model=model)
+
+    def write(self):
+        kwargs = {"encoding": "utf-8", "newline": self.line_ending}
+        with io.open(self.location, "w", **kwargs) as f:
+            self.model.dump(f)
+
+    def dumps(self):
+        strio = six.StringIO()
+        self.model.dump(strio)
+        return strio.getvalue()
+
+
+@attr.s
+class Project(object):
+
+    root = attr.ib()
+    _p = attr.ib(init=False)
+    _l = attr.ib(init=False)
+
+    def __attrs_post_init__(self):
+        self.root = root = os.path.abspath(self.root)
+        self._p = ProjectFile.read(
+            os.path.join(root, "Pipfile"),
+            plette.Pipfile,
+        )
+        self._l = ProjectFile.read(
+            os.path.join(root, "Pipfile.lock"),
+            plette.Lockfile,
+            invalid_ok=True,
+        )
+
+    @property
+    def pipfile(self):
+        return self._p.model
+
+    @property
+    def pipfile_location(self):
+        return self._p.location
+
+    @property
+    def lockfile(self):
+        return self._l.model
+
+    @property
+    def lockfile_location(self):
+        return self._l.location
+
+    @lockfile.setter
+    def lockfile(self, new):
+        self._l.model = new
+
+    def is_synced(self):
+        return self.lockfile and self.lockfile.is_up_to_date(self.pipfile)
+
+    def _get_pipfile_section(self, develop, insert=True):
+        name = "dev-packages" if develop else "packages"
+        try:
+            section = self.pipfile[name]
+        except KeyError:
+            section = plette.models.PackageCollection(tomlkit.table())
+            if insert:
+                self.pipfile[name] = section
+        return section
+
+    def contains_key_in_pipfile(self, key):
+        sections = [
+            self._get_pipfile_section(develop=False, insert=False),
+            self._get_pipfile_section(develop=True, insert=False),
+        ]
+        return any(
+            (packaging.utils.canonicalize_name(name) ==
+             packaging.utils.canonicalize_name(key))
+            for section in sections
+            for name in section
+        )
+
+    def add_line_to_pipfile(self, line, develop):
+        from requirementslib import Requirement
+        requirement = Requirement.from_line(line)
+        section = self._get_pipfile_section(develop=develop)
+        key = requirement.normalized_name
+        entry = next(iter(requirement.as_pipfile().values()))
+        if isinstance(entry, dict):
+            # HACK: TOMLKit prefers to expand tables by default, but we
+            # always want inline tables here. Also tomlkit.inline_table
+            # does not have `update()`.
+            table = tomlkit.inline_table()
+            for k, v in entry.items():
+                table[k] = v
+            entry = table
+        section[key] = entry
+
+    def remove_keys_from_pipfile(self, keys, default, develop):
+        keys = {packaging.utils.canonicalize_name(key) for key in keys}
+        sections = []
+        if default:
+            sections.append(self._get_pipfile_section(
+                develop=False, insert=False,
+            ))
+        if develop:
+            sections.append(self._get_pipfile_section(
+                develop=True, insert=False,
+            ))
+        for section in sections:
+            removals = set()
+            for name in section:
+                if packaging.utils.canonicalize_name(name) in keys:
+                    removals.add(name)
+            for key in removals:
+                del section._data[key]
+
+    def remove_keys_from_lockfile(self, keys):
+        keys = {packaging.utils.canonicalize_name(key) for key in keys}
+        removed = False
+        for section_name in ("default", "develop"):
+            try:
+                section = self.lockfile[section_name]
+            except KeyError:
+                continue
+            removals = set()
+            for name in section:
+                if packaging.utils.canonicalize_name(name) in keys:
+                    removals.add(name)
+            removed = removed or bool(removals)
+            for key in removals:
+                del section._data[key]
+
+        if removed:
+            # HACK: The lock file no longer represents the Pipfile at this
+            # point. Set the hash to an arbitrary invalid value.
+            self.lockfile.meta.hash = plette.models.Hash({"__invalid__": ""})
+
+    def difference_lockfile(self, lockfile):
+        """Generate a difference between the current and given lockfiles.
+
+        Returns a 2-tuple containing differences in default in develop
+        sections.
+
+        Each element is a 2-tuple of dicts. The first, `inthis`, contains
+        entries only present in the current lockfile; the second, `inthat`,
+        contains entries only present in the given one.
+
+        If a key exists in both this and that, but the values differ, the key
+        is present in both dicts, pointing to values from each file.
+        """
+        diff_data = {
+            "default": SectionDifference({}, {}),
+            "develop": SectionDifference({}, {}),
+        }
+        for section_name, section_diff in diff_data.items():
+            try:
+                this = self.lockfile[section_name]._data
+            except (KeyError, TypeError):
+                this = {}
+            try:
+                that = lockfile[section_name]._data
+            except (KeyError, TypeError):
+                that = {}
+            for key, this_value in this.items():
+                try:
+                    that_value = that[key]
+                except KeyError:
+                    section_diff.inthis[key] = this_value
+                    continue
+                if not _are_pipfile_entries_equal(this_value, that_value):
+                    section_diff.inthis[key] = this_value
+                    section_diff.inthat[key] = that_value
+            for key, that_value in that.items():
+                if key not in this:
+                    section_diff.inthat[key] = that_value
+        return FileDifference(**diff_data)
diff --git a/pipenv/vendor/requirementslib/models/requirements.py b/pipenv/vendor/requirementslib/models/requirements.py
index 248ca777..c2768417 100644
--- a/pipenv/vendor/requirementslib/models/requirements.py
+++ b/pipenv/vendor/requirementslib/models/requirements.py
@@ -1,7 +1,7 @@
 # -*- coding: utf-8 -*-
+
 from __future__ import absolute_import
 
-import atexit
 import collections
 import hashlib
 import os
@@ -9,6 +9,7 @@ import os
 from contextlib import contextmanager
 
 import attr
+import six
 
 from first import first
 from packaging.markers import Marker
@@ -42,7 +43,8 @@ from .utils import (
     is_pinned_requirement, make_install_requirement, optional_instance_of,
     parse_extras, specs_to_string, split_markers_from_line,
     split_vcs_method_from_uri, strip_ssh_from_git_uri, validate_path,
-    validate_specifiers, validate_vcs
+    validate_specifiers, validate_vcs, normalize_name,
+    Requirement as PkgResourcesRequirement
 )
 from .vcs import VCSRepository
 
@@ -99,7 +101,7 @@ class NamedRequirement(BaseRequirement):
         # FIXME: This should actually be canonicalized but for now we have to
         # simply lowercase it and replace underscores, since full canonicalization
         # also replaces dots and that doesn't actually work when querying the index
-        return "{0}".format(self.name.lower().replace("_", "-"))
+        return "{0}".format(normalize_name(self.name))
 
     @property
     def pipfile_part(self):
@@ -123,12 +125,12 @@ class FileRequirement(BaseRequirement):
     setup_path = attr.ib(default=None)
     path = attr.ib(default=None, validator=attr.validators.optional(validate_path))
     # : path to hit - without any of the VCS prefixes (like git+ / http+ / etc)
-    editable = attr.ib(default=None)
-    extras = attr.ib(default=attr.Factory(list))
-    uri = attr.ib()
-    link = attr.ib()
-    name = attr.ib()
-    req = attr.ib()
+    editable = attr.ib(default=False, type=bool)
+    extras = attr.ib(default=attr.Factory(list), type=list)
+    uri = attr.ib(type=six.string_types)
+    link = attr.ib(type=Link)
+    name = attr.ib(type=six.string_types)
+    req = attr.ib(type=PkgResourcesRequirement)
     _has_hashed_name = False
     _uri_scheme = attr.ib(default=None)
 
@@ -297,7 +299,7 @@ class FileRequirement(BaseRequirement):
 
     @req.default
     def get_requirement(self):
-        req = init_requirement(canonicalize_name(self.name))
+        req = init_requirement(normalize_name(self.name))
         req.editable = False
         req.line = self.link.url_without_fragment
         if self.path and self.link and self.link.scheme.startswith("file"):
@@ -948,7 +950,8 @@ class Requirement(object):
             cls_inst.req.req.line = cls_inst.as_line()
         return cls_inst
 
-    def as_line(self, sources=None, include_hashes=True, include_extras=True, as_list=False):
+    def as_line(self, sources=None, include_hashes=True, include_extras=True,
+                                                    include_markers=True, as_list=False):
         """Format this requirement as a line in requirements.txt.
 
         If ``sources`` provided, it should be an sequence of mappings, containing
@@ -967,7 +970,7 @@ class Requirement(object):
             self.req.line_part,
             self.extras_as_pip if include_extras else "",
             self.specifiers if include_specifiers else "",
-            self.markers_as_pip,
+            self.markers_as_pip if include_markers else "",
         ]
         if as_list:
             # This is used for passing to a subprocess call
diff --git a/pipenv/vendor/requirementslib/models/utils.py b/pipenv/vendor/requirementslib/models/utils.py
index cba63295..7350d0ac 100644
--- a/pipenv/vendor/requirementslib/models/utils.py
+++ b/pipenv/vendor/requirementslib/models/utils.py
@@ -508,3 +508,15 @@ def fix_requires_python_marker(requires_python):
         ])
     marker_to_add = PackagingRequirement('fakepkg; {0}'.format(marker_str)).marker
     return marker_to_add
+
+
+def normalize_name(pkg):
+    """Given a package name, return its normalized, non-canonicalized form.
+
+    :param str pkg: The name of a package
+    :return: A normalized package name
+    :rtype: str
+    """
+
+    assert isinstance(pkg, six.string_types)
+    return pkg.replace("_", "-").lower()
diff --git a/pipenv/vendor/shellingham/__init__.py b/pipenv/vendor/shellingham/__init__.py
index 90c00abb..576c4224 100644
--- a/pipenv/vendor/shellingham/__init__.py
+++ b/pipenv/vendor/shellingham/__init__.py
@@ -4,7 +4,7 @@ import os
 from ._core import ShellDetectionFailure
 
 
-__version__ = '1.2.6'
+__version__ = '1.2.7'
 
 
 def detect_shell(pid=None, max_depth=6):
diff --git a/pipenv/vendor/shellingham/posix/ps.py b/pipenv/vendor/shellingham/posix/ps.py
index ab4c2a9e..4a155ed5 100644
--- a/pipenv/vendor/shellingham/posix/ps.py
+++ b/pipenv/vendor/shellingham/posix/ps.py
@@ -21,6 +21,12 @@ def get_process_mapping():
         if e.errno != errno.ENOENT:
             raise
         raise PsNotAvailable('ps not found')
+    except subprocess.CalledProcessError as e:
+        # `ps` can return 1 if the process list is completely empty.
+        # (sarugaku/shellingham#15)
+        if not e.output.strip():
+            return {}
+        raise
     if not isinstance(output, str):
         encoding = sys.getfilesystemencoding() or sys.getdefaultencoding()
         output = output.decode(encoding)
@@ -28,9 +34,9 @@ def get_process_mapping():
     for line in output.split('\n'):
         try:
             pid, ppid, args = line.strip().split(None, 2)
+            processes[pid] = Process(
+                args=tuple(shlex.split(args)), pid=pid, ppid=ppid,
+            )
         except ValueError:
             continue
-        processes[pid] = Process(
-            args=tuple(shlex.split(args)), pid=pid, ppid=ppid,
-        )
     return processes
diff --git a/pipenv/vendor/toml.LICENSE b/pipenv/vendor/toml.LICENSE
deleted file mode 100644
index d8b406c9..00000000
--- a/pipenv/vendor/toml.LICENSE
+++ /dev/null
@@ -1,26 +0,0 @@
-The MIT License
-
-Copyright 2013-2017 Uiri Noyb
-Copyright 2015-2016 Julien Enselme
-Copyright 2016 Google Inc.
-Copyright 2017 Samuel Vasko
-Copyright 2017 Nate Prewitt
-Copyright 2017 Jack Evans
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
\ No newline at end of file
diff --git a/pipenv/vendor/toml.py b/pipenv/vendor/toml.py
deleted file mode 100644
index dac39883..00000000
--- a/pipenv/vendor/toml.py
+++ /dev/null
@@ -1,1039 +0,0 @@
-"""Python module which parses and emits TOML.
-
-Released under the MIT license.
-"""
-import re
-import io
-import datetime
-from os import linesep
-import sys
-
-__version__ = "0.9.6"
-_spec_ = "0.4.0"
-
-
-class TomlDecodeError(Exception):
-    """Base toml Exception / Error."""
-    pass
-
-
-class TomlTz(datetime.tzinfo):
-    def __init__(self, toml_offset):
-        if toml_offset == "Z":
-            self._raw_offset = "+00:00"
-        else:
-            self._raw_offset = toml_offset
-        self._sign = -1 if self._raw_offset[0] == '-' else 1
-        self._hours = int(self._raw_offset[1:3])
-        self._minutes = int(self._raw_offset[4:6])
-
-    def tzname(self, dt):
-        return "UTC" + self._raw_offset
-
-    def utcoffset(self, dt):
-        return self._sign * datetime.timedelta(hours=self._hours,
-                                               minutes=self._minutes)
-
-    def dst(self, dt):
-        return datetime.timedelta(0)
-
-
-class InlineTableDict(object):
-    """Sentinel subclass of dict for inline tables."""
-
-
-def _get_empty_inline_table(_dict):
-    class DynamicInlineTableDict(_dict, InlineTableDict):
-        """Concrete sentinel subclass for inline tables.
-        It is a subclass of _dict which is passed in dynamically at load time
-        It is also a subclass of InlineTableDict
-        """
-
-    return DynamicInlineTableDict()
-
-
-try:
-    _range = xrange
-except NameError:
-    unicode = str
-    _range = range
-    basestring = str
-    unichr = chr
-
-try:
-    FNFError = FileNotFoundError
-except NameError:
-    FNFError = IOError
-
-
-def load(f, _dict=dict):
-    """Parses named file or files as toml and returns a dictionary
-
-    Args:
-        f: Path to the file to open, array of files to read into single dict
-           or a file descriptor
-        _dict: (optional) Specifies the class of the returned toml dictionary
-
-    Returns:
-        Parsed toml file represented as a dictionary
-
-    Raises:
-        TypeError -- When f is invalid type
-        TomlDecodeError: Error while decoding toml
-        IOError / FileNotFoundError -- When an array with no valid (existing)
-        (Python 2 / Python 3)          file paths is passed
-    """
-
-    if isinstance(f, basestring):
-        with io.open(f, encoding='utf-8') as ffile:
-            return loads(ffile.read(), _dict)
-    elif isinstance(f, list):
-        from os import path as op
-        from warnings import warn
-        if not [path for path in f if op.exists(path)]:
-            error_msg = "Load expects a list to contain filenames only."
-            error_msg += linesep
-            error_msg += ("The list needs to contain the path of at least one "
-                          "existing file.")
-            raise FNFError(error_msg)
-        d = _dict()
-        for l in f:
-            if op.exists(l):
-                d.update(load(l))
-            else:
-                warn("Non-existent filename in list with at least one valid "
-                     "filename")
-        return d
-    else:
-        try:
-            return loads(f.read(), _dict)
-        except AttributeError:
-            raise TypeError("You can only load a file descriptor, filename or "
-                            "list")
-
-
-_groupname_re = re.compile(r'^[A-Za-z0-9_-]+$')
-
-
-def loads(s, _dict=dict):
-    """Parses string as toml
-
-    Args:
-        s: String to be parsed
-        _dict: (optional) Specifies the class of the returned toml dictionary
-
-    Returns:
-        Parsed toml file represented as a dictionary
-
-    Raises:
-        TypeError: When a non-string is passed
-        TomlDecodeError: Error while decoding toml
-    """
-
-    implicitgroups = []
-    retval = _dict()
-    currentlevel = retval
-    if not isinstance(s, basestring):
-        raise TypeError("Expecting something like a string")
-
-    if not isinstance(s, unicode):
-        s = s.decode('utf8')
-
-    sl = list(s)
-    openarr = 0
-    openstring = False
-    openstrchar = ""
-    multilinestr = False
-    arrayoftables = False
-    beginline = True
-    keygroup = False
-    keyname = 0
-    for i, item in enumerate(sl):
-        if item == '\r' and sl[i + 1] == '\n':
-            sl[i] = ' '
-            continue
-        if keyname:
-            if item == '\n':
-                raise TomlDecodeError("Key name found without value."
-                                      " Reached end of line.")
-            if openstring:
-                if item == openstrchar:
-                    keyname = 2
-                    openstring = False
-                    openstrchar = ""
-                continue
-            elif keyname == 1:
-                if item.isspace():
-                    keyname = 2
-                    continue
-                elif item.isalnum() or item == '_' or item == '-':
-                    continue
-            elif keyname == 2 and item.isspace():
-                continue
-            if item == '=':
-                keyname = 0
-            else:
-                raise TomlDecodeError("Found invalid character in key name: '" +
-                                      item + "'. Try quoting the key name.")
-        if item == "'" and openstrchar != '"':
-            k = 1
-            try:
-                while sl[i - k] == "'":
-                    k += 1
-                    if k == 3:
-                        break
-            except IndexError:
-                pass
-            if k == 3:
-                multilinestr = not multilinestr
-                openstring = multilinestr
-            else:
-                openstring = not openstring
-            if openstring:
-                openstrchar = "'"
-            else:
-                openstrchar = ""
-        if item == '"' and openstrchar != "'":
-            oddbackslash = False
-            k = 1
-            tripquote = False
-            try:
-                while sl[i - k] == '"':
-                    k += 1
-                    if k == 3:
-                        tripquote = True
-                        break
-                if k == 1 or (k == 3 and tripquote):
-                    while sl[i - k] == '\\':
-                        oddbackslash = not oddbackslash
-                        k += 1
-            except IndexError:
-                pass
-            if not oddbackslash:
-                if tripquote:
-                    multilinestr = not multilinestr
-                    openstring = multilinestr
-                else:
-                    openstring = not openstring
-            if openstring:
-                openstrchar = '"'
-            else:
-                openstrchar = ""
-        if item == '#' and (not openstring and not keygroup and
-                            not arrayoftables):
-            j = i
-            try:
-                while sl[j] != '\n':
-                    sl[j] = ' '
-                    j += 1
-            except IndexError:
-                break
-        if item == '[' and (not openstring and not keygroup and
-                            not arrayoftables):
-            if beginline:
-                if len(sl) > i + 1 and sl[i + 1] == '[':
-                    arrayoftables = True
-                else:
-                    keygroup = True
-            else:
-                openarr += 1
-        if item == ']' and not openstring:
-            if keygroup:
-                keygroup = False
-            elif arrayoftables:
-                if sl[i - 1] == ']':
-                    arrayoftables = False
-            else:
-                openarr -= 1
-        if item == '\n':
-            if openstring or multilinestr:
-                if not multilinestr:
-                    raise TomlDecodeError("Unbalanced quotes")
-                if ((sl[i - 1] == "'" or sl[i - 1] == '"') and (
-                        sl[i - 2] == sl[i - 1])):
-                    sl[i] = sl[i - 1]
-                    if sl[i - 3] == sl[i - 1]:
-                        sl[i - 3] = ' '
-            elif openarr:
-                sl[i] = ' '
-            else:
-                beginline = True
-        elif beginline and sl[i] != ' ' and sl[i] != '\t':
-            beginline = False
-            if not keygroup and not arrayoftables:
-                if sl[i] == '=':
-                    raise TomlDecodeError("Found empty keyname. ")
-                keyname = 1
-    s = ''.join(sl)
-    s = s.split('\n')
-    multikey = None
-    multilinestr = ""
-    multibackslash = False
-    for line in s:
-        if not multilinestr or multibackslash or '\n' not in multilinestr:
-            line = line.strip()
-        if line == "" and (not multikey or multibackslash):
-            continue
-        if multikey:
-            if multibackslash:
-                multilinestr += line
-            else:
-                multilinestr += line
-            multibackslash = False
-            if len(line) > 2 and (line[-1] == multilinestr[0] and
-                                  line[-2] == multilinestr[0] and
-                                  line[-3] == multilinestr[0]):
-                try:
-                    value, vtype = _load_value(multilinestr, _dict)
-                except ValueError as err:
-                    raise TomlDecodeError(str(err))
-                currentlevel[multikey] = value
-                multikey = None
-                multilinestr = ""
-            else:
-                k = len(multilinestr) - 1
-                while k > -1 and multilinestr[k] == '\\':
-                    multibackslash = not multibackslash
-                    k -= 1
-                if multibackslash:
-                    multilinestr = multilinestr[:-1]
-                else:
-                    multilinestr += "\n"
-            continue
-        if line[0] == '[':
-            arrayoftables = False
-            if len(line) == 1:
-                raise TomlDecodeError("Opening key group bracket on line by "
-                                      "itself.")
-            if line[1] == '[':
-                arrayoftables = True
-                line = line[2:]
-                splitstr = ']]'
-            else:
-                line = line[1:]
-                splitstr = ']'
-            i = 1
-            quotesplits = _get_split_on_quotes(line)
-            quoted = False
-            for quotesplit in quotesplits:
-                if not quoted and splitstr in quotesplit:
-                    break
-                i += quotesplit.count(splitstr)
-                quoted = not quoted
-            line = line.split(splitstr, i)
-            if len(line) < i + 1 or line[-1].strip() != "":
-                raise TomlDecodeError("Key group not on a line by itself.")
-            groups = splitstr.join(line[:-1]).split('.')
-            i = 0
-            while i < len(groups):
-                groups[i] = groups[i].strip()
-                if len(groups[i]) > 0 and (groups[i][0] == '"' or
-                                           groups[i][0] == "'"):
-                    groupstr = groups[i]
-                    j = i + 1
-                    while not groupstr[0] == groupstr[-1]:
-                        j += 1
-                        if j > len(groups) + 2:
-                            raise TomlDecodeError("Invalid group name '" +
-                                                  groupstr + "' Something " +
-                                                  "went wrong.")
-                        groupstr = '.'.join(groups[i:j]).strip()
-                    groups[i] = groupstr[1:-1]
-                    groups[i + 1:j] = []
-                else:
-                    if not _groupname_re.match(groups[i]):
-                        raise TomlDecodeError("Invalid group name '" +
-                                              groups[i] + "'. Try quoting it.")
-                i += 1
-            currentlevel = retval
-            for i in _range(len(groups)):
-                group = groups[i]
-                if group == "":
-                    raise TomlDecodeError("Can't have a keygroup with an empty "
-                                          "name")
-                try:
-                    currentlevel[group]
-                    if i == len(groups) - 1:
-                        if group in implicitgroups:
-                            implicitgroups.remove(group)
-                            if arrayoftables:
-                                raise TomlDecodeError("An implicitly defined "
-                                                      "table can't be an array")
-                        elif arrayoftables:
-                            currentlevel[group].append(_dict())
-                        else:
-                            raise TomlDecodeError("What? " + group +
-                                                  " already exists?" +
-                                                  str(currentlevel))
-                except TypeError:
-                    currentlevel = currentlevel[-1]
-                    try:
-                        currentlevel[group]
-                    except KeyError:
-                        currentlevel[group] = _dict()
-                        if i == len(groups) - 1 and arrayoftables:
-                            currentlevel[group] = [_dict()]
-                except KeyError:
-                    if i != len(groups) - 1:
-                        implicitgroups.append(group)
-                    currentlevel[group] = _dict()
-                    if i == len(groups) - 1 and arrayoftables:
-                        currentlevel[group] = [_dict()]
-                currentlevel = currentlevel[group]
-                if arrayoftables:
-                    try:
-                        currentlevel = currentlevel[-1]
-                    except KeyError:
-                        pass
-        elif line[0] == "{":
-            if line[-1] != "}":
-                raise TomlDecodeError("Line breaks are not allowed in inline"
-                                      "objects")
-            try:
-                _load_inline_object(line, currentlevel, _dict, multikey,
-                                    multibackslash)
-            except ValueError as err:
-                raise TomlDecodeError(str(err))
-        elif "=" in line:
-            try:
-                ret = _load_line(line, currentlevel, _dict, multikey,
-                                 multibackslash)
-            except ValueError as err:
-                raise TomlDecodeError(str(err))
-            if ret is not None:
-                multikey, multilinestr, multibackslash = ret
-    return retval
-
-
-def _load_inline_object(line, currentlevel, _dict, multikey=False,
-                        multibackslash=False):
-    candidate_groups = line[1:-1].split(",")
-    groups = []
-    if len(candidate_groups) == 1 and not candidate_groups[0].strip():
-        candidate_groups.pop()
-    while len(candidate_groups) > 0:
-        candidate_group = candidate_groups.pop(0)
-        try:
-            _, value = candidate_group.split('=', 1)
-        except ValueError:
-            raise ValueError("Invalid inline table encountered")
-        value = value.strip()
-        if ((value[0] == value[-1] and value[0] in ('"', "'")) or (
-                value[0] in '-0123456789' or
-                value in ('true', 'false') or
-                (value[0] == "[" and value[-1] == "]") or
-                (value[0] == '{' and value[-1] == '}'))):
-            groups.append(candidate_group)
-        elif len(candidate_groups) > 0:
-            candidate_groups[0] = candidate_group + "," + candidate_groups[0]
-        else:
-            raise ValueError("Invalid inline table value encountered")
-    for group in groups:
-        status = _load_line(group, currentlevel, _dict, multikey,
-                            multibackslash)
-        if status is not None:
-            break
-
-
-# Matches a TOML number, which allows underscores for readability
-_number_with_underscores = re.compile('([0-9])(_([0-9]))*')
-
-
-def _strictly_valid_num(n):
-    n = n.strip()
-    if not n:
-        return False
-    if n[0] == '_':
-        return False
-    if n[-1] == '_':
-        return False
-    if "_." in n or "._" in n:
-        return False
-    if len(n) == 1:
-        return True
-    if n[0] == '0' and n[1] != '.':
-        return False
-    if n[0] == '+' or n[0] == '-':
-        n = n[1:]
-        if n[0] == '0' and n[1] != '.':
-            return False
-    if '__' in n:
-        return False
-    return True
-
-
-def _get_split_on_quotes(line):
-    doublequotesplits = line.split('"')
-    quoted = False
-    quotesplits = []
-    if len(doublequotesplits) > 1 and "'" in doublequotesplits[0]:
-        singlequotesplits = doublequotesplits[0].split("'")
-        doublequotesplits = doublequotesplits[1:]
-        while len(singlequotesplits) % 2 == 0 and len(doublequotesplits):
-            singlequotesplits[-1] += '"' + doublequotesplits[0]
-            doublequotesplits = doublequotesplits[1:]
-            if "'" in singlequotesplits[-1]:
-                singlequotesplits = (singlequotesplits[:-1] +
-                                     singlequotesplits[-1].split("'"))
-        quotesplits += singlequotesplits
-    for doublequotesplit in doublequotesplits:
-        if quoted:
-            quotesplits.append(doublequotesplit)
-        else:
-            quotesplits += doublequotesplit.split("'")
-            quoted = not quoted
-    return quotesplits
-
-
-def _load_line(line, currentlevel, _dict, multikey, multibackslash):
-    i = 1
-    quotesplits = _get_split_on_quotes(line)
-    quoted = False
-    for quotesplit in quotesplits:
-        if not quoted and '=' in quotesplit:
-            break
-        i += quotesplit.count('=')
-        quoted = not quoted
-    pair = line.split('=', i)
-    strictly_valid = _strictly_valid_num(pair[-1])
-    if _number_with_underscores.match(pair[-1]):
-        pair[-1] = pair[-1].replace('_', '')
-    while len(pair[-1]) and (pair[-1][0] != ' ' and pair[-1][0] != '\t' and
-                             pair[-1][0] != "'" and pair[-1][0] != '"' and
-                             pair[-1][0] != '[' and pair[-1][0] != '{' and
-                             pair[-1] != 'true' and pair[-1] != 'false'):
-        try:
-            float(pair[-1])
-            break
-        except ValueError:
-            pass
-        if _load_date(pair[-1]) is not None:
-            break
-        i += 1
-        prev_val = pair[-1]
-        pair = line.split('=', i)
-        if prev_val == pair[-1]:
-            raise ValueError("Invalid date or number")
-        if strictly_valid:
-            strictly_valid = _strictly_valid_num(pair[-1])
-    pair = ['='.join(pair[:-1]).strip(), pair[-1].strip()]
-    if (pair[0][0] == '"' or pair[0][0] == "'") and \
-            (pair[0][-1] == '"' or pair[0][-1] == "'"):
-        pair[0] = pair[0][1:-1]
-    if len(pair[1]) > 2 and ((pair[1][0] == '"' or pair[1][0] == "'") and
-                             pair[1][1] == pair[1][0] and
-                             pair[1][2] == pair[1][0] and
-                             not (len(pair[1]) > 5 and
-                                  pair[1][-1] == pair[1][0] and
-                                  pair[1][-2] == pair[1][0] and
-                                  pair[1][-3] == pair[1][0])):
-        k = len(pair[1]) - 1
-        while k > -1 and pair[1][k] == '\\':
-            multibackslash = not multibackslash
-            k -= 1
-        if multibackslash:
-            multilinestr = pair[1][:-1]
-        else:
-            multilinestr = pair[1] + "\n"
-        multikey = pair[0]
-    else:
-        value, vtype = _load_value(pair[1], _dict, strictly_valid)
-    try:
-        currentlevel[pair[0]]
-        raise ValueError("Duplicate keys!")
-    except KeyError:
-        if multikey:
-            return multikey, multilinestr, multibackslash
-        else:
-            currentlevel[pair[0]] = value
-
-
-def _load_date(val):
-    microsecond = 0
-    tz = None
-    try:
-        if len(val) > 19:
-            if val[19] == '.':
-                if val[-1].upper() == 'Z':
-                    subsecondval = val[20:-1]
-                    tzval = "Z"
-                else:
-                    subsecondvalandtz = val[20:]
-                    if '+' in subsecondvalandtz:
-                        splitpoint = subsecondvalandtz.index('+')
-                        subsecondval = subsecondvalandtz[:splitpoint]
-                        tzval = subsecondvalandtz[splitpoint:]
-                    elif '-' in subsecondvalandtz:
-                        splitpoint = subsecondvalandtz.index('-')
-                        subsecondval = subsecondvalandtz[:splitpoint]
-                        tzval = subsecondvalandtz[splitpoint:]
-                tz = TomlTz(tzval)
-                microsecond = int(int(subsecondval) *
-                                  (10 ** (6 - len(subsecondval))))
-            else:
-                tz = TomlTz(val[19:])
-    except ValueError:
-        tz = None
-    if "-" not in val[1:]:
-        return None
-    try:
-        d = datetime.datetime(
-            int(val[:4]), int(val[5:7]),
-            int(val[8:10]), int(val[11:13]),
-            int(val[14:16]), int(val[17:19]), microsecond, tz)
-    except ValueError:
-        return None
-    return d
-
-
-def _load_unicode_escapes(v, hexbytes, prefix):
-    skip = False
-    i = len(v) - 1
-    while i > -1 and v[i] == '\\':
-        skip = not skip
-        i -= 1
-    for hx in hexbytes:
-        if skip:
-            skip = False
-            i = len(hx) - 1
-            while i > -1 and hx[i] == '\\':
-                skip = not skip
-                i -= 1
-            v += prefix
-            v += hx
-            continue
-        hxb = ""
-        i = 0
-        hxblen = 4
-        if prefix == "\\U":
-            hxblen = 8
-        hxb = ''.join(hx[i:i + hxblen]).lower()
-        if hxb.strip('0123456789abcdef'):
-            raise ValueError("Invalid escape sequence: " + hxb)
-        if hxb[0] == "d" and hxb[1].strip('01234567'):
-            raise ValueError("Invalid escape sequence: " + hxb +
-                             ". Only scalar unicode points are allowed.")
-        v += unichr(int(hxb, 16))
-        v += unicode(hx[len(hxb):])
-    return v
-
-
-# Unescape TOML string values.
-
-# content after the \
-_escapes = ['0', 'b', 'f', 'n', 'r', 't', '"']
-# What it should be replaced by
-_escapedchars = ['\0', '\b', '\f', '\n', '\r', '\t', '\"']
-# Used for substitution
-_escape_to_escapedchars = dict(zip(_escapes, _escapedchars))
-
-
-def _unescape(v):
-    """Unescape characters in a TOML string."""
-    i = 0
-    backslash = False
-    while i < len(v):
-        if backslash:
-            backslash = False
-            if v[i] in _escapes:
-                v = v[:i - 1] + _escape_to_escapedchars[v[i]] + v[i + 1:]
-            elif v[i] == '\\':
-                v = v[:i - 1] + v[i:]
-            elif v[i] == 'u' or v[i] == 'U':
-                i += 1
-            else:
-                raise ValueError("Reserved escape sequence used")
-            continue
-        elif v[i] == '\\':
-            backslash = True
-        i += 1
-    return v
-
-
-def _load_value(v, _dict, strictly_valid=True):
-    if not v:
-        raise ValueError("Empty value is invalid")
-    if v == 'true':
-        return (True, "bool")
-    elif v == 'false':
-        return (False, "bool")
-    elif v[0] == '"':
-        testv = v[1:].split('"')
-        triplequote = False
-        triplequotecount = 0
-        if len(testv) > 1 and testv[0] == '' and testv[1] == '':
-            testv = testv[2:]
-            triplequote = True
-        closed = False
-        for tv in testv:
-            if tv == '':
-                if triplequote:
-                    triplequotecount += 1
-                else:
-                    closed = True
-            else:
-                oddbackslash = False
-                try:
-                    i = -1
-                    j = tv[i]
-                    while j == '\\':
-                        oddbackslash = not oddbackslash
-                        i -= 1
-                        j = tv[i]
-                except IndexError:
-                    pass
-                if not oddbackslash:
-                    if closed:
-                        raise ValueError("Stuff after closed string. WTF?")
-                    else:
-                        if not triplequote or triplequotecount > 1:
-                            closed = True
-                        else:
-                            triplequotecount = 0
-        escapeseqs = v.split('\\')[1:]
-        backslash = False
-        for i in escapeseqs:
-            if i == '':
-                backslash = not backslash
-            else:
-                if i[0] not in _escapes and (i[0] != 'u' and i[0] != 'U' and
-                                             not backslash):
-                    raise ValueError("Reserved escape sequence used")
-                if backslash:
-                    backslash = False
-        for prefix in ["\\u", "\\U"]:
-            if prefix in v:
-                hexbytes = v.split(prefix)
-                v = _load_unicode_escapes(hexbytes[0], hexbytes[1:], prefix)
-        v = _unescape(v)
-        if len(v) > 1 and v[1] == '"' and (len(v) < 3 or v[1] == v[2]):
-            v = v[2:-2]
-        return (v[1:-1], "str")
-    elif v[0] == "'":
-        if v[1] == "'" and (len(v) < 3 or v[1] == v[2]):
-            v = v[2:-2]
-        return (v[1:-1], "str")
-    elif v[0] == '[':
-        return (_load_array(v, _dict), "array")
-    elif v[0] == '{':
-        inline_object = _get_empty_inline_table(_dict)
-        _load_inline_object(v, inline_object, _dict)
-        return (inline_object, "inline_object")
-    else:
-        parsed_date = _load_date(v)
-        if parsed_date is not None:
-            return (parsed_date, "date")
-        if not strictly_valid:
-            raise ValueError("Weirdness with leading zeroes or "
-                             "underscores in your number.")
-        itype = "int"
-        neg = False
-        if v[0] == '-':
-            neg = True
-            v = v[1:]
-        elif v[0] == '+':
-            v = v[1:]
-        v = v.replace('_', '')
-        if '.' in v or 'e' in v or 'E' in v:
-            if '.' in v and v.split('.', 1)[1] == '':
-                raise ValueError("This float is missing digits after "
-                                 "the point")
-            if v[0] not in '0123456789':
-                raise ValueError("This float doesn't have a leading digit")
-            v = float(v)
-            itype = "float"
-        else:
-            v = int(v)
-        if neg:
-            return (0 - v, itype)
-        return (v, itype)
-
-
-def _bounded_string(s):
-    if len(s) == 0:
-        return True
-    if s[-1] != s[0]:
-        return False
-    i = -2
-    backslash = False
-    while len(s) + i > 0:
-        if s[i] == "\\":
-            backslash = not backslash
-            i -= 1
-        else:
-            break
-    return not backslash
-
-
-def _load_array(a, _dict):
-    atype = None
-    retval = []
-    a = a.strip()
-    if '[' not in a[1:-1] or "" != a[1:-1].split('[')[0].strip():
-        strarray = False
-        tmpa = a[1:-1].strip()
-        if tmpa != '' and (tmpa[0] == '"' or tmpa[0] == "'"):
-            strarray = True
-        if not a[1:-1].strip().startswith('{'):
-            a = a[1:-1].split(',')
-        else:
-            # a is an inline object, we must find the matching parenthesis
-            # to define groups
-            new_a = []
-            start_group_index = 1
-            end_group_index = 2
-            in_str = False
-            while end_group_index < len(a[1:]):
-                if a[end_group_index] == '"' or a[end_group_index] == "'":
-                    if in_str:
-                        backslash_index = end_group_index - 1
-                        while (backslash_index > -1 and
-                               a[backslash_index] == '\\'):
-                            in_str = not in_str
-                            backslash_index -= 1
-                    in_str = not in_str
-                if in_str or a[end_group_index] != '}':
-                    end_group_index += 1
-                    continue
-
-                # Increase end_group_index by 1 to get the closing bracket
-                end_group_index += 1
-                new_a.append(a[start_group_index:end_group_index])
-
-                # The next start index is at least after the closing bracket, a
-                # closing bracket can be followed by a comma since we are in
-                # an array.
-                start_group_index = end_group_index + 1
-                while (start_group_index < len(a[1:]) and
-                       a[start_group_index] != '{'):
-                    start_group_index += 1
-                end_group_index = start_group_index + 1
-            a = new_a
-        b = 0
-        if strarray:
-            while b < len(a) - 1:
-                ab = a[b].strip()
-                while (not _bounded_string(ab) or
-                       (len(ab) > 2 and
-                        ab[0] == ab[1] == ab[2] and
-                        ab[-2] != ab[0] and
-                        ab[-3] != ab[0])):
-                    a[b] = a[b] + ',' + a[b + 1]
-                    ab = a[b].strip()
-                    if b < len(a) - 2:
-                        a = a[:b + 1] + a[b + 2:]
-                    else:
-                        a = a[:b + 1]
-                b += 1
-    else:
-        al = list(a[1:-1])
-        a = []
-        openarr = 0
-        j = 0
-        for i in _range(len(al)):
-            if al[i] == '[':
-                openarr += 1
-            elif al[i] == ']':
-                openarr -= 1
-            elif al[i] == ',' and not openarr:
-                a.append(''.join(al[j:i]))
-                j = i + 1
-        a.append(''.join(al[j:]))
-    for i in _range(len(a)):
-        a[i] = a[i].strip()
-        if a[i] != '':
-            nval, ntype = _load_value(a[i], _dict)
-            if atype:
-                if ntype != atype:
-                    raise ValueError("Not a homogeneous array")
-            else:
-                atype = ntype
-            retval.append(nval)
-    return retval
-
-
-def dump(o, f):
-    """Writes out dict as toml to a file
-
-    Args:
-        o: Object to dump into toml
-        f: File descriptor where the toml should be stored
-
-    Returns:
-        String containing the toml corresponding to dictionary
-
-    Raises:
-        TypeError: When anything other than file descriptor is passed
-    """
-
-    if not f.write:
-        raise TypeError("You can only dump an object to a file descriptor")
-    d = dumps(o)
-    f.write(d)
-    return d
-
-
-def dumps(o, preserve=False):
-    """Stringifies input dict as toml
-
-    Args:
-        o: Object to dump into toml
-
-        preserve: Boolean parameter. If true, preserve inline tables.
-
-    Returns:
-        String containing the toml corresponding to dict
-    """
-
-    retval = ""
-    addtoretval, sections = _dump_sections(o, "")
-    retval += addtoretval
-    while sections != {}:
-        newsections = {}
-        for section in sections:
-            addtoretval, addtosections = _dump_sections(sections[section],
-                                                        section, preserve)
-            if addtoretval or (not addtoretval and not addtosections):
-                if retval and retval[-2:] != "\n\n":
-                    retval += "\n"
-                retval += "[" + section + "]\n"
-                if addtoretval:
-                    retval += addtoretval
-            for s in addtosections:
-                newsections[section + "." + s] = addtosections[s]
-        sections = newsections
-    return retval
-
-
-def _dump_sections(o, sup, preserve=False):
-    retstr = ""
-    if sup != "" and sup[-1] != ".":
-        sup += '.'
-    retdict = o.__class__()
-    arraystr = ""
-    for section in o:
-        section = unicode(section)
-        qsection = section
-        if not re.match(r'^[A-Za-z0-9_-]+$', section):
-            if '"' in section:
-                qsection = "'" + section + "'"
-            else:
-                qsection = '"' + section + '"'
-        if not isinstance(o[section], dict):
-            arrayoftables = False
-            if isinstance(o[section], list):
-                for a in o[section]:
-                    if isinstance(a, dict):
-                        arrayoftables = True
-            if arrayoftables:
-                for a in o[section]:
-                    arraytabstr = "\n"
-                    arraystr += "[[" + sup + qsection + "]]\n"
-                    s, d = _dump_sections(a, sup + qsection)
-                    if s:
-                        if s[0] == "[":
-                            arraytabstr += s
-                        else:
-                            arraystr += s
-                    while d != {}:
-                        newd = {}
-                        for dsec in d:
-                            s1, d1 = _dump_sections(d[dsec], sup + qsection +
-                                                    "." + dsec)
-                            if s1:
-                                arraytabstr += ("[" + sup + qsection + "." +
-                                                dsec + "]\n")
-                                arraytabstr += s1
-                            for s1 in d1:
-                                newd[dsec + "." + s1] = d1[s1]
-                        d = newd
-                    arraystr += arraytabstr
-            else:
-                if o[section] is not None:
-                    retstr += (qsection + " = " +
-                               unicode(_dump_value(o[section])) + '\n')
-        elif preserve and isinstance(o[section], InlineTableDict):
-            retstr += (qsection + " = " + _dump_inline_table(o[section]))
-        else:
-            retdict[qsection] = o[section]
-    retstr += arraystr
-    return (retstr, retdict)
-
-
-def _dump_inline_table(section):
-    """Preserve inline table in its compact syntax instead of expanding
-    into subsection.
-
-    https://github.com/toml-lang/toml#user-content-inline-table
-    """
-    retval = ""
-    if isinstance(section, dict):
-        val_list = []
-        for k, v in section.items():
-            val = _dump_inline_table(v)
-            val_list.append(k + " = " + val)
-        retval += "{ " + ", ".join(val_list) + " }\n"
-        return retval
-    else:
-        return unicode(_dump_value(section))
-
-
-def _dump_value(v):
-    dump_funcs = {
-        str: _dump_str,
-        unicode: _dump_str,
-        list: _dump_list,
-        int: lambda v: v,
-        bool: lambda v: unicode(v).lower(),
-        float: _dump_float,
-        datetime.datetime: lambda v: v.isoformat().replace('+00:00', 'Z'),
-    }
-    # Lookup function corresponding to v's type
-    dump_fn = dump_funcs.get(type(v))
-    if dump_fn is None and hasattr(v, '__iter__'):
-        dump_fn = dump_funcs[list]
-    # Evaluate function (if it exists) else return v
-    return dump_fn(v) if dump_fn is not None else dump_funcs[str](v)
-
-
-def _dump_str(v):
-    if sys.version_info < (3,) and hasattr(v, 'decode') and isinstance(v, str):
-        v = v.decode('utf-8')
-    v = "%r" % v
-    if v[0] == 'u':
-        v = v[1:]
-    singlequote = v.startswith("'")
-    if singlequote or v.startswith('"'):
-        v = v[1:-1]
-    if singlequote:
-        v = v.replace("\\'", "'")
-        v = v.replace('"', '\\"')
-    v = v.split("\\x")
-    while len(v) > 1:
-        i = -1
-        if not v[0]:
-            v = v[1:]
-        v[0] = v[0].replace("\\\\", "\\")
-        # No, I don't know why != works and == breaks
-        joinx = v[0][i] != "\\"
-        while v[0][:i] and v[0][i] == "\\":
-            joinx = not joinx
-            i -= 1
-        if joinx:
-            joiner = "x"
-        else:
-            joiner = "u00"
-        v = [v[0] + joiner + v[1]] + v[2:]
-    return unicode('"' + v[0] + '"')
-
-
-def _dump_list(v):
-    retval = "["
-    for u in v:
-        retval += " " + unicode(_dump_value(u)) + ","
-    retval += "]"
-    return retval
-
-
-def _dump_float(v):
-    return "{0:.16}".format(v).replace("e+0", "e+").replace("e-0", "e-")
diff --git a/pipenv/vendor/tomlkit/__init__.py b/pipenv/vendor/tomlkit/__init__.py
index 23d4ef74..89e4cf59 100644
--- a/pipenv/vendor/tomlkit/__init__.py
+++ b/pipenv/vendor/tomlkit/__init__.py
@@ -22,4 +22,4 @@ from .api import value
 from .api import ws
 
 
-__version__ = "0.4.4"
+__version__ = "0.4.6"
diff --git a/pipenv/vendor/tomlkit/container.py b/pipenv/vendor/tomlkit/container.py
index bb3696d9..37014921 100644
--- a/pipenv/vendor/tomlkit/container.py
+++ b/pipenv/vendor/tomlkit/container.py
@@ -4,7 +4,6 @@ from ._compat import decode
 from .exceptions import KeyAlreadyPresent
 from .exceptions import NonExistentKey
 from .items import AoT
-from .items import Bool
 from .items import Comment
 from .items import Item
 from .items import Key
@@ -525,3 +524,21 @@ class Container(dict):
             return NotImplemented
 
         return self.value == other
+
+    def _getstate(self, protocol):
+        return (self._parsed,)
+
+    def __reduce__(self):
+        return self.__reduce_ex__(2)
+
+    def __reduce_ex__(self, protocol):
+        return (
+            self.__class__,
+            self._getstate(protocol),
+            (self._map, self._body, self._parsed),
+        )
+
+    def __setstate__(self, state):
+        self._map = state[0]
+        self._body = state[1]
+        self._parsed = state[2]
diff --git a/pipenv/vendor/tomlkit/exceptions.py b/pipenv/vendor/tomlkit/exceptions.py
index d889a924..46ee938b 100644
--- a/pipenv/vendor/tomlkit/exceptions.py
+++ b/pipenv/vendor/tomlkit/exceptions.py
@@ -85,7 +85,7 @@ class InvalidCharInStringError(ParseError):
     """
 
     def __init__(self, line, col, char):  # type: (int, int, str) -> None
-        message = "Invalid character '{}' in string".format(char)
+        message = "Invalid character {} in string".format(repr(char))
 
         super(InvalidCharInStringError, self).__init__(line, col, message=message)
 
diff --git a/pipenv/vendor/tomlkit/items.py b/pipenv/vendor/tomlkit/items.py
index 26f24701..abece020 100644
--- a/pipenv/vendor/tomlkit/items.py
+++ b/pipenv/vendor/tomlkit/items.py
@@ -17,6 +17,11 @@ from ._compat import decode
 from ._compat import unicode
 from ._utils import escape_string
 
+if PY2:
+    from functools32 import lru_cache
+else:
+    from functools import lru_cache
+
 
 def item(value, _parent=None):
     from .container import Container
@@ -75,18 +80,45 @@ def item(value, _parent=None):
 
 
 class StringType(Enum):
-
+    # Single Line Basic
     SLB = '"'
+    # Multi Line Basic
     MLB = '"""'
+    # Single Line Literal
     SLL = "'"
+    # Multi Line Literal
     MLL = "'''"
 
+    @property
+    @lru_cache(maxsize=None)
+    def unit(self):  # type: () -> str
+        return self.value[0]
+
+    @lru_cache(maxsize=None)
+    def is_basic(self):  # type: () -> bool
+        return self in {StringType.SLB, StringType.MLB}
+
+    @lru_cache(maxsize=None)
     def is_literal(self):  # type: () -> bool
         return self in {StringType.SLL, StringType.MLL}
 
+    @lru_cache(maxsize=None)
+    def is_singleline(self):  # type: () -> bool
+        return self in {StringType.SLB, StringType.SLL}
+
+    @lru_cache(maxsize=None)
     def is_multiline(self):  # type: () -> bool
         return self in {StringType.MLB, StringType.MLL}
 
+    @lru_cache(maxsize=None)
+    def toggle(self):  # type: () -> StringType
+        return {
+            StringType.SLB: StringType.MLB,
+            StringType.MLB: StringType.SLB,
+            StringType.SLL: StringType.MLL,
+            StringType.MLL: StringType.SLL,
+        }[self]
+
 
 class Trivia:
     """
@@ -158,7 +190,10 @@ class Key:
         return hash(self.key)
 
     def __eq__(self, other):  # type: (Key) -> bool
-        return self.key == other.key
+        if isinstance(other, Key):
+            return self.key == other.key
+
+        return self.key == other
 
     def __str__(self):  # type: () -> str
         return self.as_string()
@@ -205,6 +240,15 @@ class Item(object):
 
         return self
 
+    def _getstate(self, protocol=3):
+        return (self._trivia,)
+
+    def __reduce__(self):
+        return self.__reduce_ex__(2)
+
+    def __reduce_ex__(self, protocol):
+        return self.__class__, self._getstate(protocol)
+
 
 class Whitespace(Item):
     """
@@ -240,6 +284,9 @@ class Whitespace(Item):
     def __repr__(self):  # type: () -> str
         return "<{} {}>".format(self.__class__.__name__, repr(self._s))
 
+    def _getstate(self, protocol=3):
+        return self._s, self._fixed
+
 
 class Comment(Item):
     """
@@ -273,7 +320,7 @@ class Integer(int, Item):
         self._raw = raw
         self._sign = False
 
-        if re.match("^[+\-]\d+$", raw):
+        if re.match(r"^[+\-]\d+$", raw):
             self._sign = True
 
     @property
@@ -322,6 +369,9 @@ class Integer(int, Item):
 
         return Integer(result, self._trivia, raw)
 
+    def _getstate(self, protocol=3):
+        return int(self), self._trivia, self._raw
+
 
 class Float(float, Item):
     """
@@ -337,7 +387,7 @@ class Float(float, Item):
         self._raw = raw
         self._sign = False
 
-        if re.match("^[+\-].+$", raw):
+        if re.match(r"^[+\-].+$", raw):
             self._sign = True
 
     @property
@@ -386,6 +436,9 @@ class Float(float, Item):
 
         return Float(result, self._trivia, raw)
 
+    def _getstate(self, protocol=3):
+        return float(self), self._trivia, self._raw
+
 
 class Bool(Item):
     """
@@ -408,13 +461,16 @@ class Bool(Item):
     def as_string(self):  # type: () -> str
         return str(self._value).lower()
 
+    def _getstate(self, protocol=3):
+        return self._value, self._trivia
 
-class DateTime(datetime, Item):
+
+class DateTime(Item, datetime):
     """
     A datetime literal.
     """
 
-    def __new__(cls, value, *_):  # type: (datetime, ...) -> datetime
+    def __new__(cls, value, *_):  # type: (..., datetime, ...) -> datetime
         return datetime.__new__(
             cls,
             value.year,
@@ -458,13 +514,29 @@ class DateTime(datetime, Item):
 
         return DateTime(result, self._trivia, raw)
 
+    def _getstate(self, protocol=3):
+        return (
+            datetime(
+                self.year,
+                self.month,
+                self.day,
+                self.hour,
+                self.minute,
+                self.second,
+                self.microsecond,
+                self.tzinfo,
+            ),
+            self._trivia,
+            self._raw,
+        )
+
 
-class Date(date, Item):
+class Date(Item, date):
     """
     A date literal.
     """
 
-    def __new__(cls, value, *_):  # type: (date, ...) -> date
+    def __new__(cls, value, *_):  # type: (..., date, ...) -> date
         return date.__new__(cls, value.year, value.month, value.day)
 
     def __init__(self, _, trivia, raw):  # type: (date, Trivia, str) -> None
@@ -498,8 +570,11 @@ class Date(date, Item):
 
         return Date(result, self._trivia, raw)
 
+    def _getstate(self, protocol=3):
+        return (datetime(self.year, self.month, self.day), self._trivia, self._raw)
+
 
-class Time(time, Item):
+class Time(Item, time):
     """
     A time literal.
     """
@@ -525,6 +600,13 @@ class Time(time, Item):
     def as_string(self):  # type: () -> str
         return self._raw
 
+    def _getstate(self, protocol=3):
+        return (
+            time(self.hour, self.minute, self.second, self.microsecond, self.tzinfo),
+            self._trivia,
+            self._raw,
+        )
+
 
 class Array(Item, list):
     """
@@ -623,6 +705,9 @@ class Array(Item, list):
     def __repr__(self):
         return str(self)
 
+    def _getstate(self, protocol=3):
+        return self._value, self._trivia
+
 
 class Table(Item, dict):
     """
@@ -637,7 +722,7 @@ class Table(Item, dict):
         is_super_table=False,
         name=None,
         display_name=None,
-    ):  # type: (tomlkit.container.Container, Trivia, bool) -> None
+    ):  # type: (tomlkit.container.Container, Trivia, bool, ...) -> None
         super(Table, self).__init__(trivia)
 
         self.name = name
@@ -790,6 +875,16 @@ class Table(Item, dict):
     def __repr__(self):
         return super(Table, self).__repr__()
 
+    def _getstate(self, protocol=3):
+        return (
+            self._value,
+            self._trivia,
+            self._is_aot_element,
+            self._is_super_table,
+            self.name,
+            self.display_name,
+        )
+
 
 class InlineTable(Item, dict):
     """
@@ -924,6 +1019,9 @@ class InlineTable(Item, dict):
     def __repr__(self):
         return super(InlineTable, self).__repr__()
 
+    def _getstate(self, protocol=3):
+        return (self._value, self._trivia)
+
 
 class String(unicode, Item):
     """
@@ -965,6 +1063,9 @@ class String(unicode, Item):
     def _new(self, result):
         return String(self._t, result, result, self._trivia)
 
+    def _getstate(self, protocol=3):
+        return self._t, unicode(self), self._original, self._trivia
+
 
 class AoT(Item, list):
     """
@@ -974,7 +1075,7 @@ class AoT(Item, list):
     def __init__(
         self, body, name=None, parsed=False
     ):  # type: (List[Table], Optional[str]) -> None
-        self.name = None
+        self.name = name
         self._body = []
         self._parsed = parsed
 
@@ -1025,6 +1126,9 @@ class AoT(Item, list):
     def __repr__(self):  # type: () -> str
         return "<AoT {}>".format(self.value)
 
+    def _getstate(self, protocol=3):
+        return self._body, self.name, self._parsed
+
 
 class Null(Item):
     """
@@ -1044,3 +1148,6 @@ class Null(Item):
 
     def as_string(self):  # type: () -> str
         return ""
+
+    def _getstate(self, protocol=3):
+        return tuple()
diff --git a/pipenv/vendor/tomlkit/parser.py b/pipenv/vendor/tomlkit/parser.py
index 45c8ee8c..7971d9a2 100644
--- a/pipenv/vendor/tomlkit/parser.py
+++ b/pipenv/vendor/tomlkit/parser.py
@@ -75,7 +75,7 @@ class Parser:
         else:
             return self._src[self._marker : self._idx]
 
-    def inc(self):  # type: () -> bool
+    def inc(self, exception=None):  # type: () -> bool
         """
         Increments the parser if the end of the input has not been reached.
         Returns whether or not it was able to advance.
@@ -88,15 +88,17 @@ class Parser:
             self._idx = len(self._src)
             self._current = TOMLChar("\0")
 
-            return False
+            if not exception:
+                return False
+            raise exception
 
-    def inc_n(self, n):  # type: (int) -> bool
+    def inc_n(self, n, exception=None):  # type: (int) -> bool
         """
         Increments the parser by n characters
         if the end of the input has not been reached.
         """
         for _ in range(n):
-            if not self.inc():
+            if not self.inc(exception=exception):
                 return False
 
         return True
@@ -336,7 +338,7 @@ class Parser:
                 self.mark()
 
                 break
-            elif c in " \t\r,":
+            elif c in " \t\r":
                 self.inc()
             else:
                 raise self.parse_error(UnexpectedCharError, (c))
@@ -669,140 +671,143 @@ class Parser:
                 return
 
     def _parse_literal_string(self):  # type: () -> Item
-        return self._parse_string("'")
+        return self._parse_string(StringType.SLL)
 
     def _parse_basic_string(self):  # type: () -> Item
-        return self._parse_string('"')
+        return self._parse_string(StringType.SLB)
+
+    def _parse_escaped_char(self, multiline):
+        if multiline and self._current.is_ws():
+            # When the last non-whitespace character on a line is
+            # a \, it will be trimmed along with all whitespace
+            # (including newlines) up to the next non-whitespace
+            # character or closing delimiter.
+            # """\
+            #     hello \
+            #     world"""
+            tmp = ""
+            while self._current.is_ws():
+                tmp += self._current
+                # consume the whitespace, EOF here is an issue
+                # (middle of string)
+                self.inc(exception=UnexpectedEofError)
+                continue
 
-    def _parse_string(self, delim):  # type: (str) -> Item
-        multiline = False
-        value = ""
+            # the escape followed by whitespace must have a newline
+            # before any other chars
+            if "\n" not in tmp:
+                raise self.parse_error(InvalidCharInStringError, (self._current,))
 
-        if delim == "'":
-            str_type = StringType.SLL
-        else:
-            str_type = StringType.SLB
+            return ""
 
-        # Skip opening delim
-        if not self.inc():
-            return self.parse_error(UnexpectedEofError)
+        if self._current in _escaped:
+            c = _escaped[self._current]
 
-        if self._current == delim:
-            self.inc()
+            # consume this char, EOF here is an issue (middle of string)
+            self.inc(exception=UnexpectedEofError)
 
-            if self._current == delim:
-                multiline = True
-                if delim == "'":
-                    str_type = StringType.MLL
-                else:
-                    str_type = StringType.MLB
+            return c
 
-                if not self.inc():
-                    return self.parse_error(UnexpectedEofError)
-            else:
-                # Empty string
-                return String(str_type, "", "", Trivia())
+        if self._current in {"u", "U"}:
+            # this needs to be a unicode
+            u, ue = self._peek_unicode(self._current == "U")
+            if u is not None:
+                # consume the U char and the unicode value
+                self.inc_n(len(ue) + 1)
 
-        self.mark()
-        if self._current == "\n":
-            # The first new line should be discarded
-            self.inc()
+                return u
 
-        previous = None
-        escaped = False
-        while True:
-            if (
-                previous != "\\"
-                or previous == "\\"
-                and (escaped or str_type.is_literal())
-            ) and self._current == delim:
-                val = self.extract()
-
-                if multiline:
-                    stop = True
-                    for _ in range(3):
-                        if self._current != delim:
-                            # Not a triple quote, leave in result as-is.
-                            stop = False
+        raise self.parse_error(InvalidCharInStringError, (self._current,))
 
-                            # Adding back the quote character
-                            value += delim
-                            break
+    def _parse_string(self, delim):  # type: (str) -> Item
+        delim = StringType(delim)
+        assert delim.is_singleline()
 
-                        self.inc()  # TODO: Handle EOF
+        # only keep parsing for string if the current character matches the delim
+        if self._current != delim.unit:
+            raise ValueError("Expecting a {!r} character".format(delim))
 
-                    if not stop:
-                        continue
-                else:
-                    self.inc()
+        # consume the opening/first delim, EOF here is an issue
+        # (middle of string or middle of delim)
+        self.inc(exception=UnexpectedEofError)
 
-                return String(str_type, value, val, Trivia())
-            else:
-                if previous == "\\" and self._current.is_ws() and multiline:
-                    while self._current.is_ws():
-                        previous = self._current
+        if self._current == delim.unit:
+            # consume the closing/second delim, we do not care if EOF occurs as
+            # that would simply imply an empty single line string
+            if not self.inc() or self._current != delim.unit:
+                # Empty string
+                return String(delim, "", "", Trivia())
 
-                        self.inc()
-                        continue
+            # consume the third delim, EOF here is an issue (middle of string)
+            self.inc(exception=UnexpectedEofError)
 
-                    if self._current == delim:
-                        continue
+            delim = delim.toggle()  # convert delim to multi delim
 
-                if previous == "\\":
-                    if self._current == "\\" and not escaped:
-                        if not str_type.is_literal():
-                            escaped = True
-                        else:
-                            value += self._current
+        self.mark()  # to extract the original string with whitespace and all
+        value = ""
 
-                        previous = self._current
+        # A newline immediately following the opening delimiter will be trimmed.
+        if delim.is_multiline() and self._current == "\n":
+            # consume the newline, EOF here is an issue (middle of string)
+            self.inc(exception=UnexpectedEofError)
 
-                        if not self.inc():
-                            raise self.parse_error(UnexpectedEofError)
+        escaped = False  # whether the previous key was ESCAPE
+        while True:
+            if delim.is_singleline() and self._current.is_nl():
+                # single line cannot have actual newline characters
+                raise self.parse_error(InvalidCharInStringError, (self._current,))
+            elif not escaped and self._current == delim.unit:
+                # try to process current as a closing delim
+                original = self.extract()
+
+                close = ""
+                if delim.is_multiline():
+                    # try consuming three delims as this would mean the end of
+                    # the string
+                    for last in [False, False, True]:
+                        if self._current != delim.unit:
+                            # Not a triple quote, leave in result as-is.
+                            # Adding back the characters we already consumed
+                            value += close
+                            close = ""  # clear the close
+                            break
 
-                        continue
-                    elif self._current in _escaped and not escaped:
-                        if not str_type.is_literal():
-                            value = value[:-1]
-                            value += _escaped[self._current]
-                        else:
-                            value += self._current
-                    elif self._current in {"u", "U"} and not escaped:
-                        # Maybe unicode
-                        u, ue = self._peek_unicode(self._current == "U")
-                        if u is not None:
-                            value = value[:-1]
-                            value += u
-                            self.inc_n(len(ue))
-                        else:
-                            if not escaped and not str_type.is_literal():
-                                raise self.parse_error(
-                                    InvalidCharInStringError, (self._current,)
-                                )
-
-                            value += self._current
-                    else:
-                        if not escaped and not str_type.is_literal():
-                            raise self.parse_error(
-                                InvalidCharInStringError, (self._current,)
-                            )
+                        close += delim.unit
 
-                        value += self._current
+                        # consume this delim, EOF here is only an issue if this
+                        # is not the third (last) delim character
+                        self.inc(exception=UnexpectedEofError if not last else None)
 
-                    if self._current.is_ws() and multiline and not escaped:
+                    if not close:  # if there is no close characters, keep parsing
                         continue
                 else:
-                    value += self._current
+                    close = delim.unit
 
-                if escaped:
-                    escaped = False
+                    # consume the closing delim, we do not care if EOF occurs as
+                    # that would simply imply the end of self._src
+                    self.inc()
 
-                previous = self._current
-                if not self.inc():
-                    raise self.parse_error(UnexpectedEofError)
+                return String(delim, value, original, Trivia())
+            elif delim.is_basic() and escaped:
+                # attempt to parse the current char as an escaped value, an exception
+                # is raised if this fails
+                value += self._parse_escaped_char(delim.is_multiline())
+
+                # no longer escaped
+                escaped = False
+            elif delim.is_basic() and self._current == "\\":
+                # the next char is being escaped
+                escaped = True
+
+                # consume this char, EOF here is an issue (middle of string)
+                self.inc(exception=UnexpectedEofError)
+            else:
+                # this is either a literal string where we keep everything as is,
+                # or this is not a special escaped char in a basic string
+                value += self._current
 
-                if previous == "\\" and self._current.is_ws() and multiline:
-                    value = value[:-1]
+                # consume this char, EOF here is an issue (middle of string)
+                self.inc(exception=UnexpectedEofError)
 
     def _parse_table(
         self, parent_name=None
diff --git a/pipenv/vendor/tomlkit/toml_char.py b/pipenv/vendor/tomlkit/toml_char.py
index 8a3bf9e1..92f1a9c9 100644
--- a/pipenv/vendor/tomlkit/toml_char.py
+++ b/pipenv/vendor/tomlkit/toml_char.py
@@ -1,7 +1,13 @@
 import string
 
+from ._compat import PY2
 from ._compat import unicode
 
+if PY2:
+    from functools32 import lru_cache
+else:
+    from functools import lru_cache
+
 
 class TOMLChar(unicode):
     def __init__(self, c):
@@ -10,36 +16,42 @@ class TOMLChar(unicode):
         if len(self) > 1:
             raise ValueError("A TOML character must be of length 1")
 
+    @lru_cache(maxsize=None)
     def is_bare_key_char(self):  # type: () -> bool
         """
         Whether the character is a valid bare key name or not.
         """
         return self in string.ascii_letters + string.digits + "-" + "_"
 
+    @lru_cache(maxsize=None)
     def is_kv_sep(self):  # type: () -> bool
         """
         Whether the character is a valid key/value separator ot not.
         """
         return self in "= \t"
 
+    @lru_cache(maxsize=None)
     def is_int_float_char(self):  # type: () -> bool
         """
         Whether the character if a valid integer or float value character or not.
         """
         return self in string.digits + "+" + "-" + "_" + "." + "e"
 
+    @lru_cache(maxsize=None)
     def is_ws(self):  # type: () -> bool
         """
         Whether the character is a whitespace character or not.
         """
         return self in " \t\r\n"
 
+    @lru_cache(maxsize=None)
     def is_nl(self):  # type: () -> bool
         """
         Whether the character is a new line character or not.
         """
         return self in "\n\r"
 
+    @lru_cache(maxsize=None)
     def is_spaces(self):  # type: () -> bool
         """
         Whether the character is a space or not
diff --git a/pipenv/vendor/urllib3/__init__.py b/pipenv/vendor/urllib3/__init__.py
old mode 100755
new mode 100644
index 4bd533b5..75725167
--- a/pipenv/vendor/urllib3/__init__.py
+++ b/pipenv/vendor/urllib3/__init__.py
@@ -23,16 +23,11 @@ from .util.retry import Retry
 
 # Set default logging handler to avoid "No handler found" warnings.
 import logging
-try:  # Python 2.7+
-    from logging import NullHandler
-except ImportError:
-    class NullHandler(logging.Handler):
-        def emit(self, record):
-            pass
+from logging import NullHandler
 
 __author__ = 'Andrey Petrov (andrey.petrov@shazow.net)'
 __license__ = 'MIT'
-__version__ = '1.23'
+__version__ = '1.24'
 
 __all__ = (
     'HTTPConnectionPool',
diff --git a/pipenv/vendor/urllib3/_collections.py b/pipenv/vendor/urllib3/_collections.py
old mode 100755
new mode 100644
index 6e36b84e..34f23811
--- a/pipenv/vendor/urllib3/_collections.py
+++ b/pipenv/vendor/urllib3/_collections.py
@@ -14,10 +14,7 @@ except ImportError:  # Platform-specific: No threads available
             pass
 
 
-try:  # Python 2.7+
-    from collections import OrderedDict
-except ImportError:
-    from .packages.ordered_dict import OrderedDict
+from collections import OrderedDict
 from .exceptions import InvalidHeader
 from .packages.six import iterkeys, itervalues, PY3
 
diff --git a/pipenv/vendor/urllib3/connection.py b/pipenv/vendor/urllib3/connection.py
old mode 100755
new mode 100644
index a03b573f..02b36654
--- a/pipenv/vendor/urllib3/connection.py
+++ b/pipenv/vendor/urllib3/connection.py
@@ -2,7 +2,6 @@ from __future__ import absolute_import
 import datetime
 import logging
 import os
-import sys
 import socket
 from socket import error as SocketError, timeout as SocketTimeout
 import warnings
@@ -78,9 +77,6 @@ class HTTPConnection(_HTTPConnection, object):
 
       - ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`
       - ``source_address``: Set the source address for the current connection.
-
-        .. note:: This is ignored for Python 2.6. It is only applied for 2.7 and 3.x
-
       - ``socket_options``: Set specific options on the underlying socket. If not specified, then
         defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
         Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.
@@ -108,21 +104,13 @@ class HTTPConnection(_HTTPConnection, object):
         if six.PY3:  # Python 3
             kw.pop('strict', None)
 
-        # Pre-set source_address in case we have an older Python like 2.6.
+        # Pre-set source_address.
         self.source_address = kw.get('source_address')
 
-        if sys.version_info < (2, 7):  # Python 2.6
-            # _HTTPConnection on Python 2.6 will balk at this keyword arg, but
-            # not newer versions. We can still use it when creating a
-            # connection though, so we pop it *after* we have saved it as
-            # self.source_address.
-            kw.pop('source_address', None)
-
         #: The socket options provided by the user. If no options are
         #: provided, we use the default options.
         self.socket_options = kw.pop('socket_options', self.default_socket_options)
 
-        # Superclass also sets self.source_address in Python 2.7+.
         _HTTPConnection.__init__(self, *args, **kw)
 
     @property
@@ -183,10 +171,7 @@ class HTTPConnection(_HTTPConnection, object):
 
     def _prepare_conn(self, conn):
         self.sock = conn
-        # the _tunnel_host attribute was added in python 2.6.3 (via
-        # http://hg.python.org/cpython/rev/0f57b30a152f) so pythons 2.6(0-2) do
-        # not have them.
-        if getattr(self, '_tunnel_host', None):
+        if self._tunnel_host:
             # TODO: Fix tunnel so it doesn't depend on self.sock state.
             self._tunnel()
             # Mark this connection as not reusable
@@ -217,13 +202,13 @@ class HTTPConnection(_HTTPConnection, object):
         self.endheaders()
 
         if body is not None:
-            stringish_types = six.string_types + (six.binary_type,)
+            stringish_types = six.string_types + (bytes,)
             if isinstance(body, stringish_types):
                 body = (body,)
             for chunk in body:
                 if not chunk:
                     continue
-                if not isinstance(chunk, six.binary_type):
+                if not isinstance(chunk, bytes):
                     chunk = chunk.encode('utf8')
                 len_str = hex(len(chunk))[2:]
                 self.send(len_str.encode('utf-8'))
@@ -242,7 +227,7 @@ class HTTPSConnection(HTTPConnection):
 
     def __init__(self, host, port=None, key_file=None, cert_file=None,
                  strict=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
-                 ssl_context=None, **kw):
+                 ssl_context=None, server_hostname=None, **kw):
 
         HTTPConnection.__init__(self, host, port, strict=strict,
                                 timeout=timeout, **kw)
@@ -250,6 +235,7 @@ class HTTPSConnection(HTTPConnection):
         self.key_file = key_file
         self.cert_file = cert_file
         self.ssl_context = ssl_context
+        self.server_hostname = server_hostname
 
         # Required property for Google AppEngine 1.9.0 which otherwise causes
         # HTTPS requests to go out as HTTP. (See Issue #356)
@@ -270,6 +256,7 @@ class HTTPSConnection(HTTPConnection):
             keyfile=self.key_file,
             certfile=self.cert_file,
             ssl_context=self.ssl_context,
+            server_hostname=self.server_hostname
         )
 
 
@@ -312,12 +299,9 @@ class VerifiedHTTPSConnection(HTTPSConnection):
     def connect(self):
         # Add certificate verification
         conn = self._new_conn()
-
         hostname = self.host
-        if getattr(self, '_tunnel_host', None):
-            # _tunnel_host was added in Python 2.6.3
-            # (See: http://hg.python.org/cpython/rev/0f57b30a152f)
 
+        if self._tunnel_host:
             self.sock = conn
             # Calls self._set_hostport(), so self.host is
             # self._tunnel_host below.
@@ -328,6 +312,10 @@ class VerifiedHTTPSConnection(HTTPSConnection):
             # Override the host with the one we're requesting data from.
             hostname = self._tunnel_host
 
+        server_hostname = hostname
+        if self.server_hostname is not None:
+            server_hostname = self.server_hostname
+
         is_time_off = datetime.date.today() < RECENT_DATE
         if is_time_off:
             warnings.warn((
@@ -352,7 +340,7 @@ class VerifiedHTTPSConnection(HTTPSConnection):
             certfile=self.cert_file,
             ca_certs=self.ca_certs,
             ca_cert_dir=self.ca_cert_dir,
-            server_hostname=hostname,
+            server_hostname=server_hostname,
             ssl_context=context)
 
         if self.assert_fingerprint:
@@ -373,7 +361,7 @@ class VerifiedHTTPSConnection(HTTPSConnection):
                     'for details.)'.format(hostname)),
                     SubjectAltNameWarning
                 )
-            _match_hostname(cert, self.assert_hostname or hostname)
+            _match_hostname(cert, self.assert_hostname or server_hostname)
 
         self.is_verified = (
             context.verify_mode == ssl.CERT_REQUIRED or
diff --git a/pipenv/vendor/urllib3/connectionpool.py b/pipenv/vendor/urllib3/connectionpool.py
old mode 100755
new mode 100644
index 8fcb0bce..f7a8f193
--- a/pipenv/vendor/urllib3/connectionpool.py
+++ b/pipenv/vendor/urllib3/connectionpool.py
@@ -89,7 +89,7 @@ class ConnectionPool(object):
 
 
 # This is taken from http://hg.python.org/cpython/file/7aaba721ebc0/Lib/socket.py#l252
-_blocking_errnos = set([errno.EAGAIN, errno.EWOULDBLOCK])
+_blocking_errnos = {errno.EAGAIN, errno.EWOULDBLOCK}
 
 
 class HTTPConnectionPool(ConnectionPool, RequestMethods):
@@ -313,7 +313,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):
         # Catch possible read timeouts thrown as SSL errors. If not the
         # case, rethrow the original. We need to do this because of:
         # http://bugs.python.org/issue10272
-        if 'timed out' in str(err) or 'did not complete (read)' in str(err):  # Python 2.6
+        if 'timed out' in str(err) or 'did not complete (read)' in str(err):  # Python < 2.7.4
             raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
 
     def _make_request(self, conn, method, url, timeout=_Default, chunked=False,
@@ -375,7 +375,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):
         try:
             try:  # Python 2.7, use buffering of HTTP responses
                 httplib_response = conn.getresponse(buffering=True)
-            except TypeError:  # Python 2.6 and older, Python 3
+            except TypeError:  # Python 3
                 try:
                     httplib_response = conn.getresponse()
                 except Exception as e:
@@ -801,17 +801,7 @@ class HTTPSConnectionPool(HTTPConnectionPool):
         Establish tunnel connection early, because otherwise httplib
         would improperly set Host: header to proxy's IP:port.
         """
-        # Python 2.7+
-        try:
-            set_tunnel = conn.set_tunnel
-        except AttributeError:  # Platform-specific: Python 2.6
-            set_tunnel = conn._set_tunnel
-
-        if sys.version_info <= (2, 6, 4) and not self.proxy_headers:  # Python 2.6.4 and older
-            set_tunnel(self._proxy_host, self.port)
-        else:
-            set_tunnel(self._proxy_host, self.port, self.proxy_headers)
-
+        conn.set_tunnel(self._proxy_host, self.port, self.proxy_headers)
         conn.connect()
 
     def _new_conn(self):
diff --git a/pipenv/vendor/urllib3/contrib/__init__.py b/pipenv/vendor/urllib3/contrib/__init__.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/contrib/_appengine_environ.py b/pipenv/vendor/urllib3/contrib/_appengine_environ.py
new file mode 100644
index 00000000..f3e00942
--- /dev/null
+++ b/pipenv/vendor/urllib3/contrib/_appengine_environ.py
@@ -0,0 +1,30 @@
+"""
+This module provides means to detect the App Engine environment.
+"""
+
+import os
+
+
+def is_appengine():
+    return (is_local_appengine() or
+            is_prod_appengine() or
+            is_prod_appengine_mvms())
+
+
+def is_appengine_sandbox():
+    return is_appengine() and not is_prod_appengine_mvms()
+
+
+def is_local_appengine():
+    return ('APPENGINE_RUNTIME' in os.environ and
+            'Development/' in os.environ['SERVER_SOFTWARE'])
+
+
+def is_prod_appengine():
+    return ('APPENGINE_RUNTIME' in os.environ and
+            'Google App Engine/' in os.environ['SERVER_SOFTWARE'] and
+            not is_prod_appengine_mvms())
+
+
+def is_prod_appengine_mvms():
+    return os.environ.get('GAE_VM', False) == 'true'
diff --git a/pipenv/vendor/urllib3/contrib/_securetransport/__init__.py b/pipenv/vendor/urllib3/contrib/_securetransport/__init__.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/contrib/_securetransport/bindings.py b/pipenv/vendor/urllib3/contrib/_securetransport/bindings.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/contrib/_securetransport/low_level.py b/pipenv/vendor/urllib3/contrib/_securetransport/low_level.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/contrib/appengine.py b/pipenv/vendor/urllib3/contrib/appengine.py
old mode 100755
new mode 100644
index 66922e06..2952f114
--- a/pipenv/vendor/urllib3/contrib/appengine.py
+++ b/pipenv/vendor/urllib3/contrib/appengine.py
@@ -39,8 +39,8 @@ urllib3 on Google App Engine:
 """
 
 from __future__ import absolute_import
+import io
 import logging
-import os
 import warnings
 from ..packages.six.moves.urllib.parse import urljoin
 
@@ -53,11 +53,11 @@ from ..exceptions import (
     SSLError
 )
 
-from ..packages.six import BytesIO
 from ..request import RequestMethods
 from ..response import HTTPResponse
 from ..util.timeout import Timeout
 from ..util.retry import Retry
+from . import _appengine_environ
 
 try:
     from google.appengine.api import urlfetch
@@ -239,7 +239,7 @@ class AppEngineManager(RequestMethods):
         original_response = HTTPResponse(
             # In order for decoding to work, we must present the content as
             # a file-like object.
-            body=BytesIO(urlfetch_resp.content),
+            body=io.BytesIO(urlfetch_resp.content),
             msg=urlfetch_resp.header_msg,
             headers=urlfetch_resp.headers,
             status=urlfetch_resp.status_code,
@@ -247,7 +247,7 @@ class AppEngineManager(RequestMethods):
         )
 
         return HTTPResponse(
-            body=BytesIO(urlfetch_resp.content),
+            body=io.BytesIO(urlfetch_resp.content),
             headers=urlfetch_resp.headers,
             status=urlfetch_resp.status_code,
             original_response=original_response,
@@ -280,26 +280,10 @@ class AppEngineManager(RequestMethods):
         return retries
 
 
-def is_appengine():
-    return (is_local_appengine() or
-            is_prod_appengine() or
-            is_prod_appengine_mvms())
+# Alias methods from _appengine_environ to maintain public API interface.
 
-
-def is_appengine_sandbox():
-    return is_appengine() and not is_prod_appengine_mvms()
-
-
-def is_local_appengine():
-    return ('APPENGINE_RUNTIME' in os.environ and
-            'Development/' in os.environ['SERVER_SOFTWARE'])
-
-
-def is_prod_appengine():
-    return ('APPENGINE_RUNTIME' in os.environ and
-            'Google App Engine/' in os.environ['SERVER_SOFTWARE'] and
-            not is_prod_appengine_mvms())
-
-
-def is_prod_appengine_mvms():
-    return os.environ.get('GAE_VM', False) == 'true'
+is_appengine = _appengine_environ.is_appengine
+is_appengine_sandbox = _appengine_environ.is_appengine_sandbox
+is_local_appengine = _appengine_environ.is_local_appengine
+is_prod_appengine = _appengine_environ.is_prod_appengine
+is_prod_appengine_mvms = _appengine_environ.is_prod_appengine_mvms
diff --git a/pipenv/vendor/urllib3/contrib/ntlmpool.py b/pipenv/vendor/urllib3/contrib/ntlmpool.py
old mode 100755
new mode 100644
index 642e99ed..8ea127c5
--- a/pipenv/vendor/urllib3/contrib/ntlmpool.py
+++ b/pipenv/vendor/urllib3/contrib/ntlmpool.py
@@ -43,8 +43,7 @@ class NTLMConnectionPool(HTTPSConnectionPool):
         log.debug('Starting NTLM HTTPS connection no. %d: https://%s%s',
                   self.num_connections, self.host, self.authurl)
 
-        headers = {}
-        headers['Connection'] = 'Keep-Alive'
+        headers = {'Connection': 'Keep-Alive'}
         req_header = 'Authorization'
         resp_header = 'www-authenticate'
 
diff --git a/pipenv/vendor/urllib3/contrib/pyopenssl.py b/pipenv/vendor/urllib3/contrib/pyopenssl.py
old mode 100755
new mode 100644
index 4d4b1aff..7c0e9465
--- a/pipenv/vendor/urllib3/contrib/pyopenssl.py
+++ b/pipenv/vendor/urllib3/contrib/pyopenssl.py
@@ -163,6 +163,9 @@ def _dnsname_to_stdlib(name):
     from ASCII bytes. We need to idna-encode that string to get it back, and
     then on Python 3 we also need to convert to unicode via UTF-8 (the stdlib
     uses PyUnicode_FromStringAndSize on it, which decodes via UTF-8).
+
+    If the name cannot be idna-encoded then we return None signalling that
+    the name given should be skipped.
     """
     def idna_encode(name):
         """
@@ -172,14 +175,19 @@ def _dnsname_to_stdlib(name):
         """
         import idna
 
-        for prefix in [u'*.', u'.']:
-            if name.startswith(prefix):
-                name = name[len(prefix):]
-                return prefix.encode('ascii') + idna.encode(name)
-        return idna.encode(name)
+        try:
+            for prefix in [u'*.', u'.']:
+                if name.startswith(prefix):
+                    name = name[len(prefix):]
+                    return prefix.encode('ascii') + idna.encode(name)
+            return idna.encode(name)
+        except idna.core.IDNAError:
+            return None
 
     name = idna_encode(name)
-    if sys.version_info >= (3, 0):
+    if name is None:
+        return None
+    elif sys.version_info >= (3, 0):
         name = name.decode('utf-8')
     return name
 
@@ -223,9 +231,10 @@ def get_subj_alt_name(peer_cert):
     # Sadly the DNS names need to be idna encoded and then, on Python 3, UTF-8
     # decoded. This is pretty frustrating, but that's what the standard library
     # does with certificates, and so we need to attempt to do the same.
+    # We also want to skip over names which cannot be idna encoded.
     names = [
-        ('DNS', _dnsname_to_stdlib(name))
-        for name in ext.get_values_for_type(x509.DNSName)
+        ('DNS', name) for name in map(_dnsname_to_stdlib, ext.get_values_for_type(x509.DNSName))
+        if name is not None
     ]
     names.extend(
         ('IP Address', str(name))
diff --git a/pipenv/vendor/urllib3/contrib/securetransport.py b/pipenv/vendor/urllib3/contrib/securetransport.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/contrib/socks.py b/pipenv/vendor/urllib3/contrib/socks.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/exceptions.py b/pipenv/vendor/urllib3/exceptions.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/fields.py b/pipenv/vendor/urllib3/fields.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/filepost.py b/pipenv/vendor/urllib3/filepost.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/packages/__init__.py b/pipenv/vendor/urllib3/packages/__init__.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/packages/backports/__init__.py b/pipenv/vendor/urllib3/packages/backports/__init__.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/packages/backports/makefile.py b/pipenv/vendor/urllib3/packages/backports/makefile.py
old mode 100755
new mode 100644
index 75b80dcf..740db377
--- a/pipenv/vendor/urllib3/packages/backports/makefile.py
+++ b/pipenv/vendor/urllib3/packages/backports/makefile.py
@@ -16,7 +16,7 @@ def backport_makefile(self, mode="r", buffering=None, encoding=None,
     """
     Backport of ``socket.makefile`` from Python 3.5.
     """
-    if not set(mode) <= set(["r", "w", "b"]):
+    if not set(mode) <= {"r", "w", "b"}:
         raise ValueError(
             "invalid mode %r (only r, w, b allowed)" % (mode,)
         )
diff --git a/pipenv/vendor/urllib3/packages/ordered_dict.py b/pipenv/vendor/urllib3/packages/ordered_dict.py
deleted file mode 100755
index 4479363c..00000000
--- a/pipenv/vendor/urllib3/packages/ordered_dict.py
+++ /dev/null
@@ -1,259 +0,0 @@
-# Backport of OrderedDict() class that runs on Python 2.4, 2.5, 2.6, 2.7 and pypy.
-# Passes Python2.7's test suite and incorporates all the latest updates.
-# Copyright 2009 Raymond Hettinger, released under the MIT License.
-# http://code.activestate.com/recipes/576693/
-try:
-    from thread import get_ident as _get_ident
-except ImportError:
-    from dummy_thread import get_ident as _get_ident
-
-try:
-    from _abcoll import KeysView, ValuesView, ItemsView
-except ImportError:
-    pass
-
-
-class OrderedDict(dict):
-    'Dictionary that remembers insertion order'
-    # An inherited dict maps keys to values.
-    # The inherited dict provides __getitem__, __len__, __contains__, and get.
-    # The remaining methods are order-aware.
-    # Big-O running times for all methods are the same as for regular dictionaries.
-
-    # The internal self.__map dictionary maps keys to links in a doubly linked list.
-    # The circular doubly linked list starts and ends with a sentinel element.
-    # The sentinel element never gets deleted (this simplifies the algorithm).
-    # Each link is stored as a list of length three:  [PREV, NEXT, KEY].
-
-    def __init__(self, *args, **kwds):
-        '''Initialize an ordered dictionary.  Signature is the same as for
-        regular dictionaries, but keyword arguments are not recommended
-        because their insertion order is arbitrary.
-
-        '''
-        if len(args) > 1:
-            raise TypeError('expected at most 1 arguments, got %d' % len(args))
-        try:
-            self.__root
-        except AttributeError:
-            self.__root = root = []                     # sentinel node
-            root[:] = [root, root, None]
-            self.__map = {}
-        self.__update(*args, **kwds)
-
-    def __setitem__(self, key, value, dict_setitem=dict.__setitem__):
-        'od.__setitem__(i, y) <==> od[i]=y'
-        # Setting a new item creates a new link which goes at the end of the linked
-        # list, and the inherited dictionary is updated with the new key/value pair.
-        if key not in self:
-            root = self.__root
-            last = root[0]
-            last[1] = root[0] = self.__map[key] = [last, root, key]
-        dict_setitem(self, key, value)
-
-    def __delitem__(self, key, dict_delitem=dict.__delitem__):
-        'od.__delitem__(y) <==> del od[y]'
-        # Deleting an existing item uses self.__map to find the link which is
-        # then removed by updating the links in the predecessor and successor nodes.
-        dict_delitem(self, key)
-        link_prev, link_next, key = self.__map.pop(key)
-        link_prev[1] = link_next
-        link_next[0] = link_prev
-
-    def __iter__(self):
-        'od.__iter__() <==> iter(od)'
-        root = self.__root
-        curr = root[1]
-        while curr is not root:
-            yield curr[2]
-            curr = curr[1]
-
-    def __reversed__(self):
-        'od.__reversed__() <==> reversed(od)'
-        root = self.__root
-        curr = root[0]
-        while curr is not root:
-            yield curr[2]
-            curr = curr[0]
-
-    def clear(self):
-        'od.clear() -> None.  Remove all items from od.'
-        try:
-            for node in self.__map.itervalues():
-                del node[:]
-            root = self.__root
-            root[:] = [root, root, None]
-            self.__map.clear()
-        except AttributeError:
-            pass
-        dict.clear(self)
-
-    def popitem(self, last=True):
-        '''od.popitem() -> (k, v), return and remove a (key, value) pair.
-        Pairs are returned in LIFO order if last is true or FIFO order if false.
-
-        '''
-        if not self:
-            raise KeyError('dictionary is empty')
-        root = self.__root
-        if last:
-            link = root[0]
-            link_prev = link[0]
-            link_prev[1] = root
-            root[0] = link_prev
-        else:
-            link = root[1]
-            link_next = link[1]
-            root[1] = link_next
-            link_next[0] = root
-        key = link[2]
-        del self.__map[key]
-        value = dict.pop(self, key)
-        return key, value
-
-    # -- the following methods do not depend on the internal structure --
-
-    def keys(self):
-        'od.keys() -> list of keys in od'
-        return list(self)
-
-    def values(self):
-        'od.values() -> list of values in od'
-        return [self[key] for key in self]
-
-    def items(self):
-        'od.items() -> list of (key, value) pairs in od'
-        return [(key, self[key]) for key in self]
-
-    def iterkeys(self):
-        'od.iterkeys() -> an iterator over the keys in od'
-        return iter(self)
-
-    def itervalues(self):
-        'od.itervalues -> an iterator over the values in od'
-        for k in self:
-            yield self[k]
-
-    def iteritems(self):
-        'od.iteritems -> an iterator over the (key, value) items in od'
-        for k in self:
-            yield (k, self[k])
-
-    def update(*args, **kwds):
-        '''od.update(E, **F) -> None.  Update od from dict/iterable E and F.
-
-        If E is a dict instance, does:           for k in E: od[k] = E[k]
-        If E has a .keys() method, does:         for k in E.keys(): od[k] = E[k]
-        Or if E is an iterable of items, does:   for k, v in E: od[k] = v
-        In either case, this is followed by:     for k, v in F.items(): od[k] = v
-
-        '''
-        if len(args) > 2:
-            raise TypeError('update() takes at most 2 positional '
-                            'arguments (%d given)' % (len(args),))
-        elif not args:
-            raise TypeError('update() takes at least 1 argument (0 given)')
-        self = args[0]
-        # Make progressively weaker assumptions about "other"
-        other = ()
-        if len(args) == 2:
-            other = args[1]
-        if isinstance(other, dict):
-            for key in other:
-                self[key] = other[key]
-        elif hasattr(other, 'keys'):
-            for key in other.keys():
-                self[key] = other[key]
-        else:
-            for key, value in other:
-                self[key] = value
-        for key, value in kwds.items():
-            self[key] = value
-
-    __update = update  # let subclasses override update without breaking __init__
-
-    __marker = object()
-
-    def pop(self, key, default=__marker):
-        '''od.pop(k[,d]) -> v, remove specified key and return the corresponding value.
-        If key is not found, d is returned if given, otherwise KeyError is raised.
-
-        '''
-        if key in self:
-            result = self[key]
-            del self[key]
-            return result
-        if default is self.__marker:
-            raise KeyError(key)
-        return default
-
-    def setdefault(self, key, default=None):
-        'od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od'
-        if key in self:
-            return self[key]
-        self[key] = default
-        return default
-
-    def __repr__(self, _repr_running={}):
-        'od.__repr__() <==> repr(od)'
-        call_key = id(self), _get_ident()
-        if call_key in _repr_running:
-            return '...'
-        _repr_running[call_key] = 1
-        try:
-            if not self:
-                return '%s()' % (self.__class__.__name__,)
-            return '%s(%r)' % (self.__class__.__name__, self.items())
-        finally:
-            del _repr_running[call_key]
-
-    def __reduce__(self):
-        'Return state information for pickling'
-        items = [[k, self[k]] for k in self]
-        inst_dict = vars(self).copy()
-        for k in vars(OrderedDict()):
-            inst_dict.pop(k, None)
-        if inst_dict:
-            return (self.__class__, (items,), inst_dict)
-        return self.__class__, (items,)
-
-    def copy(self):
-        'od.copy() -> a shallow copy of od'
-        return self.__class__(self)
-
-    @classmethod
-    def fromkeys(cls, iterable, value=None):
-        '''OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
-        and values equal to v (which defaults to None).
-
-        '''
-        d = cls()
-        for key in iterable:
-            d[key] = value
-        return d
-
-    def __eq__(self, other):
-        '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
-        while comparison to a regular mapping is order-insensitive.
-
-        '''
-        if isinstance(other, OrderedDict):
-            return len(self)==len(other) and self.items() == other.items()
-        return dict.__eq__(self, other)
-
-    def __ne__(self, other):
-        return not self == other
-
-    # -- the following methods are only used in Python 2.7 --
-
-    def viewkeys(self):
-        "od.viewkeys() -> a set-like object providing a view on od's keys"
-        return KeysView(self)
-
-    def viewvalues(self):
-        "od.viewvalues() -> an object providing a view on od's values"
-        return ValuesView(self)
-
-    def viewitems(self):
-        "od.viewitems() -> a set-like object providing a view on od's items"
-        return ItemsView(self)
diff --git a/pipenv/vendor/urllib3/packages/six.py b/pipenv/vendor/urllib3/packages/six.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/packages/ssl_match_hostname/__init__.py b/pipenv/vendor/urllib3/packages/ssl_match_hostname/__init__.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/packages/ssl_match_hostname/_implementation.py b/pipenv/vendor/urllib3/packages/ssl_match_hostname/_implementation.py
old mode 100755
new mode 100644
index 1fd42f38..d6e66c01
--- a/pipenv/vendor/urllib3/packages/ssl_match_hostname/_implementation.py
+++ b/pipenv/vendor/urllib3/packages/ssl_match_hostname/_implementation.py
@@ -9,8 +9,7 @@ import sys
 # ipaddress has been backported to 2.6+ in pypi.  If it is installed on the
 # system, use it to handle IPAddress ServerAltnames (this was added in
 # python-3.5) otherwise only do DNS matching.  This allows
-# backports.ssl_match_hostname to continue to be used all the way back to
-# python-2.4.
+# backports.ssl_match_hostname to continue to be used in Python 2.7.
 try:
     import ipaddress
 except ImportError:
diff --git a/pipenv/vendor/urllib3/poolmanager.py b/pipenv/vendor/urllib3/poolmanager.py
old mode 100755
new mode 100644
index 506a3c9b..fe5491cf
--- a/pipenv/vendor/urllib3/poolmanager.py
+++ b/pipenv/vendor/urllib3/poolmanager.py
@@ -47,6 +47,7 @@ _key_fields = (
     'key__socks_options',  # dict
     'key_assert_hostname',  # bool or string
     'key_assert_fingerprint',  # str
+    'key_server_hostname', #str
 )
 
 #: The namedtuple class used to construct keys for the connection pool.
diff --git a/pipenv/vendor/urllib3/request.py b/pipenv/vendor/urllib3/request.py
old mode 100755
new mode 100644
index 1be33341..8f2f44bb
--- a/pipenv/vendor/urllib3/request.py
+++ b/pipenv/vendor/urllib3/request.py
@@ -36,7 +36,7 @@ class RequestMethods(object):
         explicitly.
     """
 
-    _encode_url_methods = set(['DELETE', 'GET', 'HEAD', 'OPTIONS'])
+    _encode_url_methods = {'DELETE', 'GET', 'HEAD', 'OPTIONS'}
 
     def __init__(self, headers=None):
         self.headers = headers or {}
diff --git a/pipenv/vendor/urllib3/response.py b/pipenv/vendor/urllib3/response.py
old mode 100755
new mode 100644
index 9873cb94..f0cfbb54
--- a/pipenv/vendor/urllib3/response.py
+++ b/pipenv/vendor/urllib3/response.py
@@ -11,7 +11,7 @@ from .exceptions import (
     BodyNotHttplibCompatible, ProtocolError, DecodeError, ReadTimeoutError,
     ResponseNotChunked, IncompleteRead, InvalidHeader
 )
-from .packages.six import string_types as basestring, binary_type, PY3
+from .packages.six import string_types as basestring, PY3
 from .packages.six.moves import http_client as httplib
 from .connection import HTTPException, BaseSSLError
 from .util.response import is_fp_closed, is_response_to_head
@@ -23,7 +23,7 @@ class DeflateDecoder(object):
 
     def __init__(self):
         self._first_try = True
-        self._data = binary_type()
+        self._data = b''
         self._obj = zlib.decompressobj()
 
     def __getattr__(self, name):
@@ -69,7 +69,7 @@ class GzipDecoder(object):
         return getattr(self._obj, name)
 
     def decompress(self, data):
-        ret = binary_type()
+        ret = b''
         if self._state == GzipDecoderState.SWALLOW_DATA or not data:
             return ret
         while True:
@@ -90,7 +90,31 @@ class GzipDecoder(object):
             self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)
 
 
+class MultiDecoder(object):
+    """
+    From RFC7231:
+        If one or more encodings have been applied to a representation, the
+        sender that applied the encodings MUST generate a Content-Encoding
+        header field that lists the content codings in the order in which
+        they were applied.
+    """
+
+    def __init__(self, modes):
+        self._decoders = [_get_decoder(m.strip()) for m in modes.split(',')]
+
+    def flush(self):
+        return self._decoders[0].flush()
+
+    def decompress(self, data):
+        for d in reversed(self._decoders):
+            data = d.decompress(data)
+        return data
+
+
 def _get_decoder(mode):
+    if ',' in mode:
+        return MultiDecoder(mode)
+
     if mode == 'gzip':
         return GzipDecoder()
 
@@ -159,7 +183,7 @@ class HTTPResponse(io.IOBase):
         self.msg = msg
         self._request_url = request_url
 
-        if body and isinstance(body, (basestring, binary_type)):
+        if body and isinstance(body, (basestring, bytes)):
             self._body = body
 
         self._pool = pool
@@ -283,8 +307,13 @@ class HTTPResponse(io.IOBase):
         # Note: content-encoding value should be case-insensitive, per RFC 7230
         # Section 3.2
         content_encoding = self.headers.get('content-encoding', '').lower()
-        if self._decoder is None and content_encoding in self.CONTENT_DECODERS:
-            self._decoder = _get_decoder(content_encoding)
+        if self._decoder is None:
+            if content_encoding in self.CONTENT_DECODERS:
+                self._decoder = _get_decoder(content_encoding)
+            elif ',' in content_encoding:
+                encodings = [e.strip() for e in content_encoding.split(',') if e.strip() in self.CONTENT_DECODERS]
+                if len(encodings):
+                    self._decoder = _get_decoder(content_encoding)
 
     def _decode(self, data, decode_content, flush_decoder):
         """
diff --git a/pipenv/vendor/urllib3/util/__init__.py b/pipenv/vendor/urllib3/util/__init__.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/util/connection.py b/pipenv/vendor/urllib3/util/connection.py
old mode 100755
new mode 100644
index 5cf488f4..5ad70b2f
--- a/pipenv/vendor/urllib3/util/connection.py
+++ b/pipenv/vendor/urllib3/util/connection.py
@@ -1,6 +1,7 @@
 from __future__ import absolute_import
 import socket
 from .wait import NoWayToWaitForSocketError, wait_for_read
+from ..contrib import _appengine_environ
 
 
 def is_connection_dropped(conn):  # Platform-specific
@@ -105,6 +106,13 @@ def _has_ipv6(host):
     sock = None
     has_ipv6 = False
 
+    # App Engine doesn't support IPV6 sockets and actually has a quota on the
+    # number of sockets that can be used, so just early out here instead of
+    # creating a socket needlessly.
+    # See https://github.com/urllib3/urllib3/issues/1446
+    if _appengine_environ.is_appengine_sandbox():
+        return False
+
     if socket.has_ipv6:
         # has_ipv6 returns true if cPython was compiled with IPv6 support.
         # It does not tell us if the system has IPv6 support enabled. To
diff --git a/pipenv/vendor/urllib3/util/queue.py b/pipenv/vendor/urllib3/util/queue.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/util/request.py b/pipenv/vendor/urllib3/util/request.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/util/response.py b/pipenv/vendor/urllib3/util/response.py
old mode 100755
new mode 100644
index 67cf730a..3d548648
--- a/pipenv/vendor/urllib3/util/response.py
+++ b/pipenv/vendor/urllib3/util/response.py
@@ -59,8 +59,14 @@ def assert_header_parsing(headers):
     get_payload = getattr(headers, 'get_payload', None)
 
     unparsed_data = None
-    if get_payload:  # Platform-specific: Python 3.
-        unparsed_data = get_payload()
+    if get_payload:
+        # get_payload is actually email.message.Message.get_payload;
+        # we're only interested in the result if it's not a multipart message
+        if not headers.is_multipart():
+            payload = get_payload()
+
+            if isinstance(payload, (bytes, str)):
+                unparsed_data = payload
 
     if defects or unparsed_data:
         raise HeaderParsingError(defects=defects, unparsed_data=unparsed_data)
diff --git a/pipenv/vendor/urllib3/util/retry.py b/pipenv/vendor/urllib3/util/retry.py
old mode 100755
new mode 100644
index 7ad3dc66..e7d0abd6
--- a/pipenv/vendor/urllib3/util/retry.py
+++ b/pipenv/vendor/urllib3/util/retry.py
@@ -115,7 +115,7 @@ class Retry(object):
         (most errors are resolved immediately by a second try without a
         delay). urllib3 will sleep for::
 
-            {backoff factor} * (2 ^ ({number of total retries} - 1))
+            {backoff factor} * (2 ** ({number of total retries} - 1))
 
         seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep
         for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer
diff --git a/pipenv/vendor/urllib3/util/ssl_.py b/pipenv/vendor/urllib3/util/ssl_.py
old mode 100755
new mode 100644
index 2893752a..24ee26d6
--- a/pipenv/vendor/urllib3/util/ssl_.py
+++ b/pipenv/vendor/urllib3/util/ssl_.py
@@ -56,9 +56,8 @@ except ImportError:
     OP_NO_COMPRESSION = 0x20000
 
 
-# Python 2.7 and earlier didn't have inet_pton on non-Linux
-# so we fallback on inet_aton in those cases. This means that
-# we can only detect IPv4 addresses in this case.
+# Python 2.7 doesn't have inet_pton on non-Linux so we fallback on inet_aton in
+# those cases. This means that we can only detect IPv4 addresses in this case.
 if hasattr(socket, 'inet_pton'):
     inet_pton = socket.inet_pton
 else:
@@ -67,7 +66,7 @@ else:
         import ipaddress
 
         def inet_pton(_, host):
-            if isinstance(host, six.binary_type):
+            if isinstance(host, bytes):
                 host = host.decode('ascii')
             return ipaddress.ip_address(host)
 
@@ -115,10 +114,7 @@ try:
 except ImportError:
     import sys
 
-    class SSLContext(object):  # Platform-specific: Python 2 & 3.1
-        supports_set_ciphers = ((2, 7) <= sys.version_info < (3,) or
-                                (3, 2) <= sys.version_info)
-
+    class SSLContext(object):  # Platform-specific: Python 2
         def __init__(self, protocol_version):
             self.protocol = protocol_version
             # Use default values from a real SSLContext
@@ -141,12 +137,6 @@ except ImportError:
                 raise SSLError("CA directories not supported in older Pythons")
 
         def set_ciphers(self, cipher_suite):
-            if not self.supports_set_ciphers:
-                raise TypeError(
-                    'Your version of Python does not support setting '
-                    'a custom cipher suite. Please upgrade to Python '
-                    '2.7, 3.2, or later if you need this functionality.'
-                )
             self.ciphers = cipher_suite
 
         def wrap_socket(self, socket, server_hostname=None, server_side=False):
@@ -167,10 +157,7 @@ except ImportError:
                 'ssl_version': self.protocol,
                 'server_side': server_side,
             }
-            if self.supports_set_ciphers:  # Platform-specific: Python 2.7+
-                return wrap_socket(socket, ciphers=self.ciphers, **kwargs)
-            else:  # Platform-specific: Python 2.6
-                return wrap_socket(socket, **kwargs)
+            return wrap_socket(socket, ciphers=self.ciphers, **kwargs)
 
 
 def assert_fingerprint(cert, fingerprint):
@@ -291,9 +278,6 @@ def create_urllib3_context(ssl_version=None, cert_reqs=None,
 
     context.options |= options
 
-    if getattr(context, 'supports_set_ciphers', True):  # Platform-specific: Python 2.6
-        context.set_ciphers(ciphers or DEFAULT_CIPHERS)
-
     context.verify_mode = cert_reqs
     if getattr(context, 'check_hostname', None) is not None:  # Platform-specific: Python 3.2
         # We do our own verification, including fingerprints and alternative
@@ -316,8 +300,7 @@ def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,
         A pre-made :class:`SSLContext` object. If none is provided, one will
         be created using :func:`create_urllib3_context`.
     :param ciphers:
-        A string of ciphers we wish the client to support. This is not
-        supported on Python 2.6 as the ssl module does not support it.
+        A string of ciphers we wish the client to support.
     :param ca_cert_dir:
         A directory containing CA certificates in multiple separate files, as
         supported by OpenSSL's -CApath flag or the capath argument to
@@ -334,7 +317,7 @@ def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,
     if ca_certs or ca_cert_dir:
         try:
             context.load_verify_locations(ca_certs, ca_cert_dir)
-        except IOError as e:  # Platform-specific: Python 2.6, 2.7, 3.2
+        except IOError as e:  # Platform-specific: Python 2.7
             raise SSLError(e)
         # Py33 raises FileNotFoundError which subclasses OSError
         # These are not equivalent unless we check the errno attribute
@@ -378,7 +361,7 @@ def is_ipaddress(hostname):
     :param str hostname: Hostname to examine.
     :return: True if the hostname is an IP address, False otherwise.
     """
-    if six.PY3 and isinstance(hostname, six.binary_type):
+    if six.PY3 and isinstance(hostname, bytes):
         # IDN A-label bytes are ASCII compatible.
         hostname = hostname.decode('ascii')
 
diff --git a/pipenv/vendor/urllib3/util/timeout.py b/pipenv/vendor/urllib3/util/timeout.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/util/url.py b/pipenv/vendor/urllib3/util/url.py
old mode 100755
new mode 100644
diff --git a/pipenv/vendor/urllib3/util/wait.py b/pipenv/vendor/urllib3/util/wait.py
old mode 100755
new mode 100644
index fa686eff..4db71baf
--- a/pipenv/vendor/urllib3/util/wait.py
+++ b/pipenv/vendor/urllib3/util/wait.py
@@ -43,9 +43,6 @@ if sys.version_info >= (3, 5):
 else:
     # Old and broken Pythons.
     def _retry_on_intr(fn, timeout):
-        if timeout is not None and timeout <= 0:
-            return fn(timeout)
-
         if timeout is None:
             deadline = float("inf")
         else:
@@ -117,7 +114,7 @@ def _have_working_poll():
     # from libraries like eventlet/greenlet.
     try:
         poll_obj = select.poll()
-        poll_obj.poll(0)
+        _retry_on_intr(poll_obj.poll, 0)
     except (AttributeError, OSError):
         return False
     else:
diff --git a/pipenv/vendor/vendor.txt b/pipenv/vendor/vendor.txt
index 7a574b9f..8812d2ae 100644
--- a/pipenv/vendor/vendor.txt
+++ b/pipenv/vendor/vendor.txt
@@ -14,28 +14,28 @@ first==2.0.1
 iso8601==0.1.12
 jinja2==2.10
 markupsafe==1.0
-parse==1.8.4
+parse==1.9.0
 pathlib2==2.3.2
     scandir==1.9
 pipdeptree==0.13.0
 pipreqs==0.4.9
     docopt==0.6.2
     yarg==0.1.9
-pythonfinder==1.1.2
-requests==2.19.1
+pythonfinder==1.1.3
+requests==2.20.0
     chardet==3.0.4
     idna==2.7
-    urllib3==1.23
-    certifi==2018.8.24
-requirementslib==1.1.9
+    urllib3==1.24
+    certifi==2018.10.15
+requirementslib==1.1.10
     attrs==18.2.0
     distlib==0.2.8
     packaging==18.0
     pyparsing==2.2.2
     pytoml==0.1.19
     plette==0.2.2
-        tomlkit==0.4.4
-shellingham==1.2.6
+        tomlkit==0.4.6
+shellingham==1.2.7
 six==1.11.0
 semver==2.8.1
 shutilwhich==1.1.0
@@ -48,3 +48,5 @@ enum34==1.1.6
 yaspin==0.14.0
 cerberus==1.2
 git+https://github.com/sarugaku/passa.git@master#egg=passa
+cursor==1.2.0
+backports.functools_lru_cache==1.5
diff --git a/pipenv/vendor/vistir/__init__.py b/pipenv/vendor/vistir/__init__.py
index fe6f884c..881985d2 100644
--- a/pipenv/vendor/vistir/__init__.py
+++ b/pipenv/vendor/vistir/__init__.py
@@ -8,12 +8,14 @@ from .contextmanagers import (
     open_file,
     temp_environ,
     temp_path,
+    spinner,
 )
 from .misc import load_path, partialclass, run, shell_escape
-from .path import mkdir_p, rmtree
+from .path import mkdir_p, rmtree, create_tracked_tempdir
+from .spin import VistirSpinner, create_spinner
 
 
-__version__ = '0.1.7'
+__version__ = '0.1.8'
 
 
 __all__ = [
@@ -31,4 +33,8 @@ __all__ = [
     "TemporaryDirectory",
     "NamedTemporaryFile",
     "partialmethod",
+    "spinner",
+    "VistirSpinner",
+    "create_spinner",
+    "create_tracked_tempdir"
 ]
diff --git a/pipenv/vendor/vistir/compat.py b/pipenv/vendor/vistir/compat.py
index 0c865fe6..eab87908 100644
--- a/pipenv/vendor/vistir/compat.py
+++ b/pipenv/vendor/vistir/compat.py
@@ -1,6 +1,7 @@
 # -*- coding=utf-8 -*-
 from __future__ import absolute_import, unicode_literals
 
+import errno
 import os
 import sys
 import warnings
@@ -16,18 +17,21 @@ __all__ = [
     "finalize",
     "partialmethod",
     "JSONDecodeError",
+    "FileNotFoundError",
     "ResourceWarning",
     "FileNotFoundError",
     "fs_str",
+    "lru_cache",
     "TemporaryDirectory",
     "NamedTemporaryFile",
 ]
 
 if sys.version_info >= (3, 5):
     from pathlib import Path
-
+    from functools import lru_cache
 else:
     from pathlib2 import Path
+    from pipenv.vendor.backports.functools_lru_cache import lru_cache
 
 if sys.version_info < (3, 3):
     from pipenv.vendor.backports.shutil_get_terminal_size import get_terminal_size
@@ -57,16 +61,18 @@ if six.PY2:
         pass
 
     class FileNotFoundError(IOError):
-        pass
+        """No such file or directory"""
+
+        def __init__(self, *args, **kwargs):
+            self.errno = errno.ENOENT
+            super(FileNotFoundError, self).__init__(*args, **kwargs)
 
 else:
     from builtins import ResourceWarning, FileNotFoundError
 
-    class ResourceWarning(ResourceWarning):
-        pass
 
-    class FileNotFoundError(FileNotFoundError):
-        pass
+if not sys.warnoptions:
+    warnings.simplefilter("default", ResourceWarning)
 
 
 class TemporaryDirectory(object):
diff --git a/pipenv/vendor/vistir/contextmanagers.py b/pipenv/vendor/vistir/contextmanagers.py
index 80f1f897..70f95c59 100644
--- a/pipenv/vendor/vistir/contextmanagers.py
+++ b/pipenv/vendor/vistir/contextmanagers.py
@@ -1,6 +1,7 @@
 # -*- coding=utf-8 -*-
 from __future__ import absolute_import, unicode_literals
 
+import io
 import os
 import stat
 import sys
@@ -13,7 +14,9 @@ from .compat import NamedTemporaryFile, Path
 from .path import is_file_url, is_valid_url, path_to_url, url_to_path
 
 
-__all__ = ["temp_environ", "temp_path", "cd", "atomic_open_for_write", "open_file"]
+__all__ = [
+    "temp_environ", "temp_path", "cd", "atomic_open_for_write", "open_file", "spinner"
+]
 
 
 # Borrowed from Pew.
@@ -77,6 +80,66 @@ def cd(path):
         os.chdir(prev_cwd)
 
 
+@contextmanager
+def dummy_spinner(spin_type, text, **kwargs):
+    class FakeClass(object):
+        def __init__(self, text=""):
+            self.text = text
+
+        def fail(self, exitcode=1, text=None):
+            if text:
+                print(text)
+            raise SystemExit(exitcode, text)
+
+        def ok(self, text):
+            print(text)
+            return 0
+
+        def write(self, text):
+            print(text)
+
+    myobj = FakeClass(text)
+    yield myobj
+
+
+@contextmanager
+def spinner(spinner_name=None, start_text=None, handler_map=None, nospin=False):
+    """Get a spinner object or a dummy spinner to wrap a context.
+
+    :param str spinner_name: A spinner type e.g. "dots" or "bouncingBar" (default: {"bouncingBar"})
+    :param str start_text: Text to start off the spinner with (default: {None})
+    :param dict handler_map: Handler map for signals to be handled gracefully (default: {None})
+    :param bool nospin: If true, use the dummy spinner (default: {False})
+    :return: A spinner object which can be manipulated while alive
+    :rtype: :class:`~vistir.spin.VistirSpinner`
+
+    Raises:
+        RuntimeError -- Raised if the spinner extra is not installed
+    """
+
+    from .spin import create_spinner
+    spinner_func = create_spinner
+    if nospin is False:
+        try:
+            import yaspin
+        except ImportError:
+            raise RuntimeError(
+                "Failed to import spinner! Reinstall vistir with command:"
+                " pip install --upgrade vistir[spinner]"
+            )
+    else:
+        spinner_name = None
+    if not start_text:
+        start_text = "Running..."
+    with spinner_func(
+        spinner_name=spinner_name,
+        text=start_text,
+        handler_map=handler_map,
+        nospin=nospin,
+    ) as _spinner:
+        yield _spinner
+
+
 @contextmanager
 def atomic_open_for_write(target, binary=False, newline=None, encoding=None):
     """Atomically open `target` for writing.
@@ -192,8 +255,11 @@ def open_file(link, session=None):
         if os.path.isdir(local_path):
             raise ValueError("Cannot open directory for read: {}".format(link))
         else:
-            with open(local_path, "rb") as local_file:
+            try:
+                local_file = io.open(local_path, "rb")
                 yield local_file
+            finally:
+                local_file.close()
     else:
         # Remote URL
         headers = {"Accept-Encoding": "identity"}
diff --git a/pipenv/vendor/vistir/misc.py b/pipenv/vendor/vistir/misc.py
index 44607a98..f42b4ad1 100644
--- a/pipenv/vendor/vistir/misc.py
+++ b/pipenv/vendor/vistir/misc.py
@@ -2,19 +2,24 @@
 from __future__ import absolute_import, unicode_literals
 
 import json
+import logging
 import locale
 import os
 import subprocess
 import sys
 
 from collections import OrderedDict
-from contextlib import contextmanager
 from functools import partial
 
 import six
 
 from .cmdparse import Script
 from .compat import Path, fs_str, partialmethod
+from .contextmanagers import spinner as spinner
+
+if os.name != "nt":
+    class WindowsError(OSError):
+        pass
 
 
 __all__ = [
@@ -30,6 +35,22 @@ __all__ = [
 ]
 
 
+def _get_logger(name=None, level="ERROR"):
+    if not name:
+        name = __name__
+    if isinstance(level, six.string_types):
+        level = getattr(logging, level.upper())
+    logger = logging.getLogger(name)
+    logger.setLevel(level)
+    formatter = logging.Formatter(
+        "%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s"
+    )
+    handler = logging.StreamHandler()
+    handler.setFormatter(formatter)
+    logger.addHandler(handler)
+    return logger
+
+
 def shell_escape(cmd):
     """Escape strings for use in :func:`~subprocess.Popen` and :func:`run`.
 
@@ -75,9 +96,11 @@ def dedup(iterable):
     return iter(OrderedDict.fromkeys(iterable))
 
 
-def _spawn_subprocess(script, env={}, block=True, cwd=None, combine_stderr=True):
+def _spawn_subprocess(script, env=None, block=True, cwd=None, combine_stderr=True):
     from distutils.spawn import find_executable
 
+    if not env:
+        env = {}
     command = find_executable(script.command)
     options = {
         "env": env,
@@ -102,7 +125,7 @@ def _spawn_subprocess(script, env={}, block=True, cwd=None, combine_stderr=True)
     try:
         return subprocess.Popen(cmd, **options)
     except WindowsError as e:
-        if e.winerror != 193:
+        if getattr(e, "winerror", 9999) != 193:
             raise
     options["shell"] = True
     # Try shell mode to use Windows's file association for file launch.
@@ -111,7 +134,7 @@ def _spawn_subprocess(script, env={}, block=True, cwd=None, combine_stderr=True)
 
 def _create_subprocess(
     cmd,
-    env={},
+    env=None,
     block=True,
     return_object=False,
     cwd=os.curdir,
@@ -120,6 +143,8 @@ def _create_subprocess(
     combine_stderr=False,
     display_limit=200
 ):
+    if not env:
+        env = {}
     try:
         c = _spawn_subprocess(cmd, env=env, block=block, cwd=cwd,
                                                     combine_stderr=combine_stderr)
@@ -128,11 +153,13 @@ def _create_subprocess(
         raise
     if not block:
         c.stdin.close()
+        log_level = "DEBUG" if verbose else "WARN"
+        logger = _get_logger(cmd._parts[0], level=log_level)
         output = []
         err = []
         spinner_orig_text = ""
         if spinner:
-            spinner_orig_text = spinner.text
+            spinner_orig_text = getattr(spinner, "text", "")
         streams = {
             "stdout": c.stdout,
             "stderr": c.stderr
@@ -147,7 +174,7 @@ def _create_subprocess(
                 line = to_text(stream.readline())
                 if not line:
                     continue
-                line = line.rstrip()
+                line = to_text("{0}".format(line.rstrip()))
                 if outstream == "stderr":
                     stderr_line = line
                 else:
@@ -155,15 +182,24 @@ def _create_subprocess(
             if not (stdout_line or stderr_line):
                 break
             if stderr_line:
-                err.append(line)
+                err.append(stderr_line)
+                if verbose:
+                    if spinner:
+                        spinner.write_err(fs_str(stderr_line))
+                    else:
+                        logger.error(stderr_line)
             if stdout_line:
                 output.append(stdout_line)
                 display_line = stdout_line
                 if len(stdout_line) > display_limit:
                     display_line = "{0}...".format(stdout_line[:display_limit])
                 if verbose:
-                    spinner.write(display_line)
-                spinner.text = "{0} {1}".format(spinner_orig_text, display_line)
+                    if spinner:
+                        spinner.write(fs_str(display_line))
+                    else:
+                        logger.debug(display_line)
+                if spinner:
+                    spinner.text = fs_str("{0} {1}".format(spinner_orig_text, display_line))
                 continue
         try:
             c.wait()
@@ -175,18 +211,22 @@ def _create_subprocess(
         if spinner:
             if c.returncode > 0:
                 spinner.fail("Failed...cleaning up...")
-            spinner.text = "Complete!"
-            spinner.ok("")
+            else:
+                spinner.text = "Complete!"
+            if not os.name == "nt":
+                spinner.ok("")
+            else:
+                spinner.ok()
         c.out = "\n".join(output)
         c.err = "\n".join(err) if err else ""
     else:
         c.out, c.err = c.communicate()
+    if not block:
+        c.wait()
+    c.out = fs_str("{0}".format(c.out)) if c.out else fs_str("")
+    c.err = fs_str("{0}".format(c.err)) if c.err else fs_str("")
     if not return_object:
-        if not block:
-            c.wait()
-        out = c.out if c.out else ""
-        err = c.err if c.err else ""
-        return out.strip(), err.strip()
+        return c.out.strip(), c.err.strip()
     return c
 
 
@@ -198,7 +238,7 @@ def run(
     cwd=None,
     verbose=False,
     nospin=False,
-    spinner=None,
+    spinner_name=None,
     combine_stderr=True,
     display_limit=200
 ):
@@ -211,7 +251,7 @@ def run(
     :param str cwd: Current working directory contect to use for spawning the subprocess.
     :param bool verbose: Whether to print stdout in real time when non-blocking.
     :param bool nospin: Whether to disable the cli spinner.
-    :param str spinner: The name of the spinner to use if enabled, defaults to bouncingBar
+    :param str spinner_name: The name of the spinner to use if enabled, defaults to bouncingBar
     :param bool combine_stderr: Optionally merge stdout and stderr in the subprocess, false if nonblocking.
     :param int dispay_limit: The max width of output lines to display when using a spinner.
     :returns: A 2-tuple of (output, error) or a :class:`subprocess.Popen` object.
@@ -221,8 +261,10 @@ def run(
         this functionality.
     """
 
-    if not env:
-        env = os.environ.copy()
+    _env = os.environ.copy()
+    if env:
+        _env.update(env)
+    env = _env
     if six.PY2:
         fs_encode = partial(to_bytes, encoding=locale_encoding)
         _env = {fs_encode(k): fs_encode(v) for k, v in os.environ.items()}
@@ -230,8 +272,8 @@ def run(
             _env[fs_encode(key)] = fs_encode(val)
     else:
         _env = {k: fs_str(v) for k, v in os.environ.items()}
-    if not spinner:
-        spinner = "bouncingBar"
+    if not spinner_name:
+        spinner_name = "bouncingBar"
     if six.PY2:
         if isinstance(cmd, six.string_types):
             cmd = cmd.encode("utf-8")
@@ -241,48 +283,7 @@ def run(
         cmd = Script.parse(cmd)
     if block or not return_object:
         combine_stderr = False
-    sigmap = {}
-    if nospin is False:
-        try:
-            import signal
-            from yaspin import yaspin
-            from yaspin import spinners
-            from yaspin.signal_handlers import fancy_handler
-        except ImportError:
-            raise RuntimeError(
-                "Failed to import spinner! Reinstall vistir with command:"
-                " pip install --upgrade vistir[spinner]"
-            )
-        else:
-            animation = getattr(spinners.Spinners, spinner)
-            sigmap = {
-                signal.SIGINT: fancy_handler
-            }
-            if os.name == "nt":
-                sigmap.update({
-                    signal.CTRL_C_EVENT: fancy_handler,
-                    signal.CTRL_BREAK_EVENT: fancy_handler
-                })
-            spinner_func = yaspin
-    else:
-
-        @contextmanager
-        def spinner_func(spin_type, text, **kwargs):
-            class FakeClass(object):
-                def __init__(self, text=""):
-                    self.text = text
-
-                def ok(self, text):
-                    return
-
-                def write(self, text):
-                    print(text)
-
-            myobj = FakeClass(text)
-            yield myobj
-
-        animation = None
-    with spinner_func(animation, sigmap=sigmap, text="Running...") as sp:
+    with spinner(spinner_name=spinner_name, start_text="Running...", nospin=nospin) as sp:
         return _create_subprocess(
             cmd,
             env=_env,
diff --git a/pipenv/vendor/vistir/path.py b/pipenv/vendor/vistir/path.py
index 166282e8..ce7ecee0 100644
--- a/pipenv/vendor/vistir/path.py
+++ b/pipenv/vendor/vistir/path.py
@@ -15,8 +15,7 @@ import six
 from six.moves import urllib_parse
 from six.moves.urllib import request as urllib_request
 
-from .compat import Path, _fs_encoding, TemporaryDirectory
-from .misc import locale_encoding, to_bytes, to_text
+from .compat import Path, _fs_encoding, TemporaryDirectory, ResourceWarning
 
 
 __all__ = [
@@ -74,6 +73,7 @@ def normalize_drive(path):
     identified with either upper or lower cased drive names. The case is
     always converted to uppercase because it seems to be preferred.
     """
+    from .misc import to_text
     if os.name != "nt" or not isinstance(path, six.string_types):
         return path
 
@@ -95,6 +95,7 @@ def path_to_url(path):
     >>> path_to_url("/home/user/code/myrepo/myfile.zip")
     'file:///home/user/code/myrepo/myfile.zip'
     """
+    from .misc import to_text, to_bytes
 
     if not path:
         return path
@@ -108,6 +109,7 @@ def url_to_path(url):
 
     Follows logic taken from pip's equivalent function
     """
+    from .misc import to_bytes
     assert is_file_url(url), "Only file: urls can be converted to local paths"
     _, netloc, path, _, _ = urllib_parse.urlsplit(url)
     # Netlocs are UNC paths
@@ -120,14 +122,16 @@ def url_to_path(url):
 
 def is_valid_url(url):
     """Checks if a given string is an url"""
+    from .misc import to_text
     if not url:
         return url
-    pieces = urllib_parse.urlparse(url)
+    pieces = urllib_parse.urlparse(to_text(url))
     return all([pieces.scheme, pieces.netloc])
 
 
 def is_file_url(url):
     """Returns true if the given url is a file url"""
+    from .misc import to_text
     if not url:
         return False
     if not isinstance(url, six.string_types):
@@ -144,6 +148,7 @@ def is_readonly_path(fn):
 
     Permissions check is `bool(path.stat & stat.S_IREAD)` or `not os.access(path, os.W_OK)`
     """
+    from .misc import to_bytes
     fn = to_bytes(fn, encoding="utf-8")
     if os.path.exists(fn):
         return bool(os.stat(fn).st_mode & stat.S_IREAD) and not os.access(fn, os.W_OK)
@@ -158,7 +163,8 @@ def mkdir_p(newdir, mode=0o777):
     :raises: OSError if a file is encountered along the way
     """
     # http://code.activestate.com/recipes/82465-a-friendly-mkdir/
-    newdir = abspathu(to_bytes(newdir, "utf-8"))
+    from .misc import to_bytes, to_text
+    newdir = to_bytes(newdir, "utf-8")
     if os.path.exists(newdir):
         if not os.path.isdir(newdir):
             raise OSError(
@@ -166,17 +172,17 @@ def mkdir_p(newdir, mode=0o777):
                     newdir
                 )
             )
-        pass
     else:
-        head, tail = os.path.split(newdir)
+        head, tail = os.path.split(to_bytes(newdir, encoding="utf-8"))
         # Make sure the tail doesn't point to the asame place as the head
-        tail_and_head_match = os.path.relpath(tail, start=os.path.basename(head)) == "."
+        curdir = to_bytes(".", encoding="utf-8")
+        tail_and_head_match = os.path.relpath(tail, start=os.path.basename(head)) == curdir
         if tail and not tail_and_head_match and not os.path.isdir(newdir):
             target = os.path.join(head, tail)
             if os.path.exists(target) and os.path.isfile(target):
                 raise OSError(
                    "A file with the same name as the desired dir, '{0}', already exists.".format(
-                        newdir
+                        to_text(newdir, encoding="utf-8")
                     )
                 )
             os.makedirs(os.path.join(head, tail), mode)
@@ -210,9 +216,11 @@ def create_tracked_tempdir(*args, **kwargs):
 
     The return value is the path to the created directory.
     """
+
     tempdir = TemporaryDirectory(*args, **kwargs)
     TRACKED_TEMPORARY_DIRECTORIES.append(tempdir)
     atexit.register(tempdir.cleanup)
+    warnings.simplefilter("default", ResourceWarning)
     return tempdir.name
 
 
@@ -223,6 +231,7 @@ def set_write_bit(fn):
     :param str fn: The target filename or path
     """
 
+    from .misc import to_bytes, locale_encoding
     fn = to_bytes(fn, encoding=locale_encoding)
     if not os.path.exists(fn):
         return
@@ -243,10 +252,17 @@ def rmtree(directory, ignore_errors=False):
        Setting `ignore_errors=True` may cause this to silently fail to delete the path
     """
 
+    from .misc import locale_encoding, to_bytes
     directory = to_bytes(directory, encoding=locale_encoding)
-    shutil.rmtree(
-        directory, ignore_errors=ignore_errors, onerror=handle_remove_readonly
-    )
+    try:
+        shutil.rmtree(
+            directory, ignore_errors=ignore_errors, onerror=handle_remove_readonly
+        )
+    except (IOError, OSError) as exc:
+        # Ignore removal failures where the file doesn't exist
+        if exc.errno == errno.ENOENT:
+            pass
+        raise
 
 
 def handle_remove_readonly(func, path, exc):
@@ -263,35 +279,41 @@ def handle_remove_readonly(func, path, exc):
     :func:`set_write_bit` on the target path and try again.
     """
     # Check for read-only attribute
-    from .compat import ResourceWarning
+    if six.PY2:
+        from .compat import ResourceWarning
+    from .misc import to_bytes
+    PERM_ERRORS = (errno.EACCES, errno.EPERM)
     default_warning_message = (
         "Unable to remove file due to permissions restriction: {!r}"
     )
     # split the initial exception out into its type, exception, and traceback
     exc_type, exc_exception, exc_tb = exc
-    path = to_bytes(path)
+    path = to_bytes(path, encoding="utf-8")
     if is_readonly_path(path):
         # Apply write permission and call original function
         set_write_bit(path)
         try:
             func(path)
         except (OSError, IOError) as e:
-            if e.errno in [errno.EACCES, errno.EPERM]:
-                warnings.warn(
-                    default_warning_message.format(
-                        to_text(path, encoding=locale_encoding)
-                    ), ResourceWarning
-                )
+            if e.errno in PERM_ERRORS:
+                warnings.warn(default_warning_message.format(path), ResourceWarning)
                 return
 
-    if exc_exception.errno in [errno.EACCES, errno.EPERM]:
-        warnings.warn(
-            default_warning_message.format(to_text(path)),
-            ResourceWarning
-        )
-        return
-
-    raise
+    if exc_exception.errno in PERM_ERRORS:
+        set_write_bit(path)
+        try:
+            func(path)
+        except (OSError, IOError) as e:
+            if e.errno in PERM_ERRORS:
+                warnings.warn(default_warning_message.format(path), ResourceWarning)
+            elif e.errno == errno.ENOENT:  # File already gone
+                return
+            else:
+                raise
+            return
+        else:
+            raise
+    raise exc
 
 
 def walk_up(bottom):
@@ -356,6 +378,7 @@ def get_converted_relative_path(path, relative_to=None):
     >>> vistir.path.get_converted_relative_path('/home/user/code/myrepo/myfolder')
     '.'
     """
+    from .misc import to_text, to_bytes  # noqa
 
     if not relative_to:
         relative_to = os.getcwdu() if six.PY2 else os.getcwd()
diff --git a/pipenv/vendor/vistir/spin.py b/pipenv/vendor/vistir/spin.py
new file mode 100644
index 00000000..d2cddd79
--- /dev/null
+++ b/pipenv/vendor/vistir/spin.py
@@ -0,0 +1,149 @@
+# -*- coding=utf-8 -*-
+import os
+import signal
+import sys
+
+from .termcolors import colored
+from .compat import fs_str
+
+import cursor
+import functools
+try:
+    import yaspin
+except ImportError:
+    yaspin = None
+    Spinners = None
+else:
+    from yaspin.spinners import Spinners
+
+handler = None
+if yaspin and os.name == "nt":
+    handler = yaspin.signal_handlers.default_handler
+elif yaspin and os.name != "nt":
+    handler = yaspin.signal_handlers.fancy_handler
+
+CLEAR_LINE = chr(27) + "[K"
+
+
+class DummySpinner(object):
+    def __init__(self, text="", **kwargs):
+        self.text = text
+
+    def __enter__(self):
+        if self.text:
+            self.write(self.text)
+        return self
+
+    def __exit__(self, exc_type, exc_val, traceback):
+        if not exc_type:
+            self.ok()
+        else:
+            self.write_err(traceback)
+        return False
+
+    def fail(self, exitcode=1, text=None):
+        if text:
+            self.write_err(text)
+        raise SystemExit(exitcode, text)
+
+    def ok(self, text=None):
+        if text:
+            self.write(self.text)
+        return 0
+
+    def write(self, text=None):
+        if text:
+            line = fs_str("{0}\n".format(text))
+            sys.stdout.write(line)
+
+    def write_err(self, text=None):
+        if text:
+            line = fs_str("{0}\n".format(text))
+            sys.stderr.write(line)
+
+
+base_obj = yaspin.core.Yaspin if yaspin is not None else DummySpinner
+
+
+class VistirSpinner(base_obj):
+    def __init__(self, *args, **kwargs):
+        """Get a spinner object or a dummy spinner to wrap a context.
+
+        Keyword Arguments:
+        :param str spinner_name: A spinner type e.g. "dots" or "bouncingBar" (default: {"bouncingBar"})
+        :param str start_text: Text to start off the spinner with (default: {None})
+        :param dict handler_map: Handler map for signals to be handled gracefully (default: {None})
+        :param bool nospin: If true, use the dummy spinner (default: {False})
+        """
+
+        self.handler = handler
+        sigmap = {}
+        if handler:
+            sigmap.update({
+                signal.SIGINT: handler,
+                signal.SIGTERM: handler
+            })
+        handler_map = kwargs.pop("handler_map", {})
+        if os.name == "nt":
+            sigmap[signal.SIGBREAK] = handler
+        else:
+            sigmap[signal.SIGALRM] = handler
+        if handler_map:
+            sigmap.update(handler_map)
+        spinner_name = kwargs.pop("spinner_name", "bouncingBar")
+        text = kwargs.pop("start_text", "") + " " + kwargs.pop("text", "")
+        if not text:
+            text = "Running..."
+        kwargs["sigmap"] = sigmap
+        kwargs["spinner"] = getattr(Spinners, spinner_name, Spinners.bouncingBar)
+        super(VistirSpinner, self).__init__(*args, **kwargs)
+        self.is_dummy = bool(yaspin is None)
+
+    def fail(self, exitcode=1, *args, **kwargs):
+        super(VistirSpinner, self).fail(**kwargs)
+
+    def ok(self, *args, **kwargs):
+        super(VistirSpinner, self).ok(*args, **kwargs)
+
+    def write(self, *args, **kwargs):
+        super(VistirSpinner, self).write(*args, **kwargs)
+
+    def write_err(self, text):
+        """Write error text in the terminal without breaking the spinner."""
+
+        sys.stderr.write("\r")
+        self._clear_err()
+        text = fs_str("{0}\n".format(text))
+        sys.stderr.write(text)
+
+    def _compose_color_func(self):
+        fn = functools.partial(
+            colored,
+            color=self._color,
+            on_color=self._on_color,
+            attrs=list(self._attrs),
+        )
+        return fn
+
+    @staticmethod
+    def _hide_cursor():
+        cursor.hide()
+
+    @staticmethod
+    def _show_cursor():
+        cursor.show()
+
+    @staticmethod
+    def _clear_err():
+        sys.stderr.write(CLEAR_LINE)
+
+    @staticmethod
+    def _clear_line():
+        sys.stdout.write(CLEAR_LINE)
+
+
+def create_spinner(*args, **kwargs):
+    nospin = kwargs.pop("nospin", False)
+    if nospin:
+        return DummySpinner(*args, **kwargs)
+    return VistirSpinner(*args, **kwargs)
diff --git a/pipenv/vendor/vistir/termcolors.py b/pipenv/vendor/vistir/termcolors.py
new file mode 100644
index 00000000..6f3ad32c
--- /dev/null
+++ b/pipenv/vendor/vistir/termcolors.py
@@ -0,0 +1,116 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, print_function, unicode_literals
+import colorama
+import os
+
+
+ATTRIBUTES = dict(
+        list(zip([
+            'bold',
+            'dark',
+            '',
+            'underline',
+            'blink',
+            '',
+            'reverse',
+            'concealed'
+            ],
+            list(range(1, 9))
+            ))
+        )
+del ATTRIBUTES['']
+
+
+HIGHLIGHTS = dict(
+        list(zip([
+            'on_grey',
+            'on_red',
+            'on_green',
+            'on_yellow',
+            'on_blue',
+            'on_magenta',
+            'on_cyan',
+            'on_white'
+            ],
+            list(range(40, 48))
+            ))
+        )
+
+
+COLORS = dict(
+        list(zip([
+            'grey',
+            'red',
+            'green',
+            'yellow',
+            'blue',
+            'magenta',
+            'cyan',
+            'white',
+            ],
+            list(range(30, 38))
+            ))
+        )
+
+
+RESET = colorama.Style.RESET_ALL
+
+
+def colored(text, color=None, on_color=None, attrs=None):
+    """Colorize text using a reimplementation of the colorizer from
+    https://github.com/pavdmyt/yaspin so that it works on windows.
+
+    Available text colors:
+        red, green, yellow, blue, magenta, cyan, white.
+
+    Available text highlights:
+        on_red, on_green, on_yellow, on_blue, on_magenta, on_cyan, on_white.
+
+    Available attributes:
+        bold, dark, underline, blink, reverse, concealed.
+
+    Example:
+        colored('Hello, World!', 'red', 'on_grey', ['blue', 'blink'])
+        colored('Hello, World!', 'green')
+    """
+    if os.getenv('ANSI_COLORS_DISABLED') is None:
+        style = "NORMAL"
+        if 'bold' in attrs:
+            style = "BRIGHT"
+            attrs.remove('bold')
+        if color is not None:
+            text = text = "%s%s%s%s%s" % (
+                getattr(colorama.Fore, color),
+                getattr(colorama.Style, style),
+                text,
+                colorama.Fore.RESET,
+                colorama.Style.NORMAL,
+            )
+
+        if on_color is not None:
+            text = "%s%s%s%s" % (
+                getattr(colorama.Back, color),
+                text,
+                colorama.Back.RESET,
+                colorama.Style.NORMAL,
+            )
+
+        if attrs is not None:
+            fmt_str = "%s[%%dm%%s%s[9m" % (
+                chr(27),
+                chr(27)
+            )
+            for attr in attrs:
+                text = fmt_str % (ATTRIBUTES[attr], text)
+
+        text += RESET
+    return text
+
+
+def cprint(text, color=None, on_color=None, attrs=None, **kwargs):
+    """Print colorize text.
+
+    It accepts arguments of print function.
+    """
+
+    print((colored(text, color, on_color, attrs)), **kwargs)
