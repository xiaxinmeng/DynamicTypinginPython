commit ad2d6c93636d02e0de022be1451013e9aa532788
Author: Dan Ryan <dan@danryan.co>
Date:   Sat Oct 6 14:28:02 2018 -0400

    Update all vendored dependencies
    
    - Verified all license changes
    - Brings us current with the latest releases
    - Didn't identify any breaking changes in click
    
    Signed-off-by: Dan Ryan <dan@danryan.co>

diff --git a/Pipfile.lock b/Pipfile.lock
index a5f12e14..3990a451 100644
--- a/Pipfile.lock
+++ b/Pipfile.lock
@@ -17,17 +17,16 @@
     "develop": {
         "alabaster": {
             "hashes": [
-                "sha256:674bb3bab080f598371f4443c5008cbfeb1a5e622dd312395d2d82af2c54c456",
-                "sha256:b63b1f4dc77c074d386752ec4a8a7517600f6c0db8cd42980cae17ab7b3275d7"
+                "sha256:446438bdcca0e05bd45ea2de1668c1d9b032e1a9154c2c259092d77031ddd359",
+                "sha256:a661d72d58e6ea8a57f7a86e37d86716863ee5e92788398526d58b26a4e4dc02"
             ],
-            "version": "==0.7.11"
+            "version": "==0.7.12"
         },
         "apipkg": {
             "hashes": [
                 "sha256:37228cda29411948b422fae072f57e31d3396d2ee1c9783775980ee9c9990af6",
                 "sha256:58587dd4dc3daefad0487f6d9ae32b4542b185e1c36db6993290e7c41ca2b47c"
             ],
-            "markers": "python_version >= '2.7' and python_version != '3.1.*' and python_version != '3.2.*' and python_version != '3.3.*' and python_version != '3.0.*'",
             "version": "==1.5"
         },
         "appdirs": {
@@ -54,17 +53,17 @@
         },
         "atomicwrites": {
             "hashes": [
-                "sha256:240831ea22da9ab882b551b31d4225591e5e447a68c5e188db5b89ca1d487585",
-                "sha256:a24da68318b08ac9c9c45029f4a10371ab5b20e4226738e150e6e7c571630ae6"
+                "sha256:0312ad34fcad8fac3704d441f7b317e50af620823353ec657a53e981f92920c0",
+                "sha256:ec9ae8adaae229e4f8446952d204a3e4b5fdd2d099f9be3aaf556120135fb3ee"
             ],
-            "version": "==1.1.5"
+            "version": "==1.2.1"
         },
         "attrs": {
             "hashes": [
-                "sha256:4b90b09eeeb9b88c35bc642cbac057e45a5fd85367b985bd2809c62b7b939265",
-                "sha256:e0d0eb91441a3b53dab4d9b743eafc1ac44476296a2053b6ca3af0b139faf87b"
+                "sha256:10cbf6e27dbce8c30807caf056c8eb50917e0eaafe86347671b57254006c3e69",
+                "sha256:ca4be454458f9dec299268d472aaa5a11f67a4ff70093396e1ceae9c76cf4bbb"
             ],
-            "version": "==18.1.0"
+            "version": "==18.2.0"
         },
         "babel": {
             "hashes": [
@@ -75,12 +74,19 @@
         },
         "black": {
             "hashes": [
-                "sha256:22158b89c1a6b4eb333a1e65e791a3f8b998cf3b11ae094adb2570f31f769a44",
-                "sha256:4b475bbd528acce094c503a3d2dbc2d05a4075f6d0ef7d9e7514518e14cc5191"
+                "sha256:817243426042db1d36617910df579a54f1afd659adb96fc5032fcf4b36209739",
+                "sha256:e030a9a28f542debc08acceb273f228ac422798e5215ba2a791a6ddeaaca22a5"
             ],
             "index": "pypi",
             "markers": "python_version >= '3.6'",
-            "version": "==18.6b4"
+            "version": "==18.9b0"
+        },
+        "bleach": {
+            "hashes": [
+                "sha256:9c471c0dd9c820f6bf4ee5ca3e348ceccefbc1475d9a40c397ed5d04e0b42c54",
+                "sha256:b407b2612b37e6cdc6704f84cec18c1f140b78e6c625652a844e89d6b9855f6b"
+            ],
+            "version": "==3.0.0"
         },
         "cerberus": {
             "hashes": [
@@ -90,10 +96,47 @@
         },
         "certifi": {
             "hashes": [
-                "sha256:4c1d68a1408dd090d2f3a869aa94c3947cc1d967821d1ed303208c9f41f0f2f4",
-                "sha256:b6e8b28b2b7e771a41ecdd12d4d43262ecab52adebbafa42c77d6b57fb6ad3a4"
-            ],
-            "version": "==2018.8.13"
+                "sha256:376690d6f16d32f9d1fe8932551d80b23e9d393a8578c5633a2ed39a64861638",
+                "sha256:456048c7e371c089d0a77a5212fb37a2c2dce1e24146e3b7e0261736aaeaa22a"
+            ],
+            "version": "==2018.8.24"
+        },
+        "cffi": {
+            "hashes": [
+                "sha256:151b7eefd035c56b2b2e1eb9963c90c6302dc15fbd8c1c0a83a163ff2c7d7743",
+                "sha256:1553d1e99f035ace1c0544050622b7bc963374a00c467edafac50ad7bd276aef",
+                "sha256:1b0493c091a1898f1136e3f4f991a784437fac3673780ff9de3bcf46c80b6b50",
+                "sha256:2ba8a45822b7aee805ab49abfe7eec16b90587f7f26df20c71dd89e45a97076f",
+                "sha256:3bb6bd7266598f318063e584378b8e27c67de998a43362e8fce664c54ee52d30",
+                "sha256:3c85641778460581c42924384f5e68076d724ceac0f267d66c757f7535069c93",
+                "sha256:3eb6434197633b7748cea30bf0ba9f66727cdce45117a712b29a443943733257",
+                "sha256:495c5c2d43bf6cebe0178eb3e88f9c4aa48d8934aa6e3cddb865c058da76756b",
+                "sha256:4c91af6e967c2015729d3e69c2e51d92f9898c330d6a851bf8f121236f3defd3",
+                "sha256:57b2533356cb2d8fac1555815929f7f5f14d68ac77b085d2326b571310f34f6e",
+                "sha256:770f3782b31f50b68627e22f91cb182c48c47c02eb405fd689472aa7b7aa16dc",
+                "sha256:79f9b6f7c46ae1f8ded75f68cf8ad50e5729ed4d590c74840471fc2823457d04",
+                "sha256:7a33145e04d44ce95bcd71e522b478d282ad0eafaf34fe1ec5bbd73e662f22b6",
+                "sha256:857959354ae3a6fa3da6651b966d13b0a8bed6bbc87a0de7b38a549db1d2a359",
+                "sha256:87f37fe5130574ff76c17cab61e7d2538a16f843bb7bca8ebbc4b12de3078596",
+                "sha256:95d5251e4b5ca00061f9d9f3d6fe537247e145a8524ae9fd30a2f8fbce993b5b",
+                "sha256:9d1d3e63a4afdc29bd76ce6aa9d58c771cd1599fbba8cf5057e7860b203710dd",
+                "sha256:a36c5c154f9d42ec176e6e620cb0dd275744aa1d804786a71ac37dc3661a5e95",
+                "sha256:a6a5cb8809091ec9ac03edde9304b3ad82ad4466333432b16d78ef40e0cce0d5",
+                "sha256:ae5e35a2c189d397b91034642cb0eab0e346f776ec2eb44a49a459e6615d6e2e",
+                "sha256:b0f7d4a3df8f06cf49f9f121bead236e328074de6449866515cea4907bbc63d6",
+                "sha256:b75110fb114fa366b29a027d0c9be3709579602ae111ff61674d28c93606acca",
+                "sha256:ba5e697569f84b13640c9e193170e89c13c6244c24400fc57e88724ef610cd31",
+                "sha256:be2a9b390f77fd7676d80bc3cdc4f8edb940d8c198ed2d8c0be1319018c778e1",
+                "sha256:ca1bd81f40adc59011f58159e4aa6445fc585a32bb8ac9badf7a2c1aa23822f2",
+                "sha256:d5d8555d9bfc3f02385c1c37e9f998e2011f0db4f90e250e5bc0c0a85a813085",
+                "sha256:e55e22ac0a30023426564b1059b035973ec82186ddddbac867078435801c7801",
+                "sha256:e90f17980e6ab0f3c2f3730e56d1fe9bcba1891eeea58966e89d352492cc74f4",
+                "sha256:ecbb7b01409e9b782df5ded849c178a0aa7c906cf8c5a67368047daab282b184",
+                "sha256:ed01918d545a38998bfa5902c7c00e0fee90e957ce036a4000a88e3fe2264917",
+                "sha256:edabd457cd23a02965166026fd9bfd196f4324fe6032e866d0f3bd0301cd486f",
+                "sha256:fdf1c1dc5bafc32bc5d08b054f94d659422b05aba244d6be4ddc1c72d9aa70fb"
+            ],
+            "version": "==1.11.5"
         },
         "chardet": {
             "hashes": [
@@ -104,11 +147,44 @@
         },
         "click": {
             "hashes": [
-                "sha256:29f99fc6125fbc931b758dc053b3114e55c77a6e4c6c3a2674a2dc986016381d",
-                "sha256:f15516df478d5a56180fbf80e68f206010e6d160fc39fa508b65e035fd75130b"
+                "sha256:2335065e6395b9e67ca716de5f7526736bfa6ceead690adf616d925bdc622b13",
+                "sha256:5b94b49521f6456670fdb30cd82a4eca9412788a93fa6dd6df72c94d5a8ff2d7"
             ],
             "index": "pypi",
-            "version": "==6.7"
+            "version": "==7.0"
+        },
+        "cmarkgfm": {
+            "hashes": [
+                "sha256:0186dccca79483e3405217993b83b914ba4559fe9a8396efc4eea56561b74061",
+                "sha256:1a625afc6f62da428df96ec325dc30866cc5781520cbd904ff4ec44cf018171c",
+                "sha256:207b7673ff4e177374c572feeae0e4ef33be620ec9171c08fd22e2b796e03e3d",
+                "sha256:275905bb371a99285c74931700db3f0c078e7603bed383e8cf1a09f3ee05a3de",
+                "sha256:50098f1c4950722521f0671e54139e0edc1837d63c990cf0f3d2c49607bb51a2",
+                "sha256:50ed116d0b60a07df0dc7b180c28569064b9d37d1578d4c9021cff04d725cb63",
+                "sha256:61a72def110eed903cd1848245897bcb80d295cd9d13944d4f9f30cba5b76655",
+                "sha256:64186fb75d973a06df0e6ea12879533b71f6e7ba1ab01ffee7fc3e7534758889",
+                "sha256:665303d34d7f14f10d7b0651082f25ebf7107f29ef3d699490cac16cdc0fc8ce",
+                "sha256:70b18f843aec58e4e64aadce48a897fe7c50426718b7753aaee399e72df64190",
+                "sha256:761ee7b04d1caee2931344ac6bfebf37102ffb203b136b676b0a71a3f0ea3c87",
+                "sha256:811527e9b7280b136734ed6cb6845e5fbccaeaa132ddf45f0246cbe544016957",
+                "sha256:987b0e157f70c72a84f3c2f9ef2d7ab0f26c08f2bf326c12c087ff9eebcb3ff5",
+                "sha256:9fc6a2183d0a9b0974ec7cdcdad42bd78a3be674cc3e65f87dd694419b3b0ab7",
+                "sha256:a3d17ee4ae739fe16f7501a52255c2e287ac817cfd88565b9859f70520afffea",
+                "sha256:ba5b5488719c0f2ced0aa1986376f7baff1a1653a8eb5fdfcf3f84c7ce46ef8d",
+                "sha256:c573ea89dd95d41b6d8cf36799c34b6d5b1eac4aed0212dee0f0a11fb7b01e8f",
+                "sha256:c5f1b9e8592d2c448c44e6bc0d91224b16ea5f8293908b1561de1f6d2d0658b1",
+                "sha256:cbe581456357d8f0674d6a590b1aaf46c11d01dd0a23af147a51a798c3818034",
+                "sha256:cf219bec69e601fe27e3974b7307d2f06082ab385d42752738ad2eb630a47d65",
+                "sha256:cf5014eb214d814a83a7a47407272d5db10b719dbeaf4d3cfe5969309d0fcf4b",
+                "sha256:d08bad67fa18f7e8ff738c090628ee0cbf0505d74a991c848d6d04abfe67b697",
+                "sha256:d6f716d7b1182bf35862b5065112f933f43dd1aa4f8097c9bcfb246f71528a34",
+                "sha256:e08e479102627641c7cb4ece421c6ed4124820b1758765db32201136762282d9",
+                "sha256:e20ac21418af0298437d29599f7851915497ce9f2866bc8e86b084d8911ee061",
+                "sha256:e25f53c37e319241b9a412382140dffac98ca756ba8f360ac7ab5e30cad9670a",
+                "sha256:e8932bddf159064f04e946fbb64693753488de21586f20e840b3be51745c8c09",
+                "sha256:f20900f16377f2109783ae9348d34bc80530808439591c3d3df73d5c7ef1a00c"
+            ],
+            "version": "==0.4.2"
         },
         "colorama": {
             "hashes": [
@@ -127,9 +203,9 @@
         },
         "distlib": {
             "hashes": [
-                "sha256:cd502c66fc27c535bab62dc4f482e403e2369c2c05281a79cc2d4e2f42a87f20"
+                "sha256:57977cd7d9ea27986ec62f425630e4ddb42efe651ff80bc58ed8dbc3c7c21f19"
             ],
-            "version": "==0.2.7"
+            "version": "==0.2.8"
         },
         "docutils": {
             "hashes": [
@@ -154,7 +230,6 @@
                 "sha256:a7a84d5fa07a089186a329528f127c9d73b9de57f1a1131b82bb5320ee651f6a",
                 "sha256:fc155a6b553c66c838d1a22dba1dc9f5f505c43285a878c6f74a79c024750b83"
             ],
-            "markers": "python_version >= '2.7' and python_version != '3.1.*' and python_version != '3.2.*' and python_version != '3.3.*' and python_version != '3.0.*'",
             "version": "==1.5.0"
         },
         "first": {
@@ -203,6 +278,12 @@
             "markers": "python_version < '3' and python_version >= '2.6'",
             "version": "==3.2.0"
         },
+        "future": {
+            "hashes": [
+                "sha256:e39ced1ab767b5936646cedba8bcce582398233d6a627067d4c6a454c90cfedb"
+            ],
+            "version": "==0.16.0"
+        },
         "idna": {
             "hashes": [
                 "sha256:156a6814fb5ac1fc6850fb002e0852d56c0c8d2531923a51032d1b70760e186e",
@@ -212,10 +293,10 @@
         },
         "imagesize": {
             "hashes": [
-                "sha256:3620cc0cadba3f7475f9940d22431fc4d407269f1be59ec9b8edcca26440cf18",
-                "sha256:5b326e4678b6925158ccc66a9fa3122b6106d7c876ee32d7de6ce59385b96315"
+                "sha256:3f349de3eb99145973fefb7dbe38554414e5c30abd0c8e4b970a7c9d09f3a1d8",
+                "sha256:f3832918bc3c66617f92e35f5d70729187676313caa60c187eb0f28b8fe5e3b5"
             ],
-            "version": "==1.0.0"
+            "version": "==1.1.0"
         },
         "incremental": {
             "hashes": [
@@ -226,12 +307,12 @@
         },
         "invoke": {
             "hashes": [
-                "sha256:1c2cf54c9b9af973ad9704d8ba81b225117cab612568cacbfb3fc42958cc20a9",
-                "sha256:334495ea16e73948894e9535019f87a88a44b73e7977492b12c2d1b5085f8197",
-                "sha256:54bdd3fd0245abd1185e05359fd2e4f26be0657cfe7d7bb1bed735e054fa53ab"
+                "sha256:4f4de934b15c2276caa4fbc5a3b8a61c0eb0b234f2be1780d2b793321995c2d6",
+                "sha256:dc492f8f17a0746e92081aec3f86ae0b4750bf41607ea2ad87e5a7b5705121b7",
+                "sha256:eb6f9262d4d25b40330fb21d1e99bf0f85011ccc3526980f8a3eaedd4b43892e"
             ],
             "index": "pypi",
-            "version": "==1.1.1"
+            "version": "==1.2.0"
         },
         "isort": {
             "hashes": [
@@ -250,11 +331,11 @@
         },
         "jedi": {
             "hashes": [
-                "sha256:b409ed0f6913a701ed474a614a3bb46e6953639033e31f769ca7581da5bd1ec1",
-                "sha256:c254b135fb39ad76e78d4d8f92765ebc9bf92cbc76f49e97ade1d5f5121e1f6f"
+                "sha256:0191c447165f798e6a730285f2eee783fff81b0d3df261945ecb80983b5c3ca7",
+                "sha256:b7493f73a2febe0dc33d51c99b474547f7f6c0b2c8fb2b21f453eef204c12148"
             ],
             "index": "pypi",
-            "version": "==0.12.1"
+            "version": "==0.13.1"
         },
         "jinja2": {
             "hashes": [
@@ -284,14 +365,6 @@
             "index": "pypi",
             "version": "==2.0.0"
         },
-        "modutil": {
-            "hashes": [
-                "sha256:2c85c1666649e92e56de17c00e1e831313602d9b55e8661d39c01e39003b45f7",
-                "sha256:cc3dad264e36ed359fdd67c4588959d2996bd0402ad9c9d974ca906821537218"
-            ],
-            "markers": "python_version >= '3.7'",
-            "version": "==2.0.0"
-        },
         "more-itertools": {
             "hashes": [
                 "sha256:c187a73da93e7a8acc0001572aebc7e3c69daf7bf6881a2cea10650bd4420092",
@@ -302,10 +375,10 @@
         },
         "packaging": {
             "hashes": [
-                "sha256:e9215d2d2535d3ae866c3d6efc77d5b24a0192cce0ff20e42896cc0664f889c0",
-                "sha256:f019b770dd64e585a99714f1fd5e01c7a8f11b45635aa953fd41c689a657375b"
+                "sha256:0886227f54515e592aaa2e5a553332c73962917f2831f1b0f9b9f4380a4b9807",
+                "sha256:f95a1e147590f204328170981833854229bb2912ac3d5f89e2a8ccd2834800c9"
             ],
-            "version": "==17.1"
+            "version": "==18.0"
         },
         "parso": {
             "hashes": [
@@ -325,21 +398,21 @@
         "passa": {
             "editable": true,
             "git": "https://github.com/sarugaku/passa.git",
-            "ref": "54e65e01744cafbcab44eb15422e1604b615caae"
+            "ref": "4f3b8102f122cf0b75e5d7c513a2e61b0b093dcd"
         },
         "pbr": {
             "hashes": [
-                "sha256:1b8be50d938c9bb75d0eaf7eda111eec1bf6dc88a62a6412e33bf077457e0f45",
-                "sha256:b486975c0cafb6beeb50ca0e17ba047647f229087bd74e37f4a7e2cac17d2caa"
+                "sha256:1be135151a0da949af8c5d0ee9013d9eafada71237eb80b3ba8896b4f12ec5dc",
+                "sha256:cf36765bf2218654ae824ec8e14257259ba44e43b117fd573c8d07a9895adbdd"
             ],
-            "version": "==4.2.0"
+            "version": "==4.3.0"
         },
         "pip-shims": {
             "hashes": [
-                "sha256:9c8a568b4a8ce4000a2982224f48a35736fca81214dfdb30dcae24287866a7e4",
-                "sha256:ebc2bb29ddd21fa00c0cf28a5d8c725100f2f7ee98703aba237efd02e205c1c1"
+                "sha256:164b93bc94b207613d9632f28f4d55eba9301f9454aaaba335de36c24d92d106",
+                "sha256:27e2439aa93af8c1b8e58cf63a40cbcd26959b26424904f2e6d57837af8f76c5"
             ],
-            "version": "==0.1.2"
+            "version": "==0.3.0"
         },
         "pipenv": {
             "editable": true,
@@ -354,11 +427,10 @@
         },
         "plette": {
             "hashes": [
-                "sha256:3c2bbf439dad64d9a89459c20305b976d797ae1c2ad48a540e7022b377717851",
-                "sha256:cc9490a009494395dea286f4f488e0839ac06e1361d4951cc12fe621b6f0a68c"
+                "sha256:c0e3553c1e581d8423daccbd825789c6e7f29b7d9e00e5331b12e1642a1a26d3",
+                "sha256:dde5d525cf5f0cbad4d938c83b93db17887918daf63c13eafed257c4f61b07b4"
             ],
-            "markers": "python_version >= '2.6'",
-            "version": "==0.1.1"
+            "version": "==0.2.2"
         },
         "pluggy": {
             "hashes": [
@@ -369,10 +441,10 @@
         },
         "py": {
             "hashes": [
-                "sha256:3fd59af7435864e1a243790d322d763925431213b6b8529c6ca71081ace3bbf7",
-                "sha256:e31fb2767eb657cbde86c454f02e99cb846d3cd9d61b318525140214fdc0e98e"
+                "sha256:06a30435d058473046be836d3fc4f27167fd84c45b99704f2fb5509ef61f9af1",
+                "sha256:50402e9d1c9005d759426988a492e0edaadb7f4e68bcddfea586bc7432d009c6"
             ],
-            "version": "==1.5.4"
+            "version": "==1.6.0"
         },
         "pycodestyle": {
             "hashes": [
@@ -381,6 +453,12 @@
             ],
             "version": "==2.3.1"
         },
+        "pycparser": {
+            "hashes": [
+                "sha256:a988718abfad80b6b157acce7bf130a30876d27603738ac39f140993246b25b3"
+            ],
+            "version": "==2.19"
+        },
         "pyflakes": {
             "hashes": [
                 "sha256:08bd6a50edf8cffa9fa09a463063c425ecaaf10d1eb0335a7e8b1401aef89e6f",
@@ -397,25 +475,24 @@
         },
         "pyparsing": {
             "hashes": [
-                "sha256:0832bcf47acd283788593e7a0f542407bd9550a55a8a8435214a1960e04bcb04",
-                "sha256:fee43f17a9c4087e7ed1605bd6df994c6173c1e977d7ade7b651292fab2bd010"
+                "sha256:bc6c7146b91af3f567cf6daeaec360bc07d45ffec4cf5353f4d7a208ce7ca30a",
+                "sha256:d29593d8ebe7b57d6967b62494f8c72b03ac0262b1eed63826c6f788b3606401"
             ],
-            "version": "==2.2.0"
+            "version": "==2.2.2"
         },
         "pytest": {
             "hashes": [
-                "sha256:3459a123ad5532852d36f6f4501dfe1acf4af1dd9541834a164666aa40395b02",
-                "sha256:96bfd45dbe863b447a3054145cd78a9d7f31475d2bce6111b133c0cc4f305118"
+                "sha256:7e258ee50338f4e46957f9e09a0f10fb1c2d05493fa901d113a8dafd0790de4e",
+                "sha256:9332147e9af2dcf46cd7ceb14d5acadb6564744ddff1fe8c17f0ce60ece7d9a2"
             ],
             "index": "pypi",
-            "version": "==3.7.2"
+            "version": "==3.8.2"
         },
         "pytest-forked": {
             "hashes": [
                 "sha256:e4500cd0509ec4a26535f7d4112a8cc0f17d3a41c29ffd4eab479d2a55b30805",
                 "sha256:f275cb48a73fc61a6710726348e1da6d68a978f0ec0c54ece5a5fae5977e5a08"
             ],
-            "markers": "python_version >= '2.7' and python_version != '3.1.*' and python_version != '3.2.*' and python_version != '3.3.*' and python_version != '3.0.*'",
             "version": "==0.2"
         },
         "pytest-pypy": {
@@ -424,19 +501,19 @@
         },
         "pytest-tap": {
             "hashes": [
-                "sha256:06ff3ca882b69814f20e36533157394372479c91c21233964dab52c071faf8d3",
-                "sha256:ea621f3ab77c12dc662ad6daeeb0152cfab522e2ef968d90500cf4c0a59dc965"
+                "sha256:3b05ec931424bbe44e944726b68f7ef185bb6d25ce9ce21ac52c9af7ffa9b506",
+                "sha256:ca063de56298034302f3cbce55c87a27d7bfa7af7de591cdb9ec6ce45fea5467"
             ],
             "index": "pypi",
-            "version": "==2.2"
+            "version": "==2.3"
         },
         "pytest-xdist": {
             "hashes": [
-                "sha256:3308c4f6221670432d01e0b393b333d77c1fd805532e1d64450e8140855eb51b",
-                "sha256:cce08b4b7f56d34d43b365e2b3667ebb8edcf91d01c2a8fccf45c56d37e71bc1"
+                "sha256:06aa39361694c9365baaa03bec71159b59ad06c9826c6279ebba368cb3571561",
+                "sha256:1ef0d05c905cfa0c5442c90e9e350e65c6ada120e33a00a066ca51c89f5f869a"
             ],
             "index": "pypi",
-            "version": "==1.22.5"
+            "version": "==1.23.2"
         },
         "pytz": {
             "hashes": [
@@ -446,6 +523,13 @@
             "index": "pypi",
             "version": "==2018.5"
         },
+        "readme-renderer": {
+            "hashes": [
+                "sha256:237ca8705ffea849870de41101dba41543561da05c0ae45b2f1c547efa9843d2",
+                "sha256:f75049a3a7afa57165551e030dd8f9882ebf688b9600535a3f7e23596651875d"
+            ],
+            "version": "==22.0"
+        },
         "requests": {
             "hashes": [
                 "sha256:63b52e3c866428a224f97cab011de738c36aec0185aa91cfacd418b5d58911d1",
@@ -462,17 +546,17 @@
         },
         "requirementslib": {
             "hashes": [
-                "sha256:698a566272669a470a8a439250353b0b628468ea0879f4f32e22245c2b9d9e44",
-                "sha256:c7031b128e13eb8d8847f9ce409f3bfab49e8d111e7e8fca432ff8a737820653"
+                "sha256:39fb4aab3ebd7f46b266ddc98a3ac731127ee35fe6cf1b3e11be7c6551cc2c9b",
+                "sha256:810d8961f333d8fef92400f58b25f80003151fb424a545e244073fc3d95ae2dd"
             ],
-            "version": "==1.1.1"
+            "version": "==1.1.7"
         },
         "resolvelib": {
             "hashes": [
-                "sha256:d52f2c0762deeb2a4cc34a84371a7a5ac85e111bdc69ce9ae729d8d636606ad6",
-                "sha256:eb759d43bbf50de9bf36afb9f6c269fabf9ff49084dbfad4ba67252d134bf4b5"
+                "sha256:6c4c6690b0bdd78bcc002e1a5d1b6abbde58c694a6ea1838f165b20d2c943db7",
+                "sha256:8734e53271ef98f38a2c99324d5e7905bc00c97dc3fc5bb7d83c82a979e71c04"
             ],
-            "version": "==0.2.1"
+            "version": "==0.2.2"
         },
         "rope": {
             "hashes": [
@@ -528,45 +612,44 @@
         },
         "tap.py": {
             "hashes": [
-                "sha256:03accd27118473475b33b44703b223df2f148679b9b01b6ac59866df0b580073",
-                "sha256:06416d376f0d398ab163674f30ea3b4a320957e4baa51793b8e86bdfdfeb857d"
+                "sha256:8ad62ba6898fcef4913c67d468d0c4beae3109b74c03363538145e31b1840b29",
+                "sha256:f6532fd7483c5fdc2ed13575fa4494e7d037f797f8a2c6f8809a859be61271f5"
             ],
-            "version": "==2.4"
+            "version": "==2.5"
         },
         "toml": {
             "hashes": [
-                "sha256:8e86bd6ce8cc11b9620cb637466453d94f5d57ad86f17e98a98d1f73e3baab2d"
+                "sha256:229f81c57791a41d65e399fc06bf0848bab550a9dfd5ed66df18ce5f05e73d5c",
+                "sha256:235682dd292d5899d361a811df37e04a8828a5b1da3115886b73cf81ebc9100e"
             ],
-            "version": "==0.9.4"
+            "version": "==0.10.0"
         },
         "tomlkit": {
             "hashes": [
-                "sha256:4f112445d6e52a038adf23b027ccb11905fdf88976990116e8f7b171b768cedb",
-                "sha256:8b84ac193aa6366769f89541cf213efe9784ac125f08164974400c43f18fcd9f"
+                "sha256:8ab16e93162fc44d3ad83d2aa29a7140b8f7d996ae1790a73b9a7aed6fb504ac",
+                "sha256:ca181cee7aee805d455628f7c94eb8ae814763769a93e69157f250fe4ebe1926"
             ],
-            "markers": "python_version != '3.2.*' and python_version != '3.3.*' and python_version != '3.1.*' and python_version != '3.0.*' and python_version >= '2.7'",
-            "version": "==0.4.2"
+            "version": "==0.4.4"
         },
         "towncrier": {
             "editable": true,
             "git": "https://github.com/hawkowl/towncrier.git",
-            "ref": "3d600a813b8bb4277b8bd77360e54531ce274b58"
+            "ref": "47754a607a9b03f06affaf167d65b990786aae25"
         },
         "tqdm": {
             "hashes": [
-                "sha256:5ef526702c0d265d5a960a3b27f3971fac13c26cf0fb819294bfa71fc6026c88",
-                "sha256:a3364bd83ce4777320b862e3c8a93d7da91e20a95f06ef79bed7dd71c654cafa"
+                "sha256:18f1818ce951aeb9ea162ae1098b43f583f7d057b34d706f66939353d1208889",
+                "sha256:df02c0650160986bac0218bb07952245fc6960d23654648b5d5526ad5a4128c9"
             ],
-            "markers": "python_version != '3.1.*' and python_version != '3.0.*' and python_version >= '2.6'",
-            "version": "==4.25.0"
+            "version": "==4.26.0"
         },
         "twine": {
             "hashes": [
-                "sha256:08eb132bbaec40c6d25b358f546ec1dc96ebd2638a86eea68769d9e67fe2b129",
-                "sha256:2fd9a4d9ff0bcacf41fdc40c8cb0cfaef1f1859457c9653fd1b92237cc4e9f25"
+                "sha256:7d89bc6acafb31d124e6e5b295ef26ac77030bf098960c2a4c4e058335827c5c",
+                "sha256:fad6f1251195f7ddd1460cb76d6ea106c93adb4e56c41e0da79658e56e547d2c"
             ],
             "index": "pypi",
-            "version": "==1.11.0"
+            "version": "==1.12.1"
         },
         "typing": {
             "hashes": [
@@ -589,7 +672,6 @@
                 "sha256:2ce32cd126117ce2c539f0134eb89de91a8413a29baac49cbab3eb50e2026669",
                 "sha256:ca07b4c0b54e14a91af9f34d0919790b016923d157afda5efdde55c96718f752"
             ],
-            "markers": "python_version != '3.0.*' and python_version >= '2.7' and python_version != '3.2.*' and python_version != '3.1.*'",
             "version": "==16.0.0"
         },
         "virtualenv-clone": {
@@ -601,10 +683,17 @@
         },
         "vistir": {
             "hashes": [
-                "sha256:011e52dd2e09f948f638262dc39fef38998d134538705a810e88ad6d7bb94c1c",
-                "sha256:f447923d4c59e8d50add4a9d8275b25a1f038f1a1a00ded50ee3c3d00a3c7f5d"
+                "sha256:8a360ac20cbcc0863d6dbbe7a52e8b2c9ebf48abd6833c3813a82c70708244af",
+                "sha256:bc6e10284792485c10585536e6aede9e38996c841cc9d2a67238cd05742c2d0b"
+            ],
+            "version": "==0.1.6"
+        },
+        "webencodings": {
+            "hashes": [
+                "sha256:a0af1213f3c2226497a97e2b3aa01a7e4bee4f403f95be16fc9acd2947514a78",
+                "sha256:b36a1c245f2d304965eb4e0a82848379241dc04b865afcc4aab16748587e1923"
             ],
-            "version": "==0.1.4"
+            "version": "==0.5.1"
         },
         "werkzeug": {
             "hashes": [
@@ -615,11 +704,17 @@
         },
         "wheel": {
             "hashes": [
-                "sha256:0a2e54558a0628f2145d2fc822137e322412115173e8a2ddbe1c9024338ae83c",
-                "sha256:80044e51ec5bbf6c894ba0bc48d26a8c20a9ba629f4ca19ea26ecfcf87685f5f"
+                "sha256:9fa1f772f1a2df2bd00ddb4fa57e1cc349301e1facb98fbe62329803a9ff1196",
+                "sha256:d215f4520a1ba1851a3c00ba2b4122665cd3d6b0834d2ba2816198b1e3024a0e"
+            ],
+            "version": "==0.32.1"
+        },
+        "yaspin": {
+            "hashes": [
+                "sha256:36fdccc5e0637b5baa8892fe2c3d927782df7d504e9020f40eb2c1502518aa5a",
+                "sha256:8e52bf8079a48e2a53f3dfeec9e04addb900c101d1591c85df69cf677d3237e7"
             ],
-            "markers": "python_version != '3.0.*' and python_version >= '2.7' and python_version != '3.2.*' and python_version != '3.3.*' and python_version != '3.1.*'",
-            "version": "==0.31.1"
+            "version": "==0.14.0"
         }
     }
 }
diff --git a/pipenv/patched/piptools/repositories/pypi.py b/pipenv/patched/piptools/repositories/pypi.py
index eb20560d..2b156073 100644
--- a/pipenv/patched/piptools/repositories/pypi.py
+++ b/pipenv/patched/piptools/repositories/pypi.py
@@ -20,11 +20,11 @@ from .._compat import (
     SafeFileCache
 )
 os.environ["PIP_SHIMS_BASE_MODULE"] = "notpip"
-from pip_shims.shims import pip_import, VcsSupport, WheelCache
+from pip_shims.shims import do_import, VcsSupport, WheelCache
 from packaging.requirements import Requirement
 from packaging.specifiers import SpecifierSet, Specifier
 from packaging.markers import Op, Value, Variable, Marker
-InstallationError = pip_import("InstallationError", "exceptions.InstallationError", "7.0", "9999")
+InstallationError = do_import(("exceptions.InstallationError", "7.0", "9999"))
 from notpip._internal.resolve import Resolver as PipResolver
 
 
@@ -264,7 +264,7 @@ class PyPIRepository(BaseRepository):
                 'download_dir': download_dir,
                 'wheel_download_dir': self._wheel_download_dir,
                 'progress_bar': 'off',
-                'build_isolation': True
+                'build_isolation': False
             }
             resolver_kwargs = {
                 'finder': self.finder,
@@ -277,7 +277,7 @@ class PyPIRepository(BaseRepository):
                 'isolated': False,
                 'wheel_cache': wheel_cache,
                 'use_user_site': False,
-                'ignore_compatibility': True
+                'ignore_compatibility': False
             }
             resolver = None
             preparer = None
diff --git a/pipenv/vendor/attr/__init__.py b/pipenv/vendor/attr/__init__.py
index 13cb6298..debfd57b 100644
--- a/pipenv/vendor/attr/__init__.py
+++ b/pipenv/vendor/attr/__init__.py
@@ -6,16 +6,24 @@ from . import converters, exceptions, filters, validators
 from ._config import get_run_validators, set_run_validators
 from ._funcs import asdict, assoc, astuple, evolve, has
 from ._make import (
-    NOTHING, Attribute, Factory, attrib, attrs, fields, fields_dict,
-    make_class, validate
+    NOTHING,
+    Attribute,
+    Factory,
+    attrib,
+    attrs,
+    fields,
+    fields_dict,
+    make_class,
+    validate,
 )
 
 
-__version__ = "18.1.0"
+__version__ = "18.2.0"
 
 __title__ = "attrs"
 __description__ = "Classes Without Boilerplate"
-__uri__ = "http://www.attrs.org/"
+__url__ = "https://www.attrs.org/"
+__uri__ = __url__
 __doc__ = __description__ + " <" + __uri__ + ">"
 
 __author__ = "Hynek Schlawack"
diff --git a/pipenv/vendor/attr/__init__.pyi b/pipenv/vendor/attr/__init__.pyi
new file mode 100644
index 00000000..492fb85e
--- /dev/null
+++ b/pipenv/vendor/attr/__init__.pyi
@@ -0,0 +1,252 @@
+from typing import (
+    Any,
+    Callable,
+    Dict,
+    Generic,
+    List,
+    Optional,
+    Sequence,
+    Mapping,
+    Tuple,
+    Type,
+    TypeVar,
+    Union,
+    overload,
+)
+
+# `import X as X` is required to make these public
+from . import exceptions as exceptions
+from . import filters as filters
+from . import converters as converters
+from . import validators as validators
+
+_T = TypeVar("_T")
+_C = TypeVar("_C", bound=type)
+
+_ValidatorType = Callable[[Any, Attribute, _T], Any]
+_ConverterType = Callable[[Any], _T]
+_FilterType = Callable[[Attribute, Any], bool]
+# FIXME: in reality, if multiple validators are passed they must be in a list or tuple,
+# but those are invariant and so would prevent subtypes of _ValidatorType from working
+# when passed in a list or tuple.
+_ValidatorArgType = Union[_ValidatorType[_T], Sequence[_ValidatorType[_T]]]
+
+# _make --
+
+NOTHING: object
+
+# NOTE: Factory lies about its return type to make this possible: `x: List[int] = Factory(list)`
+# Work around mypy issue #4554 in the common case by using an overload.
+@overload
+def Factory(factory: Callable[[], _T]) -> _T: ...
+@overload
+def Factory(
+    factory: Union[Callable[[Any], _T], Callable[[], _T]],
+    takes_self: bool = ...,
+) -> _T: ...
+
+class Attribute(Generic[_T]):
+    name: str
+    default: Optional[_T]
+    validator: Optional[_ValidatorType[_T]]
+    repr: bool
+    cmp: bool
+    hash: Optional[bool]
+    init: bool
+    converter: Optional[_ConverterType[_T]]
+    metadata: Dict[Any, Any]
+    type: Optional[Type[_T]]
+    kw_only: bool
+    def __lt__(self, x: Attribute) -> bool: ...
+    def __le__(self, x: Attribute) -> bool: ...
+    def __gt__(self, x: Attribute) -> bool: ...
+    def __ge__(self, x: Attribute) -> bool: ...
+
+# NOTE: We had several choices for the annotation to use for type arg:
+# 1) Type[_T]
+#   - Pros: Handles simple cases correctly
+#   - Cons: Might produce less informative errors in the case of conflicting TypeVars
+#   e.g. `attr.ib(default='bad', type=int)`
+# 2) Callable[..., _T]
+#   - Pros: Better error messages than #1 for conflicting TypeVars
+#   - Cons: Terrible error messages for validator checks.
+#   e.g. attr.ib(type=int, validator=validate_str)
+#        -> error: Cannot infer function type argument
+# 3) type (and do all of the work in the mypy plugin)
+#   - Pros: Simple here, and we could customize the plugin with our own errors.
+#   - Cons: Would need to write mypy plugin code to handle all the cases.
+# We chose option #1.
+
+# `attr` lies about its return type to make the following possible:
+#     attr()    -> Any
+#     attr(8)   -> int
+#     attr(validator=<some callable>)  -> Whatever the callable expects.
+# This makes this type of assignments possible:
+#     x: int = attr(8)
+#
+# This form catches explicit None or no default but with no other arguments returns Any.
+@overload
+def attrib(
+    default: None = ...,
+    validator: None = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    convert: None = ...,
+    metadata: Optional[Mapping[Any, Any]] = ...,
+    type: None = ...,
+    converter: None = ...,
+    factory: None = ...,
+    kw_only: bool = ...,
+) -> Any: ...
+
+# This form catches an explicit None or no default and infers the type from the other arguments.
+@overload
+def attrib(
+    default: None = ...,
+    validator: Optional[_ValidatorArgType[_T]] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    convert: Optional[_ConverterType[_T]] = ...,
+    metadata: Optional[Mapping[Any, Any]] = ...,
+    type: Optional[Type[_T]] = ...,
+    converter: Optional[_ConverterType[_T]] = ...,
+    factory: Optional[Callable[[], _T]] = ...,
+    kw_only: bool = ...,
+) -> _T: ...
+
+# This form catches an explicit default argument.
+@overload
+def attrib(
+    default: _T,
+    validator: Optional[_ValidatorArgType[_T]] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    convert: Optional[_ConverterType[_T]] = ...,
+    metadata: Optional[Mapping[Any, Any]] = ...,
+    type: Optional[Type[_T]] = ...,
+    converter: Optional[_ConverterType[_T]] = ...,
+    factory: Optional[Callable[[], _T]] = ...,
+    kw_only: bool = ...,
+) -> _T: ...
+
+# This form covers type=non-Type: e.g. forward references (str), Any
+@overload
+def attrib(
+    default: Optional[_T] = ...,
+    validator: Optional[_ValidatorArgType[_T]] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    convert: Optional[_ConverterType[_T]] = ...,
+    metadata: Optional[Mapping[Any, Any]] = ...,
+    type: object = ...,
+    converter: Optional[_ConverterType[_T]] = ...,
+    factory: Optional[Callable[[], _T]] = ...,
+    kw_only: bool = ...,
+) -> Any: ...
+@overload
+def attrs(
+    maybe_cls: _C,
+    these: Optional[Dict[str, Any]] = ...,
+    repr_ns: Optional[str] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    slots: bool = ...,
+    frozen: bool = ...,
+    weakref_slot: bool = ...,
+    str: bool = ...,
+    auto_attribs: bool = ...,
+    kw_only: bool = ...,
+    cache_hash: bool = ...,
+) -> _C: ...
+@overload
+def attrs(
+    maybe_cls: None = ...,
+    these: Optional[Dict[str, Any]] = ...,
+    repr_ns: Optional[str] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    slots: bool = ...,
+    frozen: bool = ...,
+    weakref_slot: bool = ...,
+    str: bool = ...,
+    auto_attribs: bool = ...,
+    kw_only: bool = ...,
+    cache_hash: bool = ...,
+) -> Callable[[_C], _C]: ...
+
+# TODO: add support for returning NamedTuple from the mypy plugin
+class _Fields(Tuple[Attribute, ...]):
+    def __getattr__(self, name: str) -> Attribute: ...
+
+def fields(cls: type) -> _Fields: ...
+def fields_dict(cls: type) -> Dict[str, Attribute]: ...
+def validate(inst: Any) -> None: ...
+
+# TODO: add support for returning a proper attrs class from the mypy plugin
+# we use Any instead of _CountingAttr so that e.g. `make_class('Foo', [attr.ib()])` is valid
+def make_class(
+    name: str,
+    attrs: Union[List[str], Tuple[str, ...], Dict[str, Any]],
+    bases: Tuple[type, ...] = ...,
+    repr_ns: Optional[str] = ...,
+    repr: bool = ...,
+    cmp: bool = ...,
+    hash: Optional[bool] = ...,
+    init: bool = ...,
+    slots: bool = ...,
+    frozen: bool = ...,
+    weakref_slot: bool = ...,
+    str: bool = ...,
+    auto_attribs: bool = ...,
+    kw_only: bool = ...,
+    cache_hash: bool = ...,
+) -> type: ...
+
+# _funcs --
+
+# TODO: add support for returning TypedDict from the mypy plugin
+# FIXME: asdict/astuple do not honor their factory args.  waiting on one of these:
+# https://github.com/python/mypy/issues/4236
+# https://github.com/python/typing/issues/253
+def asdict(
+    inst: Any,
+    recurse: bool = ...,
+    filter: Optional[_FilterType] = ...,
+    dict_factory: Type[Mapping[Any, Any]] = ...,
+    retain_collection_types: bool = ...,
+) -> Dict[str, Any]: ...
+
+# TODO: add support for returning NamedTuple from the mypy plugin
+def astuple(
+    inst: Any,
+    recurse: bool = ...,
+    filter: Optional[_FilterType] = ...,
+    tuple_factory: Type[Sequence] = ...,
+    retain_collection_types: bool = ...,
+) -> Tuple[Any, ...]: ...
+def has(cls: type) -> bool: ...
+def assoc(inst: _T, **changes: Any) -> _T: ...
+def evolve(inst: _T, **changes: Any) -> _T: ...
+
+# _config --
+
+def set_run_validators(run: bool) -> None: ...
+def get_run_validators() -> bool: ...
+
+# aliases --
+
+s = attributes = attrs
+ib = attr = attrib
+dataclass = attrs  # Technically, partial(attrs, auto_attribs=True) ;)
diff --git a/pipenv/vendor/attr/_compat.py b/pipenv/vendor/attr/_compat.py
index 42a91ee5..5bb06593 100644
--- a/pipenv/vendor/attr/_compat.py
+++ b/pipenv/vendor/attr/_compat.py
@@ -14,6 +14,7 @@ if PYPY or sys.version_info[:2] >= (3, 6):
     ordered_dict = dict
 else:
     from collections import OrderedDict
+
     ordered_dict = OrderedDict
 
 
@@ -39,38 +40,45 @@ if PY2:
 
         def __setitem__(self, key, val):
             # We gently pretend we're a Python 3 mappingproxy.
-            raise TypeError("'mappingproxy' object does not support item "
-                            "assignment")
+            raise TypeError(
+                "'mappingproxy' object does not support item assignment"
+            )
 
         def update(self, _):
             # We gently pretend we're a Python 3 mappingproxy.
-            raise AttributeError("'mappingproxy' object has no attribute "
-                                 "'update'")
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'update'"
+            )
 
         def __delitem__(self, _):
             # We gently pretend we're a Python 3 mappingproxy.
-            raise TypeError("'mappingproxy' object does not support item "
-                            "deletion")
+            raise TypeError(
+                "'mappingproxy' object does not support item deletion"
+            )
 
         def clear(self):
             # We gently pretend we're a Python 3 mappingproxy.
-            raise AttributeError("'mappingproxy' object has no attribute "
-                                 "'clear'")
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'clear'"
+            )
 
         def pop(self, key, default=None):
             # We gently pretend we're a Python 3 mappingproxy.
-            raise AttributeError("'mappingproxy' object has no attribute "
-                                 "'pop'")
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'pop'"
+            )
 
         def popitem(self):
             # We gently pretend we're a Python 3 mappingproxy.
-            raise AttributeError("'mappingproxy' object has no attribute "
-                                 "'popitem'")
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'popitem'"
+            )
 
         def setdefault(self, key, default=None):
             # We gently pretend we're a Python 3 mappingproxy.
-            raise AttributeError("'mappingproxy' object has no attribute "
-                                 "'setdefault'")
+            raise AttributeError(
+                "'mappingproxy' object has no attribute 'setdefault'"
+            )
 
         def __repr__(self):
             # Override to be identical to the Python 3 version.
@@ -81,7 +89,9 @@ if PY2:
         res.data.update(d)  # We blocked update, so we have to do it like this.
         return res
 
+
 else:
+
     def isclass(klass):
         return isinstance(klass, type)
 
@@ -99,10 +109,12 @@ def import_ctypes():
     Moved into a function for testability.
     """
     import ctypes
+
     return ctypes
 
 
 if not PY2:
+
     def just_warn(*args, **kw):
         """
         We only warn on Python 3 because we are not aware of any concrete
@@ -114,7 +126,10 @@ if not PY2:
             RuntimeWarning,
             stacklevel=2,
         )
+
+
 else:
+
     def just_warn(*args, **kw):  # pragma: nocover
         """
         We only warn on Python 3 because we are not aware of any concrete
@@ -127,8 +142,10 @@ def make_set_closure_cell():
     Moved into a function for testability.
     """
     if PYPY:  # pragma: no cover
+
         def set_closure_cell(cell, value):
             cell.__setstate__((value,))
+
     else:
         try:
             ctypes = import_ctypes()
diff --git a/pipenv/vendor/attr/_funcs.py b/pipenv/vendor/attr/_funcs.py
index 798043af..b61d2394 100644
--- a/pipenv/vendor/attr/_funcs.py
+++ b/pipenv/vendor/attr/_funcs.py
@@ -7,8 +7,13 @@ from ._make import NOTHING, _obj_setattr, fields
 from .exceptions import AttrsAttributeNotFoundError
 
 
-def asdict(inst, recurse=True, filter=None, dict_factory=dict,
-           retain_collection_types=False):
+def asdict(
+    inst,
+    recurse=True,
+    filter=None,
+    dict_factory=dict,
+    retain_collection_types=False,
+):
     """
     Return the ``attrs`` attribute values of *inst* as a dict.
 
@@ -44,22 +49,32 @@ def asdict(inst, recurse=True, filter=None, dict_factory=dict,
             continue
         if recurse is True:
             if has(v.__class__):
-                rv[a.name] = asdict(v, recurse=True, filter=filter,
-                                    dict_factory=dict_factory)
+                rv[a.name] = asdict(
+                    v, True, filter, dict_factory, retain_collection_types
+                )
             elif isinstance(v, (tuple, list, set)):
                 cf = v.__class__ if retain_collection_types is True else list
-                rv[a.name] = cf([
-                    asdict(i, recurse=True, filter=filter,
-                           dict_factory=dict_factory)
-                    if has(i.__class__) else i
-                    for i in v
-                ])
+                rv[a.name] = cf(
+                    [
+                        _asdict_anything(
+                            i, filter, dict_factory, retain_collection_types
+                        )
+                        for i in v
+                    ]
+                )
             elif isinstance(v, dict):
                 df = dict_factory
-                rv[a.name] = df((
-                    asdict(kk, dict_factory=df) if has(kk.__class__) else kk,
-                    asdict(vv, dict_factory=df) if has(vv.__class__) else vv)
-                    for kk, vv in iteritems(v))
+                rv[a.name] = df(
+                    (
+                        _asdict_anything(
+                            kk, filter, df, retain_collection_types
+                        ),
+                        _asdict_anything(
+                            vv, filter, df, retain_collection_types
+                        ),
+                    )
+                    for kk, vv in iteritems(v)
+                )
             else:
                 rv[a.name] = v
         else:
@@ -67,8 +82,44 @@ def asdict(inst, recurse=True, filter=None, dict_factory=dict,
     return rv
 
 
-def astuple(inst, recurse=True, filter=None, tuple_factory=tuple,
-            retain_collection_types=False):
+def _asdict_anything(val, filter, dict_factory, retain_collection_types):
+    """
+    ``asdict`` only works on attrs instances, this works on anything.
+    """
+    if getattr(val.__class__, "__attrs_attrs__", None) is not None:
+        # Attrs class.
+        rv = asdict(val, True, filter, dict_factory, retain_collection_types)
+    elif isinstance(val, (tuple, list, set)):
+        cf = val.__class__ if retain_collection_types is True else list
+        rv = cf(
+            [
+                _asdict_anything(
+                    i, filter, dict_factory, retain_collection_types
+                )
+                for i in val
+            ]
+        )
+    elif isinstance(val, dict):
+        df = dict_factory
+        rv = df(
+            (
+                _asdict_anything(kk, filter, df, retain_collection_types),
+                _asdict_anything(vv, filter, df, retain_collection_types),
+            )
+            for kk, vv in iteritems(val)
+        )
+    else:
+        rv = val
+    return rv
+
+
+def astuple(
+    inst,
+    recurse=True,
+    filter=None,
+    tuple_factory=tuple,
+    retain_collection_types=False,
+):
     """
     Return the ``attrs`` attribute values of *inst* as a tuple.
 
@@ -104,34 +155,56 @@ def astuple(inst, recurse=True, filter=None, tuple_factory=tuple,
             continue
         if recurse is True:
             if has(v.__class__):
-                rv.append(astuple(v, recurse=True, filter=filter,
-                                  tuple_factory=tuple_factory,
-                                  retain_collection_types=retain))
+                rv.append(
+                    astuple(
+                        v,
+                        recurse=True,
+                        filter=filter,
+                        tuple_factory=tuple_factory,
+                        retain_collection_types=retain,
+                    )
+                )
             elif isinstance(v, (tuple, list, set)):
                 cf = v.__class__ if retain is True else list
-                rv.append(cf([
-                    astuple(j, recurse=True, filter=filter,
-                            tuple_factory=tuple_factory,
-                            retain_collection_types=retain)
-                    if has(j.__class__) else j
-                    for j in v
-                ]))
+                rv.append(
+                    cf(
+                        [
+                            astuple(
+                                j,
+                                recurse=True,
+                                filter=filter,
+                                tuple_factory=tuple_factory,
+                                retain_collection_types=retain,
+                            )
+                            if has(j.__class__)
+                            else j
+                            for j in v
+                        ]
+                    )
+                )
             elif isinstance(v, dict):
                 df = v.__class__ if retain is True else dict
-                rv.append(df(
+                rv.append(
+                    df(
                         (
                             astuple(
                                 kk,
                                 tuple_factory=tuple_factory,
-                                retain_collection_types=retain
-                            ) if has(kk.__class__) else kk,
+                                retain_collection_types=retain,
+                            )
+                            if has(kk.__class__)
+                            else kk,
                             astuple(
                                 vv,
                                 tuple_factory=tuple_factory,
-                                retain_collection_types=retain
-                            ) if has(vv.__class__) else vv
+                                retain_collection_types=retain,
+                            )
+                            if has(vv.__class__)
+                            else vv,
                         )
-                        for kk, vv in iteritems(v)))
+                        for kk, vv in iteritems(v)
+                    )
+                )
             else:
                 rv.append(v)
         else:
@@ -169,16 +242,21 @@ def assoc(inst, **changes):
         Use :func:`evolve` instead.
     """
     import warnings
-    warnings.warn("assoc is deprecated and will be removed after 2018/01.",
-                  DeprecationWarning, stacklevel=2)
+
+    warnings.warn(
+        "assoc is deprecated and will be removed after 2018/01.",
+        DeprecationWarning,
+        stacklevel=2,
+    )
     new = copy.copy(inst)
     attrs = fields(inst.__class__)
     for k, v in iteritems(changes):
         a = getattr(attrs, k, NOTHING)
         if a is NOTHING:
             raise AttrsAttributeNotFoundError(
-                "{k} is not an attrs attribute on {cl}."
-                .format(k=k, cl=new.__class__)
+                "{k} is not an attrs attribute on {cl}.".format(
+                    k=k, cl=new.__class__
+                )
             )
         _obj_setattr(new, k, v)
     return new
diff --git a/pipenv/vendor/attr/_make.py b/pipenv/vendor/attr/_make.py
index fc446115..f7fd05e7 100644
--- a/pipenv/vendor/attr/_make.py
+++ b/pipenv/vendor/attr/_make.py
@@ -1,5 +1,6 @@
 from __future__ import absolute_import, division, print_function
 
+import copy
 import hashlib
 import linecache
 import sys
@@ -10,11 +11,19 @@ from operator import itemgetter
 
 from . import _config
 from ._compat import (
-    PY2, isclass, iteritems, metadata_proxy, ordered_dict, set_closure_cell
+    PY2,
+    isclass,
+    iteritems,
+    metadata_proxy,
+    ordered_dict,
+    set_closure_cell,
 )
 from .exceptions import (
-    DefaultAlreadySetError, FrozenInstanceError, NotAnAttrsClassError,
-    UnannotatedAttributeError
+    DefaultAlreadySetError,
+    FrozenInstanceError,
+    NotAnAttrsClassError,
+    PythonTooOldError,
+    UnannotatedAttributeError,
 )
 
 
@@ -22,8 +31,14 @@ from .exceptions import (
 _obj_setattr = object.__setattr__
 _init_converter_pat = "__attr_converter_{}"
 _init_factory_pat = "__attr_factory_{}"
-_tuple_property_pat = "    {attr_name} = property(itemgetter({index}))"
+_tuple_property_pat = (
+    "    {attr_name} = _attrs_property(_attrs_itemgetter({index}))"
+)
 _classvar_prefixes = ("typing.ClassVar", "t.ClassVar", "ClassVar")
+# we don't use a double-underscore prefix because that triggers
+# name mangling when trying to create a slot for the field
+# (when slots=True)
+_hash_cache_field = "_attrs_cached_hash"
 
 _empty_metadata_singleton = metadata_proxy({})
 
@@ -32,26 +47,19 @@ class _Nothing(object):
     """
     Sentinel class to indicate the lack of a value when ``None`` is ambiguous.
 
-    All instances of `_Nothing` are equal.
+    ``_Nothing`` is a singleton. There is only ever one of it.
     """
-    def __copy__(self):
-        return self
 
-    def __deepcopy__(self, _):
-        return self
+    _singleton = None
 
-    def __eq__(self, other):
-        return other.__class__ == _Nothing
-
-    def __ne__(self, other):
-        return not self == other
+    def __new__(cls):
+        if _Nothing._singleton is None:
+            _Nothing._singleton = super(_Nothing, cls).__new__(cls)
+        return _Nothing._singleton
 
     def __repr__(self):
         return "NOTHING"
 
-    def __hash__(self):
-        return 0xc0ffee
-
 
 NOTHING = _Nothing()
 """
@@ -59,10 +67,20 @@ Sentinel to indicate the lack of a value when ``None`` is ambiguous.
 """
 
 
-def attrib(default=NOTHING, validator=None,
-           repr=True, cmp=True, hash=None, init=True,
-           convert=None, metadata=None, type=None, converter=None,
-           factory=None):
+def attrib(
+    default=NOTHING,
+    validator=None,
+    repr=True,
+    cmp=True,
+    hash=None,
+    init=True,
+    convert=None,
+    metadata=None,
+    type=None,
+    converter=None,
+    factory=None,
+    kw_only=False,
+):
     """
     Create a new attribute on a class.
 
@@ -135,6 +153,13 @@ def attrib(default=NOTHING, validator=None,
         Regardless of the approach used, the type will be stored on
         ``Attribute.type``.
 
+        Please note that ``attrs`` doesn't do anything with this metadata by
+        itself. You can use it as part of your own code or for
+        :doc:`static type checking <types>`.
+    :param kw_only: Make this attribute keyword-only (Python 3+)
+        in the generated ``__init__`` (if ``init`` is ``False``, this
+        parameter is ignored).
+
     .. versionadded:: 15.2.0 *convert*
     .. versionadded:: 16.3.0 *metadata*
     .. versionchanged:: 17.1.0 *validator* can be a ``list`` now.
@@ -146,6 +171,7 @@ def attrib(default=NOTHING, validator=None,
        *convert* to achieve consistency with other noun-based arguments.
     .. versionadded:: 18.1.0
        ``factory=f`` is syntactic sugar for ``default=attr.Factory(f)``.
+    .. versionadded:: 18.2.0 *kw_only*
     """
     if hash is not None and hash is not True and hash is not False:
         raise TypeError(
@@ -161,7 +187,8 @@ def attrib(default=NOTHING, validator=None,
         warnings.warn(
             "The `convert` argument is deprecated in favor of `converter`.  "
             "It will be removed after 2019/01.",
-            DeprecationWarning, stacklevel=2
+            DeprecationWarning,
+            stacklevel=2,
         )
         converter = convert
 
@@ -172,9 +199,7 @@ def attrib(default=NOTHING, validator=None,
                 "exclusive."
             )
         if not callable(factory):
-            raise ValueError(
-                "The `factory` argument must be a callable."
-            )
+            raise ValueError("The `factory` argument must be a callable.")
         default = Factory(factory)
 
     if metadata is None:
@@ -190,6 +215,7 @@ def attrib(default=NOTHING, validator=None,
         converter=converter,
         metadata=metadata,
         type=type,
+        kw_only=kw_only,
     )
 
 
@@ -210,24 +236,30 @@ def _make_attr_tuple_class(cls_name, attr_names):
     ]
     if attr_names:
         for i, attr_name in enumerate(attr_names):
-            attr_class_template.append(_tuple_property_pat.format(
-                index=i,
-                attr_name=attr_name,
-            ))
+            attr_class_template.append(
+                _tuple_property_pat.format(index=i, attr_name=attr_name)
+            )
     else:
         attr_class_template.append("    pass")
-    globs = {"itemgetter": itemgetter}
+    globs = {"_attrs_itemgetter": itemgetter, "_attrs_property": property}
     eval(compile("\n".join(attr_class_template), "", "exec"), globs)
+
     return globs[attr_class_name]
 
 
 # Tuple class for extracted attributes from a class definition.
-# `super_attrs` is a subset of `attrs`.
-_Attributes = _make_attr_tuple_class("_Attributes", [
-    "attrs",            # all attributes to build dunder methods for
-    "super_attrs",      # attributes that have been inherited
-    "super_attrs_map",  # map inherited attributes to their originating classes
-])
+# `base_attrs` is a subset of `attrs`.
+_Attributes = _make_attr_tuple_class(
+    "_Attributes",
+    [
+        # all attributes to build dunder methods for
+        "attrs",
+        # attributes that have been inherited
+        "base_attrs",
+        # map inherited attributes to their originating classes
+        "base_attrs_map",
+    ],
+)
 
 
 def _is_class_var(annot):
@@ -250,8 +282,8 @@ def _get_annotations(cls):
         return {}
 
     # Verify that the annotations aren't merely inherited.
-    for super_cls in cls.__mro__[1:]:
-        if anns is getattr(super_cls, "__annotations__", None):
+    for base_cls in cls.__mro__[1:]:
+        if anns is getattr(base_cls, "__annotations__", None):
             return {}
 
     return anns
@@ -264,7 +296,7 @@ def _counter_getter(e):
     return e[1].counter
 
 
-def _transform_attrs(cls, these, auto_attribs):
+def _transform_attrs(cls, these, auto_attribs, kw_only):
     """
     Transform all `_CountingAttr`s on a class into `Attribute`s.
 
@@ -276,19 +308,14 @@ def _transform_attrs(cls, these, auto_attribs):
     anns = _get_annotations(cls)
 
     if these is not None:
-        ca_list = [
-            (name, ca)
-            for name, ca
-            in iteritems(these)
-        ]
+        ca_list = [(name, ca) for name, ca in iteritems(these)]
 
         if not isinstance(these, ordered_dict):
             ca_list.sort(key=_counter_getter)
     elif auto_attribs is True:
         ca_names = {
             name
-            for name, attr
-            in cd.items()
+            for name, attr in cd.items()
             if isinstance(attr, _CountingAttr)
         }
         ca_list = []
@@ -308,77 +335,91 @@ def _transform_attrs(cls, these, auto_attribs):
         unannotated = ca_names - annot_names
         if len(unannotated) > 0:
             raise UnannotatedAttributeError(
-                "The following `attr.ib`s lack a type annotation: " +
-                ", ".join(sorted(
-                    unannotated,
-                    key=lambda n: cd.get(n).counter
-                )) + "."
+                "The following `attr.ib`s lack a type annotation: "
+                + ", ".join(
+                    sorted(unannotated, key=lambda n: cd.get(n).counter)
+                )
+                + "."
             )
     else:
-        ca_list = sorted((
-            (name, attr)
-            for name, attr
-            in cd.items()
-            if isinstance(attr, _CountingAttr)
-        ), key=lambda e: e[1].counter)
+        ca_list = sorted(
+            (
+                (name, attr)
+                for name, attr in cd.items()
+                if isinstance(attr, _CountingAttr)
+            ),
+            key=lambda e: e[1].counter,
+        )
 
     own_attrs = [
         Attribute.from_counting_attr(
-            name=attr_name,
-            ca=ca,
-            type=anns.get(attr_name),
+            name=attr_name, ca=ca, type=anns.get(attr_name)
         )
-        for attr_name, ca
-        in ca_list
+        for attr_name, ca in ca_list
     ]
 
-    super_attrs = []
-    super_attr_map = {}  # A dictionary of superattrs to their classes.
+    base_attrs = []
+    base_attr_map = {}  # A dictionary of base attrs to their classes.
     taken_attr_names = {a.name: a for a in own_attrs}
 
     # Traverse the MRO and collect attributes.
-    for super_cls in cls.__mro__[1:-1]:
-        sub_attrs = getattr(super_cls, "__attrs_attrs__", None)
+    for base_cls in cls.__mro__[1:-1]:
+        sub_attrs = getattr(base_cls, "__attrs_attrs__", None)
         if sub_attrs is not None:
             for a in sub_attrs:
                 prev_a = taken_attr_names.get(a.name)
                 # Only add an attribute if it hasn't been defined before.  This
                 # allows for overwriting attribute definitions by subclassing.
                 if prev_a is None:
-                    super_attrs.append(a)
+                    base_attrs.append(a)
                     taken_attr_names[a.name] = a
-                    super_attr_map[a.name] = super_cls
+                    base_attr_map[a.name] = base_cls
 
-    attr_names = [a.name for a in super_attrs + own_attrs]
+    attr_names = [a.name for a in base_attrs + own_attrs]
 
     AttrsClass = _make_attr_tuple_class(cls.__name__, attr_names)
 
-    attrs = AttrsClass(
-        super_attrs + [
-            Attribute.from_counting_attr(
-                name=attr_name,
-                ca=ca,
-                type=anns.get(attr_name)
-            )
-            for attr_name, ca
-            in ca_list
-        ]
-    )
+    if kw_only:
+        own_attrs = [a._assoc(kw_only=True) for a in own_attrs]
+        base_attrs = [a._assoc(kw_only=True) for a in base_attrs]
+
+    attrs = AttrsClass(base_attrs + own_attrs)
 
     had_default = False
+    was_kw_only = False
     for a in attrs:
-        if had_default is True and a.default is NOTHING and a.init is True:
+        if (
+            was_kw_only is False
+            and had_default is True
+            and a.default is NOTHING
+            and a.init is True
+            and a.kw_only is False
+        ):
             raise ValueError(
                 "No mandatory attributes allowed after an attribute with a "
-                "default value or factory.  Attribute in question: {a!r}"
-                .format(a=a)
+                "default value or factory.  Attribute in question: %r" % (a,)
             )
-        elif had_default is False and \
-                a.default is not NOTHING and \
-                a.init is not False:
+        elif (
+            had_default is False
+            and a.default is not NOTHING
+            and a.init is not False
+            and
+            # Keyword-only attributes without defaults can be specified
+            # after keyword-only attributes with defaults.
+            a.kw_only is False
+        ):
             had_default = True
+        if was_kw_only is True and a.kw_only is False:
+            raise ValueError(
+                "Non keyword-only attributes are not allowed after a "
+                "keyword-only attribute.  Attribute in question: {a!r}".format(
+                    a=a
+                )
+            )
+        if was_kw_only is False and a.init is True and a.kw_only is True:
+            was_kw_only = True
 
-    return _Attributes((attrs, super_attrs, super_attr_map))
+    return _Attributes((attrs, base_attrs, base_attr_map))
 
 
 def _frozen_setattrs(self, name, value):
@@ -399,24 +440,47 @@ class _ClassBuilder(object):
     """
     Iteratively build *one* class.
     """
+
     __slots__ = (
-        "_cls", "_cls_dict", "_attrs", "_super_names", "_attr_names", "_slots",
-        "_frozen", "_has_post_init", "_delete_attribs", "_super_attr_map",
+        "_cls",
+        "_cls_dict",
+        "_attrs",
+        "_base_names",
+        "_attr_names",
+        "_slots",
+        "_frozen",
+        "_weakref_slot",
+        "_cache_hash",
+        "_has_post_init",
+        "_delete_attribs",
+        "_base_attr_map",
     )
 
-    def __init__(self, cls, these, slots, frozen, auto_attribs):
-        attrs, super_attrs, super_map = _transform_attrs(
-            cls, these, auto_attribs
+    def __init__(
+        self,
+        cls,
+        these,
+        slots,
+        frozen,
+        weakref_slot,
+        auto_attribs,
+        kw_only,
+        cache_hash,
+    ):
+        attrs, base_attrs, base_map = _transform_attrs(
+            cls, these, auto_attribs, kw_only
         )
 
         self._cls = cls
         self._cls_dict = dict(cls.__dict__) if slots else {}
         self._attrs = attrs
-        self._super_names = set(a.name for a in super_attrs)
-        self._super_attr_map = super_map
+        self._base_names = set(a.name for a in base_attrs)
+        self._base_attr_map = base_map
         self._attr_names = tuple(a.name for a in attrs)
         self._slots = slots
-        self._frozen = frozen or _has_frozen_superclass(cls)
+        self._frozen = frozen or _has_frozen_base_class(cls)
+        self._weakref_slot = weakref_slot
+        self._cache_hash = cache_hash
         self._has_post_init = bool(getattr(cls, "__attrs_post_init__", False))
         self._delete_attribs = not bool(these)
 
@@ -433,7 +497,7 @@ class _ClassBuilder(object):
         """
         Finalize class based on the accumulated configuration.
 
-        Builder cannot be used anymore after calling this method.
+        Builder cannot be used after calling this method.
         """
         if self._slots is True:
             return self._create_slots_class()
@@ -445,14 +509,22 @@ class _ClassBuilder(object):
         Apply accumulated methods and return the class.
         """
         cls = self._cls
-        super_names = self._super_names
+        base_names = self._base_names
 
         # Clean class of attribute definitions (`attr.ib()`s).
         if self._delete_attribs:
             for name in self._attr_names:
-                if name not in super_names and \
-                        getattr(cls, name, None) is not None:
-                    delattr(cls, name)
+                if (
+                    name not in base_names
+                    and getattr(cls, name, None) is not None
+                ):
+                    try:
+                        delattr(cls, name)
+                    except AttributeError:
+                        # This can happen if a base class defines a class
+                        # variable and we want to set an attribute with the
+                        # same name by using only a type annotation.
+                        pass
 
         # Attach our dunder methods.
         for name, value in self._cls_dict.items():
@@ -464,20 +536,36 @@ class _ClassBuilder(object):
         """
         Build and return a new class with a `__slots__` attribute.
         """
-        super_names = self._super_names
+        base_names = self._base_names
         cd = {
             k: v
             for k, v in iteritems(self._cls_dict)
-            if k not in tuple(self._attr_names) + ("__dict__",)
+            if k not in tuple(self._attr_names) + ("__dict__", "__weakref__")
         }
 
+        weakref_inherited = False
+
+        # Traverse the MRO to check for an existing __weakref__.
+        for base_cls in self._cls.__mro__[1:-1]:
+            if "__weakref__" in getattr(base_cls, "__dict__", ()):
+                weakref_inherited = True
+                break
+
+        names = self._attr_names
+        if (
+            self._weakref_slot
+            and "__weakref__" not in getattr(self._cls, "__slots__", ())
+            and "__weakref__" not in names
+            and not weakref_inherited
+        ):
+            names += ("__weakref__",)
+
         # We only add the names of attributes that aren't inherited.
         # Settings __slots__ to inherited attributes wastes memory.
-        cd["__slots__"] = tuple(
-            name
-            for name in self._attr_names
-            if name not in super_names
-        )
+        slot_names = [name for name in names if name not in base_names]
+        if self._cache_hash:
+            slot_names.append(_hash_cache_field)
+        cd["__slots__"] = tuple(slot_names)
 
         qualname = getattr(self._cls, "__qualname__", None)
         if qualname is not None:
@@ -492,10 +580,7 @@ class _ClassBuilder(object):
             """
             Automatically created by attrs.
             """
-            return tuple(
-                getattr(self, name)
-                for name in state_attr_names
-            )
+            return tuple(getattr(self, name) for name in state_attr_names)
 
         def slots_setstate(self, state):
             """
@@ -510,11 +595,7 @@ class _ClassBuilder(object):
         cd["__setstate__"] = slots_setstate
 
         # Create new class based on old class and our methods.
-        cls = type(self._cls)(
-            self._cls.__name__,
-            self._cls.__bases__,
-            cd,
-        )
+        cls = type(self._cls)(self._cls.__name__, self._cls.__bases__, cd)
 
         # The following is a fix for
         # https://github.com/python-attrs/attrs/issues/102.  On Python 3,
@@ -563,7 +644,9 @@ class _ClassBuilder(object):
 
     def add_hash(self):
         self._cls_dict["__hash__"] = self._add_method_dunders(
-            _make_hash(self._attrs)
+            _make_hash(
+                self._attrs, frozen=self._frozen, cache_hash=self._cache_hash
+            )
         )
 
         return self
@@ -575,7 +658,8 @@ class _ClassBuilder(object):
                 self._has_post_init,
                 self._frozen,
                 self._slots,
-                self._super_attr_map,
+                self._cache_hash,
+                self._base_attr_map,
             )
         )
 
@@ -584,11 +668,11 @@ class _ClassBuilder(object):
     def add_cmp(self):
         cd = self._cls_dict
 
-        cd["__eq__"], cd["__ne__"], cd["__lt__"], cd["__le__"], cd["__gt__"], \
-            cd["__ge__"] = (
-                self._add_method_dunders(meth)
-                for meth in _make_cmp(self._attrs)
-            )
+        cd["__eq__"], cd["__ne__"], cd["__lt__"], cd["__le__"], cd[
+            "__gt__"
+        ], cd["__ge__"] = (
+            self._add_method_dunders(meth) for meth in _make_cmp(self._attrs)
+        )
 
         return self
 
@@ -603,7 +687,7 @@ class _ClassBuilder(object):
 
         try:
             method.__qualname__ = ".".join(
-                (self._cls.__qualname__, method.__name__,)
+                (self._cls.__qualname__, method.__name__)
             )
         except AttributeError:
             pass
@@ -611,9 +695,22 @@ class _ClassBuilder(object):
         return method
 
 
-def attrs(maybe_cls=None, these=None, repr_ns=None,
-          repr=True, cmp=True, hash=None, init=True,
-          slots=False, frozen=False, str=False, auto_attribs=False):
+def attrs(
+    maybe_cls=None,
+    these=None,
+    repr_ns=None,
+    repr=True,
+    cmp=True,
+    hash=None,
+    init=True,
+    slots=False,
+    frozen=False,
+    weakref_slot=True,
+    str=False,
+    auto_attribs=False,
+    kw_only=False,
+    cache_hash=False,
+):
     r"""
     A class decorator that adds `dunder
     <https://wiki.python.org/moin/DunderAlias>`_\ -methods according to the
@@ -645,7 +742,7 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,
     :param bool cmp: Create ``__eq__``, ``__ne__``, ``__lt__``, ``__le__``,
         ``__gt__``, and ``__ge__`` methods that compare the class as if it were
         a tuple of its ``attrs`` attributes.  But the attributes are *only*
-        compared, if the type of both classes is *identical*!
+        compared, if the types of both classes are *identical*!
     :param hash: If ``None`` (default), the ``__hash__`` method is generated
         according how *cmp* and *frozen* are set.
 
@@ -653,7 +750,7 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,
         2. If *cmp* is True and *frozen* is False, ``__hash__`` will be set to
            None, marking it unhashable (which it is).
         3. If *cmp* is False, ``__hash__`` will be left untouched meaning the
-           ``__hash__`` method of the superclass will be used (if superclass is
+           ``__hash__`` method of the base class will be used (if base class is
            ``object``, this means it will fall back to id-based hashing.).
 
         Although not recommended, you can decide for yourself and force
@@ -693,6 +790,8 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,
                ``object.__setattr__(self, "attribute_name", value)``.
 
         ..  _slots: https://docs.python.org/3/reference/datamodel.html#slots
+    :param bool weakref_slot: Make instances weak-referenceable.  This has no
+        effect unless ``slots`` is also enabled.
     :param bool auto_attribs: If True, collect `PEP 526`_-annotated attributes
         (Python 3.6 and later only) from the class body.
 
@@ -710,6 +809,16 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,
         Attributes annotated as :data:`typing.ClassVar` are **ignored**.
 
         .. _`PEP 526`: https://www.python.org/dev/peps/pep-0526/
+    :param bool kw_only: Make all attributes keyword-only (Python 3+)
+        in the generated ``__init__`` (if ``init`` is ``False``, this
+        parameter is ignored).
+    :param bool cache_hash: Ensure that the object's hash code is computed
+        only once and stored on the object.  If this is set to ``True``,
+        hashing must be either explicitly or implicitly enabled for this
+        class.  If the hash code is cached, then no attributes of this
+        class which participate in hash code computation may be mutated
+        after object creation.
+
 
     .. versionadded:: 16.0.0 *slots*
     .. versionadded:: 16.1.0 *frozen*
@@ -721,12 +830,30 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,
     .. versionchanged:: 18.1.0
        If *these* is passed, no attributes are deleted from the class body.
     .. versionchanged:: 18.1.0 If *these* is ordered, the order is retained.
+    .. versionadded:: 18.2.0 *weakref_slot*
+    .. deprecated:: 18.2.0
+       ``__lt__``, ``__le__``, ``__gt__``, and ``__ge__`` now raise a
+       :class:`DeprecationWarning` if the classes compared are subclasses of
+       each other. ``__eq`` and ``__ne__`` never tried to compared subclasses
+       to each other.
+    .. versionadded:: 18.2.0 *kw_only*
+    .. versionadded:: 18.2.0 *cache_hash*
     """
+
     def wrap(cls):
         if getattr(cls, "__class__", None) is None:
             raise TypeError("attrs only works with new-style classes.")
 
-        builder = _ClassBuilder(cls, these, slots, frozen, auto_attribs)
+        builder = _ClassBuilder(
+            cls,
+            these,
+            slots,
+            frozen,
+            weakref_slot,
+            auto_attribs,
+            kw_only,
+            cache_hash,
+        )
 
         if repr is True:
             builder.add_repr(repr_ns)
@@ -741,14 +868,31 @@ def attrs(maybe_cls=None, these=None, repr_ns=None,
                 "Invalid value for hash.  Must be True, False, or None."
             )
         elif hash is False or (hash is None and cmp is False):
-            pass
+            if cache_hash:
+                raise TypeError(
+                    "Invalid value for cache_hash.  To use hash caching,"
+                    " hashing must be either explicitly or implicitly "
+                    "enabled."
+                )
         elif hash is True or (hash is None and cmp is True and frozen is True):
             builder.add_hash()
         else:
+            if cache_hash:
+                raise TypeError(
+                    "Invalid value for cache_hash.  To use hash caching,"
+                    " hashing must be either explicitly or implicitly "
+                    "enabled."
+                )
             builder.make_unhashable()
 
         if init is True:
             builder.add_init()
+        else:
+            if cache_hash:
+                raise TypeError(
+                    "Invalid value for cache_hash.  To use hash caching,"
+                    " init must be True."
+                )
 
         return builder.build_class()
 
@@ -768,19 +912,22 @@ Internal alias so we can use it in functions that take an argument called
 
 
 if PY2:
-    def _has_frozen_superclass(cls):
+
+    def _has_frozen_base_class(cls):
         """
         Check whether *cls* has a frozen ancestor by looking at its
         __setattr__.
         """
         return (
-            getattr(
-                cls.__setattr__, "__module__", None
-            ) == _frozen_setattrs.__module__ and
-            cls.__setattr__.__name__ == _frozen_setattrs.__name__
+            getattr(cls.__setattr__, "__module__", None)
+            == _frozen_setattrs.__module__
+            and cls.__setattr__.__name__ == _frozen_setattrs.__name__
         )
+
+
 else:
-    def _has_frozen_superclass(cls):
+
+    def _has_frozen_base_class(cls):
         """
         Check whether *cls* has a frozen ancestor by looking at its
         __setattr__.
@@ -795,29 +942,54 @@ def _attrs_to_tuple(obj, attrs):
     return tuple(getattr(obj, a.name) for a in attrs)
 
 
-def _make_hash(attrs):
+def _make_hash(attrs, frozen, cache_hash):
     attrs = tuple(
         a
         for a in attrs
         if a.hash is True or (a.hash is None and a.cmp is True)
     )
 
+    tab = "        "
+
     # We cache the generated hash methods for the same kinds of attributes.
     sha1 = hashlib.sha1()
     sha1.update(repr(attrs).encode("utf-8"))
     unique_filename = "<attrs generated hash %s>" % (sha1.hexdigest(),)
     type_hash = hash(unique_filename)
-    lines = [
-        "def __hash__(self):",
-        "    return hash((",
-        "        %d," % (type_hash,),
-    ]
-    for a in attrs:
-        lines.append("        self.%s," % (a.name))
 
-    lines.append("    ))")
+    method_lines = ["def __hash__(self):"]
 
-    script = "\n".join(lines)
+    def append_hash_computation_lines(prefix, indent):
+        """
+        Generate the code for actually computing the hash code.
+        Below this will either be returned directly or used to compute
+        a value which is then cached, depending on the value of cache_hash
+        """
+        method_lines.extend(
+            [indent + prefix + "hash((", indent + "        %d," % (type_hash,)]
+        )
+
+        for a in attrs:
+            method_lines.append(indent + "        self.%s," % a.name)
+
+        method_lines.append(indent + "    ))")
+
+    if cache_hash:
+        method_lines.append(tab + "if self.%s is None:" % _hash_cache_field)
+        if frozen:
+            append_hash_computation_lines(
+                "object.__setattr__(self, '%s', " % _hash_cache_field, tab * 2
+            )
+            method_lines.append(tab * 2 + ")")  # close __setattr__
+        else:
+            append_hash_computation_lines(
+                "self.%s = " % _hash_cache_field, tab * 2
+            )
+        method_lines.append(tab + "return self.%s" % _hash_cache_field)
+    else:
+        append_hash_computation_lines("return ", tab)
+
+    script = "\n".join(method_lines)
     globs = {}
     locs = {}
     bytecode = compile(script, unique_filename, "exec")
@@ -839,7 +1011,7 @@ def _add_hash(cls, attrs):
     """
     Add a hash method to *cls*.
     """
-    cls.__hash__ = _make_hash(attrs)
+    cls.__hash__ = _make_hash(attrs, frozen=False, cache_hash=False)
     return cls
 
 
@@ -855,6 +1027,12 @@ def __ne__(self, other):
     return not result
 
 
+WARNING_CMP_ISINSTANCE = (
+    "Comparision of subclasses using __%s__ is deprecated and will be removed "
+    "in 2019."
+)
+
+
 def _make_cmp(attrs):
     attrs = [a for a in attrs if a.cmp]
 
@@ -871,9 +1049,7 @@ def _make_cmp(attrs):
     # irregularities like nan == nan is false but (nan,) == (nan,) is true.
     if attrs:
         lines.append("    return  (")
-        others = [
-            "    ) == (",
-        ]
+        others = ["    ) == ("]
         for a in attrs:
             lines.append("        self.%s," % (a.name,))
             others.append("        other.%s," % (a.name,))
@@ -910,6 +1086,10 @@ def _make_cmp(attrs):
         Automatically created by attrs.
         """
         if isinstance(other, self.__class__):
+            if other.__class__ is not self.__class__:
+                warnings.warn(
+                    WARNING_CMP_ISINSTANCE % ("lt",), DeprecationWarning
+                )
             return attrs_to_tuple(self) < attrs_to_tuple(other)
         else:
             return NotImplemented
@@ -919,6 +1099,10 @@ def _make_cmp(attrs):
         Automatically created by attrs.
         """
         if isinstance(other, self.__class__):
+            if other.__class__ is not self.__class__:
+                warnings.warn(
+                    WARNING_CMP_ISINSTANCE % ("le",), DeprecationWarning
+                )
             return attrs_to_tuple(self) <= attrs_to_tuple(other)
         else:
             return NotImplemented
@@ -928,6 +1112,10 @@ def _make_cmp(attrs):
         Automatically created by attrs.
         """
         if isinstance(other, self.__class__):
+            if other.__class__ is not self.__class__:
+                warnings.warn(
+                    WARNING_CMP_ISINSTANCE % ("gt",), DeprecationWarning
+                )
             return attrs_to_tuple(self) > attrs_to_tuple(other)
         else:
             return NotImplemented
@@ -937,6 +1125,10 @@ def _make_cmp(attrs):
         Automatically created by attrs.
         """
         if isinstance(other, self.__class__):
+            if other.__class__ is not self.__class__:
+                warnings.warn(
+                    WARNING_CMP_ISINSTANCE % ("ge",), DeprecationWarning
+                )
             return attrs_to_tuple(self) >= attrs_to_tuple(other)
         else:
             return NotImplemented
@@ -951,8 +1143,9 @@ def _add_cmp(cls, attrs=None):
     if attrs is None:
         attrs = cls.__attrs_attrs__
 
-    cls.__eq__, cls.__ne__, cls.__lt__, cls.__le__, cls.__gt__, cls.__ge__ = \
-        _make_cmp(attrs)
+    cls.__eq__, cls.__ne__, cls.__lt__, cls.__le__, cls.__gt__, cls.__ge__ = _make_cmp(  # noqa
+        attrs
+    )
 
     return cls
 
@@ -964,11 +1157,7 @@ def _make_repr(attrs, ns):
     """
     Make a repr method for *attr_names* adding *ns* to the full name.
     """
-    attr_names = tuple(
-        a.name
-        for a in attrs
-        if a.repr
-    )
+    attr_names = tuple(a.name for a in attrs if a.repr)
 
     def __repr__(self):
         """
@@ -1009,6 +1198,7 @@ def _make_repr(attrs, ns):
             return "".join(result) + ")"
         finally:
             working_set.remove(id(self))
+
     return __repr__
 
 
@@ -1023,34 +1213,21 @@ def _add_repr(cls, ns=None, attrs=None):
     return cls
 
 
-def _make_init(attrs, post_init, frozen, slots, super_attr_map):
-    attrs = [
-        a
-        for a in attrs
-        if a.init or a.default is not NOTHING
-    ]
+def _make_init(attrs, post_init, frozen, slots, cache_hash, base_attr_map):
+    attrs = [a for a in attrs if a.init or a.default is not NOTHING]
 
     # We cache the generated init methods for the same kinds of attributes.
     sha1 = hashlib.sha1()
     sha1.update(repr(attrs).encode("utf-8"))
-    unique_filename = "<attrs generated init {0}>".format(
-        sha1.hexdigest()
-    )
+    unique_filename = "<attrs generated init {0}>".format(sha1.hexdigest())
 
     script, globs, annotations = _attrs_to_init_script(
-        attrs,
-        frozen,
-        slots,
-        post_init,
-        super_attr_map,
+        attrs, frozen, slots, post_init, cache_hash, base_attr_map
     )
     locs = {}
     bytecode = compile(script, unique_filename, "exec")
     attr_dict = dict((a.name, a) for a in attrs)
-    globs.update({
-        "NOTHING": NOTHING,
-        "attr_dict": attr_dict,
-    })
+    globs.update({"NOTHING": NOTHING, "attr_dict": attr_dict})
     if frozen is True:
         # Save the lookup overhead in __init__ if we need to circumvent
         # immutability.
@@ -1080,7 +1257,8 @@ def _add_init(cls, frozen):
         getattr(cls, "__attrs_post_init__", False),
         frozen,
         _is_slot_cls(cls),
-        {},
+        cache_hash=False,
+        base_attr_map={},
     )
     return cls
 
@@ -1162,14 +1340,16 @@ def _is_slot_cls(cls):
     return "__slots__" in cls.__dict__
 
 
-def _is_slot_attr(a_name, super_attr_map):
+def _is_slot_attr(a_name, base_attr_map):
     """
     Check if the attribute name comes from a slot class.
     """
-    return a_name in super_attr_map and _is_slot_cls(super_attr_map[a_name])
+    return a_name in base_attr_map and _is_slot_cls(base_attr_map[a_name])
 
 
-def _attrs_to_init_script(attrs, frozen, slots, post_init, super_attr_map):
+def _attrs_to_init_script(
+    attrs, frozen, slots, post_init, cache_hash, base_attr_map
+):
     """
     Return a script of an initializer for *attrs* and a dict of globals.
 
@@ -1180,14 +1360,14 @@ def _attrs_to_init_script(attrs, frozen, slots, post_init, super_attr_map):
     """
     lines = []
     any_slot_ancestors = any(
-        _is_slot_attr(a.name, super_attr_map)
-        for a in attrs
+        _is_slot_attr(a.name, base_attr_map) for a in attrs
     )
     if frozen is True:
         if slots is True:
             lines.append(
                 # Circumvent the __setattr__ descriptor to save one lookup per
                 # assignment.
+                # Note _setattr will be used again below if cache_hash is True
                 "_setattr = _cached_setattr.__get__(self, self.__class__)"
             )
 
@@ -1204,13 +1384,13 @@ def _attrs_to_init_script(attrs, frozen, slots, post_init, super_attr_map):
                     "value_var": value_var,
                     "conv": conv_name,
                 }
+
         else:
             # Dict frozen classes assign directly to __dict__.
             # But only if the attribute doesn't come from an ancestor slot
             # class.
-            lines.append(
-                "_inst_dict = self.__dict__"
-            )
+            # Note _inst_dict will be used again below if cache_hash is True
+            lines.append("_inst_dict = self.__dict__")
             if any_slot_ancestors:
                 lines.append(
                     # Circumvent the __setattr__ descriptor to save one lookup
@@ -1219,7 +1399,7 @@ def _attrs_to_init_script(attrs, frozen, slots, post_init, super_attr_map):
                 )
 
             def fmt_setter(attr_name, value_var):
-                if _is_slot_attr(attr_name, super_attr_map):
+                if _is_slot_attr(attr_name, base_attr_map):
                     res = "_setattr('%(attr_name)s', %(value_var)s)" % {
                         "attr_name": attr_name,
                         "value_var": value_var,
@@ -1233,7 +1413,7 @@ def _attrs_to_init_script(attrs, frozen, slots, post_init, super_attr_map):
 
             def fmt_setter_with_converter(attr_name, value_var):
                 conv_name = _init_converter_pat.format(attr_name)
-                if _is_slot_attr(attr_name, super_attr_map):
+                if _is_slot_attr(attr_name, base_attr_map):
                     tmpl = "_setattr('%(attr_name)s', %(c)s(%(value_var)s))"
                 else:
                     tmpl = "_inst_dict['%(attr_name)s'] = %(c)s(%(value_var)s)"
@@ -1242,6 +1422,7 @@ def _attrs_to_init_script(attrs, frozen, slots, post_init, super_attr_map):
                     "value_var": value_var,
                     "c": conv_name,
                 }
+
     else:
         # Not frozen.
         def fmt_setter(attr_name, value):
@@ -1259,12 +1440,13 @@ def _attrs_to_init_script(attrs, frozen, slots, post_init, super_attr_map):
             }
 
     args = []
+    kw_only_args = []
     attrs_to_validate = []
 
     # This is a dictionary of names to validator and converter callables.
     # Injecting this into __init__ globals lets us avoid lookups.
     names_for_globals = {}
-    annotations = {'return': None}
+    annotations = {"return": None}
 
     for a in attrs:
         if a.validator:
@@ -1280,78 +1462,104 @@ def _attrs_to_init_script(attrs, frozen, slots, post_init, super_attr_map):
             if has_factory:
                 init_factory_name = _init_factory_pat.format(a.name)
                 if a.converter is not None:
-                    lines.append(fmt_setter_with_converter(
-                        attr_name,
-                        init_factory_name + "({0})".format(maybe_self)))
+                    lines.append(
+                        fmt_setter_with_converter(
+                            attr_name,
+                            init_factory_name + "({0})".format(maybe_self),
+                        )
+                    )
                     conv_name = _init_converter_pat.format(a.name)
                     names_for_globals[conv_name] = a.converter
                 else:
-                    lines.append(fmt_setter(
-                        attr_name,
-                        init_factory_name + "({0})".format(maybe_self)
-                    ))
+                    lines.append(
+                        fmt_setter(
+                            attr_name,
+                            init_factory_name + "({0})".format(maybe_self),
+                        )
+                    )
                 names_for_globals[init_factory_name] = a.default.factory
             else:
                 if a.converter is not None:
-                    lines.append(fmt_setter_with_converter(
-                        attr_name,
-                        "attr_dict['{attr_name}'].default"
-                        .format(attr_name=attr_name)
-                    ))
+                    lines.append(
+                        fmt_setter_with_converter(
+                            attr_name,
+                            "attr_dict['{attr_name}'].default".format(
+                                attr_name=attr_name
+                            ),
+                        )
+                    )
                     conv_name = _init_converter_pat.format(a.name)
                     names_for_globals[conv_name] = a.converter
                 else:
-                    lines.append(fmt_setter(
-                        attr_name,
-                        "attr_dict['{attr_name}'].default"
-                        .format(attr_name=attr_name)
-                    ))
+                    lines.append(
+                        fmt_setter(
+                            attr_name,
+                            "attr_dict['{attr_name}'].default".format(
+                                attr_name=attr_name
+                            ),
+                        )
+                    )
         elif a.default is not NOTHING and not has_factory:
-            args.append(
-                "{arg_name}=attr_dict['{attr_name}'].default".format(
-                    arg_name=arg_name,
-                    attr_name=attr_name,
-                )
+            arg = "{arg_name}=attr_dict['{attr_name}'].default".format(
+                arg_name=arg_name, attr_name=attr_name
             )
+            if a.kw_only:
+                kw_only_args.append(arg)
+            else:
+                args.append(arg)
             if a.converter is not None:
                 lines.append(fmt_setter_with_converter(attr_name, arg_name))
-                names_for_globals[_init_converter_pat.format(a.name)] = (
-                    a.converter
-                )
+                names_for_globals[
+                    _init_converter_pat.format(a.name)
+                ] = a.converter
             else:
                 lines.append(fmt_setter(attr_name, arg_name))
         elif has_factory:
-            args.append("{arg_name}=NOTHING".format(arg_name=arg_name))
-            lines.append("if {arg_name} is not NOTHING:"
-                         .format(arg_name=arg_name))
+            arg = "{arg_name}=NOTHING".format(arg_name=arg_name)
+            if a.kw_only:
+                kw_only_args.append(arg)
+            else:
+                args.append(arg)
+            lines.append(
+                "if {arg_name} is not NOTHING:".format(arg_name=arg_name)
+            )
             init_factory_name = _init_factory_pat.format(a.name)
             if a.converter is not None:
-                lines.append("    " + fmt_setter_with_converter(
-                    attr_name, arg_name
-                ))
+                lines.append(
+                    "    " + fmt_setter_with_converter(attr_name, arg_name)
+                )
                 lines.append("else:")
-                lines.append("    " + fmt_setter_with_converter(
-                    attr_name,
-                    init_factory_name + "({0})".format(maybe_self)
-                ))
-                names_for_globals[_init_converter_pat.format(a.name)] = (
-                    a.converter
+                lines.append(
+                    "    "
+                    + fmt_setter_with_converter(
+                        attr_name,
+                        init_factory_name + "({0})".format(maybe_self),
+                    )
                 )
+                names_for_globals[
+                    _init_converter_pat.format(a.name)
+                ] = a.converter
             else:
                 lines.append("    " + fmt_setter(attr_name, arg_name))
                 lines.append("else:")
-                lines.append("    " + fmt_setter(
-                    attr_name,
-                    init_factory_name + "({0})".format(maybe_self)
-                ))
+                lines.append(
+                    "    "
+                    + fmt_setter(
+                        attr_name,
+                        init_factory_name + "({0})".format(maybe_self),
+                    )
+                )
             names_for_globals[init_factory_name] = a.default.factory
         else:
-            args.append(arg_name)
+            if a.kw_only:
+                kw_only_args.append(arg_name)
+            else:
+                args.append(arg_name)
             if a.converter is not None:
                 lines.append(fmt_setter_with_converter(attr_name, arg_name))
-                names_for_globals[_init_converter_pat.format(a.name)] = (
-                    a.converter
-                )
+                names_for_globals[
+                    _init_converter_pat.format(a.name)
+                ] = a.converter
             else:
                 lines.append(fmt_setter(attr_name, arg_name))
 
@@ -1364,20 +1572,52 @@ def _attrs_to_init_script(attrs, frozen, slots, post_init, super_attr_map):
         for a in attrs_to_validate:
             val_name = "__attr_validator_{}".format(a.name)
             attr_name = "__attr_{}".format(a.name)
-            lines.append("    {}(self, {}, self.{})".format(
-                val_name, attr_name, a.name))
+            lines.append(
+                "    {}(self, {}, self.{})".format(val_name, attr_name, a.name)
+            )
             names_for_globals[val_name] = a.validator
             names_for_globals[attr_name] = a
     if post_init:
         lines.append("self.__attrs_post_init__()")
 
-    return """\
+    # because this is set only after __attrs_post_init is called, a crash
+    # will result if post-init tries to access the hash code.  This seemed
+    # preferable to setting this beforehand, in which case alteration to
+    # field values during post-init combined with post-init accessing the
+    # hash code would result in silent bugs.
+    if cache_hash:
+        if frozen:
+            if slots:
+                # if frozen and slots, then _setattr defined above
+                init_hash_cache = "_setattr('%s', %s)"
+            else:
+                # if frozen and not slots, then _inst_dict defined above
+                init_hash_cache = "_inst_dict['%s'] = %s"
+        else:
+            init_hash_cache = "self.%s = %s"
+        lines.append(init_hash_cache % (_hash_cache_field, "None"))
+
+    args = ", ".join(args)
+    if kw_only_args:
+        if PY2:
+            raise PythonTooOldError(
+                "Keyword-only arguments only work on Python 3 and later."
+            )
+
+        args += "{leading_comma}*, {kw_only_args}".format(
+            leading_comma=", " if args else "",
+            kw_only_args=", ".join(kw_only_args),
+        )
+    return (
+        """\
 def __init__(self, {args}):
     {lines}
 """.format(
-        args=", ".join(args),
-        lines="\n    ".join(lines) if lines else "pass",
-    ), names_for_globals, annotations
+            args=args, lines="\n    ".join(lines) if lines else "pass"
+        ),
+        names_for_globals,
+        annotations,
+    )
 
 
 class Attribute(object):
@@ -1390,13 +1630,36 @@ class Attribute(object):
 
     For the version history of the fields, see :func:`attr.ib`.
     """
+
     __slots__ = (
-        "name", "default", "validator", "repr", "cmp", "hash", "init",
-        "metadata", "type", "converter",
+        "name",
+        "default",
+        "validator",
+        "repr",
+        "cmp",
+        "hash",
+        "init",
+        "metadata",
+        "type",
+        "converter",
+        "kw_only",
     )
 
-    def __init__(self, name, default, validator, repr, cmp, hash, init,
-                 convert=None, metadata=None, type=None, converter=None):
+    def __init__(
+        self,
+        name,
+        default,
+        validator,
+        repr,
+        cmp,
+        hash,
+        init,
+        convert=None,
+        metadata=None,
+        type=None,
+        converter=None,
+        kw_only=False,
+    ):
         # Cache this descriptor here to speed things up later.
         bound_setattr = _obj_setattr.__get__(self, Attribute)
 
@@ -1411,7 +1674,8 @@ class Attribute(object):
             warnings.warn(
                 "The `convert` argument is deprecated in favor of `converter`."
                 "  It will be removed after 2019/01.",
-                DeprecationWarning, stacklevel=2
+                DeprecationWarning,
+                stacklevel=2,
             )
             converter = convert
 
@@ -1423,11 +1687,16 @@ class Attribute(object):
         bound_setattr("hash", hash)
         bound_setattr("init", init)
         bound_setattr("converter", converter)
-        bound_setattr("metadata", (
-            metadata_proxy(metadata) if metadata
-            else _empty_metadata_singleton
-        ))
+        bound_setattr(
+            "metadata",
+            (
+                metadata_proxy(metadata)
+                if metadata
+                else _empty_metadata_singleton
+            ),
+        )
         bound_setattr("type", type)
+        bound_setattr("kw_only", kw_only)
 
     def __setattr__(self, name, value):
         raise FrozenInstanceError()
@@ -1437,7 +1706,8 @@ class Attribute(object):
         warnings.warn(
             "The `convert` attribute is deprecated in favor of `converter`.  "
             "It will be removed after 2019/01.",
-            DeprecationWarning, stacklevel=2,
+            DeprecationWarning,
+            stacklevel=2,
         )
         return self.converter
 
@@ -1452,49 +1722,82 @@ class Attribute(object):
             )
         inst_dict = {
             k: getattr(ca, k)
-            for k
-            in Attribute.__slots__
-            if k not in (
-                "name", "validator", "default", "type", "convert",
+            for k in Attribute.__slots__
+            if k
+            not in (
+                "name",
+                "validator",
+                "default",
+                "type",
+                "convert",
             )  # exclude methods and deprecated alias
         }
         return cls(
-            name=name, validator=ca._validator, default=ca._default, type=type,
+            name=name,
+            validator=ca._validator,
+            default=ca._default,
+            type=type,
             **inst_dict
         )
 
+    # Don't use attr.assoc since fields(Attribute) doesn't work
+    def _assoc(self, **changes):
+        """
+        Copy *self* and apply *changes*.
+        """
+        new = copy.copy(self)
+
+        new._setattrs(changes.items())
+
+        return new
+
     # Don't use _add_pickle since fields(Attribute) doesn't work
     def __getstate__(self):
         """
         Play nice with pickle.
         """
-        return tuple(getattr(self, name) if name != "metadata"
-                     else dict(self.metadata)
-                     for name in self.__slots__)
+        return tuple(
+            getattr(self, name) if name != "metadata" else dict(self.metadata)
+            for name in self.__slots__
+        )
 
     def __setstate__(self, state):
         """
         Play nice with pickle.
         """
+        self._setattrs(zip(self.__slots__, state))
+
+    def _setattrs(self, name_values_pairs):
         bound_setattr = _obj_setattr.__get__(self, Attribute)
-        for name, value in zip(self.__slots__, state):
+        for name, value in name_values_pairs:
             if name != "metadata":
                 bound_setattr(name, value)
             else:
-                bound_setattr(name, metadata_proxy(value) if value else
-                              _empty_metadata_singleton)
+                bound_setattr(
+                    name,
+                    metadata_proxy(value)
+                    if value
+                    else _empty_metadata_singleton,
+                )
 
 
 _a = [
-    Attribute(name=name, default=NOTHING, validator=None,
-              repr=True, cmp=True, hash=(name != "metadata"), init=True)
+    Attribute(
+        name=name,
+        default=NOTHING,
+        validator=None,
+        repr=True,
+        cmp=True,
+        hash=(name != "metadata"),
+        init=True,
+    )
     for name in Attribute.__slots__
     if name != "convert"  # XXX: remove once `convert` is gone
 ]
 
 Attribute = _add_hash(
     _add_cmp(_add_repr(Attribute, attrs=_a), attrs=_a),
-    attrs=[a for a in _a if a.hash]
+    attrs=[a for a in _a if a.hash],
 )
 
 
@@ -1506,21 +1809,59 @@ class _CountingAttr(object):
     *Internal* data structure of the attrs library.  Running into is most
     likely the result of a bug like a forgotten `@attr.s` decorator.
     """
-    __slots__ = ("counter", "_default", "repr", "cmp", "hash", "init",
-                 "metadata", "_validator", "converter", "type")
+
+    __slots__ = (
+        "counter",
+        "_default",
+        "repr",
+        "cmp",
+        "hash",
+        "init",
+        "metadata",
+        "_validator",
+        "converter",
+        "type",
+        "kw_only",
+    )
     __attrs_attrs__ = tuple(
-        Attribute(name=name, default=NOTHING, validator=None,
-                  repr=True, cmp=True, hash=True, init=True)
-        for name
-        in ("counter", "_default", "repr", "cmp", "hash", "init",)
+        Attribute(
+            name=name,
+            default=NOTHING,
+            validator=None,
+            repr=True,
+            cmp=True,
+            hash=True,
+            init=True,
+            kw_only=False,
+        )
+        for name in ("counter", "_default", "repr", "cmp", "hash", "init")
     ) + (
-        Attribute(name="metadata", default=None, validator=None,
-                  repr=True, cmp=True, hash=False, init=True),
+        Attribute(
+            name="metadata",
+            default=None,
+            validator=None,
+            repr=True,
+            cmp=True,
+            hash=False,
+            init=True,
+            kw_only=False,
+        ),
     )
     cls_counter = 0
 
-    def __init__(self, default, validator, repr, cmp, hash, init, converter,
-                 metadata, type):
+    def __init__(
+        self,
+        default,
+        validator,
+        repr,
+        cmp,
+        hash,
+        init,
+        converter,
+        metadata,
+        type,
+        kw_only,
+    ):
         _CountingAttr.cls_counter += 1
         self.counter = _CountingAttr.cls_counter
         self._default = default
@@ -1536,6 +1877,7 @@ class _CountingAttr(object):
         self.converter = converter
         self.metadata = metadata
         self.type = type
+        self.kw_only = kw_only
 
     def validator(self, meth):
         """
@@ -1587,6 +1929,7 @@ class Factory(object):
 
     .. versionadded:: 17.1.0  *takes_self*
     """
+
     factory = attrib()
     takes_self = attrib()
 
@@ -1636,7 +1979,7 @@ def make_class(name, attrs, bases=(object,), **attributes_arguments):
     type_ = type(
         name,
         bases,
-        {} if post_init is None else {"__attrs_post_init__": post_init}
+        {} if post_init is None else {"__attrs_post_init__": post_init},
     )
     # For pickling to work, the __module__ variable needs to be set to the
     # frame where the class is created.  Bypass this step in environments where
@@ -1644,7 +1987,7 @@ def make_class(name, attrs, bases=(object,), **attributes_arguments):
     # defined for arguments greater than 0 (IronPython).
     try:
         type_.__module__ = sys._getframe(1).f_globals.get(
-            "__name__", "__main__",
+            "__name__", "__main__"
         )
     except (AttributeError, ValueError):
         pass
@@ -1661,6 +2004,7 @@ class _AndValidator(object):
     """
     Compose many validators to a single one.
     """
+
     _validators = attrib()
 
     def __call__(self, inst, attr, value):
@@ -1682,7 +2026,8 @@ def and_(*validators):
     vals = []
     for validator in validators:
         vals.extend(
-            validator._validators if isinstance(validator, _AndValidator)
+            validator._validators
+            if isinstance(validator, _AndValidator)
             else [validator]
         )
 
diff --git a/pipenv/vendor/attr/converters.py b/pipenv/vendor/attr/converters.py
index 3b3bac92..37c4a07a 100644
--- a/pipenv/vendor/attr/converters.py
+++ b/pipenv/vendor/attr/converters.py
@@ -4,6 +4,8 @@ Commonly useful converters.
 
 from __future__ import absolute_import, division, print_function
 
+from ._make import NOTHING, Factory
+
 
 def optional(converter):
     """
@@ -13,7 +15,7 @@ def optional(converter):
     :param callable converter: the converter that is used for non-``None``
         values.
 
-    ..  versionadded:: 17.1.0
+    .. versionadded:: 17.1.0
     """
 
     def optional_converter(val):
@@ -22,3 +24,55 @@ def optional(converter):
         return converter(val)
 
     return optional_converter
+
+
+def default_if_none(default=NOTHING, factory=None):
+    """
+    A converter that allows to replace ``None`` values by *default* or the
+    result of *factory*.
+
+    :param default: Value to be used if ``None`` is passed. Passing an instance
+       of :class:`attr.Factory` is supported, however the ``takes_self`` option
+       is *not*.
+    :param callable factory: A callable that takes not parameters whose result
+       is used if ``None`` is passed.
+
+    :raises TypeError: If **neither** *default* or *factory* is passed.
+    :raises TypeError: If **both** *default* and *factory* are passed.
+    :raises ValueError: If an instance of :class:`attr.Factory` is passed with
+       ``takes_self=True``.
+
+    .. versionadded:: 18.2.0
+    """
+    if default is NOTHING and factory is None:
+        raise TypeError("Must pass either `default` or `factory`.")
+
+    if default is not NOTHING and factory is not None:
+        raise TypeError(
+            "Must pass either `default` or `factory` but not both."
+        )
+
+    if factory is not None:
+        default = Factory(factory)
+
+    if isinstance(default, Factory):
+        if default.takes_self:
+            raise ValueError(
+                "`takes_self` is not supported by default_if_none."
+            )
+
+        def default_if_none_converter(val):
+            if val is not None:
+                return val
+
+            return default.factory()
+
+    else:
+
+        def default_if_none_converter(val):
+            if val is not None:
+                return val
+
+            return default
+
+    return default_if_none_converter
diff --git a/pipenv/vendor/attr/converters.pyi b/pipenv/vendor/attr/converters.pyi
new file mode 100644
index 00000000..63b2a386
--- /dev/null
+++ b/pipenv/vendor/attr/converters.pyi
@@ -0,0 +1,12 @@
+from typing import TypeVar, Optional, Callable, overload
+from . import _ConverterType
+
+_T = TypeVar("_T")
+
+def optional(
+    converter: _ConverterType[_T]
+) -> _ConverterType[Optional[_T]]: ...
+@overload
+def default_if_none(default: _T) -> _ConverterType[_T]: ...
+@overload
+def default_if_none(*, factory: Callable[[], _T]) -> _ConverterType[_T]: ...
diff --git a/pipenv/vendor/attr/exceptions.py b/pipenv/vendor/attr/exceptions.py
index f949f3c9..b12e41e9 100644
--- a/pipenv/vendor/attr/exceptions.py
+++ b/pipenv/vendor/attr/exceptions.py
@@ -10,6 +10,7 @@ class FrozenInstanceError(AttributeError):
 
     .. versionadded:: 16.1.0
     """
+
     msg = "can't set attribute"
     args = [msg]
 
@@ -46,3 +47,11 @@ class UnannotatedAttributeError(RuntimeError):
 
     .. versionadded:: 17.3.0
     """
+
+
+class PythonTooOldError(RuntimeError):
+    """
+    An ``attrs`` feature requiring a more recent python version has been used.
+
+    .. versionadded:: 18.2.0
+    """
diff --git a/pipenv/vendor/attr/exceptions.pyi b/pipenv/vendor/attr/exceptions.pyi
new file mode 100644
index 00000000..48fffcc1
--- /dev/null
+++ b/pipenv/vendor/attr/exceptions.pyi
@@ -0,0 +1,7 @@
+class FrozenInstanceError(AttributeError):
+    msg: str = ...
+
+class AttrsAttributeNotFoundError(ValueError): ...
+class NotAnAttrsClassError(ValueError): ...
+class DefaultAlreadySetError(RuntimeError): ...
+class UnannotatedAttributeError(RuntimeError): ...
diff --git a/pipenv/vendor/attr/filters.pyi b/pipenv/vendor/attr/filters.pyi
new file mode 100644
index 00000000..a618140c
--- /dev/null
+++ b/pipenv/vendor/attr/filters.pyi
@@ -0,0 +1,5 @@
+from typing import Union
+from . import Attribute, _FilterType
+
+def include(*what: Union[type, Attribute]) -> _FilterType: ...
+def exclude(*what: Union[type, Attribute]) -> _FilterType: ...
diff --git a/pipenv/vendor/attr/py.typed b/pipenv/vendor/attr/py.typed
new file mode 100644
index 00000000..e69de29b
diff --git a/pipenv/vendor/attr/validators.py b/pipenv/vendor/attr/validators.py
index f8892fcd..f12d0aa5 100644
--- a/pipenv/vendor/attr/validators.py
+++ b/pipenv/vendor/attr/validators.py
@@ -7,13 +7,7 @@ from __future__ import absolute_import, division, print_function
 from ._make import _AndValidator, and_, attrib, attrs
 
 
-__all__ = [
-    "and_",
-    "in_",
-    "instance_of",
-    "optional",
-    "provides",
-]
+__all__ = ["and_", "in_", "instance_of", "optional", "provides"]
 
 
 @attrs(repr=False, slots=True, hash=True)
@@ -27,16 +21,20 @@ class _InstanceOfValidator(object):
         if not isinstance(value, self.type):
             raise TypeError(
                 "'{name}' must be {type!r} (got {value!r} that is a "
-                "{actual!r})."
-                .format(name=attr.name, type=self.type,
-                        actual=value.__class__, value=value),
-                attr, self.type, value,
+                "{actual!r}).".format(
+                    name=attr.name,
+                    type=self.type,
+                    actual=value.__class__,
+                    value=value,
+                ),
+                attr,
+                self.type,
+                value,
             )
 
     def __repr__(self):
-        return (
-            "<instance_of validator for type {type!r}>"
-            .format(type=self.type)
+        return "<instance_of validator for type {type!r}>".format(
+            type=self.type
         )
 
 
@@ -67,15 +65,17 @@ class _ProvidesValidator(object):
         if not self.interface.providedBy(value):
             raise TypeError(
                 "'{name}' must provide {interface!r} which {value!r} "
-                "doesn't."
-                .format(name=attr.name, interface=self.interface, value=value),
-                attr, self.interface, value,
+                "doesn't.".format(
+                    name=attr.name, interface=self.interface, value=value
+                ),
+                attr,
+                self.interface,
+                value,
             )
 
     def __repr__(self):
-        return (
-            "<provides validator for interface {interface!r}>"
-            .format(interface=self.interface)
+        return "<provides validator for interface {interface!r}>".format(
+            interface=self.interface
         )
 
 
@@ -106,9 +106,8 @@ class _OptionalValidator(object):
         self.validator(inst, attr, value)
 
     def __repr__(self):
-        return (
-            "<optional validator for {what} or None>"
-            .format(what=repr(self.validator))
+        return "<optional validator for {what} or None>".format(
+            what=repr(self.validator)
         )
 
 
@@ -135,16 +134,21 @@ class _InValidator(object):
     options = attrib()
 
     def __call__(self, inst, attr, value):
-        if value not in self.options:
+        try:
+            in_options = value in self.options
+        except TypeError as e:  # e.g. `1 in "abc"`
+            in_options = False
+
+        if not in_options:
             raise ValueError(
-                "'{name}' must be in {options!r} (got {value!r})"
-                .format(name=attr.name, options=self.options, value=value)
+                "'{name}' must be in {options!r} (got {value!r})".format(
+                    name=attr.name, options=self.options, value=value
+                )
             )
 
     def __repr__(self):
-        return (
-            "<in_ validator with options {options!r}>"
-            .format(options=self.options)
+        return "<in_ validator with options {options!r}>".format(
+            options=self.options
         )
 
 
diff --git a/pipenv/vendor/attr/validators.pyi b/pipenv/vendor/attr/validators.pyi
new file mode 100644
index 00000000..abbaedf1
--- /dev/null
+++ b/pipenv/vendor/attr/validators.pyi
@@ -0,0 +1,14 @@
+from typing import Container, List, Union, TypeVar, Type, Any, Optional, Tuple
+from . import _ValidatorType
+
+_T = TypeVar("_T")
+
+def instance_of(
+    type: Union[Tuple[Type[_T], ...], Type[_T]]
+) -> _ValidatorType[_T]: ...
+def provides(interface: Any) -> _ValidatorType[Any]: ...
+def optional(
+    validator: Union[_ValidatorType[_T], List[_ValidatorType[_T]]]
+) -> _ValidatorType[Optional[_T]]: ...
+def in_(options: Container[_T]) -> _ValidatorType[_T]: ...
+def and_(*validators: _ValidatorType[_T]) -> _ValidatorType[_T]: ...
diff --git a/pipenv/vendor/click/LICENSE b/pipenv/vendor/click/LICENSE
deleted file mode 100644
index 1704daa2..00000000
--- a/pipenv/vendor/click/LICENSE
+++ /dev/null
@@ -1,38 +0,0 @@
-Copyright (c) 2014 by Armin Ronacher.
-
-Click uses parts of optparse written by Gregory P. Ward and maintained by the
-Python software foundation.  This is limited to code in the parser.py
-module:
-
-Copyright (c) 2001-2006 Gregory P. Ward.  All rights reserved.
-Copyright (c) 2002-2006 Python Software Foundation.  All rights reserved.
-
-Some rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are
-met:
-
-    * Redistributions of source code must retain the above copyright
-      notice, this list of conditions and the following disclaimer.
-
-    * Redistributions in binary form must reproduce the above
-      copyright notice, this list of conditions and the following
-      disclaimer in the documentation and/or other materials provided
-      with the distribution.
-
-    * The names of the contributors may not be used to endorse or
-      promote products derived from this software without specific
-      prior written permission.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/pipenv/vendor/click/LICENSE.rst b/pipenv/vendor/click/LICENSE.rst
new file mode 100644
index 00000000..87ce152a
--- /dev/null
+++ b/pipenv/vendor/click/LICENSE.rst
@@ -0,0 +1,39 @@
+Copyright  2014 by the Pallets team.
+
+Some rights reserved.
+
+Redistribution and use in source and binary forms of the software as
+well as documentation, with or without modification, are permitted
+provided that the following conditions are met:
+
+-   Redistributions of source code must retain the above copyright
+    notice, this list of conditions and the following disclaimer.
+
+-   Redistributions in binary form must reproduce the above copyright
+    notice, this list of conditions and the following disclaimer in the
+    documentation and/or other materials provided with the distribution.
+
+-   Neither the name of the copyright holder nor the names of its
+    contributors may be used to endorse or promote products derived from
+    this software without specific prior written permission.
+
+THIS SOFTWARE AND DOCUMENTATION IS PROVIDED BY THE COPYRIGHT HOLDERS AND
+CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING,
+BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
+FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
+COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
+INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
+USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
+ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
+THIS SOFTWARE AND DOCUMENTATION, EVEN IF ADVISED OF THE POSSIBILITY OF
+SUCH DAMAGE.
+
+----
+
+Click uses parts of optparse written by Gregory P. Ward and maintained
+by the Python Software Foundation. This is limited to code in parser.py.
+
+Copyright  2001-2006 Gregory P. Ward. All rights reserved.
+Copyright  2002-2006 Python Software Foundation. All rights reserved.
diff --git a/pipenv/vendor/click/__init__.py b/pipenv/vendor/click/__init__.py
index 971e55d0..d3c33660 100644
--- a/pipenv/vendor/click/__init__.py
+++ b/pipenv/vendor/click/__init__.py
@@ -1,17 +1,15 @@
 # -*- coding: utf-8 -*-
 """
-    click
-    ~~~~~
+click
+~~~~~
 
-    Click is a simple Python module that wraps the stdlib's optparse to make
-    writing command line scripts fun.  Unlike other modules, it's based around
-    a simple API that does not come with too much magic and is composable.
+Click is a simple Python module inspired by the stdlib optparse to make
+writing command line scripts fun. Unlike other modules, it's based
+around a simple API that does not come with too much magic and is
+composable.
 
-    In case optparse ever gets removed from the stdlib, it will be shipped by
-    this module.
-
-    :copyright: (c) 2014 by Armin Ronacher.
-    :license: BSD, see LICENSE for more details.
+:copyright:  2014 by the Pallets team.
+:license: BSD, see LICENSE.rst for more details.
 """
 
 # Core classes
@@ -28,7 +26,7 @@ from .decorators import pass_context, pass_obj, make_pass_decorator, \
 
 # Types
 from .types import ParamType, File, Path, Choice, IntRange, Tuple, \
-     STRING, INT, FLOAT, BOOL, UUID, UNPROCESSED
+     DateTime, STRING, INT, FLOAT, BOOL, UUID, UNPROCESSED, FloatRange
 
 # Utilities
 from .utils import echo, get_binary_stream, get_text_stream, open_file, \
@@ -65,8 +63,9 @@ __all__ = [
     'version_option', 'help_option',
 
     # Types
-    'ParamType', 'File', 'Path', 'Choice', 'IntRange', 'Tuple', 'STRING',
-    'INT', 'FLOAT', 'BOOL', 'UUID', 'UNPROCESSED',
+    'ParamType', 'File', 'Path', 'Choice', 'IntRange', 'Tuple',
+    'DateTime', 'STRING', 'INT', 'FLOAT', 'BOOL', 'UUID', 'UNPROCESSED',
+    'FloatRange',
 
     # Utilities
     'echo', 'get_binary_stream', 'get_text_stream', 'open_file',
@@ -95,4 +94,4 @@ __all__ = [
 disable_unicode_literals_warning = False
 
 
-__version__ = '6.7'
+__version__ = '7.0'
diff --git a/pipenv/vendor/click/_bashcomplete.py b/pipenv/vendor/click/_bashcomplete.py
index d9d26d28..a5f1084c 100644
--- a/pipenv/vendor/click/_bashcomplete.py
+++ b/pipenv/vendor/click/_bashcomplete.py
@@ -1,27 +1,81 @@
+import copy
 import os
 import re
+
 from .utils import echo
 from .parser import split_arg_string
-from .core import MultiCommand, Option
+from .core import MultiCommand, Option, Argument
+from .types import Choice
+
+try:
+    from collections import abc
+except ImportError:
+    import collections as abc
 
+WORDBREAK = '='
 
-COMPLETION_SCRIPT = '''
+# Note, only BASH version 4.4 and later have the nosort option.
+COMPLETION_SCRIPT_BASH = '''
 %(complete_func)s() {
+    local IFS=$'\n'
     COMPREPLY=( $( env COMP_WORDS="${COMP_WORDS[*]}" \\
                    COMP_CWORD=$COMP_CWORD \\
                    %(autocomplete_var)s=complete $1 ) )
     return 0
 }
 
-complete -F %(complete_func)s -o default %(script_names)s
+%(complete_func)setup() {
+    local COMPLETION_OPTIONS=""
+    local BASH_VERSION_ARR=(${BASH_VERSION//./ })
+    # Only BASH version 4.4 and later have the nosort option.
+    if [ ${BASH_VERSION_ARR[0]} -gt 4 ] || ([ ${BASH_VERSION_ARR[0]} -eq 4 ] && [ ${BASH_VERSION_ARR[1]} -ge 4 ]); then
+        COMPLETION_OPTIONS="-o nosort"
+    fi
+
+    complete $COMPLETION_OPTIONS -F %(complete_func)s %(script_names)s
+}
+
+%(complete_func)setup
+'''
+
+COMPLETION_SCRIPT_ZSH = '''
+%(complete_func)s() {
+    local -a completions
+    local -a completions_with_descriptions
+    local -a response
+    response=("${(@f)$( env COMP_WORDS=\"${words[*]}\" \\
+                        COMP_CWORD=$((CURRENT-1)) \\
+                        %(autocomplete_var)s=\"complete_zsh\" \\
+                        %(script_names)s )}")
+
+    for key descr in ${(kv)response}; do
+      if [[ "$descr" == "_" ]]; then
+          completions+=("$key")
+      else
+          completions_with_descriptions+=("$key":"$descr")
+      fi
+    done
+
+    if [ -n "$completions_with_descriptions" ]; then
+        _describe -V unsorted completions_with_descriptions -U -Q
+    fi
+
+    if [ -n "$completions" ]; then
+        compadd -U -V unsorted -Q -a completions
+    fi
+    compstate[insert]="automenu"
+}
+
+compdef %(complete_func)s %(script_names)s
 '''
 
 _invalid_ident_char_re = re.compile(r'[^a-zA-Z0-9_]')
 
 
-def get_completion_script(prog_name, complete_var):
+def get_completion_script(prog_name, complete_var, shell):
     cf_name = _invalid_ident_char_re.sub('', prog_name.replace('-', '_'))
-    return (COMPLETION_SCRIPT % {
+    script = COMPLETION_SCRIPT_ZSH if shell == 'zsh' else COMPLETION_SCRIPT_BASH
+    return (script % {
         'complete_func': '_%s_completion' % cf_name,
         'script_names': prog_name,
         'autocomplete_var': complete_var,
@@ -29,37 +83,189 @@ def get_completion_script(prog_name, complete_var):
 
 
 def resolve_ctx(cli, prog_name, args):
+    """
+    Parse into a hierarchy of contexts. Contexts are connected through the parent variable.
+    :param cli: command definition
+    :param prog_name: the program that is running
+    :param args: full list of args
+    :return: the final context/command parsed
+    """
     ctx = cli.make_context(prog_name, args, resilient_parsing=True)
-    while ctx.protected_args + ctx.args and isinstance(ctx.command, MultiCommand):
-        a = ctx.protected_args + ctx.args
-        cmd = ctx.command.get_command(ctx, a[0])
-        if cmd is None:
-            return None
-        ctx = cmd.make_context(a[0], a[1:], parent=ctx, resilient_parsing=True)
+    args = ctx.protected_args + ctx.args
+    while args:
+        if isinstance(ctx.command, MultiCommand):
+            if not ctx.command.chain:
+                cmd_name, cmd, args = ctx.command.resolve_command(ctx, args)
+                if cmd is None:
+                    return ctx
+                ctx = cmd.make_context(cmd_name, args, parent=ctx,
+                                       resilient_parsing=True)
+                args = ctx.protected_args + ctx.args
+            else:
+                # Walk chained subcommand contexts saving the last one.
+                while args:
+                    cmd_name, cmd, args = ctx.command.resolve_command(ctx, args)
+                    if cmd is None:
+                        return ctx
+                    sub_ctx = cmd.make_context(cmd_name, args, parent=ctx,
+                                               allow_extra_args=True,
+                                               allow_interspersed_args=False,
+                                               resilient_parsing=True)
+                    args = sub_ctx.args
+                ctx = sub_ctx
+                args = sub_ctx.protected_args + sub_ctx.args
+        else:
+            break
     return ctx
 
 
+def start_of_option(param_str):
+    """
+    :param param_str: param_str to check
+    :return: whether or not this is the start of an option declaration (i.e. starts "-" or "--")
+    """
+    return param_str and param_str[:1] == '-'
+
+
+def is_incomplete_option(all_args, cmd_param):
+    """
+    :param all_args: the full original list of args supplied
+    :param cmd_param: the current command paramter
+    :return: whether or not the last option declaration (i.e. starts "-" or "--") is incomplete and
+    corresponds to this cmd_param. In other words whether this cmd_param option can still accept
+    values
+    """
+    if not isinstance(cmd_param, Option):
+        return False
+    if cmd_param.is_flag:
+        return False
+    last_option = None
+    for index, arg_str in enumerate(reversed([arg for arg in all_args if arg != WORDBREAK])):
+        if index + 1 > cmd_param.nargs:
+            break
+        if start_of_option(arg_str):
+            last_option = arg_str
+
+    return True if last_option and last_option in cmd_param.opts else False
+
+
+def is_incomplete_argument(current_params, cmd_param):
+    """
+    :param current_params: the current params and values for this argument as already entered
+    :param cmd_param: the current command parameter
+    :return: whether or not the last argument is incomplete and corresponds to this cmd_param. In
+    other words whether or not the this cmd_param argument can still accept values
+    """
+    if not isinstance(cmd_param, Argument):
+        return False
+    current_param_values = current_params[cmd_param.name]
+    if current_param_values is None:
+        return True
+    if cmd_param.nargs == -1:
+        return True
+    if isinstance(current_param_values, abc.Iterable) \
+            and cmd_param.nargs > 1 and len(current_param_values) < cmd_param.nargs:
+        return True
+    return False
+
+
+def get_user_autocompletions(ctx, args, incomplete, cmd_param):
+    """
+    :param ctx: context associated with the parsed command
+    :param args: full list of args
+    :param incomplete: the incomplete text to autocomplete
+    :param cmd_param: command definition
+    :return: all the possible user-specified completions for the param
+    """
+    results = []
+    if isinstance(cmd_param.type, Choice):
+        # Choices don't support descriptions.
+        results = [(c, None)
+                   for c in cmd_param.type.choices if str(c).startswith(incomplete)]
+    elif cmd_param.autocompletion is not None:
+        dynamic_completions = cmd_param.autocompletion(ctx=ctx,
+                                                       args=args,
+                                                       incomplete=incomplete)
+        results = [c if isinstance(c, tuple) else (c, None)
+                   for c in dynamic_completions]
+    return results
+
+
+def get_visible_commands_starting_with(ctx, starts_with):
+    """
+    :param ctx: context associated with the parsed command
+    :starts_with: string that visible commands must start with.
+    :return: all visible (not hidden) commands that start with starts_with.
+    """
+    for c in ctx.command.list_commands(ctx):
+        if c.startswith(starts_with):
+            command = ctx.command.get_command(ctx, c)
+            if not command.hidden:
+                yield command
+
+
+def add_subcommand_completions(ctx, incomplete, completions_out):
+    # Add subcommand completions.
+    if isinstance(ctx.command, MultiCommand):
+        completions_out.extend(
+            [(c.name, c.get_short_help_str()) for c in get_visible_commands_starting_with(ctx, incomplete)])
+
+    # Walk up the context list and add any other completion possibilities from chained commands
+    while ctx.parent is not None:
+        ctx = ctx.parent
+        if isinstance(ctx.command, MultiCommand) and ctx.command.chain:
+            remaining_commands = [c for c in get_visible_commands_starting_with(ctx, incomplete)
+                                  if c.name not in ctx.protected_args]
+            completions_out.extend([(c.name, c.get_short_help_str()) for c in remaining_commands])
+
+
 def get_choices(cli, prog_name, args, incomplete):
+    """
+    :param cli: command definition
+    :param prog_name: the program that is running
+    :param args: full list of args
+    :param incomplete: the incomplete text to autocomplete
+    :return: all the possible completions for the incomplete
+    """
+    all_args = copy.deepcopy(args)
+
     ctx = resolve_ctx(cli, prog_name, args)
     if ctx is None:
-        return
+        return []
+
+    # In newer versions of bash long opts with '='s are partitioned, but it's easier to parse
+    # without the '='
+    if start_of_option(incomplete) and WORDBREAK in incomplete:
+        partition_incomplete = incomplete.partition(WORDBREAK)
+        all_args.append(partition_incomplete[0])
+        incomplete = partition_incomplete[2]
+    elif incomplete == WORDBREAK:
+        incomplete = ''
 
-    choices = []
-    if incomplete and not incomplete[:1].isalnum():
+    completions = []
+    if start_of_option(incomplete):
+        # completions for partial options
         for param in ctx.command.params:
-            if not isinstance(param, Option):
-                continue
-            choices.extend(param.opts)
-            choices.extend(param.secondary_opts)
-    elif isinstance(ctx.command, MultiCommand):
-        choices.extend(ctx.command.list_commands(ctx))
+            if isinstance(param, Option) and not param.hidden:
+                param_opts = [param_opt for param_opt in param.opts +
+                              param.secondary_opts if param_opt not in all_args or param.multiple]
+                completions.extend([(o, param.help) for o in param_opts if o.startswith(incomplete)])
+        return completions
+    # completion for option values from user supplied values
+    for param in ctx.command.params:
+        if is_incomplete_option(all_args, param):
+            return get_user_autocompletions(ctx, all_args, incomplete, param)
+    # completion for argument values from user supplied values
+    for param in ctx.command.params:
+        if is_incomplete_argument(ctx.params, param):
+            return get_user_autocompletions(ctx, all_args, incomplete, param)
 
-    for item in choices:
-        if item.startswith(incomplete):
-            yield item
+    add_subcommand_completions(ctx, incomplete, completions)
+    # Sort before returning so that proper ordering can be enforced in custom types.
+    return sorted(completions)
 
 
-def do_complete(cli, prog_name):
+def do_complete(cli, prog_name, include_descriptions):
     cwords = split_arg_string(os.environ['COMP_WORDS'])
     cword = int(os.environ['COMP_CWORD'])
     args = cwords[1:cword]
@@ -69,15 +275,19 @@ def do_complete(cli, prog_name):
         incomplete = ''
 
     for item in get_choices(cli, prog_name, args, incomplete):
-        echo(item)
+        echo(item[0])
+        if include_descriptions:
+            # ZSH has trouble dealing with empty array parameters when returned from commands, so use a well defined character '_' to indicate no description is present.
+            echo(item[1] if item[1] else '_')
 
     return True
 
 
 def bashcomplete(cli, prog_name, complete_var, complete_instr):
-    if complete_instr == 'source':
-        echo(get_completion_script(prog_name, complete_var))
+    if complete_instr.startswith('source'):
+        shell = 'zsh' if complete_instr == 'source_zsh' else 'bash'
+        echo(get_completion_script(prog_name, complete_var, shell))
         return True
-    elif complete_instr == 'complete':
-        return do_complete(cli, prog_name)
+    elif complete_instr == 'complete' or complete_instr == 'complete_zsh':
+        return do_complete(cli, prog_name, complete_instr == 'complete_zsh')
     return False
diff --git a/pipenv/vendor/click/_compat.py b/pipenv/vendor/click/_compat.py
index 2b43412c..937e2301 100644
--- a/pipenv/vendor/click/_compat.py
+++ b/pipenv/vendor/click/_compat.py
@@ -7,24 +7,31 @@ from weakref import WeakKeyDictionary
 
 
 PY2 = sys.version_info[0] == 2
-WIN = sys.platform.startswith('win')
+CYGWIN = sys.platform.startswith('cygwin')
+# Determine local App Engine environment, per Google's own suggestion
+APP_ENGINE = ('APPENGINE_RUNTIME' in os.environ and
+              'Development/' in os.environ['SERVER_SOFTWARE'])
+WIN = sys.platform.startswith('win') and not APP_ENGINE
 DEFAULT_COLUMNS = 80
 
 
-_ansi_re = re.compile('\033\[((?:\d|;)*)([a-zA-Z])')
+_ansi_re = re.compile(r'\033\[((?:\d|;)*)([a-zA-Z])')
 
 
 def get_filesystem_encoding():
     return sys.getfilesystemencoding() or sys.getdefaultencoding()
 
 
-def _make_text_stream(stream, encoding, errors):
+def _make_text_stream(stream, encoding, errors,
+                      force_readable=False, force_writable=False):
     if encoding is None:
         encoding = get_best_encoding(stream)
     if errors is None:
         errors = 'replace'
     return _NonClosingTextIOWrapper(stream, encoding, errors,
-                                    line_buffering=True)
+                                    line_buffering=True,
+                                    force_readable=force_readable,
+                                    force_writable=force_writable)
 
 
 def is_ascii_encoding(encoding):
@@ -45,8 +52,10 @@ def get_best_encoding(stream):
 
 class _NonClosingTextIOWrapper(io.TextIOWrapper):
 
-    def __init__(self, stream, encoding, errors, **extra):
-        self._stream = stream = _FixupStream(stream)
+    def __init__(self, stream, encoding, errors,
+                 force_readable=False, force_writable=False, **extra):
+        self._stream = stream = _FixupStream(stream, force_readable,
+                                             force_writable)
         io.TextIOWrapper.__init__(self, stream, encoding, errors, **extra)
 
     # The io module is a place where the Python 3 text behavior
@@ -81,10 +90,16 @@ class _FixupStream(object):
     """The new io interface needs more from streams than streams
     traditionally implement.  As such, this fix-up code is necessary in
     some circumstances.
+
+    The forcing of readable and writable flags are there because some tools
+    put badly patched objects on sys (one such offender are certain version
+    of jupyter notebook).
     """
 
-    def __init__(self, stream):
+    def __init__(self, stream, force_readable=False, force_writable=False):
         self._stream = stream
+        self._force_readable = force_readable
+        self._force_writable = force_writable
 
     def __getattr__(self, name):
         return getattr(self._stream, name)
@@ -101,6 +116,8 @@ class _FixupStream(object):
         return self._stream.read(size)
 
     def readable(self):
+        if self._force_readable:
+            return True
         x = getattr(self._stream, 'readable', None)
         if x is not None:
             return x()
@@ -111,6 +128,8 @@ class _FixupStream(object):
         return True
 
     def writable(self):
+        if self._force_writable:
+            return True
         x = getattr(self._stream, 'writable', None)
         if x is not None:
             return x()
@@ -139,6 +158,7 @@ if PY2:
     bytes = str
     raw_input = raw_input
     string_types = (str, unicode)
+    int_types = (int, long)
     iteritems = lambda x: x.iteritems()
     range_type = xrange
 
@@ -165,10 +185,13 @@ if PY2:
     # available (which is why we use try-catch instead of the WIN variable
     # here), such as the Google App Engine development server on Windows. In
     # those cases there is just nothing we can do.
+    def set_binary_mode(f):
+        return f
+
     try:
         import msvcrt
     except ImportError:
-        set_binary_mode = lambda x: x
+        pass
     else:
         def set_binary_mode(f):
             try:
@@ -179,6 +202,21 @@ if PY2:
                 msvcrt.setmode(fileno, os.O_BINARY)
             return f
 
+    try:
+        import fcntl
+    except ImportError:
+        pass
+    else:
+        def set_binary_mode(f):
+            try:
+                fileno = f.fileno()
+            except Exception:
+                pass
+            else:
+                flags = fcntl.fcntl(fileno, fcntl.F_GETFL)
+                fcntl.fcntl(fileno, fcntl.F_SETFL, flags & ~os.O_NONBLOCK)
+            return f
+
     def isidentifier(x):
         return _identifier_re.search(x) is not None
 
@@ -186,28 +224,35 @@ if PY2:
         return set_binary_mode(sys.stdin)
 
     def get_binary_stdout():
+        _wrap_std_stream('stdout')
         return set_binary_mode(sys.stdout)
 
     def get_binary_stderr():
+        _wrap_std_stream('stderr')
         return set_binary_mode(sys.stderr)
 
     def get_text_stdin(encoding=None, errors=None):
         rv = _get_windows_console_stream(sys.stdin, encoding, errors)
         if rv is not None:
             return rv
-        return _make_text_stream(sys.stdin, encoding, errors)
+        return _make_text_stream(sys.stdin, encoding, errors,
+                                 force_readable=True)
 
     def get_text_stdout(encoding=None, errors=None):
+        _wrap_std_stream('stdout')
         rv = _get_windows_console_stream(sys.stdout, encoding, errors)
         if rv is not None:
             return rv
-        return _make_text_stream(sys.stdout, encoding, errors)
+        return _make_text_stream(sys.stdout, encoding, errors,
+                                 force_writable=True)
 
     def get_text_stderr(encoding=None, errors=None):
+        _wrap_std_stream('stderr')
         rv = _get_windows_console_stream(sys.stderr, encoding, errors)
         if rv is not None:
             return rv
-        return _make_text_stream(sys.stderr, encoding, errors)
+        return _make_text_stream(sys.stderr, encoding, errors,
+                                 force_writable=True)
 
     def filename_to_ui(value):
         if isinstance(value, bytes):
@@ -218,6 +263,7 @@ else:
     text_type = str
     raw_input = input
     string_types = (str,)
+    int_types = (int,)
     range_type = range
     isidentifier = lambda x: x.isidentifier()
     iteritems = lambda x: iter(x.items())
@@ -298,7 +344,8 @@ else:
 
         return False
 
-    def _force_correct_text_reader(text_reader, encoding, errors):
+    def _force_correct_text_reader(text_reader, encoding, errors,
+                                   force_readable=False):
         if _is_binary_reader(text_reader, False):
             binary_reader = text_reader
         else:
@@ -324,9 +371,11 @@ else:
         # we're so fundamentally fucked that nothing can repair it.
         if errors is None:
             errors = 'replace'
-        return _make_text_stream(binary_reader, encoding, errors)
+        return _make_text_stream(binary_reader, encoding, errors,
+                                 force_readable=force_readable)
 
-    def _force_correct_text_writer(text_writer, encoding, errors):
+    def _force_correct_text_writer(text_writer, encoding, errors,
+                                   force_writable=False):
         if _is_binary_writer(text_writer, False):
             binary_writer = text_writer
         else:
@@ -352,7 +401,8 @@ else:
         # we're so fundamentally fucked that nothing can repair it.
         if errors is None:
             errors = 'replace'
-        return _make_text_stream(binary_writer, encoding, errors)
+        return _make_text_stream(binary_writer, encoding, errors,
+                                 force_writable=force_writable)
 
     def get_binary_stdin():
         reader = _find_binary_reader(sys.stdin)
@@ -379,19 +429,22 @@ else:
         rv = _get_windows_console_stream(sys.stdin, encoding, errors)
         if rv is not None:
             return rv
-        return _force_correct_text_reader(sys.stdin, encoding, errors)
+        return _force_correct_text_reader(sys.stdin, encoding, errors,
+                                          force_readable=True)
 
     def get_text_stdout(encoding=None, errors=None):
         rv = _get_windows_console_stream(sys.stdout, encoding, errors)
         if rv is not None:
             return rv
-        return _force_correct_text_writer(sys.stdout, encoding, errors)
+        return _force_correct_text_writer(sys.stdout, encoding, errors,
+                                          force_writable=True)
 
     def get_text_stderr(encoding=None, errors=None):
         rv = _get_windows_console_stream(sys.stderr, encoding, errors)
         if rv is not None:
             return rv
-        return _force_correct_text_writer(sys.stderr, encoding, errors)
+        return _force_correct_text_writer(sys.stderr, encoding, errors,
+                                          force_writable=True)
 
     def filename_to_ui(value):
         if isinstance(value, bytes):
@@ -420,7 +473,7 @@ def open_stream(filename, mode='r', encoding=None, errors='strict',
     # Standard streams first.  These are simple because they don't need
     # special handling for the atomic flag.  It's entirely ignored.
     if filename == '-':
-        if 'w' in mode:
+        if any(m in mode for m in ['w', 'a', 'x']):
             if 'b' in mode:
                 return get_binary_stdout(), False
             return get_text_stdout(encoding=encoding, errors=errors), False
@@ -460,7 +513,7 @@ def open_stream(filename, mode='r', encoding=None, errors='strict',
     else:
         f = os.fdopen(fd, mode)
 
-    return _AtomicFile(f, tmp_filename, filename), True
+    return _AtomicFile(f, tmp_filename, os.path.realpath(filename)), True
 
 
 # Used in a destructor call, needs extra protection from interpreter cleanup.
@@ -533,7 +586,7 @@ if WIN:
     # Windows has a smaller terminal
     DEFAULT_COLUMNS = 79
 
-    from ._winconsole import _get_windows_console_stream
+    from ._winconsole import _get_windows_console_stream, _wrap_std_stream
 
     def _get_argv_encoding():
         import locale
@@ -595,6 +648,7 @@ else:
         return getattr(sys.stdin, 'encoding', None) or get_filesystem_encoding()
 
     _get_windows_console_stream = lambda *x: None
+    _wrap_std_stream = lambda *x: None
 
 
 def term_len(x):
@@ -620,6 +674,7 @@ def _make_cached_stream_func(src_func, wrapper_func):
             return rv
         rv = wrapper_func()
         try:
+            stream = src_func()  # In case wrapper_func() modified the stream
             cache[stream] = rv
         except Exception:
             pass
diff --git a/pipenv/vendor/click/_termui_impl.py b/pipenv/vendor/click/_termui_impl.py
index 7cfd3d5c..00a8e5ef 100644
--- a/pipenv/vendor/click/_termui_impl.py
+++ b/pipenv/vendor/click/_termui_impl.py
@@ -1,20 +1,24 @@
+# -*- coding: utf-8 -*-
 """
-    click._termui_impl
-    ~~~~~~~~~~~~~~~~~~
+click._termui_impl
+~~~~~~~~~~~~~~~~~~
 
-    This module contains implementations for the termui module.  To keep the
-    import time of Click down, some infrequently used functionality is placed
-    in this module and only imported as needed.
+This module contains implementations for the termui module. To keep the
+import time of Click down, some infrequently used functionality is
+placed in this module and only imported as needed.
 
-    :copyright: (c) 2014 by Armin Ronacher.
-    :license: BSD, see LICENSE for more details.
+:copyright:  2014 by the Pallets team.
+:license: BSD, see LICENSE.rst for more details.
 """
+
 import os
 import sys
 import time
 import math
+import contextlib
 from ._compat import _default_text_stdout, range_type, PY2, isatty, \
-     open_stream, strip_ansi, term_len, get_best_encoding, WIN
+     open_stream, strip_ansi, term_len, get_best_encoding, WIN, int_types, \
+     CYGWIN
 from .utils import echo
 from .exceptions import ClickException
 
@@ -41,7 +45,7 @@ def _length_hint(obj):
         except TypeError:
             return None
         if hint is NotImplemented or \
-           not isinstance(hint, (int, long)) or \
+           not isinstance(hint, int_types) or \
            hint < 0:
             return None
         return hint
@@ -88,6 +92,7 @@ class ProgressBar(object):
         self.current_item = None
         self.is_hidden = not isatty(self.file)
         self._last_line = None
+        self.short_limit = 0.5
 
     def __enter__(self):
         self.entered = True
@@ -101,10 +106,13 @@ class ProgressBar(object):
         if not self.entered:
             raise RuntimeError('You need to use progress bars in a with block.')
         self.render_progress()
-        return self
+        return self.generator()
+
+    def is_fast(self):
+        return time.time() - self.start <= self.short_limit
 
     def render_finish(self):
-        if self.is_hidden:
+        if self.is_hidden or self.is_fast():
             return
         self.file.write(AFTER_BAR)
         self.file.flush()
@@ -129,13 +137,13 @@ class ProgressBar(object):
 
     def format_eta(self):
         if self.eta_known:
-            t = self.eta + 1
+            t = int(self.eta)
             seconds = t % 60
-            t /= 60
+            t //= 60
             minutes = t % 60
-            t /= 60
+            t //= 60
             hours = t % 24
-            t /= 24
+            t //= 24
             if t > 0:
                 days = t
                 return '%dd %02d:%02d:%02d' % (days, hours, minutes, seconds)
@@ -152,25 +160,27 @@ class ProgressBar(object):
     def format_pct(self):
         return ('% 4d%%' % int(self.pct * 100))[1:]
 
-    def format_progress_line(self):
-        show_percent = self.show_percent
-
-        info_bits = []
+    def format_bar(self):
         if self.length_known:
             bar_length = int(self.pct * self.width)
             bar = self.fill_char * bar_length
             bar += self.empty_char * (self.width - bar_length)
-            if show_percent is None:
-                show_percent = not self.show_pos
+        elif self.finished:
+            bar = self.fill_char * self.width
         else:
-            if self.finished:
-                bar = self.fill_char * self.width
-            else:
-                bar = list(self.empty_char * (self.width or 1))
-                if self.time_per_iteration != 0:
-                    bar[int((math.cos(self.pos * self.time_per_iteration)
-                        / 2.0 + 0.5) * self.width)] = self.fill_char
-                bar = ''.join(bar)
+            bar = list(self.empty_char * (self.width or 1))
+            if self.time_per_iteration != 0:
+                bar[int((math.cos(self.pos * self.time_per_iteration)
+                    / 2.0 + 0.5) * self.width)] = self.fill_char
+            bar = ''.join(bar)
+        return bar
+
+    def format_progress_line(self):
+        show_percent = self.show_percent
+
+        info_bits = []
+        if self.length_known and show_percent is None:
+            show_percent = not self.show_pos
 
         if self.show_pos:
             info_bits.append(self.format_pos())
@@ -185,49 +195,47 @@ class ProgressBar(object):
 
         return (self.bar_template % {
             'label': self.label,
-            'bar': bar,
+            'bar': self.format_bar(),
             'info': self.info_sep.join(info_bits)
         }).rstrip()
 
     def render_progress(self):
         from .termui import get_terminal_size
-        nl = False
 
         if self.is_hidden:
-            buf = [self.label]
-            nl = True
-        else:
-            buf = []
-            # Update width in case the terminal has been resized
-            if self.autowidth:
-                old_width = self.width
-                self.width = 0
-                clutter_length = term_len(self.format_progress_line())
-                new_width = max(0, get_terminal_size()[0] - clutter_length)
-                if new_width < old_width:
-                    buf.append(BEFORE_BAR)
-                    buf.append(' ' * self.max_width)
-                    self.max_width = new_width
-                self.width = new_width
-
-            clear_width = self.width
-            if self.max_width is not None:
-                clear_width = self.max_width
-
-            buf.append(BEFORE_BAR)
-            line = self.format_progress_line()
-            line_len = term_len(line)
-            if self.max_width is None or self.max_width < line_len:
-                self.max_width = line_len
-            buf.append(line)
-
-            buf.append(' ' * (clear_width - line_len))
-        line = ''.join(buf)
+            return
 
+        buf = []
+        # Update width in case the terminal has been resized
+        if self.autowidth:
+            old_width = self.width
+            self.width = 0
+            clutter_length = term_len(self.format_progress_line())
+            new_width = max(0, get_terminal_size()[0] - clutter_length)
+            if new_width < old_width:
+                buf.append(BEFORE_BAR)
+                buf.append(' ' * self.max_width)
+                self.max_width = new_width
+            self.width = new_width
+
+        clear_width = self.width
+        if self.max_width is not None:
+            clear_width = self.max_width
+
+        buf.append(BEFORE_BAR)
+        line = self.format_progress_line()
+        line_len = term_len(line)
+        if self.max_width is None or self.max_width < line_len:
+            self.max_width = line_len
+
+        buf.append(line)
+        buf.append(' ' * (clear_width - line_len))
+        line = ''.join(buf)
         # Render the line only if it changed.
-        if line != self._last_line:
+
+        if line != self._last_line and not self.is_fast():
             self._last_line = line
-            echo(line, file=self.file, color=self.color, nl=nl)
+            echo(line, file=self.file, color=self.color, nl=False)
             self.file.flush()
 
     def make_step(self, n_steps):
@@ -239,7 +247,16 @@ class ProgressBar(object):
             return
 
         self.last_eta = time.time()
-        self.avg = self.avg[-6:] + [-(self.start - time.time()) / (self.pos)]
+
+        # self.avg is a rolling list of length <= 7 of steps where steps are
+        # defined as time elapsed divided by the total progress through
+        # self.length.
+        if self.pos:
+            step = (time.time() - self.start) / self.pos
+        else:
+            step = time.time() - self.start
+
+        self.avg = self.avg[-6:] + [step]
 
         self.eta_known = self.length_known
 
@@ -252,54 +269,56 @@ class ProgressBar(object):
         self.current_item = None
         self.finished = True
 
-    def next(self):
+    def generator(self):
+        """
+        Returns a generator which yields the items added to the bar during
+        construction, and updates the progress bar *after* the yielded block
+        returns.
+        """
+        if not self.entered:
+            raise RuntimeError('You need to use progress bars in a with block.')
+
         if self.is_hidden:
-            return next(self.iter)
-        try:
-            rv = next(self.iter)
-            self.current_item = rv
-        except StopIteration:
+            for rv in self.iter:
+                yield rv
+        else:
+            for rv in self.iter:
+                self.current_item = rv
+                yield rv
+                self.update(1)
             self.finish()
             self.render_progress()
-            raise StopIteration()
-        else:
-            self.update(1)
-            return rv
 
-    if not PY2:
-        __next__ = next
-        del next
 
-
-def pager(text, color=None):
+def pager(generator, color=None):
     """Decide what method to use for paging through text."""
     stdout = _default_text_stdout()
     if not isatty(sys.stdin) or not isatty(stdout):
-        return _nullpager(stdout, text, color)
+        return _nullpager(stdout, generator, color)
     pager_cmd = (os.environ.get('PAGER', None) or '').strip()
     if pager_cmd:
         if WIN:
-            return _tempfilepager(text, pager_cmd, color)
-        return _pipepager(text, pager_cmd, color)
+            return _tempfilepager(generator, pager_cmd, color)
+        return _pipepager(generator, pager_cmd, color)
     if os.environ.get('TERM') in ('dumb', 'emacs'):
-        return _nullpager(stdout, text, color)
+        return _nullpager(stdout, generator, color)
     if WIN or sys.platform.startswith('os2'):
-        return _tempfilepager(text, 'more <', color)
+        return _tempfilepager(generator, 'more <', color)
     if hasattr(os, 'system') and os.system('(less) 2>/dev/null') == 0:
-        return _pipepager(text, 'less', color)
+        return _pipepager(generator, 'less', color)
 
     import tempfile
     fd, filename = tempfile.mkstemp()
     os.close(fd)
     try:
         if hasattr(os, 'system') and os.system('more "%s"' % filename) == 0:
-            return _pipepager(text, 'more', color)
-        return _nullpager(stdout, text, color)
+            return _pipepager(generator, 'more', color)
+        return _nullpager(stdout, generator, color)
     finally:
         os.unlink(filename)
 
 
-def _pipepager(text, cmd, color):
+def _pipepager(generator, cmd, color):
     """Page through text by feeding it to another program.  Invoking a
     pager through this might support colors.
     """
@@ -317,17 +336,19 @@ def _pipepager(text, cmd, color):
         elif 'r' in less_flags or 'R' in less_flags:
             color = True
 
-    if not color:
-        text = strip_ansi(text)
-
     c = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE,
                          env=env)
     encoding = get_best_encoding(c.stdin)
     try:
-        c.stdin.write(text.encode(encoding, 'replace'))
-        c.stdin.close()
+        for text in generator:
+            if not color:
+                text = strip_ansi(text)
+
+            c.stdin.write(text.encode(encoding, 'replace'))
     except (IOError, KeyboardInterrupt):
         pass
+    else:
+        c.stdin.close()
 
     # Less doesn't respect ^C, but catches it for its own UI purposes (aborting
     # search or other commands inside less).
@@ -346,10 +367,12 @@ def _pipepager(text, cmd, color):
             break
 
 
-def _tempfilepager(text, cmd, color):
+def _tempfilepager(generator, cmd, color):
     """Page through text by invoking a program on a temporary file."""
     import tempfile
     filename = tempfile.mktemp()
+    # TODO: This never terminates if the passed generator never terminates.
+    text = "".join(generator)
     if not color:
         text = strip_ansi(text)
     encoding = get_best_encoding(sys.stdout)
@@ -361,11 +384,12 @@ def _tempfilepager(text, cmd, color):
         os.unlink(filename)
 
 
-def _nullpager(stream, text, color):
+def _nullpager(stream, generator, color):
     """Simply print unformatted text.  This is the ultimate fallback."""
-    if not color:
-        text = strip_ansi(text)
-    stream.write(text)
+    for text in generator:
+        if not color:
+            text = strip_ansi(text)
+        stream.write(text)
 
 
 class Editor(object):
@@ -478,6 +502,14 @@ def open_url(url, wait=False, locate=False):
             args = 'start %s "" "%s"' % (
                 wait and '/WAIT' or '', url.replace('"', ''))
         return os.system(args)
+    elif CYGWIN:
+        if locate:
+            url = _unquote_file(url)
+            args = 'cygstart "%s"' % (os.path.dirname(url).replace('"', ''))
+        else:
+            args = 'cygstart %s "%s"' % (
+                wait and '-w' or '', url.replace('"', ''))
+        return os.system(args)
 
     try:
         if locate:
@@ -497,32 +529,69 @@ def open_url(url, wait=False, locate=False):
 
 
 def _translate_ch_to_exc(ch):
-    if ch == '\x03':
+    if ch == u'\x03':
         raise KeyboardInterrupt()
-    if ch == '\x04':
+    if ch == u'\x04' and not WIN:  # Unix-like, Ctrl+D
+        raise EOFError()
+    if ch == u'\x1a' and WIN:      # Windows, Ctrl+Z
         raise EOFError()
 
 
 if WIN:
     import msvcrt
 
+    @contextlib.contextmanager
+    def raw_terminal():
+        yield
+
     def getchar(echo):
-        rv = msvcrt.getch()
+        # The function `getch` will return a bytes object corresponding to
+        # the pressed character. Since Windows 10 build 1803, it will also
+        # return \x00 when called a second time after pressing a regular key.
+        #
+        # `getwch` does not share this probably-bugged behavior. Moreover, it
+        # returns a Unicode object by default, which is what we want.
+        #
+        # Either of these functions will return \x00 or \xe0 to indicate
+        # a special key, and you need to call the same function again to get
+        # the "rest" of the code. The fun part is that \u00e0 is
+        # "latin small letter a with grave", so if you type that on a French
+        # keyboard, you _also_ get a \xe0.
+        # E.g., consider the Up arrow. This returns \xe0 and then \x48. The
+        # resulting Unicode string reads as "a with grave" + "capital H".
+        # This is indistinguishable from when the user actually types
+        # "a with grave" and then "capital H".
+        #
+        # When \xe0 is returned, we assume it's part of a special-key sequence
+        # and call `getwch` again, but that means that when the user types
+        # the \u00e0 character, `getchar` doesn't return until a second
+        # character is typed.
+        # The alternative is returning immediately, but that would mess up
+        # cross-platform handling of arrow keys and others that start with
+        # \xe0. Another option is using `getch`, but then we can't reliably
+        # read non-ASCII characters, because return values of `getch` are
+        # limited to the current 8-bit codepage.
+        #
+        # Anyway, Click doesn't claim to do this Right(tm), and using `getwch`
+        # is doing the right thing in more situations than with `getch`.
         if echo:
-            msvcrt.putchar(rv)
+            func = msvcrt.getwche
+        else:
+            func = msvcrt.getwch
+
+        rv = func()
+        if rv in (u'\x00', u'\xe0'):
+            # \x00 and \xe0 are control characters that indicate special key,
+            # see above.
+            rv += func()
         _translate_ch_to_exc(rv)
-        if PY2:
-            enc = getattr(sys.stdin, 'encoding', None)
-            if enc is not None:
-                rv = rv.decode(enc, 'replace')
-            else:
-                rv = rv.decode('cp1252', 'replace')
         return rv
 else:
     import tty
     import termios
 
-    def getchar(echo):
+    @contextlib.contextmanager
+    def raw_terminal():
         if not isatty(sys.stdin):
             f = open('/dev/tty')
             fd = f.fileno()
@@ -533,9 +602,7 @@ else:
             old_settings = termios.tcgetattr(fd)
             try:
                 tty.setraw(fd)
-                ch = os.read(fd, 32)
-                if echo and isatty(sys.stdout):
-                    sys.stdout.write(ch)
+                yield fd
             finally:
                 termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
                 sys.stdout.flush()
@@ -543,5 +610,12 @@ else:
                     f.close()
         except termios.error:
             pass
-        _translate_ch_to_exc(ch)
-        return ch.decode(get_best_encoding(sys.stdin), 'replace')
+
+    def getchar(echo):
+        with raw_terminal() as fd:
+            ch = os.read(fd, 32)
+            ch = ch.decode(get_best_encoding(sys.stdin), 'replace')
+            if echo and isatty(sys.stdout):
+                sys.stdout.write(ch)
+            _translate_ch_to_exc(ch)
+            return ch
diff --git a/pipenv/vendor/click/_unicodefun.py b/pipenv/vendor/click/_unicodefun.py
index 9e17a384..620edff3 100644
--- a/pipenv/vendor/click/_unicodefun.py
+++ b/pipenv/vendor/click/_unicodefun.py
@@ -14,6 +14,8 @@ click = sys.modules[__name__.rsplit('.', 1)[0]]
 
 def _find_unicode_literals_frame():
     import __future__
+    if not hasattr(sys, '_getframe'):  # not all Python implementations have it
+        return 0
     frm = sys._getframe(1)
     idx = 1
     while frm is not None:
@@ -41,7 +43,7 @@ def _check_for_unicode_literals():
                  'because it can introduce subtle bugs in your '
                  'code.  You should instead use explicit u"" literals '
                  'for your unicode strings.  For more information see '
-                 'http://click.pocoo.org/python3/'),
+                 'https://click.palletsprojects.com/python3/'),
          stacklevel=bad_frame)
 
 
@@ -60,8 +62,11 @@ def _verify_python3_env():
     extra = ''
     if os.name == 'posix':
         import subprocess
-        rv = subprocess.Popen(['locale', '-a'], stdout=subprocess.PIPE,
-                              stderr=subprocess.PIPE).communicate()[0]
+        try:
+            rv = subprocess.Popen(['locale', '-a'], stdout=subprocess.PIPE,
+                                  stderr=subprocess.PIPE).communicate()[0]
+        except OSError:
+            rv = b''
         good_locales = set()
         has_c_utf8 = False
 
@@ -94,7 +99,7 @@ def _verify_python3_env():
         else:
             extra += (
                 'This system lists a couple of UTF-8 supporting locales that\n'
-                'you can pick from.  The following suitable locales where\n'
+                'you can pick from.  The following suitable locales were\n'
                 'discovered: %s'
             ) % ', '.join(sorted(good_locales))
 
@@ -112,7 +117,9 @@ def _verify_python3_env():
                 'is not supported'
             ) % bad_locale
 
-    raise RuntimeError('Click will abort further execution because Python 3 '
-                       'was configured to use ASCII as encoding for the '
-                       'environment.  Consult http://click.pocoo.org/python3/'
-                       'for mitigation steps.' + extra)
+    raise RuntimeError(
+        'Click will abort further execution because Python 3 was'
+        ' configured to use ASCII as encoding for the environment.'
+        ' Consult https://click.palletsprojects.com/en/7.x/python3/ for'
+        ' mitigation steps.' + extra
+    )
diff --git a/pipenv/vendor/click/_winconsole.py b/pipenv/vendor/click/_winconsole.py
index 9aed9421..bbb080dd 100644
--- a/pipenv/vendor/click/_winconsole.py
+++ b/pipenv/vendor/click/_winconsole.py
@@ -15,7 +15,7 @@ import zlib
 import time
 import ctypes
 import msvcrt
-from click._compat import _NonClosingTextIOWrapper, text_type, PY2
+from ._compat import _NonClosingTextIOWrapper, text_type, PY2
 from ctypes import byref, POINTER, c_int, c_char, c_char_p, \
      c_void_p, py_object, c_ssize_t, c_ulong, windll, WINFUNCTYPE
 try:
@@ -201,6 +201,40 @@ class ConsoleStream(object):
         )
 
 
+class WindowsChunkedWriter(object):
+    """
+    Wraps a stream (such as stdout), acting as a transparent proxy for all
+    attribute access apart from method 'write()' which we wrap to write in
+    limited chunks due to a Windows limitation on binary console streams.
+    """
+    def __init__(self, wrapped):
+        # double-underscore everything to prevent clashes with names of
+        # attributes on the wrapped stream object.
+        self.__wrapped = wrapped
+
+    def __getattr__(self, name):
+        return getattr(self.__wrapped, name)
+
+    def write(self, text):
+        total_to_write = len(text)
+        written = 0
+
+        while written < total_to_write:
+            to_write = min(total_to_write - written, MAX_BYTES_WRITTEN)
+            self.__wrapped.write(text[written:written+to_write])
+            written += to_write
+
+
+_wrapped_std_streams = set()
+
+
+def _wrap_std_stream(name):
+    # Python 2 & Windows 7 and below
+    if PY2 and sys.getwindowsversion()[:2] <= (6, 1) and name not in _wrapped_std_streams:
+        setattr(sys, name, WindowsChunkedWriter(getattr(sys, name)))
+        _wrapped_std_streams.add(name)
+
+
 def _get_text_stdin(buffer_stream):
     text_stream = _NonClosingTextIOWrapper(
         io.BufferedReader(_WindowsConsoleReader(STDIN_HANDLE)),
@@ -210,14 +244,14 @@ def _get_text_stdin(buffer_stream):
 
 def _get_text_stdout(buffer_stream):
     text_stream = _NonClosingTextIOWrapper(
-        _WindowsConsoleWriter(STDOUT_HANDLE),
+        io.BufferedWriter(_WindowsConsoleWriter(STDOUT_HANDLE)),
         'utf-16-le', 'strict', line_buffering=True)
     return ConsoleStream(text_stream, buffer_stream)
 
 
 def _get_text_stderr(buffer_stream):
     text_stream = _NonClosingTextIOWrapper(
-        _WindowsConsoleWriter(STDERR_HANDLE),
+        io.BufferedWriter(_WindowsConsoleWriter(STDERR_HANDLE)),
         'utf-16-le', 'strict', line_buffering=True)
     return ConsoleStream(text_stream, buffer_stream)
 
@@ -261,7 +295,7 @@ def _get_windows_console_stream(f, encoding, errors):
         func = _stream_factories.get(f.fileno())
         if func is not None:
             if not PY2:
-                f = getattr(f, 'buffer')
+                f = getattr(f, 'buffer', None)
                 if f is None:
                     return None
             else:
diff --git a/pipenv/vendor/click/core.py b/pipenv/vendor/click/core.py
index 74564514..7a1e3422 100644
--- a/pipenv/vendor/click/core.py
+++ b/pipenv/vendor/click/core.py
@@ -1,4 +1,5 @@
 import errno
+import inspect
 import os
 import sys
 from contextlib import contextmanager
@@ -6,15 +7,16 @@ from itertools import repeat
 from functools import update_wrapper
 
 from .types import convert_type, IntRange, BOOL
-from .utils import make_str, make_default_short_help, echo, get_os_args
+from .utils import PacifyFlushWrapper, make_str, make_default_short_help, \
+     echo, get_os_args
 from .exceptions import ClickException, UsageError, BadParameter, Abort, \
-     MissingParameter
-from .termui import prompt, confirm
+     MissingParameter, Exit
+from .termui import prompt, confirm, style
 from .formatting import HelpFormatter, join_options
 from .parser import OptionParser, split_opt
 from .globals import push_context, pop_context
 
-from ._compat import PY2, isidentifier, iteritems
+from ._compat import PY2, isidentifier, iteritems, string_types
 from ._unicodefun import _check_for_unicode_literals, _verify_python3_env
 
 
@@ -24,6 +26,24 @@ _missing = object()
 SUBCOMMAND_METAVAR = 'COMMAND [ARGS]...'
 SUBCOMMANDS_METAVAR = 'COMMAND1 [ARGS]... [COMMAND2 [ARGS]...]...'
 
+DEPRECATED_HELP_NOTICE = ' (DEPRECATED)'
+DEPRECATED_INVOKE_NOTICE = 'DeprecationWarning: ' + \
+                           'The command %(name)s is deprecated.'
+
+
+def _maybe_show_deprecated_notice(cmd):
+    if cmd.deprecated:
+        echo(style(DEPRECATED_INVOKE_NOTICE % {'name': cmd.name}, fg='red'), err=True)
+
+
+def fast_exit(code):
+    """Exit without garbage collection, this speeds up exit by about 10ms for
+    things like bash completion.
+    """
+    sys.stdout.flush()
+    sys.stderr.flush()
+    os._exit(code)
+
 
 def _bashcomplete(cmd, prog_name, complete_var=None):
     """Internal handler for the bash completion support."""
@@ -35,7 +55,7 @@ def _bashcomplete(cmd, prog_name, complete_var=None):
 
     from ._bashcomplete import bashcomplete
     if bashcomplete(cmd, prog_name, complete_var, complete_instr):
-        sys.exit(1)
+        fast_exit(1)
 
 
 def _check_multicommand(base_command, cmd_name, cmd, register=False):
@@ -50,9 +70,7 @@ def _check_multicommand(base_command, cmd_name, cmd, register=False):
     raise RuntimeError('%s.  Command "%s" is set to chain and "%s" was '
                        'added as subcommand but it in itself is a '
                        'multi command.  ("%s" is a %s within a chained '
-                       '%s named "%s").  This restriction was supposed to '
-                       'be lifted in 6.0 but the fix was flawed.  This '
-                       'will be fixed in Click 7.0' % (
+                       '%s named "%s").' % (
                            hint, base_command.name, cmd_name,
                            cmd_name, cmd.__class__.__name__,
                            base_command.__class__.__name__,
@@ -165,7 +183,8 @@ class Context(object):
                               add some safety mapping on the right.
     :param resilient_parsing: if this flag is enabled then Click will
                               parse without any interactivity or callback
-                              invocation.  This is useful for implementing
+                              invocation.  Default values will also be
+                              ignored.  This is useful for implementing
                               things such as completion support.
     :param allow_extra_args: if this is set to `True` then extra arguments
                              at the end will not raise an error and will be
@@ -295,7 +314,8 @@ class Context(object):
         self.token_normalize_func = token_normalize_func
 
         #: Indicates if resilient parsing is enabled.  In that case Click
-        #: will do its best to not cause any failures.
+        #: will do its best to not cause any failures and default values
+        #: will be ignored. Useful for completion.
         self.resilient_parsing = resilient_parsing
 
         # If there is no envvar prefix yet, but the parent has one and
@@ -308,7 +328,7 @@ class Context(object):
                 auto_envvar_prefix = '%s_%s' % (parent.auto_envvar_prefix,
                                            self.info_name.upper())
         else:
-            self.auto_envvar_prefix = auto_envvar_prefix.upper()
+            auto_envvar_prefix = auto_envvar_prefix.upper()
         self.auto_envvar_prefix = auto_envvar_prefix
 
         if color is None and parent is not None:
@@ -372,7 +392,7 @@ class Context(object):
     @property
     def meta(self):
         """This is a dictionary which is shared with all the contexts
-        that are nested.  It exists so that click utiltiies can store some
+        that are nested.  It exists so that click utilities can store some
         state here if they need to.  It is however the responsibility of
         that code to manage this dictionary well.
 
@@ -481,7 +501,7 @@ class Context(object):
 
     def exit(self, code=0):
         """Exits the application with a given exit code."""
-        sys.exit(code)
+        raise Exit(code)
 
     def get_usage(self):
         """Helper method to get formatted usage string for the current
@@ -655,7 +675,7 @@ class BaseCommand(object):
                           name from ``sys.argv[0]``.
         :param complete_var: the environment variable that controls the
                              bash completion support.  The default is
-                             ``"_<prog_name>_COMPLETE"`` with prog name in
+                             ``"_<prog_name>_COMPLETE"`` with prog_name in
                              uppercase.
         :param standalone_mode: the default behavior is to invoke the script
                                 in standalone mode.  Click will then
@@ -670,7 +690,7 @@ class BaseCommand(object):
                       constructor.  See :class:`Context` for more information.
         """
         # If we are in Python 3, we will verify that the environment is
-        # sane at this point of reject further execution to avoid a
+        # sane at this point or reject further execution to avoid a
         # broken script.
         if not PY2:
             _verify_python3_env()
@@ -697,6 +717,13 @@ class BaseCommand(object):
                     rv = self.invoke(ctx)
                     if not standalone_mode:
                         return rv
+                    # it's not safe to `ctx.exit(rv)` here!
+                    # note that `rv` may actually contain data like "1" which
+                    # has obvious effects
+                    # more subtle case: `rv=[None, None]` can come out of
+                    # chained commands which all returned `None` -- so it's not
+                    # even always obvious that `rv` indicates success/failure
+                    # by its truthiness/falsiness
                     ctx.exit()
             except (EOFError, KeyboardInterrupt):
                 echo(file=sys.stderr)
@@ -708,9 +735,24 @@ class BaseCommand(object):
                 sys.exit(e.exit_code)
             except IOError as e:
                 if e.errno == errno.EPIPE:
+                    sys.stdout = PacifyFlushWrapper(sys.stdout)
+                    sys.stderr = PacifyFlushWrapper(sys.stderr)
                     sys.exit(1)
                 else:
                     raise
+        except Exit as e:
+            if standalone_mode:
+                sys.exit(e.exit_code)
+            else:
+                # in non-standalone mode, return the exit code
+                # note that this is only reached if `self.invoke` above raises
+                # an Exit explicitly -- thus bypassing the check there which
+                # would return its result
+                # the results of non-standalone execution may therefore be
+                # somewhat ambiguous: if there are codepaths which lead to
+                # `ctx.exit(1)` and to `return 1`, the caller won't be able to
+                # tell the difference between the two
+                return e.exit_code
         except Abort:
             if not standalone_mode:
                 raise
@@ -743,11 +785,16 @@ class Command(BaseCommand):
                        shown on the command listing of the parent command.
     :param add_help_option: by default each command registers a ``--help``
                             option.  This can be disabled by this parameter.
+    :param hidden: hide this command from help outputs.
+
+    :param deprecated: issues a message indicating that
+                             the command is deprecated.
     """
 
     def __init__(self, name, context_settings=None, callback=None,
                  params=None, help=None, epilog=None, short_help=None,
-                 options_metavar='[OPTIONS]', add_help_option=True):
+                 options_metavar='[OPTIONS]', add_help_option=True,
+                 hidden=False, deprecated=False):
         BaseCommand.__init__(self, name, context_settings)
         #: the callback to execute when the command fires.  This might be
         #: `None` in which case nothing happens.
@@ -756,13 +803,17 @@ class Command(BaseCommand):
         #: should show up in the help page and execute.  Eager parameters
         #: will automatically be handled before non eager ones.
         self.params = params or []
+        # if a form feed (page break) is found in the help text, truncate help
+        # text to the content preceding the first form feed
+        if help and '\f' in help:
+            help = help.split('\f', 1)[0]
         self.help = help
         self.epilog = epilog
         self.options_metavar = options_metavar
-        if short_help is None and help:
-            short_help = make_default_short_help(help)
         self.short_help = short_help
         self.add_help_option = add_help_option
+        self.hidden = hidden
+        self.deprecated = deprecated
 
     def get_usage(self, ctx):
         formatter = ctx.make_formatter()
@@ -816,8 +867,6 @@ class Command(BaseCommand):
     def make_parser(self, ctx):
         """Creates the underlying option parser for this command."""
         parser = OptionParser(ctx)
-        parser.allow_interspersed_args = ctx.allow_interspersed_args
-        parser.ignore_unknown_options = ctx.ignore_unknown_options
         for param in self.get_params(ctx):
             param.add_to_parser(parser, ctx)
         return parser
@@ -830,6 +879,10 @@ class Command(BaseCommand):
         self.format_help(ctx, formatter)
         return formatter.getvalue().rstrip('\n')
 
+    def get_short_help_str(self, limit=45):
+        """Gets short help for the command or makes it by shortening the long help string."""
+        return self.short_help or self.help and make_default_short_help(self.help, limit) or ''
+
     def format_help(self, ctx, formatter):
         """Writes the help into the formatter if it exists.
 
@@ -850,7 +903,14 @@ class Command(BaseCommand):
         if self.help:
             formatter.write_paragraph()
             with formatter.indentation():
-                formatter.write_text(self.help)
+                help_text = self.help
+                if self.deprecated:
+                    help_text += DEPRECATED_HELP_NOTICE
+                formatter.write_text(help_text)
+        elif self.deprecated:
+            formatter.write_paragraph()
+            with formatter.indentation():
+                formatter.write_text(DEPRECATED_HELP_NOTICE)
 
     def format_options(self, ctx, formatter):
         """Writes all the options into the formatter if they exist."""
@@ -891,6 +951,7 @@ class Command(BaseCommand):
         """Given a context, this invokes the attached callback (if it exists)
         in the right way.
         """
+        _maybe_show_deprecated_notice(self)
         if self.callback is not None:
             return ctx.invoke(self.callback, **ctx.params)
 
@@ -996,19 +1057,29 @@ class MultiCommand(Command):
         """Extra format methods for multi methods that adds all the commands
         after the options.
         """
-        rows = []
+        commands = []
         for subcommand in self.list_commands(ctx):
             cmd = self.get_command(ctx, subcommand)
             # What is this, the tool lied about a command.  Ignore it
             if cmd is None:
                 continue
+            if cmd.hidden:
+                continue
 
-            help = cmd.short_help or ''
-            rows.append((subcommand, help))
+            commands.append((subcommand, cmd))
 
-        if rows:
-            with formatter.section('Commands'):
-                formatter.write_dl(rows)
+        # allow for 3 times the default spacing
+        if len(commands):
+            limit = formatter.width - 6 - max(len(cmd[0]) for cmd in commands)
+
+            rows = []
+            for subcommand, cmd in commands:
+                help = cmd.get_short_help_str(limit)
+                rows.append((subcommand, help))
+
+            if rows:
+                with formatter.section('Commands'):
+                    formatter.write_dl(rows)
 
     def parse_args(self, ctx, args):
         if not args and self.no_args_is_help and not ctx.resilient_parsing:
@@ -1111,7 +1182,7 @@ class MultiCommand(Command):
         # an option we want to kick off parsing again for arguments to
         # resolve things like --help which now should go to the main
         # place.
-        if cmd is None:
+        if cmd is None and not ctx.resilient_parsing:
             if split_opt(cmd_name)[0]:
                 self.parse_args(ctx, ctx.args)
             ctx.fail('No such command "%s".' % original_cmd_name)
@@ -1216,7 +1287,7 @@ class CommandCollection(MultiCommand):
 
 
 class Parameter(object):
-    """A parameter to a command comes in two versions: they are either
+    r"""A parameter to a command comes in two versions: they are either
     :class:`Option`\s or :class:`Argument`\s.  Other subclasses are currently
     not supported by design as some of the internals for parsing are
     intentionally not finalized.
@@ -1261,7 +1332,8 @@ class Parameter(object):
 
     def __init__(self, param_decls=None, type=None, required=False,
                  default=None, callback=None, nargs=None, metavar=None,
-                 expose_value=True, is_eager=False, envvar=None):
+                 expose_value=True, is_eager=False, envvar=None,
+                 autocompletion=None):
         self.name, self.opts, self.secondary_opts = \
             self._parse_decls(param_decls or (), expose_value)
 
@@ -1284,6 +1356,7 @@ class Parameter(object):
         self.is_eager = is_eager
         self.metavar = metavar
         self.envvar = envvar
+        self.autocompletion = autocompletion
 
     @property
     def human_readable_name(self):
@@ -1316,10 +1389,10 @@ class Parameter(object):
 
     def consume_value(self, ctx, opts):
         value = opts.get(self.name)
-        if value is None:
-            value = ctx.lookup_default(self.name)
         if value is None:
             value = self.value_from_envvar(ctx)
+        if value is None:
+            value = ctx.lookup_default(self.name)
         return value
 
     def type_cast_value(self, ctx, value):
@@ -1364,7 +1437,7 @@ class Parameter(object):
     def full_process_value(self, ctx, value):
         value = self.process_value(ctx, value)
 
-        if value is None:
+        if value is None and not ctx.resilient_parsing:
             value = self.get_default(ctx)
 
         if self.required and self.value_is_missing(value):
@@ -1416,6 +1489,13 @@ class Parameter(object):
     def get_usage_pieces(self, ctx):
         return []
 
+    def get_error_hint(self, ctx):
+        """Get a stringified version of the param for use in error messages to
+        indicate which param caused the error.
+        """
+        hint_list = self.opts or [self.human_readable_name]
+        return ' / '.join('"%s"' % x for x in hint_list)
+
 
 class Option(Parameter):
     """Options are usually optional values on the command line and
@@ -1424,10 +1504,15 @@ class Option(Parameter):
     All other parameters are passed onwards to the parameter constructor.
 
     :param show_default: controls if the default value should be shown on the
-                         help page.  Normally, defaults are not shown.
-    :param prompt: if set to `True` or a non empty string then the user will
-                   be prompted for input if not set.  If set to `True` the
-                   prompt will be the option name capitalized.
+                         help page. Normally, defaults are not shown. If this
+                         value is a string, it shows the string instead of the
+                         value. This is particularly useful for dynamic options.
+    :param show_envvar: controls if an environment variable should be shown on
+                        the help page.  Normally, environment variables
+                        are not shown.
+    :param prompt: if set to `True` or a non empty string then the user will be
+                   prompted for input.  If set to `True` the prompt will be the
+                   option name capitalized.
     :param confirmation_prompt: if set then the value will need to be confirmed
                                 if it was prompted for.
     :param hide_input: if this is `True` then the input on the prompt will be
@@ -1448,6 +1533,7 @@ class Option(Parameter):
                                variable in case a prefix is defined on the
                                context.
     :param help: the help string.
+    :param hidden: hide this option from help outputs.
     """
     param_type_name = 'option'
 
@@ -1455,7 +1541,8 @@ class Option(Parameter):
                  prompt=False, confirmation_prompt=False,
                  hide_input=False, is_flag=None, flag_value=None,
                  multiple=False, count=False, allow_from_autoenv=True,
-                 type=None, help=None, **attrs):
+                 type=None, help=None, hidden=False, show_choices=True,
+                 show_envvar=False, **attrs):
         default_is_missing = attrs.get('default', _missing) is _missing
         Parameter.__init__(self, param_decls, type=type, **attrs)
 
@@ -1468,6 +1555,7 @@ class Option(Parameter):
         self.prompt = prompt_text
         self.confirmation_prompt = confirmation_prompt
         self.hide_input = hide_input
+        self.hidden = hidden
 
         # Flags
         if is_flag is None:
@@ -1500,6 +1588,8 @@ class Option(Parameter):
         self.allow_from_autoenv = allow_from_autoenv
         self.help = help
         self.show_default = show_default
+        self.show_choices = show_choices
+        self.show_envvar = show_envvar
 
         # Sanity check for stuff we don't support
         if __debug__:
@@ -1548,8 +1638,8 @@ class Option(Parameter):
                     opts.append(decl)
 
         if name is None and possible_names:
-            possible_names.sort(key=lambda x: len(x[0]))
-            name = possible_names[-1][1].replace('-', '_').lower()
+            possible_names.sort(key=lambda x: -len(x[0]))  # group long options first
+            name = possible_names[0][1].replace('-', '_').lower()
             if not isidentifier(name):
                 name = None
 
@@ -1595,6 +1685,8 @@ class Option(Parameter):
             parser.add_option(self.opts, **kwargs)
 
     def get_help_record(self, ctx):
+        if self.hidden:
+            return
         any_prefix_is_slash = []
 
         def _write_opts(opts):
@@ -1611,11 +1703,28 @@ class Option(Parameter):
 
         help = self.help or ''
         extra = []
+        if self.show_envvar:
+            envvar = self.envvar
+            if envvar is None:
+                if self.allow_from_autoenv and \
+                    ctx.auto_envvar_prefix is not None:
+                    envvar = '%s_%s' % (ctx.auto_envvar_prefix, self.name.upper())
+            if envvar is not None:
+              extra.append('env var: %s' % (
+                           ', '.join('%s' % d for d in envvar)
+                           if isinstance(envvar, (list, tuple))
+                           else envvar, ))
         if self.default is not None and self.show_default:
-            extra.append('default: %s' % (
-                         ', '.join('%s' % d for d in self.default)
-                         if isinstance(self.default, (list, tuple))
-                         else self.default, ))
+            if isinstance(self.show_default, string_types):
+                default_string = '({})'.format(self.show_default)
+            elif isinstance(self.default, (list, tuple)):
+                default_string = ', '.join('%s' % d for d in self.default)
+            elif inspect.isfunction(self.default):
+                default_string = "(dynamic)"
+            else:
+                default_string = self.default
+            extra.append('default: {}'.format(default_string))
+
         if self.required:
             extra.append('required')
         if extra:
@@ -1649,8 +1758,8 @@ class Option(Parameter):
         if self.is_bool_flag:
             return confirm(self.prompt, default)
 
-        return prompt(self.prompt, default=default,
-                      hide_input=self.hide_input,
+        return prompt(self.prompt, default=default, type=self.type,
+                      hide_input=self.hide_input, show_choices=self.show_choices,
                       confirmation_prompt=self.confirmation_prompt,
                       value_proc=lambda x: self.process_value(ctx, x))
 
@@ -1710,7 +1819,9 @@ class Argument(Parameter):
     def make_metavar(self):
         if self.metavar is not None:
             return self.metavar
-        var = self.name.upper()
+        var = self.type.get_metavar(self)
+        if not var:
+            var = self.name.upper()
         if not self.required:
             var = '[%s]' % var
         if self.nargs != 1:
@@ -1725,16 +1836,17 @@ class Argument(Parameter):
         if len(decls) == 1:
             name = arg = decls[0]
             name = name.replace('-', '_').lower()
-        elif len(decls) == 2:
-            name, arg = decls
         else:
-            raise TypeError('Arguments take exactly one or two '
-                            'parameter declarations, got %d' % len(decls))
+            raise TypeError('Arguments take exactly one '
+                            'parameter declaration, got %d' % len(decls))
         return name, [arg], []
 
     def get_usage_pieces(self, ctx):
         return [self.make_metavar()]
 
+    def get_error_hint(self, ctx):
+        return '"%s"' % self.make_metavar()
+
     def add_to_parser(self, parser, ctx):
         parser.add_argument(dest=self.name, nargs=self.nargs,
                             obj=self)
diff --git a/pipenv/vendor/click/decorators.py b/pipenv/vendor/click/decorators.py
index 98934526..c57c5308 100644
--- a/pipenv/vendor/click/decorators.py
+++ b/pipenv/vendor/click/decorators.py
@@ -61,7 +61,7 @@ def make_pass_decorator(object_type, ensure=False):
                 raise RuntimeError('Managed to invoke callback without a '
                                    'context object of type %r existing'
                                    % object_type.__name__)
-            return ctx.invoke(f, obj, *args[1:], **kwargs)
+            return ctx.invoke(f, obj, *args, **kwargs)
         return update_wrapper(new_func, f)
     return decorator
 
@@ -85,12 +85,12 @@ def _make_command(f, name, attrs, cls):
         help = inspect.cleandoc(help)
     attrs['help'] = help
     _check_for_unicode_literals()
-    return cls(name=name or f.__name__.lower(),
+    return cls(name=name or f.__name__.lower().replace('_', '-'),
                callback=f, params=params, **attrs)
 
 
 def command(name=None, cls=None, **attrs):
-    """Creates a new :class:`Command` and uses the decorated function as
+    r"""Creates a new :class:`Command` and uses the decorated function as
     callback.  This will also automatically attach all decorated
     :func:`option`\s and :func:`argument`\s as parameters to the command.
 
@@ -105,7 +105,7 @@ def command(name=None, cls=None, **attrs):
     command :class:`Group`.
 
     :param name: the name of the command.  This defaults to the function
-                 name.
+                 name with underscores replaced by dashes.
     :param cls: the command class to instantiate.  This defaults to
                 :class:`Command`.
     """
@@ -164,10 +164,13 @@ def option(*param_decls, **attrs):
                 :class:`Option`.
     """
     def decorator(f):
-        if 'help' in attrs:
-            attrs['help'] = inspect.cleandoc(attrs['help'])
-        OptionClass = attrs.pop('cls', Option)
-        _param_memo(f, OptionClass(param_decls, **attrs))
+        # Issue 926, copy attrs, so pre-defined options can re-use the same cls=
+        option_attrs = attrs.copy()
+
+        if 'help' in option_attrs:
+            option_attrs['help'] = inspect.cleandoc(option_attrs['help'])
+        OptionClass = option_attrs.pop('cls', Option)
+        _param_memo(f, OptionClass(param_decls, **option_attrs))
         return f
     return decorator
 
@@ -235,7 +238,11 @@ def version_option(version=None, *param_decls, **attrs):
     :param others: everything else is forwarded to :func:`option`.
     """
     if version is None:
-        module = sys._getframe(1).f_globals.get('__name__')
+        if hasattr(sys, '_getframe'):
+            module = sys._getframe(1).f_globals.get('__name__')
+        else:
+            module = ''
+
     def decorator(f):
         prog_name = attrs.pop('prog_name', None)
         message = attrs.pop('message', '%(prog)s, version %(version)s')
diff --git a/pipenv/vendor/click/exceptions.py b/pipenv/vendor/click/exceptions.py
index 74a4542b..6fa17658 100644
--- a/pipenv/vendor/click/exceptions.py
+++ b/pipenv/vendor/click/exceptions.py
@@ -2,6 +2,12 @@ from ._compat import PY2, filename_to_ui, get_text_stderr
 from .utils import echo
 
 
+def _join_param_hints(param_hint):
+    if isinstance(param_hint, (tuple, list)):
+        return ' / '.join('"%s"' % x for x in param_hint)
+    return param_hint
+
+
 class ClickException(Exception):
     """An exception that Click can handle and show to the user."""
 
@@ -9,15 +15,25 @@ class ClickException(Exception):
     exit_code = 1
 
     def __init__(self, message):
+        ctor_msg = message
         if PY2:
-            if message is not None:
-                message = message.encode('utf-8')
-        Exception.__init__(self, message)
+            if ctor_msg is not None:
+                ctor_msg = ctor_msg.encode('utf-8')
+        Exception.__init__(self, ctor_msg)
         self.message = message
 
     def format_message(self):
         return self.message
 
+    def __str__(self):
+        return self.message
+
+    if PY2:
+        __unicode__ = __str__
+
+        def __str__(self):
+            return self.message.encode('utf-8')
+
     def show(self, file=None):
         if file is None:
             file = get_text_stderr()
@@ -37,14 +53,20 @@ class UsageError(ClickException):
     def __init__(self, message, ctx=None):
         ClickException.__init__(self, message)
         self.ctx = ctx
+        self.cmd = self.ctx and self.ctx.command or None
 
     def show(self, file=None):
         if file is None:
             file = get_text_stderr()
         color = None
+        hint = ''
+        if (self.cmd is not None and
+                self.cmd.get_help_option(self.ctx) is not None):
+            hint = ('Try "%s %s" for help.\n'
+                    % (self.ctx.command_path, self.ctx.help_option_names[0]))
         if self.ctx is not None:
             color = self.ctx.color
-            echo(self.ctx.get_usage() + '\n', file=file, color=color)
+            echo(self.ctx.get_usage() + '\n%s' % hint, file=file, color=color)
         echo('Error: %s' % self.format_message(), file=file, color=color)
 
 
@@ -76,11 +98,11 @@ class BadParameter(UsageError):
         if self.param_hint is not None:
             param_hint = self.param_hint
         elif self.param is not None:
-            param_hint = self.param.opts or [self.param.human_readable_name]
+            param_hint = self.param.get_error_hint(self.ctx)
         else:
             return 'Invalid value: %s' % self.message
-        if isinstance(param_hint, (tuple, list)):
-            param_hint = ' / '.join('"%s"' % x for x in param_hint)
+        param_hint = _join_param_hints(param_hint)
+
         return 'Invalid value for %s: %s' % (param_hint, self.message)
 
 
@@ -105,11 +127,10 @@ class MissingParameter(BadParameter):
         if self.param_hint is not None:
             param_hint = self.param_hint
         elif self.param is not None:
-            param_hint = self.param.opts or [self.param.human_readable_name]
+            param_hint = self.param.get_error_hint(self.ctx)
         else:
             param_hint = None
-        if isinstance(param_hint, (tuple, list)):
-            param_hint = ' / '.join('"%s"' % x for x in param_hint)
+        param_hint = _join_param_hints(param_hint)
 
         param_type = self.param_type
         if param_type is None and self.param is not None:
@@ -164,10 +185,13 @@ class BadOptionUsage(UsageError):
     for an option is not correct.
 
     .. versionadded:: 4.0
+
+    :param option_name: the name of the option being used incorrectly.
     """
 
-    def __init__(self, message, ctx=None):
+    def __init__(self, option_name, message, ctx=None):
         UsageError.__init__(self, message, ctx)
+        self.option_name = option_name
 
 
 class BadArgumentUsage(UsageError):
@@ -199,3 +223,13 @@ class FileError(ClickException):
 
 class Abort(RuntimeError):
     """An internal signalling exception that signals Click to abort."""
+
+
+class Exit(RuntimeError):
+    """An exception that indicates that the application should exit with some
+    status code.
+
+    :param code: the status code to exit with.
+    """
+    def __init__(self, code=0):
+        self.exit_code = code
diff --git a/pipenv/vendor/click/globals.py b/pipenv/vendor/click/globals.py
index 14338e6b..843b594a 100644
--- a/pipenv/vendor/click/globals.py
+++ b/pipenv/vendor/click/globals.py
@@ -9,7 +9,7 @@ def get_current_context(silent=False):
     access the current context object from anywhere.  This is a more implicit
     alternative to the :func:`pass_context` decorator.  This function is
     primarily useful for helpers such as :func:`echo` which might be
-    interested in changing it's behavior based on the current context.
+    interested in changing its behavior based on the current context.
 
     To push the current context, :meth:`Context.scope` can be used.
 
diff --git a/pipenv/vendor/click/parser.py b/pipenv/vendor/click/parser.py
index 9775c9ff..1c3ae9c8 100644
--- a/pipenv/vendor/click/parser.py
+++ b/pipenv/vendor/click/parser.py
@@ -1,20 +1,21 @@
 # -*- coding: utf-8 -*-
 """
-    click.parser
-    ~~~~~~~~~~~~
+click.parser
+~~~~~~~~~~~~
 
-    This module started out as largely a copy paste from the stdlib's
-    optparse module with the features removed that we do not need from
-    optparse because we implement them in Click on a higher level (for
-    instance type handling, help formatting and a lot more).
+This module started out as largely a copy paste from the stdlib's
+optparse module with the features removed that we do not need from
+optparse because we implement them in Click on a higher level (for
+instance type handling, help formatting and a lot more).
 
-    The plan is to remove more and more from here over time.
+The plan is to remove more and more from here over time.
 
-    The reason this is a different module and not optparse from the stdlib
-    is that there are differences in 2.x and 3.x about the error messages
-    generated and optparse in the stdlib uses gettext for no good reason
-    and might cause us issues.
+The reason this is a different module and not optparse from the stdlib
+is that there are differences in 2.x and 3.x about the error messages
+generated and optparse in the stdlib uses gettext for no good reason
+and might cause us issues.
 """
+
 import re
 from collections import deque
 from .exceptions import UsageError, NoSuchOption, BadOptionUsage, \
@@ -74,8 +75,8 @@ def _unpack_args(args, nargs_spec):
 
 def _error_opt_args(nargs, opt):
     if nargs == 1:
-        raise BadOptionUsage('%s option requires an argument' % opt)
-    raise BadOptionUsage('%s option requires %d arguments' % (opt, nargs))
+        raise BadOptionUsage(opt, '%s option requires an argument' % opt)
+    raise BadOptionUsage(opt, '%s option requires %d arguments' % (opt, nargs))
 
 
 def split_opt(opt):
@@ -321,7 +322,7 @@ class OptionParser(object):
         if opt not in self._long_opt:
             possibilities = [word for word in self._long_opt
                              if word.startswith(opt)]
-            raise NoSuchOption(opt, possibilities=possibilities)
+            raise NoSuchOption(opt, possibilities=possibilities, ctx=self.ctx)
 
         option = self._long_opt[opt]
         if option.takes_value:
@@ -342,7 +343,7 @@ class OptionParser(object):
                 del state.rargs[:nargs]
 
         elif explicit_value is not None:
-            raise BadOptionUsage('%s option does not take a value' % opt)
+            raise BadOptionUsage(opt, '%s option does not take a value' % opt)
 
         else:
             value = None
@@ -364,7 +365,7 @@ class OptionParser(object):
                 if self.ignore_unknown_options:
                     unknown_options.append(ch)
                     continue
-                raise NoSuchOption(opt)
+                raise NoSuchOption(opt, ctx=self.ctx)
             if option.takes_value:
                 # Any characters left in arg?  Pretend they're the
                 # next arg, and stop consuming characters of arg.
diff --git a/pipenv/vendor/click/termui.py b/pipenv/vendor/click/termui.py
index d9fba523..bf9a3aa1 100644
--- a/pipenv/vendor/click/termui.py
+++ b/pipenv/vendor/click/termui.py
@@ -1,12 +1,14 @@
 import os
 import sys
 import struct
+import inspect
+import itertools
 
 from ._compat import raw_input, text_type, string_types, \
      isatty, strip_ansi, get_winterm_size, DEFAULT_COLUMNS, WIN
 from .utils import echo
 from .exceptions import Abort, UsageError
-from .types import convert_type
+from .types import convert_type, Choice, Path
 from .globals import resolve_color_default
 
 
@@ -14,8 +16,25 @@ from .globals import resolve_color_default
 # functions to customize how they work.
 visible_prompt_func = raw_input
 
-_ansi_colors = ('black', 'red', 'green', 'yellow', 'blue', 'magenta',
-                'cyan', 'white', 'reset')
+_ansi_colors = {
+    'black': 30,
+    'red': 31,
+    'green': 32,
+    'yellow': 33,
+    'blue': 34,
+    'magenta': 35,
+    'cyan': 36,
+    'white': 37,
+    'reset': 39,
+    'bright_black': 90,
+    'bright_red': 91,
+    'bright_green': 92,
+    'bright_yellow': 93,
+    'bright_blue': 94,
+    'bright_magenta': 95,
+    'bright_cyan': 96,
+    'bright_white': 97,
+}
 _ansi_reset_all = '\033[0m'
 
 
@@ -24,23 +43,27 @@ def hidden_prompt_func(prompt):
     return getpass.getpass(prompt)
 
 
-def _build_prompt(text, suffix, show_default=False, default=None):
+def _build_prompt(text, suffix, show_default=False, default=None, show_choices=True, type=None):
     prompt = text
+    if type is not None and show_choices and isinstance(type, Choice):
+        prompt += ' (' + ", ".join(map(str, type.choices)) + ')'
     if default is not None and show_default:
         prompt = '%s [%s]' % (prompt, default)
     return prompt + suffix
 
 
-def prompt(text, default=None, hide_input=False,
-           confirmation_prompt=False, type=None,
-           value_proc=None, prompt_suffix=': ',
-           show_default=True, err=False):
+def prompt(text, default=None, hide_input=False, confirmation_prompt=False,
+           type=None, value_proc=None, prompt_suffix=': ', show_default=True,
+           err=False, show_choices=True):
     """Prompts a user for input.  This is a convenience function that can
     be used to prompt a user for input later.
 
     If the user aborts the input by sending a interrupt signal, this
     function will catch it and raise a :exc:`Abort` exception.
 
+    .. versionadded:: 7.0
+       Added the show_choices parameter.
+
     .. versionadded:: 6.0
        Added unicode support for cmd.exe on Windows.
 
@@ -61,6 +84,10 @@ def prompt(text, default=None, hide_input=False,
     :param show_default: shows or hides the default value in the prompt.
     :param err: if set to true the file defaults to ``stderr`` instead of
                 ``stdout``, the same as with echo.
+    :param show_choices: Show or hide choices if the passed type is a Choice.
+                         For example if type is a Choice of either day or week,
+                         show_choices is true and text is "Group by" then the
+                         prompt will be "Group by (day, week): ".
     """
     result = None
 
@@ -82,17 +109,18 @@ def prompt(text, default=None, hide_input=False,
     if value_proc is None:
         value_proc = convert_type(type, default)
 
-    prompt = _build_prompt(text, prompt_suffix, show_default, default)
+    prompt = _build_prompt(text, prompt_suffix, show_default, default, show_choices, type)
 
     while 1:
         while 1:
             value = prompt_func(prompt)
             if value:
                 break
-            # If a default is set and used, then the confirmation
-            # prompt is always skipped because that's the only thing
-            # that really makes sense.
             elif default is not None:
+                if isinstance(value_proc, Path):
+                    # validate Path default value(exists, dir_okay etc.)
+                    value = default
+                    break
                 return default
         try:
             result = value_proc(value)
@@ -166,8 +194,14 @@ def get_terminal_size():
             sz = shutil_get_terminal_size()
             return sz.columns, sz.lines
 
+    # We provide a sensible default for get_winterm_size() when being invoked
+    # inside a subprocess. Without this, it would not provide a useful input.
     if get_winterm_size is not None:
-        return get_winterm_size()
+        size = get_winterm_size()
+        if size == (0, 0):
+            return (79, 24)
+        else:
+            return size
 
     def ioctl_gwinsz(fd):
         try:
@@ -195,22 +229,33 @@ def get_terminal_size():
     return int(cr[1]), int(cr[0])
 
 
-def echo_via_pager(text, color=None):
+def echo_via_pager(text_or_generator, color=None):
     """This function takes a text and shows it via an environment specific
     pager on stdout.
 
     .. versionchanged:: 3.0
        Added the `color` flag.
 
-    :param text: the text to page.
+    :param text_or_generator: the text to page, or alternatively, a
+                              generator emitting the text to page.
     :param color: controls if the pager supports ANSI colors or not.  The
                   default is autodetection.
     """
     color = resolve_color_default(color)
-    if not isinstance(text, string_types):
-        text = text_type(text)
+
+    if inspect.isgeneratorfunction(text_or_generator):
+        i = text_or_generator()
+    elif isinstance(text_or_generator, string_types):
+        i = [text_or_generator]
+    else:
+        i = iter(text_or_generator)
+
+    # convert every element of i to a text type if necessary
+    text_generator = (el if isinstance(el, string_types) else text_type(el)
+                      for el in i)
+
     from ._termui_impl import pager
-    return pager(text + '\n', color)
+    return pager(itertools.chain(text_generator, "\n"), color)
 
 
 def progressbar(iterable=None, length=None, label=None, show_eta=True,
@@ -347,10 +392,21 @@ def style(text, fg=None, bg=None, bold=None, dim=None, underline=None,
     * ``magenta``
     * ``cyan``
     * ``white`` (might be light gray)
+    * ``bright_black``
+    * ``bright_red``
+    * ``bright_green``
+    * ``bright_yellow``
+    * ``bright_blue``
+    * ``bright_magenta``
+    * ``bright_cyan``
+    * ``bright_white``
     * ``reset`` (reset the color code only)
 
     .. versionadded:: 2.0
 
+    .. versionadded:: 7.0
+       Added support for bright colors.
+
     :param text: the string to style with ansi codes.
     :param fg: if provided this will become the foreground color.
     :param bg: if provided this will become the background color.
@@ -369,13 +425,13 @@ def style(text, fg=None, bg=None, bold=None, dim=None, underline=None,
     bits = []
     if fg:
         try:
-            bits.append('\033[%dm' % (_ansi_colors.index(fg) + 30))
-        except ValueError:
+            bits.append('\033[%dm' % (_ansi_colors[fg]))
+        except KeyError:
             raise TypeError('Unknown color %r' % fg)
     if bg:
         try:
-            bits.append('\033[%dm' % (_ansi_colors.index(bg) + 40))
-        except ValueError:
+            bits.append('\033[%dm' % (_ansi_colors[bg] + 10))
+        except KeyError:
             raise TypeError('Unknown color %r' % bg)
     if bold is not None:
         bits.append('\033[%dm' % (1 if bold else 22))
@@ -405,7 +461,7 @@ def unstyle(text):
     return strip_ansi(text)
 
 
-def secho(text, file=None, nl=True, err=False, color=None, **styles):
+def secho(message=None, file=None, nl=True, err=False, color=None, **styles):
     """This function combines :func:`echo` and :func:`style` into one
     call.  As such the following two calls are the same::
 
@@ -417,7 +473,9 @@ def secho(text, file=None, nl=True, err=False, color=None, **styles):
 
     .. versionadded:: 2.0
     """
-    return echo(style(text, **styles), file=file, nl=nl, err=err, color=color)
+    if message is not None:
+        message = style(message, **styles)
+    return echo(message, file=file, nl=nl, err=err, color=color)
 
 
 def edit(text=None, editor=None, env=None, require_save=True,
@@ -466,7 +524,7 @@ def launch(url, wait=False, locate=False):
 
     Examples::
 
-        click.launch('http://click.pocoo.org/')
+        click.launch('https://click.palletsprojects.com/')
         click.launch('/my/downloaded/file', locate=True)
 
     .. versionadded:: 2.0
@@ -499,6 +557,10 @@ def getchar(echo=False):
     Note that this will always read from the terminal, even if something
     is piped into the standard input.
 
+    Note for Windows: in rare cases when typing non-ASCII characters, this
+    function might wait for a second character and then return both at once.
+    This is because certain Unicode characters look like special-key markers.
+
     .. versionadded:: 2.0
 
     :param echo: if set to `True`, the character read will also show up on
@@ -510,6 +572,11 @@ def getchar(echo=False):
     return f(echo)
 
 
+def raw_terminal():
+    from ._termui_impl import raw_terminal as f
+    return f()
+
+
 def pause(info='Press any key to continue ...', err=False):
     """This command stops execution and waits for the user to press any
     key to continue.  This is similar to the Windows batch "pause"
diff --git a/pipenv/vendor/click/testing.py b/pipenv/vendor/click/testing.py
index 4416c774..1b2924e0 100644
--- a/pipenv/vendor/click/testing.py
+++ b/pipenv/vendor/click/testing.py
@@ -3,8 +3,9 @@ import sys
 import shutil
 import tempfile
 import contextlib
+import shlex
 
-from ._compat import iteritems, PY2
+from ._compat import iteritems, PY2, string_types
 
 
 # If someone wants to vendor click, we want to ensure the
@@ -72,27 +73,44 @@ def make_input_stream(input, charset):
 class Result(object):
     """Holds the captured result of an invoked CLI script."""
 
-    def __init__(self, runner, output_bytes, exit_code, exception,
-                 exc_info=None):
+    def __init__(self, runner, stdout_bytes, stderr_bytes, exit_code,
+                 exception, exc_info=None):
         #: The runner that created the result
         self.runner = runner
-        #: The output as bytes.
-        self.output_bytes = output_bytes
+        #: The standard output as bytes.
+        self.stdout_bytes = stdout_bytes
+        #: The standard error as bytes, or False(y) if not available
+        self.stderr_bytes = stderr_bytes
         #: The exit code as integer.
         self.exit_code = exit_code
-        #: The exception that happend if one did.
+        #: The exception that happened if one did.
         self.exception = exception
         #: The traceback
         self.exc_info = exc_info
 
     @property
     def output(self):
-        """The output as unicode string."""
-        return self.output_bytes.decode(self.runner.charset, 'replace') \
+        """The (standard) output as unicode string."""
+        return self.stdout
+
+    @property
+    def stdout(self):
+        """The standard output as unicode string."""
+        return self.stdout_bytes.decode(self.runner.charset, 'replace') \
+            .replace('\r\n', '\n')
+
+    @property
+    def stderr(self):
+        """The standard error as unicode string."""
+        if not self.stderr_bytes:
+            raise ValueError("stderr not separately captured")
+        return self.stderr_bytes.decode(self.runner.charset, 'replace') \
             .replace('\r\n', '\n')
 
+
     def __repr__(self):
-        return '<Result %s>' % (
+        return '<%s %s>' % (
+            type(self).__name__,
             self.exception and repr(self.exception) or 'okay',
         )
 
@@ -111,14 +129,21 @@ class CliRunner(object):
                        to stdout.  This is useful for showing examples in
                        some circumstances.  Note that regular prompts
                        will automatically echo the input.
+    :param mix_stderr: if this is set to `False`, then stdout and stderr are
+                       preserved as independent streams.  This is useful for
+                       Unix-philosophy apps that have predictable stdout and
+                       noisy stderr, such that each may be measured
+                       independently
     """
 
-    def __init__(self, charset=None, env=None, echo_stdin=False):
+    def __init__(self, charset=None, env=None, echo_stdin=False,
+                 mix_stderr=True):
         if charset is None:
             charset = 'utf-8'
         self.charset = charset
         self.env = env or {}
         self.echo_stdin = echo_stdin
+        self.mix_stderr = mix_stderr
 
     def get_default_prog_name(self, cli):
         """Given a command object it will return the default program name
@@ -163,16 +188,27 @@ class CliRunner(object):
         env = self.make_env(env)
 
         if PY2:
-            sys.stdout = sys.stderr = bytes_output = StringIO()
+            bytes_output = StringIO()
             if self.echo_stdin:
                 input = EchoingStdin(input, bytes_output)
+            sys.stdout = bytes_output
+            if not self.mix_stderr:
+                bytes_error = StringIO()
+                sys.stderr = bytes_error
         else:
             bytes_output = io.BytesIO()
             if self.echo_stdin:
                 input = EchoingStdin(input, bytes_output)
             input = io.TextIOWrapper(input, encoding=self.charset)
-            sys.stdout = sys.stderr = io.TextIOWrapper(
+            sys.stdout = io.TextIOWrapper(
                 bytes_output, encoding=self.charset)
+            if not self.mix_stderr:
+                bytes_error = io.BytesIO()
+                sys.stderr = io.TextIOWrapper(
+                    bytes_error, encoding=self.charset)
+
+        if self.mix_stderr:
+            sys.stderr = sys.stdout
 
         sys.stdin = input
 
@@ -196,6 +232,7 @@ class CliRunner(object):
             return char
 
         default_color = color
+
         def should_strip_ansi(stream=None, color=None):
             if color is None:
                 return not default_color
@@ -221,7 +258,7 @@ class CliRunner(object):
                         pass
                 else:
                     os.environ[key] = value
-            yield bytes_output
+            yield (bytes_output, not self.mix_stderr and bytes_error)
         finally:
             for key, value in iteritems(old_env):
                 if value is None:
@@ -241,7 +278,7 @@ class CliRunner(object):
             clickpkg.formatting.FORCED_WIDTH = old_forced_width
 
     def invoke(self, cli, args=None, input=None, env=None,
-               catch_exceptions=True, color=False, **extra):
+               catch_exceptions=True, color=False, mix_stderr=False, **extra):
         """Invokes a command in an isolated environment.  The arguments are
         forwarded directly to the command line script, the `extra` keyword
         arguments are passed to the :meth:`~clickpkg.Command.main` function of
@@ -260,7 +297,10 @@ class CliRunner(object):
            The ``color`` parameter was added.
 
         :param cli: the command to invoke
-        :param args: the arguments to invoke
+        :param args: the arguments to invoke. It may be given as an iterable
+                     or a string. When given as string it will be interpreted
+                     as a Unix shell command. More details at
+                     :func:`shlex.split`.
         :param input: the input data for `sys.stdin`.
         :param env: the environment overrides.
         :param catch_exceptions: Whether to catch any other exceptions than
@@ -270,36 +310,48 @@ class CliRunner(object):
                       application can still override this explicitly.
         """
         exc_info = None
-        with self.isolation(input=input, env=env, color=color) as out:
+        with self.isolation(input=input, env=env, color=color) as outstreams:
             exception = None
             exit_code = 0
 
+            if isinstance(args, string_types):
+                args = shlex.split(args)
+
             try:
-                cli.main(args=args or (),
-                         prog_name=self.get_default_prog_name(cli), **extra)
-            except SystemExit as e:
-                if e.code != 0:
-                    exception = e
+                prog_name = extra.pop("prog_name")
+            except KeyError:
+                prog_name = self.get_default_prog_name(cli)
 
+            try:
+                cli.main(args=args or (), prog_name=prog_name, **extra)
+            except SystemExit as e:
                 exc_info = sys.exc_info()
-
                 exit_code = e.code
+                if exit_code is None:
+                    exit_code = 0
+
+                if exit_code != 0:
+                    exception = e
+
                 if not isinstance(exit_code, int):
                     sys.stdout.write(str(exit_code))
                     sys.stdout.write('\n')
                     exit_code = 1
+
             except Exception as e:
                 if not catch_exceptions:
                     raise
                 exception = e
-                exit_code = -1
+                exit_code = 1
                 exc_info = sys.exc_info()
             finally:
                 sys.stdout.flush()
-                output = out.getvalue()
+                stdout = outstreams[0].getvalue()
+                stderr = outstreams[1] and outstreams[1].getvalue()
 
         return Result(runner=self,
-                      output_bytes=output,
+                      stdout_bytes=stdout,
+                      stderr_bytes=stderr,
                       exit_code=exit_code,
                       exception=exception,
                       exc_info=exc_info)
diff --git a/pipenv/vendor/click/types.py b/pipenv/vendor/click/types.py
index 36390026..1f88032f 100644
--- a/pipenv/vendor/click/types.py
+++ b/pipenv/vendor/click/types.py
@@ -1,5 +1,6 @@
 import os
 import stat
+from datetime import datetime
 
 from ._compat import open_stream, text_type, filename_to_ui, \
     get_filesystem_encoding, get_streerror, _get_argv_encoding, PY2
@@ -126,34 +127,54 @@ class StringParamType(ParamType):
 
 
 class Choice(ParamType):
-    """The choice type allows a value to be checked against a fixed set of
-    supported values.  All of these values have to be strings.
+    """The choice type allows a value to be checked against a fixed set
+    of supported values. All of these values have to be strings.
+
+    You should only pass a list or tuple of choices. Other iterables
+    (like generators) may lead to surprising results.
 
     See :ref:`choice-opts` for an example.
+
+    :param case_sensitive: Set to false to make choices case
+        insensitive. Defaults to true.
     """
+
     name = 'choice'
 
-    def __init__(self, choices):
+    def __init__(self, choices, case_sensitive=True):
         self.choices = choices
+        self.case_sensitive = case_sensitive
 
     def get_metavar(self, param):
         return '[%s]' % '|'.join(self.choices)
 
     def get_missing_message(self, param):
-        return 'Choose from %s.' % ', '.join(self.choices)
+        return 'Choose from:\n\t%s.' % ',\n\t'.join(self.choices)
 
     def convert(self, value, param, ctx):
         # Exact match
         if value in self.choices:
             return value
 
-        # Match through normalization
+        # Match through normalization and case sensitivity
+        # first do token_normalize_func, then lowercase
+        # preserve original `value` to produce an accurate message in
+        # `self.fail`
+        normed_value = value
+        normed_choices = self.choices
+
         if ctx is not None and \
            ctx.token_normalize_func is not None:
-            value = ctx.token_normalize_func(value)
-            for choice in self.choices:
-                if ctx.token_normalize_func(choice) == value:
-                    return choice
+            normed_value = ctx.token_normalize_func(value)
+            normed_choices = [ctx.token_normalize_func(choice) for choice in
+                              self.choices]
+
+        if not self.case_sensitive:
+            normed_value = normed_value.lower()
+            normed_choices = [choice.lower() for choice in normed_choices]
+
+        if normed_value in normed_choices:
+            return normed_value
 
         self.fail('invalid choice: %s. (choose from %s)' %
                   (value, ', '.join(self.choices)), param, ctx)
@@ -162,6 +183,59 @@ class Choice(ParamType):
         return 'Choice(%r)' % list(self.choices)
 
 
+class DateTime(ParamType):
+    """The DateTime type converts date strings into `datetime` objects.
+
+    The format strings which are checked are configurable, but default to some
+    common (non-timezone aware) ISO 8601 formats.
+
+    When specifying *DateTime* formats, you should only pass a list or a tuple.
+    Other iterables, like generators, may lead to surprising results.
+
+    The format strings are processed using ``datetime.strptime``, and this
+    consequently defines the format strings which are allowed.
+
+    Parsing is tried using each format, in order, and the first format which
+    parses successfully is used.
+
+    :param formats: A list or tuple of date format strings, in the order in
+                    which they should be tried. Defaults to
+                    ``'%Y-%m-%d'``, ``'%Y-%m-%dT%H:%M:%S'``,
+                    ``'%Y-%m-%d %H:%M:%S'``.
+    """
+    name = 'datetime'
+
+    def __init__(self, formats=None):
+        self.formats = formats or [
+            '%Y-%m-%d',
+            '%Y-%m-%dT%H:%M:%S',
+            '%Y-%m-%d %H:%M:%S'
+        ]
+
+    def get_metavar(self, param):
+        return '[{}]'.format('|'.join(self.formats))
+
+    def _try_to_convert_date(self, value, format):
+        try:
+            return datetime.strptime(value, format)
+        except ValueError:
+            return None
+
+    def convert(self, value, param, ctx):
+        # Exact match
+        for format in self.formats:
+            dtime = self._try_to_convert_date(value, format)
+            if dtime:
+                return dtime
+
+        self.fail(
+            'invalid datetime format: {}. (choose from {})'.format(
+                value, ', '.join(self.formats)))
+
+    def __repr__(self):
+        return 'DateTime'
+
+
 class IntParamType(ParamType):
     name = 'integer'
 
@@ -214,6 +288,59 @@ class IntRange(IntParamType):
         return 'IntRange(%r, %r)' % (self.min, self.max)
 
 
+class FloatParamType(ParamType):
+    name = 'float'
+
+    def convert(self, value, param, ctx):
+        try:
+            return float(value)
+        except (UnicodeError, ValueError):
+            self.fail('%s is not a valid floating point value' %
+                      value, param, ctx)
+
+    def __repr__(self):
+        return 'FLOAT'
+
+
+class FloatRange(FloatParamType):
+    """A parameter that works similar to :data:`click.FLOAT` but restricts
+    the value to fit into a range.  The default behavior is to fail if the
+    value falls outside the range, but it can also be silently clamped
+    between the two edges.
+
+    See :ref:`ranges` for an example.
+    """
+    name = 'float range'
+
+    def __init__(self, min=None, max=None, clamp=False):
+        self.min = min
+        self.max = max
+        self.clamp = clamp
+
+    def convert(self, value, param, ctx):
+        rv = FloatParamType.convert(self, value, param, ctx)
+        if self.clamp:
+            if self.min is not None and rv < self.min:
+                return self.min
+            if self.max is not None and rv > self.max:
+                return self.max
+        if self.min is not None and rv < self.min or \
+           self.max is not None and rv > self.max:
+            if self.min is None:
+                self.fail('%s is bigger than the maximum valid value '
+                          '%s.' % (rv, self.max), param, ctx)
+            elif self.max is None:
+                self.fail('%s is smaller than the minimum valid value '
+                          '%s.' % (rv, self.min), param, ctx)
+            else:
+                self.fail('%s is not in the valid range of %s to %s.'
+                          % (rv, self.min, self.max), param, ctx)
+        return rv
+
+    def __repr__(self):
+        return 'FloatRange(%r, %r)' % (self.min, self.max)
+
+
 class BoolParamType(ParamType):
     name = 'boolean'
 
@@ -221,9 +348,9 @@ class BoolParamType(ParamType):
         if isinstance(value, bool):
             return bool(value)
         value = value.lower()
-        if value in ('true', '1', 'yes', 'y'):
+        if value in ('true', 't', '1', 'yes', 'y'):
             return True
-        elif value in ('false', '0', 'no', 'n'):
+        elif value in ('false', 'f', '0', 'no', 'n'):
             return False
         self.fail('%s is not a valid boolean' % value, param, ctx)
 
@@ -231,20 +358,6 @@ class BoolParamType(ParamType):
         return 'BOOL'
 
 
-class FloatParamType(ParamType):
-    name = 'float'
-
-    def convert(self, value, param, ctx):
-        try:
-            return float(value)
-        except (UnicodeError, ValueError):
-            self.fail('%s is not a valid floating point value' %
-                      value, param, ctx)
-
-    def __repr__(self):
-        return 'FLOAT'
-
-
 class UUIDParameterType(ParamType):
     name = 'uuid'
 
@@ -273,9 +386,12 @@ class File(ParamType):
     opened in binary mode or for writing.  The encoding parameter can be used
     to force a specific encoding.
 
-    The `lazy` flag controls if the file should be opened immediately or
-    upon first IO.  The default is to be non lazy for standard input and
-    output streams as well as files opened for reading, lazy otherwise.
+    The `lazy` flag controls if the file should be opened immediately or upon
+    first IO. The default is to be non-lazy for standard input and output
+    streams as well as files opened for reading, `lazy` otherwise. When opening a
+    file lazily for reading, it is still opened temporarily for validation, but
+    will not be held open until first IO. lazy is mainly useful when opening
+    for writing to avoid creating the file until it is needed.
 
     Starting with Click 2.0, files can also be opened atomically in which
     case all writes go into a separate file in the same folder and upon
@@ -358,14 +474,16 @@ class Path(ParamType):
     :param readable: if true, a readable check is performed.
     :param resolve_path: if this is true, then the path is fully resolved
                          before the value is passed onwards.  This means
-                         that it's absolute and symlinks are resolved.
+                         that it's absolute and symlinks are resolved.  It
+                         will not expand a tilde-prefix, as this is
+                         supposed to be done by the shell only.
     :param allow_dash: If this is set to `True`, a single dash to indicate
                        standard streams is permitted.
-    :param type: optionally a string type that should be used to
-                 represent the path.  The default is `None` which
-                 means the return value will be either bytes or
-                 unicode depending on what makes most sense given the
-                 input data Click deals with.
+    :param path_type: optionally a string type that should be used to
+                      represent the path.  The default is `None` which
+                      means the return value will be either bytes or
+                      unicode depending on what makes most sense given the
+                      input data Click deals with.
     """
     envvar_list_splitter = os.path.pathsep
 
@@ -384,7 +502,7 @@ class Path(ParamType):
         if self.file_okay and not self.dir_okay:
             self.name = 'file'
             self.path_type = 'File'
-        if self.dir_okay and not self.file_okay:
+        elif self.dir_okay and not self.file_okay:
             self.name = 'directory'
             self.path_type = 'Directory'
         else:
diff --git a/pipenv/vendor/click/utils.py b/pipenv/vendor/click/utils.py
index eee626d3..fc84369f 100644
--- a/pipenv/vendor/click/utils.py
+++ b/pipenv/vendor/click/utils.py
@@ -43,6 +43,7 @@ def make_str(value):
 
 
 def make_default_short_help(help, max_length=45):
+    """Return a condensed version of help string."""
     words = help.split()
     total_length = 0
     result = []
@@ -171,7 +172,7 @@ def echo(message=None, file=None, nl=True, err=False, color=None):
 
     Primarily it means that you can print binary data as well as Unicode
     data on both 2.x and 3.x to the given file in the most appropriate way
-    possible.  This is a very carefree function as in that it will try its
+    possible.  This is a very carefree function in that it will try its
     best to not fail.  As of Click 6.0 this includes support for unicode
     output on the Windows console.
 
@@ -183,7 +184,7 @@ def echo(message=None, file=None, nl=True, err=False, color=None):
     -   hide ANSI codes automatically if the destination file is not a
         terminal.
 
-    .. _colorama: http://pypi.python.org/pypi/colorama
+    .. _colorama: https://pypi.org/project/colorama/
 
     .. versionchanged:: 6.0
        As of Click 6.0 the echo function will properly support unicode
@@ -413,3 +414,27 @@ def get_app_dir(app_name, roaming=True, force_posix=False):
     return os.path.join(
         os.environ.get('XDG_CONFIG_HOME', os.path.expanduser('~/.config')),
         _posixify(app_name))
+
+
+class PacifyFlushWrapper(object):
+    """This wrapper is used to catch and suppress BrokenPipeErrors resulting
+    from ``.flush()`` being called on broken pipe during the shutdown/final-GC
+    of the Python interpreter. Notably ``.flush()`` is always called on
+    ``sys.stdout`` and ``sys.stderr``. So as to have minimal impact on any
+    other cleanup code, and the case where the underlying file is not a broken
+    pipe, all calls and attributes are proxied.
+    """
+
+    def __init__(self, wrapped):
+        self.wrapped = wrapped
+
+    def flush(self):
+        try:
+            self.wrapped.flush()
+        except IOError as e:
+            import errno
+            if e.errno != errno.EPIPE:
+                raise
+
+    def __getattr__(self, attr):
+        return getattr(self.wrapped, attr)
diff --git a/pipenv/vendor/delegator.py b/pipenv/vendor/delegator.py
index 5820db7b..d15aeb97 100644
--- a/pipenv/vendor/delegator.py
+++ b/pipenv/vendor/delegator.py
@@ -4,6 +4,7 @@ import shlex
 import signal
 import sys
 import locale
+import errno
 
 from pexpect.popen_spawn import PopenSpawn
 
@@ -11,12 +12,40 @@ from pexpect.popen_spawn import PopenSpawn
 try:
     STR_TYPES = (str, unicode)
 except NameError:
-    STR_TYPES = (str, )
+    STR_TYPES = (str,)
 
 TIMEOUT = 30
 
-class Command(object):
 
+def pid_exists(pid):
+    """Check whether pid exists in the current process table."""
+    if pid == 0:
+        # According to "man 2 kill" PID 0 has a special meaning:
+        # it refers to <<every process in the process group of the
+        # calling process>> so we don't want to go any further.
+        # If we get here it means this UNIX platform *does* have
+        # a process with id 0.
+        return True
+    try:
+        os.kill(pid, 0)
+    except OSError as err:
+        if err.errno == errno.ESRCH:
+            # ESRCH == No such process
+            return False
+        elif err.errno == errno.EPERM:
+            # EPERM clearly means there's a process to deny access to
+            return True
+        else:
+            # According to "man 2 kill" possible error values are
+            # (EINVAL, EPERM, ESRCH) therefore we should never get
+            # here. If we do let's be explicit in considering this
+            # an error.
+            raise err
+    else:
+        return True
+
+
+class Command(object):
     def __init__(self, cmd, timeout=TIMEOUT):
         super(Command, self).__init__()
         self.cmd = cmd
@@ -28,7 +57,7 @@ class Command(object):
         self.__err = None
 
     def __repr__(self):
-        return '<Command {!r}>'.format(self.cmd)
+        return "<Command {!r}>".format(self.cmd)
 
     @property
     def _popen_args(self):
@@ -37,27 +66,23 @@ class Command(object):
     @property
     def _default_popen_kwargs(self):
         return {
-            'env': os.environ.copy(),
-            'stdin': subprocess.PIPE,
-            'stdout': subprocess.PIPE,
-            'stderr': subprocess.PIPE,
-            'shell': True,
-            'universal_newlines': True,
-            'bufsize': 0
+            "env": os.environ.copy(),
+            "stdin": subprocess.PIPE,
+            "stdout": subprocess.PIPE,
+            "stderr": subprocess.PIPE,
+            "shell": True,
+            "universal_newlines": True,
+            "bufsize": 0,
         }
 
     @property
     def _default_pexpect_kwargs(self):
-        encoding = 'utf-8'
-        if sys.platform == 'win32':
+        encoding = "utf-8"
+        if sys.platform == "win32":
             default_encoding = locale.getdefaultlocale()[1]
             if default_encoding is not None:
                 encoding = default_encoding
-        return {
-            'env': os.environ.copy(),
-            'encoding': encoding,
-            'timeout': self.timeout
-        }
+        return {"env": os.environ.copy(), "encoding": encoding, "timeout": self.timeout}
 
     @property
     def _uses_subprocess(self):
@@ -71,12 +96,16 @@ class Command(object):
     def std_out(self):
         return self.subprocess.stdout
 
+    @property
+    def ok(self):
+        return self.return_code == 0
+
     @property
     def _pexpect_out(self):
         if self.subprocess.encoding:
-            result = ''
+            result = ""
         else:
-            result = b''
+            result = b""
 
         if self.subprocess.before:
             result += self.subprocess.before
@@ -120,11 +149,16 @@ class Command(object):
     def pid(self):
         """The process' PID."""
         # Support for pexpect's functionality.
-        if hasattr(self.subprocess, 'proc'):
+        if hasattr(self.subprocess, "proc"):
             return self.subprocess.proc.pid
         # Standard subprocess method.
         return self.subprocess.pid
 
+    @property
+    def is_alive(self):
+        """Is the process alive?"""
+        return pid_exists(self.pid)
+
     @property
     def return_code(self):
         # Support for pexpect's functionality.
@@ -144,23 +178,23 @@ class Command(object):
         # Use subprocess.
         if self.blocking:
             popen_kwargs = self._default_popen_kwargs.copy()
-            popen_kwargs['universal_newlines'] = not binary
+            popen_kwargs["universal_newlines"] = not binary
             if cwd:
-                popen_kwargs['cwd'] = cwd
+                popen_kwargs["cwd"] = cwd
             if env:
-                popen_kwargs['env'].update(env)
+                popen_kwargs["env"].update(env)
             s = subprocess.Popen(self._popen_args, **popen_kwargs)
         # Otherwise, use pexpect.
         else:
             pexpect_kwargs = self._default_pexpect_kwargs.copy()
             if binary:
-                pexpect_kwargs['encoding'] = None
+                pexpect_kwargs["encoding"] = None
             if cwd:
-                pexpect_kwargs['cwd'] = cwd
+                pexpect_kwargs["cwd"] = cwd
             if env:
-                pexpect_kwargs['env'].update(env)
+                pexpect_kwargs["env"].update(env)
             # Enable Python subprocesses to work with expect functionality.
-            pexpect_kwargs['env']['PYTHONUNBUFFERED'] = '1'
+            pexpect_kwargs["env"]["PYTHONUNBUFFERED"] = "1"
             s = PopenSpawn(self._popen_args, **pexpect_kwargs)
         self.subprocess = s
         self.was_run = True
@@ -169,7 +203,7 @@ class Command(object):
         """Waits on the given pattern to appear in std_out"""
 
         if self.blocking:
-            raise RuntimeError('expect can only be used on non-blocking commands.')
+            raise RuntimeError("expect can only be used on non-blocking commands.")
 
         self.subprocess.expect(pattern=pattern, timeout=timeout)
 
@@ -177,7 +211,7 @@ class Command(object):
         """Sends the given string or signal to std_in."""
 
         if self.blocking:
-            raise RuntimeError('send can only be used on non-blocking commands.')
+            raise RuntimeError("send can only be used on non-blocking commands.")
 
         if not signal:
             if self._uses_subprocess:
@@ -191,7 +225,10 @@ class Command(object):
         self.subprocess.terminate()
 
     def kill(self):
-        self.subprocess.kill(signal.SIGINT)
+        if self._uses_pexpect:
+            self.subprocess.kill(signal.SIGINT)
+        else:
+            self.subprocess.send_signal(signal.SIGINT)
 
     def block(self):
         """Blocks until process is complete."""
@@ -237,12 +274,12 @@ def _expand_args(command):
     # Prepare arguments.
     if isinstance(command, STR_TYPES):
         if sys.version_info[0] == 2:
-            splitter = shlex.shlex(command.encode('utf-8'))
+            splitter = shlex.shlex(command.encode("utf-8"))
         elif sys.version_info[0] == 3:
             splitter = shlex.shlex(command)
         else:
-            splitter = shlex.shlex(command.encode('utf-8'))
-        splitter.whitespace = '|'
+            splitter = shlex.shlex(command.encode("utf-8"))
+        splitter.whitespace = "|"
         splitter.whitespace_split = True
         command = []
 
@@ -283,4 +320,3 @@ def run(command, block=True, binary=False, timeout=TIMEOUT, cwd=None, env=None):
         c.block()
 
     return c
-
diff --git a/pipenv/vendor/distlib/__init__.py b/pipenv/vendor/distlib/__init__.py
index d4aab453..a786b4d3 100644
--- a/pipenv/vendor/distlib/__init__.py
+++ b/pipenv/vendor/distlib/__init__.py
@@ -6,7 +6,7 @@
 #
 import logging
 
-__version__ = '0.2.7'
+__version__ = '0.2.8'
 
 class DistlibException(Exception):
     pass
diff --git a/pipenv/vendor/distlib/database.py b/pipenv/vendor/distlib/database.py
index a19905e2..b13cdac9 100644
--- a/pipenv/vendor/distlib/database.py
+++ b/pipenv/vendor/distlib/database.py
@@ -20,7 +20,8 @@ import zipimport
 from . import DistlibException, resources
 from .compat import StringIO
 from .version import get_scheme, UnsupportedVersionError
-from .metadata import Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME
+from .metadata import (Metadata, METADATA_FILENAME, WHEEL_METADATA_FILENAME,
+                       LEGACY_METADATA_FILENAME)
 from .util import (parse_requirement, cached_property, parse_name_and_version,
                    read_exports, write_exports, CSVReader, CSVWriter)
 
@@ -132,7 +133,9 @@ class DistributionPath(object):
                 if not r or r.path in seen:
                     continue
                 if self._include_dist and entry.endswith(DISTINFO_EXT):
-                    possible_filenames = [METADATA_FILENAME, WHEEL_METADATA_FILENAME]
+                    possible_filenames = [METADATA_FILENAME,
+                                          WHEEL_METADATA_FILENAME,
+                                          LEGACY_METADATA_FILENAME]
                     for metadata_filename in possible_filenames:
                         metadata_path = posixpath.join(entry, metadata_filename)
                         pydist = finder.find(metadata_path)
diff --git a/pipenv/vendor/distlib/locators.py b/pipenv/vendor/distlib/locators.py
index 11d26361..5c655c3e 100644
--- a/pipenv/vendor/distlib/locators.py
+++ b/pipenv/vendor/distlib/locators.py
@@ -255,7 +255,9 @@ class Locator(object):
         if path.endswith('.whl'):
             try:
                 wheel = Wheel(path)
-                if is_compatible(wheel, self.wheel_tags):
+                if not is_compatible(wheel, self.wheel_tags):
+                    logger.debug('Wheel not compatible: %s', path)
+                else:
                     if project_name is None:
                         include = True
                     else:
@@ -613,6 +615,7 @@ class SimpleScrapingLocator(Locator):
         # as it is for coordinating our internal threads - the ones created
         # in _prepare_threads.
         self._gplock = threading.RLock()
+        self.platform_check = False  # See issue #112
 
     def _prepare_threads(self):
         """
@@ -658,8 +661,8 @@ class SimpleScrapingLocator(Locator):
             del self.result
         return result
 
-    platform_dependent = re.compile(r'\b(linux-(i\d86|x86_64|arm\w+)|'
-                                    r'win(32|-amd64)|macosx-?\d+)\b', re.I)
+    platform_dependent = re.compile(r'\b(linux_(i\d86|x86_64|arm\w+)|'
+                                    r'win(32|_amd64)|macosx_?\d+)\b', re.I)
 
     def _is_platform_dependent(self, url):
         """
@@ -677,7 +680,7 @@ class SimpleScrapingLocator(Locator):
         Note that the return value isn't actually used other than as a boolean
         value.
         """
-        if self._is_platform_dependent(url):
+        if self.platform_check and self._is_platform_dependent(url):
             info = None
         else:
             info = self.convert_url_to_download_info(url, self.project_name)
diff --git a/pipenv/vendor/distlib/metadata.py b/pipenv/vendor/distlib/metadata.py
index 6d6470ff..77eed7f9 100644
--- a/pipenv/vendor/distlib/metadata.py
+++ b/pipenv/vendor/distlib/metadata.py
@@ -91,7 +91,9 @@ _426_FIELDS = ('Metadata-Version', 'Name', 'Version', 'Platform',
 _426_MARKERS = ('Private-Version', 'Provides-Extra', 'Obsoleted-By',
                 'Setup-Requires-Dist', 'Extension')
 
-_566_FIELDS = _426_FIELDS + ('Description-Content-Type',)
+# See issue #106: Sometimes 'Requires' occurs wrongly in the metadata. Include
+# it in the tuple literal below to allow it (for now)
+_566_FIELDS = _426_FIELDS + ('Description-Content-Type', 'Requires')
 
 _566_MARKERS = ('Description-Content-Type',)
 
@@ -377,8 +379,8 @@ class LegacyMetadata(object):
                 value = msg[field]
                 if value is not None and value != 'UNKNOWN':
                     self.set(field, value)
-        logger.debug('Attempting to set metadata for %s', self)
-        self.set_metadata_version()
+        # logger.debug('Attempting to set metadata for %s', self)
+        # self.set_metadata_version()
 
     def write(self, filepath, skip_unknown=False):
         """Write the metadata fields to filepath."""
@@ -648,6 +650,7 @@ class LegacyMetadata(object):
 
 METADATA_FILENAME = 'pydist.json'
 WHEEL_METADATA_FILENAME = 'metadata.json'
+LEGACY_METADATA_FILENAME = 'METADATA'
 
 
 class Metadata(object):
diff --git a/pipenv/vendor/distlib/scripts.py b/pipenv/vendor/distlib/scripts.py
index 0b7c3d0b..8e22cb91 100644
--- a/pipenv/vendor/distlib/scripts.py
+++ b/pipenv/vendor/distlib/scripts.py
@@ -236,8 +236,10 @@ class ScriptMaker(object):
     def _write_script(self, names, shebang, script_bytes, filenames, ext):
         use_launcher = self.add_launchers and self._is_nt
         linesep = os.linesep.encode('utf-8')
+        if not shebang.endswith(linesep):
+            shebang += linesep
         if not use_launcher:
-            script_bytes = shebang + linesep + script_bytes
+            script_bytes = shebang + script_bytes
         else:  # pragma: no cover
             if ext == 'py':
                 launcher = self._get_launcher('t')
@@ -247,7 +249,7 @@ class ScriptMaker(object):
             with ZipFile(stream, 'w') as zf:
                 zf.writestr('__main__.py', script_bytes)
             zip_data = stream.getvalue()
-            script_bytes = launcher + shebang + linesep + zip_data
+            script_bytes = launcher + shebang + zip_data
         for name in names:
             outname = os.path.join(self.target_dir, name)
             if use_launcher:  # pragma: no cover
diff --git a/pipenv/vendor/distlib/util.py b/pipenv/vendor/distlib/util.py
index 0b14a93b..9d4bfd3b 100644
--- a/pipenv/vendor/distlib/util.py
+++ b/pipenv/vendor/distlib/util.py
@@ -545,16 +545,14 @@ class FileOperator(object):
     def write_binary_file(self, path, data):
         self.ensure_dir(os.path.dirname(path))
         if not self.dry_run:
+            if os.path.exists(path):
+                os.remove(path)
             with open(path, 'wb') as f:
                 f.write(data)
         self.record_as_written(path)
 
     def write_text_file(self, path, data, encoding):
-        self.ensure_dir(os.path.dirname(path))
-        if not self.dry_run:
-            with open(path, 'wb') as f:
-                f.write(data.encode(encoding))
-        self.record_as_written(path)
+        self.write_binary_file(path, data.encode(encoding))
 
     def set_mode(self, bits, mask, files):
         if os.name == 'posix' or (os.name == 'java' and os._name == 'posix'):
@@ -582,7 +580,7 @@ class FileOperator(object):
             if self.record:
                 self.dirs_created.add(path)
 
-    def byte_compile(self, path, optimize=False, force=False, prefix=None):
+    def byte_compile(self, path, optimize=False, force=False, prefix=None, hashed_invalidation=False):
         dpath = cache_from_source(path, not optimize)
         logger.info('Byte-compiling %s to %s', path, dpath)
         if not self.dry_run:
@@ -592,7 +590,10 @@ class FileOperator(object):
                 else:
                     assert path.startswith(prefix)
                     diagpath = path[len(prefix):]
-            py_compile.compile(path, dpath, diagpath, True)     # raise error
+            compile_kwargs = {}
+            if hashed_invalidation and hasattr(py_compile, 'PycInvalidationMode'):
+                compile_kwargs['invalidation_mode'] = py_compile.PycInvalidationMode.CHECKED_HASH
+            py_compile.compile(path, dpath, diagpath, True, **compile_kwargs)     # raise error
         self.record_as_written(dpath)
         return dpath
 
diff --git a/pipenv/vendor/distlib/wheel.py b/pipenv/vendor/distlib/wheel.py
index 77372235..b04bfaef 100644
--- a/pipenv/vendor/distlib/wheel.py
+++ b/pipenv/vendor/distlib/wheel.py
@@ -442,7 +442,9 @@ class Wheel(object):
         This can be used to issue any warnings to raise any exceptions.
         If kwarg ``lib_only`` is True, only the purelib/platlib files are
         installed, and the headers, scripts, data and dist-info metadata are
-        not written.
+        not written. If kwarg ``bytecode_hashed_invalidation`` is True, written
+        bytecode will try to use file-hash based invalidation (PEP-552) on
+        supported interpreter versions (CPython 2.7+).
 
         The return value is a :class:`InstalledDistribution` instance unless
         ``options.lib_only`` is True, in which case the return value is ``None``.
@@ -451,6 +453,7 @@ class Wheel(object):
         dry_run = maker.dry_run
         warner = kwargs.get('warner')
         lib_only = kwargs.get('lib_only', False)
+        bc_hashed_invalidation = kwargs.get('bytecode_hashed_invalidation', False)
 
         pathname = os.path.join(self.dirname, self.filename)
         name_ver = '%s-%s' % (self.name, self.version)
@@ -557,7 +560,8 @@ class Wheel(object):
                                                            '%s' % outfile)
                         if bc and outfile.endswith('.py'):
                             try:
-                                pyc = fileop.byte_compile(outfile)
+                                pyc = fileop.byte_compile(outfile,
+                                                          hashed_invalidation=bc_hashed_invalidation)
                                 outfiles.append(pyc)
                             except Exception:
                                 # Don't give up if byte-compilation fails,
diff --git a/pipenv/vendor/modutil.py b/pipenv/vendor/modutil.py
deleted file mode 100644
index d68f4851..00000000
--- a/pipenv/vendor/modutil.py
+++ /dev/null
@@ -1,145 +0,0 @@
-"""Help for working with modules."""
-__version__ = "2.0.0"
-
-import importlib
-import importlib.machinery
-import importlib.util
-import types
-
-
-STANDARD_MODULE_ATTRS = frozenset(['__all__', '__builtins__', '__cached__',
-                                   '__doc__', '__file__', '__loader__',
-                                   '__name__', '__package__', '__spec__',
-                                   '__getattr__'])
-
-
-class ModuleAttributeError(AttributeError):
-    """An AttributeError specifically for modules.
-
-    The module_name and 'attribute' attributes are set to strings representing
-    the module the attribute was searched on and the missing attribute,
-    respectively.
-
-    """
-
-    def __init__(self, module_name, attribute):
-        self.module_name = module_name
-        self.attribute = attribute
-        super().__init__(f"module {module_name!r} has no attribute {attribute!r}")
-
-
-
-def lazy_import(module_name, to_import):
-    """Return the importing module and a callable for lazy importing.
-
-    The module named by module_name represents the module performing the
-    import to help facilitate resolving relative imports.
-
-    to_import is an iterable of the modules to be potentially imported (absolute
-    or relative). The `as` form of importing is also supported,
-    e.g. `pkg.mod as spam`.
-
-    This function returns a tuple of two items. The first is the importer
-    module for easy reference within itself. The second item is a callable to be
-    set to `__getattr__`.
-    """
-    module = importlib.import_module(module_name)
-    import_mapping = {}
-    for name in to_import:
-        importing, _, binding = name.partition(' as ')
-        if not binding:
-            _, _, binding = importing.rpartition('.')
-        import_mapping[binding] = importing
-
-    def __getattr__(name):
-        if name not in import_mapping:
-            raise ModuleAttributeError(module_name, name)
-        importing = import_mapping[name]
-        # imortlib.import_module() implicitly sets submodules on this module as
-        # appropriate for direct imports.
-        imported = importlib.import_module(importing,
-                                           module.__spec__.parent)
-        setattr(module, name, imported)
-        return imported
-
-    return module, __getattr__
-
-
-def filtered_attrs(module, *, modules=False, private=False, dunder=False,
-                   common=False):
-    """Return a collection of attributes on 'module'.
-
-    If 'modules' is false then module instances are excluded. If 'private' is
-    false then attributes starting with, but not ending in, '_' will be
-    excluded. With 'dunder' set to false then attributes starting and ending
-    with '_' are left out. The 'common' argument controls whether attributes
-    found in STANDARD_MODULE_ATTRS are returned.
-
-    """
-    attr_names = set()
-    for name, value in module.__dict__.items():
-        if not common and name in STANDARD_MODULE_ATTRS:
-            continue
-        if name.startswith('_'):
-            if name.endswith('_'):
-                if not dunder:
-                    continue
-            elif not private:
-                continue
-        if not modules and isinstance(value, types.ModuleType):
-            continue
-        attr_names.add(name)
-    return frozenset(attr_names)
-
-
-def calc___all__(module_name, **kwargs):
-    """Return a sorted list of defined attributes on 'module_name'.
-
-    All values specified in **kwargs are directly passed to filtered_attrs().
-
-    """
-    module = importlib.import_module(module_name)
-    return sorted(filtered_attrs(module, **kwargs))
-
-
-def filtered_dir(module_name, *, additions={}, **kwargs):
-    """Return a callable appropriate for __dir__().
-
-    All values specified in **kwargs get passed directly to filtered_attrs().
-    The 'additions' argument should be an iterable which is added to the final
-    results.
-
-    """
-    module = importlib.import_module(module_name)
-
-    def __dir__():
-        attr_names = set(filtered_attrs(module, **kwargs))
-        attr_names.update(additions)
-        return sorted(attr_names)
-
-    return __dir__
-
-
-def chained___getattr__(module_name, *getattrs):
-    """Create a callable which calls each __getattr__ in sequence.
-
-    Any raised ModuleAttributeError which matches module_name and the
-    attribute being searched for will be caught and the search will continue.
-    All other exceptions will be allowed to propagate. If no callable
-    successfully returns a value, ModuleAttributeError will be raised.
-
-    """
-    def __getattr__(name):
-        """Call each __getattr__ function in sequence."""
-        for getattr_ in getattrs:
-            try:
-                return getattr_(name)
-            except ModuleAttributeError as exc:
-                if exc.module_name == module_name and exc.attribute == name:
-                    continue
-                else:
-                    raise
-        else:
-            raise ModuleAttributeError(module_name, name)
-
-    return __getattr__
diff --git a/pipenv/vendor/packaging/__about__.py b/pipenv/vendor/packaging/__about__.py
index 4255c5b5..21fc6ce3 100644
--- a/pipenv/vendor/packaging/__about__.py
+++ b/pipenv/vendor/packaging/__about__.py
@@ -12,10 +12,10 @@ __title__ = "packaging"
 __summary__ = "Core utilities for Python packages"
 __uri__ = "https://github.com/pypa/packaging"
 
-__version__ = "17.1"
+__version__ = "18.0"
 
 __author__ = "Donald Stufft and individual contributors"
 __email__ = "donald@stufft.io"
 
 __license__ = "BSD or Apache License, Version 2.0"
-__copyright__ = "Copyright 2014-2016 %s" % __author__
+__copyright__ = "Copyright 2014-2018 %s" % __author__
diff --git a/pipenv/vendor/packaging/requirements.py b/pipenv/vendor/packaging/requirements.py
index f87c57cc..e8008a6d 100644
--- a/pipenv/vendor/packaging/requirements.py
+++ b/pipenv/vendor/packaging/requirements.py
@@ -92,16 +92,16 @@ class Requirement(object):
         try:
             req = REQUIREMENT.parseString(requirement_string)
         except ParseException as e:
-            raise InvalidRequirement(
-                "Invalid requirement, parse error at \"{0!r}\"".format(
-                    requirement_string[e.loc:e.loc + 8]))
+            raise InvalidRequirement("Parse error at \"{0!r}\": {1}".format(
+                requirement_string[e.loc:e.loc + 8], e.msg
+            ))
 
         self.name = req.name
         if req.url:
             parsed_url = urlparse.urlparse(req.url)
             if not (parsed_url.scheme and parsed_url.netloc) or (
                     not parsed_url.scheme and not parsed_url.netloc):
-                raise InvalidRequirement("Invalid URL given")
+                raise InvalidRequirement("Invalid URL: {0}".format(req.url))
             self.url = req.url
         else:
             self.url = None
diff --git a/pipenv/vendor/packaging/specifiers.py b/pipenv/vendor/packaging/specifiers.py
index 9b6353f0..4c798999 100644
--- a/pipenv/vendor/packaging/specifiers.py
+++ b/pipenv/vendor/packaging/specifiers.py
@@ -503,7 +503,7 @@ class Specifier(_IndividualSpecifier):
                 return False
 
         # Ensure that we do not allow a local version of the version mentioned
-        # in the specifier, which is techincally greater than, to match.
+        # in the specifier, which is technically greater than, to match.
         if prospective.local is not None:
             if Version(prospective.base_version) == Version(spec.base_version):
                 return False
diff --git a/pipenv/vendor/passa/LICENSE b/pipenv/vendor/passa/LICENSE
index e1a278e7..cd41e272 100644
--- a/pipenv/vendor/passa/LICENSE
+++ b/pipenv/vendor/passa/LICENSE
@@ -1,4 +1,4 @@
-Copyright (c) 2018, Dan Ryan <dan@danryan.co>
+Copyright (c) 2018, Dan Ryan <dan@danryan.co> and Tzu-ping Chung <uranusjr@gmail.com>
 
 Permission to use, copy, modify, and distribute this software for any
 purpose with or without fee is hereby granted, provided that the above
diff --git a/pipenv/vendor/passa/actions/__init__.py b/pipenv/vendor/passa/actions/__init__.py
new file mode 100644
index 00000000..e69de29b
diff --git a/pipenv/vendor/passa/actions/add.py b/pipenv/vendor/passa/actions/add.py
new file mode 100644
index 00000000..63384667
--- /dev/null
+++ b/pipenv/vendor/passa/actions/add.py
@@ -0,0 +1,57 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+import itertools
+import sys
+
+
+def add_packages(packages=[], editables=[], project=None, dev=False, sync=False, clean=False):
+    from passa.models.lockers import PinReuseLocker
+    from passa.operations.lock import lock
+
+    lines = list(itertools.chain(
+        packages,
+        ("-e {}".format(e) for e in editables),
+    ))
+
+    project = project
+    for line in lines:
+        try:
+            project.add_line_to_pipfile(line, develop=dev)
+        except (TypeError, ValueError) as e:
+            print("Cannot add {line!r} to Pipfile: {error}".format(
+                line=line, error=str(e),
+            ), file=sys.stderr)
+            return 2
+
+    prev_lockfile = project.lockfile
+
+    locker = PinReuseLocker(project)
+    success = lock(locker)
+    if not success:
+        return 1
+
+    project._p.write()
+    project._l.write()
+    print("Written to project at", project.root)
+
+    if not sync:
+        return
+
+    from passa.models.synchronizers import Synchronizer
+    from passa.operations.sync import sync
+
+    lockfile_diff = project.difference_lockfile(prev_lockfile)
+    default = any(lockfile_diff.default)
+    develop = any(lockfile_diff.develop)
+
+    syncer = Synchronizer(
+        project, default=default, develop=develop,
+        clean_unneeded=clean,
+    )
+    success = sync(syncer)
+    if not success:
+        return 1
+
+    print("Synchronized project at", project.root)
diff --git a/pipenv/vendor/passa/actions/clean.py b/pipenv/vendor/passa/actions/clean.py
new file mode 100644
index 00000000..3570e4db
--- /dev/null
+++ b/pipenv/vendor/passa/actions/clean.py
@@ -0,0 +1,16 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+
+def clean(project, dev=False):
+    from passa.models.synchronizers import Cleaner
+    from passa.operations.sync import clean
+
+    cleaner = Cleaner(project, default=True, develop=dev)
+
+    success = clean(cleaner)
+    if not success:
+        return 1
+
+    print("Cleaned project at", project.root)
diff --git a/pipenv/vendor/passa/actions/freeze.py b/pipenv/vendor/passa/actions/freeze.py
new file mode 100644
index 00000000..ca4dbb2a
--- /dev/null
+++ b/pipenv/vendor/passa/actions/freeze.py
@@ -0,0 +1,93 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+import contextlib
+import io
+import itertools
+import sys
+
+import vistir.misc
+
+
+def _source_as_lines(source, extra):
+    url = source["url"]
+    if extra:
+        lines = ["--extra-index-url {}".format(url)]
+    else:
+        lines = ["--index-url {}".format(url)]
+    if not source.get("verify_ssl", True):
+        lines = ["--trusted-host {}".format(url)]
+    return lines
+
+
+def _requirement_as_line(requirement, sources, include_hashes):
+    if requirement.index:
+        sources = sources
+    else:
+        sources = None
+    line = vistir.misc.to_text(
+        requirement.as_line(sources=sources, include_hashes=include_hashes)
+    )
+    return line
+
+
+@contextlib.contextmanager
+def open_for_output(filename):
+    if filename is None:
+        yield sys.stdout
+        return
+    with io.open(filename, "w", encoding="utf-8", newline="\n") as f:
+        yield f
+
+
+def freeze(project=None, default=True, dev=True, include_hashes=None, target=None):
+    from requirementslib import Requirement
+
+    lockfile = project.lockfile
+    if not lockfile:
+        print("Pipfile.lock is required to export.", file=sys.stderr)
+        return 1
+
+    section_names = []
+    if default:
+        section_names.append("default")
+    if dev:
+        section_names.append("develop")
+    requirements = [
+        Requirement.from_pipfile(key, entry._data)
+        for key, entry in itertools.chain.from_iterable(
+            lockfile.get(name, {}).items()
+            for name in section_names
+        )
+    ]
+
+    if include_hashes is None:
+        include_hashes = all(r.is_named for r in requirements)
+
+    sources = lockfile.meta.sources._data
+
+    source_lines = list(vistir.misc.dedup(itertools.chain(
+        itertools.chain.from_iterable(
+            _source_as_lines(source, False)
+            for source in sources[:1]
+        ),
+        itertools.chain.from_iterable(
+            _source_as_lines(source, True)
+            for source in sources[1:]
+        ),
+    )))
+
+    requirement_lines = sorted(vistir.misc.dedup(
+        _requirement_as_line(requirement, sources, include_hashes)
+        for requirement in requirements
+    ))
+
+    with open_for_output(target) as f:
+        for line in source_lines:
+            f.write(line)
+            f.write("\n")
+        f.write("\n")
+        for line in requirement_lines:
+            f.write(line)
+            f.write("\n")
diff --git a/pipenv/vendor/passa/actions/init.py b/pipenv/vendor/passa/actions/init.py
new file mode 100644
index 00000000..1d9f5923
--- /dev/null
+++ b/pipenv/vendor/passa/actions/init.py
@@ -0,0 +1,59 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+import io
+import os
+from pip_shims import Command as PipCommand, cmdoptions
+import plette
+import six
+import vistir
+
+
+class PipCmd(PipCommand):
+    name = "PipCmd"
+
+
+def get_sources(urls, trusted_hosts):
+    trusted_hosts = [six.moves.urllib.parse.urlparse(url).netloc for url in trusted_hosts]
+    sources = []
+    for url in urls:
+        parsed_url = six.moves.urllib.parse.urlparse(url)
+        netloc = parsed_url.netloc
+        if '@' in netloc:
+            _, _, netloc = netloc.rpartition('@')
+        name, _, _ = netloc.partition('.')  # Just use the domain name as the source name
+        verify_ssl = True
+        if netloc in trusted_hosts:
+            verify_ssl = False
+        sources.append({"url": url, "name": name, "verify_ssl": verify_ssl})
+    return sources
+
+
+def init_project(root=None, python_version=None):
+    pipfile_path = os.path.join(root, "Pipfile")
+    if os.path.isfile(pipfile_path):
+        raise RuntimeError("{0!r} is already a Pipfile project".format(root))
+    if not os.path.exists(root):
+        vistir.path.mkdir_p(root, mode=0o755)
+    pip_command = PipCmd()
+    cmdoptions.make_option_group(cmdoptions.index_group, pip_command.parser)
+    parsed, _ = pip_command.parser.parse_args([])
+    index_urls = [parsed.index_url] + parsed.extra_index_urls
+    sources = get_sources(index_urls, parsed.trusted_hosts)
+    data = {
+        "sources": sources,
+        "packages": {},
+        "dev-packages": {},
+    }
+    if python_version:
+        data["requires"] = {"python_version": python_version}
+    return create_project(pipfile_path=pipfile_path, data=data)
+
+
+def create_project(pipfile_path, data={}):
+    pipfile = plette.pipfiles.Pipfile(data=data)
+    with io.open(pipfile_path, "w") as fh:
+        pipfile.dump(fh)
+    print("Successfully created new pipfile at {0!r}".format(pipfile_path))
+    return 0
diff --git a/pipenv/vendor/passa/actions/install.py b/pipenv/vendor/passa/actions/install.py
new file mode 100644
index 00000000..1728dae5
--- /dev/null
+++ b/pipenv/vendor/passa/actions/install.py
@@ -0,0 +1,32 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+
+def install(project=None, check=True, dev=False, clean=True):
+    from passa.models.lockers import BasicLocker
+    from passa.operations.lock import lock
+
+    project = project
+
+    if not check or not project.is_synced():
+        locker = BasicLocker(project)
+        success = lock(locker)
+        if not success:
+            return 1
+        project._l.write()
+        print("Written to project at", project.root)
+
+    from passa.models.synchronizers import Synchronizer
+    from passa.operations.sync import sync
+
+    syncer = Synchronizer(
+        project, default=True, develop=dev,
+        clean_unneeded=clean,
+    )
+
+    success = sync(syncer)
+    if not success:
+        return 1
+
+    print("Synchronized project at", project.root)
diff --git a/pipenv/vendor/passa/actions/lock.py b/pipenv/vendor/passa/actions/lock.py
new file mode 100644
index 00000000..7c094695
--- /dev/null
+++ b/pipenv/vendor/passa/actions/lock.py
@@ -0,0 +1,17 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+
+def lock(project=None):
+    from passa.models.lockers import BasicLocker
+    from passa.operations.lock import lock
+
+    project = project
+    locker = BasicLocker(project)
+    success = lock(locker)
+    if not success:
+        return
+
+    project._l.write()
+    print("Written to project at", project.root)
diff --git a/pipenv/vendor/passa/actions/remove.py b/pipenv/vendor/passa/actions/remove.py
new file mode 100644
index 00000000..158f5e69
--- /dev/null
+++ b/pipenv/vendor/passa/actions/remove.py
@@ -0,0 +1,38 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+
+def remove(project=None, only="default", packages=[], clean=True):
+    from passa.models.lockers import PinReuseLocker
+    from passa.operations.lock import lock
+
+    default = (only != "dev")
+    develop = (only != "default")
+
+    project = project
+    project.remove_keys_from_pipfile(
+        packages, default=default, develop=develop,
+    )
+
+    locker = PinReuseLocker(project)
+    success = lock(locker)
+    if not success:
+        return 1
+
+    project._p.write()
+    project._l.write()
+    print("Written to project at", project.root)
+
+    if not clean:
+        return
+
+    from passa.models.synchronizers import Cleaner
+    from passa.operations.sync import clean
+
+    cleaner = Cleaner(project, default=True, develop=True)
+    success = clean(cleaner)
+    if not success:
+        return 1
+
+    print("Cleaned project at", project.root)
diff --git a/pipenv/vendor/passa/actions/sync.py b/pipenv/vendor/passa/actions/sync.py
new file mode 100644
index 00000000..23e36eeb
--- /dev/null
+++ b/pipenv/vendor/passa/actions/sync.py
@@ -0,0 +1,20 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+
+def sync(project=None, dev=False, clean=True):
+    from passa.models.synchronizers import Synchronizer
+    from passa.operations.sync import sync
+
+    project = project
+    syncer = Synchronizer(
+        project, default=True, develop=dev,
+        clean_unneeded=clean,
+    )
+
+    success = sync(syncer)
+    if not success:
+        return 1
+
+    print("Synchronized project at", project.root)
diff --git a/pipenv/vendor/passa/actions/upgrade.py b/pipenv/vendor/passa/actions/upgrade.py
new file mode 100644
index 00000000..fb3ad7f5
--- /dev/null
+++ b/pipenv/vendor/passa/actions/upgrade.py
@@ -0,0 +1,52 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+import sys
+
+
+def upgrade(project=None, strategy="only-if-needed", sync=True, packages=[]):
+    from passa.models.lockers import EagerUpgradeLocker, PinReuseLocker
+    from passa.operations.lock import lock
+
+    for package in packages:
+        if not project.contains_key_in_pipfile(package):
+            print("{package!r} not found in Pipfile".format(
+                package=package,
+            ), file=sys.stderr)
+            return 2
+
+    project.remove_keys_from_lockfile(packages)
+
+    prev_lockfile = project.lockfile
+
+    if strategy == "eager":
+        locker = EagerUpgradeLocker(project, packages)
+    else:
+        locker = PinReuseLocker(project)
+    success = lock(locker)
+    if not success:
+        return 1
+
+    project._l.write()
+    print("Written to project at", project.root)
+
+    if not sync:
+        return
+
+    from passa.operations.sync import sync
+    from passa.models.synchronizers import Synchronizer
+
+    lockfile_diff = project.difference_lockfile(prev_lockfile)
+    default = bool(any(lockfile_diff.default))
+    develop = bool(any(lockfile_diff.develop))
+
+    syncer = Synchronizer(
+        project, default=default, develop=develop,
+        clean_unneeded=False,
+    )
+    success = sync(syncer)
+    if not success:
+        return 1
+
+    print("Synchronized project at", project.root)
diff --git a/pipenv/vendor/passa/cli/__init__.py b/pipenv/vendor/passa/cli/__init__.py
index cb503e81..b6891d38 100644
--- a/pipenv/vendor/passa/cli/__init__.py
+++ b/pipenv/vendor/passa/cli/__init__.py
@@ -34,7 +34,7 @@ def main(argv=None):
             continue
         parser = subparsers.add_parser(klass.name, help=klass.description)
         command = klass(parser)
-        parser.set_defaults(func=command.main)
+        parser.set_defaults(func=command.run)
 
     options = root_parser.parse_args(argv)
 
diff --git a/pipenv/vendor/passa/cli/_base.py b/pipenv/vendor/passa/cli/_base.py
index 68e0e34d..0ca48682 100644
--- a/pipenv/vendor/passa/cli/_base.py
+++ b/pipenv/vendor/passa/cli/_base.py
@@ -6,31 +6,7 @@ import argparse
 import os
 import sys
 
-import tomlkit.exceptions
-
-
-def build_project(root):
-    # This is imported lazily to reduce import overhead. Not evey command
-    # needs the project instance.
-    from passa.internals.projects import Project
-    root = os.path.abspath(root)
-    if not os.path.isfile(os.path.join(root, "Pipfile")):
-        raise argparse.ArgumentError(
-            "{0!r} is not a Pipfile project".format(root),
-        )
-    try:
-        project = Project(root)
-    except tomlkit.exceptions.ParseError as e:
-        raise argparse.ArgumentError(
-            "failed to parse Pipfile: {0!r}".format(str(e)),
-        )
-    return project
-
-
-# Better error reporting. Recent argparse would emit something like
-# "invalid project root value: 'xxxxxx'". The str() wrapper is needed to
-# keep Python 2 happy :(
-build_project.__name__ = str("project root")
+from .options import project
 
 
 class BaseCommand(object):
@@ -38,19 +14,30 @@ class BaseCommand(object):
     """
     name = None
     description = None
-    parsed_main = None
-
-    def __init__(self, parser):
+    default_arguments = [project]
+    arguments = []
+
+    def __init__(self, parser=None):
+        if not parser:
+            parser = argparse.ArgumentParser(
+                prog=os.path.basename(sys.argv[0]),
+                description="Base argument parser for passa"
+            )
         self.parser = parser
         self.add_arguments()
 
     @classmethod
-    def run_current_module(cls):
+    def build_parser(cls):
         parser = argparse.ArgumentParser(
             prog="passa {}".format(cls.name),
             description=cls.description,
         )
-        cls(parser)()
+        return cls(parser)
+
+    @classmethod
+    def run_parser(cls):
+        parser = cls.build_parser()
+        parser()
 
     def __call__(self, argv=None):
         options = self.parser.parse_args(argv)
@@ -58,16 +45,17 @@ class BaseCommand(object):
         if result is not None:
             sys.exit(result)
 
+    def add_default_arguments(self):
+        for arg in self.default_arguments:
+            arg.add_to_parser(self.parser)
+
     def add_arguments(self):
-        self.parser.add_argument(
-            "--project",
-            metavar="project",
-            default=os.getcwd(),
-            type=build_project,
-            help="path to project root (directory containing Pipfile)",
-        )
+        self.add_default_arguments()
+        for arg in self.arguments:
+            arg.add_to_parser(self.parser)
 
     def main(self, options):
-        # This __dict__ access is needed for Python 2 to prevent Python from
-        # wrapping parsed_main into an unbounded method.
-        return type(self).__dict__["parsed_main"](options)
+        return self.run(options)
+
+    def run(self, options):
+        raise NotImplementedError
diff --git a/pipenv/vendor/passa/cli/add.py b/pipenv/vendor/passa/cli/add.py
index 26ce0ed8..d5596cde 100644
--- a/pipenv/vendor/passa/cli/add.py
+++ b/pipenv/vendor/passa/cli/add.py
@@ -2,98 +2,27 @@
 
 from __future__ import absolute_import, print_function, unicode_literals
 
-import itertools
-import sys
-
+from ..actions.add import add_packages
 from ._base import BaseCommand
-
-
-def main(options):
-    from passa.internals.lockers import PinReuseLocker
-    from passa.operations.lock import lock
-
-    lines = list(itertools.chain(
-        options.requirement_lines,
-        ("-e {}".format(e) for e in options.editable_lines),
-    ))
-
-    project = options.project
-    for line in lines:
-        try:
-            project.add_line_to_pipfile(line, develop=options.dev)
-        except (TypeError, ValueError) as e:
-            print("Cannot add {line!r} to Pipfile: {error}".format(
-                line=line, error=str(e),
-            ), file=sys.stderr)
-            return 2
-
-    prev_lockfile = project.lockfile
-
-    locker = PinReuseLocker(project)
-    success = lock(locker)
-    if not success:
-        return 1
-
-    project._p.write()
-    project._l.write()
-    print("Written to project at", project.root)
-
-    if not options.sync:
-        return
-
-    from passa.internals.synchronizers import Synchronizer
-    from passa.operations.sync import sync
-
-    lockfile_diff = project.difference_lockfile(prev_lockfile)
-    default = bool(any(lockfile_diff.default))
-    develop = bool(any(lockfile_diff.develop))
-
-    syncer = Synchronizer(
-        project, default=default, develop=develop,
-        clean_unneeded=False,
-    )
-    success = sync(syncer)
-    if not success:
-        return 1
-
-    print("Synchronized project at", project.root)
+from .options import package_group
 
 
 class Command(BaseCommand):
 
     name = "add"
     description = "Add packages to project."
-    parsed_main = main
+    arguments = [package_group]
 
-    def add_arguments(self):
-        super(Command, self).add_arguments()
-        self.parser.add_argument(
-            "requirement_lines", metavar="requirement",
-            nargs="*",
-            help="requirement to add (can be used multiple times)",
-        )
-        self.parser.add_argument(
-            "-e", "--editable",
-            metavar="requirement", dest="editable_lines",
-            action="append", default=[],
-            help="editable requirement to add (can be used multiple times)",
-        )
-        self.parser.add_argument(
-            "--dev",
-            action="store_true",
-            help="add packages to [dev-packages]",
-        )
-        self.parser.add_argument(
-            "--no-sync", dest="sync",
-            action="store_false", default=True,
-            help="do not synchronize the environment",
-        )
-
-    def main(self, options):
-        if not options.editable_lines and not options.requirement_lines:
+    def run(self, options):
+        if not options.editables and not options.packages:
             self.parser.error("Must supply either a requirement or --editable")
-        return super(Command, self).main(options)
+        return add_packages(
+            packages=options.packages,
+            editables=options.editables,
+            project=options.project,
+            dev=options.dev
+        )
 
 
 if __name__ == "__main__":
-    Command.run_current_module()
+    Command.run_parser()
diff --git a/pipenv/vendor/passa/cli/clean.py b/pipenv/vendor/passa/cli/clean.py
index cd1b679b..e23d5ee5 100644
--- a/pipenv/vendor/passa/cli/clean.py
+++ b/pipenv/vendor/passa/cli/clean.py
@@ -2,37 +2,20 @@
 
 from __future__ import absolute_import, print_function, unicode_literals
 
+from ..actions.clean import clean
 from ._base import BaseCommand
-
-
-def main(options):
-    from passa.internals.synchronizers import Cleaner
-    from passa.operations.sync import clean
-
-    project = options.project
-    cleaner = Cleaner(project, default=True, develop=options.dev)
-
-    success = clean(cleaner)
-    if not success:
-        return 1
-
-    print("Cleaned project at", project.root)
+from .options import dev, no_default
 
 
 class Command(BaseCommand):
 
     name = "clean"
     description = "Uninstall unlisted packages from the environment."
-    parsed_main = main
+    arguments = [dev, no_default]
 
-    def add_arguments(self):
-        super(Command, self).add_arguments()
-        self.parser.add_argument(
-            "--no-dev", dest="dev",
-            action="store_false", default=True,
-            help="uninstall develop packages, only keep default ones",
-        )
+    def run(self, options):
+        return clean(project=options.project, default=options.default, dev=options.dev)
 
 
 if __name__ == "__main__":
-    Command.run_current_module()
+    Command.run_parser()
diff --git a/pipenv/vendor/passa/cli/freeze.py b/pipenv/vendor/passa/cli/freeze.py
index 6ca57170..053c7273 100644
--- a/pipenv/vendor/passa/cli/freeze.py
+++ b/pipenv/vendor/passa/cli/freeze.py
@@ -2,137 +2,23 @@
 
 from __future__ import absolute_import, print_function, unicode_literals
 
-import contextlib
-import io
-import itertools
-import sys
-
-import six
-import vistir.misc
-
+from ..actions.freeze import freeze
 from ._base import BaseCommand
-
-
-def _source_as_lines(source, extra):
-    url = source["url"]
-    if extra:
-        lines = ["--extra-index-url {}".format(url)]
-    else:
-        lines = ["--index-url {}".format(url)]
-    if not source.get("verify_ssl", True):
-        lines = ["--trusted-host {}".format(url)]
-    return lines
-
-
-def _requirement_as_line(requirement, sources, include_hashes):
-    if requirement.index:
-        sources = sources
-    else:
-        sources = None
-    line = requirement.as_line(sources=sources, include_hashes=include_hashes)
-    if not isinstance(line, six.text_type):
-        line = line.decode("utf-8")
-    return line
-
-
-@contextlib.contextmanager
-def open_for_output(filename):
-    if filename is None:
-        yield sys.stdout
-        return
-    with io.open(filename, "w", encoding="utf-8", newline="\n") as f:
-        yield f
-
-
-def main(options):
-    from requirementslib import Requirement
-
-    lockfile = options.project.lockfile
-    if not lockfile:
-        print("Pipfile.lock is required to export.", file=sys.stderr)
-        return 1
-
-    section_names = []
-    if options.default:
-        section_names.append("default")
-    if options.dev:
-        section_names.append("develop")
-    requirements = [
-        Requirement.from_pipfile(key, entry._data)
-        for key, entry in itertools.chain.from_iterable(
-            lockfile.get(name, {}).items()
-            for name in section_names
-        )
-    ]
-
-    include_hashes = options.include_hashes
-    if include_hashes is None:
-        include_hashes = all(r.is_named for r in requirements)
-
-    sources = lockfile.meta.sources._data
-
-    source_lines = list(vistir.misc.dedup(itertools.chain(
-        itertools.chain.from_iterable(
-            _source_as_lines(source, False)
-            for source in sources[:1]
-        ),
-        itertools.chain.from_iterable(
-            _source_as_lines(source, True)
-            for source in sources[1:]
-        ),
-    )))
-
-    requirement_lines = sorted(vistir.misc.dedup(
-        _requirement_as_line(requirement, sources, include_hashes)
-        for requirement in requirements
-    ))
-
-    with open_for_output(options.target) as f:
-        for line in source_lines:
-            f.write(line)
-            f.write("\n")
-        f.write("\n")
-        for line in requirement_lines:
-            f.write(line)
-            f.write("\n\n")
+from .options import dev, include_hashes_group, no_default, target
 
 
 class Command(BaseCommand):
 
     name = "freeze"
     description = "Export project depenencies to requirements.txt."
-    parsed_main = main
+    arguments = [dev, no_default, target, include_hashes_group]
 
-    def add_arguments(self):
-        super(Command, self).add_arguments()
-        self.parser.add_argument(
-            "--target",
-            default=None,
-            help="file to export into (default is to print to stdout)",
-        )
-        self.parser.add_argument(
-            "--dev",
-            action="store_true", default=False,
-            help="include development packages in requirements.txt",
-        )
-        self.parser.add_argument(
-            "--no-default", dest="default",
-            action="store_false", default=True,
-            help="do not include default packages in requirements.txt",
-        )
-        include_hashes_group = self.parser.add_mutually_exclusive_group()
-        include_hashes_group.add_argument(
-            "--include-hashes", dest="include_hashes",
-            action="store_true",
-            help="output hashes in requirements.txt (default is to guess)",
-        )
-        include_hashes_group.add_argument(
-            "--no-include-hashes", dest="include_hashes",
-            action="store_false",
-            help=("do not output hashes in requirements.txt "
-                  "(default is to guess)"),
+    def run(self, options):
+        return freeze(
+            project=options.project, default=options.default, dev=options.dev,
+            include_hashes=options.include_hashes
         )
 
 
 if __name__ == "__main__":
-    Command.run_current_module()
+    Command.run_parser()
diff --git a/pipenv/vendor/passa/cli/init.py b/pipenv/vendor/passa/cli/init.py
new file mode 100644
index 00000000..95ce8d84
--- /dev/null
+++ b/pipenv/vendor/passa/cli/init.py
@@ -0,0 +1,32 @@
+# -*- coding=utf-8 -*-
+
+from __future__ import absolute_import, print_function, unicode_literals
+
+import argparse
+import os
+
+from ..actions.init import init_project
+from ._base import BaseCommand
+from .options import new_project_group
+
+
+class Command(BaseCommand):
+
+    name = "init"
+    description = "Create a new project."
+    default_arguments = []
+    arguments = [new_project_group]
+
+    def run(self, options):
+        pipfile_path = os.path.join(options.project, "Pipfile")
+        if os.path.exists(pipfile_path):
+            raise argparse.ArgumentError(
+                "{0!r} is already a Pipfile project".format(options.project),
+            )
+        return init_project(
+            root=options.project, python_version=options.python_version
+        )
+
+
+if __name__ == "__main__":
+    Command.run_parser()
diff --git a/pipenv/vendor/passa/cli/install.py b/pipenv/vendor/passa/cli/install.py
index f47377b1..1c0b4591 100644
--- a/pipenv/vendor/passa/cli/install.py
+++ b/pipenv/vendor/passa/cli/install.py
@@ -2,62 +2,21 @@
 
 from __future__ import absolute_import, print_function, unicode_literals
 
+from ..actions.install import install
 from ._base import BaseCommand
-
-
-def main(options):
-    from passa.internals.lockers import BasicLocker
-    from passa.operations.lock import lock
-
-    project = options.project
-
-    if not options.check or not project.is_synced():
-        locker = BasicLocker(project)
-        success = lock(locker)
-        if not success:
-            return 1
-        project._l.write()
-        print("Written to project at", project.root)
-
-    from passa.internals.synchronizers import Synchronizer
-    from passa.operations.sync import sync
-
-    syncer = Synchronizer(
-        project, default=True, develop=options.dev,
-        clean_unneeded=options.clean,
-    )
-
-    success = sync(syncer)
-    if not success:
-        return 1
-
-    print("Synchronized project at", project.root)
+from .options import dev, no_check, no_clean
 
 
 class Command(BaseCommand):
 
     name = "install"
     description = "Generate Pipfile.lock to synchronize the environment."
-    parsed_main = main
-
-    def add_arguments(self):
-        super(Command, self).add_arguments()
-        self.parser.add_argument(
-            "--no-check", dest="check",
-            action="store_false", default=True,
-            help="do not check if Pipfile.lock is update, always resolve",
-        )
-        self.parser.add_argument(
-            "--dev",
-            action="store_true",
-            help="install develop packages",
-        )
-        self.parser.add_argument(
-            "--no-clean", dest="clean",
-            action="store_false", default=True,
-            help="do not uninstall packages not specified in Pipfile.lock",
-        )
+    arguments = [no_check, dev, no_clean]
+
+    def run(self, options):
+        return install(project=options.project, check=options.check, dev=options.dev,
+                            clean=options.clean)
 
 
 if __name__ == "__main__":
-    Command.run_current_module()
+    Command.run_parser()
diff --git a/pipenv/vendor/passa/cli/lock.py b/pipenv/vendor/passa/cli/lock.py
index 67b1d118..9b0651a1 100644
--- a/pipenv/vendor/passa/cli/lock.py
+++ b/pipenv/vendor/passa/cli/lock.py
@@ -2,28 +2,17 @@
 
 from __future__ import absolute_import, print_function, unicode_literals
 
+from ..actions.lock import lock
 from ._base import BaseCommand
 
 
-def main(options):
-    from passa.internals.lockers import BasicLocker
-    from passa.operations.lock import lock
-
-    project = options.project
-    locker = BasicLocker(project)
-    success = lock(locker)
-    if not success:
-        return
-
-    project._l.write()
-    print("Written to project at", project.root)
-
-
 class Command(BaseCommand):
     name = "lock"
     description = "Generate Pipfile.lock."
-    parsed_main = main
+
+    def run(self, options):
+        return lock(project=options.project)
 
 
 if __name__ == "__main__":
-    Command.run_current_module()
+    Command.run_parser()
diff --git a/pipenv/vendor/passa/cli/options.py b/pipenv/vendor/passa/cli/options.py
new file mode 100644
index 00000000..da89a3b1
--- /dev/null
+++ b/pipenv/vendor/passa/cli/options.py
@@ -0,0 +1,153 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import
+
+import argparse
+import os
+import sys
+
+import tomlkit.exceptions
+
+import passa.models.projects
+import vistir
+
+
+PYTHON_VERSION = ".".join(str(v) for v in sys.version_info[:2])
+
+
+class Project(passa.models.projects.Project):
+    def __init__(self, root, *args, **kwargs):
+        root = vistir.compat.Path(root).absolute()
+        pipfile = root.joinpath("Pipfile")
+        if not pipfile.is_file():
+            raise argparse.ArgumentError(
+                "{0!r} is not a Pipfile project".format(root),
+            )
+        try:
+            super(Project, self).__init__(root.as_posix(), *args, **kwargs)
+        except tomlkit.exceptions.ParseError as e:
+            raise argparse.ArgumentError(
+                "failed to parse Pipfile: {0!r}".format(str(e)),
+            )
+
+    def __name__(self):
+        return "Project Root"
+
+
+class Option(object):
+    def __init__(self, *args, **kwargs):
+        self.args = args
+        self.kwargs = kwargs
+
+    def add_to_parser(self, parser):
+        parser.add_argument(*self.args, **self.kwargs)
+
+    def add_to_group(self, group):
+        group.add_argument(*self.args, **self.kwargs)
+
+
+class ArgumentGroup(object):
+    def __init__(self, name, parser=None, is_mutually_exclusive=False, required=None, options=[]):
+        self.name = name
+        self.options = options
+        self.parser = parser
+        self.required = required
+        self.is_mutually_exclusive = is_mutually_exclusive
+        self.argument_group = None
+
+    def add_to_parser(self, parser):
+        group = None
+        if self.is_mutually_exclusive:
+            group = parser.add_mutually_exclusive_group(required=self.required)
+        else:
+            group = parser.add_argument_group()
+        for option in self.options:
+            option.add_to_group(group)
+        self.argument_group = group
+        self.parser = parser
+
+
+project = Option(
+    "--project", metavar="project", default=os.getcwd(), type=Project,
+    help="path to project root (directory containing Pipfile)",
+)
+
+new_project = Option(
+    "--project", metavar="project", default=os.getcwd(), type=str,
+    help="path to project root (directory containing Pipfile)",
+)
+
+python_version = Option(
+    "--py-version", "--python-version", "--requires-python", metavar="python-version",
+    dest="python_version", default=PYTHON_VERSION, type=str,
+    help="required minor python version for the project"
+)
+
+packages = Option(
+    "packages", metavar="package", nargs="*",
+    help="requirement to add (can be used multiple times)",
+)
+
+editable = Option(
+    '-e', '--editable', dest='editables', nargs="*", default=[], metavar='path/vcs',
+    help="editable requirement to add (can be used multiple times)",
+)
+
+dev = Option(
+    "--dev", action="store_true", default=False,
+    help="Use [dev-packages] for install/freeze/uninstall operations",
+)
+
+no_sync = Option(
+    "--no-sync", dest="sync", action="store_false", default=True,
+    help="do not synchronize the environment",
+)
+
+target = Option(
+    "-t", "--target", default=None,
+    help="file to export into (default is to print to stdout)"
+)
+
+no_default = Option(
+    "--no-default", dest="default", action="store_false", default=True,
+    help="do not include default packages when exporting, importing, or cleaning"
+)
+
+include_hashes = Option(
+    "--include-hashes", dest="include_hashes", action="store_true",
+    help="output hashes in requirements.txt (default is to guess)",
+)
+
+no_include_hashes = Option(
+    "--no-include-hashes", dest="include_hashes", action="store_false",
+    help="do not output hashes in requirements.txt (default is to guess)",
+)
+
+no_check = Option(
+    "--no-check", dest="check", action="store_false", default=True,
+    help="do not check if Pipfile.lock is up to date, always resolve",
+)
+
+no_clean = Option(
+    "--no-clean", dest="clean", action="store_false", default=True,
+    help="do not remove packages not specified in Pipfile.lock",
+)
+
+dev_only = Option(
+    "--dev", dest="only", action="store_const", const="dev",
+    help="only try to modify [dev-packages]",
+)
+
+default_only = Option(
+    "--default", dest="only", action="store_const", const="default",
+    help="only try to modify [default]",
+)
+
+strategy = Option(
+    "--strategy", choices=["eager", "only-if-needed"], default="only-if-needed",
+    help="how dependency upgrading is handled",
+)
+
+include_hashes_group = ArgumentGroup("include_hashes", is_mutually_exclusive=True, options=[include_hashes, no_include_hashes])
+dev_group = ArgumentGroup("dev", is_mutually_exclusive="True", options=[dev_only, default_only])
+package_group = ArgumentGroup("packages", options=[packages, editable, dev, no_sync])
+new_project_group = ArgumentGroup("new-project", options=[new_project, python_version])
diff --git a/pipenv/vendor/passa/cli/remove.py b/pipenv/vendor/passa/cli/remove.py
index b1dbfd7c..538acbf9 100644
--- a/pipenv/vendor/passa/cli/remove.py
+++ b/pipenv/vendor/passa/cli/remove.py
@@ -2,74 +2,21 @@
 
 from __future__ import absolute_import, print_function, unicode_literals
 
+from ..actions.remove import remove
 from ._base import BaseCommand
-
-
-def main(options):
-    from passa.internals.lockers import PinReuseLocker
-    from passa.operations.lock import lock
-
-    default = (options.only != "dev")
-    develop = (options.only != "default")
-
-    project = options.project
-    project.remove_keys_from_pipfile(
-        options.packages, default=default, develop=develop,
-    )
-
-    locker = PinReuseLocker(project)
-    success = lock(locker)
-    if not success:
-        return 1
-
-    project._p.write()
-    project._l.write()
-    print("Written to project at", project.root)
-
-    if not options.clean:
-        return
-
-    from passa.internals.synchronizers import Cleaner
-    from passa.operations.sync import clean
-
-    cleaner = Cleaner(project, default=True, develop=True)
-    success = clean(cleaner)
-    if not success:
-        return 1
-
-    print("Cleaned project at", project.root)
+from .options import dev_group, no_clean, packages
 
 
 class Command(BaseCommand):
 
     name = "remove"
     description = "Remove packages from project."
-    parsed_main = main
+    arguments = [dev_group, no_clean, packages]
 
-    def add_arguments(self):
-        super(Command, self).add_arguments()
-        self.parser.add_argument(
-            "packages", metavar="package",
-            nargs="+",
-            help="package to remove (can be used multiple times)",
-        )
-        dev_group = self.parser.add_mutually_exclusive_group()
-        dev_group.add_argument(
-            "--dev", dest="only",
-            action="store_const", const="dev",
-            help="only try to remove from [dev-packages]",
-        )
-        dev_group.add_argument(
-            "--default", dest="only",
-            action="store_const", const="default",
-            help="only try to remove from [packages]",
-        )
-        self.parser.add_argument(
-            "--no-clean", dest="clean",
-            action="store_false", default=True,
-            help="do not uninstall packages not specified in Pipfile.lock",
-        )
+    def run(self, options):
+        return remove(project=options.project, only=options.only,
+                        packages=options.packages, clean=options.clean)
 
 
 if __name__ == "__main__":
-    Command.run_current_module()
+    Command.run_parser()
diff --git a/pipenv/vendor/passa/cli/sync.py b/pipenv/vendor/passa/cli/sync.py
index ade81e0a..a09b7842 100644
--- a/pipenv/vendor/passa/cli/sync.py
+++ b/pipenv/vendor/passa/cli/sync.py
@@ -2,45 +2,20 @@
 
 from __future__ import absolute_import, print_function, unicode_literals
 
+from ..actions.sync import sync
 from ._base import BaseCommand
-
-
-def main(options):
-    from passa.internals.synchronizers import Synchronizer
-    from passa.operations.sync import sync
-
-    project = options.project
-    syncer = Synchronizer(
-        project, default=True, develop=options.dev,
-        clean_unneeded=options.clean,
-    )
-
-    success = sync(syncer)
-    if not success:
-        return 1
-
-    print("Synchronized project at", project.root)
+from .options import dev, no_clean
 
 
 class Command(BaseCommand):
 
     name = "sync"
     description = "Install Pipfile.lock into the environment."
-    parsed_main = main
-
-    def add_arguments(self):
-        super(Command, self).add_arguments()
-        self.parser.add_argument(
-            "--dev",
-            action="store_true",
-            help="install develop packages",
-        )
-        self.parser.add_argument(
-            "--no-clean", dest="clean",
-            action="store_false", default=True,
-            help="do not uninstall packages not specified in Pipfile.lock",
-        )
+    arguments = [dev, no_clean]
+
+    def run(self, options):
+        return sync(project=options.project, dev=options.dev, clean=options.clean)
 
 
 if __name__ == "__main__":
-    Command.run_current_module()
+    Command.run_parser()
diff --git a/pipenv/vendor/passa/cli/upgrade.py b/pipenv/vendor/passa/cli/upgrade.py
index 011fff6b..cf7f5021 100644
--- a/pipenv/vendor/passa/cli/upgrade.py
+++ b/pipenv/vendor/passa/cli/upgrade.py
@@ -1,91 +1,21 @@
 # -*- coding=utf-8 -*-
-
 from __future__ import absolute_import, print_function, unicode_literals
 
-import sys
-
+from ..actions.upgrade import upgrade
 from ._base import BaseCommand
-
-
-def main(options):
-    from passa.internals.lockers import EagerUpgradeLocker, PinReuseLocker
-    from passa.operations.lock import lock
-
-    project = options.project
-    packages = options.packages
-    for package in packages:
-        if not project.contains_key_in_pipfile(package):
-            print("{package!r} not found in Pipfile".format(
-                package=package,
-            ), file=sys.stderr)
-            return 2
-
-    project.remove_keys_from_lockfile(packages)
-
-    prev_lockfile = project.lockfile
-
-    if options.strategy == "eager":
-        locker = EagerUpgradeLocker(project, packages)
-    else:
-        locker = PinReuseLocker(project)
-    success = lock(locker)
-    if not success:
-        return 1
-
-    project._l.write()
-    print("Written to project at", project.root)
-
-    if not options.sync:
-        return
-
-    from passa.operations.sync import sync
-    from passa.internals.synchronizers import Synchronizer
-
-    lockfile_diff = project.difference_lockfile(prev_lockfile)
-    default = bool(any(lockfile_diff.default))
-    develop = bool(any(lockfile_diff.develop))
-
-    syncer = Synchronizer(
-        project, default=default, develop=develop,
-        clean_unneeded=False,
-    )
-    success = sync(syncer)
-    if not success:
-        return 1
-
-    print("Synchronized project at", project.root)
+from .options import no_clean, no_sync, packages, strategy
 
 
 class Command(BaseCommand):
 
     name = "upgrade"
     description = "Upgrade packages in project."
-    parsed_main = main
+    arguments = [packages, strategy, no_clean, no_sync]
 
-    def add_arguments(self):
-        super(Command, self).add_arguments()
-        self.parser.add_argument(
-            "packages", metavar="package",
-            nargs="+",
-            help="package to upgrade (can be used multiple times)",
-        )
-        self.parser.add_argument(
-            "--strategy",
-            choices=["eager", "only-if-needed"],
-            default="only-if-needed",
-            help="how dependency upgrading is handled",
-        )
-        self.parser.add_argument(
-            "--no-sync", dest="sync",
-            action="store_false", default=True,
-            help="do not synchronize the environment",
-        )
-        self.parser.add_argument(
-            "--no-clean", dest="clean",
-            action="store_false", default=True,
-            help="do not uninstall packages not specified in Pipfile.lock",
-        )
+    def run(self, options):
+        return upgrade(project=options.project, strategy=options.strategy,
+                            sync=options.sync, packages=options.packages)
 
 
 if __name__ == "__main__":
-    Command.run_current_module()
+    Command.run_parser()
diff --git a/pipenv/vendor/passa/internals/_pip.py b/pipenv/vendor/passa/internals/_pip.py
index b7629713..2aa143a2 100644
--- a/pipenv/vendor/passa/internals/_pip.py
+++ b/pipenv/vendor/passa/internals/_pip.py
@@ -3,19 +3,22 @@
 from __future__ import absolute_import, unicode_literals
 
 import contextlib
+import io
+import itertools
 import distutils.log
 import os
 
-import setuptools.dist
-
+import distlib.database
 import distlib.scripts
 import distlib.wheel
+import packaging.utils
 import pip_shims
+import setuptools.dist
 import six
 import vistir
 
+from ..models.caches import CACHE_DIR
 from ._pip_shims import VCS_SUPPORT, build_wheel as _build_wheel, unpack_url
-from .caches import CACHE_DIR
 from .utils import filter_sources
 
 
@@ -44,7 +47,6 @@ def _prepare_wheel_building_kwargs(ireq):
     else:
         src_dir = vistir.path.create_tracked_tempdir(prefix='passa-src')
 
-
     # This logic matches pip's behavior, although I don't fully understand the
     # intention. I guess the idea is to build editables in-place, otherwise out
     # of the source tree?
@@ -128,6 +130,10 @@ def _convert_hashes(values):
     return hashes
 
 
+class WheelBuildError(RuntimeError):
+    pass
+
+
 def build_wheel(ireq, sources, hashes=None):
     """Build a wheel file for the InstallRequirement object.
 
@@ -138,8 +144,8 @@ def build_wheel(ireq, sources, hashes=None):
     If `hashes` is truthy, it is assumed to be a list of hashes (as formatted
     in Pipfile.lock) to be checked against the download.
 
-    Returns a `distlib.wheel.Wheel` instance. Raises a `RuntimeError` if the
-    wheel cannot be built.
+    Returns a `distlib.wheel.Wheel` instance. Raises a `WheelBuildError` (a
+    `RuntimeError` subclass) if the wheel cannot be built.
     """
     kwargs = _prepare_wheel_building_kwargs(ireq)
     finder = _get_finder(sources)
@@ -172,7 +178,7 @@ def build_wheel(ireq, sources, hashes=None):
         unpack_url(
             ireq.link, ireq.source_dir, download_dir,
             only_download=only_download, session=finder.session,
-            hashes=ireq.hashes(False), progress_bar=False,
+            hashes=ireq.hashes(False), progress_bar="off",
         )
 
     if ireq.is_wheel:
@@ -186,7 +192,7 @@ def build_wheel(ireq, sources, hashes=None):
             finder, _get_wheel_cache(), kwargs,
         )
         if wheel_path is None or not os.path.exists(wheel_path):
-            raise RuntimeError("failed to build wheel from {}".format(ireq))
+            raise WheelBuildError
     return distlib.wheel.Wheel(wheel_path)
 
 
@@ -202,7 +208,7 @@ def _obtrain_ref(vcs_obj, src_dir, name, rev=None):
 
 
 def get_vcs_ref(requirement):
-    backend = VCS_SUPPORT._registry.get(requirement.vcs)
+    backend = VCS_SUPPORT.get_backend(requirement.vcs)
     vcs = backend(url=requirement.req.vcs_uri)
     src = _get_src_dir()
     name = requirement.normalized_name
@@ -215,7 +221,7 @@ def find_installation_candidates(ireq, sources):
     return finder.find_all_candidates(ireq.name)
 
 
-class RequirementUninstallation(object):
+class RequirementUninstaller(object):
     """A context manager to remove a package for the inner block.
 
     This uses `UninstallPathSet` to control the workflow. If the inner block
@@ -243,8 +249,9 @@ class RequirementUninstallation(object):
             self.pathset.rollback()
 
 
-def uninstall_requirement(ireq, **kwargs):
-    return RequirementUninstallation(ireq, **kwargs)
+def uninstall(name, **kwargs):
+    ireq = pip_shims.InstallRequirement.from_line(name)
+    return RequirementUninstaller(ireq, **kwargs)
 
 
 @contextlib.contextmanager
@@ -315,3 +322,76 @@ class WheelInstaller(NoopInstaller):
 
     def install(self):
         self.wheel.install(self.paths, distlib.scripts.ScriptMaker(None, None))
+
+
+def _iter_egg_info_directories(root, name):
+    name = packaging.utils.canonicalize_name(name)
+    for parent, dirnames, filenames in os.walk(root):
+        matched_indexes = []
+        for i, dirname in enumerate(dirnames):
+            if not dirname.lower().endswith("egg-info"):
+                continue
+            egg_info_name = packaging.utils.canonicalize_name(dirname[:-9])
+            if egg_info_name != name:
+                continue
+            matched_indexes.append(i)
+            yield os.path.join(parent, dirname)
+
+        # Modify dirnames in-place to NOT look into egg-info directories.
+        # This is a documented behavior in stdlib.
+        for i in reversed(matched_indexes):
+            del dirnames[i]
+
+
+def _read_pkg_info(directory):
+    path = os.path.join(directory, "PKG-INFO")
+    try:
+        with io.open(path, encoding="utf-8", errors="replace") as f:
+            return f.read()
+    except (IOError, OSError):
+        return None
+
+
+def _find_egg_info(ireq):
+    """Find this package's .egg-info directory.
+
+    Due to how sdists are designed, the .egg-info directory cannot be reliably
+    found without running setup.py to aggregate all configurations. This
+    function instead uses some heuristics to locate the egg-info directory
+    that most likely represents this package.
+
+    The best .egg-info directory's path is returned as a string. None is
+    returned if no matches can be found.
+    """
+    root = ireq.setup_py_dir
+
+    directory_iterator = _iter_egg_info_directories(root, ireq.name)
+    try:
+        top_egg_info = next(directory_iterator)
+    except StopIteration:   # No egg-info found. Wat.
+        return None
+    directory_iterator = itertools.chain([top_egg_info], directory_iterator)
+
+    # Read the sdist's PKG-INFO to determine which egg_info is best.
+    pkg_info = _read_pkg_info(root)
+
+    # PKG-INFO not readable. Just return whatever comes first, I guess.
+    if pkg_info is None:
+        return top_egg_info
+
+    # Walk the sdist to find the egg-info with matching PKG-INFO.
+    for directory in directory_iterator:
+        egg_pkg_info = _read_pkg_info(directory)
+        if egg_pkg_info == pkg_info:
+            return directory
+
+    # Nothing matches...? Use the first one we found, I guess.
+    return top_egg_info
+
+
+def read_sdist_metadata(ireq):
+    egg_info_dir = _find_egg_info(ireq)
+    if not egg_info_dir:
+        return None
+    distribution = distlib.database.EggInfoDistribution(egg_info_dir)
+    return distribution.metadata
diff --git a/pipenv/vendor/passa/internals/candidates.py b/pipenv/vendor/passa/internals/candidates.py
index 1b154bbf..67b09049 100644
--- a/pipenv/vendor/passa/internals/candidates.py
+++ b/pipenv/vendor/passa/internals/candidates.py
@@ -2,9 +2,6 @@
 
 from __future__ import absolute_import, unicode_literals
 
-import os
-import sys
-
 import packaging.specifiers
 import packaging.version
 import requirementslib
@@ -12,13 +9,17 @@ import requirementslib
 from ._pip import find_installation_candidates, get_vcs_ref
 
 
-def _filter_matching_python_requirement(candidates, python_version):
+def _filter_matching_python_requirement(candidates, required_python):
+    # TODO: This should also takes the parent's python_version and
+    # python_full_version markers, and only return matches with valid
+    # intersections. For example, if parent requires `python_version >= '3.0'`,
+    # this should not return entries with "Requires-Python: <3".
     for c in candidates:
         try:
             requires_python = c.requires_python
         except AttributeError:
             requires_python = c.location.requires_python
-        if python_version and requires_python:
+        if required_python and requires_python:
             # Old specifications had people setting this to single digits
             # which is effectively the same as '>=digit,<digit+1'
             if requires_python.isdigit():
@@ -29,7 +30,7 @@ def _filter_matching_python_requirement(candidates, python_version):
                 specset = packaging.specifiers.SpecifierSet(requires_python)
             except packaging.specifiers.InvalidSpecifier:
                 continue
-            if not specset.contains(python_version):
+            if not specset.contains(required_python):
                 continue
         yield c
 
@@ -50,7 +51,7 @@ def _requirement_from_metadata(name, version, extras, index):
     return r
 
 
-def find_candidates(requirement, sources, allow_prereleases):
+def find_candidates(requirement, sources, requires_python, allow_prereleases):
     # A non-named requirement has exactly one candidate that is itself. For
     # VCS, we also lock the requirement to an exact ref.
     if not requirement.is_named:
@@ -62,13 +63,9 @@ def find_candidates(requirement, sources, allow_prereleases):
     ireq = requirement.as_ireq()
     icans = find_installation_candidates(ireq, sources)
 
-    python_version = os.environ.get(
-        "PASSA_PYTHON_VERSION",
-        "{0[0]}.{0[1]}".format(sys.version_info),
-    )
-    if python_version != ":all:":
+    if requires_python:
         matching_icans = list(_filter_matching_python_requirement(
-            icans, packaging.version.parse(python_version),
+            icans, packaging.version.parse(requires_python),
         ))
         icans = matching_icans or icans
 
diff --git a/pipenv/vendor/passa/internals/dependencies.py b/pipenv/vendor/passa/internals/dependencies.py
index 60087ec5..53b19b17 100644
--- a/pipenv/vendor/passa/internals/dependencies.py
+++ b/pipenv/vendor/passa/internals/dependencies.py
@@ -13,8 +13,8 @@ import requests
 import requirementslib
 import six
 
-from ._pip import build_wheel
-from .caches import DependencyCache, RequiresPythonCache
+from ..models.caches import DependencyCache, RequiresPythonCache
+from ._pip import WheelBuildError, build_wheel, read_sdist_metadata
 from .markers import contains_extra, get_contained_extras, get_without_extra
 from .utils import get_pinned_version, is_pinned
 
@@ -91,16 +91,20 @@ def _get_dependencies_from_json_url(url, session):
     except KeyError:
         requirement_lines = info["requires"]
 
-    # The JSON API return null for empty requirements, for some reason, so we
-    # can't just pass it into the comprehension.
-    if not requirement_lines:
-        return [], requires_python
-
-    dependencies = [
-        dep_req.as_line(include_hashes=False) for dep_req in (
+    # The JSON API returns null both when there are not requirements, or the
+    # requirement list cannot be retrieved. We can't safely assume, so it's
+    # better to drop it and fall back to downloading the package.
+    try:
+        dependency_requirements_iterator = (
             requirementslib.Requirement.from_line(line)
             for line in requirement_lines
         )
+    except TypeError:
+        return
+
+    dependencies = [
+        dep_req.as_line(include_hashes=False)
+        for dep_req in dependency_requirements_iterator
         if not contains_extra(dep_req.markers)
     ]
     return dependencies, requires_python
@@ -149,8 +153,7 @@ def _get_dependencies_from_json(ireq, sources):
             if dependencies is not None:
                 return dependencies
         except Exception as e:
-            pass
-        print("unable to read dependencies via {0}".format(url))
+            print("unable to read dependencies via {0} ({1})".format(url, e))
     return
 
 
@@ -214,13 +217,27 @@ def _read_requires_python(metadata):
 def _get_dependencies_from_pip(ireq, sources):
     """Retrieves dependencies for the requirement from pipenv.patched.notpip internals.
 
-    The current strategy is to build a wheel out of the ireq, and read metadata
-    out of it.
+    The current strategy is to try the followings in order, returning the
+    first successful result.
+
+    1. Try to build a wheel out of the ireq, and read metadata out of it.
+    2. Read metadata out of the egg-info directory if it is present.
     """
-    wheel = build_wheel(ireq, sources)
     extras = ireq.extras or ()
-    requirements = _read_requirements(wheel.metadata, extras)
-    requires_python = _read_requires_python(wheel.metadata)
+    try:
+        wheel = build_wheel(ireq, sources)
+    except WheelBuildError:
+        # XXX: This depends on a side effect of `build_wheel`. This block is
+        # reached when it fails to build an sdist, where the sdist would have
+        # been downloaded, extracted into `ireq.source_dir`, and partially
+        # built (hopefully containing .egg-info).
+        metadata = read_sdist_metadata(ireq)
+        if not metadata:
+            raise
+    else:
+        metadata = wheel.metadata
+    requirements = _read_requirements(metadata, extras)
+    requires_python = _read_requires_python(metadata)
     return requirements, requires_python
 
 
diff --git a/pipenv/vendor/passa/models/__init__.py b/pipenv/vendor/passa/models/__init__.py
new file mode 100644
index 00000000..e69de29b
diff --git a/pipenv/vendor/passa/internals/caches.py b/pipenv/vendor/passa/models/caches.py
similarity index 98%
rename from pipenv/vendor/passa/internals/caches.py
rename to pipenv/vendor/passa/models/caches.py
index 6d3131fa..c6d29b5e 100644
--- a/pipenv/vendor/passa/internals/caches.py
+++ b/pipenv/vendor/passa/models/caches.py
@@ -13,8 +13,8 @@ import pip_shims
 import requests
 import vistir
 
-from ._pip_shims import VCS_SUPPORT
-from .utils import get_pinned_version
+from ..internals._pip_shims import VCS_SUPPORT
+from ..internals.utils import get_pinned_version
 
 
 CACHE_DIR = os.environ.get("PASSA_CACHE_DIR", appdirs.user_cache_dir("passa"))
diff --git a/pipenv/vendor/passa/internals/lockers.py b/pipenv/vendor/passa/models/lockers.py
similarity index 86%
rename from pipenv/vendor/passa/internals/lockers.py
rename to pipenv/vendor/passa/models/lockers.py
index 4f7a722b..c25ca60d 100644
--- a/pipenv/vendor/passa/internals/lockers.py
+++ b/pipenv/vendor/passa/models/lockers.py
@@ -4,18 +4,19 @@ from __future__ import absolute_import, unicode_literals
 
 import itertools
 
+import resolvelib
+
 import plette
 import requirementslib
-import resolvelib
 import vistir
 
+from ..internals.hashes import get_hashes
+from ..internals.reporters import StdOutReporter
+from ..internals.traces import trace_graph
+from ..internals.utils import identify_requirment
 from .caches import HashCache
-from .hashes import get_hashes
 from .metadata import set_metadata
 from .providers import BasicProvider, EagerUpgradeProvider, PinReuseProvider
-from .reporters import StdOutReporter
-from .traces import trace_graph
-from .utils import identify_requirment
 
 
 def _get_requirements(model, section_name):
@@ -29,6 +30,21 @@ def _get_requirements(model, section_name):
     )}
 
 
+def _get_requires_python(pipfile):
+    try:
+        requires = pipfile.requires
+    except AttributeError:
+        return ""
+    try:
+        return requires.python_full_version
+    except AttributeError:
+        pass
+    try:
+        return requires.python_version
+    except AttributeError:
+        return ""
+
+
 def _collect_derived_entries(state, traces, identifiers):
     """Produce a mapping containing all candidates derived from `identifiers`.
 
@@ -93,6 +109,7 @@ class AbstractLocker(object):
         self.allow_prereleases = bool(
             project.pipfile.get("pipenv", {}).get("allow_prereleases", False),
         )
+        self.requires_python = _get_requires_python(project.pipfile)
 
     def __repr__(self):
         return "<{0} @ {1!r}>".format(type(self).__name__, self.project.root)
@@ -132,7 +149,8 @@ class AbstractLocker(object):
 
         set_metadata(
             state.mapping, traces,
-            provider.fetched_dependencies, provider.requires_pythons,
+            provider.fetched_dependencies,
+            provider.collected_requires_pythons,
         )
 
         lockfile = plette.Lockfile.with_meta_from(self.project.pipfile)
@@ -153,7 +171,8 @@ class BasicLocker(AbstractLocker):
     """
     def get_provider(self):
         return BasicProvider(
-            self.requirements, self.sources, self.allow_prereleases,
+            self.requirements, self.sources,
+            self.requires_python, self.allow_prereleases,
         )
 
 
@@ -172,8 +191,8 @@ class PinReuseLocker(AbstractLocker):
 
     def get_provider(self):
         return PinReuseProvider(
-            self.preferred_pins,
-            self.requirements, self.sources, self.allow_prereleases,
+            self.preferred_pins, self.requirements, self.sources,
+            self.requires_python, self.allow_prereleases,
         )
 
 
@@ -190,5 +209,6 @@ class EagerUpgradeLocker(PinReuseLocker):
     def get_provider(self):
         return EagerUpgradeProvider(
             self.tracked_names, self.preferred_pins,
-            self.requirements, self.sources, self.allow_prereleases,
+            self.requirements, self.sources,
+            self.requires_python, self.allow_prereleases,
         )
diff --git a/pipenv/vendor/passa/internals/metadata.py b/pipenv/vendor/passa/models/metadata.py
similarity index 97%
rename from pipenv/vendor/passa/internals/metadata.py
rename to pipenv/vendor/passa/models/metadata.py
index 9709c535..a949f1e9 100644
--- a/pipenv/vendor/passa/internals/metadata.py
+++ b/pipenv/vendor/passa/models/metadata.py
@@ -10,8 +10,8 @@ import packaging.specifiers
 import vistir
 import vistir.misc
 
-from .markers import get_without_extra
-from .specifiers import cleanup_pyspecs, pyspec_from_markers
+from ..internals.markers import get_without_extra
+from ..internals.specifiers import cleanup_pyspecs, pyspec_from_markers
 
 
 def dedup_markers(s):
diff --git a/pipenv/vendor/passa/internals/projects.py b/pipenv/vendor/passa/models/projects.py
similarity index 96%
rename from pipenv/vendor/passa/internals/projects.py
rename to pipenv/vendor/passa/models/projects.py
index 6a9fcce5..f6e037d6 100644
--- a/pipenv/vendor/passa/internals/projects.py
+++ b/pipenv/vendor/passa/models/projects.py
@@ -218,8 +218,14 @@ class Project(object):
             "develop": SectionDifference({}, {}),
         }
         for section_name, section_diff in diff_data.items():
-            this = self.lockfile[section_name]._data
-            that = lockfile[section_name]._data
+            try:
+                this = self.lockfile[section_name]._data
+            except (KeyError, TypeError):
+                this = {}
+            try:
+                that = lockfile[section_name]._data
+            except (KeyError, TypeError):
+                that = {}
             for key, this_value in this.items():
                 try:
                     that_value = that[key]
diff --git a/pipenv/vendor/passa/internals/providers.py b/pipenv/vendor/passa/models/providers.py
similarity index 92%
rename from pipenv/vendor/passa/internals/providers.py
rename to pipenv/vendor/passa/models/providers.py
index 1c062af7..36b2f2ea 100644
--- a/pipenv/vendor/passa/internals/providers.py
+++ b/pipenv/vendor/passa/models/providers.py
@@ -6,11 +6,10 @@ import os
 
 import resolvelib
 
-from .candidates import find_candidates
-from .dependencies import get_dependencies
-from .utils import (
-    filter_sources, get_allow_prereleases,
-    are_requirements_equal, identify_requirment, strip_extras,
+from ..internals.candidates import find_candidates
+from ..internals.dependencies import get_dependencies
+from ..internals.utils import (
+    filter_sources, get_allow_prereleases, identify_requirment, strip_extras,
 )
 
 
@@ -20,8 +19,10 @@ PROTECTED_PACKAGE_NAMES = {"pip", "setuptools"}
 class BasicProvider(resolvelib.AbstractProvider):
     """Provider implementation to interface with `requirementslib.Requirement`.
     """
-    def __init__(self, root_requirements, sources, allow_prereleases):
+    def __init__(self, root_requirements, sources,
+                 requires_python, allow_prereleases):
         self.sources = sources
+        self.requires_python = requires_python
         self.allow_prereleases = bool(allow_prereleases)
         self.invalid_candidates = set()
 
@@ -33,9 +34,9 @@ class BasicProvider(resolvelib.AbstractProvider):
         self.fetched_dependencies = {None: {
             self.identify(r): r for r in root_requirements
         }}
-        # TODO: Find a way to resolve with multiple versions (by tricking
-        # runtime) Include multiple keys in pipfiles?
-        self.requires_pythons = {None: ""}  # TODO: Don't use any value
+
+        # Should Pipfile's requires.python_[full_]version be included?
+        self.collected_requires_pythons = {None: ""}
 
     def identify(self, dependency):
         return identify_requirment(dependency)
@@ -46,8 +47,9 @@ class BasicProvider(resolvelib.AbstractProvider):
         return len(candidates)
 
     def find_matches(self, requirement):
+        sources = filter_sources(requirement, self.sources)
         candidates = find_candidates(
-            requirement, filter_sources(requirement, self.sources),
+            requirement, sources, self.requires_python,
             get_allow_prereleases(requirement, self.allow_prereleases),
         )
         return candidates
@@ -118,7 +120,7 @@ class BasicProvider(resolvelib.AbstractProvider):
         self.fetched_dependencies[candidate_key] = {
             self.identify(r): r for r in dependencies
         }
-        self.requires_pythons[candidate_key] = requires_python
+        self.collected_requires_pythons[candidate_key] = requires_python
         return dependencies
 
 
diff --git a/pipenv/vendor/passa/internals/synchronizers.py b/pipenv/vendor/passa/models/synchronizers.py
similarity index 91%
rename from pipenv/vendor/passa/internals/synchronizers.py
rename to pipenv/vendor/passa/models/synchronizers.py
index 2a1f1d18..bad49052 100644
--- a/pipenv/vendor/passa/internals/synchronizers.py
+++ b/pipenv/vendor/passa/models/synchronizers.py
@@ -14,7 +14,7 @@ import packaging.markers
 import packaging.version
 import requirementslib
 
-from ._pip import uninstall_requirement, EditableInstaller, WheelInstaller
+from ..internals._pip import uninstall, EditableInstaller, WheelInstaller
 
 
 def _is_installation_local(name):
@@ -23,8 +23,9 @@ def _is_installation_local(name):
     This is used to distinguish packages seen by a virtual environment. A venv
     may be able to see global packages, but we don't want to mess with them.
     """
-    location = pkg_resources.working_set.by_key[name].location
-    return os.path.commonprefix([location, sys.prefix]) == sys.prefix
+    loc = os.path.normcase(pkg_resources.working_set.by_key[name].location)
+    pre = os.path.normcase(sys.prefix)
+    return os.path.commonprefix([loc, pre]) == pre
 
 
 def _is_up_to_date(distro, version):
@@ -76,11 +77,10 @@ def _group_installed_names(packages):
 @contextlib.contextmanager
 def _remove_package(name):
     if name is None or not _is_installation_local(name):
-        yield
+        yield None
         return
-    r = requirementslib.Requirement.from_line(name)
-    with uninstall_requirement(r.as_ireq(), auto_confirm=True, verbose=False):
-        yield
+    with uninstall(name, auto_confirm=True, verbose=False) as uninstaller:
+        yield uninstaller
 
 
 def _get_packages(lockfile, default, develop):
@@ -109,7 +109,7 @@ def _build_paths():
     }
 
 
-PROTECTED_FROM_CLEAN = {"setuptools", "pip"}
+PROTECTED_FROM_CLEAN = {"setuptools", "pip", "wheel"}
 
 
 def _clean(names):
@@ -117,9 +117,9 @@ def _clean(names):
     for name in names:
         if name in PROTECTED_FROM_CLEAN:
             continue
-        with _remove_package(name):
-            pass
-        cleaned.add(name)
+        with _remove_package(name) as uninst:
+            if uninst:
+                cleaned.add(name)
     return cleaned
 
 
@@ -210,5 +210,5 @@ class Cleaner(object):
 
     def clean(self):
         groupcoll = _group_installed_names(self.packages)
-        _clean(groupcoll.unneeded)
-        return groupcoll.unneeded
+        cleaned = _clean(groupcoll.unneeded)
+        return cleaned
diff --git a/pipenv/vendor/pip_shims/__init__.py b/pipenv/vendor/pip_shims/__init__.py
index acaeee25..8cb2bca1 100644
--- a/pipenv/vendor/pip_shims/__init__.py
+++ b/pipenv/vendor/pip_shims/__init__.py
@@ -1,79 +1,24 @@
 # -*- coding=utf-8 -*-
 from __future__ import absolute_import
 
-__version__ = '0.1.2'
+import sys
 
-__all__ = [
-    "__version__",
-    "_strip_extras",
-    "cmdoptions",
-    "Command",
-    "ConfigOptionParser",
-    "DistributionNotFound",
-    "FAVORITE_HASH",
-    "FormatControl",
-    "get_installed_distributions",
-    "index_group",
-    "InstallRequirement",
-    "is_archive_file",
-    "is_file_url",
-    "is_installable_dir",
-    "unpack_url",
-    "Link",
-    "make_abstract_dist",
-    "make_option_group",
-    "PackageFinder",
-    "parse_requirements",
-    "parse_version",
-    "path_to_url",
-    "pip_version",
-    "PipError",
-    "RequirementPreparer",
-    "RequirementSet",
-    "RequirementTracker",
-    "Resolver",
-    "SafeFileCache",
-    "url_to_path",
-    "USER_CACHE_DIR",
-    "VcsSupport",
-    "Wheel",
-    "WheelCache",
-    "WheelBuilder"
-]
+__version__ = '0.3.0'
 
-from .shims import (
-    _strip_extras,
-    cmdoptions,
-    Command,
-    ConfigOptionParser,
-    DistributionNotFound,
-    FAVORITE_HASH,
-    FormatControl,
-    get_installed_distributions,
-    index_group,
-    InstallRequirement,
-    is_archive_file,
-    is_file_url,
-    unpack_url,
-    is_installable_dir,
-    Link,
-    make_abstract_dist,
-    make_option_group,
-    PackageFinder,
-    parse_requirements,
-    parse_version,
-    path_to_url,
-    pip_version,
-    PipError,
-    RequirementPreparer,
-    RequirementSet,
-    RequirementTracker,
-    Resolver,
-    SafeFileCache,
-    url_to_path,
-    USER_CACHE_DIR,
-    VcsSupport,
-    Wheel,
-    WheelCache,
-    WheelBuilder,
-)
+from . import shims
+
+
+old_module = sys.modules["pip_shims"]
+
+
+module = sys.modules["pip_shims"] = shims._new()
+module.shims = shims
+module.__dict__.update({
+    '__file__': __file__,
+    '__package__': "pip_shims",
+    '__path__': __path__,
+    '__doc__': __doc__,
+    '__all__': module.__all__ + ['shims',],
+    '__version__': __version__,
+    '__name__': __name__
+})
diff --git a/pipenv/vendor/pip_shims/shims.py b/pipenv/vendor/pip_shims/shims.py
index 5fc58beb..656ff7f5 100644
--- a/pipenv/vendor/pip_shims/shims.py
+++ b/pipenv/vendor/pip_shims/shims.py
@@ -1,163 +1,326 @@
 # -*- coding=utf-8 -*-
 from collections import namedtuple
 from contextlib import contextmanager
-from .utils import _parse, get_package, STRING_TYPES
 import importlib
 import os
-from pipenv.patched.notpip import __version__ as pip_version
 import sys
 
 
-has_modutil = False
-if sys.version_info[:2] >= (3, 7):
-    try:
-        import modutil
-    except ImportError:
-        has_modutil = False
-    else:
-        has_modutil = True
-
-
-BASE_IMPORT_PATH = os.environ.get("PIP_SHIMS_BASE_MODULE", "pip")
-path_info = namedtuple("PathInfo", "path start_version end_version")
-parsed_pip_version = _parse(pip_version)
-
-
-def is_valid(path_info_tuple):
-    if (
-        path_info_tuple.start_version <= parsed_pip_version
-        and path_info_tuple.end_version >= parsed_pip_version
-    ):
-        return 1
-    return 0
-
-
-def get_ordered_paths(module_paths, base_path):
-    if not isinstance(module_paths, list):
-        module_paths = [module_paths]
-    prefix_order = [pth.format(base_path) for pth in ["{0}._internal", "{0}"]]
-    if _parse(pip_version) < _parse("10.0.0"):
-        prefix_order = reversed(prefix_order)
-    paths = sorted(module_paths, key=is_valid, reverse=True)
-    search_order = [
-        "{0}.{1}".format(p, pth.path)
-        for p in prefix_order
-        for pth in paths
-        if pth is not None
-    ]
-    return search_order
-
-
-def do_import(module_paths, base_path=BASE_IMPORT_PATH):
-    search_order = get_ordered_paths(module_paths, base_path)
-    imported = None
-    if has_modutil:
-        pkgs = [get_package(pkg) for pkg in search_order]
-        imports = [
-            modutil.lazy_import(__name__, {to_import}) for to_import, pkg in pkgs
-        ]
-        imp_getattrs = [imp_getattr for mod, imp_getattr in imports]
-        chained = modutil.chained___getattr__(__name__, *imp_getattrs)
+import six
+six.add_move(six.MovedAttribute("Callable", "collections", "collections.abc"))
+from six.moves import Callable
+
+
+class _shims(object):
+    CURRENT_PIP_VERSION  = "18.1"
+    BASE_IMPORT_PATH = os.environ.get("PIP_SHIMS_BASE_MODULE", "pip")
+    path_info = namedtuple("PathInfo", "path start_version end_version")
+
+    def __dir__(self):
+        result = list(self._locations.keys()) + list(self.__dict__.keys())
+        result.extend(('__file__', '__doc__', '__all__',
+                       '__docformat__', '__name__', '__path__',
+                       '__package__', '__version__'))
+        return result
+
+    @classmethod
+    def _new(cls):
+        return cls()
+
+    @property
+    def __all__(self):
+        return list(self._locations.keys())
+
+    def __init__(self):
+        from .utils import _parse, get_package, STRING_TYPES
+        self._parse = _parse
+        self.get_package = get_package
+        self.STRING_TYPES = STRING_TYPES
+        self._modules = {
+            "pip": importlib.import_module("pip"),
+        }
+        self.pip_version = getattr(self._modules["pip"], "__version__")
+        self.parsed_pip_version = self._parse(self.pip_version)
+        self._contextmanagers = ("RequirementTracker",)
+        self._moves = {
+            "InstallRequirement": {
+                "from_editable": "install_req_from_editable",
+                "from_line": "install_req_from_line",
+            }
+        }
+        self._locations = {
+            "parse_version": ("index.parse_version", "7", "9999"),
+            "_strip_extras": (
+                ("req.req_install._strip_extras", "7", "18.0"),
+                ("req.constructors._strip_extras", "18.1", "9999"),
+            ),
+            "cmdoptions": (
+                ("cli.cmdoptions", "18.1", "9999"),
+                ("cmdoptions", "7.0.0", "18.0")
+            ),
+            "Command": (
+                ("cli.base_command.Command", "18.1", "9999"),
+                ("basecommand.Command", "7.0.0", "18.0")
+            ),
+            "ConfigOptionParser": (
+                ("cli.parser.ConfigOptionParser", "18.1", "9999"),
+                ("baseparser.ConfigOptionParser", "7.0.0", "18.0")
+            ),
+            "DistributionNotFound": ("exceptions.DistributionNotFound", "7.0.0", "9999"),
+            "FAVORITE_HASH": ("utils.hashes.FAVORITE_HASH", "7.0.0", "9999"),
+            "FormatControl": (
+                ("models.format_control.FormatControl", "18.1", "9999"),
+                ("index.FormatControl", "7.0.0", "18.0"),
+            ),
+            "FrozenRequirement": (
+                ("FrozenRequirement", "7.0.0", "9.0.3"),
+                ("operations.freeze.FrozenRequirement", "10.0.0", "9999")
+            ),
+            "get_installed_distributions": (
+                ("utils.misc.get_installed_distributions", "10", "9999"),
+                ("utils.get_installed_distributions", "7", "9.0.3")
+            ),
+            "index_group": (
+                ("cli.cmdoptions.index_group", "18.1", "9999"),
+                ("cmdoptions.index_group", "7.0.0", "18.0")
+            ),
+            "InstallRequirement": ("req.req_install.InstallRequirement", "7.0.0", "9999"),
+            "install_req_from_editable": (
+                ("req.constructors.install_req_from_editable", "18.1", "9999"),
+                ("req.req_install.InstallRequirement.from_editable", "7.0.0", "18.0")
+            ),
+            "install_req_from_line": (
+                ("req.constructors.install_req_from_line", "18.1", "9999"),
+                ("req.req_install.InstallRequirement.from_line", "7.0.0", "18.0")
+            ),
+            "is_archive_file": ("download.is_archive_file", "7.0.0", "9999"),
+            "is_file_url": ("download.is_file_url", "7.0.0", "9999"),
+            "unpack_url": ("download.unpack_url", "7.0.0", "9999"),
+            "is_installable_dir": (
+                ("utils.misc.is_installable_dir", "10.0.0", "9999"),
+                ("utils.is_installable_dir", "7.0.0", "9.0.3")
+            ),
+            "Link": ("index.Link", "7.0.0", "9999"),
+            "make_abstract_dist": (
+                ("operations.prepare.make_abstract_dist", "10.0.0", "9999"),
+                ("req.req_set.make_abstract_dist", "7.0.0", "9.0.3")
+            ),
+            "make_option_group": (
+                ("cli.cmdoptions.make_option_group", "18.1", "9999"),
+                ("cmdoptions.make_option_group", "7.0.0", "18.0")
+            ),
+            "PackageFinder": ("index.PackageFinder", "7.0.0", "9999"),
+            "parse_requirements": ("req.req_file.parse_requirements", "7.0.0", "9999"),
+            "parse_version": ("index.parse_version", "7.0.0", "9999"),
+            "path_to_url": ("download.path_to_url", "7.0.0", "9999"),
+            "PipError": ("exceptions.PipError", "7.0.0", "9999"),
+            "RequirementPreparer": ("operations.prepare.RequirementPreparer", "7", "9999"),
+            "RequirementSet": ("req.req_set.RequirementSet", "7.0.0", "9999"),
+            "RequirementTracker": ("req.req_tracker.RequirementTracker", "7.0.0", "9999"),
+            "Resolver": ("resolve.Resolver", "7.0.0", "9999"),
+            "SafeFileCache": ("download.SafeFileCache", "7.0.0", "9999"),
+            "UninstallPathSet": ("req.req_uninstall.UninstallPathSet", "7.0.0", "9999"),
+            "url_to_path": ("download.url_to_path", "7.0.0", "9999"),
+            "USER_CACHE_DIR": ("locations.USER_CACHE_DIR", "7.0.0", "9999"),
+            "VcsSupport": ("vcs.VcsSupport", "7.0.0", "9999"),
+            "Wheel": ("wheel.Wheel", "7.0.0", "9999"),
+            "WheelCache": (
+                ("cache.WheelCache", "10.0.0", "9999"),
+                ("wheel.WheelCache", "7", "9.0.3")
+            ),
+            "WheelBuilder": ("wheel.WheelBuilder", "7.0.0", "9999"),
+        }
+
+    def _ensure_methods(self, cls, classname, *methods):
+        method_names = [m[0] for m in methods]
+        if all(getattr(cls, m, None) for m in method_names):
+            return cls
+        new_functions = {}
+        class BaseFunc(Callable):
+            def __init__(self, func_base, name, *args, **kwargs):
+                self.func = func_base
+                self.__name__ = self.__qualname__ = name
+
+            def __call__(self, cls, *args, **kwargs):
+                return self.func(*args, **kwargs)
+
+        for method_name, fn in methods:
+            new_functions[method_name] = classmethod(BaseFunc(fn, method_name))
+        if six.PY2:
+            classname = classname.encode(sys.getdefaultencoding())
+        type_ = type(
+            classname,
+            (cls,),
+            new_functions
+        )
+        return type_
+
+    def _get_module_paths(self, module, base_path=None):
+        if not base_path:
+            base_path = self.BASE_IMPORT_PATH
+        module = self._locations[module]
+        if not isinstance(next(iter(module)), (tuple, list)):
+            module_paths = self.get_pathinfo(module)
+        else:
+            module_paths = [self.get_pathinfo(pth) for pth in module]
+        return self.sort_paths(module_paths, base_path)
+
+    def _get_remapped_methods(self, moved_package):
+        original_base, original_target = moved_package
+        original_import = self._import(self._locations[original_target])
+        old_to_new = {}
+        new_to_old = {}
+        for method_name, new_method_name in self._moves.get(original_target, {}).items():
+            module_paths = self._get_module_paths(new_method_name)
+            target = next(iter(
+                sorted(set([
+                    tgt for mod, tgt in map(self.get_package, module_paths)
+                ]))), None
+            )
+            old_to_new[method_name] = {
+                "target": target,
+                "name": new_method_name,
+                "location": self._locations[new_method_name],
+                "module": self._import(self._locations[new_method_name])
+            }
+            new_to_old[new_method_name] = {
+                "target": original_target,
+                "name": method_name,
+                "location": self._locations[original_target],
+                "module": original_import
+            }
+        return (old_to_new, new_to_old)
+
+    def _import_moved_module(self, moved_package):
+        old_to_new, new_to_old = self._get_remapped_methods(moved_package)
         imported = None
-        for to_import, pkg in pkgs:
-            _, _, module_name = to_import.rpartition(".")
-            try:
-                imported = chained(module_name)
-            except (modutil.ModuleAttributeError, ImportError):
-                continue
+        method_map = []
+        new_target = None
+        for old_method, remapped in old_to_new.items():
+            new_name = remapped["name"]
+            new_target = new_to_old[new_name]["target"]
+            if not imported:
+                imported = self._modules[new_target] = new_to_old[new_name]["module"]
+            method_map.append((old_method, remapped["module"]))
+        if getattr(imported, "__class__", "") == type:
+            imported = self._ensure_methods(
+                imported, new_target, *method_map
+            )
+        self._modules[new_target] = imported
+        if imported:
+            return imported
+        return
+
+    def _check_moved_methods(self, search_pth, moves):
+        module_paths = [
+            self.get_package(pth) for pth in self._get_module_paths(search_pth)
+        ]
+        moved_methods = [
+            (base, target_cls) for base, target_cls
+            in module_paths if target_cls in moves
+        ]
+        return next(iter(moved_methods), None)
+
+    def __getattr__(self, *args, **kwargs):
+        locations = super(_shims, self).__getattribute__("_locations")
+        contextmanagers = super(_shims, self).__getattribute__("_contextmanagers")
+        moves = super(_shims, self).__getattribute__("_moves")
+        if args[0] in locations:
+            moved_package = self._check_moved_methods(args[0], moves)
+            if moved_package:
+                imported = self._import_moved_module(moved_package)
+                if imported:
+                    return imported
             else:
-                if not imported:
-                    continue
-                return getattr(imported, pkg)
-        if not imported:
-            return
-        return imported
-    for to_import in search_order:
-        to_import, package = get_package(to_import)
+                imported = self._import(locations[args[0]])
+                if not imported and args[0] in contextmanagers:
+                    return self.nullcontext
+                return imported
+        return super(_shims, self).__getattribute__(*args, **kwargs)
+
+    def is_valid(self, path_info_tuple):
+        if (
+            path_info_tuple.start_version <= self.parsed_pip_version
+            and path_info_tuple.end_version >= self.parsed_pip_version
+        ):
+            return 1
+        return 0
+
+    def sort_paths(self, module_paths, base_path):
+        if not isinstance(module_paths, list):
+            module_paths = [module_paths]
+        prefix_order = [pth.format(base_path) for pth in ["{0}._internal", "{0}"]]
+        # Pip 10 introduced the internal api division
+        if self._parse(self.pip_version) < self._parse("10.0.0"):
+            prefix_order = reversed(prefix_order)
+        paths = sorted(module_paths, key=self.is_valid, reverse=True)
+        search_order = [
+            "{0}.{1}".format(p, pth.path)
+            for p in prefix_order
+            for pth in paths
+            if pth is not None
+        ]
+        return search_order
+
+    def import_module(self, module):
+        if module in self._modules:
+            return self._modules[module]
         try:
-            imported = importlib.import_module(to_import)
+            imported = importlib.import_module(module)
         except ImportError:
-            continue
+            imported = None
         else:
-            return getattr(imported, package)
-    return imported
-
-
-def pip_import(import_name, *module_paths):
-    paths = []
-    for pip_path in module_paths:
-        if not isinstance(pip_path, (list, tuple)):
-            module_path, start_version, end_version = module_paths
-            new_path = path_info(module_path, _parse(start_version), _parse(end_version))
-            paths.append(new_path)
-            break
+            self._modules[module] = imported
+        return imported
+
+    def none_or_ctxmanager(self, pkg_name):
+        if pkg_name in self._contextmanagers:
+            return self.nullcontext
+        return None
+
+    def get_package_from_modules(self, modules):
+        modules = [
+            (package_name, self.import_module(m))
+            for m, package_name in map(self.get_package, modules)
+        ]
+        imports = [
+            getattr(m, pkg, self.none_or_ctxmanager(pkg)) for pkg, m in modules
+            if m is not None
+        ]
+        return next(iter(imports), None)
+
+    def _import(self, module_paths, base_path=None):
+        if not base_path:
+            base_path = self.BASE_IMPORT_PATH
+        if not isinstance(next(iter(module_paths)), (tuple, list)):
+            module_paths = self.get_pathinfo(module_paths)
         else:
-            module_path, start_version, end_version = pip_path
-            paths.append(path_info(module_path, _parse(start_version), _parse(end_version)))
-    return do_import(paths)
-
-
-parse_version = pip_import("parse_version", "index.parse_version", "7", "9999")
-_strip_extras = pip_import("_strip_extras", "req.req_install._strip_extras", "7", "9999")
-cmdoptions = pip_import(
-    "", ("cli.cmdoptions", "18.1", "9999"), ("cmdoptions", "7.0.0", "18.0"),
-)
-Command = pip_import("Command",
-    ("cli.base_command.Command", "18.1", "9999"),
-    ("basecommand.Command", "7.0.0", "18.0"),
-)
-ConfigOptionParser = pip_import("ConfigOptionParser",
-    ("cli.parser.ConfigOptionParser", "18.1", "9999"),
-    ("baseparser.ConfigOptionParser", "7.0.0", "18.0"),
-)
-DistributionNotFound = pip_import("DistributionNotFound", "exceptions.DistributionNotFound", "7.0.0", "9999")
-FAVORITE_HASH = pip_import("FAVORITE_HASH", "utils.hashes.FAVORITE_HASH", "7.0.0", "9999")
-FormatControl = pip_import("FormatControl", "index.FormatControl", "7.0.0", "9999")
-get_installed_distributions = pip_import("get_installed_distributions",
-    ("utils.misc.get_installed_distributions", "10", "9999"),
-    ("utils.get_installed_distributions", "7", "9.0.3")
-)
-index_group = pip_import("index_group",
-    ("cli.cmdoptions.index_group", "18.1", "9999"),
-    ("cmdoptions.index_group", "7.0.0", "18.0"),
-)
-InstallRequirement = pip_import("InstallRequirement", "req.req_install.InstallRequirement", "7.0.0", "9999")
-is_archive_file = pip_import("is_archive_file", "download.is_archive_file", "7.0.0", "9999")
-is_file_url = pip_import("is_file_url", "download.is_file_url", "7.0.0", "9999")
-unpack_url = pip_import("unpack_url", "download.unpack_url", "7.0.0", "9999")
-is_installable_dir = pip_import("is_installable_dir",
-    ("utils.misc.is_installable_dir", "10.0.0", "9999"),
-    ("utils.is_installable_dir", "7.0.0", "9.0.3"),
-)
-Link = pip_import("Link", "index.Link", "7.0.0", "9999")
-make_abstract_dist = pip_import("make_abstract_dist",
-    ("operations.prepare.make_abstract_dist", "10.0.0", "9999"),
-    ("req.req_set.make_abstract_dist", "7.0.0", "9.0.3"),
-)
-make_option_group = pip_import("make_option_group",
-    ("cli.cmdoptions.make_option_group", "18.1", "9999"),
-    ("cmdoptions.make_option_group", "7.0.0", "18.0"),
-)
-PackageFinder = pip_import("PackageFinder", "index.PackageFinder", "7.0.0", "9999")
-parse_requirements = pip_import("parse_requirements", "req.req_file.parse_requirements", "7.0.0", "9999")
-parse_version = pip_import("parse_version", "index.parse_version", "7.0.0", "9999")
-path_to_url = pip_import("path_to_url", "download.path_to_url", "7.0.0", "9999")
-PipError = pip_import("PipError", "exceptions.PipError", "7.0.0", "9999")
-RequirementPreparer = pip_import("RequirementPreparer", "operations.prepare.RequirementPreparer", "7", "9999")
-RequirementSet = pip_import("RequirementSet", "req.req_set.RequirementSet", "7.0.0", "9999")
-RequirementTracker = pip_import("RequirementTracker", "req.req_tracker.RequirementTracker", "7.0.0", "9999")
-Resolver = pip_import("Resolver", "resolve.Resolver", "7.0.0", "9999")
-SafeFileCache = pip_import("SafeFileCache", "download.SafeFileCache", "7.0.0", "9999")
-url_to_path = pip_import("url_to_path", "download.url_to_path", "7.0.0", "9999")
-USER_CACHE_DIR = pip_import("USER_CACHE_DIR", "locations.USER_CACHE_DIR", "7.0.0", "9999")
-VcsSupport = pip_import("VcsSupport", "vcs.VcsSupport", "7.0.0", "9999")
-Wheel = pip_import("Wheel", "wheel.Wheel", "7.0.0", "9999")
-WheelCache = pip_import("WheelCache", ("cache.WheelCache", "10.0.0", "9999"), ("wheel.WheelCache", "7", "9.0.3"))
-WheelBuilder = pip_import("WheelBuilder", "wheel.WheelBuilder", "7.0.0", "9999")
-
-
-if not RequirementTracker:
+            module_paths = [self.get_pathinfo(pth) for pth in module_paths]
+        search_order = self.sort_paths(module_paths, base_path)
+        return self.get_package_from_modules(search_order)
+
+    def do_import(self, *args, **kwargs):
+        return self._import(*args, **kwargs)
 
     @contextmanager
-    def RequirementTracker():
-        yield
+    def nullcontext(self, *args, **kwargs):
+        try:
+            yield
+        finally:
+            pass
+
+    def get_pathinfo(self, module_path):
+        assert isinstance(module_path, (list, tuple))
+        module_path, start_version, end_version = module_path
+        return self.path_info(module_path, self._parse(start_version), self._parse(end_version))
+
+
+old_module = sys.modules[__name__] if __name__ in sys.modules else None
+module = sys.modules[__name__] = _shims()
+module.__dict__.update({
+    '__file__': __file__,
+    '__package__': __package__,
+    '__doc__': __doc__,
+    '__all__': module.__all__,
+    '__name__': __name__,
+})
diff --git a/pipenv/vendor/plette/__init__.py b/pipenv/vendor/plette/__init__.py
index c99c1bc1..8099f0b1 100644
--- a/pipenv/vendor/plette/__init__.py
+++ b/pipenv/vendor/plette/__init__.py
@@ -3,7 +3,7 @@ __all__ = [
     "Lockfile", "Pipfile",
 ]
 
-__version__ = '0.1.1'
+__version__ = '0.2.2'
 
 from .lockfiles import Lockfile
 from .pipfiles import Pipfile
diff --git a/pipenv/vendor/plette/lockfiles.py b/pipenv/vendor/plette/lockfiles.py
index fe97a521..10df07e1 100644
--- a/pipenv/vendor/plette/lockfiles.py
+++ b/pipenv/vendor/plette/lockfiles.py
@@ -1,6 +1,12 @@
 from __future__ import unicode_literals
 
 import json
+import numbers
+
+try:
+    import collections.abc as collections_abc
+except ImportError:
+    import collections as collections_abc
 
 import six
 
@@ -44,6 +50,20 @@ LOCKFILE_SECTIONS = {
 PIPFILE_SPEC_CURRENT = 6
 
 
+def _copy_jsonsafe(value):
+    """Deep-copy a value into JSON-safe types.
+    """
+    if isinstance(value, six.string_types + (numbers.Number,)):
+        return value
+    if isinstance(value, collections_abc.Mapping):
+        return {six.text_type(k): _copy_jsonsafe(v) for k, v in value.items()}
+    if isinstance(value, collections_abc.Iterable):
+        return [_copy_jsonsafe(v) for v in value]
+    if value is None:   # This doesn't happen often for us.
+        return None
+    return six.text_type(value)
+
+
 class Lockfile(DataView):
     """Representation of a Pipfile.lock.
     """
@@ -71,10 +91,10 @@ class Lockfile(DataView):
     def with_meta_from(cls, pipfile):
         data = {
             "_meta": {
-                "hash": pipfile.get_hash()._data,
+                "hash": _copy_jsonsafe(pipfile.get_hash()._data),
                 "pipfile-spec": PIPFILE_SPEC_CURRENT,
-                "requires": pipfile._data.get("requires", {}).copy(),
-                "sources": pipfile.sources._data.copy(),
+                "requires": _copy_jsonsafe(pipfile._data.get("requires", {})),
+                "sources": _copy_jsonsafe(pipfile.sources._data),
             },
             "default": {},
             "develop": {},
diff --git a/pipenv/vendor/plette/models/base.py b/pipenv/vendor/plette/models/base.py
index e8bbd4fa..d70752ee 100644
--- a/pipenv/vendor/plette/models/base.py
+++ b/pipenv/vendor/plette/models/base.py
@@ -31,8 +31,7 @@ class DataView(object):
     """A "view" to a data.
 
     Validates the input mapping on creation. A subclass is expected to
-    provide a `__SCHEMA__` class attribute specifying a validator schema,
-    or a concrete Cerberus validator object.
+    provide a `__SCHEMA__` class attribute specifying a validator schema.
     """
     def __init__(self, data):
         self.validate(data)
@@ -54,6 +53,9 @@ class DataView(object):
     def __setitem__(self, key, value):
         self._data[key] = value
 
+    def __delitem__(self, key):
+        del self._data[key]
+
     def get(self, key, default=None):
         try:
             return self[key]
@@ -66,11 +68,12 @@ class DataView(object):
 
 
 class DataViewCollection(DataView):
-    """A collection of dataview.
+    """A homogeneous collection of data views.
 
     Subclasses are expected to assign a class attribute `item_class` to specify
-    how items should be coerced when accessed. The item class should conform to
-    the `DataView` protocol.
+    the type of items it contains. This class will be used to coerce return
+    values when accessed. The item class should conform to the `DataView`
+    protocol.
 
     You should not instantiate an instance from this class, but from one of its
     subclasses instead.
@@ -87,7 +90,7 @@ class DataViewCollection(DataView):
         return self.item_class(self._data[key])
 
     def __setitem__(self, key, value):
-        if isinstance(value, self.item_class):
+        if isinstance(value, DataView):
             value = value._data
         self._data[key] = value
 
@@ -96,7 +99,7 @@ class DataViewCollection(DataView):
 
 
 class DataViewMapping(DataViewCollection):
-    """A mapping of dataview.
+    """A mapping of data views.
 
     The keys are primitive values, while values are instances of `item_class`.
     """
@@ -119,7 +122,7 @@ class DataViewMapping(DataViewCollection):
 
 
 class DataViewSequence(DataViewCollection):
-    """A sequence of dataview.
+    """A sequence of data views.
 
     Each entry is an instance of `item_class`.
     """
@@ -130,3 +133,13 @@ class DataViewSequence(DataViewCollection):
 
     def __iter__(self):
         return (self.item_class(d) for d in self._data)
+
+    def __getitem__(self, key):
+        if isinstance(key, slice):
+            return type(self)(self._data[key])
+        return super(DataViewSequence, self).__getitem__(key)
+
+    def append(self, value):
+        if isinstance(value, DataView):
+            value = value._data
+        self._data.append(value)
diff --git a/pipenv/vendor/pyparsing.py b/pipenv/vendor/pyparsing.py
index 69be39f6..cf38419b 100644
--- a/pipenv/vendor/pyparsing.py
+++ b/pipenv/vendor/pyparsing.py
@@ -1,6 +1,6 @@
 # module pyparsing.py
 #
-# Copyright (c) 2003-2016  Paul T. McGuire
+# Copyright (c) 2003-2018  Paul T. McGuire
 #
 # Permission is hereby granted, free of charge, to any person obtaining
 # a copy of this software and associated documentation files (the
@@ -25,6 +25,7 @@
 __doc__ = \
 """
 pyparsing module - Classes and methods to define and execute parsing grammars
+=============================================================================
 
 The pyparsing module is an alternative approach to creating and executing simple grammars,
 vs. the traditional lex/yacc approach, or the use of regular expressions.  With pyparsing, you
@@ -58,10 +59,23 @@ The pyparsing module handles some of the problems that are typically vexing when
  - extra or missing whitespace (the above program will also handle "Hello,World!", "Hello  ,  World  !", etc.)
  - quoted strings
  - embedded comments
+
+
+Getting Started -
+-----------------
+Visit the classes L{ParserElement} and L{ParseResults} to see the base classes that most other pyparsing
+classes inherit from. Use the docstrings for examples of how to:
+ - construct literal match expressions from L{Literal} and L{CaselessLiteral} classes
+ - construct character word-group expressions using the L{Word} class
+ - see how to create repetitive expressions using L{ZeroOrMore} and L{OneOrMore} classes
+ - use L{'+'<And>}, L{'|'<MatchFirst>}, L{'^'<Or>}, and L{'&'<Each>} operators to combine simple expressions into more complex ones
+ - associate names with your parsed results using L{ParserElement.setResultsName}
+ - find some helpful expression short-cuts like L{delimitedList} and L{oneOf}
+ - find more useful common expressions in the L{pyparsing_common} namespace class
 """
 
-__version__ = "2.2.0"
-__versionTime__ = "06 Mar 2017 02:06 UTC"
+__version__ = "2.2.2"
+__versionTime__ = "29 Sep 2018 15:58 UTC"
 __author__ = "Paul McGuire <ptmcg@users.sourceforge.net>"
 
 import string
@@ -82,6 +96,15 @@ try:
 except ImportError:
     from threading import RLock
 
+try:
+    # Python 3
+    from collections.abc import Iterable
+    from collections.abc import MutableMapping
+except ImportError:
+    # Python 2.7
+    from collections import Iterable
+    from collections import MutableMapping
+
 try:
     from collections import OrderedDict as _OrderedDict
 except ImportError:
@@ -940,7 +963,7 @@ class ParseResults(object):
     def __dir__(self):
         return (dir(type(self)) + list(self.keys()))
 
-collections.MutableMapping.register(ParseResults)
+MutableMapping.register(ParseResults)
 
 def col (loc,strg):
     """Returns current column within a string, counting newlines as line separators.
@@ -1025,11 +1048,11 @@ def _trim_arity(func, maxargs=2):
             # special handling for Python 3.5.0 - extra deep call stack by 1
             offset = -3 if system_version == (3,5,0) else -2
             frame_summary = traceback.extract_stack(limit=-offset+limit-1)[offset]
-            return [(frame_summary.filename, frame_summary.lineno)]
+            return [frame_summary[:2]]
         def extract_tb(tb, limit=0):
             frames = traceback.extract_tb(tb, limit=limit)
             frame_summary = frames[-1]
-            return [(frame_summary.filename, frame_summary.lineno)]
+            return [frame_summary[:2]]
     else:
         extract_stack = traceback.extract_stack
         extract_tb = traceback.extract_tb
@@ -1374,7 +1397,7 @@ class ParserElement(object):
             else:
                 preloc = loc
             tokensStart = preloc
-            if self.mayIndexError or loc >= len(instring):
+            if self.mayIndexError or preloc >= len(instring):
                 try:
                     loc,tokens = self.parseImpl( instring, preloc, doActions )
                 except IndexError:
@@ -1408,7 +1431,6 @@ class ParserElement(object):
                                                   self.resultsName,
                                                   asList=self.saveAsList and isinstance(tokens,(ParseResults,list)),
                                                   modal=self.modalResults )
-
         if debugging:
             #~ print ("Matched",self,"->",retTokens.asList())
             if (self.debugActions[1] ):
@@ -2754,7 +2776,7 @@ class Regex(Token):
         roman = Regex(r"M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})")
     """
     compiledREtype = type(re.compile("[A-Z]"))
-    def __init__( self, pattern, flags=0):
+    def __init__( self, pattern, flags=0, asGroupList=False, asMatch=False):
         """The parameters C{pattern} and C{flags} are passed to the C{re.compile()} function as-is. See the Python C{re} module for an explanation of the acceptable patterns and flags."""
         super(Regex,self).__init__()
 
@@ -2787,6 +2809,8 @@ class Regex(Token):
         self.errmsg = "Expected " + self.name
         self.mayIndexError = False
         self.mayReturnEmpty = True
+        self.asGroupList = asGroupList
+        self.asMatch = asMatch
 
     def parseImpl( self, instring, loc, doActions=True ):
         result = self.re.match(instring,loc)
@@ -2795,10 +2819,15 @@ class Regex(Token):
 
         loc = result.end()
         d = result.groupdict()
-        ret = ParseResults(result.group())
-        if d:
-            for k in d:
-                ret[k] = d[k]
+        if self.asMatch:
+            ret = result
+        elif self.asGroupList:
+            ret = result.groups()
+        else:
+            ret = ParseResults(result.group())
+            if d:
+                for k in d:
+                    ret[k] = d[k]
         return loc,ret
 
     def __str__( self ):
@@ -2812,6 +2841,28 @@ class Regex(Token):
 
         return self.strRepr
 
+    def sub(self, repl):
+        """
+        Return Regex with an attached parse action to transform the parsed
+        result as if called using C{re.sub(expr, repl, string)}.
+        """
+        if self.asGroupList:
+            warnings.warn("cannot use sub() with Regex(asGroupList=True)", 
+                           SyntaxWarning, stacklevel=2)
+            raise SyntaxError()
+
+        if self.asMatch and callable(repl):
+            warnings.warn("cannot use sub() with a callable with Regex(asMatch=True)", 
+                           SyntaxWarning, stacklevel=2)
+            raise SyntaxError()        
+
+        if self.asMatch:
+            def pa(tokens):
+                return tokens[0].expand(repl)
+        else:
+            def pa(tokens):
+                return self.re.sub(repl, tokens[0])
+        return self.addParseAction(pa)
 
 class QuotedString(Token):
     r"""
@@ -3242,7 +3293,7 @@ class ParseExpression(ParserElement):
 
         if isinstance( exprs, basestring ):
             self.exprs = [ ParserElement._literalStringClass( exprs ) ]
-        elif isinstance( exprs, collections.Iterable ):
+        elif isinstance( exprs, Iterable ):
             exprs = list(exprs)
             # if sequence of strings provided, wrap with Literal
             if all(isinstance(expr, basestring) for expr in exprs):
@@ -4062,7 +4113,7 @@ class SkipTo(ParseElementEnhance):
         self.mayReturnEmpty = True
         self.mayIndexError = False
         self.includeMatch = include
-        self.asList = False
+        self.saveAsList = False
         if isinstance(failOn, basestring):
             self.failOn = ParserElement._literalStringClass(failOn)
         else:
@@ -4393,7 +4444,7 @@ def traceParseAction(f):
 
         @traceParseAction
         def remove_duplicate_chars(tokens):
-            return ''.join(sorted(set(''.join(tokens)))
+            return ''.join(sorted(set(''.join(tokens))))
 
         wds = OneOrMore(wd).setParseAction(remove_duplicate_chars)
         print(wds.parseString("slkdjs sld sldd sdlf sdljf"))
@@ -4583,7 +4634,7 @@ def oneOf( strs, caseless=False, useRegex=True ):
     symbols = []
     if isinstance(strs,basestring):
         symbols = strs.split()
-    elif isinstance(strs, collections.Iterable):
+    elif isinstance(strs, Iterable):
         symbols = list(strs)
     else:
         warnings.warn("Invalid argument to oneOf, expected string or iterable",
@@ -4734,7 +4785,7 @@ stringEnd   = StringEnd().setName("stringEnd")
 _escapedPunc = Word( _bslash, r"\[]-*.$+^?()~ ", exact=2 ).setParseAction(lambda s,l,t:t[0][1])
 _escapedHexChar = Regex(r"\\0?[xX][0-9a-fA-F]+").setParseAction(lambda s,l,t:unichr(int(t[0].lstrip(r'\0x'),16)))
 _escapedOctChar = Regex(r"\\0[0-7]+").setParseAction(lambda s,l,t:unichr(int(t[0][1:],8)))
-_singleChar = _escapedPunc | _escapedHexChar | _escapedOctChar | Word(printables, excludeChars=r'\]', exact=1) | Regex(r"\w", re.UNICODE)
+_singleChar = _escapedPunc | _escapedHexChar | _escapedOctChar | CharsNotIn(r'\]', exact=1)
 _charRange = Group(_singleChar + Suppress("-") + _singleChar)
 _reBracketExpr = Literal("[") + Optional("^").setResultsName("negate") + Group( OneOrMore( _charRange | _singleChar ) ).setResultsName("body") + "]"
 
diff --git a/pipenv/vendor/pythonfinder/__init__.py b/pipenv/vendor/pythonfinder/__init__.py
index f6ef476b..586be002 100644
--- a/pipenv/vendor/pythonfinder/__init__.py
+++ b/pipenv/vendor/pythonfinder/__init__.py
@@ -1,6 +1,6 @@
 from __future__ import print_function, absolute_import
 
-__version__ = '1.0.2'
+__version__ = '1.1.0'
 
 __all__ = ["Finder", "WindowsFinder", "SystemPath", "InvalidPythonVersion"]
 from .pythonfinder import Finder
diff --git a/pipenv/vendor/pythonfinder/cli.py b/pipenv/vendor/pythonfinder/cli.py
index d285fb29..64d3372d 100644
--- a/pipenv/vendor/pythonfinder/cli.py
+++ b/pipenv/vendor/pythonfinder/cli.py
@@ -8,7 +8,6 @@ from . import __version__
 from .pythonfinder import Finder
 
 
-# @click.group(invoke_without_command=True, context_settings=CONTEXT_SETTINGS)
 @click.command()
 @click.option("--find", default=False, nargs=1, help="Find a specific python version.")
 @click.option("--which", default=False, nargs=1, help="Run the which command.")
@@ -29,6 +28,23 @@ def cli(ctx, find=False, which=False, findall=False, version=False):
         )
         sys.exit(0)
     finder = Finder()
+    if findall:
+        versions = finder.find_all_python_versions()
+        if versions:
+            click.secho("Found python at the following locations:", fg="green")
+            for v in versions:
+                py = v.py_version
+                click.secho(
+                    "Python: {py.version!s} ({py.architecture!s}) @ {py.comes_from.path!s}".format(
+                        py=py
+                    ),
+                    fg="yellow",
+                )
+        else:
+            click.secho(
+                "ERROR: No valid python versions found! Check your path and try again.",
+                fg="red",
+            )
     if find:
 
         if any([find.startswith("{0}".format(n)) for n in range(10)]):
diff --git a/pipenv/vendor/pythonfinder/models/__init__.py b/pipenv/vendor/pythonfinder/models/__init__.py
index ef0ed368..e788c21c 100644
--- a/pipenv/vendor/pythonfinder/models/__init__.py
+++ b/pipenv/vendor/pythonfinder/models/__init__.py
@@ -12,22 +12,3 @@ from ..utils import KNOWN_EXTS, unnest
 from .path import SystemPath
 from .python import PythonVersion
 from .windows import WindowsFinder
-
-
-@six.add_metaclass(abc.ABCMeta)
-class BaseFinder(object):
-    def get_versions(self):
-        """Return the available versions from the finder"""
-        raise NotImplementedError
-
-    @classmethod
-    def create(cls):
-        raise NotImplementedError
-
-    @property
-    def version_paths(self):
-        return self.versions.values()
-
-    @property
-    def expanded_paths(self):
-        return (p.paths.values() for p in self.version_paths)
diff --git a/pipenv/vendor/pythonfinder/models/python.py b/pipenv/vendor/pythonfinder/models/python.py
index 8a40e248..0fcce6c8 100644
--- a/pipenv/vendor/pythonfinder/models/python.py
+++ b/pipenv/vendor/pythonfinder/models/python.py
@@ -11,8 +11,6 @@ import attr
 from packaging.version import Version
 from packaging.version import parse as parse_version
 
-from vistir.compat import Path
-
 from ..environment import SYSTEM_ARCH
 from ..utils import (
     _filter_none, ensure_path, get_python_version, optional_instance_of
diff --git a/pipenv/vendor/pythonfinder/models/windows.py b/pipenv/vendor/pythonfinder/models/windows.py
index 4f0b64d1..fcb4d42a 100644
--- a/pipenv/vendor/pythonfinder/models/windows.py
+++ b/pipenv/vendor/pythonfinder/models/windows.py
@@ -60,7 +60,10 @@ class WindowsFinder(BaseFinder):
         env_versions = pep514env.findall()
         path = None
         for version_object in env_versions:
-            path = ensure_path(version_object.info.install_path.__getattr__(""))
+            install_path = getattr(version_object.info, 'install_path', None)
+            if install_path is None:
+                continue
+            path = ensure_path(install_path.__getattr__(""))
             try:
                 py_version = PythonVersion.from_windows_launcher(version_object)
             except InvalidPythonVersion:
diff --git a/pipenv/vendor/pythonfinder/utils.py b/pipenv/vendor/pythonfinder/utils.py
index 285e06be..6494d243 100644
--- a/pipenv/vendor/pythonfinder/utils.py
+++ b/pipenv/vendor/pythonfinder/utils.py
@@ -14,8 +14,6 @@ import six
 
 import vistir
 
-from vistir.compat import Path
-
 from .exceptions import InvalidPythonVersion
 
 
@@ -31,7 +29,7 @@ def get_python_version(path):
     """Get python version string using subprocess from a given path."""
     version_cmd = [path, "-c", "import sys; print(sys.version.split()[0])"]
     try:
-        out, _ = vistir.misc.run(version_cmd)
+        out, _ = vistir.misc.run(version_cmd, block=True, nospin=True)
     except OSError:
         raise InvalidPythonVersion("%s is not a valid python path" % path)
     if not out:
@@ -44,7 +42,7 @@ def optional_instance_of(cls):
 
 
 def path_and_exists(path):
-    return attr.validators.instance_of(Path) and path.exists()
+    return attr.validators.instance_of(vistir.compat.Path) and path.exists()
 
 
 def path_is_executable(path):
@@ -87,9 +85,9 @@ def ensure_path(path):
     :rtype: :class:`~pathlib.Path`
     """
 
-    if isinstance(path, Path):
+    if isinstance(path, vistir.compat.Path):
         path = path.as_posix()
-    path = Path(os.path.expandvars(path))
+    path = vistir.compat.Path(os.path.expandvars(path))
     try:
         path = path.resolve()
     except OSError:
@@ -105,8 +103,8 @@ def _filter_none(k, v):
 
 def filter_pythons(path):
     """Return all valid pythons in a given path"""
-    if not isinstance(path, Path):
-        path = Path(str(path))
+    if not isinstance(path, vistir.compat.Path):
+        path = vistir.compat.Path(str(path))
     if not path.is_dir():
         return path if path_is_python(path) else None
     return filter(lambda x: path_is_python(x), path.iterdir())
diff --git a/pipenv/vendor/pytoml/parser.py b/pipenv/vendor/pytoml/parser.py
index e03a03fb..9f94e923 100644
--- a/pipenv/vendor/pytoml/parser.py
+++ b/pipenv/vendor/pytoml/parser.py
@@ -223,8 +223,8 @@ _float_re = re.compile(r'[+-]?(?:0|[1-9](?:_?\d)*)(?:\.\d(?:_?\d)*)?(?:[eE][+-]?
 _datetime_re = re.compile(r'(\d{4})-(\d{2})-(\d{2})T(\d{2}):(\d{2}):(\d{2})(\.\d+)?(?:Z|([+-]\d{2}):(\d{2}))')
 
 _basicstr_ml_re = re.compile(r'(?:(?:|"|"")[^"\\\000-\011\013-\037])*')
-_litstr_re = re.compile(r"[^'\000-\037]*")
-_litstr_ml_re = re.compile(r"(?:(?:|'|'')(?:[^'\000-\011\013-\037]))*")
+_litstr_re = re.compile(r"[^'\000\010\012-\037]*")
+_litstr_ml_re = re.compile(r"(?:(?:|'|'')(?:[^'\000-\010\013-\037]))*")
 def _p_value(s, object_pairs_hook):
     pos = s.pos()
 
diff --git a/pipenv/vendor/requirementslib/__init__.py b/pipenv/vendor/requirementslib/__init__.py
index 01a56efa..ddfbcf98 100644
--- a/pipenv/vendor/requirementslib/__init__.py
+++ b/pipenv/vendor/requirementslib/__init__.py
@@ -1,5 +1,5 @@
 # -*- coding=utf-8 -*-
-__version__ = '1.1.6'
+__version__ = '1.1.7'
 
 
 from .exceptions import RequirementError
diff --git a/pipenv/vendor/requirementslib/models/dependencies.py b/pipenv/vendor/requirementslib/models/dependencies.py
index 90678344..ae643517 100644
--- a/pipenv/vendor/requirementslib/models/dependencies.py
+++ b/pipenv/vendor/requirementslib/models/dependencies.py
@@ -274,8 +274,11 @@ def get_dependencies(ireq, sources=None, parent=None):
             ireq, "project_name",
             getattr(ireq, "project", ireq.name),
         )
-        version = getattr(ireq, "version")
-        ireq = InstallRequirement.from_line("{0}=={1}".format(name, version))
+        version = getattr(ireq, "version", None)
+        if not version:
+            ireq = InstallRequirement.from_line("{0}".format(name))
+        else:
+            ireq = InstallRequirement.from_line("{0}=={1}".format(name, version))
     pip_options = get_pip_options(sources=sources)
     getters = [
         get_dependencies_from_cache,
diff --git a/pipenv/vendor/requirementslib/models/requirements.py b/pipenv/vendor/requirementslib/models/requirements.py
index 13a3a60e..73de6d2d 100644
--- a/pipenv/vendor/requirementslib/models/requirements.py
+++ b/pipenv/vendor/requirementslib/models/requirements.py
@@ -29,7 +29,7 @@ from vistir.path import (
 )
 
 from ..exceptions import RequirementError
-from ..utils import VCS_LIST, is_installable_file, is_vcs
+from ..utils import VCS_LIST, is_installable_file, is_vcs, ensure_setup_py
 from .baserequirement import BaseRequirement
 from .dependencies import (
     AbstractDependency, find_all_matches, get_abstract_dependencies,
@@ -760,7 +760,7 @@ class Requirement(object):
     @property
     def markers_as_pip(self):
         if self.markers:
-            return "; {0}".format(self.markers).replace('"', "'")
+            return " ; {0}".format(self.markers).replace('"', "'")
 
         return ""
 
@@ -1054,7 +1054,8 @@ class Requirement(object):
         if self.editable or self.req.editable:
             if ireq_line.startswith("-e "):
                 ireq_line = ireq_line[len("-e "):]
-            ireq = InstallRequirement.from_editable(ireq_line)
+            with ensure_setup_py(self.req.path):
+                ireq = InstallRequirement.from_editable(ireq_line)
         else:
             ireq = InstallRequirement.from_line(ireq_line)
         if not getattr(ireq, "req", None):
diff --git a/pipenv/vendor/requirementslib/models/utils.py b/pipenv/vendor/requirementslib/models/utils.py
index 2c6ef7e0..de9acb53 100644
--- a/pipenv/vendor/requirementslib/models/utils.py
+++ b/pipenv/vendor/requirementslib/models/utils.py
@@ -508,5 +508,3 @@ def fix_requires_python_marker(requires_python):
         ])
     marker_to_add = PackagingRequirement('fakepkg; {0}'.format(marker_str)).marker
     return marker_to_add
-
-
diff --git a/pipenv/vendor/requirementslib/models/vcs.py b/pipenv/vendor/requirementslib/models/vcs.py
index 5d3ec08f..fb2e6bc3 100644
--- a/pipenv/vendor/requirementslib/models/vcs.py
+++ b/pipenv/vendor/requirementslib/models/vcs.py
@@ -52,7 +52,7 @@ class VCSRepository(object):
         sha = self.repo_instance.get_revision_sha(self.checkout_directory, target_ref.arg_rev)
         target_rev = target_ref.make_new(sha)
         if parse_version(pip_version) > parse_version("18.0"):
-            self.repo_instance.update(self.checkout_directory, self.url, target_rev)
+            self.repo_instance.update(self.checkout_directory, self.url, target_ref)
         else:
             self.repo_instance.update(self.checkout_directory, target_ref)
         self.commit_hash = self.get_commit_hash(ref)
diff --git a/pipenv/vendor/requirementslib/utils.py b/pipenv/vendor/requirementslib/utils.py
index c41f9675..b490d3cf 100644
--- a/pipenv/vendor/requirementslib/utils.py
+++ b/pipenv/vendor/requirementslib/utils.py
@@ -1,21 +1,23 @@
 # -*- coding=utf-8 -*-
 from __future__ import absolute_import
 
+import contextlib
 import logging
 import os
 
 import six
+import tomlkit
 
 from six.moves.urllib.parse import urlparse, urlsplit
 
-from pip_shims import (
-    Command, VcsSupport, cmdoptions, is_archive_file, is_installable_dir
+from pip_shims.shims import (
+    Command, VcsSupport, cmdoptions, is_archive_file,
+    is_installable_dir as _is_installable_dir
 )
 from vistir.compat import Path
-from vistir.path import is_valid_url, ensure_mkdir_p
+from vistir.path import is_valid_url, ensure_mkdir_p, create_tracked_tempdir
 
 
-VCS_ACCESS = VcsSupport()
 VCS_LIST = ("git", "svn", "hg", "bzr")
 VCS_SCHEMES = []
 SCHEME_LIST = ("http://", "https://", "ftp://", "ftps://", "file://")
@@ -37,6 +39,19 @@ def setup_logger():
 log = setup_logger()
 
 
+def is_installable_dir(path):
+    if _is_installable_dir(path):
+        return True
+    path = Path(path)
+    pyproject = path.joinpath("pyproject.toml")
+    if pyproject.exists():
+        pyproject_toml = tomlkit.loads(pyproject.read_text())
+        build_system = pyproject_toml.get("build-system", {}).get("build-backend", "")
+        if build_system:
+            return True
+    return False
+
+
 def is_vcs(pipfile_entry):
     """Determine if dictionary entry from Pipfile is for a vcs dependency."""
     if hasattr(pipfile_entry, "keys"):
@@ -150,3 +165,19 @@ def get_pip_command():
 @ensure_mkdir_p(mode=0o777)
 def _ensure_dir(path):
     return path
+
+
+@contextlib.contextmanager
+def ensure_setup_py(base_dir):
+    if not base_dir:
+        base_dir = create_tracked_tempdir(prefix="requirementslib-setup")
+    base_dir = Path(base_dir)
+    setup_py = base_dir.joinpath("setup.py")
+    is_new = False if setup_py.exists() else True
+    if not setup_py.exists():
+        setup_py.write_text(u"")
+    try:
+        yield
+    finally:
+        if is_new:
+            setup_py.unlink()
diff --git a/pipenv/vendor/shellingham/__init__.py b/pipenv/vendor/shellingham/__init__.py
index a415c4a9..90c00abb 100644
--- a/pipenv/vendor/shellingham/__init__.py
+++ b/pipenv/vendor/shellingham/__init__.py
@@ -4,7 +4,7 @@ import os
 from ._core import ShellDetectionFailure
 
 
-__version__ = '1.2.4'
+__version__ = '1.2.6'
 
 
 def detect_shell(pid=None, max_depth=6):
diff --git a/pipenv/vendor/shellingham/posix.py b/pipenv/vendor/shellingham/posix.py
index b25dd874..0bbf988b 100644
--- a/pipenv/vendor/shellingham/posix.py
+++ b/pipenv/vendor/shellingham/posix.py
@@ -21,7 +21,7 @@ def _get_process_mapping():
     processes = {}
     for line in output.split('\n'):
         try:
-            pid, ppid, args = line.strip().split(maxsplit=2)
+            pid, ppid, args = line.strip().split(None, 2)
         except ValueError:
             continue
         processes[pid] = Process(
diff --git a/pipenv/vendor/shellingham/posix/_default.py b/pipenv/vendor/shellingham/posix/_default.py
deleted file mode 100644
index 86944276..00000000
--- a/pipenv/vendor/shellingham/posix/_default.py
+++ /dev/null
@@ -1,27 +0,0 @@
-import collections
-import shlex
-import subprocess
-import sys
-
-
-Process = collections.namedtuple('Process', 'args pid ppid')
-
-
-def get_process_mapping():
-    """Try to look up the process tree via the output of `ps`.
-    """
-    output = subprocess.check_output([
-        'ps', '-ww', '-o', 'pid=', '-o', 'ppid=', '-o', 'args=',
-    ])
-    if not isinstance(output, str):
-        output = output.decode(sys.stdout.encoding)
-    processes = {}
-    for line in output.split('\n'):
-        try:
-            pid, ppid, args = line.strip().split(None, 2)
-        except ValueError:
-            continue
-        processes[pid] = Process(
-            args=tuple(shlex.split(args)), pid=pid, ppid=ppid,
-        )
-    return processes
diff --git a/pipenv/vendor/shellingham/posix/_proc.py b/pipenv/vendor/shellingham/posix/_proc.py
index 921f2508..e3a6e46d 100644
--- a/pipenv/vendor/shellingham/posix/_proc.py
+++ b/pipenv/vendor/shellingham/posix/_proc.py
@@ -1,40 +1,34 @@
 import os
 import re
 
-from ._core import Process
+from ._default import Process
 
 
 STAT_PPID = 3
 STAT_TTY = 6
 
-STAT_PATTERN = re.compile(r'\(.+\)|\S+')
-
-
-def _get_stat(pid):
-    with open(os.path.join('/proc', str(pid), 'stat')) as f:
-        parts = STAT_PATTERN.findall(f.read())
-        return parts[STAT_TTY], parts[STAT_PPID]
-
-
-def _get_cmdline(pid):
-    with open(os.path.join('/proc', str(pid), 'cmdline')) as f:
-        return tuple(f.read().split('\0')[:-1])
-
 
 def get_process_mapping():
     """Try to look up the process tree via the /proc interface.
     """
-    self_tty = _get_stat(os.getpid())[0]
+    with open('/proc/{0}/stat'.format(os.getpid())) as f:
+        self_tty = f.read().split()[STAT_TTY]
     processes = {}
     for pid in os.listdir('/proc'):
         if not pid.isdigit():
             continue
         try:
-            tty, ppid = _get_stat(pid)
-            if tty != self_tty:
-                continue
-            args = _get_cmdline(pid)
-            processes[pid] = Process(args=args, pid=pid, ppid=ppid)
+            stat = '/proc/{0}/stat'.format(pid)
+            cmdline = '/proc/{0}/cmdline'.format(pid)
+            with open(stat) as fstat, open(cmdline) as fcmdline:
+                stat = re.findall(r'\(.+\)|\S+', fstat.read())
+                cmd = fcmdline.read().split('\x00')[:-1]
+            ppid = stat[STAT_PPID]
+            tty = stat[STAT_TTY]
+            if tty == self_tty:
+                processes[pid] = Process(
+                    args=tuple(cmd), pid=pid, ppid=ppid,
+                )
         except IOError:
             # Process has disappeared - just ignore it.
             continue
diff --git a/pipenv/vendor/shellingham/posix/_ps.py b/pipenv/vendor/shellingham/posix/_ps.py
index e96278cf..86944276 100644
--- a/pipenv/vendor/shellingham/posix/_ps.py
+++ b/pipenv/vendor/shellingham/posix/_ps.py
@@ -1,8 +1,10 @@
+import collections
 import shlex
 import subprocess
 import sys
 
-from ._core import Process
+
+Process = collections.namedtuple('Process', 'args pid ppid')
 
 
 def get_process_mapping():
diff --git a/pipenv/vendor/shellingham/posix/linux.py b/pipenv/vendor/shellingham/posix/linux.py
deleted file mode 100644
index 6db97834..00000000
--- a/pipenv/vendor/shellingham/posix/linux.py
+++ /dev/null
@@ -1,35 +0,0 @@
-import os
-import re
-
-from ._default import Process
-
-
-STAT_PPID = 3
-STAT_TTY = 6
-
-
-def get_process_mapping():
-    """Try to look up the process tree via Linux's /proc
-    """
-    with open('/proc/{0}/stat'.format(os.getpid())) as f:
-        self_tty = f.read().split()[STAT_TTY]
-    processes = {}
-    for pid in os.listdir('/proc'):
-        if not pid.isdigit():
-            continue
-        try:
-            stat = '/proc/{0}/stat'.format(pid)
-            cmdline = '/proc/{0}/cmdline'.format(pid)
-            with open(stat) as fstat, open(cmdline) as fcmdline:
-                stat = re.findall(r'\(.+\)|\S+', fstat.read())
-                cmd = fcmdline.read().split('\x00')[:-1]
-            ppid = stat[STAT_PPID]
-            tty = stat[STAT_TTY]
-            if tty == self_tty:
-                processes[pid] = Process(
-                    args=tuple(cmd), pid=pid, ppid=ppid,
-                )
-        except IOError:
-            # Process has disappeared - just ignore it.
-            continue
-    return processes
diff --git a/pipenv/vendor/shellingham/posix/proc.py b/pipenv/vendor/shellingham/posix/proc.py
index e64a5fe2..89d6c8e9 100644
--- a/pipenv/vendor/shellingham/posix/proc.py
+++ b/pipenv/vendor/shellingham/posix/proc.py
@@ -1,5 +1,7 @@
+import io
 import os
 import re
+import sys
 
 from ._core import Process
 
@@ -27,13 +29,21 @@ def detect_proc():
 
 
 def _get_stat(pid, name):
-    with open(os.path.join('/proc', str(pid), name)) as f:
+    path = os.path.join('/proc', str(pid), name)
+    with io.open(path, encoding='ascii', errors='replace') as f:
+        # We only care about TTY and PPID -- all numbers.
         parts = STAT_PATTERN.findall(f.read())
         return parts[STAT_TTY], parts[STAT_PPID]
 
 
 def _get_cmdline(pid):
-    with open(os.path.join('/proc', str(pid), 'cmdline')) as f:
+    path = os.path.join('/proc', str(pid), 'cmdline')
+    encoding = sys.getfilesystemencoding() or 'utf-8'
+    with io.open(path, encoding=encoding, errors='replace') as f:
+        # XXX: Command line arguments can be arbitrary byte sequences, not
+        # necessarily decodable. For Shellingham's purpose, however, we don't
+        # care. (pypa/pipenv#2820)
+        # cmdline appends an extra NULL at the end, hence the [:-1].
         return tuple(f.read().split('\0')[:-1])
 
 
diff --git a/pipenv/vendor/toml.py b/pipenv/vendor/toml.py
index 0bf04ae5..dac39883 100644
--- a/pipenv/vendor/toml.py
+++ b/pipenv/vendor/toml.py
@@ -6,9 +6,10 @@ import re
 import io
 import datetime
 from os import linesep
+import sys
 
-__version__ = "0.9.4"
-__spec__ = "0.4.0"
+__version__ = "0.9.6"
+_spec_ = "0.4.0"
 
 
 class TomlDecodeError(Exception):
@@ -230,7 +231,7 @@ def loads(s, _dict=dict):
         if item == '[' and (not openstring and not keygroup and
                             not arrayoftables):
             if beginline:
-                if sl[i + 1] == '[':
+                if len(sl) > i + 1 and sl[i + 1] == '[':
                     arrayoftables = True
                 else:
                     keygroup = True
@@ -282,7 +283,10 @@ def loads(s, _dict=dict):
             if len(line) > 2 and (line[-1] == multilinestr[0] and
                                   line[-2] == multilinestr[0] and
                                   line[-3] == multilinestr[0]):
-                value, vtype = _load_value(multilinestr, _dict)
+                try:
+                    value, vtype = _load_value(multilinestr, _dict)
+                except ValueError as err:
+                    raise TomlDecodeError(str(err))
                 currentlevel[multikey] = value
                 multikey = None
                 multilinestr = ""
@@ -298,23 +302,42 @@ def loads(s, _dict=dict):
             continue
         if line[0] == '[':
             arrayoftables = False
+            if len(line) == 1:
+                raise TomlDecodeError("Opening key group bracket on line by "
+                                      "itself.")
             if line[1] == '[':
                 arrayoftables = True
-                line = line[2:].split(']]', 1)
+                line = line[2:]
+                splitstr = ']]'
             else:
-                line = line[1:].split(']', 1)
-            if line[1].strip() != "":
+                line = line[1:]
+                splitstr = ']'
+            i = 1
+            quotesplits = _get_split_on_quotes(line)
+            quoted = False
+            for quotesplit in quotesplits:
+                if not quoted and splitstr in quotesplit:
+                    break
+                i += quotesplit.count(splitstr)
+                quoted = not quoted
+            line = line.split(splitstr, i)
+            if len(line) < i + 1 or line[-1].strip() != "":
                 raise TomlDecodeError("Key group not on a line by itself.")
-            groups = line[0].split('.')
+            groups = splitstr.join(line[:-1]).split('.')
             i = 0
             while i < len(groups):
                 groups[i] = groups[i].strip()
-                if groups[i][0] == '"' or groups[i][0] == "'":
+                if len(groups[i]) > 0 and (groups[i][0] == '"' or
+                                           groups[i][0] == "'"):
                     groupstr = groups[i]
                     j = i + 1
                     while not groupstr[0] == groupstr[-1]:
                         j += 1
-                        groupstr = '.'.join(groups[i:j])
+                        if j > len(groups) + 2:
+                            raise TomlDecodeError("Invalid group name '" +
+                                                  groupstr + "' Something " +
+                                                  "went wrong.")
+                        groupstr = '.'.join(groups[i:j]).strip()
                     groups[i] = groupstr[1:-1]
                     groups[i + 1:j] = []
                 else:
@@ -366,11 +389,17 @@ def loads(s, _dict=dict):
             if line[-1] != "}":
                 raise TomlDecodeError("Line breaks are not allowed in inline"
                                       "objects")
-            _load_inline_object(line, currentlevel, _dict, multikey,
-                                multibackslash)
+            try:
+                _load_inline_object(line, currentlevel, _dict, multikey,
+                                    multibackslash)
+            except ValueError as err:
+                raise TomlDecodeError(str(err))
         elif "=" in line:
-            ret = _load_line(line, currentlevel, _dict, multikey,
-                             multibackslash)
+            try:
+                ret = _load_line(line, currentlevel, _dict, multikey,
+                                 multibackslash)
+            except ValueError as err:
+                raise TomlDecodeError(str(err))
             if ret is not None:
                 multikey, multilinestr, multibackslash = ret
     return retval
@@ -387,15 +416,18 @@ def _load_inline_object(line, currentlevel, _dict, multikey=False,
         try:
             _, value = candidate_group.split('=', 1)
         except ValueError:
-            raise TomlDecodeError("Invalid inline table encountered")
+            raise ValueError("Invalid inline table encountered")
         value = value.strip()
         if ((value[0] == value[-1] and value[0] in ('"', "'")) or (
                 value[0] in '-0123456789' or
                 value in ('true', 'false') or
-                (value[0] == "[" and value[-1] == "]"))):
+                (value[0] == "[" and value[-1] == "]") or
+                (value[0] == '{' and value[-1] == '}'))):
             groups.append(candidate_group)
-        else:
+        elif len(candidate_groups) > 0:
             candidate_groups[0] = candidate_group + "," + candidate_groups[0]
+        else:
+            raise ValueError("Invalid inline table value encountered")
     for group in groups:
         status = _load_line(group, currentlevel, _dict, multikey,
                             multibackslash)
@@ -430,8 +462,38 @@ def _strictly_valid_num(n):
     return True
 
 
+def _get_split_on_quotes(line):
+    doublequotesplits = line.split('"')
+    quoted = False
+    quotesplits = []
+    if len(doublequotesplits) > 1 and "'" in doublequotesplits[0]:
+        singlequotesplits = doublequotesplits[0].split("'")
+        doublequotesplits = doublequotesplits[1:]
+        while len(singlequotesplits) % 2 == 0 and len(doublequotesplits):
+            singlequotesplits[-1] += '"' + doublequotesplits[0]
+            doublequotesplits = doublequotesplits[1:]
+            if "'" in singlequotesplits[-1]:
+                singlequotesplits = (singlequotesplits[:-1] +
+                                     singlequotesplits[-1].split("'"))
+        quotesplits += singlequotesplits
+    for doublequotesplit in doublequotesplits:
+        if quoted:
+            quotesplits.append(doublequotesplit)
+        else:
+            quotesplits += doublequotesplit.split("'")
+            quoted = not quoted
+    return quotesplits
+
+
 def _load_line(line, currentlevel, _dict, multikey, multibackslash):
     i = 1
+    quotesplits = _get_split_on_quotes(line)
+    quoted = False
+    for quotesplit in quotesplits:
+        if not quoted and '=' in quotesplit:
+            break
+        i += quotesplit.count('=')
+        quoted = not quoted
     pair = line.split('=', i)
     strictly_valid = _strictly_valid_num(pair[-1])
     if _number_with_underscores.match(pair[-1]):
@@ -451,7 +513,7 @@ def _load_line(line, currentlevel, _dict, multikey, multibackslash):
         prev_val = pair[-1]
         pair = line.split('=', i)
         if prev_val == pair[-1]:
-            raise TomlDecodeError("Invalid date or number")
+            raise ValueError("Invalid date or number")
         if strictly_valid:
             strictly_valid = _strictly_valid_num(pair[-1])
     pair = ['='.join(pair[:-1]).strip(), pair[-1].strip()]
@@ -478,7 +540,7 @@ def _load_line(line, currentlevel, _dict, multikey, multibackslash):
         value, vtype = _load_value(pair[1], _dict, strictly_valid)
     try:
         currentlevel[pair[0]]
-        raise TomlDecodeError("Duplicate keys!")
+        raise ValueError("Duplicate keys!")
     except KeyError:
         if multikey:
             return multikey, multilinestr, multibackslash
@@ -492,13 +554,28 @@ def _load_date(val):
     try:
         if len(val) > 19:
             if val[19] == '.':
-                microsecond = int(val[20:26])
-                if len(val) > 26:
-                    tz = TomlTz(val[26:32])
+                if val[-1].upper() == 'Z':
+                    subsecondval = val[20:-1]
+                    tzval = "Z"
+                else:
+                    subsecondvalandtz = val[20:]
+                    if '+' in subsecondvalandtz:
+                        splitpoint = subsecondvalandtz.index('+')
+                        subsecondval = subsecondvalandtz[:splitpoint]
+                        tzval = subsecondvalandtz[splitpoint:]
+                    elif '-' in subsecondvalandtz:
+                        splitpoint = subsecondvalandtz.index('-')
+                        subsecondval = subsecondvalandtz[:splitpoint]
+                        tzval = subsecondvalandtz[splitpoint:]
+                tz = TomlTz(tzval)
+                microsecond = int(int(subsecondval) *
+                                  (10 ** (6 - len(subsecondval))))
             else:
-                tz = TomlTz(val[19:25])
+                tz = TomlTz(val[19:])
     except ValueError:
         tz = None
+    if "-" not in val[1:]:
+        return None
     try:
         d = datetime.datetime(
             int(val[:4]), int(val[5:7]),
@@ -510,8 +587,6 @@ def _load_date(val):
 
 
 def _load_unicode_escapes(v, hexbytes, prefix):
-    hexchars = ['0', '1', '2', '3', '4', '5', '6', '7',
-                '8', '9', 'a', 'b', 'c', 'd', 'e', 'f']
     skip = False
     i = len(v) - 1
     while i > -1 and v[i] == '\\':
@@ -532,14 +607,12 @@ def _load_unicode_escapes(v, hexbytes, prefix):
         hxblen = 4
         if prefix == "\\U":
             hxblen = 8
-        while i < hxblen:
-            try:
-                if not hx[i].lower() in hexchars:
-                    raise IndexError("This is a hack")
-            except IndexError:
-                raise TomlDecodeError("Invalid escape sequence")
-            hxb += hx[i].lower()
-            i += 1
+        hxb = ''.join(hx[i:i + hxblen]).lower()
+        if hxb.strip('0123456789abcdef'):
+            raise ValueError("Invalid escape sequence: " + hxb)
+        if hxb[0] == "d" and hxb[1].strip('01234567'):
+            raise ValueError("Invalid escape sequence: " + hxb +
+                             ". Only scalar unicode points are allowed.")
         v += unichr(int(hxb, 16))
         v += unicode(hx[len(hxb):])
     return v
@@ -569,7 +642,7 @@ def _unescape(v):
             elif v[i] == 'u' or v[i] == 'U':
                 i += 1
             else:
-                raise TomlDecodeError("Reserved escape sequence used")
+                raise ValueError("Reserved escape sequence used")
             continue
         elif v[i] == '\\':
             backslash = True
@@ -579,19 +652,25 @@ def _unescape(v):
 
 def _load_value(v, _dict, strictly_valid=True):
     if not v:
-        raise TomlDecodeError("Empty value is invalid")
+        raise ValueError("Empty value is invalid")
     if v == 'true':
         return (True, "bool")
     elif v == 'false':
         return (False, "bool")
     elif v[0] == '"':
         testv = v[1:].split('"')
-        if testv[0] == '' and testv[1] == '':
-            testv = testv[2:-2]
+        triplequote = False
+        triplequotecount = 0
+        if len(testv) > 1 and testv[0] == '' and testv[1] == '':
+            testv = testv[2:]
+            triplequote = True
         closed = False
         for tv in testv:
             if tv == '':
-                closed = True
+                if triplequote:
+                    triplequotecount += 1
+                else:
+                    closed = True
             else:
                 oddbackslash = False
                 try:
@@ -605,9 +684,12 @@ def _load_value(v, _dict, strictly_valid=True):
                     pass
                 if not oddbackslash:
                     if closed:
-                        raise TomlDecodeError("Stuff after closed string. WTF?")
+                        raise ValueError("Stuff after closed string. WTF?")
                     else:
-                        closed = True
+                        if not triplequote or triplequotecount > 1:
+                            closed = True
+                        else:
+                            triplequotecount = 0
         escapeseqs = v.split('\\')[1:]
         backslash = False
         for i in escapeseqs:
@@ -616,7 +698,7 @@ def _load_value(v, _dict, strictly_valid=True):
             else:
                 if i[0] not in _escapes and (i[0] != 'u' and i[0] != 'U' and
                                              not backslash):
-                    raise TomlDecodeError("Reserved escape sequence used")
+                    raise ValueError("Reserved escape sequence used")
                 if backslash:
                     backslash = False
         for prefix in ["\\u", "\\U"]:
@@ -624,7 +706,7 @@ def _load_value(v, _dict, strictly_valid=True):
                 hexbytes = v.split(prefix)
                 v = _load_unicode_escapes(hexbytes[0], hexbytes[1:], prefix)
         v = _unescape(v)
-        if v[1] == '"' and (len(v) < 3 or v[1] == v[2]):
+        if len(v) > 1 and v[1] == '"' and (len(v) < 3 or v[1] == v[2]):
             v = v[2:-2]
         return (v[1:-1], "str")
     elif v[0] == "'":
@@ -642,8 +724,8 @@ def _load_value(v, _dict, strictly_valid=True):
         if parsed_date is not None:
             return (parsed_date, "date")
         if not strictly_valid:
-            raise TomlDecodeError("Weirdness with leading zeroes or underscores"
-                                  " in your number.")
+            raise ValueError("Weirdness with leading zeroes or "
+                             "underscores in your number.")
         itype = "int"
         neg = False
         if v[0] == '-':
@@ -654,10 +736,10 @@ def _load_value(v, _dict, strictly_valid=True):
         v = v.replace('_', '')
         if '.' in v or 'e' in v or 'E' in v:
             if '.' in v and v.split('.', 1)[1] == '':
-                raise TomlDecodeError("This float is missing digits after "
-                                      "the point")
+                raise ValueError("This float is missing digits after "
+                                 "the point")
             if v[0] not in '0123456789':
-                raise TomlDecodeError("This float doesn't have a leading digit")
+                raise ValueError("This float doesn't have a leading digit")
             v = float(v)
             itype = "float"
         else:
@@ -667,6 +749,22 @@ def _load_value(v, _dict, strictly_valid=True):
         return (v, itype)
 
 
+def _bounded_string(s):
+    if len(s) == 0:
+        return True
+    if s[-1] != s[0]:
+        return False
+    i = -2
+    backslash = False
+    while len(s) + i > 0:
+        if s[i] == "\\":
+            backslash = not backslash
+            i -= 1
+        else:
+            break
+    return not backslash
+
+
 def _load_array(a, _dict):
     atype = None
     retval = []
@@ -687,6 +785,12 @@ def _load_array(a, _dict):
             in_str = False
             while end_group_index < len(a[1:]):
                 if a[end_group_index] == '"' or a[end_group_index] == "'":
+                    if in_str:
+                        backslash_index = end_group_index - 1
+                        while (backslash_index > -1 and
+                               a[backslash_index] == '\\'):
+                            in_str = not in_str
+                            backslash_index -= 1
                     in_str = not in_str
                 if in_str or a[end_group_index] != '}':
                     end_group_index += 1
@@ -709,9 +813,11 @@ def _load_array(a, _dict):
         if strarray:
             while b < len(a) - 1:
                 ab = a[b].strip()
-                while ab[-1] != ab[0] or (len(ab) > 2 and
-                                          ab[0] == ab[1] == ab[2] and
-                                          ab[-2] != ab[0] and ab[-3] != ab[0]):
+                while (not _bounded_string(ab) or
+                       (len(ab) > 2 and
+                        ab[0] == ab[1] == ab[2] and
+                        ab[-2] != ab[0] and
+                        ab[-3] != ab[0])):
                     a[b] = a[b] + ',' + a[b + 1]
                     ab = a[b].strip()
                     if b < len(a) - 2:
@@ -739,7 +845,7 @@ def _load_array(a, _dict):
             nval, ntype = _load_value(a[i], _dict)
             if atype:
                 if ntype != atype:
-                    raise TomlDecodeError("Not a homogeneous array")
+                    raise ValueError("Not a homogeneous array")
             else:
                 atype = ntype
             retval.append(nval)
@@ -874,46 +980,57 @@ def _dump_inline_table(section):
 
 def _dump_value(v):
     dump_funcs = {
-        str: lambda: _dump_str(v),
-        unicode: lambda: _dump_str(v),
-        list: lambda: _dump_list(v),
-        bool: lambda: unicode(v).lower(),
-        float: lambda: _dump_float(v),
-        datetime.datetime: lambda: v.isoformat(),
+        str: _dump_str,
+        unicode: _dump_str,
+        list: _dump_list,
+        int: lambda v: v,
+        bool: lambda v: unicode(v).lower(),
+        float: _dump_float,
+        datetime.datetime: lambda v: v.isoformat().replace('+00:00', 'Z'),
     }
     # Lookup function corresponding to v's type
     dump_fn = dump_funcs.get(type(v))
+    if dump_fn is None and hasattr(v, '__iter__'):
+        dump_fn = dump_funcs[list]
     # Evaluate function (if it exists) else return v
-    return dump_fn() if dump_fn is not None else v
+    return dump_fn(v) if dump_fn is not None else dump_funcs[str](v)
 
 
 def _dump_str(v):
+    if sys.version_info < (3,) and hasattr(v, 'decode') and isinstance(v, str):
+        v = v.decode('utf-8')
     v = "%r" % v
     if v[0] == 'u':
         v = v[1:]
     singlequote = v.startswith("'")
-    v = v[1:-1]
+    if singlequote or v.startswith('"'):
+        v = v[1:-1]
     if singlequote:
         v = v.replace("\\'", "'")
         v = v.replace('"', '\\"')
-    v = v.replace("\\x", "\\u00")
-    return unicode('"' + v + '"')
+    v = v.split("\\x")
+    while len(v) > 1:
+        i = -1
+        if not v[0]:
+            v = v[1:]
+        v[0] = v[0].replace("\\\\", "\\")
+        # No, I don't know why != works and == breaks
+        joinx = v[0][i] != "\\"
+        while v[0][:i] and v[0][i] == "\\":
+            joinx = not joinx
+            i -= 1
+        if joinx:
+            joiner = "x"
+        else:
+            joiner = "u00"
+        v = [v[0] + joiner + v[1]] + v[2:]
+    return unicode('"' + v[0] + '"')
 
 
 def _dump_list(v):
-    t = []
     retval = "["
     for u in v:
-        t.append(_dump_value(u))
-    while t != []:
-        s = []
-        for u in t:
-            if isinstance(u, list):
-                for r in u:
-                    s.append(r)
-            else:
-                retval += " " + unicode(u) + ","
-        t = s
+        retval += " " + unicode(_dump_value(u)) + ","
     retval += "]"
     return retval
 
diff --git a/pipenv/vendor/toml/LICENSE b/pipenv/vendor/toml/LICENSE
new file mode 100644
index 00000000..08e981ff
--- /dev/null
+++ b/pipenv/vendor/toml/LICENSE
@@ -0,0 +1,26 @@
+The MIT License
+
+Copyright 2013-2018 William Pearson
+Copyright 2015-2016 Julien Enselme
+Copyright 2016 Google Inc.
+Copyright 2017 Samuel Vasko
+Copyright 2017 Nate Prewitt
+Copyright 2017 Jack Evans
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in
+all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+THE SOFTWARE.
\ No newline at end of file
diff --git a/pipenv/vendor/toml/__init__.py b/pipenv/vendor/toml/__init__.py
new file mode 100644
index 00000000..e436b271
--- /dev/null
+++ b/pipenv/vendor/toml/__init__.py
@@ -0,0 +1,21 @@
+"""Python module which parses and emits TOML.
+
+Released under the MIT license.
+"""
+
+from toml import encoder
+from toml import decoder
+
+__version__ = "0.10.0"
+_spec_ = "0.5.0"
+
+load = decoder.load
+loads = decoder.loads
+TomlDecoder = decoder.TomlDecoder
+TomlDecodeError = decoder.TomlDecodeError
+
+dump = encoder.dump
+dumps = encoder.dumps
+TomlEncoder = encoder.TomlEncoder
+TomlArraySeparatorEncoder = encoder.TomlArraySeparatorEncoder
+TomlPreserveInlineDictEncoder = encoder.TomlPreserveInlineDictEncoder
diff --git a/pipenv/vendor/toml/decoder.py b/pipenv/vendor/toml/decoder.py
new file mode 100644
index 00000000..4d468dd4
--- /dev/null
+++ b/pipenv/vendor/toml/decoder.py
@@ -0,0 +1,945 @@
+import datetime
+import io
+from os import linesep
+import re
+import sys
+
+from toml.tz import TomlTz
+
+if sys.version_info < (3,):
+    _range = xrange  # noqa: F821
+else:
+    unicode = str
+    _range = range
+    basestring = str
+    unichr = chr
+
+
+def _detect_pathlib_path(p):
+    if (3, 4) <= sys.version_info:
+        import pathlib
+        if isinstance(p, pathlib.PurePath):
+            return True
+    return False
+
+
+def _ispath(p):
+    if isinstance(p, basestring):
+        return True
+    return _detect_pathlib_path(p)
+
+
+def _getpath(p):
+    if (3, 6) <= sys.version_info:
+        import os
+        return os.fspath(p)
+    if _detect_pathlib_path(p):
+        return str(p)
+    return p
+
+
+try:
+    FNFError = FileNotFoundError
+except NameError:
+    FNFError = IOError
+
+
+TIME_RE = re.compile("([0-9]{2}):([0-9]{2}):([0-9]{2})(\.([0-9]{3,6}))?")
+
+
+class TomlDecodeError(ValueError):
+    """Base toml Exception / Error."""
+
+    def __init__(self, msg, doc, pos):
+        lineno = doc.count('\n', 0, pos) + 1
+        colno = pos - doc.rfind('\n', 0, pos)
+        emsg = '{} (line {} column {} char {})'.format(msg, lineno, colno, pos)
+        ValueError.__init__(self, emsg)
+        self.msg = msg
+        self.doc = doc
+        self.pos = pos
+        self.lineno = lineno
+        self.colno = colno
+
+
+# Matches a TOML number, which allows underscores for readability
+_number_with_underscores = re.compile('([0-9])(_([0-9]))*')
+
+
+def _strictly_valid_num(n):
+    n = n.strip()
+    if not n:
+        return False
+    if n[0] == '_':
+        return False
+    if n[-1] == '_':
+        return False
+    if "_." in n or "._" in n:
+        return False
+    if len(n) == 1:
+        return True
+    if n[0] == '0' and n[1] not in ['.', 'o', 'b', 'x']:
+        return False
+    if n[0] == '+' or n[0] == '-':
+        n = n[1:]
+        if len(n) > 1 and n[0] == '0' and n[1] != '.':
+            return False
+    if '__' in n:
+        return False
+    return True
+
+
+def load(f, _dict=dict, decoder=None):
+    """Parses named file or files as toml and returns a dictionary
+
+    Args:
+        f: Path to the file to open, array of files to read into single dict
+           or a file descriptor
+        _dict: (optional) Specifies the class of the returned toml dictionary
+
+    Returns:
+        Parsed toml file represented as a dictionary
+
+    Raises:
+        TypeError -- When f is invalid type
+        TomlDecodeError: Error while decoding toml
+        IOError / FileNotFoundError -- When an array with no valid (existing)
+        (Python 2 / Python 3)          file paths is passed
+    """
+
+    if _ispath(f):
+        with io.open(_getpath(f), encoding='utf-8') as ffile:
+            return loads(ffile.read(), _dict, decoder)
+    elif isinstance(f, list):
+        from os import path as op
+        from warnings import warn
+        if not [path for path in f if op.exists(path)]:
+            error_msg = "Load expects a list to contain filenames only."
+            error_msg += linesep
+            error_msg += ("The list needs to contain the path of at least one "
+                          "existing file.")
+            raise FNFError(error_msg)
+        if decoder is None:
+            decoder = TomlDecoder()
+        d = decoder.get_empty_table()
+        for l in f:
+            if op.exists(l):
+                d.update(load(l, _dict, decoder))
+            else:
+                warn("Non-existent filename in list with at least one valid "
+                     "filename")
+        return d
+    else:
+        try:
+            return loads(f.read(), _dict, decoder)
+        except AttributeError:
+            raise TypeError("You can only load a file descriptor, filename or "
+                            "list")
+
+
+_groupname_re = re.compile(r'^[A-Za-z0-9_-]+$')
+
+
+def loads(s, _dict=dict, decoder=None):
+    """Parses string as toml
+
+    Args:
+        s: String to be parsed
+        _dict: (optional) Specifies the class of the returned toml dictionary
+
+    Returns:
+        Parsed toml file represented as a dictionary
+
+    Raises:
+        TypeError: When a non-string is passed
+        TomlDecodeError: Error while decoding toml
+    """
+
+    implicitgroups = []
+    if decoder is None:
+        decoder = TomlDecoder(_dict)
+    retval = decoder.get_empty_table()
+    currentlevel = retval
+    if not isinstance(s, basestring):
+        raise TypeError("Expecting something like a string")
+
+    if not isinstance(s, unicode):
+        s = s.decode('utf8')
+
+    original = s
+    sl = list(s)
+    openarr = 0
+    openstring = False
+    openstrchar = ""
+    multilinestr = False
+    arrayoftables = False
+    beginline = True
+    keygroup = False
+    dottedkey = False
+    keyname = 0
+    for i, item in enumerate(sl):
+        if item == '\r' and sl[i + 1] == '\n':
+            sl[i] = ' '
+            continue
+        if keyname:
+            if item == '\n':
+                raise TomlDecodeError("Key name found without value."
+                                      " Reached end of line.", original, i)
+            if openstring:
+                if item == openstrchar:
+                    keyname = 2
+                    openstring = False
+                    openstrchar = ""
+                continue
+            elif keyname == 1:
+                if item.isspace():
+                    keyname = 2
+                    continue
+                elif item == '.':
+                    dottedkey = True
+                    continue
+                elif item.isalnum() or item == '_' or item == '-':
+                    continue
+                elif (dottedkey and sl[i - 1] == '.' and
+                      (item == '"' or item == "'")):
+                    openstring = True
+                    openstrchar = item
+                    continue
+            elif keyname == 2:
+                if item.isspace():
+                    if dottedkey:
+                        nextitem = sl[i + 1]
+                        if not nextitem.isspace() and nextitem != '.':
+                            keyname = 1
+                    continue
+                if item == '.':
+                    dottedkey = True
+                    nextitem = sl[i + 1]
+                    if not nextitem.isspace() and nextitem != '.':
+                        keyname = 1
+                    continue
+            if item == '=':
+                keyname = 0
+                dottedkey = False
+            else:
+                raise TomlDecodeError("Found invalid character in key name: '" +
+                                      item + "'. Try quoting the key name.",
+                                      original, i)
+        if item == "'" and openstrchar != '"':
+            k = 1
+            try:
+                while sl[i - k] == "'":
+                    k += 1
+                    if k == 3:
+                        break
+            except IndexError:
+                pass
+            if k == 3:
+                multilinestr = not multilinestr
+                openstring = multilinestr
+            else:
+                openstring = not openstring
+            if openstring:
+                openstrchar = "'"
+            else:
+                openstrchar = ""
+        if item == '"' and openstrchar != "'":
+            oddbackslash = False
+            k = 1
+            tripquote = False
+            try:
+                while sl[i - k] == '"':
+                    k += 1
+                    if k == 3:
+                        tripquote = True
+                        break
+                if k == 1 or (k == 3 and tripquote):
+                    while sl[i - k] == '\\':
+                        oddbackslash = not oddbackslash
+                        k += 1
+            except IndexError:
+                pass
+            if not oddbackslash:
+                if tripquote:
+                    multilinestr = not multilinestr
+                    openstring = multilinestr
+                else:
+                    openstring = not openstring
+            if openstring:
+                openstrchar = '"'
+            else:
+                openstrchar = ""
+        if item == '#' and (not openstring and not keygroup and
+                            not arrayoftables):
+            j = i
+            try:
+                while sl[j] != '\n':
+                    sl[j] = ' '
+                    j += 1
+            except IndexError:
+                break
+        if item == '[' and (not openstring and not keygroup and
+                            not arrayoftables):
+            if beginline:
+                if len(sl) > i + 1 and sl[i + 1] == '[':
+                    arrayoftables = True
+                else:
+                    keygroup = True
+            else:
+                openarr += 1
+        if item == ']' and not openstring:
+            if keygroup:
+                keygroup = False
+            elif arrayoftables:
+                if sl[i - 1] == ']':
+                    arrayoftables = False
+            else:
+                openarr -= 1
+        if item == '\n':
+            if openstring or multilinestr:
+                if not multilinestr:
+                    raise TomlDecodeError("Unbalanced quotes", original, i)
+                if ((sl[i - 1] == "'" or sl[i - 1] == '"') and (
+                        sl[i - 2] == sl[i - 1])):
+                    sl[i] = sl[i - 1]
+                    if sl[i - 3] == sl[i - 1]:
+                        sl[i - 3] = ' '
+            elif openarr:
+                sl[i] = ' '
+            else:
+                beginline = True
+        elif beginline and sl[i] != ' ' and sl[i] != '\t':
+            beginline = False
+            if not keygroup and not arrayoftables:
+                if sl[i] == '=':
+                    raise TomlDecodeError("Found empty keyname. ", original, i)
+                keyname = 1
+    s = ''.join(sl)
+    s = s.split('\n')
+    multikey = None
+    multilinestr = ""
+    multibackslash = False
+    pos = 0
+    for idx, line in enumerate(s):
+        if idx > 0:
+            pos += len(s[idx - 1]) + 1
+        if not multilinestr or multibackslash or '\n' not in multilinestr:
+            line = line.strip()
+        if line == "" and (not multikey or multibackslash):
+            continue
+        if multikey:
+            if multibackslash:
+                multilinestr += line
+            else:
+                multilinestr += line
+            multibackslash = False
+            if len(line) > 2 and (line[-1] == multilinestr[0] and
+                                  line[-2] == multilinestr[0] and
+                                  line[-3] == multilinestr[0]):
+                try:
+                    value, vtype = decoder.load_value(multilinestr)
+                except ValueError as err:
+                    raise TomlDecodeError(str(err), original, pos)
+                currentlevel[multikey] = value
+                multikey = None
+                multilinestr = ""
+            else:
+                k = len(multilinestr) - 1
+                while k > -1 and multilinestr[k] == '\\':
+                    multibackslash = not multibackslash
+                    k -= 1
+                if multibackslash:
+                    multilinestr = multilinestr[:-1]
+                else:
+                    multilinestr += "\n"
+            continue
+        if line[0] == '[':
+            arrayoftables = False
+            if len(line) == 1:
+                raise TomlDecodeError("Opening key group bracket on line by "
+                                      "itself.", original, pos)
+            if line[1] == '[':
+                arrayoftables = True
+                line = line[2:]
+                splitstr = ']]'
+            else:
+                line = line[1:]
+                splitstr = ']'
+            i = 1
+            quotesplits = decoder._get_split_on_quotes(line)
+            quoted = False
+            for quotesplit in quotesplits:
+                if not quoted and splitstr in quotesplit:
+                    break
+                i += quotesplit.count(splitstr)
+                quoted = not quoted
+            line = line.split(splitstr, i)
+            if len(line) < i + 1 or line[-1].strip() != "":
+                raise TomlDecodeError("Key group not on a line by itself.",
+                                      original, pos)
+            groups = splitstr.join(line[:-1]).split('.')
+            i = 0
+            while i < len(groups):
+                groups[i] = groups[i].strip()
+                if len(groups[i]) > 0 and (groups[i][0] == '"' or
+                                           groups[i][0] == "'"):
+                    groupstr = groups[i]
+                    j = i + 1
+                    while not groupstr[0] == groupstr[-1]:
+                        j += 1
+                        if j > len(groups) + 2:
+                            raise TomlDecodeError("Invalid group name '" +
+                                                  groupstr + "' Something " +
+                                                  "went wrong.", original, pos)
+                        groupstr = '.'.join(groups[i:j]).strip()
+                    groups[i] = groupstr[1:-1]
+                    groups[i + 1:j] = []
+                else:
+                    if not _groupname_re.match(groups[i]):
+                        raise TomlDecodeError("Invalid group name '" +
+                                              groups[i] + "'. Try quoting it.",
+                                              original, pos)
+                i += 1
+            currentlevel = retval
+            for i in _range(len(groups)):
+                group = groups[i]
+                if group == "":
+                    raise TomlDecodeError("Can't have a keygroup with an empty "
+                                          "name", original, pos)
+                try:
+                    currentlevel[group]
+                    if i == len(groups) - 1:
+                        if group in implicitgroups:
+                            implicitgroups.remove(group)
+                            if arrayoftables:
+                                raise TomlDecodeError("An implicitly defined "
+                                                      "table can't be an array",
+                                                      original, pos)
+                        elif arrayoftables:
+                            currentlevel[group].append(decoder.get_empty_table()
+                                                       )
+                        else:
+                            raise TomlDecodeError("What? " + group +
+                                                  " already exists?" +
+                                                  str(currentlevel),
+                                                  original, pos)
+                except TypeError:
+                    currentlevel = currentlevel[-1]
+                    if group not in currentlevel:
+                        currentlevel[group] = decoder.get_empty_table()
+                        if i == len(groups) - 1 and arrayoftables:
+                            currentlevel[group] = [decoder.get_empty_table()]
+                except KeyError:
+                    if i != len(groups) - 1:
+                        implicitgroups.append(group)
+                    currentlevel[group] = decoder.get_empty_table()
+                    if i == len(groups) - 1 and arrayoftables:
+                        currentlevel[group] = [decoder.get_empty_table()]
+                currentlevel = currentlevel[group]
+                if arrayoftables:
+                    try:
+                        currentlevel = currentlevel[-1]
+                    except KeyError:
+                        pass
+        elif line[0] == "{":
+            if line[-1] != "}":
+                raise TomlDecodeError("Line breaks are not allowed in inline"
+                                      "objects", original, pos)
+            try:
+                decoder.load_inline_object(line, currentlevel, multikey,
+                                           multibackslash)
+            except ValueError as err:
+                raise TomlDecodeError(str(err), original, pos)
+        elif "=" in line:
+            try:
+                ret = decoder.load_line(line, currentlevel, multikey,
+                                        multibackslash)
+            except ValueError as err:
+                raise TomlDecodeError(str(err), original, pos)
+            if ret is not None:
+                multikey, multilinestr, multibackslash = ret
+    return retval
+
+
+def _load_date(val):
+    microsecond = 0
+    tz = None
+    try:
+        if len(val) > 19:
+            if val[19] == '.':
+                if val[-1].upper() == 'Z':
+                    subsecondval = val[20:-1]
+                    tzval = "Z"
+                else:
+                    subsecondvalandtz = val[20:]
+                    if '+' in subsecondvalandtz:
+                        splitpoint = subsecondvalandtz.index('+')
+                        subsecondval = subsecondvalandtz[:splitpoint]
+                        tzval = subsecondvalandtz[splitpoint:]
+                    elif '-' in subsecondvalandtz:
+                        splitpoint = subsecondvalandtz.index('-')
+                        subsecondval = subsecondvalandtz[:splitpoint]
+                        tzval = subsecondvalandtz[splitpoint:]
+                    else:
+                        tzval = None
+                        subsecondval = subsecondvalandtz
+                if tzval is not None:
+                    tz = TomlTz(tzval)
+                microsecond = int(int(subsecondval) *
+                                  (10 ** (6 - len(subsecondval))))
+            else:
+                tz = TomlTz(val[19:])
+    except ValueError:
+        tz = None
+    if "-" not in val[1:]:
+        return None
+    try:
+        if len(val) == 10:
+            d = datetime.date(
+                int(val[:4]), int(val[5:7]),
+                int(val[8:10]))
+        else:
+            d = datetime.datetime(
+                int(val[:4]), int(val[5:7]),
+                int(val[8:10]), int(val[11:13]),
+                int(val[14:16]), int(val[17:19]), microsecond, tz)
+    except ValueError:
+        return None
+    return d
+
+
+def _load_unicode_escapes(v, hexbytes, prefix):
+    skip = False
+    i = len(v) - 1
+    while i > -1 and v[i] == '\\':
+        skip = not skip
+        i -= 1
+    for hx in hexbytes:
+        if skip:
+            skip = False
+            i = len(hx) - 1
+            while i > -1 and hx[i] == '\\':
+                skip = not skip
+                i -= 1
+            v += prefix
+            v += hx
+            continue
+        hxb = ""
+        i = 0
+        hxblen = 4
+        if prefix == "\\U":
+            hxblen = 8
+        hxb = ''.join(hx[i:i + hxblen]).lower()
+        if hxb.strip('0123456789abcdef'):
+            raise ValueError("Invalid escape sequence: " + hxb)
+        if hxb[0] == "d" and hxb[1].strip('01234567'):
+            raise ValueError("Invalid escape sequence: " + hxb +
+                             ". Only scalar unicode points are allowed.")
+        v += unichr(int(hxb, 16))
+        v += unicode(hx[len(hxb):])
+    return v
+
+
+# Unescape TOML string values.
+
+# content after the \
+_escapes = ['0', 'b', 'f', 'n', 'r', 't', '"']
+# What it should be replaced by
+_escapedchars = ['\0', '\b', '\f', '\n', '\r', '\t', '\"']
+# Used for substitution
+_escape_to_escapedchars = dict(zip(_escapes, _escapedchars))
+
+
+def _unescape(v):
+    """Unescape characters in a TOML string."""
+    i = 0
+    backslash = False
+    while i < len(v):
+        if backslash:
+            backslash = False
+            if v[i] in _escapes:
+                v = v[:i - 1] + _escape_to_escapedchars[v[i]] + v[i + 1:]
+            elif v[i] == '\\':
+                v = v[:i - 1] + v[i:]
+            elif v[i] == 'u' or v[i] == 'U':
+                i += 1
+            else:
+                raise ValueError("Reserved escape sequence used")
+            continue
+        elif v[i] == '\\':
+            backslash = True
+        i += 1
+    return v
+
+
+class InlineTableDict(object):
+    """Sentinel subclass of dict for inline tables."""
+
+
+class TomlDecoder(object):
+
+    def __init__(self, _dict=dict):
+        self._dict = _dict
+
+    def get_empty_table(self):
+        return self._dict()
+
+    def get_empty_inline_table(self):
+        class DynamicInlineTableDict(self._dict, InlineTableDict):
+            """Concrete sentinel subclass for inline tables.
+            It is a subclass of _dict which is passed in dynamically at load
+            time
+
+            It is also a subclass of InlineTableDict
+            """
+
+        return DynamicInlineTableDict()
+
+    def load_inline_object(self, line, currentlevel, multikey=False,
+                           multibackslash=False):
+        candidate_groups = line[1:-1].split(",")
+        groups = []
+        if len(candidate_groups) == 1 and not candidate_groups[0].strip():
+            candidate_groups.pop()
+        while len(candidate_groups) > 0:
+            candidate_group = candidate_groups.pop(0)
+            try:
+                _, value = candidate_group.split('=', 1)
+            except ValueError:
+                raise ValueError("Invalid inline table encountered")
+            value = value.strip()
+            if ((value[0] == value[-1] and value[0] in ('"', "'")) or (
+                    value[0] in '-0123456789' or
+                    value in ('true', 'false') or
+                    (value[0] == "[" and value[-1] == "]") or
+                    (value[0] == '{' and value[-1] == '}'))):
+                groups.append(candidate_group)
+            elif len(candidate_groups) > 0:
+                candidate_groups[0] = (candidate_group + "," +
+                                       candidate_groups[0])
+            else:
+                raise ValueError("Invalid inline table value encountered")
+        for group in groups:
+            status = self.load_line(group, currentlevel, multikey,
+                                    multibackslash)
+            if status is not None:
+                break
+
+    def _get_split_on_quotes(self, line):
+        doublequotesplits = line.split('"')
+        quoted = False
+        quotesplits = []
+        if len(doublequotesplits) > 1 and "'" in doublequotesplits[0]:
+            singlequotesplits = doublequotesplits[0].split("'")
+            doublequotesplits = doublequotesplits[1:]
+            while len(singlequotesplits) % 2 == 0 and len(doublequotesplits):
+                singlequotesplits[-1] += '"' + doublequotesplits[0]
+                doublequotesplits = doublequotesplits[1:]
+                if "'" in singlequotesplits[-1]:
+                    singlequotesplits = (singlequotesplits[:-1] +
+                                         singlequotesplits[-1].split("'"))
+            quotesplits += singlequotesplits
+        for doublequotesplit in doublequotesplits:
+            if quoted:
+                quotesplits.append(doublequotesplit)
+            else:
+                quotesplits += doublequotesplit.split("'")
+                quoted = not quoted
+        return quotesplits
+
+    def load_line(self, line, currentlevel, multikey, multibackslash):
+        i = 1
+        quotesplits = self._get_split_on_quotes(line)
+        quoted = False
+        for quotesplit in quotesplits:
+            if not quoted and '=' in quotesplit:
+                break
+            i += quotesplit.count('=')
+            quoted = not quoted
+        pair = line.split('=', i)
+        strictly_valid = _strictly_valid_num(pair[-1])
+        if _number_with_underscores.match(pair[-1]):
+            pair[-1] = pair[-1].replace('_', '')
+        while len(pair[-1]) and (pair[-1][0] != ' ' and pair[-1][0] != '\t' and
+                                 pair[-1][0] != "'" and pair[-1][0] != '"' and
+                                 pair[-1][0] != '[' and pair[-1][0] != '{' and
+                                 pair[-1] != 'true' and pair[-1] != 'false'):
+            try:
+                float(pair[-1])
+                break
+            except ValueError:
+                pass
+            if _load_date(pair[-1]) is not None:
+                break
+            i += 1
+            prev_val = pair[-1]
+            pair = line.split('=', i)
+            if prev_val == pair[-1]:
+                raise ValueError("Invalid date or number")
+            if strictly_valid:
+                strictly_valid = _strictly_valid_num(pair[-1])
+        pair = ['='.join(pair[:-1]).strip(), pair[-1].strip()]
+        if '.' in pair[0]:
+            if '"' in pair[0] or "'" in pair[0]:
+                quotesplits = self._get_split_on_quotes(pair[0])
+                quoted = False
+                levels = []
+                for quotesplit in quotesplits:
+                    if quoted:
+                        levels.append(quotesplit)
+                    else:
+                        levels += [level.strip() for level in
+                                   quotesplit.split('.')]
+                    quoted = not quoted
+            else:
+                levels = pair[0].split('.')
+            while levels[-1] == "":
+                levels = levels[:-1]
+            for level in levels[:-1]:
+                if level == "":
+                    continue
+                if level not in currentlevel:
+                    currentlevel[level] = self.get_empty_table()
+                currentlevel = currentlevel[level]
+            pair[0] = levels[-1].strip()
+        elif (pair[0][0] == '"' or pair[0][0] == "'") and \
+                (pair[0][-1] == pair[0][0]):
+            pair[0] = pair[0][1:-1]
+        if len(pair[1]) > 2 and ((pair[1][0] == '"' or pair[1][0] == "'") and
+                                 pair[1][1] == pair[1][0] and
+                                 pair[1][2] == pair[1][0] and
+                                 not (len(pair[1]) > 5 and
+                                      pair[1][-1] == pair[1][0] and
+                                      pair[1][-2] == pair[1][0] and
+                                      pair[1][-3] == pair[1][0])):
+            k = len(pair[1]) - 1
+            while k > -1 and pair[1][k] == '\\':
+                multibackslash = not multibackslash
+                k -= 1
+            if multibackslash:
+                multilinestr = pair[1][:-1]
+            else:
+                multilinestr = pair[1] + "\n"
+            multikey = pair[0]
+        else:
+            value, vtype = self.load_value(pair[1], strictly_valid)
+        try:
+            currentlevel[pair[0]]
+            raise ValueError("Duplicate keys!")
+        except TypeError:
+            raise ValueError("Duplicate keys!")
+        except KeyError:
+            if multikey:
+                return multikey, multilinestr, multibackslash
+            else:
+                currentlevel[pair[0]] = value
+
+    def load_value(self, v, strictly_valid=True):
+        if not v:
+            raise ValueError("Empty value is invalid")
+        if v == 'true':
+            return (True, "bool")
+        elif v == 'false':
+            return (False, "bool")
+        elif v[0] == '"' or v[0] == "'":
+            quotechar = v[0]
+            testv = v[1:].split(quotechar)
+            triplequote = False
+            triplequotecount = 0
+            if len(testv) > 1 and testv[0] == '' and testv[1] == '':
+                testv = testv[2:]
+                triplequote = True
+            closed = False
+            for tv in testv:
+                if tv == '':
+                    if triplequote:
+                        triplequotecount += 1
+                    else:
+                        closed = True
+                else:
+                    oddbackslash = False
+                    try:
+                        i = -1
+                        j = tv[i]
+                        while j == '\\':
+                            oddbackslash = not oddbackslash
+                            i -= 1
+                            j = tv[i]
+                    except IndexError:
+                        pass
+                    if not oddbackslash:
+                        if closed:
+                            raise ValueError("Stuff after closed string. WTF?")
+                        else:
+                            if not triplequote or triplequotecount > 1:
+                                closed = True
+                            else:
+                                triplequotecount = 0
+            if quotechar == '"':
+                escapeseqs = v.split('\\')[1:]
+                backslash = False
+                for i in escapeseqs:
+                    if i == '':
+                        backslash = not backslash
+                    else:
+                        if i[0] not in _escapes and (i[0] != 'u' and
+                                                     i[0] != 'U' and
+                                                     not backslash):
+                            raise ValueError("Reserved escape sequence used")
+                        if backslash:
+                            backslash = False
+                for prefix in ["\\u", "\\U"]:
+                    if prefix in v:
+                        hexbytes = v.split(prefix)
+                        v = _load_unicode_escapes(hexbytes[0], hexbytes[1:],
+                                                  prefix)
+                v = _unescape(v)
+            if len(v) > 1 and v[1] == quotechar and (len(v) < 3 or
+                                                     v[1] == v[2]):
+                v = v[2:-2]
+            return (v[1:-1], "str")
+        elif v[0] == '[':
+            return (self.load_array(v), "array")
+        elif v[0] == '{':
+            inline_object = self.get_empty_inline_table()
+            self.load_inline_object(v, inline_object)
+            return (inline_object, "inline_object")
+        elif TIME_RE.match(v):
+            h, m, s, _, ms = TIME_RE.match(v).groups()
+            time = datetime.time(int(h), int(m), int(s), int(ms) if ms else 0)
+            return (time, "time")
+        else:
+            parsed_date = _load_date(v)
+            if parsed_date is not None:
+                return (parsed_date, "date")
+            if not strictly_valid:
+                raise ValueError("Weirdness with leading zeroes or "
+                                 "underscores in your number.")
+            itype = "int"
+            neg = False
+            if v[0] == '-':
+                neg = True
+                v = v[1:]
+            elif v[0] == '+':
+                v = v[1:]
+            v = v.replace('_', '')
+            lowerv = v.lower()
+            if '.' in v or ('x' not in v and ('e' in v or 'E' in v)):
+                if '.' in v and v.split('.', 1)[1] == '':
+                    raise ValueError("This float is missing digits after "
+                                     "the point")
+                if v[0] not in '0123456789':
+                    raise ValueError("This float doesn't have a leading "
+                                     "digit")
+                v = float(v)
+                itype = "float"
+            elif len(lowerv) == 3 and (lowerv == 'inf' or lowerv == 'nan'):
+                v = float(v)
+                itype = "float"
+            if itype == "int":
+                v = int(v, 0)
+            if neg:
+                return (0 - v, itype)
+            return (v, itype)
+
+    def bounded_string(self, s):
+        if len(s) == 0:
+            return True
+        if s[-1] != s[0]:
+            return False
+        i = -2
+        backslash = False
+        while len(s) + i > 0:
+            if s[i] == "\\":
+                backslash = not backslash
+                i -= 1
+            else:
+                break
+        return not backslash
+
+    def load_array(self, a):
+        atype = None
+        retval = []
+        a = a.strip()
+        if '[' not in a[1:-1] or "" != a[1:-1].split('[')[0].strip():
+            strarray = False
+            tmpa = a[1:-1].strip()
+            if tmpa != '' and (tmpa[0] == '"' or tmpa[0] == "'"):
+                strarray = True
+            if not a[1:-1].strip().startswith('{'):
+                a = a[1:-1].split(',')
+            else:
+                # a is an inline object, we must find the matching parenthesis
+                # to define groups
+                new_a = []
+                start_group_index = 1
+                end_group_index = 2
+                in_str = False
+                while end_group_index < len(a[1:]):
+                    if a[end_group_index] == '"' or a[end_group_index] == "'":
+                        if in_str:
+                            backslash_index = end_group_index - 1
+                            while (backslash_index > -1 and
+                                   a[backslash_index] == '\\'):
+                                in_str = not in_str
+                                backslash_index -= 1
+                        in_str = not in_str
+                    if in_str or a[end_group_index] != '}':
+                        end_group_index += 1
+                        continue
+
+                    # Increase end_group_index by 1 to get the closing bracket
+                    end_group_index += 1
+
+                    new_a.append(a[start_group_index:end_group_index])
+
+                    # The next start index is at least after the closing
+                    # bracket, a closing bracket can be followed by a comma
+                    # since we are in an array.
+                    start_group_index = end_group_index + 1
+                    while (start_group_index < len(a[1:]) and
+                           a[start_group_index] != '{'):
+                        start_group_index += 1
+                    end_group_index = start_group_index + 1
+                a = new_a
+            b = 0
+            if strarray:
+                while b < len(a) - 1:
+                    ab = a[b].strip()
+                    while (not self.bounded_string(ab) or
+                           (len(ab) > 2 and
+                            ab[0] == ab[1] == ab[2] and
+                            ab[-2] != ab[0] and
+                            ab[-3] != ab[0])):
+                        a[b] = a[b] + ',' + a[b + 1]
+                        ab = a[b].strip()
+                        if b < len(a) - 2:
+                            a = a[:b + 1] + a[b + 2:]
+                        else:
+                            a = a[:b + 1]
+                    b += 1
+        else:
+            al = list(a[1:-1])
+            a = []
+            openarr = 0
+            j = 0
+            for i in _range(len(al)):
+                if al[i] == '[':
+                    openarr += 1
+                elif al[i] == ']':
+                    openarr -= 1
+                elif al[i] == ',' and not openarr:
+                    a.append(''.join(al[j:i]))
+                    j = i + 1
+            a.append(''.join(al[j:]))
+        for i in _range(len(a)):
+            a[i] = a[i].strip()
+            if a[i] != '':
+                nval, ntype = self.load_value(a[i])
+                if atype:
+                    if ntype != atype:
+                        raise ValueError("Not a homogeneous array")
+                else:
+                    atype = ntype
+                retval.append(nval)
+        return retval
diff --git a/pipenv/vendor/toml/encoder.py b/pipenv/vendor/toml/encoder.py
new file mode 100644
index 00000000..79bfd37b
--- /dev/null
+++ b/pipenv/vendor/toml/encoder.py
@@ -0,0 +1,250 @@
+import datetime
+import re
+import sys
+
+from toml.decoder import InlineTableDict
+
+if sys.version_info >= (3,):
+    unicode = str
+
+
+def dump(o, f):
+    """Writes out dict as toml to a file
+
+    Args:
+        o: Object to dump into toml
+        f: File descriptor where the toml should be stored
+
+    Returns:
+        String containing the toml corresponding to dictionary
+
+    Raises:
+        TypeError: When anything other than file descriptor is passed
+    """
+
+    if not f.write:
+        raise TypeError("You can only dump an object to a file descriptor")
+    d = dumps(o)
+    f.write(d)
+    return d
+
+
+def dumps(o, encoder=None):
+    """Stringifies input dict as toml
+
+    Args:
+        o: Object to dump into toml
+
+        preserve: Boolean parameter. If true, preserve inline tables.
+
+    Returns:
+        String containing the toml corresponding to dict
+    """
+
+    retval = ""
+    if encoder is None:
+        encoder = TomlEncoder(o.__class__)
+    addtoretval, sections = encoder.dump_sections(o, "")
+    retval += addtoretval
+    while sections:
+        newsections = encoder.get_empty_table()
+        for section in sections:
+            addtoretval, addtosections = encoder.dump_sections(
+                sections[section], section)
+
+            if addtoretval or (not addtoretval and not addtosections):
+                if retval and retval[-2:] != "\n\n":
+                    retval += "\n"
+                retval += "[" + section + "]\n"
+                if addtoretval:
+                    retval += addtoretval
+            for s in addtosections:
+                newsections[section + "." + s] = addtosections[s]
+        sections = newsections
+    return retval
+
+
+def _dump_str(v):
+    if sys.version_info < (3,) and hasattr(v, 'decode') and isinstance(v, str):
+        v = v.decode('utf-8')
+    v = "%r" % v
+    if v[0] == 'u':
+        v = v[1:]
+    singlequote = v.startswith("'")
+    if singlequote or v.startswith('"'):
+        v = v[1:-1]
+    if singlequote:
+        v = v.replace("\\'", "'")
+        v = v.replace('"', '\\"')
+    v = v.split("\\x")
+    while len(v) > 1:
+        i = -1
+        if not v[0]:
+            v = v[1:]
+        v[0] = v[0].replace("\\\\", "\\")
+        # No, I don't know why != works and == breaks
+        joinx = v[0][i] != "\\"
+        while v[0][:i] and v[0][i] == "\\":
+            joinx = not joinx
+            i -= 1
+        if joinx:
+            joiner = "x"
+        else:
+            joiner = "u00"
+        v = [v[0] + joiner + v[1]] + v[2:]
+    return unicode('"' + v[0] + '"')
+
+
+def _dump_float(v):
+    return "{0:.16}".format(v).replace("e+0", "e+").replace("e-0", "e-")
+
+
+def _dump_time(v):
+    utcoffset = v.utcoffset()
+    if utcoffset is None:
+        return v.isoformat()
+    # The TOML norm specifies that it's local time thus we drop the offset
+    return v.isoformat()[:-6]
+
+
+class TomlEncoder(object):
+
+    def __init__(self, _dict=dict, preserve=False):
+        self._dict = _dict
+        self.preserve = preserve
+        self.dump_funcs = {
+            str: _dump_str,
+            unicode: _dump_str,
+            list: self.dump_list,
+            bool: lambda v: unicode(v).lower(),
+            int: lambda v: v,
+            float: _dump_float,
+            datetime.datetime: lambda v: v.isoformat().replace('+00:00', 'Z'),
+            datetime.time: _dump_time,
+            datetime.date: lambda v: v.isoformat()
+        }
+
+    def get_empty_table(self):
+        return self._dict()
+
+    def dump_list(self, v):
+        retval = "["
+        for u in v:
+            retval += " " + unicode(self.dump_value(u)) + ","
+        retval += "]"
+        return retval
+
+    def dump_inline_table(self, section):
+        """Preserve inline table in its compact syntax instead of expanding
+        into subsection.
+
+        https://github.com/toml-lang/toml#user-content-inline-table
+        """
+        retval = ""
+        if isinstance(section, dict):
+            val_list = []
+            for k, v in section.items():
+                val = self.dump_inline_table(v)
+                val_list.append(k + " = " + val)
+            retval += "{ " + ", ".join(val_list) + " }\n"
+            return retval
+        else:
+            return unicode(self.dump_value(section))
+
+    def dump_value(self, v):
+        # Lookup function corresponding to v's type
+        dump_fn = self.dump_funcs.get(type(v))
+        if dump_fn is None and hasattr(v, '__iter__'):
+            dump_fn = self.dump_funcs[list]
+        # Evaluate function (if it exists) else return v
+        return dump_fn(v) if dump_fn is not None else self.dump_funcs[str](v)
+
+    def dump_sections(self, o, sup):
+        retstr = ""
+        if sup != "" and sup[-1] != ".":
+            sup += '.'
+        retdict = self._dict()
+        arraystr = ""
+        for section in o:
+            section = unicode(section)
+            qsection = section
+            if not re.match(r'^[A-Za-z0-9_-]+$', section):
+                if '"' in section:
+                    qsection = "'" + section + "'"
+                else:
+                    qsection = '"' + section + '"'
+            if not isinstance(o[section], dict):
+                arrayoftables = False
+                if isinstance(o[section], list):
+                    for a in o[section]:
+                        if isinstance(a, dict):
+                            arrayoftables = True
+                if arrayoftables:
+                    for a in o[section]:
+                        arraytabstr = "\n"
+                        arraystr += "[[" + sup + qsection + "]]\n"
+                        s, d = self.dump_sections(a, sup + qsection)
+                        if s:
+                            if s[0] == "[":
+                                arraytabstr += s
+                            else:
+                                arraystr += s
+                        while d:
+                            newd = self._dict()
+                            for dsec in d:
+                                s1, d1 = self.dump_sections(d[dsec], sup +
+                                                            qsection + "." +
+                                                            dsec)
+                                if s1:
+                                    arraytabstr += ("[" + sup + qsection +
+                                                    "." + dsec + "]\n")
+                                    arraytabstr += s1
+                                for s1 in d1:
+                                    newd[dsec + "." + s1] = d1[s1]
+                            d = newd
+                        arraystr += arraytabstr
+                else:
+                    if o[section] is not None:
+                        retstr += (qsection + " = " +
+                                   unicode(self.dump_value(o[section])) + '\n')
+            elif self.preserve and isinstance(o[section], InlineTableDict):
+                retstr += (qsection + " = " +
+                           self.dump_inline_table(o[section]))
+            else:
+                retdict[qsection] = o[section]
+        retstr += arraystr
+        return (retstr, retdict)
+
+
+class TomlPreserveInlineDictEncoder(TomlEncoder):
+
+    def __init__(self, _dict=dict):
+        super(TomlPreserveInlineDictEncoder, self).__init__(_dict, True)
+
+
+class TomlArraySeparatorEncoder(TomlEncoder):
+
+    def __init__(self, _dict=dict, preserve=False, separator=","):
+        super(TomlArraySeparatorEncoder, self).__init__(_dict, preserve)
+        if separator.strip() == "":
+            separator = "," + separator
+        elif separator.strip(' \t\n\r,'):
+            raise ValueError("Invalid separator for arrays")
+        self.separator = separator
+
+    def dump_list(self, v):
+        t = []
+        retval = "["
+        for u in v:
+            t.append(self.dump_value(u))
+        while t != []:
+            s = []
+            for u in t:
+                if isinstance(u, list):
+                    for r in u:
+                        s.append(r)
+                else:
+                    retval += " " + unicode(u) + self.separator
+            t = s
+        retval += "]"
+        return retval
diff --git a/pipenv/vendor/toml/ordered.py b/pipenv/vendor/toml/ordered.py
new file mode 100644
index 00000000..9c20c41a
--- /dev/null
+++ b/pipenv/vendor/toml/ordered.py
@@ -0,0 +1,15 @@
+from collections import OrderedDict
+from toml import TomlEncoder
+from toml import TomlDecoder
+
+
+class TomlOrderedDecoder(TomlDecoder):
+
+    def __init__(self):
+        super(self.__class__, self).__init__(_dict=OrderedDict)
+
+
+class TomlOrderedEncoder(TomlEncoder):
+
+    def __init__(self):
+        super(self.__class__, self).__init__(_dict=OrderedDict)
diff --git a/pipenv/vendor/toml/tz.py b/pipenv/vendor/toml/tz.py
new file mode 100644
index 00000000..93c3c8ad
--- /dev/null
+++ b/pipenv/vendor/toml/tz.py
@@ -0,0 +1,21 @@
+from datetime import tzinfo, timedelta
+
+
+class TomlTz(tzinfo):
+    def __init__(self, toml_offset):
+        if toml_offset == "Z":
+            self._raw_offset = "+00:00"
+        else:
+            self._raw_offset = toml_offset
+        self._sign = -1 if self._raw_offset[0] == '-' else 1
+        self._hours = int(self._raw_offset[1:3])
+        self._minutes = int(self._raw_offset[4:6])
+
+    def tzname(self, dt):
+        return "UTC" + self._raw_offset
+
+    def utcoffset(self, dt):
+        return self._sign * timedelta(hours=self._hours, minutes=self._minutes)
+
+    def dst(self, dt):
+        return timedelta(0)
diff --git a/pipenv/vendor/tomlkit/__init__.py b/pipenv/vendor/tomlkit/__init__.py
index 45de35fd..23d4ef74 100644
--- a/pipenv/vendor/tomlkit/__init__.py
+++ b/pipenv/vendor/tomlkit/__init__.py
@@ -22,4 +22,4 @@ from .api import value
 from .api import ws
 
 
-__version__ = "0.4.2"
+__version__ = "0.4.4"
diff --git a/pipenv/vendor/tomlkit/_compat.py b/pipenv/vendor/tomlkit/_compat.py
index 26296ff5..f94bb10e 100644
--- a/pipenv/vendor/tomlkit/_compat.py
+++ b/pipenv/vendor/tomlkit/_compat.py
@@ -162,16 +162,3 @@ def decode(string, encodings=None):
             pass
 
     return string.decode(encodings[0], errors="ignore")
-
-
-_escaped = {"b": "\b", "t": "\t", "n": "\n", "f": "\f", "r": "\r", '"': '"', "\\": "\\"}
-_escapable = re.compile(r"(?<!\\)([\n\b\t\f\r\\])")
-
-
-def string_escape(string):
-    if PY2:
-        return _escapable.sub(lambda m: m.group(1).encode("string_escape"), string)
-
-    return _escapable.sub(
-        lambda m: m.group(1).encode("unicode_escape").decode("utf-8"), string
-    )
diff --git a/pipenv/vendor/tomlkit/_utils.py b/pipenv/vendor/tomlkit/_utils.py
index 6f9fb055..f62a354a 100644
--- a/pipenv/vendor/tomlkit/_utils.py
+++ b/pipenv/vendor/tomlkit/_utils.py
@@ -6,6 +6,7 @@ from datetime import time
 from datetime import timedelta
 
 
+from ._compat import decode
 from ._compat import timezone
 
 RFC_3339_DATETIME = re.compile(
@@ -85,3 +86,35 @@ def parse_rfc3339(string):  # type: (str) -> Union[datetime, date, time]
         return time(hour, minute, second, microsecond)
 
     raise ValueError("Invalid RFC 339 string")
+
+
+_escaped = {"b": "\b", "t": "\t", "n": "\n", "f": "\f", "r": "\r", '"': '"', "\\": "\\"}
+_escapes = {v: k for k, v in _escaped.items()}
+
+
+def escape_string(s):
+    s = decode(s)
+
+    res = []
+    start = 0
+
+    def flush():
+        if start != i:
+            res.append(s[start:i])
+
+        return i + 1
+
+    i = 0
+    while i < len(s):
+        c = s[i]
+        if c in '"\\\n\r\t\b\f':
+            start = flush()
+            res.append("\\" + _escapes[c])
+        elif ord(c) < 0x20:
+            start = flush()
+            res.append("\\u%04x" % ord(c))
+        i += 1
+
+    flush()
+
+    return "".join(res)
diff --git a/pipenv/vendor/tomlkit/container.py b/pipenv/vendor/tomlkit/container.py
index a7876ff1..bb3696d9 100644
--- a/pipenv/vendor/tomlkit/container.py
+++ b/pipenv/vendor/tomlkit/container.py
@@ -137,9 +137,9 @@ class Container(dict):
         is_table = isinstance(item, (Table, AoT))
         if key is not None and self._body and not self._parsed:
             # If there is already at least one table in the current container
-            # an the given item is not a table, we need to find the last
+            # and the given item is not a table, we need to find the last
             # item that is not a table and insert after it
-            # If not such item exists, insert at the top of the table
+            # If no such item exists, insert at the top of the table
             key_after = None
             idx = 0
             for k, v in self._body:
@@ -333,7 +333,7 @@ class Container(dict):
             if table.is_aot_element():
                 open_, close = "[[", "]]"
 
-            cur += "{}{}{}{}{}{}{}".format(
+            cur += "{}{}{}{}{}{}{}{}".format(
                 table.trivia.indent,
                 open_,
                 decode(_key),
@@ -341,6 +341,7 @@ class Container(dict):
                 table.trivia.comment_ws,
                 decode(table.trivia.comment),
                 table.trivia.trail,
+                "\n" if "\n" not in table.trivia.trail and len(table.value) > 0 else "",
             )
 
         for k, v in table.value.body:
@@ -450,6 +451,10 @@ class Container(dict):
 
             yield k, v
 
+    def update(self, other):  # type: (Dict) -> None
+        for k, v in other.items():
+            self[k] = v
+
     def __contains__(self, key):  # type: (Union[Key, str]) -> bool
         if not isinstance(key, Key):
             key = Key(key)
diff --git a/pipenv/vendor/tomlkit/items.py b/pipenv/vendor/tomlkit/items.py
index 8807f4b3..26f24701 100644
--- a/pipenv/vendor/tomlkit/items.py
+++ b/pipenv/vendor/tomlkit/items.py
@@ -15,6 +15,7 @@ else:
 from ._compat import PY2
 from ._compat import decode
 from ._compat import unicode
+from ._utils import escape_string
 
 
 def item(value, _parent=None):
@@ -60,7 +61,7 @@ def item(value, _parent=None):
 
         return a
     elif isinstance(value, (str, unicode)):
-        escaped = decode(value).replace('"', '\\"').replace("\\\\", "\\")
+        escaped = escape_string(value)
 
         return String(StringType.SLB, value, escaped, Trivia())
     elif isinstance(value, datetime):
@@ -751,6 +752,10 @@ class Table(Item, dict):
         for k, v in self._value.items():
             yield k, v
 
+    def update(self, other):  # type: (Dict) -> None
+        for k, v in other.items():
+            self[k] = v
+
     def __contains__(self, key):  # type: (Union[Key, str]) -> bool
         return key in self._value
 
@@ -758,7 +763,26 @@ class Table(Item, dict):
         return self._value[key]
 
     def __setitem__(self, key, value):  # type: (Union[Key, str], Any) -> None
-        self.append(key, value)
+        if not isinstance(value, Item):
+            value = item(value)
+
+        self._value[key] = value
+
+        if key is not None:
+            super(Table, self).__setitem__(key, value)
+
+        m = re.match("(?s)^[^ ]*([ ]+).*$", self._trivia.indent)
+        if not m:
+            return
+
+        indent = m.group(1)
+
+        if not isinstance(value, Whitespace):
+            m = re.match("(?s)^([^ ]*)(.*)$", value.trivia.indent)
+            if not m:
+                value.trivia.indent = indent
+            else:
+                value.trivia.indent = m.group(1) + indent + m.group(2)
 
     def __delitem__(self, key):  # type: (Union[Key, str]) -> None
         self.remove(key)
@@ -862,6 +886,10 @@ class InlineTable(Item, dict):
         for k, v in self._value.items():
             yield k, v
 
+    def update(self, other):  # type: (Dict) -> None
+        for k, v in other.items():
+            self[k] = v
+
     def __contains__(self, key):  # type: (Union[Key, str]) -> bool
         return key in self._value
 
@@ -869,7 +897,26 @@ class InlineTable(Item, dict):
         return self._value[key]
 
     def __setitem__(self, key, value):  # type: (Union[Key, str], Any) -> None
-        self.append(key, value)
+        if not isinstance(value, Item):
+            value = item(value)
+
+        self._value[key] = value
+
+        if key is not None:
+            super(InlineTable, self).__setitem__(key, value)
+
+        m = re.match("(?s)^[^ ]*([ ]+).*$", self._trivia.indent)
+        if not m:
+            return
+
+        indent = m.group(1)
+
+        if not isinstance(value, Whitespace):
+            m = re.match("(?s)^([^ ]*)(.*)$", value.trivia.indent)
+            if not m:
+                value.trivia.indent = indent
+            else:
+                value.trivia.indent = m.group(1) + indent + m.group(2)
 
     def __delitem__(self, key):  # type: (Union[Key, str]) -> None
         self.remove(key)
diff --git a/pipenv/vendor/tomlkit/parser.py b/pipenv/vendor/tomlkit/parser.py
index 3d4984d1..45c8ee8c 100644
--- a/pipenv/vendor/tomlkit/parser.py
+++ b/pipenv/vendor/tomlkit/parser.py
@@ -11,6 +11,7 @@ from copy import copy
 from ._compat import PY2
 from ._compat import chr
 from ._compat import decode
+from ._utils import _escaped
 from ._utils import parse_rfc3339
 from .container import Container
 from .exceptions import EmptyKeyError
@@ -286,19 +287,20 @@ class Parser:
 
     def _save_idx(self):  # type: () -> Tuple[Iterator, int, str]
         if PY2:
-            return itertools.tee(self._chars)[1], self._idx, self._current
+            # Python 2.7 does not allow to directly copy
+            # an iterator, so we have to make tees of the original
+            # chars iterator.
+            chars1, chars2 = itertools.tee(self._chars)
+
+            # We can no longer use the original chars iterator.
+            self._chars = chars1
+
+            return chars2, self._idx, self._current
 
         return copy(self._chars), self._idx, self._current
 
     def _restore_idx(self, chars, idx, current):  # type: (Iterator, int, str) -> None
-        if PY2:
-            self._chars = iter(
-                [(i + idx, TOMLChar(c)) for i, c in enumerate(self._src[idx:])]
-            )
-            next(self._chars)
-        else:
-            self._chars = chars
-
+        self._chars = chars
         self._idx = idx
         self._current = current
 
@@ -736,15 +738,6 @@ class Parser:
 
                 return String(str_type, value, val, Trivia())
             else:
-                escape_vals = {
-                    "b": "\b",
-                    "t": "\t",
-                    "n": "\n",
-                    "f": "\f",
-                    "r": "\r",
-                    "\\": "\\",
-                    '"': '"',
-                }
                 if previous == "\\" and self._current.is_ws() and multiline:
                     while self._current.is_ws():
                         previous = self._current
@@ -768,10 +761,10 @@ class Parser:
                             raise self.parse_error(UnexpectedEofError)
 
                         continue
-                    elif self._current in escape_vals and not escaped:
+                    elif self._current in _escaped and not escaped:
                         if not str_type.is_literal():
                             value = value[:-1]
-                            value += escape_vals[self._current]
+                            value += _escaped[self._current]
                         else:
                             value += self._current
                     elif self._current in {"u", "U"} and not escaped:
diff --git a/pipenv/vendor/vistir/__init__.py b/pipenv/vendor/vistir/__init__.py
index 1e843dee..4be472ab 100644
--- a/pipenv/vendor/vistir/__init__.py
+++ b/pipenv/vendor/vistir/__init__.py
@@ -13,7 +13,7 @@ from .misc import load_path, partialclass, run, shell_escape
 from .path import mkdir_p, rmtree
 
 
-__version__ = '0.1.5'
+__version__ = '0.1.6'
 
 
 __all__ = [
diff --git a/pipenv/vendor/vistir/misc.py b/pipenv/vendor/vistir/misc.py
index 98ebe502..723bb117 100644
--- a/pipenv/vendor/vistir/misc.py
+++ b/pipenv/vendor/vistir/misc.py
@@ -13,15 +13,20 @@ from functools import partial
 
 import six
 
-from yaspin import yaspin, spinners
-
 from .cmdparse import Script
 from .compat import Path, fs_str, partialmethod
 
 
 __all__ = [
-    "shell_escape", "unnest", "dedup", "run", "load_path", "partialclass", "to_text",
-    "to_bytes", "locale_encoding"
+    "shell_escape",
+    "unnest",
+    "dedup",
+    "run",
+    "load_path",
+    "partialclass",
+    "to_text",
+    "to_bytes",
+    "locale_encoding",
 ]
 
 
@@ -72,15 +77,17 @@ def dedup(iterable):
 
 def _spawn_subprocess(script, env={}, block=True, cwd=None):
     from distutils.spawn import find_executable
+
     command = find_executable(script.command)
     options = {
         "env": env,
         "universal_newlines": True,
         "stdout": subprocess.PIPE,
         "stderr": subprocess.PIPE if block else subprocess.STDOUT,
-        "stdin": None if block else subprocess.PIPE,
-        "shell": False
+        "shell": False,
     }
+    if not block:
+        options["stdin"] = subprocess.PIPE
     if cwd:
         options["cwd"] = cwd
     # Command not found, maybe this is a shell built-in?
@@ -102,17 +109,26 @@ def _spawn_subprocess(script, env={}, block=True, cwd=None):
     return subprocess.Popen(script.cmdify(), **options)
 
 
-def _create_subprocess(cmd, env={}, block=True, return_object=False, cwd=os.curdir, verbose=False, spinner=None):
+def _create_subprocess(
+    cmd,
+    env={},
+    block=True,
+    return_object=False,
+    cwd=os.curdir,
+    verbose=False,
+    spinner=None,
+):
     try:
         c = _spawn_subprocess(cmd, env=env, block=block, cwd=cwd)
     except Exception as exc:
-        print(
-            "Error %s while executing command %s", exc, " ".join(cmd._parts)
-        )
+        print("Error %s while executing command %s", exc, " ".join(cmd._parts))
         raise
     if not block:
         c.stdin.close()
         output = []
+        spinner_orig_text = ""
+        if spinner:
+            spinner_orig_text = spinner.text
         if c.stdout is not None:
             while True:
                 line = to_text(c.stdout.readline())
@@ -120,17 +136,22 @@ def _create_subprocess(cmd, env={}, block=True, return_object=False, cwd=os.curd
                     break
                 line = line.rstrip()
                 output.append(line)
+                display_line = line
+                if len(line) > 200:
+                    display_line = "{0}...".format(line[:200])
                 if verbose:
-                    print(line + "\n")
-                elif spinner:
-                    spinner.text = line
+                    spinner.write(display_line)
                 else:
+                    spinner.text = "{0} {1}".format(spinner_orig_text, display_line)
                     continue
         try:
             c.wait()
         finally:
             if c.stdout:
                 c.stdout.close()
+        if spinner:
+            spinner.text = "Complete!"
+            spinner.ok("")
         c.out = "".join(output)
         c.err = ""
     else:
@@ -140,7 +161,15 @@ def _create_subprocess(cmd, env={}, block=True, return_object=False, cwd=os.curd
     return c
 
 
-def run(cmd, env={}, return_object=False, block=True, cwd=None, verbose=False, nospin=False,):
+def run(
+    cmd,
+    env={},
+    return_object=False,
+    block=True,
+    cwd=None,
+    verbose=False,
+    nospin=False,
+):
     """Use `subprocess.Popen` to get the output of a command and decode it.
 
     :param list cmd: A list representing the command you want to run.
@@ -166,17 +195,46 @@ def run(cmd, env={}, return_object=False, block=True, cwd=None, verbose=False, n
             cmd = [c.encode("utf-8") for c in cmd]
     if not isinstance(cmd, Script):
         cmd = Script.parse(cmd)
-    spinner = yaspin
-    if nospin:
+    if nospin is False:
+        try:
+            from yaspin import yaspin
+            from yaspin import spinners
+        except ImportError:
+            raise RuntimeError(
+                "Failed to import spinner! Reinstall vistir with command:"
+                " pip install --upgrade vistir[spinner]"
+            )
+        else:
+            spinner = yaspin
+            animation = spinners.Spinners.bouncingBar
+    else:
+
         @contextmanager
-        def spinner(spin_type):
+        def spinner(spin_type, text):
             class FakeClass(object):
-                def __init__(self):
-                    self.text = ""
-            myobj = FakeClass()
+                def __init__(self, text=""):
+                    self.text = text
+
+                def ok(self, text):
+                    return
+
+                def write(self, text):
+                    print(text)
+
+            myobj = FakeClass(text)
             yield myobj
-    with spinner(spinners.Spinners.bouncingBar) as sp:
-        return _create_subprocess(cmd, env=_env, return_object=return_object, block=block, cwd=cwd, verbose=verbose, spinner=sp)
+
+        animation = None
+    with spinner(animation, text="Running...") as sp:
+        return _create_subprocess(
+            cmd,
+            env=_env,
+            return_object=return_object,
+            block=block,
+            cwd=cwd,
+            verbose=verbose,
+            spinner=sp,
+        )
 
 
 def load_path(python):
@@ -217,20 +275,18 @@ def partialclass(cls, *args, **kwargs):
     {'url': 'https://pypi.org/simple', 'verify_ssl': True, 'name': 'pypi'}
     """
 
-    name_attrs = [n for n in (getattr(cls, name, str(cls)) for name in ("__name__", "__qualname__")) if n is not None]
+    name_attrs = [
+        n
+        for n in (getattr(cls, name, str(cls)) for name in ("__name__", "__qualname__"))
+        if n is not None
+    ]
     name_attrs = name_attrs[0]
     type_ = type(
-        name_attrs,
-        (cls,),
-        {
-            "__init__": partialmethod(cls.__init__, *args, **kwargs),
-        }
+        name_attrs, (cls,), {"__init__": partialmethod(cls.__init__, *args, **kwargs)}
     )
     # Swiped from attrs.make_class
     try:
-        type_.__module__ = sys._getframe(1).f_globals.get(
-            "__name__", "__main__",
-        )
+        type_.__module__ = sys._getframe(1).f_globals.get("__name__", "__main__")
     except (AttributeError, ValueError):
         pass
     return type_
@@ -258,7 +314,7 @@ def to_bytes(string, encoding="utf-8", errors="ignore"):
         if encoding.lower() == "utf-8":
             return string
         else:
-            return string.decode('utf-8').encode(encoding, errors)
+            return string.decode("utf-8").encode(encoding, errors)
     elif isinstance(string, memoryview):
         return bytes(string)
     elif not isinstance(string, six.string_types):
@@ -269,7 +325,7 @@ def to_bytes(string, encoding="utf-8", errors="ignore"):
                 return bytes(string)
         except UnicodeEncodeError:
             if isinstance(string, Exception):
-                return b' '.join(to_bytes(arg, encoding, errors) for arg in string)
+                return b" ".join(to_bytes(arg, encoding, errors) for arg in string)
             return six.text_type(string).encode(encoding, errors)
     else:
         return string.encode(encoding, errors)
@@ -300,18 +356,18 @@ def to_text(string, encoding="utf-8", errors=None):
                     string = six.text_type(string, encoding, errors)
                 else:
                     string = six.text_type(string)
-            elif hasattr(string, '__unicode__'):
+            elif hasattr(string, "__unicode__"):
                 string = six.text_type(string)
             else:
                 string = six.text_type(bytes(string), encoding, errors)
         else:
             string = string.decode(encoding, errors)
     except UnicodeDecodeError as e:
-            string = ' '.join(to_text(arg, encoding, errors) for arg in string)
+        string = " ".join(to_text(arg, encoding, errors) for arg in string)
     return string
 
 
 try:
-    locale_encoding = locale.getdefaultencoding()[1] or 'ascii'
+    locale_encoding = locale.getdefaultencoding()[1] or "ascii"
 except Exception:
-    locale_encoding = 'ascii'
+    locale_encoding = "ascii"
diff --git a/tasks/vendoring/__init__.py b/tasks/vendoring/__init__.py
index 3c5d8d99..3198c2d4 100644
--- a/tasks/vendoring/__init__.py
+++ b/tasks/vendoring/__init__.py
@@ -627,8 +627,8 @@ def main(ctx, package=None):
         vendor_file = _vendor_dir / 'vendor.txt'
         vendor_file.write_bytes(vendor_src_file.read_bytes())
         download_licenses(ctx, _vendor_dir)
-    from .vendor_passa import vendor_passa
-    log("Vendoring passa...")
-    vendor_passa(ctx)
+    # from .vendor_passa import vendor_passa
+    # log("Vendoring passa...")
+    # vendor_passa(ctx)
     # update_safety(ctx)
     log('Revendoring complete')
diff --git a/tasks/vendoring/patches/patched/piptools.patch b/tasks/vendoring/patches/patched/piptools.patch
index 90c420b9..5e219609 100644
--- a/tasks/vendoring/patches/patched/piptools.patch
+++ b/tasks/vendoring/patches/patched/piptools.patch
@@ -96,11 +96,11 @@ index bf69803..eb20560 100644
 +    SafeFileCache
  )
 +os.environ["PIP_SHIMS_BASE_MODULE"] = "notpip"
-+from pip_shims.shims import pip_import, VcsSupport, WheelCache
++from pip_shims.shims import do_import, VcsSupport, WheelCache
 +from packaging.requirements import Requirement
 +from packaging.specifiers import SpecifierSet, Specifier
 +from packaging.markers import Op, Value, Variable, Marker
-+InstallationError = pip_import("InstallationError", "exceptions.InstallationError", "7.0", "9999")
++InstallationError = do_import(("InstallationError", "exceptions.InstallationError", "7.0", "9999"))
 +from notpip._internal.resolve import Resolver as PipResolver
 +
  
