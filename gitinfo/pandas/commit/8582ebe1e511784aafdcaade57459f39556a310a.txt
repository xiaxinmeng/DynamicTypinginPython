commit 8582ebe1e511784aafdcaade57459f39556a310a
Author: Adam Klein <adamklein@gmail.com>
Date:   Thu Mar 15 14:12:01 2012 -0400

    ENH: remove skts extraneous code from code base

diff --git a/.gitignore b/.gitignore
index f1c40f091..352d7f0f1 100644
--- a/.gitignore
+++ b/.gitignore
@@ -7,7 +7,6 @@ MANIFEST
 *.c
 !np_datetime.c
 !np_datetime_strings.c
-!pandas/src/timeseries/*.c
 !skts.c
 *.cpp
 *.so
diff --git a/pandas/src/timeseries/c_dates.c b/pandas/src/timeseries/c_dates.c
deleted file mode 100644
index e40b0846d..000000000
--- a/pandas/src/timeseries/c_dates.c
+++ /dev/null
@@ -1,3011 +0,0 @@
-#include "c_dates.h"
-#include <datetime.h>
-#include <time.h>
-
-
-int get_freq_group(int freq) { return (freq/1000)*1000; }
-
-static asfreq_info NULL_AF_INFO;
-
-/*********************************************************
-** Python callbacks. These functions must be called by  **
-** the module __init__ script                           **
-*********************************************************/
-
-static PyObject *DateFromString = NULL;
-PyObject *
-set_callback_DateFromString(PyObject *dummy, PyObject *args) {
-    return set_callback(args, &DateFromString);
-}
-
-static PyObject *DateTimeFromString = NULL;
-PyObject *
-set_callback_DateTimeFromString(PyObject *dummy, PyObject *args) {
-    return set_callback(args, &DateTimeFromString);
-}
-
-//DERIVED FROM mx.DateTime
-/*
-    Functions in the following section are borrowed from mx.DateTime version
-    2.0.6, and hence this code is subject to the terms of the egenix public
-    license version 1.0.0
-*/
-
-#define Py_AssertWithArg(x,errortype,errorstr,a1) {if (!(x)) {PyErr_Format(errortype,errorstr,a1);goto onError;}}
-#define Py_Error(errortype,errorstr) {PyErr_SetString(errortype,errorstr);goto onError;}
-
- /* Error Exception objects */
-static PyObject *DateCalc_Error;
-static PyObject *DateCalc_RangeError;
-
-#define GREGORIAN_CALENDAR 0
-#define JULIAN_CALENDAR 1
-
-#define SECONDS_PER_DAY ((double) 86400.0)
-
-/* Table with day offsets for each month (0-based, without and with leap) */
-static int month_offset[2][13] = {
-    { 0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365 },
-    { 0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366 }
-};
-
-/* Table of number of days in a month (0-based, without and with leap) */
-static int days_in_month[2][12] = {
-    { 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 },
-    { 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31 }
-};
-
-struct date_info {
-    long absdate;
-    double abstime;
-
-    double second;
-    int minute;
-    int hour;
-    int day;
-    int month;
-    int quarter;
-    int year;
-    int day_of_week;
-    int day_of_year;
-    int calendar;
-};
-
-
-/* Return 1/0 iff year points to a leap year in calendar. */
-static
-int dInfoCalc_Leapyear(register long year,
-            int calendar)
-{
-    if (calendar == GREGORIAN_CALENDAR) {
-        return (year % 4 == 0) && ((year % 100 != 0) || (year % 400 == 0));
-    } else {
-        return (year % 4 == 0);
-    }
-}
-
-static
-int dInfoCalc_ISOWeek(struct date_info *dinfo)
-{
-    int week;
-
-    /* Estimate */
-    week = (dinfo->day_of_year-1) - dinfo->day_of_week + 3;
-    if (week >= 0) week = week / 7 + 1;
-
-    /* Verify */
-    if (week < 0) {
-        /* The day lies in last week of the previous year */
-        if ((week > -2) ||
-            (week == -2 && dInfoCalc_Leapyear(dinfo->year-1, dinfo->calendar)))
-            week = 53;
-        else
-            week = 52;
-    } else if (week == 53) {
-    /* Check if the week belongs to year or year+1 */
-        if (31-dinfo->day + dinfo->day_of_week < 3) {
-            week = 1;
-        }
-    }
-
-    return week;
-}
-
-
-/* Return the day of the week for the given absolute date. */
-static
-int dInfoCalc_DayOfWeek(register long absdate)
-{
-    int day_of_week;
-
-    if (absdate >= 1) {
-        day_of_week = (absdate - 1) % 7;
-    } else {
-        day_of_week = 6 - ((-absdate) % 7);
-    }
-    return day_of_week;
-}
-
-/* Return the year offset, that is the absolute date of the day
-   31.12.(year-1) in the given calendar.
-
-   Note:
-   For the Julian calendar we shift the absdate (which is measured
-   using the Gregorian Epoch) value by two days because the Epoch
-   (0001-01-01) in the Julian calendar lies 2 days before the Epoch in
-   the Gregorian calendar. */
-static
-int dInfoCalc_YearOffset(register long year,
-              int calendar)
-{
-    year--;
-    if (calendar == GREGORIAN_CALENDAR) {
-    if (year >= 0 || -1/4 == -1)
-        return year*365 + year/4 - year/100 + year/400;
-    else
-        return year*365 + (year-3)/4 - (year-99)/100 + (year-399)/400;
-    }
-    else if (calendar == JULIAN_CALENDAR) {
-    if (year >= 0 || -1/4 == -1)
-        return year*365 + year/4 - 2;
-    else
-        return year*365 + (year-3)/4 - 2;
-    }
-    Py_Error(DateCalc_Error, "unknown calendar");
- onError:
-    return -1;
-}
-
-
-/* Set the instance's value using the given date and time. calendar
-   may be set to the flags: GREGORIAN_CALENDAR,
-   JULIAN_CALENDAR to indicate the calendar to be used. */
-
-static
-int dInfoCalc_SetFromDateAndTime(struct date_info *dinfo,
-                  int year,
-                  int month,
-                  int day,
-                  int hour,
-                  int minute,
-                  double second,
-                  int calendar)
-{
-
-    /* Calculate the absolute date */
-    {
-        int leap;
-        long yearoffset,absdate;
-
-        /* Range check */
-        Py_AssertWithArg(year > -(INT_MAX / 366) && year < (INT_MAX / 366),
-                 DateCalc_RangeError,
-                 "year out of range: %i",
-                 year);
-
-        /* Is it a leap year ? */
-        leap = dInfoCalc_Leapyear(year,calendar);
-
-        /* Negative month values indicate months relative to the years end */
-        if (month < 0) month += 13;
-        Py_AssertWithArg(month >= 1 && month <= 12,
-                 DateCalc_RangeError,
-                 "month out of range (1-12): %i",
-                 month);
-
-        /* Negative values indicate days relative to the months end */
-        if (day < 0) day += days_in_month[leap][month - 1] + 1;
-        Py_AssertWithArg(day >= 1 && day <= days_in_month[leap][month - 1],
-                 DateCalc_RangeError,
-                 "day out of range: %i",
-                 day);
-
-        yearoffset = dInfoCalc_YearOffset(year,calendar);
-        if (PyErr_Occurred()) goto onError;
-
-        absdate = day + month_offset[leap][month - 1] + yearoffset;
-
-        dinfo->absdate = absdate;
-
-        dinfo->year = year;
-        dinfo->month = month;
-        dinfo->quarter = ((month-1)/3)+1;
-        dinfo->day = day;
-
-        dinfo->day_of_week = dInfoCalc_DayOfWeek(absdate);
-        dinfo->day_of_year = (short)(absdate - yearoffset);
-
-        dinfo->calendar = calendar;
-    }
-
-    /* Calculate the absolute time */
-    {
-    Py_AssertWithArg(hour >= 0 && hour <= 23,
-             DateCalc_RangeError,
-             "hour out of range (0-23): %i",
-             hour);
-    Py_AssertWithArg(minute >= 0 && minute <= 59,
-             DateCalc_RangeError,
-             "minute out of range (0-59): %i",
-             minute);
-    Py_AssertWithArg(second >= (double)0.0 &&
-             (second < (double)60.0 ||
-              (hour == 23 && minute == 59 &&
-               second < (double)61.0)),
-             DateCalc_RangeError,
-             "second out of range (0.0 - <60.0; <61.0 for 23:59): %f",
-             second);
-
-    dinfo->abstime = (double)(hour*3600 + minute*60) + second;
-
-    dinfo->hour = hour;
-    dinfo->minute = minute;
-    dinfo->second = second;
-    }
-    return 0;
- onError:
-    return -1;
-}
-
-static int monthToQuarter(int month) { return ((month-1)/3)+1; }
-
-/* Sets the date part of the date_info struct using the indicated
-   calendar.
-
-   XXX This could also be done using some integer arithmetics rather
-       than with this iterative approach... */
-static
-int dInfoCalc_SetFromAbsDate(register struct date_info *dinfo,
-                  long absdate,
-                  int calendar)
-{
-    register long year;
-    long yearoffset;
-    int leap,dayoffset;
-    int *monthoffset;
-
-    /* Approximate year */
-    if (calendar == GREGORIAN_CALENDAR) {
-        year = (long)(((double)absdate) / 365.2425);
-    } else if (calendar == JULIAN_CALENDAR) {
-        year = (long)(((double)absdate) / 365.25);
-    } else {
-        Py_Error(DateCalc_Error, "unknown calendar");
-    }
-    if (absdate > 0) year++;
-
-    /* Apply corrections to reach the correct year */
-    while (1) {
-        /* Calculate the year offset */
-        yearoffset = dInfoCalc_YearOffset(year,calendar);
-        if (PyErr_Occurred())
-            goto onError;
-
-        /* Backward correction: absdate must be greater than the
-           yearoffset */
-        if (yearoffset >= absdate) {
-            year--;
-            continue;
-        }
-
-        dayoffset = absdate - yearoffset;
-        leap = dInfoCalc_Leapyear(year,calendar);
-
-        /* Forward correction: non leap years only have 365 days */
-        if (dayoffset > 365 && !leap) {
-            year++;
-            continue;
-        }
-        break;
-    }
-
-    dinfo->year = year;
-    dinfo->calendar = calendar;
-
-    /* Now iterate to find the month */
-    monthoffset = month_offset[leap];
-    {
-        register int month;
-
-        for (month = 1; month < 13; month++) {
-            if (monthoffset[month] >= dayoffset)
-            break;
-        }
-
-        dinfo->month = month;
-        dinfo->quarter = monthToQuarter(month);
-        dinfo->day = dayoffset - month_offset[leap][month-1];
-    }
-
-
-    dinfo->day_of_week = dInfoCalc_DayOfWeek(absdate);
-    dinfo->day_of_year = dayoffset;
-    dinfo->absdate = absdate;
-
-    return 0;
-
- onError:
-    return -1;
-}
-
-/* Sets the time part of the DateTime object. */
-static
-int dInfoCalc_SetFromAbsTime(struct date_info *dinfo,
-                  double abstime)
-{
-    int inttime;
-    int hour,minute;
-    double second;
-
-    inttime = (int)abstime;
-    hour = inttime / 3600;
-    minute = (inttime % 3600) / 60;
-    second = abstime - (double)(hour*3600 + minute*60);
-
-    dinfo->hour = hour;
-    dinfo->minute = minute;
-    dinfo->second = second;
-
-    dinfo->abstime = abstime;
-
-    return 0;
-}
-
-/* Set the instance's value using the given date and time. calendar
-   may be set to the flags: GREGORIAN_CALENDAR, JULIAN_CALENDAR to
-   indicate the calendar to be used. */
-static
-int dInfoCalc_SetFromAbsDateTime(struct date_info *dinfo,
-                  long absdate,
-                  double abstime,
-                  int calendar)
-{
-
-    /* Bounds check */
-    Py_AssertWithArg(abstime >= 0.0 && abstime <= SECONDS_PER_DAY,
-             DateCalc_Error,
-             "abstime out of range (0.0 - 86400.0): %f",
-             abstime);
-
-    /* Calculate the date */
-    if (dInfoCalc_SetFromAbsDate(dinfo,
-                  absdate,
-                  calendar))
-    goto onError;
-
-    /* Calculate the time */
-    if (dInfoCalc_SetFromAbsTime(dinfo,
-                  abstime))
-    goto onError;
-
-    return 0;
- onError:
-    return -1;
-}
-
-/*
-====================================================
-== End of section borrowed from mx.DateTime       ==
-====================================================
-*/
-
-
-
-
-
-///////////////////////////////////////////////////////////////////////
-
-// helpers for frequency conversion routines //
-
-static long DtoB_weekday(long fromDate) { return (((fromDate) / 7) * 5) + (fromDate)%7; }
-
-static long DtoB_WeekendToMonday(long absdate, int day_of_week) {
-
-    if (day_of_week > 4) {
-        //change to Monday after weekend
-        absdate += (7 - day_of_week);
-    }
-    return DtoB_weekday(absdate);
-}
-
-static long DtoB_WeekendToFriday(long absdate, int day_of_week) {
-
-    if (day_of_week > 4) {
-        //change to friday before weekend
-        absdate -= (day_of_week - 4);
-    }
-    return DtoB_weekday(absdate);
-}
-
-static long absdate_from_ymd(int y, int m, int d) {
-    struct date_info tempDate;
-    if (dInfoCalc_SetFromDateAndTime(&tempDate, y, m, d, 0, 0, 0, GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-    return tempDate.absdate;
-}
-
-
-///////////////////////////////////////////////
-
-// frequency specifc conversion routines
-// each function must take an integer fromDate and 
-// a char relation ('S' or 'E' for 'START' or 'END')
-
-//************ FROM DAILY ***************
-
-static long asfreq_DtoA(long fromDate, char relation, asfreq_info *af_info) {
-
-    struct date_info dinfo;
-    if (dInfoCalc_SetFromAbsDate(&dinfo, fromDate,
-                    GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-    if (dinfo.month > af_info->to_a_year_end) { return (long)(dinfo.year + 1); }
-    else { return (long)(dinfo.year); }
-}
-
-static long DtoQ_yq(long fromDate, asfreq_info *af_info,
-                              int *year, int *quarter) {
-    struct date_info dinfo;
-    if (dInfoCalc_SetFromAbsDate(&dinfo, fromDate,
-                    GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-    if (af_info->to_q_year_end != 12) {
-        dinfo.month -= af_info->to_q_year_end;
-        if (dinfo.month <= 0) { dinfo.month += 12; }
-        else { dinfo.year += 1; }
-        dinfo.quarter = monthToQuarter(dinfo.month);
-    }
-
-    *year = dinfo.year;
-    *quarter = dinfo.quarter;
-
-    return 0;
-}
-
-
-static long asfreq_DtoQ(long fromDate, char relation, asfreq_info *af_info) {
-
-    int year, quarter;
-
-    if (DtoQ_yq(fromDate, af_info, &year, &quarter) == INT_ERR_CODE)
-    { return INT_ERR_CODE; }
-
-    return (long)((year - 1) * 4 + quarter);
-}
-
-static long asfreq_DtoM(long fromDate, char relation, asfreq_info *af_info) {
-
-    struct date_info dinfo;
-    if (dInfoCalc_SetFromAbsDate(&dinfo, fromDate,
-                    GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-    return (long)((dinfo.year - 1) * 12 + dinfo.month);
-}
-
-static long asfreq_DtoW(long fromDate, char relation, asfreq_info *af_info) {
-    return (fromDate - (1 + af_info->to_week_end))/7 + 1;
-}
-
-static long asfreq_DtoB(long fromDate, char relation, asfreq_info *af_info) {
-
-    struct date_info dinfo;
-    if (dInfoCalc_SetFromAbsDate(&dinfo, fromDate,
-                    GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-
-    if (relation == 'S') {
-        return DtoB_WeekendToFriday(dinfo.absdate, dinfo.day_of_week);
-    } else {
-        return DtoB_WeekendToMonday(dinfo.absdate, dinfo.day_of_week);
-    }
-}
-
-static long asfreq_DtoB_forConvert(long fromDate, char relation, asfreq_info *af_info) {
-
-    struct date_info dinfo;
-    if (dInfoCalc_SetFromAbsDate(&dinfo, fromDate,
-                    GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-
-    if (dinfo.day_of_week > 4) {
-        return -1;
-    } else {
-        return DtoB_weekday(fromDate);
-    }
-}
-
-// needed for getDateInfo function
-static long asfreq_DtoD(long fromDate, char relation, asfreq_info *af_info) { return fromDate; }
-
-static long asfreq_DtoHIGHFREQ(long fromDate, char relation, long periodsPerDay) {
-    if (fromDate >= HIGHFREQ_ORIG) {
-        if (relation == 'S') { return (fromDate - HIGHFREQ_ORIG)*(periodsPerDay) + 1; }
-        else                 { return (fromDate - HIGHFREQ_ORIG + 1)*(periodsPerDay); }
-    } else { return -1; }
-}
-
-static long asfreq_DtoH(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoHIGHFREQ(fromDate, relation, 24); }
-static long asfreq_DtoT(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoHIGHFREQ(fromDate, relation, 24*60); }
-static long asfreq_DtoS(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoHIGHFREQ(fromDate, relation, 24*60*60); }
-
-//************ FROM SECONDLY ***************
-
-static long asfreq_StoD(long fromDate, char relation, asfreq_info *af_info)
-    { return (fromDate - 1)/(60*60*24) + HIGHFREQ_ORIG; }
-
-static long asfreq_StoA(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoA(asfreq_StoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-static long asfreq_StoQ(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoQ(asfreq_StoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-static long asfreq_StoM(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoM(asfreq_StoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-static long asfreq_StoW(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoW(asfreq_StoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-static long asfreq_StoB(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoB(asfreq_StoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-static long asfreq_StoB_forConvert(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoB_forConvert(asfreq_StoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-static long asfreq_StoT(long fromDate, char relation, asfreq_info *af_info)
-    { return (fromDate - 1)/60 + 1; }
-static long asfreq_StoH(long fromDate, char relation, asfreq_info *af_info)
-    { return (fromDate - 1)/(60*60) + 1; }
-
-//************ FROM MINUTELY ***************
-
-static long asfreq_TtoD(long fromDate, char relation, asfreq_info *af_info)
-    { return (fromDate - 1)/(60*24) + HIGHFREQ_ORIG; }
-
-static long asfreq_TtoA(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoA(asfreq_TtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-static long asfreq_TtoQ(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoQ(asfreq_TtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-static long asfreq_TtoM(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoM(asfreq_TtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-static long asfreq_TtoW(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoW(asfreq_TtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-static long asfreq_TtoB(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoB(asfreq_TtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-
-static long asfreq_TtoB_forConvert(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoB_forConvert(asfreq_TtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-
-static long asfreq_TtoH(long fromDate, char relation, asfreq_info *af_info)
-    { return (fromDate - 1)/60 + 1; }
-static long asfreq_TtoS(long fromDate, char relation, asfreq_info *af_info) {
-    if (relation == 'S') {  return fromDate*60 - 59; }
-    else                 {  return fromDate*60;      }}
-
-//************ FROM HOURLY ***************
-
-static long asfreq_HtoD(long fromDate, char relation, asfreq_info *af_info)
-    { return (fromDate - 1)/24 + HIGHFREQ_ORIG; }
-static long asfreq_HtoA(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoA(asfreq_HtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-static long asfreq_HtoQ(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoQ(asfreq_HtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-static long asfreq_HtoM(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoM(asfreq_HtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-static long asfreq_HtoW(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoW(asfreq_HtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-static long asfreq_HtoB(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoB(asfreq_HtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-
-static long asfreq_HtoB_forConvert(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoB_forConvert(asfreq_HtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-
-// calculation works out the same as TtoS, so we just call that function for HtoT
-static long asfreq_HtoT(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_TtoS(fromDate, relation, &NULL_AF_INFO); }
-static long asfreq_HtoS(long fromDate, char relation, asfreq_info *af_info) {
-    if (relation == 'S') {  return fromDate*60*60 - 60*60 + 1; }
-    else                 {  return fromDate*60*60;             }}
-
-//************ FROM BUSINESS ***************
-
-static long asfreq_BtoD(long fromDate, char relation, asfreq_info *af_info)
-    { return ((fromDate-1)/5)*7 + (fromDate-1)%5 + 1; }
-
-static long asfreq_BtoA(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoA(asfreq_BtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-
-static long asfreq_BtoQ(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoQ(asfreq_BtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-
-static long asfreq_BtoM(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoM(asfreq_BtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-
-static long asfreq_BtoW(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoW(asfreq_BtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-
-static long asfreq_BtoH(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoH(asfreq_BtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-
-static long asfreq_BtoT(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoT(asfreq_BtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-
-static long asfreq_BtoS(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoS(asfreq_BtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-
-//************ FROM WEEKLY ***************
-
-static long asfreq_WtoD(long fromDate, char relation, asfreq_info *af_info) {
-    if (relation == 'S') { return fromDate * 7 - 6 + af_info->from_week_end;}
-    else                 { return fromDate * 7 + af_info->from_week_end; }
-}
-
-static long asfreq_WtoA(long fromDate, char relation, asfreq_info *af_info) {
-    return asfreq_DtoA(asfreq_WtoD(fromDate, 'E', af_info), relation, af_info); }
-static long asfreq_WtoQ(long fromDate, char relation, asfreq_info *af_info) {
-    return asfreq_DtoQ(asfreq_WtoD(fromDate, 'E', af_info), relation, af_info); }
-static long asfreq_WtoM(long fromDate, char relation, asfreq_info *af_info) {
-    return asfreq_DtoM(asfreq_WtoD(fromDate, 'E', af_info), relation, &NULL_AF_INFO); }
-
-static long asfreq_WtoW(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoW(asfreq_WtoD(fromDate, relation, af_info), relation, af_info); }
-
-static long asfreq_WtoB(long fromDate, char relation, asfreq_info *af_info) {
-
-    struct date_info dinfo;
-    if (dInfoCalc_SetFromAbsDate(&dinfo, asfreq_WtoD(fromDate, relation, af_info),
-                    GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-
-    if (relation == 'S') { return DtoB_WeekendToMonday(dinfo.absdate, dinfo.day_of_week); }
-    else                 { return DtoB_WeekendToFriday(dinfo.absdate, dinfo.day_of_week); }
-}
-
-static long asfreq_WtoH(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoH(asfreq_WtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-static long asfreq_WtoT(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoT(asfreq_WtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-static long asfreq_WtoS(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoS(asfreq_WtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-
-//************ FROM MONTHLY ***************
-
-static void MtoD_ym(long fromDate, long *y, long *m) {
-    *y = (fromDate - 1) / 12 + 1;
-    *m = fromDate - 12 * (*y) - 1;
-}
-
-static long asfreq_MtoD(long fromDate, char relation, asfreq_info *af_info) {
-
-    long y, m, absdate;
-
-    if (relation == 'S') {
-        MtoD_ym(fromDate, &y, &m);
-        if ((absdate = absdate_from_ymd(y, m, 1)) == INT_ERR_CODE) return INT_ERR_CODE;
-        return absdate;
-    } else {
-        MtoD_ym(fromDate+1, &y, &m);
-        if ((absdate = absdate_from_ymd(y, m, 1)) == INT_ERR_CODE) return INT_ERR_CODE;
-        return absdate-1;
-    }
-}
-
-static long asfreq_MtoA(long fromDate, char relation, asfreq_info *af_info) {
-    return asfreq_DtoA(asfreq_MtoD(fromDate, 'E', &NULL_AF_INFO), relation, af_info); }
-
-static long asfreq_MtoQ(long fromDate, char relation, asfreq_info *af_info) {
-    return asfreq_DtoQ(asfreq_MtoD(fromDate, 'E', &NULL_AF_INFO), relation, af_info); }
-
-static long asfreq_MtoW(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoW(asfreq_MtoD(fromDate, relation, &NULL_AF_INFO), relation, af_info); }
-
-static long asfreq_MtoB(long fromDate, char relation, asfreq_info *af_info) {
-
-    struct date_info dinfo;
-    if (dInfoCalc_SetFromAbsDate(&dinfo, asfreq_MtoD(fromDate, relation, &NULL_AF_INFO),
-                    GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-
-    if (relation == 'S') { return DtoB_WeekendToMonday(dinfo.absdate, dinfo.day_of_week); }
-    else                 { return DtoB_WeekendToFriday(dinfo.absdate, dinfo.day_of_week); }
-}
-
-static long asfreq_MtoH(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoH(asfreq_MtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-static long asfreq_MtoT(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoT(asfreq_MtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-static long asfreq_MtoS(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoS(asfreq_MtoD(fromDate, relation, &NULL_AF_INFO), relation, &NULL_AF_INFO); }
-
-//************ FROM QUARTERLY ***************
-
-static void QtoD_ym(long fromDate, long *y, long *m, asfreq_info *af_info) {
-
-    *y = (fromDate - 1) / 4 + 1;
-    *m = (fromDate + 4) * 3 - 12 * (*y) - 2;
-
-    if (af_info->from_q_year_end != 12) {
-        *m += af_info->from_q_year_end;
-        if (*m > 12) { *m -= 12; }
-        else { *y -= 1; }
-    }
-}
-
-static long asfreq_QtoD(long fromDate, char relation, asfreq_info *af_info) {
-
-    long y, m, absdate;
-
-    if (relation == 'S') {
-        QtoD_ym(fromDate, &y, &m, af_info);
-        if ((absdate = absdate_from_ymd(y, m, 1)) == INT_ERR_CODE) return INT_ERR_CODE;
-        return absdate;
-    } else {
-        QtoD_ym(fromDate+1, &y, &m, af_info);
-        if ((absdate = absdate_from_ymd(y, m, 1)) == INT_ERR_CODE) return INT_ERR_CODE;
-        return absdate - 1;
-    }
-}
-
-static long asfreq_QtoQ(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoQ(asfreq_QtoD(fromDate, relation, af_info), relation, af_info); }
-
-static long asfreq_QtoA(long fromDate, char relation, asfreq_info *af_info) {
-    return asfreq_DtoA(asfreq_QtoD(fromDate, relation, af_info), relation, af_info); }
-
-static long asfreq_QtoM(long fromDate, char relation, asfreq_info *af_info) {
-    return asfreq_DtoM(asfreq_QtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-
-static long asfreq_QtoW(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoW(asfreq_QtoD(fromDate, relation, af_info), relation, af_info); }
-
-static long asfreq_QtoB(long fromDate, char relation, asfreq_info *af_info) {
-
-    struct date_info dinfo;
-    if (dInfoCalc_SetFromAbsDate(&dinfo, asfreq_QtoD(fromDate, relation, af_info),
-                    GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-
-    if (relation == 'S') { return DtoB_WeekendToMonday(dinfo.absdate, dinfo.day_of_week); }
-    else                 { return DtoB_WeekendToFriday(dinfo.absdate, dinfo.day_of_week); }
-}
-
-
-static long asfreq_QtoH(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoH(asfreq_QtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-static long asfreq_QtoT(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoT(asfreq_QtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-static long asfreq_QtoS(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoS(asfreq_QtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-
-
-//************ FROM ANNUAL ***************
-
-static long asfreq_AtoD(long fromDate, char relation, asfreq_info *af_info) {
-    long absdate, year, final_adj;
-    int month = (af_info->from_a_year_end) % 12;
-
-    if (month == 0) { month = 1; }
-    else { month += 1; }
-
-    if (relation == 'S') {
-        if (af_info->from_a_year_end == 12) {year = fromDate;}
-        else {year = fromDate - 1;}
-        final_adj = 0;
-    } else {
-        if (af_info->from_a_year_end == 12) {year = fromDate+1;}
-        else {year = fromDate;}
-        final_adj = -1;
-    }
-    absdate = absdate_from_ymd(year, month, 1);
-    if (absdate  == INT_ERR_CODE) return INT_ERR_CODE;
-    return absdate + final_adj;
-}
-
-static long asfreq_AtoA(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoA(asfreq_AtoD(fromDate, relation, af_info), relation, af_info); }
-
-static long asfreq_AtoQ(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoQ(asfreq_AtoD(fromDate, relation, af_info), relation, af_info); }
-
-static long asfreq_AtoM(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoM(asfreq_AtoD(fromDate, relation, af_info), relation, af_info); }
-
-static long asfreq_AtoW(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoW(asfreq_AtoD(fromDate, relation, af_info), relation, af_info); }
-
-static long asfreq_AtoB(long fromDate, char relation, asfreq_info *af_info) {
-
-    struct date_info dinfo;
-    if (dInfoCalc_SetFromAbsDate(&dinfo, asfreq_AtoD(fromDate, relation, af_info),
-                    GREGORIAN_CALENDAR)) return INT_ERR_CODE;
-
-    if (relation == 'S') { return DtoB_WeekendToMonday(dinfo.absdate, dinfo.day_of_week); }
-    else                 { return DtoB_WeekendToFriday(dinfo.absdate, dinfo.day_of_week); }
-}
-
-static long asfreq_AtoH(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoH(asfreq_AtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-static long asfreq_AtoT(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoT(asfreq_AtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-static long asfreq_AtoS(long fromDate, char relation, asfreq_info *af_info)
-    { return asfreq_DtoS(asfreq_AtoD(fromDate, relation, af_info), relation, &NULL_AF_INFO); }
-
-static long nofunc(long fromDate, char relation, asfreq_info *af_info) { return -1; }
-
-// end of frequency specific conversion routines
-
-// return a pointer to appropriate conversion function
-long (*get_asfreq_func(int fromFreq, int toFreq, int forConvert))(long, char, asfreq_info*) {
-
-    int fromGroup = get_freq_group(fromFreq);
-    int toGroup = get_freq_group(toFreq);
-
-    if (fromGroup == FR_UND) { fromGroup = FR_DAY; }
-
-    switch(fromGroup)
-    {
-        case FR_ANN:
-            switch(toGroup)
-            {
-                case FR_ANN: return &asfreq_AtoA;
-                case FR_QTR: return &asfreq_AtoQ;
-                case FR_MTH: return &asfreq_AtoM;
-                case FR_WK: return &asfreq_AtoW;
-                case FR_BUS: return &asfreq_AtoB;
-                case FR_DAY: return &asfreq_AtoD;
-                case FR_HR: return &asfreq_AtoH;
-                case FR_MIN: return &asfreq_AtoT;
-                case FR_SEC: return &asfreq_AtoS;
-                default: return &nofunc;
-            }
-
-        case FR_QTR:
-            switch(toGroup)
-            {
-                case FR_ANN: return &asfreq_QtoA;
-                case FR_QTR: return &asfreq_QtoQ;
-                case FR_MTH: return &asfreq_QtoM;
-                case FR_WK: return &asfreq_QtoW;
-                case FR_BUS: return &asfreq_QtoB;
-                case FR_DAY: return &asfreq_QtoD;
-                case FR_HR: return &asfreq_QtoH;
-                case FR_MIN: return &asfreq_QtoT;
-                case FR_SEC: return &asfreq_QtoS;
-                default: return &nofunc;
-            }
-
-        case FR_MTH:
-            switch(toGroup)
-            {
-                case FR_ANN: return &asfreq_MtoA;
-                case FR_QTR: return &asfreq_MtoQ;
-                case FR_WK: return &asfreq_MtoW;
-                case FR_BUS: return &asfreq_MtoB;
-                case FR_DAY: return &asfreq_MtoD;
-                case FR_HR: return &asfreq_MtoH;
-                case FR_MIN: return &asfreq_MtoT;
-                case FR_SEC: return &asfreq_MtoS;
-                default: return &nofunc;
-            }
-
-        case FR_WK:
-            switch(toGroup)
-            {
-                case FR_ANN: return &asfreq_WtoA;
-                case FR_QTR: return &asfreq_WtoQ;
-                case FR_MTH: return &asfreq_WtoM;
-                case FR_WK: return &asfreq_WtoW;
-                case FR_BUS: return &asfreq_WtoB;
-                case FR_DAY: return &asfreq_WtoD;
-                case FR_HR: return &asfreq_WtoH;
-                case FR_MIN: return &asfreq_WtoT;
-                case FR_SEC: return &asfreq_WtoS;
-                default: return &nofunc;
-            }
-
-        case FR_BUS:
-            switch(toGroup)
-            {
-                case FR_ANN: return &asfreq_BtoA;
-                case FR_QTR: return &asfreq_BtoQ;
-                case FR_MTH: return &asfreq_BtoM;
-                case FR_WK: return &asfreq_BtoW;
-                case FR_DAY: return &asfreq_BtoD;
-                case FR_HR: return &asfreq_BtoH;
-                case FR_MIN: return &asfreq_BtoT;
-                case FR_SEC: return &asfreq_BtoS;
-                default: return &nofunc;
-            }
-
-        case FR_DAY:
-            switch(toGroup)
-            {
-                case FR_ANN: return &asfreq_DtoA;
-                case FR_QTR: return &asfreq_DtoQ;
-                case FR_MTH: return &asfreq_DtoM;
-                case FR_WK: return &asfreq_DtoW;
-                case FR_BUS:
-                    if (forConvert) { return &asfreq_DtoB_forConvert; }
-                    else            { return &asfreq_DtoB; }
-                case FR_DAY: return &asfreq_DtoD;
-                case FR_HR: return &asfreq_DtoH;
-                case FR_MIN: return &asfreq_DtoT;
-                case FR_SEC: return &asfreq_DtoS;
-                default: return &nofunc;
-            }
-
-        case FR_HR:
-            switch(toGroup)
-            {
-                case FR_ANN: return &asfreq_HtoA;
-                case FR_QTR: return &asfreq_HtoQ;
-                case FR_MTH: return &asfreq_HtoM;
-                case FR_WK: return &asfreq_HtoW;
-                case FR_BUS:
-                    if (forConvert) { return &asfreq_HtoB_forConvert; }
-                    else            { return &asfreq_HtoB; }
-                case FR_DAY: return &asfreq_HtoD;
-                case FR_MIN: return &asfreq_HtoT;
-                case FR_SEC: return &asfreq_HtoS;
-                default: return &nofunc;
-            }
-
-        case FR_MIN:
-            switch(toGroup)
-            {
-                case FR_ANN: return &asfreq_TtoA;
-                case FR_QTR: return &asfreq_TtoQ;
-                case FR_MTH: return &asfreq_TtoM;
-                case FR_WK: return &asfreq_TtoW;
-                case FR_BUS:
-                    if (forConvert) { return &asfreq_TtoB_forConvert; }
-                    else            { return &asfreq_TtoB; }
-                case FR_DAY: return &asfreq_TtoD;
-                case FR_HR: return &asfreq_TtoH;
-                case FR_SEC: return &asfreq_TtoS;
-                default: return &nofunc;
-            }
-
-        case FR_SEC:
-            switch(toGroup)
-            {
-                case FR_ANN: return &asfreq_StoA;
-                case FR_QTR: return &asfreq_StoQ;
-                case FR_MTH: return &asfreq_StoM;
-                case FR_WK: return &asfreq_StoW;
-                case FR_BUS:
-                    if (forConvert) { return &asfreq_StoB_forConvert; }
-                    else            { return &asfreq_StoB; }
-                case FR_DAY: return &asfreq_StoD;
-                case FR_HR: return &asfreq_StoH;
-                case FR_MIN: return &asfreq_StoT;
-                default: return &nofunc;
-            }
-        default: return &nofunc;
-    }
-}
-
-static int calc_a_year_end(int freq, int group) {
-    int result = (freq - group) % 12;
-    if (result == 0) {return 12;}
-    else {return result;}
-}
-
-static int calc_week_end(int freq, int group) {
-    return freq - group;
-}
-
-void get_asfreq_info(int fromFreq, int toFreq, asfreq_info *af_info) {
-
-    int fromGroup = get_freq_group(fromFreq);
-    int toGroup = get_freq_group(toFreq);
-
-    switch(fromGroup)
-    {
-        case FR_WK: {
-            af_info->from_week_end = calc_week_end(fromFreq, fromGroup);
-        } break;
-        case FR_ANN: {
-            af_info->from_a_year_end = calc_a_year_end(fromFreq, fromGroup);
-        } break;
-        case FR_QTR: {
-            af_info->from_q_year_end = calc_a_year_end(fromFreq, fromGroup);
-        } break;
-
-    }
-
-    switch(toGroup)
-    {
-        case FR_WK: {
-            af_info->to_week_end = calc_week_end(toFreq, toGroup);
-        } break;
-        case FR_ANN: {
-            af_info->to_a_year_end = calc_a_year_end(toFreq, toGroup);
-        } break;
-        case FR_QTR: {
-            af_info->to_q_year_end = calc_a_year_end(toFreq, toGroup);
-        } break;
-    }
-
-}
-
-static double getAbsTime(int freq, long dailyDate, long originalDate) {
-
-    long startOfDay, periodsPerDay;
-
-    switch(freq)
-    {
-        case FR_HR:
-            periodsPerDay = 24;
-            break;
-        case FR_MIN:
-            periodsPerDay = 24*60;
-            break;
-        case FR_SEC:
-            periodsPerDay = 24*60*60;
-            break;
-        default:
-            return 24*60*60 - 1;
-    }
-
-    startOfDay = asfreq_DtoHIGHFREQ(dailyDate, 'S', periodsPerDay);
-    return (24*60*60)*((double)(originalDate - startOfDay))/((double)periodsPerDay);
-}
-
-/************************************************************
-** Date type definition
-************************************************************/
-
-typedef struct {
-    PyObject_HEAD
-    int freq; /* frequency of date */
-    long value; /* integer representation of date */
-    PyObject* cached_vals;
-} DateObject;
-
-/* Forward declarations */
-static PyTypeObject DateType;
-#define DateObject_Check(op) PyObject_TypeCheck(op, &DateType)
-
-static void
-DateObject_dealloc(DateObject* self) {
-    Py_XDECREF(self->cached_vals);
-    self->ob_type->tp_free((PyObject*)self);
-}
-
-
-static PyObject *freq_dict, *freq_dict_rev, *freq_constants;
-
-#define DICT_SETINT_STRKEY(dict, key, val) \
-    {PyObject *pyval = PyInt_FromLong(val); \
-     PyDict_SetItemString(dict, key, pyval); \
-     Py_DECREF(pyval); }
-
-#define ADD_FREQ_CONSTANT(const_name, val) \
-    DICT_SETINT_STRKEY(freq_constants, const_name, val)
-
-#define INIT_FREQ(const_name, key, aliases) \
-    {PyObject *pykey = PyInt_FromLong(key); \
-     PyDict_SetItem(freq_dict, pykey, aliases); \
-     PyDict_SetItemString(freq_constants, const_name, pykey); \
-     Py_DECREF(pykey); \
-     Py_DECREF(aliases); }
-
-
-static int init_freq_group(int num_items, int num_roots, int base_const,
-                            char item_abbrevs[][2][10], char group_prefixes[][15],
-                            char item_const_names[][15]) {
-
-    int i;
-
-    for (i = 0; i < num_items; i++) {
-
-        PyObject *aliases;
-        int j, size, k;
-
-        if (i == 0) { k = 3; } else { k = 2; }
-
-        size = num_roots * k;
-
-        aliases = PyTuple_New(size);
-
-        for (j = 0; j < num_roots; j++) {
-            PyObject *alias_v1, *alias_v2;
-            char *root, *alt;
-
-            if ((root = PyArray_malloc((30) * sizeof(char))) == NULL) return INT_ERR_CODE;
-            if ((alt = PyArray_malloc((30) * sizeof(char))) == NULL) return INT_ERR_CODE;
-
-            strcpy(root, group_prefixes[j]);
-            strcpy(alt, group_prefixes[j]);
-
-            if (i == 0) {
-                PyObject *alias = PyString_FromString(root);
-                PyTuple_SET_ITEM(aliases, j*k + 2, alias);
-            }
-
-            strcat(root, "-");
-            strcat(root, item_abbrevs[i][0]);
-            strcat(alt, "-");
-            strcat(alt, item_abbrevs[i][1]);
-
-            alias_v1 = PyString_FromString(root);
-            alias_v2 = PyString_FromString(alt);
-
-            free(root);
-            free(alt);
-
-            PyTuple_SET_ITEM(aliases, j*k, alias_v1);
-            PyTuple_SET_ITEM(aliases, j*k + 1, alias_v2);
-        }
-
-        INIT_FREQ(item_const_names[i], base_const+i, aliases);
-    }
-
-    return 0;
-}
-
-/* take a dictionary with integer keys and tuples of strings for values,
-   and populate a dictionary with all the strings as keys and integers
-   for values */
-static int reverse_dict(PyObject *source, PyObject *dest) {
-
-    PyObject *key, *value;
-
-    Py_ssize_t pos = 0;
-
-    while (PyDict_Next(source, &pos, &key, &value)) {
-        PyObject *tuple_iter;
-        PyObject *item;
-
-        if((tuple_iter = PyObject_GetIter(value)) == NULL) return INT_ERR_CODE;
-
-        while ((item = PyIter_Next(tuple_iter)) != NULL) {
-            PyDict_SetItem(dest, item, key);
-            Py_DECREF(item);
-        }
-        Py_DECREF(tuple_iter);
-    }
-    return 0;
-}
-
-static int build_freq_dict(void) {
-
-    char ANN_prefixes[8][15] = { "A", "Y", "ANN", "ANNUAL", "ANNUALLY",
-                                 "YR", "YEAR", "YEARLY" };
-
-    char QTRE_prefixes[8][15] = { "Q", "QTR", "QUARTER", "QUARTERLY", "Q-E",
-                                  "QTR-E", "QUARTER-E", "QUARTERLY-E"};
-    char QTRS_prefixes[4][15] = { "Q-S", "QTR-S", "QUARTER-S", "QUARTERLY-S" };
-
-    char WK_prefixes[4][15] =  { "W", "WK", "WEEK", "WEEKLY" };
-
-    /* Note: order of this array must match up with how the Annual
-       frequency constants are lined up */
-    char month_names[12][2][10] = {
-        { "DEC", "DECEMBER" },
-        { "JAN", "JANUARY" },
-        { "FEB", "FEBRUARY" },
-        { "MAR", "MARCH" },
-        { "APR", "APRIL" },
-        { "MAY", "MAY" },
-        { "JUN", "JUNE" },
-        { "JUL", "JULY" },
-        { "AUG", "AUGUST" },
-        { "SEP", "SEPTEMBER" },
-        { "OCT", "OCTOBER" },
-        { "NOV", "NOVEMBER" }};
-
-    char day_names[7][2][10] = {
-        { "SUN", "SUNDAY" },
-        { "MON", "MONDAY" },
-        { "TUE", "TUESDAY" },
-        { "WED", "WEDNESDAY" },
-        { "THU", "THURSDAY" },
-        { "FRI", "FRIDAY" },
-        { "SAT", "SATURDAY" }};
-
-    char ANN_const_names[12][15] = {
-        "FR_ANNDEC",
-        "FR_ANNJAN",
-        "FR_ANNFEB",
-        "FR_ANNMAR",
-        "FR_ANNAPR",
-        "FR_ANNMAY",
-        "FR_ANNJUN",
-        "FR_ANNJUL",
-        "FR_ANNAUG",
-        "FR_ANNSEP",
-        "FR_ANNOCT",
-        "FR_ANNNOV"};
-
-    char QTRE_const_names[12][15] = {
-        "FR_QTREDEC",
-        "FR_QTREJAN",
-        "FR_QTREFEB",
-        "FR_QTREMAR",
-        "FR_QTREAPR",
-        "FR_QTREMAY",
-        "FR_QTREJUN",
-        "FR_QTREJUL",
-        "FR_QTREAUG",
-        "FR_QTRESEP",
-        "FR_QTREOCT",
-        "FR_QTRENOV"};
-
-    char QTRS_const_names[12][15] = {
-        "FR_QTRSDEC",
-        "FR_QTRSJAN",
-        "FR_QTRSFEB",
-        "FR_QTRSMAR",
-        "FR_QTRSAPR",
-        "FR_QTRSMAY",
-        "FR_QTRSJUN",
-        "FR_QTRSJUL",
-        "FR_QTRSAUG",
-        "FR_QTRSSEP",
-        "FR_QTRSOCT",
-        "FR_QTRSNOV"};
-
-    char WK_const_names[7][15] = {
-        "FR_WKSUN",
-        "FR_WKMON",
-        "FR_WKTUE",
-        "FR_WKWED",
-        "FR_WKTHU",
-        "FR_WKFRI",
-        "FR_WKSAT"};
-
-    PyObject *aliases;
-
-    freq_dict = PyDict_New();
-    freq_dict_rev = PyDict_New();
-    freq_constants = PyDict_New();
-
-    aliases = Py_BuildValue("(ssss)", "M", "MTH", "MONTH", "MONTHLY");
-    INIT_FREQ("FR_MTH", FR_MTH, aliases);
-
-    aliases = Py_BuildValue("(ssss)", "B", "BUS", "BUSINESS", "BUSINESSLY");
-    INIT_FREQ("FR_BUS", FR_BUS, aliases);
-
-    aliases = Py_BuildValue("(ssss)", "D", "DAY", "DLY", "DAILY");
-    INIT_FREQ("FR_DAY", FR_DAY, aliases);
-
-    aliases = Py_BuildValue("(sssss)", "H", "HR", "HOUR", "HRLY", "HOURLY");
-    INIT_FREQ("FR_HR", FR_HR, aliases);
-
-    aliases = Py_BuildValue("(ssss)", "T", "MIN", "MINUTE", "MINUTELY");
-    INIT_FREQ("FR_MIN", FR_MIN, aliases);
-
-    aliases = Py_BuildValue("(ssss)", "S", "SEC", "SECOND", "SECONDLY");
-    INIT_FREQ("FR_SEC", FR_SEC, aliases);
-
-    aliases = Py_BuildValue("(ssss)", "U", "UND", "UNDEF", "UNDEFINED");
-    INIT_FREQ("FR_UND", FR_UND, aliases);
-
-    ADD_FREQ_CONSTANT("FR_ANN", FR_ANN);
-
-    if(init_freq_group(12, 8, FR_ANN,
-        month_names, ANN_prefixes, ANN_const_names) == INT_ERR_CODE) {
-            return INT_ERR_CODE;
-    }
-
-    ADD_FREQ_CONSTANT("FR_QTR", FR_QTR);
-
-    if(init_freq_group(12, 8, FR_QTREDEC,
-        month_names, QTRE_prefixes, QTRE_const_names) == INT_ERR_CODE) {
-            return INT_ERR_CODE;
-    }
-
-    if(init_freq_group(12, 4, FR_QTRSDEC,
-        month_names, QTRS_prefixes, QTRS_const_names) == INT_ERR_CODE) {
-            return INT_ERR_CODE;
-    }
-
-    ADD_FREQ_CONSTANT("FR_WK", FR_WK);
-
-    if(init_freq_group(7, 4, FR_WK,
-                    day_names, WK_prefixes, WK_const_names) == INT_ERR_CODE) {
-            return INT_ERR_CODE;
-    }
-
-    if(reverse_dict(freq_dict, freq_dict_rev) == INT_ERR_CODE) {
-        return INT_ERR_CODE;
-    }
-
-    return 0;
-}
-
-
-/* take user specified frequency and convert to int representation
-   of the frequency */
-int check_freq(PyObject *freq_spec) {
-
-    if (PyInt_Check(freq_spec)) {
-        return (int)PyInt_AsLong(freq_spec);
-    } else if (PyString_Check(freq_spec)) {
-        char *freq_str, *freq_str_uc;
-        PyObject *freq_val;
-
-        freq_str = PyString_AsString(freq_spec);
-        if((freq_str_uc = str_uppercase(freq_str)) == NULL) {return INT_ERR_CODE;}
-
-        freq_val = PyDict_GetItemString(freq_dict_rev, freq_str_uc);
-
-        free(freq_str_uc);
-
-        if (freq_val == NULL) {
-            PyErr_SetString(PyExc_ValueError, "invalid frequency specification");
-            return INT_ERR_CODE;
-        } else {
-            int ret_val = (int)PyInt_AsLong(freq_val);
-            return ret_val;
-        }
-    } else if (freq_spec == Py_None) {
-        return FR_UND;
-    } else {
-        int retval = (int)PyInt_AsLong(freq_spec);
-        if (PyErr_Occurred()) {
-            PyErr_SetString(PyExc_ValueError, "invalid frequency specification");
-            return INT_ERR_CODE;
-        } else { return retval; }
-    }
-
-}
-
-static PyObject *
-DateObject_new(PyTypeObject *type, PyObject *args, PyObject *kwds) {
-
-    DateObject *self;
-
-    self = (DateObject*)type->tp_alloc(type, 0);
-    if (self != NULL) {
-        // initialize attributes that need initializing in here
-        self->freq = FR_UND;
-        self->value = -1;
-    }
-
-    return (PyObject *)self;
-}
-
-/* for use in C code */
-static DateObject *
-DateObject_New(void) {
-    PyObject *dummy;
-    return (DateObject*)DateObject_new(&DateType, dummy, dummy);
-}
-
-#define INIT_ERR(errortype, errmsg) PyErr_SetString(errortype,errmsg);return -1
-
-static int
-DateObject_init(DateObject *self, PyObject *args, PyObject *kwds) {
-
-    PyObject *freq=NULL, *value=NULL, *datetime=NULL, *string=NULL;
-    char *INSUFFICIENT_MSG = "insufficient parameters to initialize Date";
-
-    int def_info=INT_ERR_CODE;
-
-    int year=def_info, month=def_info, day=def_info, quarter=def_info,
-        hour=def_info, minute=def_info, second=def_info;
-
-    int free_dt=0;
-
-    static char *kwlist[] = {"freq", "value", "string",
-                             "year", "month", "day", "quarter",
-                             "hour", "minute", "second",
-                             "datetime", NULL};
-
-    if (! PyArg_ParseTupleAndKeywords(args, kwds, "O|OOiiiiiiiO", kwlist,
-                                      &freq, &value, &string,
-                                      &year, &month, &day, &quarter,
-                                      &hour, &minute, &second,
-                                      &datetime)) {
-        return -1;
-    }
-
-    if (PyObject_HasAttrString(freq, "freq")) {
-        PyObject *freq_attr = PyObject_GetAttrString(freq, "freq");
-        self->freq = PyInt_AS_LONG(freq_attr);
-        Py_DECREF(freq_attr);
-    } else {
-        if((self->freq = check_freq(freq)) == INT_ERR_CODE) return -1;
-    }
-
-    if ((value && PyString_Check(value)) || string) {
-
-        PyObject *string_arg = PyTuple_New(1);
-        int freq_group = get_freq_group(self->freq);
-
-        free_dt = 1;
-
-        if (!string) {
-            string = value;
-        }
-
-        PyTuple_SET_ITEM(string_arg, 0, string);
-        Py_INCREF(string);
-
-        if (freq_group == FR_HR ||
-            freq_group == FR_MIN ||
-            freq_group == FR_SEC)
-             { datetime = PyEval_CallObject(DateTimeFromString, string_arg); }
-        else { datetime = PyEval_CallObject(DateFromString, string_arg); }
-
-        Py_DECREF(string_arg);
-
-        value = NULL;
-    }
-
-    if (value && (PyDateTime_Check(value) || PyDate_Check(value))) {
-        if (!datetime) {
-            datetime = value;
-        }
-        value = NULL;
-    } // datetime = (datetime||value), value = NULL
-
-
-    if (value) {
-        self->value = PyInt_AsLong(value);
-    } else {
-
-        int freq_group = get_freq_group(self->freq);
-
-        if (datetime) {
-            if (PyDateTime_Check(datetime) || PyDate_Check(datetime)) {
-                year=PyDateTime_GET_YEAR(datetime);
-                month=PyDateTime_GET_MONTH(datetime);
-                quarter=((month-1)/3)+1;
-                day=PyDateTime_GET_DAY(datetime);
-                hour=PyDateTime_DATE_GET_HOUR(datetime);
-                minute=PyDateTime_DATE_GET_MINUTE(datetime);
-                second=PyDateTime_DATE_GET_SECOND(datetime);
-            } else {
-                PyObject *err_msg, *_type;
-                _type = PyObject_Type(datetime);
-                err_msg = PyString_FromString("Expected datetime object, received: ");
-                PyString_ConcatAndDel(&err_msg, PyObject_Str(_type));
-                PyErr_SetString(PyExc_TypeError, PyString_AsString(err_msg));
-                Py_DECREF(_type);
-                Py_DECREF(err_msg);
-                return -1;
-            }
-        }
-
-        if (!datetime) {
-
-            // First, some basic checks.....
-            if (year == def_info) {
-                INIT_ERR(PyExc_ValueError, INSUFFICIENT_MSG);
-            }
-            if (self->freq == FR_BUS ||
-               self->freq == FR_DAY ||
-               self->freq == FR_WK ||
-               self->freq == FR_UND) {
-                if (month == def_info || day == def_info) {
-                    INIT_ERR(PyExc_ValueError, INSUFFICIENT_MSG);
-                }
-
-                // if FR_BUS, check for week day
-
-            } else if (self->freq == FR_MTH) {
-                if (month == def_info) {
-                    INIT_ERR(PyExc_ValueError, INSUFFICIENT_MSG);
-                }
-            } else if (freq_group == FR_QTR) {
-                if (quarter == def_info) {
-                    INIT_ERR(PyExc_ValueError, INSUFFICIENT_MSG);
-                }
-            } else if (self->freq == FR_SEC) {
-                if (month == def_info ||
-                    day == def_info ||
-                    second == def_info) {
-                    INIT_ERR(PyExc_ValueError, INSUFFICIENT_MSG);
-                }
-                if (hour == def_info) {
-                    hour = second/3600;
-                    minute = (second % 3600)/60;
-                    second = second % 60;
-                } else if (minute == def_info) {
-                    INIT_ERR(PyExc_ValueError, INSUFFICIENT_MSG);
-                }
-            } else if (self->freq == FR_MIN) {
-                if (month == def_info ||
-                    day == def_info ||
-                    minute == def_info) {
-                    INIT_ERR(PyExc_ValueError, INSUFFICIENT_MSG);
-                }
-                if (hour == def_info) {
-                    hour = minute/60;
-                    minute = minute % 60;
-                }
-            } else if (self->freq == FR_HR) {
-                if (month == def_info ||
-                    day == def_info ||
-                    hour == def_info) {
-                    INIT_ERR(PyExc_ValueError, INSUFFICIENT_MSG);
-                }
-            }
-
-        }
-
-        if (self->freq == FR_SEC) {
-            long absdays, delta;
-            absdays = absdate_from_ymd(year, month, day);
-            delta = (absdays - HIGHFREQ_ORIG);
-            self->value = (int)(delta*86400 + hour*3600 + minute*60 + second + 1);
-        } else if (self->freq == FR_MIN) {
-            long absdays, delta;
-            absdays = absdate_from_ymd(year, month, day);
-            delta = (absdays - HIGHFREQ_ORIG);
-            self->value = (int)(delta*1440 + hour*60 + minute + 1);
-        } else if (self->freq == FR_HR) {
-            long absdays, delta;
-            if((absdays = absdate_from_ymd(year, month, day)) == INT_ERR_CODE) return -1;
-            delta = (absdays - HIGHFREQ_ORIG);
-            self->value = (int)(delta*24 + hour + 1);
-        } else if (self->freq == FR_DAY) {
-            if((self->value = (int)absdate_from_ymd(year, month, day)) == INT_ERR_CODE) return -1;
-        } else if (self->freq == FR_UND) {
-            if((self->value = (int)absdate_from_ymd(year, month, day)) == INT_ERR_CODE) return -1;
-        } else if (self->freq == FR_BUS) {
-            long weeks, days;
-            if((days = absdate_from_ymd(year, month, day)) == INT_ERR_CODE) return -1;
-            weeks = days/7;
-            self->value = (int)(days - weeks*2);
-        } else if (freq_group == FR_WK) {
-            int adj_ordinal, ordinal, day_adj;
-            if((ordinal = (int)absdate_from_ymd(year, month, day)) == INT_ERR_CODE) return -1;
-            day_adj = (7 - (self->freq - FR_WK)) % 7;
-            adj_ordinal = ordinal + ((7 - day_adj) - ordinal % 7) % 7;
-            self->value = adj_ordinal/7;
-        } else if (self->freq == FR_MTH) {
-            self->value = (year-1)*12 + month;
-        } else if (freq_group == FR_QTR) {
-            if ((self->freq - freq_group) > 12) {
-                // quarterly frequency with year determined by ending period
-                self->value = year*4 + quarter;
-            } else {
-                /* quarterly frequency with year determined by ending period
-                   or has December year end*/
-                self->value = (year-1)*4 + quarter;
-            }
-        } else if (freq_group == FR_ANN) {
-            self->value = year;
-        }
-
-    }
-
-    if (free_dt) { Py_DECREF(datetime); }
-
-    return 0;
-}
-
-static PyMemberDef DateObject_members[] = {
-    {"freq", T_INT, offsetof(DateObject, freq), 0,
-     "frequency"},
-    {"value", T_INT, offsetof(DateObject, value), 0,
-     "integer representation of the Date"},
-    {NULL}  /* Sentinel */
-};
-
-static char DateObject_toordinal_doc[] =
-"Returns the proleptic Gregorian ordinal of the date, as an integer.\n"
-"This corresponds to the number of days since Jan., 1st, 1AD.\n\n"
-"When the instance has a frequency less than daily, the proleptic date \n"
-"is calculated for the last day of the period.\n\n"
-"   >>> ts.Date('D', '2001-01-01').toordinal()\n"
-"   730486\n"
-"   >>> ts.Date('H', '2001-01-01 18:00').toordinal()\n"
-"   730486\n"
-"   >>> ts.Date('M', '2001-01-01').toordinal()\n"
-"   730516\n"
-"   >>> # Note that 730516 = 730486 + 31 - 1\n"
-"   >>> ts.Date('Y', '2001-01-01').toordinal()\n"
-"   730850\n"
-"   >>> # Note that 730850 = 730486 + 365 - 1\n";
-
-static PyObject *
-DateObject_toordinal(DateObject* self)
-{
-    if (self->freq == FR_DAY) {
-        return PyInt_FromLong(self->value);
-    } else {
-        long (*toDaily)(long, char, asfreq_info*) = NULL;
-        asfreq_info af_info;
-
-        toDaily = get_asfreq_func(self->freq, FR_DAY, 0);
-        get_asfreq_info(self->freq, FR_DAY, &af_info);
-
-        return PyInt_FromLong(toDaily(self->value, 'E', &af_info));
-    }
-}
-
-static char DateObject_asfreq_doc[] =
-"   asfreq(freq, relation='END')\n"
-"\n"
-"   Returns a :class:`Date` object converted to a specified frequency.\n"
-"\n"
-"   :Parameters:\n"
-"\n"
-"      **freq** : {string, integer}\n"
-"         Frequency to convert the instance to. Accepts any valid frequency\n"
-"         specification (string or integer).\n"
-"\n"
-"      **relation** : {'END', 'START'} (optional)\n"
-"         Applies only when converting a :class:`Date` to a higher frequency,\n"
-"         or when converting a weekend Date to a business frequency Date.\n"
-"         Valid values are 'START' and 'END'.\n"
-"         For example, when converting a monthly :class:`Date` to the daily\n"
-"         frequency, ``relation='START'`` gives the first day of the month\n"
-"         while ``relation='END'`` gives the last day of the month.\n"
-"\n"
-"   .. warning::\n"
-"\n"
-"      Some information will be lost when a :class:`Date` is converted to \n"
-"      a lower frequency and then back to the original one.\n"
-"      For example, if a daily :class:`Date` is converted to monthly and \n"
-"      then back to a daily one, the :attr:`day` information is lost::\n"
-"\n"
-"         >>> D = ts.Date('D', year=2007, month=12, day=15)\n"
-"         >>> D.asfreq('M')\n"
-"         <M: Dec-2007>\n"
-"         >>> D.asfreq('M').asfreq('D', relation='START')\n"
-"         <D: 01-Dec-2007>\n"
-"         >>> D.asfreq('M').asfreq('D', relation=\"END\")\n"
-"         <D: 31-Dec-2007>\n"
-"\n";
-
-static PyObject *
-DateObject_asfreq(DateObject *self, PyObject *args, PyObject *kwds)
-{
-
-    PyObject *freq=NULL;
-    char *relation_raw=NULL;
-    char *relation_uc;
-    char relation;
-    int invalid_relation=0;
-    int toFreq;
-    int result_val;
-    DateObject *result = DateObject_New();
-
-    static char *kwlist[] = {"freq", "relation", NULL};
-
-    long (*asfreq_func)(long, char, asfreq_info*) = NULL;
-    asfreq_info af_info;
-
-    if (! PyArg_ParseTupleAndKeywords(args, kwds, "O|s", kwlist,
-                                      &freq, &relation_raw)) return NULL;
-
-    if(relation_raw) {
-        if (strlen(relation_raw) > 0) {
-            if((relation_uc = str_uppercase(relation_raw)) == NULL)
-            {return PyErr_NoMemory();}
-
-            // 'BEFORE' and 'AFTER' values for this parameter are deprecated
-            if (strcmp(relation_uc, "END") == 0 ||
-                strcmp(relation_uc, "E") == 0 ||
-                strcmp(relation_uc, "START") == 0 ||
-                strcmp(relation_uc, "S") == 0 ||
-                strcmp(relation_uc, "BEFORE") == 0 ||
-                strcmp(relation_uc, "B") == 0 ||
-                strcmp(relation_uc, "AFTER") == 0 ||
-                strcmp(relation_uc, "A") == 0) {
-                 if(relation_uc[0] == 'E' || relation_uc[0] == 'A') { relation = 'E'; }
-                 else { relation = 'S'; }
-
-            } else { invalid_relation=1; }
-
-            free(relation_uc);
-
-        } else {
-            invalid_relation=1;
-        }
-
-        if (invalid_relation) {
-            PyErr_SetString(PyExc_ValueError,"Invalid relation specification");
-            return NULL;
-        }
-    } else {
-        relation = 'E';
-    }
-
-    if ((toFreq = check_freq(freq)) == INT_ERR_CODE) return NULL;
-
-    if (toFreq == self->freq) {
-        result->freq = self->freq;
-        result->value = self->value;
-        return (PyObject*)result;
-    }
-
-    get_asfreq_info(self->freq, toFreq, &af_info);
-    asfreq_func = get_asfreq_func(self->freq, toFreq, 0);
-
-    result_val = asfreq_func(self->value, relation, &af_info);
-
-    if (result_val == INT_ERR_CODE) return NULL;
-
-    result->freq = toFreq;
-    result->value = result_val;
-
-    return (PyObject*)result;
-
-}
-
-static char DateObject_strfmt_doc[] =
-"Deprecated alias for strftime method";
-
-static char DateObject_strftime_doc[] =
-"\n"
-"   Returns the string representation of the :class:`Date`, \n"
-"   depending on the selected :keyword:`format`.\n"
-"   :keyword:`format` must be a string containing one or several directives.\n"
-"   The method recognizes the same directives as the :func:`time.strftime` \n"
-"   function of the standard Python distribution, as well as the specific \n"
-"   additional directives ``%f``, ``%F``, ``%q``.\n"
-"\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | Directive | Meaning                        | Notes |\n"
-"   +===========+================================+=======+\n"
-"   | ``%a``    | Locale's abbreviated weekday   |       |\n"
-"   |           | name.                          |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%A``    | Locale's full weekday name.    |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%b``    | Locale's abbreviated month     |       |\n"
-"   |           | name.                          |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%B``    | Locale's full month name.      |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%c``    | Locale's appropriate date and  |       |\n"
-"   |           | time representation.           |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%d``    | Day of the month as a decimal  |       |\n"
-"   |           | number [01,31].                |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%f``    | 'Fiscal' year without a        | \(1)  |\n"
-"   |           | century  as a decimal number   |       |\n"
-"   |           | [00,99]                        |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%F``    | 'Fiscal' year with a century   | \(2)  |\n"
-"   |           | as a decimal number            |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%H``    | Hour (24-hour clock) as a      |       |\n"
-"   |           | decimal number [00,23].        |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%I``    | Hour (12-hour clock) as a      |       |\n"
-"   |           | decimal number [01,12].        |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%j``    | Day of the year as a decimal   |       |\n"
-"   |           | number [001,366].              |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%m``    | Month as a decimal number      |       |\n"
-"   |           | [01,12].                       |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%M``    | Minute as a decimal number     |       |\n"
-"   |           | [00,59].                       |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%p``    | Locale's equivalent of either  | \(3)  |\n"
-"   |           | AM or PM.                      |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%q``    | Quarter as a decimal number    |       |\n"
-"   |           | [01,04]                        |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%S``    | Second as a decimal number     | \(4)  |\n"
-"   |           | [00,61].                       |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%U``    | Week number of the year        | \(5)  |\n"
-"   |           | (Sunday as the first day of    |       |\n"
-"   |           | the week) as a decimal number  |       |\n"
-"   |           | [00,53].  All days in a new    |       |\n"
-"   |           | year preceding the first       |       |\n"
-"   |           | Sunday are considered to be in |       |\n"
-"   |           | week 0.                        |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%w``    | Weekday as a decimal number    |       |\n"
-"   |           | [0(Sunday),6].                 |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%W``    | Week number of the year        | \(5)  |\n"
-"   |           | (Monday as the first day of    |       |\n"
-"   |           | the week) as a decimal number  |       |\n"
-"   |           | [00,53].  All days in a new    |       |\n"
-"   |           | year preceding the first       |       |\n"
-"   |           | Monday are considered to be in |       |\n"
-"   |           | week 0.                        |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%x``    | Locale's appropriate date      |       |\n"
-"   |           | representation.                |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%X``    | Locale's appropriate time      |       |\n"
-"   |           | representation.                |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%y``    | Year without century as a      |       |\n"
-"   |           | decimal number [00,99].        |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%Y``    | Year with century as a decimal |       |\n"
-"   |           | number.                        |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%Z``    | Time zone name (no characters  |       |\n"
-"   |           | if no time zone exists).       |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"   | ``%%``    | A literal ``'%'`` character.   |       |\n"
-"   +-----------+--------------------------------+-------+\n"
-"\n"
-"   .. note::\n"
-"\n"
-"      (1)\n"
-"         The ``%f`` directive is the same as ``%y`` if the frequency is \n"
-"         not quarterly.\n"
-"         Otherwise, it corresponds to the 'fiscal' year, as defined by \n"
-"         the :attr:`qyear` attribute.\n"
-"\n"
-"      (2)\n"
-"         The ``%F`` directive is the same as ``%Y`` if the frequency is \n"
-"         not quarterly.\n"
-"         Otherwise, it corresponds to the 'fiscal' year, as defined by \n"
-"         the :attr:`qyear` attribute.\n"
-"\n"
-"      (3)\n"
-"         The ``%p`` directive only affects the output hour field \n"
-"         if the ``%I`` directive is used to parse the hour.\n"
-"\n"
-"      (4)\n"
-"         The range really is ``0`` to ``61``; this accounts for leap seconds \n"
-"         and the (very rare) double leap seconds.\n"
-"\n"
-"      (5)\n"
-"         The ``%U`` and ``%W`` directives are only used in calculations \n"
-"         when the day of the week and the year are specified.\n"
-"\n"
-"\n"
-"   .. rubric::  Examples\n"
-"\n"
-"   >>> a = ts.Date(freq='q-jul', year=2006, quarter=1)\n"
-"   >>> a.strftime('%F-Q%q')\n"
-"   '2006-Q1'\n"
-"   >>> # Output the last month in the quarter of this date\n"
-"   >>> a.strftime('%b-%Y')\n"
-"   'Oct-2005'\n"
-"   >>> \n"
-"   >>> a = ts.Date(freq='d', year=2001, month=1, day=1)\n"
-"   >>> a.strftime('%d-%b-%Y')\n"
-"   '01-Jan-2006'\n"
-"   >>> a.strftime('%b. %d, %Y was a %A')\n"
-"   'Jan. 01, 2001 was a Monday'\n";
-static PyObject *
-DateObject_strftime(DateObject *self, PyObject *args)
-{
-
-    char *orig_fmt_str, *fmt_str;
-    char *result;
-
-    int num_extra_fmts = 3;
-
-    char extra_fmts[3][2][10] = {{"%q", "^`AB`^"},
-                                 {"%f", "^`CD`^"},
-                                 {"%F", "^`EF`^"}};
-
-    int extra_fmts_found[3] = {0,0,0};
-    int extra_fmts_found_one = 0;
-    struct tm c_date;
-    struct date_info tempDate;
-    long absdate;
-    double abstime;
-    int i, result_len;
-    PyObject *py_result;
-
-    long (*toDaily)(long, char, asfreq_info*) = NULL;
-    asfreq_info af_info;
-
-    if (!PyArg_ParseTuple(args, "s:strftime(fmt)", &orig_fmt_str)) return NULL;
-
-    toDaily = get_asfreq_func(self->freq, FR_DAY, 0);
-    get_asfreq_info(self->freq, FR_DAY, &af_info);
-
-    absdate = toDaily(self->value, 'E', &af_info);
-    abstime = getAbsTime(self->freq, absdate, self->value);
-
-    if(dInfoCalc_SetFromAbsDateTime(&tempDate, absdate, abstime,
-                                    GREGORIAN_CALENDAR)) return NULL;
-
-    // populate standard C date struct with info from our date_info struct
-    c_date.tm_sec = (int)tempDate.second;
-    c_date.tm_min = tempDate.minute;
-    c_date.tm_hour = tempDate.hour;
-    c_date.tm_mday = tempDate.day;
-    c_date.tm_mon = tempDate.month - 1;
-    c_date.tm_year = tempDate.year - 1900;
-    c_date.tm_wday = (tempDate.day_of_week + 1) % 7;
-    c_date.tm_yday = tempDate.day_of_year - 1;
-    c_date.tm_isdst = -1;
-
-    result_len = strlen(orig_fmt_str) + 50;
-    if ((result = PyArray_malloc(result_len * sizeof(char))) == NULL) {return PyErr_NoMemory();}
-
-    fmt_str = orig_fmt_str;
-
-    // replace any special format characters with their place holder
-    for(i=0; i < num_extra_fmts; i++) {
-        char *special_loc;
-        if ((special_loc = strstr(fmt_str,extra_fmts[i][0])) != NULL) {
-            char *tmp_str = fmt_str;
-            fmt_str = str_replace(fmt_str, extra_fmts[i][0],
-                                           extra_fmts[i][1]);
-            /* only free the previous loop value if this is not the first
-               special format string found */
-            if (extra_fmts_found_one) { free(tmp_str); }
-
-            if (fmt_str == NULL) {return NULL;}
-
-            extra_fmts_found[i] = 1;
-            extra_fmts_found_one = 1;
-        }
-    }
-
-    strftime(result, result_len, fmt_str, &c_date);
-    if (extra_fmts_found_one) { free(fmt_str); }
-
-    // replace any place holders with the appropriate value
-    for(i=0; i < num_extra_fmts; i++) {
-        if (extra_fmts_found[i]) {
-            char *tmp_str = result;
-            char *extra_str;
-
-            if (strcmp(extra_fmts[i][0], "%q") == 0 ||
-                strcmp(extra_fmts[i][0], "%f") == 0 ||
-                strcmp(extra_fmts[i][0], "%F") == 0) {
-
-                asfreq_info af_info;
-                int qtr_freq, year, quarter, year_len;
-
-                if (get_freq_group(self->freq) == FR_QTR) {
-                    qtr_freq = self->freq;
-                } else { qtr_freq = FR_QTR; }
-                get_asfreq_info(FR_DAY, qtr_freq, &af_info);
-
-                if(DtoQ_yq(absdate, &af_info, &year, &quarter) == INT_ERR_CODE)
-                { return NULL; }
-
-                if(strcmp(extra_fmts[i][0], "%q") == 0) {
-                    if ((extra_str = PyArray_malloc(2 * sizeof(char))) == NULL) {
-                        free(tmp_str);
-                        return PyErr_NoMemory();
-                    }
-                    sprintf(extra_str, "%i", quarter);
-                } else {
-                    if ((qtr_freq % 1000) > 12) { year -= 1; }
-
-                    if (strcmp(extra_fmts[i][0], "%f") == 0) {
-                        year_len = 2;
-                        year = year % 100;
-                    } else { year_len = 4; }
-
-                    if ((extra_str = PyArray_malloc((year_len+1) * sizeof(char))) == NULL) {
-                        free(tmp_str);
-                        return PyErr_NoMemory();
-                    }
-
-                    if (year_len == 2 && year < 10) {
-                        sprintf(extra_str, "0%i", year);
-                    } else { sprintf(extra_str, "%i", year); }
-                }
-
-            } else {
-                PyErr_SetString(PyExc_RuntimeError,"Unrecognized format string");
-                return NULL;
-            }
-
-            result = str_replace(result, extra_fmts[i][1], extra_str);
-            free(tmp_str);
-            free(extra_str);
-            if (result == NULL) { return NULL; }
-        }
-    }
-
-    py_result = PyString_FromString(result);
-    free(result);
-
-    return py_result;
-}
-
-static PyObject *
-DateObject___str__(DateObject* self)
-{
-
-    int freq_group = get_freq_group(self->freq);
-    PyObject *string_arg, *retval;
-
-    string_arg = NULL;
-    if (freq_group == FR_UND) {
-        retval = PyString_FromFormat("%ld", self->value);
-        return retval;}
-    else if (freq_group == FR_ANN) { string_arg = Py_BuildValue("(s)", "%Y"); }
-    else if (freq_group == FR_QTR) { string_arg = Py_BuildValue("(s)", "%FQ%q"); }
-    else if (freq_group == FR_MTH) { string_arg = Py_BuildValue("(s)", "%b-%Y"); }
-    else if (freq_group == FR_DAY ||
-             freq_group == FR_BUS ||
-             freq_group == FR_WK) { string_arg = Py_BuildValue("(s)", "%d-%b-%Y"); }
-    else if (freq_group == FR_HR) { string_arg = Py_BuildValue("(s)", "%d-%b-%Y %H:00"); }
-    else if (freq_group == FR_MIN) { string_arg = Py_BuildValue("(s)", "%d-%b-%Y %H:%M"); }
-    else if (freq_group == FR_SEC) { string_arg = Py_BuildValue("(s)", "%d-%b-%Y %H:%M:%S"); }
-
-    if (string_arg == NULL) { return NULL; }
-
-    retval = DateObject_strftime(self, string_arg);
-    Py_DECREF(string_arg);
-
-    return retval;
-}
-
-static PyObject *
-DateObject_freqstr(DateObject *self, void *closure) {
-    PyObject *key = PyInt_FromLong(self->freq);
-    PyObject *freq_aliases = PyDict_GetItem(freq_dict, key);
-    PyObject *main_alias = PyTuple_GET_ITEM(freq_aliases, 0);
-    Py_DECREF(key);
-    Py_INCREF(main_alias);
-    return main_alias;
-}
-
-
-static PyObject *
-DateObject___repr__(DateObject* self)
-{
-    PyObject *py_str_rep, *py_freqstr, *py_repr;
-    char *str_rep, *freqstr, *repr;
-    int repr_len;
-
-    py_str_rep = DateObject___str__(self);
-    if (py_str_rep == NULL) { return NULL; }
-
-    py_freqstr = DateObject_freqstr(self, NULL);
-
-    str_rep = PyString_AsString(py_str_rep);
-    freqstr = PyString_AsString(py_freqstr);
-
-    repr_len = strlen(str_rep) + strlen(freqstr) + 6;
-
-    if((repr = PyArray_malloc((repr_len + 1) * sizeof(char))) == NULL)
-    { return PyErr_NoMemory(); }
-
-    strcpy(repr, "<");
-    strcat(repr, freqstr);
-    strcat(repr, " : ");
-    strcat(repr, str_rep);
-    strcat(repr, ">");
-
-    py_repr = PyString_FromString(repr);
-
-    Py_DECREF(py_str_rep);
-    Py_DECREF(py_freqstr);
-
-    free(repr);
-
-    return py_repr;
-}
-
-/******************************
-   These methods seem rather useless. May or may not implement them.
-fromordinal(self, ordinal):
-    return Date(self.freq, datetime=dt.datetime.fromordinal(ordinal))
-tostring(self):
-    return str(self)
-toobject(self):
-    return self
-isvalid(self):
-    return True
-*******************************/
-
-
-static DateObject *
-DateObject_FromFreqAndValue(int freq, int value) {
-
-    DateObject *result = DateObject_New();
-
-    PyObject *args = PyTuple_New(0);
-    PyObject *kw = PyDict_New();
-    PyObject *py_freq = PyInt_FromLong(freq);
-    PyObject *py_value = PyInt_FromLong(value);
-
-    PyDict_SetItemString(kw, "freq", py_freq);
-    PyDict_SetItemString(kw, "value", py_value);
-
-    Py_DECREF(py_freq);
-    Py_DECREF(py_value);
-
-    DateObject_init(result, args, kw);
-
-    Py_DECREF(args);
-    Py_DECREF(kw);
-
-    return result;
-}
-
-static PyObject *
-DateObject_date_plus_int(PyObject *date, PyObject *pyint) {
-    DateObject *dateobj = (DateObject*)date;
-
-    if (!PyInt_Check(pyint) && !PyObject_HasAttrString(pyint, "__int__")) {
-        // invalid type for addition
-
-        char *err_str, *type_str;
-        PyObject *type_repr, *obj_type;
-
-        obj_type = PyObject_Type(pyint);
-        type_repr = PyObject_Repr(obj_type);
-        type_str = PyString_AsString(type_repr);
-
-        if ((err_str = PyArray_malloc(255 * sizeof(char))) == NULL) {
-            return PyErr_NoMemory();
-        }
-        sprintf(err_str, "Cannot add Date and %s", type_str);
-        Py_DECREF(obj_type);
-        Py_DECREF(type_repr);
-        PyErr_SetString(PyExc_TypeError, err_str);
-        free(err_str);
-        return NULL;
-    }
-
-    return (PyObject*)DateObject_FromFreqAndValue(
-        dateobj->freq, PyInt_AsLong(pyint) + dateobj->value);
-}
-
-static PyObject *
-DateObject___add__(PyObject *left, PyObject *right)
-{
-    if (DateObject_Check(left) && DateObject_Check(right)) {
-        PyErr_SetString(PyExc_TypeError, "Cannot add Date to Date");
-        return NULL;
-    } else if (DateObject_Check(left)) {
-        return DateObject_date_plus_int(left, right);
-    } else {
-        return DateObject_date_plus_int(right, left);
-    }
-}
-
-static PyObject *
-DateObject___subtract__(PyObject *left, PyObject *right)
-{
-    int result;
-    DateObject *dleft;
-    if (!DateObject_Check(left)) {
-        PyErr_SetString(PyExc_ValueError, "Cannot subtract a Date from a non-Date object.");
-        return NULL;
-    }
-
-    dleft = (DateObject*)left;
-
-    if (DateObject_Check(right)) {
-        DateObject *dright = (DateObject*)right;
-        if (dleft->freq != dright->freq) {
-            PyErr_SetString(PyExc_ValueError, "Cannot subtract Date objects with different frequencies.");
-            return NULL;
-        }
-        result = dleft->value - dright->value;
-        return PyInt_FromLong(result);
-    } else {
-        result = dleft->value - PyInt_AsLong(right);
-        return (PyObject*)DateObject_FromFreqAndValue(dleft->freq, result);
-    }
-}
-
-static int
-DateObject___compare__(DateObject * obj1, DateObject * obj2)
-{
-    if (obj1->freq != obj2->freq) {
-        PyErr_SetString(PyExc_ValueError,
-                        "Cannot compare Date objects with different frequencies.");
-        return -1;
-    }
-
-    if (obj1->value < obj2->value) return -1;
-    if (obj1->value > obj2->value) return 1;
-    if (obj1->value == obj2->value) return 0;
-    return -1;
-}
-
-static long
-DateObject___hash__(DateObject *self)
-{
-    register int freq_group = get_freq_group(self->freq);
-
-    /* within a given frequency, hash values are guaranteed to be unique
-       for different dates. For different frequencies, we make a reasonable
-       effort to ensure hash values will be unique, but it is not guaranteed */
-    if (freq_group == FR_BUS) {
-        return self->value + 10000000;
-    } else if (freq_group == FR_WK) {
-        return self->value + 100000000;
-    } else { return self->value; }
-}
-
-static PyObject *
-DateObject___int__(DateObject *self)
-{
-    return PyInt_FromLong(self->value);
-}
-
-static PyObject *
-DateObject___float__(DateObject *self)
-{
-    return PyFloat_FromDouble((double)(self->value));
-}
-
-static PyObject *
-DateObject___long__(DateObject *self)
-{
-    return PyLong_FromLong(self->value);
-}
-
-
-/***************************************************
-           ====== Date Properties ======
-****************************************************/
-
-// helper function for date property funcs
-static int
-DateObject_set_date_info(DateObject *self, struct date_info *dinfo) {
-    PyObject *daily_obj = DateObject_toordinal(self);
-    long absdate = PyInt_AsLong(daily_obj);
-
-    Py_DECREF(daily_obj);
-
-    if(dInfoCalc_SetFromAbsDate(dinfo, absdate,
-                                GREGORIAN_CALENDAR)) return -1;
-
-    return 0;
-}
-
-// helper function for date property funcs
-static int
-DateObject_set_date_info_wtime(DateObject *self, struct date_info *dinfo) {
-    PyObject *daily_obj = DateObject_toordinal(self);
-    long absdate = PyInt_AsLong(daily_obj);
-    double abstime;
-
-    Py_DECREF(daily_obj);
-
-    abstime = getAbsTime(self->freq, absdate, self->value);
-
-    if(dInfoCalc_SetFromAbsDateTime(dinfo, absdate, abstime,
-                                    GREGORIAN_CALENDAR)) return -1;
-
-    return 0;
-}
-
-static PyObject *
-DateObject_year(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong(dinfo.year);
-}
-
-static int _DateObject_quarter_year(DateObject *self, int *year, int *quarter) {
-
-    PyObject *daily_obj;
-    long absdate;
-
-    asfreq_info af_info;
-    int qtr_freq;
-
-    daily_obj = DateObject_toordinal(self);
-    absdate = PyInt_AsLong(daily_obj);
-    Py_DECREF(daily_obj);
-
-    if (get_freq_group(self->freq) == FR_QTR) {
-        qtr_freq = self->freq;
-    } else { qtr_freq = FR_QTR; }
-    get_asfreq_info(FR_DAY, qtr_freq, &af_info);
-
-    if(DtoQ_yq(absdate, &af_info, year, quarter) == INT_ERR_CODE)
-    { return INT_ERR_CODE; }
-
-    if ((qtr_freq % 1000) > 12) { *year -= 1; }
-
-    return 0;
-}
-
-static PyObject *
-DateObject_qyear(DateObject *self, void *closure) {
-    int year, quarter;
-    if(_DateObject_quarter_year(self,
-            &year, &quarter) == INT_ERR_CODE) { return NULL; }
-    return PyInt_FromLong(year);
-}
-
-static PyObject *
-DateObject_quarter(DateObject *self, void *closure) {
-    int year, quarter;
-    if(_DateObject_quarter_year(self,
-            &year, &quarter) == INT_ERR_CODE) { return NULL; }
-    return PyInt_FromLong(quarter);
-}
-
-static PyObject *
-DateObject_month(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong(dinfo.month);
-}
-
-static PyObject *
-DateObject_day(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong(dinfo.day);
-}
-
-static PyObject *
-DateObject_weekday(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong(dinfo.day_of_week);
-}
-
-static PyObject *
-DateObject_day_of_week(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong(dinfo.day_of_week);
-}
-
-static PyObject *
-DateObject_day_of_year(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong(dinfo.day_of_year);
-}
-
-static PyObject *
-DateObject_week(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong(dInfoCalc_ISOWeek(&dinfo));
-}
-
-static PyObject *
-DateObject_hour(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info_wtime(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong(dinfo.hour);
-}
-
-static PyObject *
-DateObject_minute(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info_wtime(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong(dinfo.minute);
-}
-
-static PyObject *
-DateObject_second(DateObject *self, void *closure) {
-    struct date_info dinfo;
-    if(DateObject_set_date_info_wtime(self, &dinfo) == -1) return NULL;
-    return PyInt_FromLong((int)dinfo.second);
-}
-
-static PyObject *
-DateObject_datetime(DateObject *self, void *closure) {
-    PyObject *datetime;
-    int hour=0, minute=0, second=0;
-    int freq_group;
-    struct date_info dinfo;
-
-    if(DateObject_set_date_info_wtime(self, &dinfo) == -1) return NULL;
-    freq_group = get_freq_group(self->freq);
-
-    switch(freq_group) {
-        case FR_HR:
-            hour = dinfo.hour;
-            break;
-        case FR_MIN:
-            hour = dinfo.hour;
-            minute = dinfo.minute;
-            break;
-        case FR_SEC:
-            hour = dinfo.hour;
-            minute = dinfo.minute;
-            second = (int)dinfo.second;
-            break;
-    }
-
-    datetime = PyDateTime_FromDateAndTime(
-                dinfo.year, dinfo.month, dinfo.day, hour, minute, second, 0);
-    return datetime;
-}
-
-static int
-DateObject_ReadOnlyErr(DateObject *self, PyObject *value, void *closure) {
-   PyErr_SetString(PyExc_AttributeError, "Cannot set read-only property");
-   return -1;
-}
-
-static PyGetSetDef DateObject_getseters[] = {
-    {"year", (getter)DateObject_year, (setter)DateObject_ReadOnlyErr,
-            "Returns the year.", NULL},
-    {"qyear", (getter)DateObject_qyear, (setter)DateObject_ReadOnlyErr,
-            "For quarterly frequency dates, returns the year corresponding to the\n"
-            "year end (start) month. When using QTR or QTR-E based quarterly\n"
-            "frequencies, this is the fiscal year in a financial context.\n\n"
-            "For non-quarterly dates, this simply returns the year of the date.",
-            NULL},
-    {"quarter", (getter)DateObject_quarter, (setter)DateObject_ReadOnlyErr,
-            "Returns the quarter.", NULL},
-    {"month", (getter)DateObject_month, (setter)DateObject_ReadOnlyErr,
-            "Returns the month.", NULL},
-    {"week", (getter)DateObject_week, (setter)DateObject_ReadOnlyErr,
-            "Returns the week.", NULL},
-    {"day", (getter)DateObject_day, (setter)DateObject_ReadOnlyErr,
-            "Returns the day of month.", NULL},
-    {"weekday", (getter)DateObject_weekday, (setter)DateObject_ReadOnlyErr,
-            "Returns the day of week.", NULL},
-    // deprecated alias for weekday property
-    {"day_of_week", (getter)DateObject_weekday, (setter)DateObject_ReadOnlyErr,
-            "Returns the day of week.", NULL},
-    {"day_of_year", (getter)DateObject_day_of_year, (setter)DateObject_ReadOnlyErr,
-            "Returns the day of year.", NULL},
-    {"second", (getter)DateObject_second, (setter)DateObject_ReadOnlyErr,
-            "Returns the second.", NULL},
-    {"minute", (getter)DateObject_minute, (setter)DateObject_ReadOnlyErr,
-            "Returns the minute.", NULL},
-    {"hour", (getter)DateObject_hour, (setter)DateObject_ReadOnlyErr,
-            "Returns the hour.", NULL},
-
-    {"freqstr", (getter)DateObject_freqstr, (setter)DateObject_ReadOnlyErr,
-            "Returns the string representation of frequency.", NULL},
-    {"datetime", (getter)DateObject_datetime, (setter)DateObject_ReadOnlyErr,
-            "Returns the Date object converted to standard python datetime object",
-            NULL},
-
-    {NULL}  /* Sentinel */
-};
-
-
-static PyNumberMethods DateObject_as_number = {
-    (binaryfunc)DateObject___add__,      /* nb_add */
-    (binaryfunc)DateObject___subtract__, /* nb_subtract */
-    0,                                   /* nb_multiply */
-    0,                                   /* nb_divide */
-    0,                                   /* nb_remainder */
-    0,                                   /* nb_divmod */
-    0,                                   /* nb_power */
-    0,                                   /* nb_negative */
-    0,                                   /* nb_positive */
-    0,                                   /* nb_absolute */
-    0,                                   /* nb_nonzero */
-    0,                                   /* nb_invert */
-    0,                                   /* nb_lshift */
-    0,                                   /* nb_rshift */
-    0,                                   /* nb_and */
-    0,                                   /* nb_xor */
-    0,                                   /* nb_or */
-    0,                                   /* nb_coerce */
-    (unaryfunc)DateObject___int__,       /* nb_int */
-    (unaryfunc)DateObject___long__,      /* nb_long */
-    (unaryfunc)DateObject___float__,     /* nb_float */
-    (unaryfunc)0,                        /* nb_oct */
-    (unaryfunc)0,                        /* nb_hex */
-};
-
-static PyMethodDef DateObject_methods[] = {
-    {"toordinal", (PyCFunction)DateObject_toordinal, METH_NOARGS,
-     DateObject_toordinal_doc},
-    {"strftime", (PyCFunction)DateObject_strftime, METH_VARARGS,
-     DateObject_strftime_doc},
-    // deprecated alias for strftime
-    {"strfmt", (PyCFunction)DateObject_strftime, METH_VARARGS,
-     DateObject_strfmt_doc},
-    {"asfreq", (PyCFunction)DateObject_asfreq, METH_VARARGS | METH_KEYWORDS,
-     DateObject_asfreq_doc},
-    {NULL}  /* Sentinel */
-};
-
-
-static PyTypeObject DateType = {
-    PyObject_HEAD_INIT(NULL)
-    0,                               /* ob_size */
-    "timeseries.Date",               /* tp_name */
-    sizeof(DateObject),              /* tp_basicsize */
-    0,                               /* tp_itemsize */
-    (destructor)DateObject_dealloc,  /* tp_dealloc */
-    0,                               /* tp_print */
-    0,                               /* tp_getattr */
-    0,                               /* tp_setattr */
-    (cmpfunc)DateObject___compare__, /* tp_compare */
-    (reprfunc)DateObject___repr__,   /* tp_repr */
-    &DateObject_as_number,           /* tp_as_number */
-    0,                               /* tp_as_sequence */
-    0,                               /* tp_as_mapping */
-    (hashfunc)DateObject___hash__,   /* tp_hash */
-    0,                               /* tp_call*/
-    (reprfunc)DateObject___str__,    /* tp_str */
-    0,                               /* tp_getattro */
-    0,                               /* tp_setattro */
-    0,                               /* tp_as_buffer */
-    Py_TPFLAGS_DEFAULT |             /* tp_flags */
-    Py_TPFLAGS_CHECKTYPES |
-    Py_TPFLAGS_BASETYPE,
-    "Defines a Date object, as the combination of a date and a frequency.\n"
-    "Several options are available to construct a Date object explicitly:\n\n"
-    "- Give appropriate values to the `year`, `month`, `day`, `quarter`, `hours`,\n"
-    "  `minutes`, `seconds` arguments.\n\n"
-    "  >>> td.Date(freq='Q',year=2004,quarter=3)\n"
-    "  >>> td.Date(freq='D',year=2001,month=1,day=1)\n\n"
-    "- Use the `string` keyword. This method uses a modified version of the\n"
-    "  mx.DateTime parser submodule. More information is available in its\n"
-    "  documentation.\n\n"
-    "  >>> ts.Date('D', '2007-01-01')\n\n"
-    "- Use the `datetime` keyword with an existing datetime.datetime object.\n\n"
-    "  >>> td.Date('D', datetime=datetime.datetime.now())",  /* tp_doc */
-    0,                               /* tp_traverse */
-    0,                               /* tp_clear */
-    0,                               /* tp_richcompare */
-    0,                               /* tp_weaklistoffset */
-    0,                               /* tp_iter */
-    0,                               /* tp_iternext */
-    DateObject_methods,              /* tp_methods */
-    DateObject_members,              /* tp_members */
-    DateObject_getseters,            /* tp_getset */
-    0,                               /* tp_base */
-    0,                               /* tp_dict */
-    0,                               /* tp_descr_get */
-    0,                               /* tp_descr_set */
-    0,                               /* tp_dictoffset */
-    (initproc)DateObject_init,       /* tp_init */
-    0,                               /* tp_alloc */
-    DateObject_new,                  /* tp_new */
-};
-
-
-///////////////////////////////////////////////////////////////////////
-
-PyObject *
-c_dates_check_freq(PyObject *self, PyObject *args) {
-
-    PyObject *freq;
-    int freq_val;
-
-    if (!PyArg_ParseTuple(args, "O:check_freq(freq)", &freq)) return NULL;
-    if ((freq_val = check_freq(freq)) == INT_ERR_CODE) return NULL;
-
-    return PyInt_FromLong(freq_val);
-}
-
-PyObject *
-c_dates_check_freq_str(PyObject *self, PyObject *args) {
-
-    PyObject *alias_tuple, *result, *freq_key;
-
-    if ((freq_key = c_dates_check_freq(self, args)) == NULL) return NULL;
-
-    alias_tuple = PyDict_GetItem(freq_dict, freq_key);
-    result = PyTuple_GET_ITEM(alias_tuple, 0);
-
-    Py_INCREF(result);
-
-    Py_DECREF(freq_key);
-
-    return result;
-}
-
-PyObject *
-c_dates_get_freq_group(PyObject *self, PyObject *args) {
-
-    PyObject *freq;
-    int freq_val;
-
-    if (!PyArg_ParseTuple(args, "O:get_freq_group(freq)", &freq)) return NULL;
-    if ((freq_val = check_freq(freq)) == INT_ERR_CODE) return NULL;
-
-    return PyInt_FromLong(get_freq_group(freq_val));
-}
-
-PyObject *
-c_dates_now(PyObject *self, PyObject *args) {
-
-    PyObject *freq, *init_args, *init_kwargs;
-
-#ifdef WIN32
-    __time64_t rawtime;
-#else
-    time_t rawtime;
-#endif
-    struct tm *timeinfo;
-    int freq_val;
-
-    DateObject *secondly_date;
-
-    if (!PyArg_ParseTuple(args, "O:now(freq)", &freq)) return NULL;
-
-    if ((freq_val = check_freq(freq)) == INT_ERR_CODE) return NULL;
-#ifdef WIN32
-    _time64(&rawtime);
-#else
-    time(&rawtime);
-#endif
-
-
-#ifdef WIN32
-    timeinfo = _localtime64(&rawtime);
-#else
-    timeinfo = localtime(&rawtime);
-#endif
-
-    init_args = PyTuple_New(0);
-    init_kwargs = PyDict_New();
-
-    DICT_SETINT_STRKEY(init_kwargs, "freq", FR_SEC);
-    DICT_SETINT_STRKEY(init_kwargs, "year", timeinfo->tm_year+1900);
-    DICT_SETINT_STRKEY(init_kwargs, "month", timeinfo->tm_mon+1);
-    DICT_SETINT_STRKEY(init_kwargs, "day", timeinfo->tm_mday);
-    DICT_SETINT_STRKEY(init_kwargs, "hour", timeinfo->tm_hour);
-    DICT_SETINT_STRKEY(init_kwargs, "minute", timeinfo->tm_min);
-    DICT_SETINT_STRKEY(init_kwargs, "second", timeinfo->tm_sec);
-
-    secondly_date = DateObject_New();
-    DateObject_init(secondly_date, init_args, init_kwargs);
-
-    Py_DECREF(init_args);
-    Py_DECREF(init_kwargs);
-
-    if (freq_val != FR_SEC) {
-        DateObject *result = DateObject_New();
-
-        long (*asfreq_func)(long, char, asfreq_info*) = NULL;
-        asfreq_info af_info;
-
-        int date_val;
-
-        get_asfreq_info(FR_SEC, freq_val, &af_info);
-        asfreq_func = get_asfreq_func(FR_SEC, freq_val, 0);
-
-        date_val = asfreq_func(secondly_date->value, 'S', &af_info);
-
-        Py_DECREF(secondly_date);
-
-        result->freq = freq_val;
-        result->value = date_val;
-
-        return (PyObject*)result;
-
-    } else { return (PyObject*)secondly_date; }
-}
-
-
-PyObject *
-DateArray_asfreq(PyObject *self, PyObject *args)
-{
-    PyArrayObject *fromDates, *toDates;
-    PyArrayIterObject *iterFrom, *iterTo;
-    PyObject *fromDateObj, *toDateObj;
-    char *relation;
-    int fromFreq, toFreq;
-    long fromDate, toDate;
-    long (*asfreq_main)(long, char, asfreq_info*) = NULL;
-    asfreq_info af_info;
-
-    if (!PyArg_ParseTuple(args,
-                "Oiis:asfreq(fromDates, fromfreq, tofreq, relation)",
-                &fromDates, &fromFreq, &toFreq, &relation)) return NULL;
-
-    get_asfreq_info(fromFreq, toFreq, &af_info);
-
-    asfreq_main = get_asfreq_func(fromFreq, toFreq, 0);
-
-    toDates = (PyArrayObject *)PyArray_Copy(fromDates);
-
-    iterFrom = (PyArrayIterObject *)PyArray_IterNew((PyObject *)fromDates);
-    if (iterFrom == NULL) return NULL;
-
-    iterTo = (PyArrayIterObject *)PyArray_IterNew((PyObject *)toDates);
-    if (iterTo == NULL) return NULL;
-
-    while (iterFrom->index < iterFrom->size) {
-
-        fromDateObj = PyArray_GETITEM(fromDates, iterFrom->dataptr);
-        fromDate = PyInt_AsLong(fromDateObj);
-        CHECK_ASFREQ(toDate = asfreq_main(fromDate, relation[0], &af_info));
-        toDateObj = PyInt_FromLong(toDate);
-
-        PyArray_SETITEM(toDates, iterTo->dataptr, toDateObj);
-
-        Py_DECREF(fromDateObj);
-        Py_DECREF(toDateObj);
-
-        PyArray_ITER_NEXT(iterFrom);
-        PyArray_ITER_NEXT(iterTo);
-    }
-
-    Py_DECREF(iterFrom);
-    Py_DECREF(iterTo);
-
-    return (PyObject *)toDates;
-
-}
-
-/**************************************************************
-** The following functions are used by DateArray_getDateInfo **
-** to determine how many consecutive periods will have the   **
-** same result                                               **
-**************************************************************/
-
-// also used for qyear
-static int __skip_periods_year(int freq) {
-
-    int freq_group = get_freq_group(freq);
-
-    switch(freq_group)
-    {
-        case FR_QTR:
-            return 4;
-        case FR_MTH:
-            return 12;
-        case FR_WK:
-            return 51;
-        case FR_BUS:
-            return 260;
-        case FR_DAY:
-            return 365;
-        case FR_HR:
-            return 365*24;
-        case FR_MIN:
-            return 365*24*60;
-        case FR_SEC:
-            return 365*24*60*60;
-        default:
-            return 1;
-    }
-}
-
-static int __skip_periods_quarter(int freq) {
-
-    int freq_group = get_freq_group(freq);
-
-    switch(freq_group)
-    {
-        case FR_MTH:
-            return 3;
-        case FR_WK:
-            return 12;
-        case FR_BUS:
-            return 64;
-        case FR_DAY:
-            return 90;
-        case FR_HR:
-            return 90*24;
-        case FR_MIN:
-            return 90*24*60;
-        case FR_SEC:
-            return 90*24*60*60;
-        default:
-            return 1;
-    }
-}
-
-static int __skip_periods_month(int freq) {
-
-    int freq_group = get_freq_group(freq);
-
-    switch(freq_group)
-    {
-        case FR_WK:
-            return 3;
-        case FR_BUS:
-            return 20;
-        case FR_DAY:
-            return 28;
-        case FR_HR:
-            return 28*24;
-        case FR_MIN:
-            return 28*24*60;
-        case FR_SEC:
-            return 28*24*60*60;
-        default:
-            return 1;
-    }
-}
-
-// also used for day_of_year, day_of_week
-static int __skip_periods_day(int freq) {
-
-    int freq_group = get_freq_group(freq);
-
-    switch(freq_group)
-    {
-        case FR_HR:
-            return 24;
-        case FR_MIN:
-            return 24*60;
-        case FR_SEC:
-            return 24*60*60;
-        default:
-            return 1;
-    }
-}
-
-static int __skip_periods_week(int freq) {
-
-    int freq_group = get_freq_group(freq);
-
-    switch(freq_group)
-    {
-        case FR_BUS:
-            return 5;
-        case FR_DAY:
-            return 7;
-        case FR_HR:
-            return 7*24;
-        case FR_MIN:
-            return 7*24*60;
-        case FR_SEC:
-            return 7*24*60*60;
-        default:
-            return 1;
-    }
-}
-
-static int __skip_periods_hour(int freq) {
-
-    int freq_group = get_freq_group(freq);
-
-    switch(freq_group)
-    {
-        case FR_MIN:
-            return 60;
-        case FR_SEC:
-            return 60*60;
-        default:
-            return 1;
-    }
-}
-
-static int __skip_periods_minute(int freq) {
-
-    int freq_group = get_freq_group(freq);
-
-    switch(freq_group)
-    {
-        case FR_SEC:
-            return 60;
-        default:
-            return 1;
-    }
-}
-
-PyObject *
-DateArray_getDateInfo(PyObject *self, PyObject *args)
-{
-    int freq, is_full, skip_periods, counter=1, val_changed=0;
-    char *info;
-
-    PyObject *prev_val=NULL;
-    PyArrayObject *array, *newArray;
-    PyArrayIterObject *iterSource, *iterResult;
-
-    PyObject* (*getDateInfo)(DateObject*, void*) = NULL;
-
-    if (!PyArg_ParseTuple(args, "Oisi:getDateInfo(array, freq, info, is_full)",
-                                &array, &freq, &info, &is_full)) return NULL;
-    newArray = (PyArrayObject *)PyArray_Copy(array);
-
-    iterSource = (PyArrayIterObject *)PyArray_IterNew((PyObject *)array);
-    iterResult = (PyArrayIterObject *)PyArray_IterNew((PyObject *)newArray);
-
-
-    switch(*info)
-    {
-        case 'Y': //year
-            getDateInfo = &DateObject_year;
-            skip_periods = __skip_periods_year(freq);
-            break;
-        case 'F': //"fiscal" year
-            getDateInfo = &DateObject_qyear;
-            skip_periods = __skip_periods_year(freq);
-            break;
-        case 'Q': //quarter
-            getDateInfo = &DateObject_quarter;
-            skip_periods = __skip_periods_quarter(freq);
-            break;
-        case 'M': //month
-            getDateInfo = &DateObject_month;
-            skip_periods = __skip_periods_month(freq);
-            break;
-        case 'D': //day
-            getDateInfo = &DateObject_day;
-            skip_periods = __skip_periods_day(freq);
-            break;
-        case 'R': //day of year
-            getDateInfo = &DateObject_day_of_year;
-            skip_periods = __skip_periods_day(freq);
-            break;
-        case 'W': //day of week
-            getDateInfo = &DateObject_day_of_week;
-            skip_periods = __skip_periods_day(freq);
-            break;
-        case 'I': //week of year
-            getDateInfo = &DateObject_week;
-            skip_periods = __skip_periods_week(freq);
-            break;
-        case 'H': //hour
-            getDateInfo = &DateObject_hour;
-            skip_periods = __skip_periods_hour(freq);
-            break;
-        case 'T': //minute
-            getDateInfo = &DateObject_minute;
-            skip_periods = __skip_periods_minute(freq);
-            break;
-        case 'S': //second
-            getDateInfo = &DateObject_second;
-            skip_periods = 1;
-            break;
-        default:
-            return NULL;
-    }
-
-    {
-        DateObject *curr_date;
-        PyObject *val, *dInfo;
-
-        while (iterSource->index < iterSource->size) {
-
-            if ((val_changed == 0) ||
-                (is_full == 0) ||
-                (prev_val == NULL) ||
-                (counter >= skip_periods)) {
-
-                   val = PyArray_GETITEM(array, iterSource->dataptr);
-                   curr_date = DateObject_FromFreqAndValue(freq, PyInt_AsLong(val));
-                   dInfo = getDateInfo(curr_date, NULL);
-
-                   if ((prev_val != NULL) &&
-                       (PyInt_AsLong(prev_val) != PyInt_AsLong(dInfo))) {
-                       val_changed = 1;
-                       counter = 0;
-                   }
-
-                   Py_DECREF(val);
-                   Py_DECREF(curr_date);
-
-                   if (prev_val != NULL) {
-                       Py_DECREF(prev_val);
-                   }
-
-                   prev_val = dInfo;
-            }
-
-            PyArray_SETITEM(newArray, iterResult->dataptr, dInfo);
-
-            PyArray_ITER_NEXT(iterSource);
-            PyArray_ITER_NEXT(iterResult);
-
-            counter += 1;
-        }
-    }
-
-    if (prev_val != NULL) {
-        Py_DECREF(prev_val);
-    }
-    Py_DECREF(iterSource);
-    Py_DECREF(iterResult);
-
-    return (PyObject *) newArray;
-}
-
-
-void import_c_dates(PyObject *m)
-{
-
-    if (PyType_Ready(&DateType) < 0) return;
-
-    DateCalc_Error =
-        PyErr_NewException("c_dates.DateCalc_Error", NULL, NULL);
-    DateCalc_RangeError =
-        PyErr_NewException("c_dates.DateCalc_RangeError", NULL, NULL);
-
-    import_array();
-    PyDateTime_IMPORT;
-
-    Py_INCREF(&DateType);
-    PyModule_AddObject(m, "Date", (PyObject *)(&DateType));
-
-    if(build_freq_dict() == INT_ERR_CODE) {
-        PyErr_SetString(                    \
-            PyExc_ImportError,              \
-            "initialization of module timeseries.c_dates failed");
-        return;
-    };
-
-    PyModule_AddObject(m, "freq_dict", freq_dict);
-    PyModule_AddObject(m, "freq_dict_rev", freq_dict_rev);
-    PyModule_AddObject(m, "freq_constants", freq_constants);
-
-    PyModule_AddObject(m, "DateCalc_Error", DateCalc_Error);
-    PyModule_AddObject(m, "DateCalc_RangeError", DateCalc_RangeError);
-
-}
diff --git a/pandas/src/timeseries/c_dates.h b/pandas/src/timeseries/c_dates.h
deleted file mode 100644
index 8ca6fc49e..000000000
--- a/pandas/src/timeseries/c_dates.h
+++ /dev/null
@@ -1,123 +0,0 @@
-#ifndef C_DATES_H
-#define C_DATES_H
-
-#include "c_lib.h"
-
-#define HIGHFREQ_ORIG 719163
-
-/*** FREQUENCY CONSTANTS ***/
-
-#define FR_ANN  1000  /* Annual */
-#define FR_ANNDEC  FR_ANN  /* Annual - December year end*/
-#define FR_ANNJAN  1001  /* Annual - January year end*/
-#define FR_ANNFEB  1002  /* Annual - February year end*/
-#define FR_ANNMAR  1003  /* Annual - March year end*/
-#define FR_ANNAPR  1004  /* Annual - April year end*/
-#define FR_ANNMAY  1005  /* Annual - May year end*/
-#define FR_ANNJUN  1006  /* Annual - June year end*/
-#define FR_ANNJUL  1007  /* Annual - July year end*/
-#define FR_ANNAUG  1008  /* Annual - August year end*/
-#define FR_ANNSEP  1009  /* Annual - September year end*/
-#define FR_ANNOCT  1010  /* Annual - October year end*/
-#define FR_ANNNOV  1011  /* Annual - November year end*/
-
-/* The standard quarterly frequencies. Year is determined by what year the end
-   month lies in. */
-#define FR_QTR  2000       /* Quarterly - December year end (default quarterly) */
-#define FR_QTRDEC  FR_QTR  /* Quarterly - December year end */
-#define FR_QTRJAN  2001    /* Quarterly - January year end */
-#define FR_QTRFEB  2002    /* Quarterly - February year end */
-#define FR_QTRMAR  2003    /* Quarterly - March year end */
-#define FR_QTRAPR  2004    /* Quarterly - April year end */
-#define FR_QTRMAY  2005    /* Quarterly - May year end */
-#define FR_QTRJUN  2006    /* Quarterly - June year end */
-#define FR_QTRJUL  2007    /* Quarterly - July year end */
-#define FR_QTRAUG  2008    /* Quarterly - August year end */
-#define FR_QTRSEP  2009    /* Quarterly - September year end */
-#define FR_QTROCT  2010    /* Quarterly - October year end */
-#define FR_QTRNOV  2011    /* Quarterly - November year end */
-
-/* End period based quarterly frequencies. Year is determined by what year the
-   end month lies in. */
-#define FR_QTREDEC  FR_QTRDEC  /* Quarterly - December year end*/
-#define FR_QTREJAN  FR_QTRJAN  /* Quarterly - January year end*/
-#define FR_QTREFEB  FR_QTRFEB  /* Quarterly - February year end*/
-#define FR_QTREMAR  FR_QTRMAR  /* Quarterly - March year end*/
-#define FR_QTREAPR  FR_QTRAPR  /* Quarterly - April year end*/
-#define FR_QTREMAY  FR_QTRMAY  /* Quarterly - May year end*/
-#define FR_QTREJUN  FR_QTRJUN  /* Quarterly - June year end*/
-#define FR_QTREJUL  FR_QTRJUL  /* Quarterly - July year end*/
-#define FR_QTREAUG  FR_QTRAUG  /* Quarterly - August year end*/
-#define FR_QTRESEP  FR_QTRSEP  /* Quarterly - September year end*/
-#define FR_QTREOCT  FR_QTROCT  /* Quarterly - October year end*/
-#define FR_QTRENOV  FR_QTRNOV  /* Quarterly - November year end*/
-
-/* Starting period based quarterly frequencies. Year is determined by what year
-   the starting month lies in. */
-#define FR_QTRSDEC  FR_QTRDEC+12  /* Quarterly - December year end*/
-#define FR_QTRSJAN  FR_QTRJAN+12  /* Quarterly - January year end*/
-#define FR_QTRSFEB  FR_QTRFEB+12  /* Quarterly - February year end*/
-#define FR_QTRSMAR  FR_QTRMAR+12  /* Quarterly - March year end*/
-#define FR_QTRSAPR  FR_QTRAPR+12  /* Quarterly - April year end*/
-#define FR_QTRSMAY  FR_QTRMAY+12  /* Quarterly - May year end*/
-#define FR_QTRSJUN  FR_QTRJUN+12  /* Quarterly - June year end*/
-#define FR_QTRSJUL  FR_QTRJUL+12  /* Quarterly - July year end*/
-#define FR_QTRSAUG  FR_QTRAUG+12  /* Quarterly - August year end*/
-#define FR_QTRSSEP  FR_QTRSEP+12  /* Quarterly - September year end*/
-#define FR_QTRSOCT  FR_QTROCT+12  /* Quarterly - October year end*/
-#define FR_QTRSNOV  FR_QTRNOV+12  /* Quarterly - November year end*/
-
-#define FR_MTH  3000  /* Monthly */
-
-#define FR_WK   4000  /* Weekly */
-#define FR_WKSUN FR_WK /* Weekly - Sunday end of week */
-#define FR_WKMON 4001 /* Weekly - Monday end of week */
-#define FR_WKTUE 4002 /* Weekly - Tuesday end of week */
-#define FR_WKWED 4003 /* Weekly - Wednesday end of week */
-#define FR_WKTHU 4004 /* Weekly - Thursday end of week */
-#define FR_WKFRI 4005 /* Weekly - Friday end of week */
-#define FR_WKSAT 4006 /* Weekly - Saturday end of week */
-
-#define FR_BUS  5000  /* Business days */
-#define FR_DAY  6000  /* Daily */
-#define FR_HR   7000  /* Hourly */
-#define FR_MIN  8000  /* Minutely */
-#define FR_SEC  9000  /* Secondly */
-#define FR_UND  -10000 /* Undefined */
-
-////////////////////////////////////////////////////
-
-int get_freq_group(int);
-
-typedef struct {
-    int from_week_end; //day the week ends on in the "from" frequency
-    int to_week_end; //day the week ends on in the "to" frequency
-
-    int from_a_year_end; //month the year ends on in the "from" frequency
-    int to_a_year_end; //month the year ends on in the "to" frequency
-
-    int from_q_year_end; //month the year ends on in the "from" frequency
-    int to_q_year_end; //month the year ends on in the "to" frequency
-} asfreq_info;
-
-int check_freq(PyObject *);
-void get_asfreq_info(int, int, asfreq_info*);
-long (*get_asfreq_func(int, int, int))(long, char, asfreq_info*);
-
-#define CHECK_ASFREQ(result) if ((result) == INT_ERR_CODE) return NULL
-
-PyObject *DateArray_asfreq(PyObject *, PyObject *);
-PyObject *DateArray_getDateInfo(PyObject *, PyObject *);
-
-
-PyObject *c_dates_now(PyObject *, PyObject *);
-PyObject *c_dates_check_freq(PyObject *, PyObject *);
-PyObject *c_dates_check_freq_str(PyObject *, PyObject *);
-PyObject *c_dates_get_freq_group(PyObject *, PyObject *);
-
-PyObject *set_callback_DateFromString(PyObject *, PyObject *);
-PyObject *set_callback_DateTimeFromString(PyObject *, PyObject *);
-
-void import_c_dates(PyObject *);
-
-#endif
diff --git a/pandas/src/timeseries/c_lib.c b/pandas/src/timeseries/c_lib.c
deleted file mode 100644
index 043220bfd..000000000
--- a/pandas/src/timeseries/c_lib.c
+++ /dev/null
@@ -1,204 +0,0 @@
-#include "c_lib.h"
-#include "numpy/arrayobject.h"
-
-// Numpy UFUNCS
-static PyObject *NP_ADD, *NP_MULTIPLY, *NP_SUBTRACT, *NP_SQRT,
-                *NP_GREATER, *NP_GREATER_EQUAL;
-
-/*********************************************************
-** Convenience wrappers for numpy UFUNCS                **
-*********************************************************/
-PyObject*
-np_add(PyObject *left_val, PyObject *right_val) {
-
-    PyObject *result;
-
-    result = PyObject_CallFunction(
-                         NP_ADD, "OO",
-                         (PyArrayObject*)left_val,
-                         right_val);
-    return result;
-}
-
-PyObject*
-np_subtract(PyObject *left_val, PyObject *right_val) {
-
-    PyObject *result;
-
-    result = PyObject_CallFunction(
-                         NP_SUBTRACT, "OO",
-                         (PyArrayObject*)left_val,
-                         right_val);
-    return result;
-}
-
-PyObject*
-np_multiply(PyObject *left_val, PyObject *right_val) {
-
-    PyObject *result;
-
-    result = PyObject_CallFunction(
-                         NP_MULTIPLY, "OO",
-                         (PyArrayObject*)left_val,
-                         right_val);
-    return result;
-}
-
-PyObject*
-np_sqrt(PyObject *val) {
-    return PyObject_CallFunction(NP_SQRT, "(O)", val);
-}
-
-int np_greater(PyObject *left_val, PyObject *right_val) {
-
-    PyObject *temp;
-    int result;
-
-    temp = PyObject_CallFunction(
-                         NP_GREATER, "OO",
-                         (PyArrayObject*)left_val,
-                         right_val);
-
-    result = (int)PyInt_AsLong(temp);
-    Py_DECREF(temp);
-    return result;
-}
-
-int np_greater_equal(PyObject *left_val, PyObject *right_val) {
-
-    PyObject *temp;
-    int result;
-
-    temp = PyObject_CallFunction(
-                         NP_GREATER_EQUAL, "OO",
-                         (PyArrayObject*)left_val,
-                         right_val);
-
-    result = (int)PyInt_AsLong(temp);
-    Py_DECREF(temp);
-    return result;
-}
-
-char *str_uppercase(char *str) {
-    if (str) {
-        int i, len=strlen(str);
-        char *result;
-        if((result = PyArray_malloc((len + 1)*sizeof(char))) == NULL) {
-            return (char *)PyErr_NoMemory();
-        }
-        strcpy(result, str);
-
-        for (i=0;i<len;i++) {
-            switch(result[i])
-            {
-                case 'a': { result[i]='A'; break; }
-                case 'b': { result[i]='B'; break; }
-                case 'c': { result[i]='C'; break; }
-                case 'd': { result[i]='D'; break; }
-                case 'e': { result[i]='E'; break; }
-                case 'f': { result[i]='F'; break; }
-                case 'g': { result[i]='G'; break; }
-                case 'h': { result[i]='H'; break; }
-                case 'i': { result[i]='I'; break; }
-                case 'j': { result[i]='J'; break; }
-                case 'k': { result[i]='K'; break; }
-                case 'l': { result[i]='L'; break; }
-                case 'm': { result[i]='M'; break; }
-                case 'n': { result[i]='N'; break; }
-                case 'o': { result[i]='O'; break; }
-                case 'p': { result[i]='P'; break; }
-                case 'q': { result[i]='Q'; break; }
-                case 'r': { result[i]='R'; break; }
-                case 's': { result[i]='S'; break; }
-                case 't': { result[i]='T'; break; }
-                case 'u': { result[i]='U'; break; }
-                case 'v': { result[i]='V'; break; }
-                case 'w': { result[i]='W'; break; }
-                case 'x': { result[i]='X'; break; }
-                case 'y': { result[i]='Y'; break; }
-                case 'z': { result[i]='Z'; break; }
-            }
-        }
-
-        return result;
-    } else { return NULL; }
-}
-
-char *str_replace(const char *s, const char *old, const char *new) {
-    char *ret;
-    int i, count = 0;
-    size_t newlen = strlen(new);
-    size_t oldlen = strlen(old);
-
-    for (i = 0; s[i] != '\0'; i++) {
-        if (strstr(&s[i], old) == &s[i]) {
-           count++;
-           i += oldlen - 1;
-        }
-    }
-
-    ret = PyArray_malloc(i + 1 + count * (newlen - oldlen));
-    if (ret == NULL) {return (char *)PyErr_NoMemory();}
-
-    i = 0;
-    while (*s) {
-        if (strstr(s, old) == s) {
-            strcpy(&ret[i], new);
-            i += newlen;
-            s += oldlen;
-        } else {
-            ret[i++] = *s++;
-        }
-    }
-    ret[i] = '\0';
-
-    return ret;
-}
-
-
-PyObject *
-set_callback(PyObject *args, PyObject **callback)
-{
-    PyObject *result = NULL;
-    PyObject *temp;
-
-    if (PyArg_ParseTuple(args, "O:set_callback", &temp)) {
-
-        if (!PyCallable_Check(temp)) {
-            PyErr_SetString(PyExc_TypeError, "parameter must be callable");
-            return NULL;
-        }
-
-        Py_XINCREF(temp);        // Add a reference to new callback
-        Py_XDECREF(*callback);  // Dispose of previous callback
-        *callback = temp;       // Remember new callback
-        // Boilerplate to return "None"
-        Py_INCREF(Py_None);
-        result = Py_None;
-    }
-    return result;
-}
-
-void import_c_lib(PyObject *m) {
-    PyObject *ops_dict;
-
-    import_array();
-
-    ops_dict = PyArray_GetNumericOps();
-
-    NP_ADD = PyDict_GetItemString(ops_dict, "add");
-    NP_MULTIPLY = PyDict_GetItemString(ops_dict, "multiply");
-    NP_SUBTRACT = PyDict_GetItemString(ops_dict, "subtract");
-    NP_SQRT = PyDict_GetItemString(ops_dict, "sqrt");
-    NP_GREATER = PyDict_GetItemString(ops_dict, "greater");
-    NP_GREATER_EQUAL = PyDict_GetItemString(ops_dict, "greater_equal");
-
-    Py_INCREF(NP_ADD);
-    Py_INCREF(NP_MULTIPLY);
-    Py_INCREF(NP_SUBTRACT);
-    Py_INCREF(NP_SQRT);
-    Py_INCREF(NP_GREATER);
-    Py_INCREF(NP_GREATER_EQUAL);
-
-    Py_DECREF(ops_dict);
-}
diff --git a/pandas/src/timeseries/c_lib.h b/pandas/src/timeseries/c_lib.h
deleted file mode 100644
index 3e3e32683..000000000
--- a/pandas/src/timeseries/c_lib.h
+++ /dev/null
@@ -1,30 +0,0 @@
-#ifndef C_LIB_H
-#define C_LIB_H
-
-#include <Python.h>
-#include <structmember.h>
-#include "numpy/arrayobject.h"
-
-/* c_lib defines generic functions that aren't inherently time series/date
-specific but are needed in various parts of the module. */
-
-#define INT_ERR_CODE -999
-
-#define MEM_CHECK(item) if (item == NULL) { return PyErr_NoMemory(); }
-#define ERR_CHECK(item) if (item == NULL) { return NULL; }
-
-char *str_uppercase(char *);
-char *str_replace(const char*, const char*, const char*);
-
-PyObject *np_add(PyObject*, PyObject*);
-PyObject *np_multiply(PyObject*, PyObject*);
-PyObject *np_subtract(PyObject*, PyObject*);
-PyObject *np_sqrt(PyObject*);
-int np_greater(PyObject*, PyObject*);
-int np_greater_equal(PyObject*, PyObject*);
-
-PyObject *set_callback(PyObject*, PyObject**);
-
-void import_c_lib(PyObject*);
-
-#endif
diff --git a/pandas/src/timeseries/c_tseries.c b/pandas/src/timeseries/c_tseries.c
deleted file mode 100644
index 46816cbd3..000000000
--- a/pandas/src/timeseries/c_tseries.c
+++ /dev/null
@@ -1,956 +0,0 @@
-#include "c_dates.h"
-#include "c_tseries.h"
-
-/* Helper function for TimeSeries_convert:
-    determine the size of the second dimension for the resulting
-    converted array */
-static long get_height(int fromFreq, int toFreq) {
-
-    int maxBusDaysPerYear, maxBusDaysPerQuarter, maxBusDaysPerMonth;
-    int maxDaysPerYear, maxDaysPerQuarter, maxDaysPerMonth;
-
-    int fromGroup = get_freq_group(fromFreq);
-    int toGroup = get_freq_group(toFreq);
-
-    if (fromGroup == FR_UND) { fromGroup = FR_DAY; }
-
-    maxBusDaysPerYear = 262;
-    maxBusDaysPerQuarter = 66;
-    maxBusDaysPerMonth = 23;
-
-    maxDaysPerYear = 366;
-    maxDaysPerQuarter = 92;
-    maxDaysPerMonth = 31;
-
-    switch(fromGroup)
-    {
-        case FR_ANN: return 1;
-        case FR_QTR:
-            switch(toGroup)
-            {
-                case FR_ANN: return 4;
-                default: return 1;
-            }
-        case FR_MTH: //monthly
-            switch(toGroup)
-            {
-                case FR_ANN: return 12;
-                case FR_QTR: return 3;
-                default: return 1;
-            }
-        case FR_WK: //weekly
-            switch(toGroup)
-            {
-                case FR_ANN: return 53;
-                case FR_QTR: return 13;
-                case FR_MTH: return 4;
-                default: return 1;
-            }
-        case FR_BUS: //business
-            switch(toGroup)
-            {
-                case FR_ANN: return maxBusDaysPerYear;;
-                case FR_QTR: return maxBusDaysPerQuarter;
-                case FR_MTH: return maxBusDaysPerMonth;
-                case FR_WK: return 5;
-                default: return 1;
-            }
-        case FR_DAY: //daily
-            switch(toGroup)
-            {
-                case FR_ANN: return maxDaysPerYear;;
-                case FR_QTR: return maxDaysPerQuarter;
-                case FR_MTH: return maxDaysPerMonth;
-                case FR_WK: return 7;
-                default: return 1;
-            }
-        case FR_HR: //hourly
-            switch(toGroup)
-            {
-                case FR_ANN: return 24 * maxDaysPerYear;;
-                case FR_QTR: return 24 * maxDaysPerQuarter;
-                case FR_MTH: return 24 * maxDaysPerMonth;
-                case FR_WK: return 24 * 7;
-                case FR_DAY: return 24;
-                case FR_BUS: return 24;
-                default: return 1;
-            }
-        case FR_MIN: //minutely
-            switch(toGroup)
-            {
-                case FR_ANN: return 24 * 60 * maxDaysPerYear;;
-                case FR_QTR: return 24 * 60 * maxDaysPerQuarter;
-                case FR_MTH: return 24 * 60 * maxDaysPerMonth;
-                case FR_WK: return 24 * 60 * 7;
-                case FR_DAY: return 24 * 60;
-                case FR_BUS: return 24 * 60;
-                case FR_HR: return 60;
-                default: return 1;
-            }
-        case FR_SEC: //minutely
-            switch(toGroup)
-            {
-                case FR_ANN: return 24 * 60 * 60 * maxDaysPerYear;;
-                case FR_QTR: return 24 * 60 * 60 * maxDaysPerQuarter;
-                case FR_MTH: return 24 * 60 * 60 * maxDaysPerMonth;
-                case FR_WK: return 24 * 60 * 60 * 7;
-                case FR_DAY: return 24 * 60 * 60;
-                case FR_BUS: return 24 * 60 * 60;
-                case FR_HR: return 60 * 60;
-                case FR_MIN: return 60;
-                default: return 1;
-            }
-        default: return 1;
-    }
-}
-
-PyObject *
-TimeSeries_convert(PyObject *self, PyObject *args)
-{
-    PyObject *arrayTest;
-    PyArrayObject *array, *newArray;
-    PyArrayObject *mask, *newMask;
-
-    PyObject *returnVal = NULL;
-    PyObject *start_index_retval;
-
-    long startIndex;
-    long newStart, newStartTemp;
-    long newEnd, newEndTemp;
-    long newLen, newHeight;
-    long currIndex, prevIndex;
-    long nd;
-    npy_intp *dim, *newIdx;
-    long currPerLen;
-    char *position;
-    PyObject *fromFreq_arg, *toFreq_arg;
-    int fromFreq, toFreq;
-    char relation;
-    asfreq_info af_info;
-    int i;
-
-    PyObject *val, *valMask;
-
-    long (*asfreq_main)(long, char, asfreq_info*) = NULL;
-    long (*asfreq_endpoints)(long, char, asfreq_info*) = NULL;
-    long (*asfreq_reverse)(long, char, asfreq_info*) = NULL;
-
-    returnVal = PyDict_New();
-
-    if (!PyArg_ParseTuple(args,
-        "OOOslO:convert(array, fromfreq, tofreq, position, startIndex, mask)",
-        &array, &fromFreq_arg, &toFreq_arg,
-        &position, &startIndex, &mask)) return NULL;
-
-    if((fromFreq = check_freq(fromFreq_arg)) == INT_ERR_CODE) return NULL;
-    if((toFreq = check_freq(toFreq_arg)) == INT_ERR_CODE) return NULL;
-
-    if (toFreq == fromFreq)
-    {
-        PyObject *sidx;
-        newArray = (PyArrayObject *)PyArray_Copy(array);
-        newMask = (PyArrayObject *)PyArray_Copy(mask);
-        sidx = PyInt_FromLong(startIndex);
-
-        PyDict_SetItemString(returnVal, "values", (PyObject*)newArray);
-        PyDict_SetItemString(returnVal, "mask", (PyObject*)newMask);
-        PyDict_SetItemString(returnVal, "startindex", sidx);
-
-        Py_DECREF(newArray);
-        Py_DECREF(newMask);
-        Py_DECREF(sidx);
-
-        return returnVal;
-    }
-
-    switch(position[0])
-    {
-        case 'S':
-            // start -> before
-            relation = 'S';
-            break;
-        case 'E':
-            // end -> after
-            relation = 'E';
-            break;
-        default:
-            return NULL;
-            break;
-    }
-
-    get_asfreq_info(fromFreq, toFreq, &af_info);
-
-    asfreq_main = get_asfreq_func(fromFreq, toFreq, 1);
-    asfreq_endpoints = get_asfreq_func(fromFreq, toFreq, 0);
-
-    //convert start index to new frequency
-    CHECK_ASFREQ(newStartTemp = asfreq_main(startIndex, 'S', &af_info));
-    if (newStartTemp < 1) {
-        CHECK_ASFREQ(newStart = asfreq_endpoints(startIndex, 'E', &af_info));
-    }
-    else { newStart = newStartTemp; }
-
-    //convert end index to new frequency
-    CHECK_ASFREQ(newEndTemp = asfreq_main(startIndex+array->dimensions[0]-1, 'E', &af_info));
-    if (newEndTemp < 1) {
-        CHECK_ASFREQ(newEnd = asfreq_endpoints(startIndex+array->dimensions[0]-1, 'S', &af_info));
-    }
-    else { newEnd = newEndTemp; }
-
-    if (newStart < 1) {
-        PyErr_SetString(PyExc_ValueError, "start_date outside allowable range for destination frequency");
-        return NULL;
-    }
-
-    newLen = newEnd - newStart + 1;
-    newHeight = get_height(fromFreq, toFreq);
-
-    if (newHeight > 1) {
-        long tempval;
-        asfreq_info af_info_rev;
-
-        get_asfreq_info(toFreq, fromFreq, &af_info_rev);
-        asfreq_reverse = get_asfreq_func(toFreq, fromFreq, 0);
-
-        CHECK_ASFREQ(tempval = asfreq_reverse(newStart, 'S', &af_info_rev));
-        currPerLen = startIndex - tempval;
-
-        nd = 2;
-        dim = PyDimMem_NEW(nd);
-        dim[0] = (npy_intp)newLen;
-        dim[1] = (npy_intp)newHeight;
-    } else {
-        nd = 1;
-        dim = PyDimMem_NEW(nd);
-        dim[0] = (npy_intp)newLen;
-    }
-
-    newIdx = PyDimMem_NEW(nd);
-    arrayTest = PyArray_SimpleNew(nd, dim, array->descr->type_num);
-    if (arrayTest == NULL) { return NULL; }
-    newArray = (PyArrayObject*)arrayTest;
-    newMask  = (PyArrayObject*)PyArray_SimpleNew(nd, dim, mask->descr->type_num);
-
-    PyDimMem_FREE(dim);
-
-    PyArray_FILLWBYTE(newArray,0);
-    PyArray_FILLWBYTE(newMask,1);
-
-    prevIndex = newStart;
-
-    //set values in the new array
-    for (i = 0; i < array->dimensions[0]; i++) {
-
-        npy_intp idx = (npy_intp)i;
-
-        val = PyArray_GETITEM(array, PyArray_GetPtr(array, &idx));
-        valMask = PyArray_GETITEM(mask, PyArray_GetPtr(mask, &idx));
-
-        CHECK_ASFREQ(currIndex = asfreq_main(startIndex + i, relation, &af_info));
-
-        newIdx[0] = (npy_intp)(currIndex-newStart);
-
-        if (newHeight > 1) {
-
-                if (currIndex != prevIndex)
-                {
-                    //reset period length
-                    currPerLen = 0;
-                    prevIndex = currIndex;
-                }
-
-                newIdx[1] = (npy_intp)currPerLen;
-                currPerLen++;
-        }
-
-        if (newIdx[0] > -1) {
-            PyArray_SETITEM(newArray, PyArray_GetPtr(newArray, newIdx), val);
-            PyArray_SETITEM(newMask, PyArray_GetPtr(newMask, newIdx), valMask);
-        }
-
-        Py_DECREF(val);
-        Py_DECREF(valMask);
-
-    }
-
-    PyDimMem_FREE(newIdx);
-
-    start_index_retval = (PyObject*)PyInt_FromLong(newStart);
-
-    PyDict_SetItemString(returnVal, "values", (PyObject*)newArray);
-    PyDict_SetItemString(returnVal, "mask", (PyObject*)newMask);
-    PyDict_SetItemString(returnVal, "startindex", start_index_retval);
-
-    Py_DECREF(newArray);
-    Py_DECREF(newMask);
-    Py_DECREF(start_index_retval);
-
-    return returnVal;
-}
-
-
-/* This function is directly copied from the numpy source  */
-/* Return typenumber from dtype2 unless it is NULL, then return
-   NPY_DOUBLE if dtype1->type_num is integer or bool
-   and dtype1->type_num otherwise.
-*/
-static int
-_get_type_num_double(PyArray_Descr *dtype1, PyArray_Descr *dtype2)
-{
-    if (dtype2 != NULL) {
-        return dtype2->type_num;
-    }
-
-    /* For integer or bool data-types */
-    if (dtype1->type_num < NPY_FLOAT) {
-        return NPY_DOUBLE;
-    }
-    else {
-        return dtype1->type_num;
-    }
-}
-
-static int
-_get_type_num(PyArray_Descr *dtype1, PyArray_Descr *dtype2)
-{
-    if (dtype2 != NULL) {
-        return dtype2->type_num;
-    } else {
-        return dtype1->type_num;
-    }
-}
-
-
-/* validates the standard arguments to moving functions and set the original
-   mask, original ndarray, and mask for the result */
-static PyObject *
-check_mov_args(
-    PyObject *orig_arrayobj, int span, int min_win_size,
-    PyObject **orig_ndarray, PyObject **orig_mask, PyObject **result_mask
-) {
-
-    PyArrayObject **orig_ndarray_tmp, **result_mask_tmp;
-    int *raw_result_mask;
-
-    if (!PyArray_Check(orig_arrayobj)) {
-        PyErr_SetString(PyExc_ValueError, "array must be a valid subtype of ndarray");
-        return NULL;
-    }
-
-    // check if array has a mask, and if that mask is an array
-    if (PyObject_HasAttrString(orig_arrayobj, "_mask")) {
-        PyObject *tempMask = PyObject_GetAttrString(orig_arrayobj, "_mask");
-        if (PyArray_Check(tempMask)) {
-            *orig_mask = PyArray_EnsureArray(tempMask);
-        } else {
-            Py_DECREF(tempMask);
-        }
-    }
-
-    *orig_ndarray = PyArray_EnsureArray(orig_arrayobj);
-    orig_ndarray_tmp = (PyArrayObject**)orig_ndarray;
-
-    if ((*orig_ndarray_tmp)->nd != 1) {
-        PyErr_SetString(PyExc_ValueError, "array must be 1 dimensional");
-        return NULL;
-    }
-
-    if (span < min_win_size) {
-        char *error_str;
-        error_str = PyArray_malloc(60 * sizeof(char));
-        MEM_CHECK(error_str)
-        sprintf(error_str,
-                "span must be greater than or equal to %i",
-                min_win_size);
-        PyErr_SetString(PyExc_ValueError, error_str);
-        free(error_str);
-        return NULL;
-    }
-
-    raw_result_mask = PyArray_malloc((*orig_ndarray_tmp)->dimensions[0] * sizeof(int));
-    MEM_CHECK(raw_result_mask)
-
-    {
-        PyArrayObject *orig_mask_tmp;
-        int i, valid_points=0, is_masked;
-
-        orig_mask_tmp = (PyArrayObject*)(*orig_mask);
-
-        for (i=0; i<((*orig_ndarray_tmp)->dimensions[0]); i++) {
-
-            npy_intp idx = (npy_intp)i;
-            is_masked=0;
-
-            if (*orig_mask != NULL) {
-                PyObject *valMask;
-                valMask = PyArray_GETITEM(orig_mask_tmp,
-                                          PyArray_GetPtr(orig_mask_tmp, &idx));
-                is_masked = (int)PyInt_AsLong(valMask);
-                Py_DECREF(valMask);
-            }
-
-            if (is_masked) {
-                valid_points=0;
-            } else {
-                if (valid_points < span) { valid_points += 1; }
-                if (valid_points < span) { is_masked = 1; }
-            }
-
-            raw_result_mask[i] = is_masked;
-        }
-    }
-
-    *result_mask = PyArray_SimpleNewFromData(
-                             1, (*orig_ndarray_tmp)->dimensions,
-                             PyArray_INT32, raw_result_mask);
-    MEM_CHECK(*result_mask)
-    result_mask_tmp = (PyArrayObject**)result_mask;
-    (*result_mask_tmp)->flags = ((*result_mask_tmp)->flags) | NPY_OWNDATA;
-    return 0;
-}
-
-// check if value at specified index is masked
-static int
-_is_masked(PyArrayObject *mask, npy_intp idx) {
-
-    if (mask != NULL) {
-        PyObject *val_mask;
-        int is_masked;
-
-        val_mask = PyArray_GETITEM(mask, PyArray_GetPtr(mask, &idx));
-        is_masked = (int)PyInt_AsLong(val_mask);
-        Py_DECREF(val_mask);
-        return is_masked;
-    } else {
-        return 0;
-    }
-
-}
-
-/* computation portion of moving sum. Appropriate mask is overlayed on top
-   afterwards */
-static PyObject*
-calc_mov_sum(
-    PyArrayObject *orig_ndarray, PyArrayObject *orig_mask, int span, int rtype)
-{
-    PyArrayObject *result_ndarray=NULL;
-    int i=0, non_masked=0;
-
-    result_ndarray = (PyArrayObject*)PyArray_ZEROS(
-                                       orig_ndarray->nd,
-                                       orig_ndarray->dimensions,
-                                       rtype, 0);
-    ERR_CHECK(result_ndarray)
-
-    for (i=0; i<orig_ndarray->dimensions[0]; i++) {
-
-        PyObject *val=NULL, *mov_sum_val=NULL;
-        npy_intp idx = (npy_intp)i;
-        int curr_val_masked;
-
-        curr_val_masked = _is_masked(orig_mask, idx);
-
-        val = PyArray_GETITEM(
-            orig_ndarray, PyArray_GetPtr(orig_ndarray, &idx));
-
-        if (curr_val_masked == 0) {
-            non_masked += 1;
-        } else {
-            non_masked = 0;
-        }
-
-        if (
-            ((i == 0) || (curr_val_masked == 1)) ||
-            ((i > 0) && (_is_masked(orig_mask, i-1) == 1))
-        ) {
-            // if current or previous value is masked, reset moving sum
-            mov_sum_val = val;
-        } else {
-            PyObject *mov_sum_prevval;
-
-            idx = (npy_intp)(i-1);
-            mov_sum_prevval= PyArray_GETITEM(result_ndarray,
-                                   PyArray_GetPtr(result_ndarray, &idx));
-            mov_sum_val = np_add(val, mov_sum_prevval);
-            Py_DECREF(mov_sum_prevval);
-            ERR_CHECK(mov_sum_val)
-
-            if (non_masked > span) {
-                PyObject *temp_val, *rem_val;
-                idx = (npy_intp)(i-span);
-
-                if (_is_masked(orig_mask, idx) == 0) {
-                    // don't subtract off old value if it was masked because it
-                    // is not included in moving sum
-
-                    temp_val = mov_sum_val;
-                    rem_val = PyArray_GETITEM(orig_ndarray,
-                                       PyArray_GetPtr(orig_ndarray, &idx));
-
-                    mov_sum_val = np_subtract(temp_val, rem_val);
-                    ERR_CHECK(mov_sum_val)
-
-                    Py_DECREF(temp_val);
-                    Py_DECREF(rem_val);
-                }
-            }
-        }
-
-        idx = (npy_intp)i;
-
-        PyArray_SETITEM(result_ndarray,
-                        PyArray_GetPtr(result_ndarray, &idx),
-                        mov_sum_val);
-
-        if (mov_sum_val != val) { Py_DECREF(val); }
-
-        Py_DECREF(mov_sum_val);
-    }
-
-    return (PyObject*)result_ndarray;
-
-}
-
-PyObject *
-MaskedArray_mov_sum(PyObject *self, PyObject *args, PyObject *kwds)
-{
-    PyObject *orig_arrayobj=NULL, *orig_ndarray=NULL, *orig_mask=NULL,
-             *result_ndarray=NULL, *result_mask=NULL,
-             *result_dict=NULL;
-    PyArray_Descr *dtype=NULL;
-
-    int rtype, span, type_num_double;
-
-    static char *kwlist[] = {"array", "span", "type_num_double", "dtype", NULL};
-
-    if (!PyArg_ParseTupleAndKeywords(args, kwds,
-                "Oii|O&:mov_sum(array, span, type_num_double , dtype)", kwlist,
-                &orig_arrayobj, &span, &type_num_double,
-                PyArray_DescrConverter2, &dtype)) return NULL;
-
-    check_mov_args(orig_arrayobj, span, 1,
-                   &orig_ndarray, &orig_mask, &result_mask);
-
-    if (type_num_double) {
-        /* if the moving sum is being used as an intermediate step in something
-        like a standard deviation calculation, etc... then _get_type_num_double
-        should be used to determine the appropriate return type. */
-        rtype = _get_type_num_double(((PyArrayObject*)orig_ndarray)->descr, dtype);
-    } else {
-        rtype = _get_type_num(((PyArrayObject*)orig_ndarray)->descr, dtype);
-    }
-
-    result_ndarray = calc_mov_sum(
-        (PyArrayObject*)orig_ndarray, (PyArrayObject*)orig_mask,
-        span, rtype
-    );
-    ERR_CHECK(result_ndarray)
-
-    result_dict = PyDict_New();
-    MEM_CHECK(result_dict)
-    PyDict_SetItemString(result_dict, "array", result_ndarray);
-    PyDict_SetItemString(result_dict, "mask", result_mask);
-
-    Py_DECREF(result_ndarray);
-    Py_DECREF(result_mask);
-    return result_dict;
-}
-
-PyObject*
-calc_mov_ranked(PyArrayObject *orig_ndarray, int span, int rtype, char rank_type)
-{
-    PyArrayObject *result_ndarray=NULL;
-    PyObject **result_array, **ref_array, **even_array=NULL;
-    PyObject *new_val, *old_val;
-    PyObject *temp_add, *one_half;
-    int a, i, k, R, arr_size, z;
-    int *r;
-    npy_intp idx;
-
-    arr_size = (int)(orig_ndarray->dimensions[0]);
-
-    result_ndarray = (PyArrayObject*)PyArray_ZEROS(
-                                       orig_ndarray->nd,
-                                       orig_ndarray->dimensions,
-                                       rtype, 0);
-    ERR_CHECK(result_ndarray)
-
-    if (arr_size >= span) {
-        result_array = calloc(arr_size, sizeof(PyObject*));
-        MEM_CHECK(result_array)
-
-        /* this array will be used for quick access to the data in the original
-           array (so PyArray_GETITEM doesn't have to be used over and over in the
-           main loop) */
-        ref_array = PyArray_malloc(arr_size * sizeof(PyObject*));
-        MEM_CHECK(ref_array)
-
-        for (i=0; i<arr_size; i++) {
-            idx = (npy_intp)i;
-            ref_array[i] = PyArray_GETITEM(orig_ndarray, PyArray_GetPtr(orig_ndarray, &idx));
-        }
-
-        /* this array wll be used for keeping track of the "ranks" of the values
-           in the current window */
-        r = PyArray_malloc(span * sizeof(int));
-        MEM_CHECK(r)
-
-        for (i=0; i < span; i++) {
-            r[i] = 1;
-        }
-
-        if (rank_type == 'E' && ((span % 2) == 0)) {
-            // array to store two median values when span is an even #
-            even_array = calloc(2, sizeof(PyObject*));
-            MEM_CHECK(even_array)
-        }
-
-		switch(rank_type) {
-			case 'E': // median
-				R = (span + 1)/2;
-				break;
-			case 'I': // min
-				R = 1;
-				break;
-			case 'A': // max
-				R = span;
-				break;
-			default:
-			{
-				PyErr_SetString(PyExc_RuntimeError, "unexpected rank type");
-		        return NULL;
-			}
-		}
-
-        one_half = PyFloat_FromDouble(0.5);
-
-        z = arr_size - span;
-
-        /* Calculate initial ranks "r" */
-        for (i=0; i < span; i++) {
-
-            for (k=0;   k < i;  k++) {
-                if (np_greater_equal(ref_array[z+i], ref_array[z+k])) {
-                    r[i]++;
-                }
-            }
-            for (k=i+1; k < span; k++) {
-                if (np_greater(ref_array[z+i], ref_array[z+k])) {
-                    r[i]++;
-                }
-            }
-
-            /* If rank=R, this is the median */
-            if (even_array != NULL) {
-                if (r[i]==R) {
-                    even_array[0] = ref_array[z+i];
-                } else if (r[i] == (R+1)) {
-                    even_array[1] = ref_array[z+i];
-                }
-            } else {
-                if (r[i]==R) {
-                    result_array[arr_size-1] = ref_array[z+i];
-                }
-            }
-        }
-
-        if (even_array != NULL) {
-            temp_add = np_add(even_array[0], even_array[1]);
-            result_array[arr_size-1] = np_multiply(temp_add, one_half);
-            Py_DECREF(temp_add);
-        }
-
-        for (i=arr_size-2; i >= span-1; i--) {
-            a = span;
-            z = i - span + 1;
-            old_val = ref_array[i+1];
-            new_val = ref_array[i-span+1];
-
-            for (k=span-1; k > 0; k--) {
-                r[k] = r[k-1]; /* Shift previous iteration's ranks */
-                if (np_greater_equal(ref_array[z+k], new_val)) {r[k]++; a--;}
-                if (np_greater(ref_array[z+k], old_val)) {r[k]--;}
-
-                if (r[k]==R) {
-                    result_array[i] = ref_array[z+k];
-                }
-
-                if (even_array != NULL) {
-                    if (r[k]==R) {
-                        even_array[0] = ref_array[z+k];
-                    } else if (r[k] == (R+1)) {
-                        even_array[1] = ref_array[z+k];
-                    }
-                } else {
-                    if (r[k]==R) {
-                        result_array[i] = ref_array[z+k];
-                    }
-                }
-
-            }
-
-            r[0] = a;
-
-            if (even_array != NULL) {
-                if (a==R) {
-                    even_array[0] = new_val;
-                } else if (a == (R+1)) {
-                    even_array[1] = new_val;
-                }
-
-                temp_add = np_add(even_array[0], even_array[1]);
-                result_array[i] = np_multiply(temp_add, one_half);;
-                Py_DECREF(temp_add);
-
-            } else {
-                if (a==R) {
-                    result_array[i] = new_val;
-                }
-            }
-
-        }
-
-        Py_DECREF(one_half);
-
-        for (i=span-1; i<arr_size; i++) {
-            idx = (npy_intp)i;
-            PyArray_SETITEM(result_ndarray,
-                            PyArray_GetPtr(result_ndarray, &idx),
-                            result_array[i]);
-        }
-
-        for (i=0; i<arr_size; i++) {
-            Py_DECREF(ref_array[i]);
-        }
-
-        if (even_array != NULL) {
-            for (i=span-1; i<arr_size; i++) {
-                Py_DECREF(result_array[i]);
-            }
-        }
-
-        free(ref_array);
-        free(result_array);
-    }
-
-    return (PyObject*)result_ndarray;
-
-}
-
-PyObject *
-MaskedArray_mov_median(PyObject *self, PyObject *args, PyObject *kwds)
-{
-    PyObject *orig_arrayobj=NULL, *orig_ndarray=NULL, *orig_mask=NULL,
-             *result_ndarray=NULL, *result_mask=NULL, *result_dict=NULL;
-    PyArray_Descr *dtype=NULL;
-
-    int rtype, span;
-
-    static char *kwlist[] = {"array", "span", "dtype", NULL};
-
-    if (!PyArg_ParseTupleAndKeywords(args, kwds,
-                "Oi|O&:mov_median(array, span, dtype)", kwlist,
-                &orig_arrayobj, &span,
-                PyArray_DescrConverter2, &dtype)) return NULL;
-
-    check_mov_args(orig_arrayobj, span, 1,
-                   &orig_ndarray, &orig_mask, &result_mask);
-
-    if ((span % 2) == 0) {
-        rtype = _get_type_num_double(((PyArrayObject*)orig_ndarray)->descr, dtype);
-    } else {
-        rtype = _get_type_num(((PyArrayObject*)orig_ndarray)->descr, dtype);
-    }
-
-    result_ndarray = calc_mov_ranked((PyArrayObject*)orig_ndarray,
-                                     span, rtype, 'E');
-    ERR_CHECK(result_ndarray)
-
-    result_dict = PyDict_New();
-    MEM_CHECK(result_dict)
-    PyDict_SetItemString(result_dict, "array", result_ndarray);
-    PyDict_SetItemString(result_dict, "mask", result_mask);
-
-    Py_DECREF(result_ndarray);
-    Py_DECREF(result_mask);
-    return result_dict;
-}
-
-PyObject *
-MaskedArray_mov_min(PyObject *self, PyObject *args, PyObject *kwds)
-{
-    PyObject *orig_arrayobj=NULL, *orig_ndarray=NULL, *orig_mask=NULL,
-             *result_ndarray=NULL, *result_mask=NULL, *result_dict=NULL;
-    PyArray_Descr *dtype=NULL;
-
-    int rtype, span;
-
-    static char *kwlist[] = {"array", "span", "dtype", NULL};
-
-    if (!PyArg_ParseTupleAndKeywords(args, kwds,
-                "Oi|O&:mov_min(array, span, dtype)", kwlist,
-                &orig_arrayobj, &span,
-                PyArray_DescrConverter2, &dtype)) return NULL;
-
-    check_mov_args(orig_arrayobj, span, 1,
-                   &orig_ndarray, &orig_mask, &result_mask);
-
-    rtype = _get_type_num(((PyArrayObject*)orig_ndarray)->descr, dtype);
-
-    result_ndarray = calc_mov_ranked((PyArrayObject*)orig_ndarray,
-                                     span, rtype, 'I');
-    ERR_CHECK(result_ndarray)
-
-    result_dict = PyDict_New();
-    MEM_CHECK(result_dict)
-    PyDict_SetItemString(result_dict, "array", result_ndarray);
-    PyDict_SetItemString(result_dict, "mask", result_mask);
-
-    Py_DECREF(result_ndarray);
-    Py_DECREF(result_mask);
-    return result_dict;
-}
-
-PyObject *
-MaskedArray_mov_max(PyObject *self, PyObject *args, PyObject *kwds)
-{
-    PyObject *orig_arrayobj=NULL, *orig_ndarray=NULL, *orig_mask=NULL,
-             *result_ndarray=NULL, *result_mask=NULL, *result_dict=NULL;
-    PyArray_Descr *dtype=NULL;
-
-    int rtype, span;
-
-    static char *kwlist[] = {"array", "span", "dtype", NULL};
-
-    if (!PyArg_ParseTupleAndKeywords(args, kwds,
-                "Oi|O&:mov_max(array, span, dtype)", kwlist,
-                &orig_arrayobj, &span,
-                PyArray_DescrConverter2, &dtype)) return NULL;
-
-    check_mov_args(orig_arrayobj, span, 1,
-                   &orig_ndarray, &orig_mask, &result_mask);
-
-    rtype = _get_type_num(((PyArrayObject*)orig_ndarray)->descr, dtype);
-
-    result_ndarray = calc_mov_ranked((PyArrayObject*)orig_ndarray,
-                                     span, rtype, 'A');
-    ERR_CHECK(result_ndarray)
-
-    result_dict = PyDict_New();
-    MEM_CHECK(result_dict)
-    PyDict_SetItemString(result_dict, "array", result_ndarray);
-    PyDict_SetItemString(result_dict, "mask", result_mask);
-
-    Py_DECREF(result_ndarray);
-    Py_DECREF(result_mask);
-    return result_dict;
-}
-
-/* computation portion of exponentially weighted moving average. Appropriate
-   mask is overlayed on top afterwards */
-static PyObject*
-calc_mov_average_expw(
-    PyArrayObject *orig_ndarray, PyArrayObject *orig_mask, int span, int rtype)
-{
-    PyArrayObject *result_ndarray=NULL;
-    PyObject *decay_factor=NULL;
-    int i=0, initialized=0;
-
-    result_ndarray = (PyArrayObject*)PyArray_ZEROS(
-                                       orig_ndarray->nd,
-                                       orig_ndarray->dimensions,
-                                       rtype, 0);
-    ERR_CHECK(result_ndarray)
-
-    decay_factor = PyFloat_FromDouble(2.0/((double)(span + 1)));
-
-    for (i=0; i<orig_ndarray->dimensions[0]; i++) {
-
-        PyObject *val=NULL, *mov_avg_val=NULL;
-        npy_intp idx = (npy_intp)i;
-        int curr_val_masked;
-
-        curr_val_masked = _is_masked(orig_mask, idx);
-
-        val = PyArray_GETITEM(
-            orig_ndarray, PyArray_GetPtr(orig_ndarray, &idx));
-
-        if (initialized == 0) {
-            mov_avg_val = val;
-            if (curr_val_masked == 0) {
-                initialized = 1;
-            }
-        } else {
-            PyObject *mov_avg_prevval, *temp_val_a, *temp_val_b;
-            idx = (npy_intp)(i-1);
-            mov_avg_prevval = PyArray_GETITEM(result_ndarray,
-                               PyArray_GetPtr(result_ndarray, &idx));
-
-            if (curr_val_masked == 0) {
-                temp_val_a = np_subtract(val, mov_avg_prevval);
-                temp_val_b = np_multiply(decay_factor, temp_val_a);
-                mov_avg_val = np_add(mov_avg_prevval, temp_val_b);
-
-                Py_DECREF(mov_avg_prevval);
-                Py_DECREF(temp_val_a);
-                Py_DECREF(temp_val_b);
-                ERR_CHECK(mov_avg_val);
-            } else {
-                mov_avg_val = mov_avg_prevval;
-            }
-        }
-
-        idx = (npy_intp)i;
-
-        PyArray_SETITEM(result_ndarray,
-                        PyArray_GetPtr(result_ndarray, &idx),
-                        mov_avg_val);
-
-        if (mov_avg_val != val) { Py_DECREF(val); }
-
-        Py_DECREF(mov_avg_val);
-    }
-
-    return (PyObject*)result_ndarray;
-
-}
-
-PyObject *
-MaskedArray_mov_average_expw(PyObject *self, PyObject *args, PyObject *kwds)
-{
-    PyObject *orig_arrayobj=NULL, *orig_ndarray=NULL, *orig_mask=NULL,
-             *result_ndarray=NULL, *result_mask=NULL,
-             *result_dict=NULL;
-    PyArray_Descr *dtype=NULL;
-
-    int rtype, span;
-
-    static char *kwlist[] = {"array", "span", "dtype", NULL};
-
-    if (!PyArg_ParseTupleAndKeywords(args, kwds,
-                "Oi|O&:mov_average_expw(array, span, dtype)", kwlist,
-                &orig_arrayobj, &span,
-                PyArray_DescrConverter2, &dtype)) return NULL;
-
-    // note: we do not actually use the "result_mask" in this case
-    check_mov_args(orig_arrayobj, span, 1,
-                   &orig_ndarray, &orig_mask, &result_mask);
-
-    rtype = _get_type_num_double(((PyArrayObject*)orig_ndarray)->descr, dtype);
-
-    result_ndarray = calc_mov_average_expw(
-        (PyArrayObject*)orig_ndarray, (PyArrayObject*)orig_mask,
-        span, rtype
-    );
-    ERR_CHECK(result_ndarray)
-
-    result_dict = PyDict_New();
-    MEM_CHECK(result_dict)
-    PyDict_SetItemString(result_dict, "array", result_ndarray);
-
-    Py_DECREF(result_ndarray);
-    Py_DECREF(result_mask);
-    return result_dict;
-}
-
-void import_c_tseries(PyObject *m) { import_array(); }
diff --git a/pandas/src/timeseries/c_tseries.h b/pandas/src/timeseries/c_tseries.h
deleted file mode 100644
index 282262e8c..000000000
--- a/pandas/src/timeseries/c_tseries.h
+++ /dev/null
@@ -1,16 +0,0 @@
-#ifndef C_TSERIES_H
-#define C_TSERIES_H
-
-#include "c_lib.h"
-
-PyObject *TimeSeries_convert(PyObject *, PyObject *);
-
-PyObject *MaskedArray_mov_sum(PyObject *, PyObject *, PyObject *);
-PyObject *MaskedArray_mov_median(PyObject *, PyObject *, PyObject *);
-PyObject *MaskedArray_mov_min(PyObject *, PyObject *, PyObject *);
-PyObject *MaskedArray_mov_max(PyObject *, PyObject *, PyObject *);
-PyObject *MaskedArray_mov_average_expw(PyObject *, PyObject *, PyObject *);
-
-void import_c_tseries(PyObject *);
-
-#endif
diff --git a/pandas/src/timeseries/cseries.c b/pandas/src/timeseries/cseries.c
deleted file mode 100644
index 876852d51..000000000
--- a/pandas/src/timeseries/cseries.c
+++ /dev/null
@@ -1,73 +0,0 @@
-#include "c_lib.h"
-#include "c_dates.h"
-#include "c_tseries.h"
-
-static PyMethodDef cseries_methods[] = {
-
-    {"MA_mov_sum", (PyCFunction)MaskedArray_mov_sum,
-     METH_VARARGS | METH_KEYWORDS, ""},
-    {"MA_mov_median", (PyCFunction)MaskedArray_mov_median,
-     METH_VARARGS | METH_KEYWORDS, ""},
-    {"MA_mov_min", (PyCFunction)MaskedArray_mov_min,
-     METH_VARARGS | METH_KEYWORDS, ""},
-    {"MA_mov_max", (PyCFunction)MaskedArray_mov_max,
-     METH_VARARGS | METH_KEYWORDS, ""},
-    {"MA_mov_average_expw", (PyCFunction)MaskedArray_mov_average_expw,
-     METH_VARARGS | METH_KEYWORDS, ""},
-
-    {"TS_convert", (PyCFunction)TimeSeries_convert,
-     METH_VARARGS, ""},
-
-    {"DA_asfreq", (PyCFunction)DateArray_asfreq,
-     METH_VARARGS, ""},
-    {"DA_getDateInfo", (PyCFunction)DateArray_getDateInfo,
-     METH_VARARGS, ""},
-
-
-    {"now", (PyCFunction)c_dates_now,
-     METH_VARARGS,
-        "now(freq)\n"
-        "\n"
-        "Returns the current date/time, at the given frequency\n"
-        "\n"
-        "Parameters\n"
-        "----------\n"
-        "freq : {freq_spec}\n"
-        "   Frequency to convert the Date to. Accepts any valid frequency\n"
-        "   specification (string or integer)\n"},
-
-    {"check_freq", (PyCFunction)c_dates_check_freq,
-     METH_VARARGS,
-        "Translates a user specified frequency into the corresponding frequency constant"},
-
-    {"check_freq_str", (PyCFunction)c_dates_check_freq_str,
-     METH_VARARGS,
-        "Translates a user specified frequency into standard string representation"},
-
-    {"get_freq_group", (PyCFunction)c_dates_get_freq_group,
-     METH_VARARGS,
-        "translate user specified frequency into frequency group constant"},
-
-
-    {"set_callback_DateFromString", (PyCFunction)set_callback_DateFromString,
-     METH_VARARGS, ""},
-    {"set_callback_DateTimeFromString", (PyCFunction)set_callback_DateTimeFromString,
-     METH_VARARGS, ""},
-
-    {NULL, NULL}
-};
-
-PyMODINIT_FUNC
-init_skts(void)
-{
-    PyObject *m;
-
-    m = Py_InitModule("pandas._skts", cseries_methods);
-    if (m == NULL)
-      return;
-
-    import_c_lib(m);
-    import_c_dates(m);
-    import_c_tseries(m);
-
-}
diff --git a/pandas/timeseries/__init__.py b/pandas/timeseries/__init__.py
deleted file mode 100644
index 771d27be3..000000000
--- a/pandas/timeseries/__init__.py
+++ /dev/null
@@ -1,30 +0,0 @@
-"""TimeSeries
-
-:author: Pierre GF Gerard-Marchant & Matt Knox
-:contact: pierregm_at_uga_dot_edu - mattknox_ca_at_hotmail_dot_com
-:version: $Id$
-"""
-
-
-__author__ = "Pierre GF Gerard-Marchant  & Matt Knox ($Author$)"
-__revision__ = "$Revision$"
-__date__     = '$Date$'
-
-import const
-import tdates
-from tdates import *
-import tseries
-from tseries import *
-import trecords
-from trecords import *
-_c = const
-from extras import tsfromtxt, guess_freq
-
-__all__ = [
-    '_c', 'const', 'tdates','tseries','trecords', 'tsfromtxt', 'guess_freq']
-__all__.extend(tdates.__all__)
-__all__.extend(tseries.__all__)
-__all__.extend(trecords.__all__)
-
-from numpy.testing import Tester
-test = Tester().test
diff --git a/pandas/timeseries/_preview.py b/pandas/timeseries/_preview.py
deleted file mode 100644
index 7647b7146..000000000
--- a/pandas/timeseries/_preview.py
+++ /dev/null
@@ -1,1387 +0,0 @@
-"""
-This file contains local copies of functions to be released in numpy 1.4.0.
-Once we drop support for numpy 1.3.x we can eliminate this file.
-"""
-
-__all__ = ['genfromtxt']
-
-import itertools
-import warnings
-from operator import itemgetter
-from __builtin__ import bool, int, long, float, complex, object, unicode, str
-
-import numpy as np
-import numpy.core.numeric as nx
-
-#####--------------------------------------------------------------------------
-#---- numpy.lib._iotools functions ---
-#####--------------------------------------------------------------------------
-
-def _is_string_like(obj):
-    """
-    Check whether obj behaves like a string.
-    """
-    try:
-        obj + ''
-    except (TypeError, ValueError):
-        return False
-    return True
-
-
-def _to_filehandle(fname, flag='r', return_opened=False):
-    """
-    Returns the filehandle corresponding to a string or a file.
-    If the string ends in '.gz', the file is automatically unzipped.
-
-    Parameters
-    ----------
-    fname : string, filehandle
-        Name of the file whose filehandle must be returned.
-    flag : string, optional
-        Flag indicating the status of the file ('r' for read, 'w' for write).
-    return_opened : boolean, optional
-        Whether to return the opening status of the file.
-    """
-    if _is_string_like(fname):
-        if fname.endswith('.gz'):
-            import gzip
-            fhd = gzip.open(fname, flag)
-        elif fname.endswith('.bz2'):
-            import bz2
-            fhd = bz2.BZ2File(fname)
-        else:
-            fhd = file(fname, flag)
-        opened = True
-    elif hasattr(fname, 'seek'):
-        fhd = fname
-        opened = False
-    else:
-        raise ValueError('fname must be a string or file handle')
-    if return_opened:
-        return fhd, opened
-    return fhd
-
-
-def has_nested_fields(ndtype):
-    """
-    Returns whether one or several fields of a dtype are nested.
-
-    Parameters
-    ----------
-    ndtype : dtype
-        Data-type of a structured array.
-
-    Raises
-    ------
-    AttributeError : If `ndtype` does not have a `names` attribute.
-
-    Examples
-    --------
-    >>> dt = np.dtype([('name', 'S4'), ('x', float), ('y', float)])
-    >>> np.lib._iotools.has_nested_fields(dt)
-    False
-
-    """
-    for name in ndtype.names or ():
-        if ndtype[name].names:
-            return True
-    return False
-
-
-def flatten_dtype(ndtype, flatten_base=False):
-    """
-    Unpack a structured data-type by collapsing nested fields and/or fields
-    with a shape.
-
-    Note that the field names are lost.
-
-    Parameters
-    ----------
-    ndtype : dtype
-        The datatype to collapse
-    flatten_base : {False, True}, optional
-        Whether to transform a field with a shape into several fields or not.
-
-    Examples
-    --------
-    >>> dt = np.dtype([('name', 'S4'), ('x', float), ('y', float),
-    ...                ('block', int, (2, 3))])
-    >>> np.lib._iotools.flatten_dtype(dt)
-    [dtype('|S4'), dtype('float64'), dtype('float64'), dtype('int32')]
-    >>> np.lib._iotools.flatten_dtype(dt, flatten_base=True)
-    [dtype('|S4'), dtype('float64'), dtype('float64'), dtype('int32'),
-     dtype('int32'), dtype('int32'), dtype('int32'), dtype('int32'),
-     dtype('int32')]
-
-    """
-    names = ndtype.names
-    if names is None:
-        if flatten_base:
-            return [ndtype.base] * int(np.prod(ndtype.shape))
-        return [ndtype.base]
-    else:
-        types = []
-        for field in names:
-            (typ, _) = ndtype.fields[field]
-            flat_dt = flatten_dtype(typ, flatten_base)
-            types.extend(flat_dt)
-        return types
-
-
-
-
-
-
-class LineSplitter:
-    """
-    Object to split a string at a given delimiter or at given places.
-
-    Parameters
-    ----------
-    delimiter : str, int, or sequence of ints, optional
-        If a string, character used to delimit consecutive fields.
-        If an integer or a sequence of integers, width(s) of each field.
-    comment : str, optional
-        Character used to mark the beginning of a comment. Default is '#'.
-    autostrip : bool, optional
-        Whether to strip each individual field. Default is True.
-
-    """
-
-    def autostrip(self, method):
-        """
-        Wrapper to strip each member of the output of `method`.
-
-        Parameters
-        ----------
-        method : function
-            Function that takes a single argument and returns a sequence of
-            strings.
-
-        Returns
-        -------
-        wrapped : function
-            The result of wrapping `method`. `wrapped` takes a single input
-            argument and returns a list of strings that are stripped of
-            white-space.
-
-        """
-        return lambda input: [_.strip() for _ in method(input)]
-    #
-    def __init__(self, delimiter=None, comments='#', autostrip=True):
-        self.comments = comments
-        # Delimiter is a character
-        if (delimiter is None) or _is_string_like(delimiter):
-            delimiter = delimiter or None
-            _handyman = self._delimited_splitter
-        # Delimiter is a list of field widths
-        elif hasattr(delimiter, '__iter__'):
-            _handyman = self._variablewidth_splitter
-            idx = np.cumsum([0] + list(delimiter))
-            delimiter = [slice(i, j) for (i, j) in zip(idx[:-1], idx[1:])]
-        # Delimiter is a single integer
-        elif int(delimiter):
-            (_handyman, delimiter) = (self._fixedwidth_splitter, int(delimiter))
-        else:
-            (_handyman, delimiter) = (self._delimited_splitter, None)
-        self.delimiter = delimiter
-        if autostrip:
-            self._handyman = self.autostrip(_handyman)
-        else:
-            self._handyman = _handyman
-    #
-    def _delimited_splitter(self, line):
-        line = line.split(self.comments)[0].strip()
-        if not line:
-            return []
-        return line.split(self.delimiter)
-    #
-    def _fixedwidth_splitter(self, line):
-        line = line.split(self.comments)[0]
-        if not line:
-            return []
-        fixed = self.delimiter
-        slices = [slice(i, i + fixed) for i in range(len(line))[::fixed]]
-        return [line[s] for s in slices]
-    #
-    def _variablewidth_splitter(self, line):
-        line = line.split(self.comments)[0]
-        if not line:
-            return []
-        slices = self.delimiter
-        return [line[s] for s in slices]
-    #
-    def __call__(self, line):
-        return self._handyman(line)
-
-
-
-class NameValidator:
-    """
-    Object to validate a list of strings to use as field names.
-
-    The strings are stripped of any non alphanumeric character, and spaces
-    are replaced by '_'. During instantiation, the user can define a list of
-    names to exclude, as well as a list of invalid characters. Names in the
-    exclusion list are appended a '_' character.
-
-    Once an instance has been created, it can be called with a list of names,
-    and a list of valid names will be created.
-    The `__call__` method accepts an optional keyword "default" that sets
-    the default name in case of ambiguity. By default this is 'f', so
-    that names will default to `f0`, `f1`, etc.
-
-    Parameters
-    ----------
-    excludelist : sequence, optional
-        A list of names to exclude. This list is appended to the default list
-        ['return', 'file', 'print']. Excluded names are appended an underscore:
-        for example, `file` becomes `file_` if supplied.
-    deletechars : str, optional
-        A string combining invalid characters that must be deleted from the
-        names.
-    casesensitive : {True, False, 'upper', 'lower'}, optional
-        * If True, field names are case-sensitive.
-        * If False or 'upper', field names are converted to upper case.
-        * If 'lower', field names are converted to lower case.
-
-        The default value is True.
-
-    Notes
-    -----
-    Calling an instance of `NameValidator` is the same as calling its method
-    `validate`.
-
-    Examples
-    --------
-    >>> validator = np.lib._iotools.NameValidator()
-    >>> validator(['file', 'field2', 'with space', 'CaSe'])
-    ['file_', 'field2', 'with_space', 'CaSe']
-
-    >>> validator = np.lib._iotools.NameValidator(excludelist=['excl'],
-                                                  deletechars='q',
-                                                  case_sensitive='False')
-    >>> validator(['excl', 'field2', 'no_q', 'with space', 'CaSe'])
-    ['excl_', 'field2', 'no_', 'with_space', 'case']
-
-    """
-    #
-    defaultexcludelist = ['return', 'file', 'print']
-    defaultdeletechars = set("""~!@#$%^&*()-=+~\|]}[{';: /?.>,<""")
-    #
-    def __init__(self, excludelist=None, deletechars=None, case_sensitive=None):
-        # Process the exclusion list ..
-        if excludelist is None:
-            excludelist = []
-        excludelist.extend(self.defaultexcludelist)
-        self.excludelist = excludelist
-        # Process the list of characters to delete
-        if deletechars is None:
-            delete = self.defaultdeletechars
-        else:
-            delete = set(deletechars)
-        delete.add('"')
-        self.deletechars = delete
-        # Process the case option .....
-        if (case_sensitive is None) or (case_sensitive is True):
-            self.case_converter = lambda x: x
-        elif (case_sensitive is False) or ('u' in case_sensitive):
-            self.case_converter = lambda x: x.upper()
-        elif 'l' in case_sensitive:
-            self.case_converter = lambda x: x.lower()
-        else:
-            self.case_converter = lambda x: x
-
-    def validate(self, names, defaultfmt="f%i", nbfields=None):
-        """
-        Validate a list of strings to use as field names for a structured array.
-
-        Parameters
-        ----------
-        names : sequence of str
-            Strings to be validated.
-        defaultfmt : str, optional
-            Default format string, used if validating a given string reduces its
-            length to zero.
-        nboutput : integer, optional
-            Final number of validated names, used to expand or shrink the initial
-            list of names.
-
-        Returns
-        -------
-        validatednames : list of str
-            The list of validated field names.
-
-        Notes
-        -----
-        A `NameValidator` instance can be called directly, which is the same as
-        calling `validate`. For examples, see `NameValidator`.
-
-        """
-        # Initial checks ..............
-        if (names is None):
-            if (nbfields is None):
-                return None
-            names = []
-        if isinstance(names, basestring):
-            names = [names, ]
-        if nbfields is not None:
-            nbnames = len(names)
-            if (nbnames < nbfields):
-                names = list(names) + [''] * (nbfields - nbnames)
-            elif (nbnames > nbfields):
-                names = names[:nbfields]
-        # Set some shortcuts ...........
-        deletechars = self.deletechars
-        excludelist = self.excludelist
-        case_converter = self.case_converter
-        # Initializes some variables ...
-        validatednames = []
-        seen = dict()
-        nbempty = 0
-        #
-        for item in names:
-            item = case_converter(item)
-            item = item.strip().replace(' ', '_')
-            item = ''.join([c for c in item if c not in deletechars])
-            if item == '':
-                item = defaultfmt % nbempty
-                while item in names:
-                    nbempty += 1
-                    item = defaultfmt % nbempty
-                nbempty += 1
-            elif item in excludelist:
-                item += '_'
-            cnt = seen.get(item, 0)
-            if cnt > 0:
-                validatednames.append(item + '_%d' % cnt)
-            else:
-                validatednames.append(item)
-            seen[item] = cnt + 1
-        return tuple(validatednames)
-    #
-    def __call__(self, names, defaultfmt="f%i", nbfields=None):
-        return self.validate(names, defaultfmt=defaultfmt, nbfields=nbfields)
-
-
-
-def str2bool(value):
-    """
-    Tries to transform a string supposed to represent a boolean to a boolean.
-
-    Parameters
-    ----------
-    value : str
-        The string that is transformed to a boolean.
-
-    Returns
-    -------
-    boolval : bool
-        The boolean representation of `value`.
-
-    Raises
-    ------
-    ValueError
-        If the string is not 'True' or 'False' (case independent)
-
-    Examples
-    --------
-    >>> np.lib._iotools.str2bool('TRUE')
-    True
-    >>> np.lib._iotools.str2bool('false')
-    False
-
-    """
-    value = value.upper()
-    if value == 'TRUE':
-        return True
-    elif value == 'FALSE':
-        return False
-    else:
-        raise ValueError("Invalid boolean")
-
-
-class ConverterError(Exception):
-    """
-    Exception raised when an error occurs in a converter for string values.
-
-    """
-    pass
-
-class ConverterLockError(ConverterError):
-    """
-    Exception raised when an attempt is made to upgrade a locked converter.
-
-    """
-    pass
-
-class ConversionWarning(UserWarning):
-    """
-    Warning issued when a string converter has a problem.
-
-    Notes
-    -----
-    In `genfromtxt` a `ConversionWarning` is issued if raising exceptions
-    is explicitly suppressed with the "invalid_raise" keyword.
-
-    """
-    pass
-
-
-
-class StringConverter:
-    """
-    Factory class for function transforming a string into another object (int,
-    float).
-
-    After initialization, an instance can be called to transform a string
-    into another object. If the string is recognized as representing a missing
-    value, a default value is returned.
-
-    Attributes
-    ----------
-    func : function
-        Function used for the conversion.
-    default : any
-        Default value to return when the input corresponds to a missing value.
-    type : type
-        Type of the output.
-    _status : int
-        Integer representing the order of the conversion.
-    _mapper : sequence of tuples
-        Sequence of tuples (dtype, function, default value) to evaluate in
-        order.
-    _locked : bool
-        Holds `locked` parameter.
-
-    Parameters
-    ----------
-    dtype_or_func : {None, dtype, function}, optional
-        If a `dtype`, specifies the input data type, used to define a basic
-        function and a default value for missing data. For example, when
-        `dtype` is float, the `func` attribute is set to `float` and the
-        default value to `np.nan`.
-        If a function, this function is used to convert a string to another
-        object. In this case, it is recommended to give an associated default
-        value as input.
-    default : any, optional
-        Value to return by default, that is, when the string to be converted
-        is flagged as missing. If not given, `StringConverter` tries to supply
-        a reasonable default value.
-    missing_values : sequence of str, optional
-        Sequence of strings indicating a missing value.
-    locked : bool, optional
-        Whether the StringConverter should be locked to prevent automatic
-        upgrade or not. Default is False.
-
-    """
-    #
-    _mapper = [(nx.bool_, str2bool, False),
-               (nx.integer, int, -1),
-               (nx.floating, float, nx.nan),
-               (complex, complex, nx.nan + 0j),
-               (nx.string_, str, '???')]
-    (_defaulttype, _defaultfunc, _defaultfill) = zip(*_mapper)
-    #
-    @classmethod
-    def _getsubdtype(cls, val):
-        """Returns the type of the dtype of the input variable."""
-        return np.array(val).dtype.type
-    #
-    @classmethod
-    def upgrade_mapper(cls, func, default=None):
-        """
-    Upgrade the mapper of a StringConverter by adding a new function and its
-    corresponding default.
-
-    The input function (or sequence of functions) and its associated default
-    value (if any) is inserted in penultimate position of the mapper.
-    The corresponding type is estimated from the dtype of the default value.
-
-    Parameters
-    ----------
-    func : var
-        Function, or sequence of functions
-
-    Examples
-    --------
-    >>> import dateutil.parser
-    >>> import datetime
-    >>> dateparser = datetustil.parser.parse
-    >>> defaultdate = datetime.date(2000, 1, 1)
-    >>> StringConverter.upgrade_mapper(dateparser, default=defaultdate)
-        """
-        # Func is a single functions
-        if hasattr(func, '__call__'):
-            cls._mapper.insert(-1, (cls._getsubdtype(default), func, default))
-            return
-        elif hasattr(func, '__iter__'):
-            if isinstance(func[0], (tuple, list)):
-                for _ in func:
-                    cls._mapper.insert(-1, _)
-                return
-            if default is None:
-                default = [None] * len(func)
-            else:
-                default = list(default)
-                default.append([None] * (len(func) - len(default)))
-            for (fct, dft) in zip(func, default):
-                cls._mapper.insert(-1, (cls._getsubdtype(dft), fct, dft))
-    #
-    def __init__(self, dtype_or_func=None, default=None, missing_values=None,
-                 locked=False):
-        # Defines a lock for upgrade
-        self._locked = bool(locked)
-        # No input dtype: minimal initialization
-        if dtype_or_func is None:
-            self.func = str2bool
-            self._status = 0
-            self.default = default or False
-            ttype = np.bool
-        else:
-            # Is the input a np.dtype ?
-            try:
-                self.func = None
-                ttype = np.dtype(dtype_or_func).type
-            except TypeError:
-                # dtype_or_func must be a function, then
-                if not hasattr(dtype_or_func, '__call__'):
-                    errmsg = "The input argument `dtype` is neither a function"\
-                             " or a dtype (got '%s' instead)"
-                    raise TypeError(errmsg % type(dtype_or_func))
-                # Set the function
-                self.func = dtype_or_func
-                # If we don't have a default, try to guess it or set it to None
-                if default is None:
-                    try:
-                        default = self.func('0')
-                    except ValueError:
-                        default = None
-                ttype = self._getsubdtype(default)
-            # Set the status according to the dtype
-            _status = -1
-            for (i, (deftype, func, default_def)) in enumerate(self._mapper):
-                if np.issubdtype(ttype, deftype):
-                    _status = i
-                    if default is None:
-                        self.default = default_def
-                    else:
-                        self.default = default
-                    break
-            if _status == -1:
-                # We never found a match in the _mapper...
-                _status = 0
-                self.default = default
-            self._status = _status
-            # If the input was a dtype, set the function to the last we saw
-            if self.func is None:
-                self.func = func
-            # If the status is 1 (int), change the function to smthg more robust
-            if self.func == self._mapper[1][1]:
-                self.func = lambda x : int(float(x))
-        # Store the list of strings corresponding to missing values.
-        if missing_values is None:
-            self.missing_values = set([''])
-        else:
-            if isinstance(missing_values, basestring):
-                missing_values = missing_values.split(",")
-            self.missing_values = set(list(missing_values) + [''])
-        #
-        self._callingfunction = self._strict_call
-        self.type = ttype
-        self._checked = False
-        self._initial_default = default
-    #
-    def _loose_call(self, value):
-        try:
-            return self.func(value)
-        except ValueError:
-            return self.default
-    #
-    def _strict_call(self, value):
-        try:
-            return self.func(value)
-        except ValueError:
-            if value.strip() in self.missing_values:
-                if not self._status:
-                    self._checked = False
-                return self.default
-            raise ValueError("Cannot convert string '%s'" % value)
-    #
-    def __call__(self, value):
-        return self._callingfunction(value)
-    #
-    def upgrade(self, value):
-        """
-        Try to find the best converter for a given string, and return the result.
-
-        The supplied string `value` is converted by testing different
-        converters in order. First the `func` method of the `StringConverter`
-        instance is tried, if this fails other available converters are tried.
-        The order in which these other converters are tried is determined by the
-        `_status` attribute of the instance.
-
-        Parameters
-        ----------
-        value : str
-            The string to convert.
-
-        Returns
-        -------
-        out : any
-            The result of converting `value` with the appropriate converter.
-
-        """
-        self._checked = True
-        try:
-            self._strict_call(value)
-        except ValueError:
-            # Raise an exception if we locked the converter...
-            if self._locked:
-                errmsg = "Converter is locked and cannot be upgraded"
-                raise ConverterLockError(errmsg)
-            _statusmax = len(self._mapper)
-            # Complains if we try to upgrade by the maximum
-            _status = self._status
-            if _status == _statusmax:
-                errmsg = "Could not find a valid conversion function"
-                raise ConverterError(errmsg)
-            elif _status < _statusmax - 1:
-                _status += 1
-            (self.type, self.func, default) = self._mapper[_status]
-            self._status = _status
-            if self._initial_default is not None:
-                self.default = self._initial_default
-            else:
-                self.default = default
-            self.upgrade(value)
-
-    def iterupgrade(self, value):
-        self._checked = True
-        if not hasattr(value, '__iter__'):
-            value = (value,)
-        _strict_call = self._strict_call
-        try:
-            map(_strict_call, value)
-        except ValueError:
-            # Raise an exception if we locked the converter...
-            if self._locked:
-                errmsg = "Converter is locked and cannot be upgraded"
-                raise ConverterLockError(errmsg)
-            _statusmax = len(self._mapper)
-            # Complains if we try to upgrade by the maximum
-            _status = self._status
-            if _status == _statusmax:
-                raise ConverterError("Could not find a valid conversion function")
-            elif _status < _statusmax - 1:
-                _status += 1
-            (self.type, self.func, default) = self._mapper[_status]
-            if self._initial_default is not None:
-                self.default = self._initial_default
-            else:
-                self.default = default
-            self._status = _status
-            self.iterupgrade(value)
-
-    def update(self, func, default=None, missing_values='', locked=False):
-        """
-        Set StringConverter attributes directly.
-
-        Parameters
-        ----------
-        func : function
-            Conversion function.
-        default : any, optional
-            Value to return by default, that is, when the string to be converted
-            is flagged as missing. If not given, `StringConverter` tries to supply
-            a reasonable default value.
-        missing_values : sequence of str, optional
-            Sequence of strings indicating a missing value.
-        locked : bool, optional
-            Whether the StringConverter should be locked to prevent automatic
-            upgrade or not. Default is False.
-
-        Notes
-        -----
-        `update` takes the same parameters as the constructor of `StringConverter`,
-        except that `func` does not accept a `dtype` whereas `dtype_or_func` in
-        the constructor does.
-
-        """
-        self.func = func
-        self._locked = locked
-        # Don't reset the default to None if we can avoid it
-        if default is not None:
-            self.default = default
-            self.type = self._getsubdtype(default)
-        else:
-            try:
-                tester = func('1')
-            except (TypeError, ValueError):
-                tester = None
-            self.type = self._getsubdtype(tester)
-        # Add the missing values to the existing set
-        if missing_values is not None:
-            if _is_string_like(missing_values):
-                self.missing_values.add(missing_values)
-            elif hasattr(missing_values, '__iter__'):
-                for val in missing_values:
-                    self.missing_values.add(val)
-        else:
-            self.missing_values = []
-
-
-
-def easy_dtype(ndtype, names=None, defaultfmt="f%i", **validationargs):
-    """
-    Convenience function to create a `np.dtype` object.
-
-    The function processes the input `dtype` and matches it with the given
-    names.
-
-    Parameters
-    ----------
-    ndtype : var
-        Definition of the dtype. Can be any string or dictionary
-        recognized by the `np.dtype` function, or a sequence of types.
-    names : str or sequence, optional
-        Sequence of strings to use as field names for a structured dtype.
-        For convenience, `names` can be a string of a comma-separated list of
-        names.
-    defaultfmt : str, optional
-        Format string used to define missing names, such as ``"f%i"``
-        (default) or ``"fields_%02i"``.
-    validationargs : optional
-        A series of optional arguments used to initialize a `NameValidator`.
-
-    Examples
-    --------
-    >>> np.lib._iotools.easy_dtype(float)
-    dtype('float64')
-    >>> np.lib._iotools.easy_dtype("i4, f8")
-    dtype([('f0', '<i4'), ('f1', '<f8')])
-    >>> np.lib._iotools.easy_dtype("i4, f8", defaultfmt="field_%03i")
-    dtype([('field_000', '<i4'), ('field_001', '<f8')])
-
-    >>> np.lib._iotools.easy_dtype((int, float, float), names="a,b,c")
-    dtype([('a', '<i8'), ('b', '<f8'), ('c', '<f8')])
-    >>> np.lib._iotools.easy_dtype(float, names="a,b,c")
-    dtype([('a', '<f8'), ('b', '<f8'), ('c', '<f8')])
-
-    """
-    try:
-        ndtype = np.dtype(ndtype)
-    except TypeError:
-        validate = NameValidator(**validationargs)
-        nbfields = len(ndtype)
-        if names is None:
-            names = [''] * len(ndtype)
-        elif isinstance(names, basestring):
-            names = names.split(",")
-        names = validate(names, nbfields=nbfields, defaultfmt=defaultfmt)
-        ndtype = np.dtype(dict(formats=ndtype, names=names))
-    else:
-        nbtypes = len(ndtype)
-        # Explicit names
-        if names is not None:
-            validate = NameValidator(**validationargs)
-            if isinstance(names, basestring):
-                names = names.split(",")
-            # Simple dtype: repeat to match the nb of names
-            if nbtypes == 0:
-                formats = tuple([ndtype.type] * len(names))
-                names = validate(names, defaultfmt=defaultfmt)
-                ndtype = np.dtype(zip(names, formats))
-            # Structured dtype: just validate the names as needed
-            else:
-                ndtype.names = validate(names, nbfields=nbtypes,
-                                        defaultfmt=defaultfmt)
-        # No implicit names
-        elif (nbtypes > 0):
-            validate = NameValidator(**validationargs)
-            # Default initial names : should we change the format ?
-            if (ndtype.names == tuple("f%i" % i for i in range(nbtypes))) and \
-               (defaultfmt != "f%i"):
-                ndtype.names = validate([''] * nbtypes, defaultfmt=defaultfmt)
-            # Explicit initial names : just validate
-            else:
-                ndtype.names = validate(ndtype.names, defaultfmt=defaultfmt)
-    return ndtype
-
-
-#####--------------------------------------------------------------------------
-#---- numpy.lib.io functions ---
-#####--------------------------------------------------------------------------
-
-_string_like = _is_string_like
-
-def genfromtxt(fname, dtype=float, comments='#', delimiter=None,
-               skiprows=0, skip_header=0, skip_footer=0, converters=None,
-               missing='', missing_values=None, filling_values=None,
-               usecols=None, names=None, excludelist=None, deletechars=None,
-               autostrip=False, case_sensitive=True, defaultfmt="f%i",
-               unpack=None, usemask=False, loose=True, invalid_raise=True):
-    """
-    Load data from a text file, with missing values handled as specified.
-
-    Each line past the first `skiprows` lines is split at the `delimiter`
-    character, and characters following the `comments` character are discarded.
-
-    Parameters
-    ----------
-    fname : file or str
-        File or filename to read.  If the filename extension is `.gz` or
-        `.bz2`, the file is first decompressed.
-    dtype : dtype, optional
-        Data type of the resulting array.
-        If None, the dtypes will be determined by the contents of each
-        column, individually.
-    comments : str, optional
-        The character used to indicate the start of a comment.
-        All the characters occurring on a line after a comment are discarded
-    delimiter : str, int, or sequence, optional
-        The string used to separate values.  By default, any consecutive
-        whitespaces act as delimiter.  An integer or sequence of integers
-        can also be provided as width(s) of each field.
-    skip_header : int, optional
-        The numbers of lines to skip at the beginning of the file.
-    skip_footer : int, optional
-        The numbers of lines to skip at the end of the file
-    converters : variable or None, optional
-        The set of functions that convert the data of a column to a value.
-        The converters can also be used to provide a default value
-        for missing data: ``converters = {3: lambda s: float(s or 0)}``.
-    missing_values : variable or None, optional
-        The set of strings corresponding to missing data.
-    filling_values : variable or None, optional
-        The set of values to be used as default when the data are missing.
-    usecols : sequence or None, optional
-        Which columns to read, with 0 being the first.  For example,
-        ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns.
-    names : {None, True, str, sequence}, optional
-        If `names` is True, the field names are read from the first valid line
-        after the first `skiprows` lines.
-        If `names` is a sequence or a single-string of comma-separated names,
-        the names will be used to define the field names in a structured dtype.
-        If `names` is None, the names of the dtype fields will be used, if any.
-    excludelist : sequence, optional
-        A list of names to exclude. This list is appended to the default list
-        ['return','file','print']. Excluded names are appended an underscore:
-        for example, `file` would become `file_`.
-    deletechars : str, optional
-        A string combining invalid characters that must be deleted from the
-        names.
-    defaultfmt : str, optional
-        A format used to define default field names, such as "f%i" or "f_%02i".
-    autostrip : bool, optional
-        Whether to automatically strip white spaces from the variables.
-    case_sensitive : {True, False, 'upper', 'lower'}, optional
-        If True, field names are case sensitive.
-        If False or 'upper', field names are converted to upper case.
-        If 'lower', field names are converted to lower case.
-    unpack : bool, optional
-        If True, the returned array is transposed, so that arguments may be
-        unpacked using ``x, y, z = loadtxt(...)``
-    usemask : bool, optional
-        If True, return a masked array.
-        If False, return a regular array.
-    invalid_raise : bool, optional
-        If True, an exception is raised if an inconsistency is detected in the
-        number of columns.
-        If False, a warning is emitted and the offending lines are skipped.
-
-    Returns
-    -------
-    out : ndarray
-        Data read from the text file. If `usemask` is True, this is a
-        masked array.
-
-    See Also
-    --------
-    numpy.loadtxt : equivalent function when no data is missing.
-
-    Notes
-    -----
-    * When spaces are used as delimiters, or when no delimiter has been given
-      as input, there should not be any missing data between two fields.
-    * When the variables are named (either by a flexible dtype or with `names`,
-      there must not be any header in the file (else a ValueError
-      exception is raised).
-    * Individual values are not stripped of spaces by default.
-      When using a custom converter, make sure the function does remove spaces.
-
-    Examples
-    ---------
-    >>> from StringIO import StringIO
-    >>> import numpy as np
-
-    Comma delimited file with mixed dtype
-
-    >>> s = StringIO("1,1.3,abcde")
-    >>> data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'),
-        ('mystring','S5')], delimiter=",")
-    >>> data
-    array((1, 1.3, 'abcde'),
-          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', '|S5')])
-
-    Using dtype = None
-
-    >>> s.seek(0) # needed for StringIO example only
-    >>> data = np.genfromtxt(s, dtype=None,
-        names = ['myint','myfloat','mystring'], delimiter=",")
-    >>> data
-    array((1, 1.3, 'abcde'),
-          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', '|S5')])
-
-    Specifying dtype and names
-
-    >>> s.seek(0)
-    >>> data = np.genfromtxt(s, dtype="i8,f8,S5",
-        names=['myint','myfloat','mystring'], delimiter=",")
-    >>> data
-    array((1, 1.3, 'abcde'),
-          dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', '|S5')])
-
-    An example with fixed-width columns
-
-    >>> s = StringIO("11.3abcde")
-    >>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'],
-            delimiter=[1,3,5])
-    >>> data
-    array((1, 1.3, 'abcde'),
-          dtype=[('intvar', '<i8'), ('fltvar', '<f8'), ('strvar', '|S5')])
-
-    """
-    #
-    if usemask:
-        from numpy.ma import MaskedArray, make_mask_descr
-    # Check the input dictionary of converters
-    user_converters = converters or {}
-    if not isinstance(user_converters, dict):
-        errmsg = "The input argument 'converter' should be a valid dictionary "\
-            "(got '%s' instead)"
-        raise TypeError(errmsg % type(user_converters))
-
-    # Initialize the filehandle, the LineSplitter and the NameValidator
-    if isinstance(fname, basestring):
-        fhd = np.lib._datasource.open(fname)
-    elif not hasattr(fname, 'read'):
-        raise TypeError("The input should be a string or a filehandle. "\
-                        "(got %s instead)" % type(fname))
-    else:
-        fhd = fname
-    split_line = LineSplitter(delimiter=delimiter, comments=comments,
-                              autostrip=autostrip)._handyman
-    validate_names = NameValidator(excludelist=excludelist,
-                                   deletechars=deletechars,
-                                   case_sensitive=case_sensitive)
-
-    # Get the first valid lines after the first skiprows ones ..
-    if skiprows:
-        warnings.warn("The use of `skiprows` is deprecated.\n"\
-                      "Please use `skip_header` instead.",
-                      DeprecationWarning)
-        skip_header = skiprows
-    # Skip the first `skip_header` rows
-    for i in xrange(skip_header):
-        fhd.readline()
-    # Keep on until we find the first valid values
-    first_values = None
-    while not first_values:
-        first_line = fhd.readline()
-        if first_line == '':
-            raise IOError('End-of-file reached before encountering data.')
-        if names is True:
-            if comments in first_line:
-                first_line = ''.join(first_line.split(comments)[1])
-        first_values = split_line(first_line)
-    # Should we take the first values as names ?
-    if names is True:
-        fval = first_values[0].strip()
-        if fval in comments:
-            del first_values[0]
-
-    # Check the columns to use
-    if usecols is not None:
-        try:
-            usecols = [_.strip() for _ in usecols.split(",")]
-        except AttributeError:
-            try:
-                usecols = list(usecols)
-            except TypeError:
-                usecols = [usecols, ]
-    nbcols = len(usecols or first_values)
-
-    # Check the names and overwrite the dtype.names if needed
-    if names is True:
-        names = validate_names([_.strip() for _ in first_values])
-        first_line = ''
-    elif _is_string_like(names):
-        names = validate_names([_.strip() for _ in names.split(',')])
-    elif names:
-        names = validate_names(names)
-    # Get the dtype
-    if dtype is not None:
-        dtype = easy_dtype(dtype, defaultfmt=defaultfmt, names=names)
-        names = dtype.names
-    # Make sure the names is a list (for 2.5)
-    if names is not None:
-        names = list(names)
-
-
-    if usecols:
-        for (i, current) in enumerate(usecols):
-            # if usecols is a list of names, convert to a list of indices
-            if _is_string_like(current):
-                usecols[i] = names.index(current)
-            elif current < 0:
-                usecols[i] = current + len(first_values)
-        # If the dtype is not None, make sure we update it
-        if (dtype is not None) and (len(dtype) > nbcols):
-            descr = dtype.descr
-            dtype = np.dtype([descr[_] for _ in usecols])
-            names = list(dtype.names)
-        # If `names` is not None, update the names
-        elif (names is not None) and (len(names) > nbcols):
-            names = [names[_] for _ in usecols]
-
-
-    # Process the missing values ...............................
-    # Rename missing_values for convenience
-    user_missing_values = missing_values or ()
-
-    # Define the list of missing_values (one column: one list)
-    missing_values = [list(['']) for _ in range(nbcols)]
-
-    # We have a dictionary: process it field by field
-    if isinstance(user_missing_values, dict):
-        # Loop on the items
-        for (key, val) in user_missing_values.items():
-            # Is the key a string ?
-            if _is_string_like(key):
-                try:
-                    # Transform it into an integer
-                    key = names.index(key)
-                except ValueError:
-                    # We couldn't find it: the name must have been dropped, then
-                    continue
-            # Redefine the key as needed if it's a column number
-            if usecols:
-                try:
-                    key = usecols.index(key)
-                except ValueError:
-                    pass
-            # Transform the value as a list of string
-            if isinstance(val, (list, tuple)):
-                val = [str(_) for _ in val]
-            else:
-                val = [str(val), ]
-            # Add the value(s) to the current list of missing
-            if key is None:
-                # None acts as default
-                for miss in missing_values:
-                    miss.extend(val)
-            else:
-                missing_values[key].extend(val)
-    # We have a sequence : each item matches a column
-    elif isinstance(user_missing_values, (list, tuple)):
-        for (value, entry) in zip(user_missing_values, missing_values):
-            value = str(value)
-            if value not in entry:
-                entry.append(value)
-    # We have a string : apply it to all entries
-    elif isinstance(user_missing_values, basestring):
-        user_value = user_missing_values.split(",")
-        for entry in missing_values:
-            entry.extend(user_value)
-    # We have something else: apply it to all entries
-    else:
-        for entry in missing_values:
-            entry.extend([str(user_missing_values)])
-
-    # Process the deprecated `missing`
-    if missing != '':
-        warnings.warn("The use of `missing` is deprecated.\n"\
-                      "Please use `missing_values` instead.",
-                      DeprecationWarning)
-        values = [str(_) for _ in missing.split(",")]
-        for entry in missing_values:
-            entry.extend(values)
-
-    # Process the filling_values ...............................
-    # Rename the input for convenience
-    user_filling_values = filling_values or []
-    # Define the default
-    filling_values = [None] * nbcols
-    # We have a dictionary : update each entry individually
-    if isinstance(user_filling_values, dict):
-        for (key, val) in user_filling_values.items():
-            if _is_string_like(key):
-                try:
-                    # Transform it into an integer
-                    key = names.index(key)
-                except ValueError:
-                    # We couldn't find it: the name must have been dropped, then
-                    continue
-            # Redefine the key if it's a column number and usecols is defined
-            if usecols:
-                try:
-                    key = usecols.index(key)
-                except ValueError:
-                    pass
-            # Add the value to the list
-            filling_values[key] = val
-    # We have a sequence : update on a one-to-one basis
-    elif isinstance(user_filling_values, (list, tuple)):
-        n = len(user_filling_values)
-        if (n <= nbcols):
-            filling_values[:n] = user_filling_values
-        else:
-            filling_values = user_filling_values[:nbcols]
-    # We have something else : use it for all entries
-    else:
-        filling_values = [user_filling_values] * nbcols
-
-    # Initialize the converters ................................
-    if dtype is None:
-        # Note: we can't use a [...]*nbcols, as we would have 3 times the same
-        # ... converter, instead of 3 different converters.
-        converters = [StringConverter(None, missing_values=miss, default=fill)
-                      for (miss, fill) in zip(missing_values, filling_values)]
-    else:
-        dtype_flat = flatten_dtype(dtype, flatten_base=True)
-        # Initialize the converters
-        if len(dtype_flat) > 1:
-            # Flexible type : get a converter from each dtype
-            zipit = zip(dtype_flat, missing_values, filling_values)
-            converters = [StringConverter(dt, locked=True,
-                                          missing_values=miss, default=fill)
-                           for (dt, miss, fill) in zipit]
-        else:
-            # Set to a default converter (but w/ different missing values)
-            zipit = zip(missing_values, filling_values)
-            converters = [StringConverter(dtype, locked=True,
-                                          missing_values=miss, default=fill)
-                          for (miss, fill) in zipit]
-    # Update the converters to use the user-defined ones
-    uc_update = []
-    for (i, conv) in user_converters.items():
-        # If the converter is specified by column names, use the index instead
-        if _is_string_like(i):
-            try:
-                i = names.index(i)
-            except ValueError:
-                continue
-        elif usecols:
-            try:
-                i = usecols.index(i)
-            except ValueError:
-                # Unused converter specified
-                continue
-        converters[i].update(conv, locked=True,
-                             default=filling_values[i],
-                             missing_values=missing_values[i],)
-        uc_update.append((i, conv))
-    # Make sure we have the corrected keys in user_converters...
-    user_converters.update(uc_update)
-
-    miss_chars = [_.missing_values for _ in converters]
-
-
-    # Initialize the output lists ...
-    # ... rows
-    rows = []
-    append_to_rows = rows.append
-    # ... masks
-    if usemask:
-        masks = []
-        append_to_masks = masks.append
-    # ... invalid
-    invalid = []
-    append_to_invalid = invalid.append
-
-    # Parse each line
-    for (i, line) in enumerate(itertools.chain([first_line, ], fhd)):
-        values = split_line(line)
-        nbvalues = len(values)
-        # Skip an empty line
-        if nbvalues == 0:
-            continue
-        # Select only the columns we need
-        if usecols:
-            try:
-                values = [values[_] for _ in usecols]
-            except IndexError:
-                append_to_invalid((i, nbvalues))
-                continue
-        elif nbvalues != nbcols:
-            append_to_invalid((i, nbvalues))
-            continue
-        # Store the values
-        append_to_rows(tuple(values))
-        if usemask:
-            append_to_masks(tuple([v.strip() in m
-                                   for (v, m) in zip(values, missing_values)]))
-
-    # Strip the last skip_footer data
-    if skip_footer > 0:
-        rows = rows[:-skip_footer]
-        if usemask:
-            masks = masks[:-skip_footer]
-
-    # Upgrade the converters (if needed)
-    if dtype is None:
-        for (i, converter) in enumerate(converters):
-            current_column = map(itemgetter(i), rows)
-            try:
-                converter.iterupgrade(current_column)
-            except ConverterLockError:
-                errmsg = "Converter #%i is locked and cannot be upgraded: " % i
-                current_column = itertools.imap(itemgetter(i), rows)
-                for (j, value) in enumerate(current_column):
-                    try:
-                        converter.upgrade(value)
-                    except (ConverterError, ValueError):
-                        errmsg += "(occurred line #%i for value '%s')"
-                        errmsg %= (j + 1 + skip_header, value)
-                        raise ConverterError(errmsg)
-
-    # Check that we don't have invalid values
-    if len(invalid) > 0:
-        nbrows = len(rows)
-        # Construct the error message
-        template = "    Line #%%i (got %%i columns instead of %i)" % nbcols
-        if skip_footer > 0:
-            nbrows -= skip_footer
-            errmsg = [template % (i + skip_header + 1, nb)
-                      for (i, nb) in invalid if i < nbrows]
-        else:
-            errmsg = [template % (i + skip_header + 1, nb)
-                      for (i, nb) in invalid]
-        if len(errmsg):
-            errmsg.insert(0, "Some errors were detected !")
-            errmsg = "\n".join(errmsg)
-            # Raise an exception ?
-            if invalid_raise:
-                raise ValueError(errmsg)
-            # Issue a warning ?
-            else:
-                warnings.warn(errmsg, ConversionWarning)
-
-    # Convert each value according to the converter:
-    # We want to modify the list in place to avoid creating a new one...
-#    if loose:
-#        conversionfuncs = [conv._loose_call for conv in converters]
-#    else:
-#        conversionfuncs = [conv._strict_call for conv in converters]
-#    for (i, vals) in enumerate(rows):
-#        rows[i] = tuple([convert(val)
-#                         for (convert, val) in zip(conversionfuncs, vals)])
-    if loose:
-        rows = zip(*(map(converter._loose_call, map(itemgetter(i), rows))
-                     for (i, converter) in enumerate(converters)))
-    else:
-        rows = zip(*(map(converter._strict_call, map(itemgetter(i), rows))
-                     for (i, converter) in enumerate(converters)))
-    # Reset the dtype
-    data = rows
-    if dtype is None:
-        # Get the dtypes from the types of the converters
-        column_types = [conv.type for conv in converters]
-        # Find the columns with strings...
-        strcolidx = [i for (i, v) in enumerate(column_types)
-                     if v in (type('S'), np.string_)]
-        # ... and take the largest number of chars.
-        for i in strcolidx:
-            column_types[i] = "|S%i" % max(len(row[i]) for row in data)
-        #
-        if names is None:
-            # If the dtype is uniform, don't define names, else use ''
-            base = set([c.type for c in converters if c._checked])
-            if len(base) == 1:
-                (ddtype, mdtype) = (list(base)[0], np.bool)
-            else:
-                ddtype = [(defaultfmt % i, dt)
-                          for (i, dt) in enumerate(column_types)]
-                if usemask:
-                    mdtype = [(defaultfmt % i, np.bool)
-                              for (i, dt) in enumerate(column_types)]
-        else:
-            ddtype = zip(names, column_types)
-            mdtype = zip(names, [np.bool] * len(column_types))
-        output = np.array(data, dtype=ddtype)
-        if usemask:
-            outputmask = np.array(masks, dtype=mdtype)
-    else:
-        # Overwrite the initial dtype names if needed
-        if names and dtype.names:
-            dtype.names = names
-        # Case 1. We have a structured type
-        if len(dtype_flat) > 1:
-            # Nested dtype, eg  [('a', int), ('b', [('b0', int), ('b1', 'f4')])]
-            # First, create the array using a flattened dtype:
-            # [('a', int), ('b1', int), ('b2', float)]
-            # Then, view the array using the specified dtype.
-            if 'O' in (_.char for _ in dtype_flat):
-                if has_nested_fields(dtype):
-                    errmsg = "Nested fields involving objects "\
-                             "are not supported..."
-                    raise NotImplementedError(errmsg)
-                else:
-                    output = np.array(data, dtype=dtype)
-            else:
-                rows = np.array(data, dtype=[('', _) for _ in dtype_flat])
-                output = rows.view(dtype)
-            # Now, process the rowmasks the same way
-            if usemask:
-                rowmasks = np.array(masks,
-                                    dtype=np.dtype([('', np.bool)
-                                    for t in dtype_flat]))
-                # Construct the new dtype
-                mdtype = make_mask_descr(dtype)
-                outputmask = rowmasks.view(mdtype)
-        # Case #2. We have a basic dtype
-        else:
-            # We used some user-defined converters
-            if user_converters:
-                ishomogeneous = True
-                descr = []
-                for (i, ttype) in enumerate([conv.type for conv in converters]):
-                    # Keep the dtype of the current converter
-                    if i in user_converters:
-                        ishomogeneous &= (ttype == dtype.type)
-                        if ttype == np.string_:
-                            ttype = "|S%i" % max(len(row[i]) for row in data)
-                        descr.append(('', ttype))
-                    else:
-                        descr.append(('', dtype))
-                # So we changed the dtype ?
-                if not ishomogeneous:
-                    # We have more than one field
-                    if len(descr) > 1:
-                        dtype = np.dtype(descr)
-                    # We have only one field: drop the name if not needed.
-                    else:
-                        dtype = np.dtype(ttype)
-            #
-            output = np.array(data, dtype)
-            if usemask:
-                if dtype.names:
-                    mdtype = [(_, np.bool) for _ in dtype.names]
-                else:
-                    mdtype = np.bool
-                outputmask = np.array(masks, dtype=mdtype)
-    # Try to take care of the missing data we missed
-    names = output.dtype.names
-    if usemask and names:
-        for (name, conv) in zip(names or (), converters):
-            missing_values = [conv(_) for _ in conv.missing_values if _ != '']
-            for mval in missing_values:
-                outputmask[name] |= (output[name] == mval)
-    # Construct the final array
-    if usemask:
-        output = output.view(MaskedArray)
-        output._mask = outputmask
-    if unpack:
-        return output.squeeze().T
-    return output.squeeze()
diff --git a/pandas/timeseries/_tools.py b/pandas/timeseries/_tools.py
deleted file mode 100644
index ce5520f74..000000000
--- a/pandas/timeseries/_tools.py
+++ /dev/null
@@ -1,95 +0,0 @@
-"""
-A collection of helper tools
-
-
-Decorators
-==========
-
-.. autoclass:: docwrapper
-
-.. autoclass:: deprecated_for
-
-"""
-
-import functools
-import warnings
-
-
-
-class docwrapper(object):
-    """
-    Decorator that updates the docstring of a function with a dictionary
-    of templates.
-
-    Parameters
-    ----------
-    template : dictionary
-        A dictionary giving for each key the docstring to extend.
-    """
-    #
-    def __init__(self, template):
-        self.template = template
-    #
-    def __call__(self, func):
-        def wrapped(*args, **kwargs):
-            "Just call the function w/ the proper arguments"
-            return func(*args, **kwargs)
-        wrapped.__name__ = func.__name__
-        wrapped.__dict__ = func.__dict__
-        wrapped.__doc__ = ((func.__doc__ or "") % self.template) or None
-        return wrapped
-
-
-
-
-class deprecated_for:
-    """
-    Decorator marking a function as deprecated.
-
-    When a decorated function is called, a warning is emitted.
-
-    Parameters
-    ----------
-    newfunc : function, optional
-        Function that should replace the deprecated one.
-
-    Examples
-    --------
-    >>> def new_function(*args, **kwargs):
-    ...     do_something
-    ...
-    >>> @deprecated_for(new_function)
-    >>> def old_function(*args, **kwargs):
-    ...    do_something
-    ...
-    >>> old_function(*args)
-    DeprecationWarning: The function `old_function` is deprecated.
-    Please use the `new_function` instead.
-    """
-    #
-    def __init__(self, newfunc=None):
-        self.replacement = newfunc
-        msg = "The function `%(oldname)s` is deprecated.\n"
-        doctemplate = "(Deprecated function)\n%(olddoc)s"
-        if newfunc is not None:
-            msg += "Please use the `%s` function instead." % newfunc.__name__
-            newdoc = newfunc.__doc__
-            if newdoc is not None:
-                doctemplate += "\n(New usage)\n%s" % newdoc
-        self.msg = msg
-        self.doctemplate = doctemplate
-    #
-    def __call__(self, func):
-        oldinfo = dict(oldname=func.__name__, olddoc=func.__doc__ or "")
-        msg = self.msg % oldinfo
-        def wrapped(*args, **kwargs):
-            warnings.warn_explicit(msg, category=DeprecationWarning,
-                                   filename=func.func_code.co_filename,
-                                   lineno=func.func_code.co_firstlineno + 1)
-            return func(*args, **kwargs)
-        wrapped.__name__ = func.__name__
-        wrapped.__dict__ = func.__dict__
-        wrapped.__doc__ = (self.doctemplate % oldinfo) or None
-        return wrapped
-
-deprecated = deprecated_for()
diff --git a/pandas/timeseries/const.py b/pandas/timeseries/const.py
deleted file mode 100644
index 7013bcae5..000000000
--- a/pandas/timeseries/const.py
+++ /dev/null
@@ -1,87 +0,0 @@
-"""
-This module contains all the integer frequency constants. Below is a detailed
-description of the constants, as well as a listing of the corresponding string
-aliases.
-
-All functions in the timeseries module that accept a frequency parameter can
-accept either the integer constant, or a valid string alias.
-
-|----------------------------------------------------------------------------|
-|CONSTANT         | String aliases (case insensitive) and comments           |
-|----------------------------------------------------------------------------|
-| Note: For annual frequencies, "Year" is determined by where the last month |
-| of the year falls.                                                         |
-|----------------------------------------------------------------------------|
-| FR_ANN          | 'A', 'Y', 'ANNUAL', 'ANNUALLY', 'YEAR', 'YEARLY'         |
-|----------------------------------------------------------------------------|
-| FR_ANNDEC       | 'A-DEC', 'A-December', 'Y-DEC', 'ANNUAL-DEC', etc...     |
-|                 | (annual frequency with December year end, equivalent to  |
-|                 | FR_ANN)                                                  |
-|----------------------------------------------------------------------------|
-| FR_ANNNOV       | 'A-NOV', 'A-NOVEMBER', 'Y-NOVEMBER', 'ANNUAL-NOV', etc...|
-|                   (annual frequency with November year end)                |
-| ...etc for the rest of the months                                          |
-|----------------------------------------------------------------------------|
-| Note: For the following quarterly frequencies, "Year" is determined by     |
-| where the last quarter of the current group of quarters ENDS               |
-|----------------------------------------------------------------------------|
-| FR_QTR          | 'Q', 'QUARTER', 'QUARTERLY'                              |
-|----------------------------------------------------------------------------|
-| FR_QTREDEC      | 'Q-DEC', 'QTR-December', 'QUARTERLY-DEC', etc...         |
-|                 | (quarterly frequency with December year end, equivalent  |
-|                 | to FR_QTR)                                               |
-|----------------------------------------------------------------------------|
-| FR_QTRENOV      | 'Q-NOV', 'QTR-NOVEMBER', 'QUARTERLY-NOV', etc...         |
-|                 | (quarterly frequency with November year end)             |
-| ...etc for the rest of the months                                          |
-|----------------------------------------------------------------------------|
-| Note: For the following quarterly frequencies, "Year" is determined by     |
-| where the first quarter of the current group of quarters STARTS            |
-|----------------------------------------------------------------------------|
-| FR_QTRSDEC      | 'Q-S-DEC', 'QTR-S-December', etc... (quarterly frequency |
-|                 | with December year end)                                  |
-| ...etc for the rest of the months                                          |
-|----------------------------------------------------------------------------|
-| FR_MTH          | 'M', 'MONTH', 'MONTHLY'                                  |
-|----------------------------------------------------------------------------|
-| FR_WK           | 'W', 'WEEK', 'WEEKLY'                                    |
-|----------------------------------------------------------------------------|
-| FR_WKSUN        | 'W-SUN', 'WEEK-SUNDAY', 'WEEKLY-SUN', etc... (weekly     |
-|                 | frequency with Sunday being the last day of the week,    |
-|                 | equivalent to FR_WK)                                     |
-|----------------------------------------------------------------------------|
-| FR_WKSAT        | 'W-SAT', 'WEEK-SATURDAY', 'WEEKLY-SAT', etc... (weekly   |
-|                 | frequency with Saturday being the last day of the week)  |
-| ...etc for the rest of the days of the week                                |
-|----------------------------------------------------------------------------|
-| FR_DAY          | 'D', 'DAY', 'DAILY'                                      |
-|----------------------------------------------------------------------------|
-| FR_BUS          | 'B', 'BUSINESS', 'BUSINESSLY' (this is a daily frequency |
-|                 | excluding Saturdays and Sundays)                         |
-|----------------------------------------------------------------------------|
-| FR_HR           | 'H', 'HOUR', 'HOURLY'                                    |
-|----------------------------------------------------------------------------|
-| FR_MIN          | 'T', 'MINUTE', 'MINUTELY'                                |
-|----------------------------------------------------------------------------|
-| FR_SEC          | 'S', 'SECOND', 'SECONDLY'                                |
-|----------------------------------------------------------------------------|
-| FR_UND          | 'U', 'UNDEF', 'UNDEFINED'                                |
-|----------------------------------------------------------------------------|
-
-:author: Pierre GF Gerard-Marchant & Matt Knox
-:contact: pierregm_at_uga_dot_edu - mattknox_ca_at_hotmail_dot_com
-:version: $Id$
-"""
-__author__ = "Pierre GF Gerard-Marchant & Matt Knox ($Author$)"
-__revision__ = "$Revision$"
-__date__     = '$Date$'
-
-from pandas._skts import freq_constants
-
-"""add constants in pandas._skts.freq_constants dictionary to global namespace
-for this module"""
-
-__all__ = [list(freq_constants)]
-
-_g = globals()
-_g.update(freq_constants)
diff --git a/pandas/timeseries/extras.py b/pandas/timeseries/extras.py
deleted file mode 100644
index 714e32fcd..000000000
--- a/pandas/timeseries/extras.py
+++ /dev/null
@@ -1,575 +0,0 @@
-"""
-Extras functions for time series.
-
-:author: Pierre GF Gerard-Marchant & Matt Knox
-:contact: pierregm_at_uga_dot_edu - mattknox_ca_at_hotmail_dot_com
-:version: $Id$
-"""
-__author__ = "Pierre GF Gerard-Marchant & Matt Knox ($Author$)"
-__revision__ = "$Revision$"
-__date__ = '$Date$'
-
-
-import numpy as np
-import numpy.ma as ma
-from numpy.ma import masked
-
-import const as _c
-from tdates import Date, date_array, DateArray
-from tseries import TimeSeries, time_series
-from pandas._skts import DateCalc_Error
-
-from _preview import genfromtxt, easy_dtype
-
-__all__ = ['accept_atmost_missing',
-           'convert_to_annual', 'count_missing',
-           'guess_freq',
-           'isleapyear',
-           'tsfromtxt']
-
-#..............................................................................
-def isleapyear(year):
-    """
-    Returns true if year is a leap year.
-
-    Parameters
-    ----------
-    year : integer / sequence
-        A given (list of) year(s).
-    """
-    year = np.asarray(year)
-    return np.logical_or(year % 400 == 0,
-                         np.logical_and(year % 4 == 0, year % 100 > 0))
-
-#..............................................................................
-def count_missing(series):
-    """
-    Returns the number of missing data per period.
-
-    Notes
-    -----
-    This function is designed to return the actual number of missing values when
-    a series has been converted from one frequency to a smaller frequency.
-
-    For example, converting a 12-month-long daily series to months will yield
-    a (12x31) array, with missing values in February, April, June...
-    count_missing will discard these extra missing values.
-    """
-    if not isinstance(series, TimeSeries):
-        raise TypeError, "The input data should be a valid TimeSeries object! "\
-                         "(got %s instead)" % type(series)
-    if series.ndim == 1:
-        return len(series) - series.count()
-    elif series.ndim != 2:
-        raise NotImplementedError
-    #
-    missing = series.shape[-1] - series.count(axis= -1)
-    period = series.shape[-1]
-    freq = series.freq
-    if (period == 366) and (freq // _c.FR_ANN == 1):
-        # row: years, cols: days
-        missing -= ~isleapyear(series.year)
-    elif period == 31 and (freq // _c.FR_MTH == 1):
-        months = series.months
-        # row: months, cols: days
-        missing[np.array([m in [4, 6, 9, 11] for m in months])] -= 1
-        isfeb = (months == 2)
-        missing[isfeb] -= 2
-        missing[isfeb & ~isleapyear(series.year)] -= 1
-    elif period == 92 and (freq // _c.FR_QTR == 1):
-        # row: quarters, cold:days
-        months = series.months
-        if freq in (_c.FR_QTREJAN, _c.FR_QTRSJAN, _c.FR_QTREAPR, _c.FR_QTRSAPR,
-                    _c.FR_QTREOCT, _c.FR_QTRSOCT, _c.FR_QTREOCT, _c.FR_QTRSOCT):
-            isfeb = (months == 4)
-            missing[isfeb] -= 2
-        elif freq in (_c.FR_QTREFEB, _c.FR_QTRSFEB, _c.FR_QTREMAY, _c.FR_QTRSMAY,
-                      _c.FR_QTREAUG, _c.FR_QTRSAUG, _c.FR_QTRENOV, _c.FR_QTRSNOV):
-            missing[np.array([m in [2, 11] for m in months])] -= 1
-            isfeb = (months == 2)
-        elif freq in (_c.FR_QTREMAR, _c.FR_QTRSMAR, _c.FR_QTREJUN, _c.FR_QTRSJUN,
-                      _c.FR_QTRESEP, _c.FR_QTRSSEP, _c.FR_QTREDEC, _c.FR_QTRSDEC):
-            missing[np.array([m in [3, 6] for m in months])] -= 1
-            isfeb = (months == 3)
-        missing[isfeb & ~isleapyear(series.year)] -= 1
-    elif period not in (12, 7):
-        raise NotImplementedError, "Not yet implemented for that frequency..."
-    return missing
-
-
-
-def convert_to_annual(series):
-    """
-    Group a series by years, taking leap years into account.
-
-    The output has as many rows as distinct years in the original series,
-    and as many columns as the length of a leap year in the units corresponding
-    to the original frequency (366 for daily frequency, 366*24 for hourly...).
-    The fist column of the output corresponds to Jan. 1st, 00:00:00,
-    while the last column corresponds to Dec, 31st, 23:59:59.
-    Entries corresponding to Feb. 29th are masked for non-leap years.
-
-    For example, if the initial series has a daily frequency, the 59th column
-    of the output always corresponds to Feb. 28th, the 61st column to Mar. 1st,
-    and the 60th column is masked for non-leap years.
-    With a hourly initial frequency, the (59*24)th column of the output always
-    correspond to Feb. 28th 23:00, the (61*24)th column to Mar. 1st, 00:00, and
-    the 24 columns between (59*24) and (61*24) are masked.
-
-    If the original frequency is less than daily, the output is equivalent to
-    ``series.convert('A', func=None)``.
-
-
-    Parameters
-    ----------
-    series : TimeSeries
-        A valid :class:`~scikits.timeseries.TimeSeries` object.
-
-    Returns
-    -------
-    aseries : TimeSeries
-        A 2D  :class:`~scikits.timeseries.TimeSeries` object with annual ('A')
-        frequency.
-
-    """
-    freq = series._dates.freq
-    if freq < _c.FR_DAY:
-        return series.convert('A')
-    baseidx = np.array((59, 60), dtype=int)
-    if (freq == _c.FR_DAY):
-        (idx0228, idx0301) = baseidx
-    elif (freq == _c.FR_HR):
-        (idx0228, idx0301) = baseidx * 24
-    elif (freq == _c.FR_MIN):
-        (idx0228, idx0301) = baseidx * 24 * 60
-    elif (freq == _c.FR_SEC):
-        (idx0228, idx0301) = baseidx * 24 * 3600
-    aseries = series.convert('A')
-    leapcondition = isleapyear(aseries.dates.years)
-    leapidx = np.arange(len(aseries), dtype=int)[~leapcondition]
-    aseries[leapidx, idx0301:] = aseries[leapidx, idx0228:idx0228 - idx0301]
-    aseries[leapidx, idx0228:idx0301] = ma.masked
-    return aseries
-
-
-
-#.............................................................................
-def accept_atmost_missing(series, max_missing, strict=False):
-    """
-    Masks the rows of `series` that contain more than `max_missing` missing data.
-    Returns a new masked series.
-
-    Parameters
-    ----------
-    series : TimeSeries
-        Input time series.
-    max_missing : float
-        Number of maximum acceptable missing values per row (if larger than 1),
-        or maximum acceptable percentage of missing values (if lower than 1).
-    strict : boolean *[False]*
-        Whether the number of missing values should be strictly greater than
-        `max_missing` or not.
-
-    Returns
-    -------
-    output : TimeSeries
-        A new TimeSeries object
-    """
-    series = np.array(series, copy=True, subok=True)
-    if not isinstance(series, TimeSeries):
-        raise TypeError, "The input data should be a valid TimeSeries object! "\
-                         "(got %s instead)" % type(series)
-    # Find the number of missing values ....
-    missing = count_missing(series)
-    # Transform an acceptable percentage in a number
-    if max_missing < 1:
-        max_missing = np.round(max_missing * series.shape[-1], 0)
-    #
-    series.unshare_mask()
-    if strict:
-        series[missing > max_missing] = masked
-    else:
-        series[missing >= max_missing] = masked
-    return series
-
-
-def guess_freq(dates):
-    """
-    Return an estimate of the frequency from a list of dates.
-
-    The frequency is estimated from the difference of dates (in days or seconds)
-    after chronological sorting.
-
-
-    Parameters
-    ----------
-    dates : var
-        Sequence of dates
-
-    Notes
-    -----
-    * In practice, the list of dates is first transformed into a list of
-      :class:`datetime.datetime` objects.
-    """
-    if isinstance(dates, DateArray):
-        dates = dates.copy()
-
-    try:
-        dates = date_array(dates, freq='S', autosort=True)
-    except c_dates.DateCalc_Error:
-        # contains dates prior to 1979, assume lower frequency
-        dates = date_array(dates, freq='D', autosort=True)
-
-    ddif = np.diff(dates)
-    mind = np.min(ddif)
-
-    if dates.freq == _c.FR_SEC and mind < 86400:
-
-        # hourly, minutely, or secondly frequency
-        if (mind > 3599) and not np.all(ddif % 3600 > 0):
-            freq = _c.FR_HR
-        elif mind < 59:
-            freq = _c.FR_SEC
-        else:
-            freq = _c.FR_MIN
-        return freq
-
-    # daily or lower frequency
-    if dates.freq == _c.FR_SEC:
-        dates = dates.asfreq('D')
-        ddif = np.diff(dates)
-        mind = np.min(ddif)
-
-    if mind > 360:
-        return _c.FR_ANN
-
-    if mind > 88:
-        qincs = [89, 90, 91, 92, 273, 274, 275, 276, 277]
-        if np.all([i in qincs for i in (ddif % 365)]):
-            freq = _c.FR_QTR
-        else:
-            freq = _c.FR_MTH
-        return freq
-
-    if (mind > 27):
-        return _c.FR_MTH
-
-    dow = dates.day_of_week
-    if (mind % 7 == 0) and np.all((ddif % 7) == 0):
-
-        mdow = np.min(dow)
-        freq = _c.FR_WKSUN + ((mdow + 1) % 7)
-        return freq
-    else:
-        if np.any((dow == 5) | (dow == 6)):
-            freq = _c.FR_DAY
-        else:
-            # no weekends, assume business frequency
-            freq = _c.FR_BUS
-        return freq
-
-
-
-
-def tsfromtxt(fname, dtype=None, freq='U', comments='#', delimiter=None,
-              skip_header=0, skip_footer=0, skiprows=0,
-              converters=None, dateconverter=None,
-              missing='', missing_values=None, filling_values=None,
-              usecols=None, datecols=None,
-              names=None, excludelist=None, deletechars=None, autostrip=True,
-              case_sensitive=True, defaultfmt="f%i", unpack=None, loose=True,
-              asrecarray=False, invalid_raise=True):
-    """
-    Load a TimeSeries from a text file.
-
-    Each line of the input after the first `skiprows` ones is split at
-    `delimiter`. Characters occuring after `comments` are discarded.
-
-    If a column is named ``'dates'`` (case insensitive), it is used to define
-    the dates. The ``freq`` parameter should be set to the expected frequency of
-    the output series.
-    If the date information spans several columns (for example, year in col #1,
-    month in col #2...), a specific conversion function must be defined with
-    the ``dateconverter`` parameter. This function should accept as many inputs
-    as date columns, and return a valid :class:`Date` object.
-
-    Parameters
-    ----------
-    fname : file or string
-        File or filename to read.
-        If the file extension is ``.gz`` or ``.bz2``, the file is first
-        decompressed.
-    dtype : data-type, optional
-        Data type of the resulting array.
-        If it is a structured data-type, the resulting array is 1-dimensional,
-        and each row is interpreted as an element of the array. In this case,
-        the number of columns used must match the number of fields in the dtype
-        and the names of each field are set by the corresponding name of the dtype.
-        If None, the dtypes will be determined by the contents of each
-        column, individually.
-    comments : {string}, optional
-        The character used to indicate the start of a comment.
-        All the characters occurring on a line after a comment are discarded.
-    delimiter : {string}, optional
-        The string used to separate values.  By default, any consecutive
-        whitespace act as delimiter.
-    skip_header : int, optional
-        The numbers of lines to skip at the beginning of the file.
-    skip_footer : int, optional
-        The numbers of lines to skip at the end of the file
-    converters : variable or None, optional
-        The set of functions that convert the data of a column to a value.
-        The converters can also be used to provide a default value
-        for missing data: ``converters = {3: lambda s: float(s or 0)}``.
-    dateconverter : {function}, optional
-        The function to convert the date information to a :class:`Date` object.
-        This function requires as many parameters as number of ``datecols``.
-        This parameter is mandatory if ``dtype=None``.
-    missing_values : variable or None, optional
-        The set of strings corresponding to missing data.
-    filling_values : variable or None, optional
-        The set of values to be used as default when the data are missing.
-    usecols : sequence or None, optional
-        Which columns to read, with 0 being the first.  For example,
-        ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns.
-    datecols : {None, int, sequence}, optional
-        Which columns store the date information.
-    names : {None, True, str, sequence}, optional
-        If `names` is True, the field names are read from the first valid line
-        after the first `skiprows` lines.
-        If `names` is a sequence or a single-string of comma-separated names,
-        the names will be used to define the field names in a structured dtype.
-        If `names` is None, the names of the dtype fields will be used, if any.
-    excludelist : sequence, optional
-        A list of names to exclude. This list is appended to the default list
-        ['return','file','print']. Excluded names are appended an underscore:
-        for example, `file` would become `file_`.
-    deletechars : str, optional
-        A string combining invalid characters that must be deleted from the
-        names.
-    defaultfmt : str, optional
-        A format used to define default field names, such as "f%i" or "f_%02i".
-    autostrip : bool, optional
-        Whether to automatically strip white spaces from the variables.
-    case_sensitive : {True, False, 'upper', 'lower'}, optional
-        If True, field names are case sensitive.
-        If False or 'upper', field names are converted to upper case.
-        If 'lower', field names are converted to lower case.
-    unpack : bool, optional
-        If True, the returned array is transposed, so that arguments may be
-        unpacked using ``x, y, z = loadtxt(...)``
-    usemask : bool, optional
-        If True, return a masked array.
-        If False, return a regular array.
-    asrecarray : {False, True}, optional
-        Whether to return a TimeSeriesRecords or a series with a structured
-        dtype.
-    invalid_raise : bool, optional
-        If True, an exception is raised if an inconsistency is detected in the
-        number of columns.
-        If False, a warning is emitted and the offending lines are skipped.
-
-
-    Returns
-    -------
-    out : MaskedArray
-        Data read from the text file.
-
-    See Also
-    --------
-    numpy.lib.io.genfromtxt
-        Equivalent function for standard arrays
-
-    Notes
-    -----
-    * When spaces are used as delimiters, or when no delimiter has been given
-      as input, there should not be any missing data between two fields.
-    * When the variable are named (either by a flexible dtype or with `names`,
-      there must not be any header in the file (else a :exc:`ValueError`
-      exception is raised).
-    * If ``names`` is True or a sequence of strings, these names overwrite
-      the fields names of a structured array.
-    * The sequence of names must NOT take the date columns into account.
-    * If the datatype is not given explicitly (``dtype=None``),
-      a :keyword:`dateconverter` must be given explicitly.
-    * If the ``dtype`` is given explicitly,
-      it must NOT refer to the date columns.
-    * By default, the types of variables is defined from the values encountered
-      in the file (``dtype=None``). This is *NOT* the default for np.genfromtxt.
-
-    Examples
-    --------
-    >>> data = "year, month, a, b\\n 2001, 01, 0.0, 10.\\n 2001, 02, 1.1, 11."
-    >>> dateconverter = lambda y, m: Date('M', year=int(y), month=int(m))
-    >>> series = tsfromtxt(StringIO.StringIO(data), delimiter=',', names=True,
-    ...                    datecols=(0,1), dateconverter=dateconverter,)
-    >>> series
-    timeseries([(0.0, 10.0) (1.1, 11.0)],
-       dtype = [('a', '<f8'), ('b', '<f8')],
-       dates = [Jan-2001 Feb-2001],
-       freq  = M)
-    >>> series = tsfromtxt(StringIO.StringIO(data), delimiter=",",
-    ...                    datecols=(0, 1), dateconverter=dateconverter,
-    ...                    names="A, B", skip_header=1)
-    timeseries([(0.0, 10.0) (1.1000000000000001, 11.0)],
-       dtype = [('A', '<f8'), ('B', '<f8')],
-       dates = [Jan-2001 Feb-2001],
-       freq  = M)
-
-    """
-    # Update the date converter ...........................
-    converters = converters or {}
-    dateconv = dateconverter or None
-    if dateconv is None:
-        dateconv = lambda s: Date(freq, string=s)
-    if 'dates' in converters:
-        dateconv = converters['dates']
-        del(converters['dates'])
-
-    # Make sure `datecols` is a sequence ..................
-    if datecols is not None:
-        try:
-            datecols = [_.strip() for _ in datecols.split(",")]
-        except AttributeError:
-            try:
-                datecols = list(datecols)
-            except TypeError:
-                datecols = [datecols, ]
-        # ... and update the converters
-        converters.update((i, str) for i in datecols)
-
-    # Save the initial names and dtypes ...................
-    idtype = dtype
-    if isinstance(names, basestring):
-        names = names.split(",")
-    inames = names
-
-    # Update the dtype (if needed) ........................
-    if (dtype is not None):
-        # Crash if we can't find the datecols
-        if datecols is None:
-            raise TypeError("No column selected for the dates!")
-        # Make sure dtype is a valid np.dtype and make a copy
-        dtype = easy_dtype(dtype, names=names)
-        idtype = dtype
-        inames = dtype.names
-        if inames is not None:
-            nbfields = len(inames) + len(datecols)
-            # Create a new dtype description and a set of names
-            dtype = [''] * nbfields
-            names = [''] * nbfields
-            idx = range(nbfields)
-            for i in datecols:
-                if i < 0:
-                    i += nbfields
-                del idx[idx.index(i)]
-                # Set the default dtype for date columns, as np.object
-                # (we can't use string as we don't know the final size)
-                dtype[i] = ('', np.object)
-            convdict = {'b': bool, 'i': int, 'l':int, 'u': int,
-                        'f': float, 'd': float, 'g': float,
-                        'c': complex, 'D': complex,
-                        'S': str, 'U': str, 'a': str}
-            converter_update = []
-            for (i, name) in zip(idx, inames):
-                field = idtype[name]
-                dtype[i] = (name, field)
-                converter_update.append((i, convdict[field.char]))
-                names[i] = name
-            converters.update(converter_update)
-    elif names not in (True, None):
-        # Make sure that we saved the names as a list
-        inames = list(inames)
-        # Get the list of columns to use
-        if usecols is None:
-            nbcols = len(datecols) + len(inames)
-            names = [''] * nbcols
-            ucols = range(nbcols)
-        else:
-            names = [''] * (max(usecols) + 1)
-            ucols = usecols
-        # Fill the list of names:
-        for i in ucols:
-            if i in datecols:
-                names[i] = "__%i" % i
-            else:
-                names[i] = inames.pop(0)
-    #
-    # Update the optional arguments ...
-    kwargs = dict(dtype=dtype, comments=comments, delimiter=delimiter,
-                  skiprows=skiprows, converters=converters,
-                  skip_header=skip_header, skip_footer=skip_footer,
-                  missing=missing, missing_values=missing_values,
-                  filling_values=filling_values,
-                  usecols=usecols, unpack=unpack, names=names,
-                  excludelist=excludelist, deletechars=deletechars,
-                  case_sensitive=case_sensitive, defaultfmt=defaultfmt,
-                  autostrip=autostrip, loose=loose, invalid_raise=invalid_raise,
-                  usemask=True)
-    # Get the raw data ................
-    mrec = genfromtxt(fname, **kwargs)
-    if not mrec.shape:
-        mrec.shape = -1
-    names = mrec.dtype.names
-    # Revert to the original dtype.....
-    dtype = idtype
-    # Get the date columns ................................
-    if datecols is None:
-        import re
-        datespattern = re.compile("'?_?dates?'?", re.IGNORECASE)
-        datecols = [i for (i, name) in enumerate(names or ())
-                     if datespattern.search(name)]
-        if not datecols:
-            raise TypeError("No column selected for the dates!")
-    else:
-        # We have `datecols` already, make sure the indices are positive
-        # (the nb of fields might still be undefined)
-        nbfields = len(names)
-        for (i, v) in enumerate(datecols):
-            if (v < 0):
-                datecols[i] = v + nbfields
-    # Fix the date columns if usecols was given
-    if usecols is not None:
-        datecols = tuple([list(usecols).index(d) for d in datecols])
-    # Get the date info ...............
-    if names:
-        _dates = [mrec[names[i]] for i in datecols]
-    else:
-        _dates = [mrec[:, i] for i in datecols]
-    # Convert the date columns to a date_array
-    if len(_dates) == 1:
-        _dates = np.array(_dates[0], copy=False, ndmin=1)
-        dates = date_array([dateconv(args) for args in _dates],
-                           freq=freq, autosort=False)
-    else:
-        dates = date_array([dateconv(*args) for args in zip(*_dates)],
-                           freq=freq, autosort=False)
-    # Resort the array according to the dates
-    sortidx = dates.argsort()
-    dates = dates[sortidx]
-    mrec = mrec[sortidx]
-    # Get the dtype from the named columns (if any), or just use the initial one
-    mdtype = mrec.dtype
-    if mdtype.names:
-        newdescr = [descr for (i, descr) in enumerate(mdtype.descr)
-                    if i not in datecols]
-        output = time_series(ma.empty((len(mrec),), dtype=newdescr),
-                             dates=dates)
-        for name in output.dtype.names:
-            output[name] = mrec[name]
-        if (idtype is not None):
-            if (idtype.names is None):
-                dtype = (idtype, len(output.dtype.names))
-            else:
-                dtype = idtype
-            output = output.view(dtype)
-    else:
-        dataidx = [i for i in range(mrec.shape[-1]) if i not in datecols]
-        if len(dataidx) == 1:
-            dataidx = dataidx[0]
-        output = time_series(mrec[:, dataidx], dates=dates)
-    #
-    if asrecarray:
-        from trecords import TimeSeriesRecords
-        return output.view(TimeSeriesRecords)
-    return output
diff --git a/pandas/timeseries/parser.py b/pandas/timeseries/parser.py
deleted file mode 100644
index a3be9a5d9..000000000
--- a/pandas/timeseries/parser.py
+++ /dev/null
@@ -1,963 +0,0 @@
-#-*- coding: latin-1 -*-
-""" 
-Date/Time string parsing module.
-
-This code is a slightly modified version of Parser.py found in mx.DateTime
-version 3.0.0
-
-As such, it is subject to the terms of the eGenix public license version 1.1.0.
-Please see license.txt for more details.
-"""
-
-__all__ = [
-'DateFromString', 'DateTimeFromString'
-           ]
-
-import types
-import re
-import datetime as dt
-
-class RangeError(Exception): pass
-
-# Enable to produce debugging output
-_debug = 0
-
-# REs for matching date and time parts in a string; These REs
-# parse a superset of ARPA, ISO, American and European style dates.
-# Timezones are supported via the Timezone submodule.
-
-_year = '(?P<year>-?\d+\d(?!:))'
-_fullyear = '(?P<year>-?\d+\d\d(?!:))'
-_year_epoch = '(?:' + _year + '(?P<epoch> *[ABCDE\.]+)?)'
-_fullyear_epoch = '(?:' + _fullyear + '(?P<epoch> *[ABCDE\.]+)?)'
-_relyear = '(?:\((?P<relyear>[-+]?\d+)\))'
-
-_month = '(?P<month>\d?\d(?!:))'
-_fullmonth = '(?P<month>\d\d(?!:))'
-_litmonth = ('(?P<litmonth>'
-             'jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|'
-             'mr|mae|mrz|mai|okt|dez|'
-             'fev|avr|juin|juil|aou|ao|dc|'
-             'ene|abr|ago|dic|'
-             'out'
-             ')[a-z,\.;]*')
-litmonthtable = {
-    # English
-    'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6,
-    'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12,
-    # German
-    'mr':3, 'mae':3, 'mrz':3, 'mai':5, 'okt':10, 'dez':12,
-    # French
-    'fev':2, 'avr':4, 'juin':6, 'juil':7, 'aou':8, 'ao':8,
-    'dc':12,
-    # Spanish
-    'ene':1, 'abr':4, 'ago':8, 'dic':12,
-    # Portuguese
-    'out':10,
-    }
-_relmonth = '(?:\((?P<relmonth>[-+]?\d+)\))'
-
-_day = '(?P<day>\d?\d(?!:))'
-_usday = '(?P<day>\d?\d(?!:))(?:st|nd|rd|th|[,\.;])?'
-_fullday = '(?P<day>\d\d(?!:))'
-_litday = ('(?P<litday>'
-           'mon|tue|wed|thu|fri|sat|sun|'
-           'die|mit|don|fre|sam|son|'
-           'lun|mar|mer|jeu|ven|sam|dim|'
-           'mie|jue|vie|sab|dom|'
-           'pri|seg|ter|cua|qui'
-           ')[a-z]*')
-litdaytable = {
-    # English
-    'mon':0, 'tue':1, 'wed':2, 'thu':3, 'fri':4, 'sat':5, 'sun':6,
-    # German
-    'die':1, 'mit':2, 'don':3, 'fre':4, 'sam':5, 'son':6,
-    # French
-    'lun':0, 'mar':1, 'mer':2, 'jeu':3, 'ven':4, 'sam':5, 'dim':6,
-    # Spanish
-    'mie':2, 'jue':3, 'vie':4, 'sab':5, 'dom':6,
-    # Portuguese
-    'pri':0, 'seg':1, 'ter':2, 'cua':3, 'qui':4,
-    }
-_relday = '(?:\((?P<relday>[-+]?\d+)\))'
-
-_hour = '(?P<hour>[012]?\d)'
-_minute = '(?P<minute>[0-6]\d)'
-_second = '(?P<second>[0-6]\d(?:[.,]\d+)?)'
-
-_days = '(?P<days>\d*\d(?:[.,]\d+)?)'
-_hours = '(?P<hours>\d*\d(?:[.,]\d+)?)'
-_minutes = '(?P<minutes>\d*\d(?:[.,]\d+)?)'
-_seconds = '(?P<seconds>\d*\d(?:[.,]\d+)?)'
-
-_reldays = '(?:\((?P<reldays>[-+]?\d+(?:[.,]\d+)?)\))'
-_relhours = '(?:\((?P<relhours>[-+]?\d+(?:[.,]\d+)?)\))'
-_relminutes = '(?:\((?P<relminutes>[-+]?\d+(?:[.,]\d+)?)\))'
-_relseconds = '(?:\((?P<relseconds>[-+]?\d+(?:[.,]\d+)?)\))'
-
-_sign = '(?:(?P<sign>[-+]) *)'
-_week = 'W(?P<week>\d?\d)'
-_zone = '(?P<zone>[A-Z]+|[+-]\d\d?:?(?:\d\d)?)'
-_ampm = '(?P<ampm>[ap][m.]+)'
-
-_time = (_hour + ':' + _minute + '(?::' + _second + '|[^:]|$) *'
-         + _ampm + '? *' + _zone + '?')
-_isotime = _hour + ':?' + _minute + ':?' + _second + '? *' + _zone + '?'
-
-_yeardate = _year
-_weekdate = _year + '-?(?:' + _week + '-?' + _day + '?)?'
-_eurodate = _day + '\.' + _month + '\.' + _year_epoch + '?'
-_usdate = _month + '/' + _day + '(?:/' + _year_epoch + '|[^/]|$)'
-_altusdate = _month + '-' + _day + '-' + _fullyear_epoch
-_isodate = _year + '-' + _month + '-?' + _day + '?(?!:)'
-_altisodate = _year + _fullmonth + _fullday + '(?!:)'
-_usisodate = _fullyear + '/' + _fullmonth + '/' + _fullday
-_litdate = ('(?:'+ _litday + ',? )? *' +
-            _usday + ' *' +
-            '[- ] *(?:' + _litmonth + '|'+ _month +') *[- ] *' +
-            _year_epoch + '?')
-_altlitdate = ('(?:'+ _litday + ',? )? *' +
-               _litmonth + '[ ,.a-z]+' +
-               _usday +
-               '(?:[ a-z]+' + _year_epoch + ')?')
-_eurlitdate = ('(?:'+ _litday + ',?[ a-z]+)? *' +
-               '(?:'+ _usday + '[ a-z]+)? *' +
-               _litmonth +
-               '(?:[ ,.a-z]+' + _year_epoch + ')?')
-
-_relany = '[*%?a-zA-Z]+'
-
-_relisodate = ('(?:(?:' + _relany + '|' + _year + '|' + _relyear + ')-' +
-               '(?:' + _relany + '|' + _month + '|' + _relmonth + ')-' +
-               '(?:' + _relany + '|' + _day + '|' + _relday + '))')
-
-_asctime = ('(?:'+ _litday + ',? )? *' +
-                _usday + ' *' +
-                '[- ] *(?:' + _litmonth + '|'+ _month +') *[- ]' +
-                '(?:[0-9: ]+)' +
-                _year_epoch + '?')
-
-_relisotime = ('(?:(?:' + _relany + '|' + _hour + '|' + _relhours + '):' +
-               '(?:' + _relany + '|' + _minute + '|' + _relminutes + ')' +
-               '(?::(?:' + _relany + '|' + _second + '|' + _relseconds + '))?)')
-
-_isodelta1 = (_sign + '?' +
-              _days + ':' + _hours + ':' + _minutes + ':' + _seconds)
-_isodelta2 = (_sign + '?' +
-              _hours + ':' + _minutes + ':' + _seconds)
-_isodelta3 = (_sign + '?' +
-              _hours + ':' + _minutes)
-_litdelta = (_sign + '?' +
-             '(?:' + _days + ' *d[a-z]*[,; ]*)?' +
-             '(?:' + _hours + ' *h[a-z]*[,; ]*)?' +
-             '(?:' + _minutes + ' *m[a-z]*[,; ]*)?' +
-             '(?:' + _seconds + ' *s[a-z]*[,; ]*)?')
-_litdelta2 = (_sign + '?' +
-             '(?:' + _days + ' *d[a-z]*[,; ]*)?' +
-              _hours + ':' + _minutes + '(?::' + _seconds + ')?')
-
-_timeRE = re.compile(_time, re.I)
-_isotimeRE = re.compile(_isotime, re.I)
-_isodateRE = re.compile(_isodate, re.I)
-_altisodateRE = re.compile(_altisodate, re.I)
-_usisodateRE = re.compile(_usisodate, re.I)
-_yeardateRE = re.compile(_yeardate, re.I)
-_eurodateRE = re.compile(_eurodate, re.I)
-_usdateRE = re.compile(_usdate, re.I)
-_altusdateRE = re.compile(_altusdate, re.I)
-_litdateRE = re.compile(_litdate, re.I)
-_altlitdateRE = re.compile(_altlitdate, re.I)
-_eurlitdateRE = re.compile(_eurlitdate, re.I)
-_relisodateRE = re.compile(_relisodate, re.I)
-_asctimeRE = re.compile(_asctime, re.I)
-_isodelta1RE = re.compile(_isodelta1)
-_isodelta2RE = re.compile(_isodelta2)
-_isodelta3RE = re.compile(_isodelta3)
-_litdeltaRE = re.compile(_litdelta)
-_litdelta2RE = re.compile(_litdelta2)
-_relisotimeRE = re.compile(_relisotime, re.I)
-
-# Available date parsers
-_date_formats = ('euro',
-                 'usiso', 'us', 'altus',
-                 'iso', 'altiso',
-                 'lit', 'altlit', 'eurlit',
-                 'year', 'unknown')
-
-# Available time parsers
-_time_formats = ('standard',
-                 'iso',
-                 'unknown')
-
-_zoneoffset = ('(?:'
-              '(?P<zonesign>[+-])?'
-              '(?P<hours>\d\d?)'
-              ':?'
-              '(?P<minutes>\d\d)?'
-              '(?P<extra>\d+)?'
-              ')'
-              )
-
-_zoneoffsetRE = re.compile(_zoneoffset)
-
-_zonetable = {
-              # Timezone abbreviations
-              # Std     Summer
-
-              # Standards
-              'UT':0,
-              'UTC':0,
-              'GMT':0,
-
-              # A few common timezone abbreviations
-              'CET':1,  'CEST':2, 'CETDST':2, # Central European
-              'MET':1,  'MEST':2, 'METDST':2, # Mean European
-              'MEZ':1,  'MESZ':2,             # Mitteleuropische Zeit
-              'EET':2,  'EEST':3, 'EETDST':3, # Eastern Europe
-              'WET':0,  'WEST':1, 'WETDST':1, # Western Europe
-              'MSK':3,  'MSD':4,  # Moscow
-              'IST':5.5,          # India
-              'JST':9,            # Japan
-              'KST':9,            # Korea
-              'HKT':8,            # Hong Kong
-
-              # US time zones
-              'AST':-4, 'ADT':-3, # Atlantic
-              'EST':-5, 'EDT':-4, # Eastern
-              'CST':-6, 'CDT':-5, # Central
-              'MST':-7, 'MDT':-6, # Midwestern
-              'PST':-8, 'PDT':-7, # Pacific
-
-              # Australian time zones
-              'CAST':9.5, 'CADT':10.5, # Central
-              'EAST':10,  'EADT':11,   # Eastern
-              'WAST':8,   'WADT':9,    # Western
-              'SAST':9.5, 'SADT':10.5, # Southern
-
-              # US military time zones
-              'Z': 0,
-              'A': 1,
-              'B': 2,
-              'C': 3,
-              'D': 4,
-              'E': 5,
-              'F': 6,
-              'G': 7,
-              'H': 8,
-              'I': 9,
-              'K': 10,
-              'L': 11,
-              'M': 12,
-              'N':-1,
-              'O':-2,
-              'P':-3,
-              'Q':-4,
-              'R':-5,
-              'S':-6,
-              'T':-7,
-              'U':-8,
-              'V':-9,
-              'W':-10,
-              'X':-11,
-              'Y':-12
-              }
-
-
-def utc_offset(zone):
-    """ utc_offset(zonestring)
-
-        Return the UTC time zone offset in minutes.
-
-        zone must be string and can either be given as +-HH:MM,
-        +-HHMM, +-HH numeric offset or as time zone
-        abbreviation. Daylight saving time must be encoded into the
-        zone offset.
-
-        Timezone abbreviations are treated case-insensitive.
-
-    """
-    if not zone:
-        return 0
-    uzone = zone.upper()
-    if uzone in _zonetable:
-        return _zonetable[uzone]*60
-    offset = _zoneoffsetRE.match(zone)
-    if not offset:
-        raise ValueError,'wrong format or unkown time zone: "%s"' % zone
-    zonesign,hours,minutes,extra = offset.groups()
-    if extra:
-        raise ValueError,'illegal time zone offset: "%s"' % zone
-    offset = int(hours or 0) * 60 + int(minutes or 0)
-    if zonesign == '-':
-        offset = -offset
-    return offset
-
-def add_century(year):
-
-    """ Sliding window approach to the Y2K problem: adds a suitable
-        century to the given year and returns it as integer.
-
-        The window used depends on the current year. If adding the current
-        century to the given year gives a year within the range
-        current_year-70...current_year+30 [both inclusive], then the
-        current century is added. Otherwise the century (current + 1 or
-        - 1) producing the least difference is chosen.
-
-    """
-
-    current_year=dt.datetime.now().year
-    current_century=(dt.datetime.now().year / 100) * 100
-
-    if year > 99:
-        # Take it as-is
-        return year
-    year = year + current_century
-    diff = year - current_year
-    if diff >= -70 and diff <= 30:
-        return year
-    elif diff < -70:
-        return year + 100
-    else:
-        return year - 100
-
-
-def _parse_date(text):
-    """
-    Parses the date part given in text and returns a tuple
-    (text,day,month,year,style) with the following meanings:
-
-    * text gives the original text without the date part
-
-    * day,month,year give the parsed date
-
-    * style gives information about which parser was successful:
-      'euro' - the European date parser
-      'us' - the US date parser
-      'altus' - the alternative US date parser (with '-' instead of '/')
-      'iso' - the ISO date parser
-      'altiso' - the alternative ISO date parser (without '-')
-      'usiso' - US style ISO date parser (yyyy/mm/dd)
-      'lit' - the US literal date parser
-      'altlit' - the alternative US literal date parser
-      'eurlit' - the Eurpean literal date parser
-      'unknown' - no date part was found, defaultdate was used
-
-    Formats may be set to a tuple of style strings specifying which of the above
-    parsers to use and in which order to try them.
-    Default is to try all of them in the above order.
-
-    ``defaultdate`` provides the defaults to use in case no date part is found.
-    Most other parsers default to the current year January 1 if some of these
-    date parts are missing.
-
-    If ``'unknown'`` is not given in formats and the date cannot be parsed,
-    a :exc:`ValueError` is raised.
-
-    """
-    match = None
-    style = ''
-
-    formats = _date_formats
-
-    us_formats=('us', 'altus')
-    iso_formats=('iso', 'altiso', 'usiso')
-
-    now=dt.datetime.now
-
-    # Apply parsers in the order given in formats
-    for format in formats:
-
-        if format == 'euro':
-            # European style date
-            match = _eurodateRE.search(text)
-            if match is not None:
-                day,month,year,epoch = match.groups()
-                if year:
-                    if len(year) == 2:
-                        # Y2K problem:
-                        year = add_century(int(year))
-                    else:
-                        year = int(year)
-                else:
-                    defaultdate = now()
-                    year = defaultdate.year
-                if epoch and 'B' in epoch:
-                    year = -year + 1
-                month = int(month)
-                day = int(day)
-                # Could have mistaken euro format for us style date
-                # which uses month, day order
-                if month > 12 or month == 0:
-                    match = None
-                    continue
-                break
-
-        elif format == 'year':
-            # just a year specified
-            match = _yeardateRE.match(text)
-            if match is not None:
-                year = match.groups()[0]
-                if year:
-                    if len(year) == 2:
-                        # Y2K problem:
-                        year = add_century(int(year))
-                    else:
-                        year = int(year)
-                else:
-                    defaultdate = now()
-                    year = defaultdate.year
-                day = 1
-                month = 1
-                break
-
-        elif format in iso_formats:
-            # ISO style date
-            if format == 'iso':
-                match = _isodateRE.search(text)
-            elif format == 'altiso':
-                match = _altisodateRE.search(text)
-                # Avoid mistaking ISO time parts ('Thhmmss') for dates
-                if match is not None:
-                    left, right = match.span()
-                    if left > 0 and \
-                       text[left - 1:left] == 'T':
-                        match = None
-                        continue
-            else:
-                match = _usisodateRE.search(text)
-            if match is not None:
-                year,month,day = match.groups()
-                if len(year) == 2:
-                    # Y2K problem:
-                    year = add_century(int(year))
-                else:
-                    year = int(year)
-                # Default to January 1st
-                if not month:
-                    month = 1
-                else:
-                    month = int(month)
-                if not day:
-                    day = 1
-                else:
-                    day = int(day)
-                break
-
-        elif format in us_formats:
-            # US style date
-            if format == 'us':
-                match = _usdateRE.search(text)
-            else:
-                match = _altusdateRE.search(text)
-            if match is not None:
-                month,day,year,epoch = match.groups()
-                if year:
-                    if len(year) == 2:
-                        # Y2K problem:
-                        year = add_century(int(year))
-                    else:
-                        year = int(year)
-                else:
-                    defaultdate = now()
-                    year = defaultdate.year
-                if epoch and 'B' in epoch:
-                    year = -year + 1
-                # Default to 1 if no day is given
-                if day:
-                    day = int(day)
-                else:
-                    day = 1
-                month = int(month)
-                # Could have mistaken us format for euro style date
-                # which uses day, month order
-                if month > 12 or month == 0:
-                    match = None
-                    continue
-                break
-
-        elif format == 'lit':
-            # US style literal date
-            match = _litdateRE.search(text)
-            if match is not None:
-                litday,day,litmonth,month,year,epoch = match.groups()
-                break
-
-        elif format == 'altlit':
-            # Alternative US style literal date
-            match = _altlitdateRE.search(text)
-            if match is not None:
-                litday,litmonth,day,year,epoch = match.groups()
-                month = '<missing>'
-                break
-
-        elif format == 'eurlit':
-            # European style literal date
-            match = _eurlitdateRE.search(text)
-            if match is not None:
-                litday,day,litmonth,year,epoch = match.groups()
-                month = '<missing>'
-                break
-
-        elif format == 'unknown':
-            # No date part: use defaultdate
-            defaultdate = now()
-            year = defaultdate.year
-            month = defaultdate.month
-            day = defaultdate.day
-            style = format
-            break
-
-    # Check success
-    if match is not None:
-        # Remove date from text
-        left, right = match.span()
-        if 0 and _debug:
-            print 'parsed date:',repr(text[left:right]),\
-                  'giving:',year,month,day
-        text = text[:left] + text[right:]
-        style = format
-
-    elif not style:
-        # Not recognized: raise an error
-        raise ValueError, 'unknown date format: "%s"' % text
-
-    # Literal date post-processing
-    if style in ('lit', 'altlit', 'eurlit'):
-        if 0 and _debug: print match.groups()
-        # Default to current year, January 1st
-        if not year:
-            defaultdate = now()
-            year = defaultdate.year
-        else:
-            if len(year) == 2:
-                # Y2K problem:
-                year = add_century(int(year))
-            else:
-                year = int(year)
-        if epoch and 'B' in epoch:
-            year = -year + 1
-        if litmonth:
-            litmonth = litmonth.lower()
-            try:
-                month = litmonthtable[litmonth]
-            except KeyError:
-                raise ValueError,\
-                      'wrong month name: "%s"' % litmonth
-        elif month:
-            month = int(month)
-        else:
-            month = 1
-        if day:
-            day = int(day)
-        else:
-            day = 1
-
-    #print '_parse_date:',text,day,month,year,style
-    return text,day,month,year,style
-
-def _parse_time(text):
-
-    """ Parses a time part given in text and returns a tuple
-        (text,hour,minute,second,offset,style) with the following
-        meanings:
-
-        * text gives the original text without the time part
-        * hour,minute,second give the parsed time
-        * offset gives the time zone UTC offset
-        * style gives information about which parser was successful:
-          'standard' - the standard parser
-          'iso' - the ISO time format parser
-          'unknown' - no time part was found
-
-        formats may be set to a tuple specifying the parsers to use:
-          'standard' - standard time format with ':' delimiter
-          'iso' - ISO time format (superset of 'standard')
-          'unknown' - default to 0:00:00, 0 zone offset
-
-        If 'unknown' is not given in formats and the time cannot be
-        parsed, a ValueError is raised.
-
-    """
-    match = None
-    style = ''
-
-    formats=_time_formats
-
-    # Apply parsers in the order given in formats
-    for format in formats:
-
-        # Standard format
-        if format == 'standard':
-            match = _timeRE.search(text)
-            if match is not None:
-                hour,minute,second,ampm,zone = match.groups()
-                style = 'standard'
-                break
-
-        # ISO format
-        if format == 'iso':
-            match =  _isotimeRE.search(text)
-            if match is not None:
-                hour,minute,second,zone = match.groups()
-                ampm = None
-                style = 'iso'
-                break
-
-        # Default handling
-        elif format == 'unknown':
-            hour,minute,second,offset = 0,0,0.0,0
-            style = 'unknown'
-            break
-
-    if not style:
-        # If no default handling should be applied, raise an error
-        raise ValueError, 'unknown time format: "%s"' % text
-
-    # Post-processing
-    if match is not None:
-
-        if zone:
-            # Convert to UTC offset
-            offset = utc_offset(zone)
-        else:
-            offset = 0
-
-        hour = int(hour)
-        if ampm:
-            if ampm[0] in ('p', 'P'):
-                # 12pm = midday
-                if hour < 12:
-                    hour = hour + 12
-            else:
-                # 12am = midnight
-                if hour >= 12:
-                    hour = hour - 12
-        if minute:
-            minute = int(minute)
-        else:
-            minute = 0
-        if not second:
-            second = 0.0
-        else:
-            if ',' in second:
-                second = second.replace(',', '.')
-            second = float(second)
-
-        # Remove time from text
-        left,right = match.span()
-        if 0 and _debug:
-            print 'parsed time:',repr(text[left:right]),\
-                  'giving:',hour,minute,second,offset
-        text = text[:left] + text[right:]
-
-    #print '_parse_time:',text,hour,minute,second,offset,style
-    return text,hour,minute,second,offset,style
-
-###
-
-def DateTimeFromString(text):
-
-    """ DateTimeFromString(text, [formats, defaultdate])
-
-        Returns a datetime instance reflecting the date and time given
-        in text. In case a timezone is given, the returned instance
-        will point to the corresponding UTC time value. Otherwise, the
-        value is set as given in the string.
-
-        formats may be set to a tuple of strings specifying which of
-        the following parsers to use and in which order to try
-        them. Default is to try all of them in the order given below:
-
-          'euro' - the European date parser
-          'us' - the US date parser
-          'altus' - the alternative US date parser (with '-' instead of '/')
-          'iso' - the ISO date parser
-          'altiso' - the alternative ISO date parser (without '-')
-          'usiso' - US style ISO date parser (yyyy/mm/dd)
-          'lit' - the US literal date parser
-          'altlit' - the alternative US literal date parser
-          'eurlit' - the Eurpean literal date parser
-          'unknown' - if no date part is found, use defaultdate
-
-        defaultdate provides the defaults to use in case no date part
-        is found. Most of the parsers default to the current year
-        January 1 if some of these date parts are missing.
-
-        If 'unknown' is not given in formats and the date cannot
-        be parsed, a ValueError is raised.
-
-        time_formats may be set to a tuple of strings specifying which
-        of the following parsers to use and in which order to try
-        them. Default is to try all of them in the order given below:
-
-          'standard' - standard time format HH:MM:SS (with ':' delimiter)
-          'iso' - ISO time format (superset of 'standard')
-          'unknown' - default to 00:00:00 in case the time format
-                      cannot be parsed
-
-        Defaults to 00:00:00.00 for time parts that are not included
-        in the textual representation.
-
-        If 'unknown' is not given in time_formats and the time cannot
-        be parsed, a ValueError is raised.
-
-    """
-    origtext = text
-
-    text,hour,minute,second,offset,timestyle = _parse_time(origtext)
-    text,day,month,year,datestyle = _parse_date(text)
-
-    if 0 and _debug:
-        print 'tried time/date on %s, date=%s, time=%s' % (origtext,
-                                                           datestyle,
-                                                           timestyle)
-
-    # If this fails, try the ISO order (date, then time)
-    if timestyle in ('iso', 'unknown'):
-        text,day,month,year,datestyle = _parse_date(origtext)
-        text,hour,minute,second,offset,timestyle = _parse_time(text)
-        if 0 and _debug:
-            print 'tried ISO on %s, date=%s, time=%s' % (origtext,
-                                                         datestyle,
-                                                         timestyle)
-
-    try:
-        microsecond = int(1000000 * (second % 1))
-        second = int(second)
-        return dt.datetime(year,month,day,hour,minute,second, microsecond) - \
-                                        dt.timedelta(minutes=offset)
-    except ValueError, why:
-        raise RangeError,\
-              'Failed to parse "%s": %s' % (origtext, why)
-
-def DateFromString(text):
-
-    """ DateFromString(text, [formats, defaultdate])
-
-        Returns a datetime instance reflecting the date given in
-        text. A possibly included time part is ignored.
-
-        formats and defaultdate work just like for
-        DateTimeFromString().
-
-    """
-    _text,day,month,year,datestyle = _parse_date(text)
-
-    try:
-        return dt.datetime(year,month,day)
-    except ValueError, why:
-        raise RangeError,\
-              'Failed to parse "%s": %s' % (text, why)
-
-def validateDateTimeString(text):
-
-    """ validateDateTimeString(text, [formats, defaultdate])
-
-        Validates the given text and returns 1/0 depending on whether
-        text includes parseable date and time values or not.
-
-        formats works just like for DateTimeFromString() and defines
-        the order of date/time parsers to apply. It defaults to the
-        same list of parsers as for DateTimeFromString().
-
-        XXX Undocumented !
-
-    """
-    try:
-        DateTimeFromString(text)
-    except ValueError, why:
-        return 0
-    return 1
-
-
-def validateDateString(text):
-
-    """ validateDateString(text, [formats, defaultdate])
-
-        Validates the given text and returns 1/0 depending on whether
-        text includes a parseable date value or not.
-
-        formats works just like for DateTimeFromString() and defines
-        the order of date/time parsers to apply. It defaults to the
-        same list of parsers as for DateTimeFromString().
-
-        XXX Undocumented !
-
-    """
-    try:
-        DateFromString(text)
-    except ValueError, why:
-        return 0
-    return 1
-
-### Tests
-
-def _test():
-
-    import sys
-
-    t = dt.datetime.now()
-    _date = t.strftime('%Y-%m-%d')
-
-    print 'Testing DateTime Parser...'
-
-    l = [
-
-        # Literal formats
-        ('Sun Nov  6 08:49:37 1994', '1994-11-06 08:49:37.00'),
-        ('sun nov  6 08:49:37 1994', '1994-11-06 08:49:37.00'),
-        ('sUN NOV  6 08:49:37 1994', '1994-11-06 08:49:37.00'),
-        ('Sunday, 06-Nov-94 08:49:37 GMT', '1994-11-06 08:49:37.00'),
-        ('Sun, 06 Nov 1994 08:49:37 GMT', '1994-11-06 08:49:37.00'),
-        ('06-Nov-94 08:49:37', '1994-11-06 08:49:37.00'),
-        ('06-Nov-94', '1994-11-06 00:00:00.00'),
-        ('06-NOV-94', '1994-11-06 00:00:00.00'),
-        ('November 19 08:49:37', '%s-11-19 08:49:37.00' % t.year),
-        ('Nov. 9', '%s-11-09 00:00:00.00' % t.year),
-        ('Sonntag, der 6. November 1994, 08:49:37 GMT', '1994-11-06 08:49:37.00'),
-        ('6. November 2001, 08:49:37', '2001-11-06 08:49:37.00'),
-        ('sep 6', '%s-09-06 00:00:00.00' % t.year),
-        ('sep 6 2000', '2000-09-06 00:00:00.00'),
-        ('September 29', '%s-09-29 00:00:00.00' % t.year),
-        ('Sep. 29', '%s-09-29 00:00:00.00' % t.year),
-        ('6 sep', '%s-09-06 00:00:00.00' % t.year),
-        ('29 September', '%s-09-29 00:00:00.00' % t.year),
-        ('29 Sep.', '%s-09-29 00:00:00.00' % t.year),
-        ('sep 6 2001', '2001-09-06 00:00:00.00'),
-        ('Sep 6, 2001', '2001-09-06 00:00:00.00'),
-        ('September 6, 2001', '2001-09-06 00:00:00.00'),
-        ('sep 6 01', '2001-09-06 00:00:00.00'),
-        ('Sep 6, 01', '2001-09-06 00:00:00.00'),
-        ('September 6, 01', '2001-09-06 00:00:00.00'),
-        ('30 Apr 2006 20:19:00', '2006-04-30 20:19:00.00'),
-
-        # ISO formats
-        ('1994-11-06 08:49:37', '1994-11-06 08:49:37.00'),
-        ('010203', '2001-02-03 00:00:00.00'),
-        ('2001-02-03 00:00:00.00', '2001-02-03 00:00:00.00'),
-        ('2001-02 00:00:00.00', '2001-02-01 00:00:00.00'),
-        ('2001-02-03', '2001-02-03 00:00:00.00'),
-        ('2001-02', '2001-02-01 00:00:00.00'),
-        ('20000824/2300', '2000-08-24 23:00:00.00'),
-        ('20000824/0102', '2000-08-24 01:02:00.00'),
-        ('20000824', '2000-08-24 00:00:00.00'),
-        ('20000824/020301', '2000-08-24 02:03:01.00'),
-        ('20000824 020301', '2000-08-24 02:03:01.00'),
-        ('20000824T020301', '2000-08-24 02:03:01.00'),
-        ('20000824 020301', '2000-08-24 02:03:01.00'),
-        ('2000-08-24 02:03:01.00', '2000-08-24 02:03:01.00'),
-        ('T020311', '%s 02:03:11.00' % _date),
-        ('2003-12-9', '2003-12-09 00:00:00.00'),
-        ('03-12-9', '2003-12-09 00:00:00.00'),
-        ('003-12-9', '0003-12-09 00:00:00.00'),
-        ('0003-12-9', '0003-12-09 00:00:00.00'),
-        ('2003-1-9', '2003-01-09 00:00:00.00'),
-        ('03-1-9', '2003-01-09 00:00:00.00'),
-        ('003-1-9', '0003-01-09 00:00:00.00'),
-        ('0003-1-9', '0003-01-09 00:00:00.00'),
-
-        # US formats
-        ('06/11/94 08:49:37', '1994-06-11 08:49:37.00'),
-        ('11/06/94 08:49:37', '1994-11-06 08:49:37.00'),
-        ('9/23/2001', '2001-09-23 00:00:00.00'),
-        ('9-23-2001', '2001-09-23 00:00:00.00'),
-        ('9/6', '%s-09-06 00:00:00.00' % t.year),
-        ('09/6', '%s-09-06 00:00:00.00' % t.year),
-        ('9/06', '%s-09-06 00:00:00.00' % t.year),
-        ('09/06', '%s-09-06 00:00:00.00' % t.year),
-        ('9/6/2001', '2001-09-06 00:00:00.00'),
-        ('09/6/2001', '2001-09-06 00:00:00.00'),
-        ('9/06/2001', '2001-09-06 00:00:00.00'),
-        ('09/06/2001', '2001-09-06 00:00:00.00'),
-        ('9-6-2001', '2001-09-06 00:00:00.00'),
-        ('09-6-2001', '2001-09-06 00:00:00.00'),
-        ('9-06-2001', '2001-09-06 00:00:00.00'),
-        ('09-06-2001', '2001-09-06 00:00:00.00'),
-        ('2002/05/28 13:10:56.1147 GMT+2', '2002-05-28 13:10:56.114699'),
-        ('1970/01/01', '1970-01-01 00:00:00.00'),
-        ('20021025 12:00 PM', '2002-10-25 12:00:00.00'),
-        ('20021025 12:30 PM', '2002-10-25 12:30:00.00'),
-        ('20021025 12:00 AM', '2002-10-25 00:00:00.00'),
-        ('20021025 12:30 AM', '2002-10-25 00:30:00.00'),
-        ('20021025 1:00 PM', '2002-10-25 13:00:00.00'),
-        ('20021025 2:00 AM', '2002-10-25 02:00:00.00'),
-        ('Thursday, February 06, 2003 12:40 PM', '2003-02-06 12:40:00.00'),
-        ('Mon, 18 Sep 2006 23:03:00', '2006-09-18 23:03:00.00'),
-
-        # European formats
-        ('6.11.2001, 08:49:37', '2001-11-06 08:49:37.00'),
-        ('06.11.2001, 08:49:37', '2001-11-06 08:49:37.00'),
-        ('06.11. 08:49:37', '%s-11-06 08:49:37.00' % t.year),
-        #('21/12/2002', '2002-12-21 00:00:00.00'),
-        #('21/08/2002', '2002-08-21 00:00:00.00'),
-        #('21-08-2002', '2002-08-21 00:00:00.00'),
-        #('13/01/03', '2003-01-13 00:00:00.00'),
-        #('13/1/03', '2003-01-13 00:00:00.00'),
-        #('13/1/3', '2003-01-13 00:00:00.00'),
-        #('13/01/3', '2003-01-13 00:00:00.00'),
-
-        # Time only formats
-        ('01:03', '%s 01:03:00.00' % _date),
-        ('01:03:11', '%s 01:03:11.00' % _date),
-        ('01:03:11.50', '%s 01:03:11.500000' % _date),
-        ('01:03:11.50 AM', '%s 01:03:11.500000' % _date),
-        ('01:03:11.50 PM', '%s 13:03:11.500000' % _date),
-        ('01:03:11.50 a.m.', '%s 01:03:11.500000' % _date),
-        ('01:03:11.50 p.m.', '%s 13:03:11.500000' % _date),
-
-        # Invalid formats
-        ('6..2001, 08:49:37', '%s 08:49:37.00' % _date),
-        ('9//2001', 'ignore'),
-        ('06--94 08:49:37', 'ignore'),
-        ('20-03 00:00:00.00', 'ignore'),
-        ('9/2001', 'ignore'),
-        ('9-6', 'ignore'),
-        ('09-6', 'ignore'),
-        ('9-06', 'ignore'),
-        ('09-06', 'ignore'),
-        ('20000824/23', 'ignore'),
-        ('November 1994 08:49:37', 'ignore'),
-        ]
-
-    # Add Unicode versions
-    try:
-        unicode
-    except NameError:
-        pass
-    else:
-        k = []
-        for text, result in l:
-            k.append((unicode(text), result))
-        l.extend(k)
-
-    for text, reference in l:
-        try:
-            value = DateTimeFromString(text)
-        except:
-            if reference is None:
-                continue
-            else:
-                value = str(sys.exc_info()[1])
-        valid_datetime = validateDateTimeString(text)
-        valid_date = validateDateString(text)
-
-        if reference[-3:] == '.00': reference = reference[:-3]
-
-        if str(value) != reference and \
-           not reference == 'ignore':
-            print 'Failed to parse "%s"' % text
-            print '  expected: %s' % (reference or '<exception>')
-            print '  parsed:   %s' % value
-        elif _debug:
-            print 'Parsed "%s" successfully' % text
-        if _debug:
-            if not valid_datetime:
-                print '  "%s" failed date/time validation' % text
-            if not valid_date:
-                print '  "%s" failed date validation' % text
-
-    et = dt.datetime.now()
-    print 'done. (after %f seconds)' % ((et-t).seconds)
-
-if __name__ == '__main__':
-    _test()
diff --git a/pandas/timeseries/setup.py b/pandas/timeseries/setup.py
deleted file mode 100644
index e0f5128ad..000000000
--- a/pandas/timeseries/setup.py
+++ /dev/null
@@ -1,28 +0,0 @@
-
-__revision__ = "$Revision$"
-__date__     = '$Date$'
-
-import os
-from os.path import join
-
-def configuration(parent_package='',top_path=None):
-    from numpy.distutils.misc_util import Configuration, get_numpy_include_dirs
-    nxheader = join(get_numpy_include_dirs()[0],'numpy',)
-    confgr = Configuration('timeseries',parent_package,top_path)
-    sources = [join('src', x) for x in ('c_lib.c',
-                                        'c_dates.c',
-                                        'c_tseries.c',
-                                        'pandas._skts.c')]
-    confgr.add_extension('pandas._skts',
-                         sources=sources,
-                         include_dirs=[nxheader, 'include'])
-
-    confgr.add_subpackage('lib')
-    confgr.add_subpackage('tests')
-    return confgr
-
-if __name__ == "__main__":
-    from numpy.distutils.core import setup
-    #setup.update(nmasetup)
-    config = configuration(top_path='').todict()
-    setup(**config)
diff --git a/pandas/timeseries/tdates.py b/pandas/timeseries/tdates.py
deleted file mode 100644
index 510fe10e8..000000000
--- a/pandas/timeseries/tdates.py
+++ /dev/null
@@ -1,1155 +0,0 @@
-"""
-Classes definition for the support of individual dates and array of dates.
-
-:author: Pierre GF Gerard-Marchant & Matt Knox
-:contact: pierregm_at_uga_dot_edu - mattknox_ca_at_hotmail_dot_com
-
-"""
-
-# TODO: Implement DateArray in C (Cython ?)
-# TODO: Optimize the cache of DateArray (steps computation, sorting...)
-# TODO: Optimize date_array / _listparser : sort only at the end ?
-# TODO: __getitem__ w/ slice and ischrono : get the proper steps...
-
-__author__ = "Pierre GF Gerard-Marchant & Matt Knox"
-__revision__ = "$Revision$"
-__date__ = '$Date$'
-
-import datetime as dt
-
-import warnings
-
-import numpy as np
-from numpy import ndarray
-import numpy.core.numerictypes as ntypes
-from numpy.core.numerictypes import generic
-
-from parser import DateFromString, DateTimeFromString
-
-import const as _c
-import pandas._skts
-# initialize python callbacks for C code
-pandas._skts.set_callback_DateFromString(DateFromString)
-pandas._skts.set_callback_DateTimeFromString(DateTimeFromString)
-from pandas._skts import Date, now, check_freq, check_freq_str, get_freq_group, \
-                    DateCalc_Error, DateCalc_RangeError
-
-__all__ = ['ArithmeticDateError',
-           'Date', 'DateArray', 'DateCalc_Error', 'DateCalc_RangeError',
-           'DateError',
-           'FrequencyDateError',
-           'InsufficientDateError',
-           'check_freq', 'check_freq_str', 'convert_to_float',
-           'date_array', 'day', 'day_of_year',
-           'get_freq_group',
-           'hour',
-           'minute', 'month',
-           'nodates', 'now',
-           'period_break', 'prevbusday',
-           'quarter',
-           'second',
-           'weekday',
-           'week',
-           'year',
-          ]
-
-#####---------------------------------------------------------------------------
-#---- --- Date Exceptions ---
-#####---------------------------------------------------------------------------
-class DateError(Exception):
-    """
-    Defines a generic DateArrayError.
-    """
-    def __init__ (self, value=None):
-        "Creates an exception."
-        self.value = value
-    def __str__(self):
-        "Calculates the string representation."
-        return str(self.value)
-    __repr__ = __str__
-
-class InsufficientDateError(DateError):
-    """
-    Defines the exception raised when there is not enough information
-    to create a Date object.
-    """
-    def __init__(self, msg=None):
-        if msg is None:
-            msg = "Insufficient parameters to create a date "\
-                  "at the given frequency."
-        DateError.__init__(self, msg)
-
-class FrequencyDateError(DateError):
-    """
-    Defines the exception raised when the frequencies are incompatible.
-    """
-    def __init__(self, msg, freql=None, freqr=None):
-        msg += " : Incompatible frequencies!"
-        if not (freql is None or freqr is None):
-            msg += " (%s<>%s)" % (freql, freqr)
-        DateError.__init__(self, msg)
-
-class ArithmeticDateError(DateError):
-    """
-    Defines the exception raised when dates are used in arithmetic expressions.
-    """
-    def __init__(self, msg=''):
-        msg += " Cannot use dates for arithmetics!"
-        DateError.__init__(self, msg)
-
-
-#####---------------------------------------------------------------------------
-#---- --- Functions ---
-#####---------------------------------------------------------------------------
-
-def prevbusday(day_end_hour=18, day_end_min=0):
-    """
-    Returns the previous business day (Monday-Friday) at business frequency.
-
-    Parameters
-    ----------
-    day_end_hour : {18, int}, optional
-        Hour of the end of a business day.
-    day_end_min : {0, int}, optional
-        Minutes of the end of a business day.
-
-    Notes
-    -----
-    If it is currently Saturday or Sunday, then the preceding Friday will be
-    returned.
-    If it is later than the specified ``day_end_hour`` and ``day_end_min``,
-    ``now('Business')`` will be returned.
-    Otherwise, ``now('Business')-1`` will be returned.
-
-    """
-    tempDate = dt.datetime.now()
-    dateNum = tempDate.hour + float(tempDate.minute) / 60
-    checkNum = day_end_hour + float(day_end_min) / 60
-    if dateNum < checkNum and tempDate.weekday() < 5:
-        return now(_c.FR_BUS) - 1
-    else:
-        return now(_c.FR_BUS)
-
-#####---------------------------------------------------------------------------
-#---- --- DateArray ---
-#####---------------------------------------------------------------------------
-def _check_chronological_order(dates):
-    """
-    Checks whether dates are in the chronological order.
-    If not, output the indices corresponding to the chronological order.
-    Otherwise, output None.
-    """
-    idx = dates.argsort()
-    if (idx[1:] - idx[:-1] < 0).any():
-        return idx.view(ndarray)
-    return
-
-
-ufunc_dateOK = ['add', 'subtract',
-                'equal', 'not_equal', 'less', 'less_equal',
-                'greater', 'greater_equal',
-                'isnan']
-
-class _datearithmetics(object):
-    """
-    Defines a wrapper for arithmetic methods.
-    Instead of directly calling a ufunc, the corresponding method of the `._data`
-    object is called instead.
-    If `asdates` is True, a DateArray object is returned , else a regular ndarray
-    is returned.
-    """
-    def __init__ (self, methodname, asdates=True):
-        """
-    Parameters
-    ----------
-    methodname : string
-        Method name.
-    asdates : {True, False}
-        Whether to return a DateArray object (True) or a regular ndarray.
-        """
-        self.methodname = methodname
-        self._asdates = asdates
-        self.__doc__ = getattr(methodname, '__doc__')
-        self.obj = None
-    #
-    def __get__(self, obj, objtype=None):
-        self.obj = obj
-        return self
-    #
-    def __call__ (self, other, *args, **kwargs):
-        "Execute the call behavior."
-        instance = self.obj
-        freq = instance.freq
-        if 'context' not in kwargs:
-            kwargs['context'] = 'DateOK'
-        method = getattr(super(DateArray, instance), self.methodname)
-        other_val = other
-        if isinstance(other, DateArray):
-            if other.freq != freq:
-                raise FrequencyDateError("Cannot operate on dates", \
-                                         freq, other.freq)
-        elif isinstance(other, Date):
-            if other.freq != freq:
-                raise FrequencyDateError("Cannot operate on dates", \
-                                         freq, other.freq)
-            other_val = other.value
-        elif isinstance(other, ndarray):
-            if other.dtype.kind not in ['i', 'f']:
-                raise ArithmeticDateError
-        if self._asdates and not isinstance(other, (DateArray, Date)):
-            return instance.__class__(method(other_val, *args),
-                                      freq=freq)
-        else:
-            return method(other_val, *args).view(np.ndarray)
-
-
-
-class DateArray(ndarray):
-    """
-    Defines a ndarray of dates, as ordinals.
-
-    When viewed globally (array-wise), ``DateArray`` is an array of integers.
-    When viewed element-wise, ``DateArray`` is a sequence of dates.
-    For example, a test such as :
-
-    >>> DateArray(...) == value
-
-    will be valid only if value is an integer, not a :class:`Date` object.
-    However, a loop such as :
-
-    >>> for d in DateArray(...):
-
-    accesses the array element by element. Therefore, `d` is a :class:`Date` object.
-    """
-
-    def __new__(cls, dates=None, freq=None, copy=False):
-        # Get the frequency ......
-        if freq is None:
-            _freq = getattr(dates, 'freq', _c.FR_UND)
-        else:
-            _freq = check_freq(freq)
-        # Get the dates ..........
-        _dates = np.array(dates, copy=copy, dtype=int, subok=1)
-        if _dates.ndim == 0:
-            _dates.shape = (1,)
-        _dates = _dates.view(cls)
-        _dates.freq = _freq
-        #
-        _cached = _dates._cachedinfo
-        if _cached['ischrono'] is None:
-            sortidx = _dates.__array__().ravel().argsort()
-            sortflag = (sortidx == np.arange(_dates.size)).all()
-            if sortflag:
-                _cached['chronidx'] = None
-            else:
-                _cached['chronidx'] = sortidx
-            _cached['ischrono'] = sortflag
-        return _dates
-
-    def _reset_cachedinfo(self):
-        "Reset the internal cache information"
-        self._cachedinfo = dict(toobj=None, tostr=None, toord=None,
-                                steps=None, full=None, hasdups=None,
-                                chronidx=None, ischrono=None)
-
-    def __array_wrap__(self, obj, context=None):
-        if context is None:
-            return self
-        elif context[0].__name__ not in ufunc_dateOK:
-            raise ArithmeticDateError, "(function %s)" % context[0].__name__
-
-    def __array_finalize__(self, obj):
-        self.freq = getattr(obj, 'freq', _c.FR_UND)
-        self._reset_cachedinfo()
-        self._cachedinfo.update(getattr(obj, '_cachedinfo', {}))
-        return
-
-    def _get_unsorted(self):
-        "Returns the indices of the dates in chronological order"
-        chronidx = self._cachedinfo['chronidx']
-        if chronidx is None:
-            flag = self.is_chronological()
-            chronidx = self._cachedinfo['chronidx']
-        if np.size(chronidx) < 1:
-            return None
-        return chronidx
-    def _set_unsorted(self, value):
-        "Sets the indices of the dates in chronological order"
-        self._cachedinfo.update({'chronidx': value})
-    _unsorted = property(fget=_get_unsorted, fset=_set_unsorted)
-
-    def __getitem__(self, indx):
-        reset_full = True
-        keep_chrono = False
-        # Determine what kind of index is used
-        if isinstance(indx, Date):
-            # indx = self.find_dates(indx)
-            # indx = int(self.find_dates(indx)[0])
-            indx = self.date_to_index(indx)
-            reset_full = False
-        elif isinstance(indx, slice):
-            keep_chrono = True
-        elif np.asarray(indx).dtype.kind == 'O':
-            try:
-                indx = self.find_dates(indx)
-            except AttributeError:
-                pass
-
-        # Select the data
-        r = ndarray.__getitem__(self, indx)
-        # Case 1. A simple integer
-        if isinstance(r, (generic, int)):
-            return Date(self.freq, value=r)
-        elif not getattr(r, 'ndim', 1):
-            # need to check if it has a ndim attribute for situations
-            # like when the datearray is the data for a maskedarray
-            # or some other subclass of ndarray with wierd getitem
-            # behaviour
-            return Date(self.freq, value=r.item())
-        else:
-            if hasattr(r, '_cachedinfo'):
-                _cache = r._cachedinfo
-                # Select the appropriate cached representations
-                _cache.update(dict([(k, _cache[k][indx])
-                                    for k in ('toobj', 'tostr', 'toord')
-                                    if _cache[k] is not None]))
-                # Reset the ischrono flag if needed
-                if not (keep_chrono and _cache['ischrono']):
-                    _cache['ischrono'] = None
-                # Reset the sorting indices
-                _cache['chronidx'] = None
-                # Reset the steps
-                _cache['steps'] = None
-                if reset_full:
-                    _cache['full'] = None
-                    _cache['hasdups'] = None
-            return r
-
-    def __getslice__(self, i, j):
-        """
-    Returns a slice of the date_array
-        """
-        return self.__getitem__(slice(i, j))
-
-
-    def __repr__(self):
-        return ndarray.__repr__(self)[:-1] + \
-               ",\n          freq='%s')" % self.freqstr
-
-
-    def __contains__(self, date):
-        """
-    Used to check whether a single date (or equivalent integer value) is
-    contained in the DateArray.
-        """
-        if isinstance(date, Date) and date.freq != self.freq:
-            raise ValueError(
-                "expected date of frequency '%s' but got date of frequency "\
-                "'%s'" % (self.freqstr, date.freqstr))
-        datenum = np.array(date, dtype=self.dtype)
-        if datenum.ndim != 0:
-            raise ValueError("Cannot check containment of multiple dates")
-        return datenum in self.view(np.ndarray)
-
-    #......................................................
-    __add__ = _datearithmetics('__add__', asdates=True)
-    __radd__ = _datearithmetics('__add__', asdates=True)
-    __sub__ = _datearithmetics('__sub__', asdates=True)
-    __rsub__ = _datearithmetics('__rsub__', asdates=True)
-    __le__ = _datearithmetics('__le__', asdates=False)
-    __lt__ = _datearithmetics('__lt__', asdates=False)
-    __ge__ = _datearithmetics('__ge__', asdates=False)
-    __gt__ = _datearithmetics('__gt__', asdates=False)
-    __eq__ = _datearithmetics('__eq__', asdates=False)
-    __ne__ = _datearithmetics('__ne__', asdates=False)
-    #......................................................
-
-    def min(self, *args, **kwargs):
-        """
-    Returns the minimum Date.
-
-    For a description of the input parameters, please refer to numpy.min.
-        """
-        obj = ndarray.min(self, *args, **kwargs)
-        if not obj.shape:
-            return Date(self.freq, obj)
-        return obj
-
-    def max(self, *args, **kwargs):
-        """
-    Returns the maximum Date.
-
-    For a description of the input parameters, please refer to numpy.max.
-        """
-        obj = ndarray.max(self, *args, **kwargs)
-        if not obj.shape:
-            return Date(self.freq, obj)
-        return obj
-
-    @property
-    def freqstr(self):
-        "Returns the frequency string code."
-        return check_freq_str(self.freq)
-
-    @property
-    def year(self):
-        "Returns the corresponding year for each date of the instance."
-        return self.__getdateinfo__('Y')
-    years = year
-    @property
-    def qyear(self):
-        """
-    For quarterly frequency dates, returns the year corresponding to the
-    year end (start) month. When using QTR or QTR-E based quarterly
-    frequencies, this is the fiscal year in a financial context.
-
-    For non-quarterly dates, this simply returns the year of the date.
-
-    """
-        return self.__getdateinfo__('F')
-    qyears = qyear
-    @property
-    def quarter(self):
-        "Returns the corresponding quarter for each date of the instance."
-        return self.__getdateinfo__('Q')
-    quarters = quarter
-    @property
-    def month(self):
-        "Returns the corresponding month for each month of the instance."
-        return self.__getdateinfo__('M')
-    months = month
-    @property
-    def week(self):
-        "Returns the corresponding week for each week of the instance."
-        return self.__getdateinfo__('I')
-    weeks = week
-    @property
-    def day(self):
-        "Returns the corresponding day of month for each date of the instance."
-        return self.__getdateinfo__('D')
-    days = day
-    @property
-    def day_of_week(self):
-        "Returns the corresponding day of week for each date of the instance."
-        return self.__getdateinfo__('W')
-    weekdays = weekday = day_of_week
-    @property
-    def day_of_year(self):
-        "Returns the corresponding day of year for each date of the instance."
-        return self.__getdateinfo__('R')
-    yeardays = day_of_year
-    @property
-    def hour(self):
-        "Returns the corresponding hour for each date of the instance."
-        return self.__getdateinfo__('H')
-    hours = hour
-    @property
-    def minute(self):
-        "Returns the corresponding minute for each date of the instance."
-        return self.__getdateinfo__('T')
-    minutes = minute
-    @property
-    def second(self):
-        "Returns the corresponding second for each date of the instance."
-        return self.__getdateinfo__('S')
-    seconds = second
-
-    def __getdateinfo__(self, info):
-        return np.asarray(pandas._skts.DA_getDateInfo(np.asarray(self),
-                                                 self.freq, info,
-                                                 int(self.is_full())),
-                          dtype=int)
-    __getDateInfo = __getdateinfo__
-
-    #.... Conversion methods ....................
-
-    def tovalues(self):
-        """
-    Converts the instance to a :class:`~numpy.ndarray` of integers.
-
-    The values correspond to the integer representation of the underlying
-    :class:`Date` objects, as controlled by the frequency attribute.
-
-    Examples
-    --------
-    >>> d = ts.date_array(start_date=ts.Date('M', '2001-01'), length=5)
-    >>> d.tovalues()
-    array([24001, 24002, 24003, 24004, 24005])
-
-        """
-        return np.asarray(self)
-    tovalue = values = tovalues
-    #
-    def toordinals(self):
-        """
-    Converts the dates to the corresponding proleptic Gregorian ordinals,
-    and returns a :class:`~numpy.ndarray` of integers.
-
-    Examples
-    --------
-    >>> d = ts.date_array(start_date=ts.Date('M', '2001-01'), length=5)
-    >>> d.toordinals()
-    array([ 730516.,  730544.,  730575.,  730605.,  730636.])
-
-        """
-        # TODO: Why do we need floats ?
-        # Note: we better try to cache the result
-        if self._cachedinfo['toord'] is None:
-            if self.freq == _c.FR_UND:
-                diter = (d.value for d in self)
-            else:
-                diter = (d.toordinal() for d in self)
-            toord = np.fromiter(diter, dtype=float)
-            self._cachedinfo['toord'] = toord
-        return self._cachedinfo['toord']
-    toordinal = toordinals
-    #
-    def tolist(self):
-        """
-    Returns a hierarchical Python list of standard :class:`datetime.datetime`
-    objects corresponding to the dates of the instance.
-
-    If the input is nD, the list will be nested in a such way that
-    ``np.array(self.tolist())`` is also nD and corresponding to the
-    values of the instance.
-
-    Examples
-    --------
-    >>> d = ts.date_array(start_date=ts.Date('M', '2001-01'), length=5)
-    >>> d.tolist()
-    [datetime.datetime(2001, 1, 31, 0, 0),
-     datetime.datetime(2001, 2, 28, 0, 0),
-     datetime.datetime(2001, 3, 31, 0, 0),
-     datetime.datetime(2001, 4, 30, 0, 0),
-     datetime.datetime(2001, 5, 31, 0, 0)]
-    >>> d[:4].reshape(2,2).tolist()
-    [[datetime.datetime(2001, 1, 31, 0, 0), datetime.datetime(2001, 2, 28, 0, 0)],
-     [datetime.datetime(2001, 3, 31, 0, 0), datetime.datetime(2001, 4, 30, 0, 0)]]
-
-        """
-        # We need an array to 
-        _result = np.empty(self.shape, dtype=np.object_)
-        _result.flat = [d.datetime for d in self.ravel()]
-        return _result.tolist()
-    #
-    def tostring(self):
-        """
-    Converts the dates to a :class:`~numpy.ndarray` of strings.
-
-    The format of the strings depends of the frequency of the 
-    instance.
-
-    Examples
-    --------
-    >>> d = ts.date_array(start_date=ts.Date('M', '2001-01'), length=5)
-    >>> d.tostrings()
-    array(['Jan-2001', 'Feb-2001', 'Mar-2001', 'Apr-2001', 'May-2001'], 
-          dtype='|S8')
-
-        """
-        # Note: we better cache the result
-        if self._cachedinfo['tostr'] is None:
-            firststr = str(self[0])
-            if self.size:
-                ncharsize = len(firststr)
-                tostr = np.fromiter((str(d) for d in self),
-                                    dtype='|S%i' % ncharsize)
-            else:
-                tostr = firststr
-            self._cachedinfo['tostr'] = tostr
-        return self._cachedinfo['tostr']
-    #
-    def asfreq(self, freq=None, relation="END"):
-        """
-
-    Converts the dates to another frequency.
-
-    Parameters
-    ----------
-    freq : {freq_spec}
-        Frequency into which :class:`DateArray` must be converted.
-        Accepts any valid frequency specification (string or integer)
-    relation : {"END", "START"} (optional)
-        Applies only when converting a lower frequency :class:`Date` to a higher
-        frequency :class:`Date`, or when converting a weekend :class:`Date` to a business
-        frequency :class:`Date`. Valid values are 'START' and 'END' (or just 'S' and
-        'E' for brevity if you wish).
-
-        For example, if converting a monthly date to a daily date, specifying
-        'START' ('END') would result in the first (last) day in the month.
-
-        """
-        # Note: As we define a new object, we don't need caching
-        if (freq is None) or (freq == _c.FR_UND):
-            return self
-        tofreq = check_freq(freq)
-        if tofreq == self.freq:
-            return self
-
-        relation = relation.upper()
-        if relation not in ('START', 'END', 'S', 'E'):
-            errmsg = "Invalid specification for the 'relation' parameter: %s"
-            raise ValueError(errmsg % relation)
-
-        fromfreq = self.freq
-        if fromfreq == _c.FR_UND:
-            new = self.__array__()
-        else:
-            new = pandas._skts.DA_asfreq(self.__array__(),
-                                    fromfreq, tofreq, relation[0])
-        return DateArray(new, freq=freq)
-
-
-    #......................................................
-    # Pickling
-    def __getstate__(self):
-        """
-    Returns the internal state of the TimeSeries, for pickling purposes.
-        """
-        state = (1,
-                 self.shape,
-                 self.dtype,
-                 self.flags.fnc,
-                 self.view(ndarray).tostring(),
-                 self.freq,
-                 )
-        return state
-    #
-    def __setstate__(self, state):
-        """
-    Restores the internal state of the TimeSeries, for pickling purposes.
-    `state` is typically the output of the ``__getstate__`` output, and is a 5-tuple:
-
-        - class name
-        - a tuple giving the shape of the data
-        - a typecode for the data
-        - a binary string for the data
-        - a binary string for the mask.
-        """
-        (ver, shp, typ, isf, raw, frq) = state
-        ndarray.__setstate__(self, (shp, typ, isf, raw))
-        self.freq = frq
-
-    def __reduce__(self):
-        """Returns a 3-tuple for pickling a DateArray."""
-        return (self.__class__,
-                (self.__array__(), self.freq),
-                self.__getstate__())
-
-
-    def find_dates(self, *dates):
-        """
-    Returns the indices corresponding to given dates, as an array.
-
-        """
-        #http://aspn.activestate.com/ASPN/Mail/Message/python-tutor/2302348
-        def flatten_sequence(iterable):
-            """Flattens a compound of nested iterables."""
-            itm = iter(iterable)
-            for elm in itm:
-                if hasattr(elm, '__iter__') and not isinstance(elm, basestring):
-                    for f in flatten_sequence(elm):
-                        yield f
-                else:
-                    yield elm
-        #
-        def flatargs(*args):
-            "Flattens the arguments."
-            if not hasattr(args, '__iter__'):
-                return args
-            else:
-                return flatten_sequence(args)
-
-        ifreq = self.freq
-        c = np.zeros(self.shape, dtype=bool)
-        for d in flatargs(*dates):
-            if d.freq != ifreq:
-                d = d.asfreq(ifreq)
-            c += (self == d.value)
-        c = c.nonzero()
-        if np.size(c) == 0:
-            raise IndexError("Date out of bounds!")
-        return c
-
-    def date_to_index(self, dates):
-        """
-   Returns the index corresponding to one given date, as an integer.
-        """
-        vals = self.view(ndarray)
-        if isinstance(dates, Date):
-            _val = dates.value
-            if _val not in vals:
-                raise IndexError("Date '%s' is out of bounds" % dates)
-            if self.is_valid():
-                return _val - vals[0]
-            else:
-                return np.where(vals == _val)[0][0]
-        #
-        _dates = DateArray(dates, freq=self.freq)
-        if self.is_valid():
-            indx = (_dates.view(ndarray) - vals[0])
-            err_cond = (indx < 0) | (indx > self.size)
-            if err_cond.any():
-                err_indx = np.compress(err_cond, _dates)[0]
-                err_msg = "Date '%s' is out of bounds '%s' <= date <= '%s'"
-                raise IndexError(err_msg % (err_indx, self[0], self[-1]))
-            return indx
-        vals = vals.tolist()
-        indx = np.array([vals.index(d) for d in _dates.view(ndarray)])
-        #
-        return indx
-
-
-    def is_chronological(self):
-        """
-    Returns whether the dates are sorted in chronological order
-        """
-        _cached = self._cachedinfo
-        chronoflag = _cached['ischrono']
-        if chronoflag is None:
-            sortidx = ndarray.argsort(self.__array__(), axis=None)
-            chronoflag = (sortidx == np.arange(self.size)).all()
-            _cached['ischrono'] = chronoflag
-            if chronoflag:
-                _cached['chronidx'] = np.array([], dtype=int)
-            else:
-                _cached['chronidx'] = sortidx
-        return chronoflag
-
-    def sort_chronologically(self):
-        """
-    Forces the instance to be sorted in chronological order.
-        """
-        _cached = self._cachedinfo
-        if not self.is_chronological():
-            self.sort()
-            _cached['chronidx'] = np.array([], dtype=int)
-            _cached['ischrono'] = True
-
-
-    def get_steps(self):
-        """
-    Returns the time steps between consecutive dates, in the same unit as
-    the frequency of the instance.
-        """
-        _cached = self._cachedinfo
-        if _cached['steps'] is None:
-            if self.size > 1:
-                val = self.__array__().ravel()
-                if not self.is_chronological():
-                    val = val[_cached['chronidx']]
-                steps = val[1:] - val[:-1]
-                if _cached['full'] is None:
-                    _cached['full'] = (steps.max() == 1)
-                if _cached['hasdups'] is None:
-                    _cached['hasdups'] = (steps.min() == 0)
-            else:
-                _cached.update(ischrono=True,
-                               chronidx=np.array([], dtype=int),
-                               full=True,
-                               hasdups=False)
-                steps = np.array([], dtype=int)
-            _cached['steps'] = steps
-        return _cached['steps']
-
-    def has_missing_dates(self):
-        "Returns whether the instance has missing dates."
-        if self._cachedinfo['full'] is None:
-            steps = self.get_steps()
-        return not(self._cachedinfo['full'])
-
-    def is_full(self):
-        "Returns whether the instance has no missing dates."
-        if self._cachedinfo['full'] is None:
-            steps = self.get_steps()
-        return self._cachedinfo['full']
-
-    def isfull(self):
-        "Deprecated version of :meth:`DateArray.is_full"
-        errmsg = "Deprecated name: use 'is_full' instead."
-        warnings.warn(errmsg, DeprecationWarning,)
-        return self.is_full()
-
-    def has_duplicated_dates(self):
-        "Returns whether the instance has duplicated dates."
-        if self._cachedinfo['hasdups'] is None:
-            steps = self.get_steps()
-        return self._cachedinfo['hasdups']
-
-    def is_valid(self):
-        "Returns whether the instance is valid: no missing/duplicated dates."
-        return  (self.is_full() and not self.has_duplicated_dates())
-
-    def isvalid(self):
-        "Deprecated version of :meth:`DateArray.is_valid"
-        errmsg = "Deprecated name: use 'is_valid' instead."
-        warnings.warn(errmsg, DeprecationWarning,)
-        return  (self.is_full() and not self.has_duplicated_dates())
-    #......................................................
-    @property
-    def start_date(self):
-        "Returns the first date of the array (in chronological order)."
-        if self.size:
-            if self.is_chronological():
-                return self[0]
-            _sortidx = self._cachedinfo['chronidx']
-            return self[_sortidx[0]]
-        return None
-
-    @property
-    def end_date(self):
-        "Returns the last date of the array (in chronological order)."
-        if self.size:
-            if self.is_chronological():
-                return self[-1]
-            _sortidx = self._cachedinfo['chronidx']
-            return self[_sortidx[-1]]
-        return None
-
-    #-----------------------------
-
-    def argsort(self, axis= -1, kind='quicksort', order=None):
-        """
-        Returns the indices that would sort the DateArray.
-        Refer to `numpy.argsort` for full documentation
-        
-        See Also
-        --------
-        numpy.argsort : equivalent function
-        """
-        return self.__array__().argsort(axis=axis, kind=kind, order=order)
-
-    def sort(self, axis= -1, kind='quicksort', order=None):
-        "(This docstring should be overwritten)"
-        ndarray.sort(self, axis=axis, kind=kind, order=order)
-        _cached = self._cachedinfo
-        kwargs = dict(toobj=None, toord=None, tostr=None)
-        if self.ndim == 1:
-            kwargs.update(ischrono=True, chronidx=np.array([], dtype=int))
-        _cached.update(**kwargs)
-        return None
-    sort.__doc__ = ndarray.sort.__doc__
-
-
-def fill_missing_dates(dates, freq=None):
-    """
-    Finds and fills the missing dates in a :class:`DateArray`.
-
-    Parameters
-    ----------
-    dates : {DateArray}
-        Initial array of dates.
-    freq : {freq_spec}, optional
-        Frequency of result. 
-        If not specified, the frequency of the input is used.
-    """
-    # Check the frequency ........
-    orig_freq = freq
-    freq = check_freq(freq)
-    if (orig_freq is not None) and (freq == _c.FR_UND):
-        freqstr = check_freq_str(freq)
-        errmsg = "Unable to define a proper date resolution (found %s)."
-        raise ValueError(errmsg % freqstr)
-    # Check the dates .............
-    if not isinstance(dates, DateArray):
-        errmsg = "A DateArray was expected, got %s instead."
-        raise ValueError(errmsg % type(dates))
-    # Convert the dates to the new frequency (if needed)
-    if freq != dates.freq:
-        dates = dates.asfreq(freq)
-    # Flatten the array
-    if dates.ndim != 1:
-        dates = dates.ravel()
-    # Skip if there's no need to fill
-    if not dates.has_missing_dates():
-        return dates
-    # ...and now, fill it ! ......
-    (tstart, tend) = dates[[0, -1]]
-    return date_array(start_date=tstart, end_date=tend)
-DateArray.fill_missing_dates = fill_missing_dates
-
-nodates = DateArray([])
-
-
-#####---------------------------------------------------------------------------
-#---- --- DateArray functions ---
-#####---------------------------------------------------------------------------
-def _listparser(dlist, freq=None):
-    "Constructs a DateArray from a list."
-    dlist = np.array(dlist, copy=False, ndmin=1)
-    # Case #1: dates as strings .................
-    if dlist.dtype.kind in 'SU':
-        #...construct a list of dates
-        dlist = np.fromiter((Date(freq, string=s).value for s in dlist),
-                            dtype=int)
-    # Case #2: dates as numbers .................
-    elif dlist.dtype.kind in 'if':
-        #...hopefully, they are values
-        dlist = dlist.astype(int)
-    # Case #3: dates as objects .................
-    elif dlist.dtype.kind == 'O':
-        template = dlist[0]
-        #...as Date objects
-        if isinstance(template, Date):
-            dlist = np.fromiter((d.value for d in dlist), dtype=int)
-            if freq in (_c.FR_UND, None):
-                freq = template.freq
-        #...as mx.DateTime objects
-        elif hasattr(template, 'absdays'):
-            dlist = np.fromiter((Date(freq, datetime=m) for m in dlist),
-                                dtype=int)
-        #...as datetime objects
-        elif hasattr(template, 'toordinal'):
-            dlist = np.fromiter((Date(freq, datetime=d) for d in dlist),
-                                dtype=int)
-    #
-    result = dlist.view(DateArray)
-    result.freq = freq
-    return result
-
-
-def date_array(dlist=None, start_date=None, end_date=None, length=None,
-               freq=None, autosort=False):
-    """
-    Factory function for constructing a :class:`DateArray`.
-
-    Parameters
-    ----------
-    dlist : {sequence, DateArray}, optional
-        If not None, :keyword:`dlist` must be any of these possibilities:
-
-        * an existing :class:`DateArray` object;
-        * a sequence of :class:`Date` objects with the same frequency;
-        * a sequence of :class:`datetime.datetime` objects;
-        * a sequence of dates in string format;
-        * a sequence of integers corresponding to the representation of 
-          :class:`Date` objects.
-
-        In any of the last four possibilities, the :keyword:`freq` parameter
-        must also be given.
-    start_date : {var}, optional
-        First date of a continuous :class:`DateArray`.
-        This parameter is used only if :keyword:`dlist` is None.
-        In that case, one of the :keyword:`end_date` or the :keyword:`length`
-        parameters must be given.
-    end_date : {var}, optional
-        Last date of the output. 
-        Use this parameter in combination with :keyword:`start_date` to create
-        a continuous :class:`DateArray`.
-    length : {int}, optional
-        Length of the output.
-        Use this parameter in combination with :keyword:`start_date` to create
-        a continuous :class:`DateArray`.
-    autosort : {True, False}, optional
-        Whether the input dates must be sorted in chronological order.
-
-    Notes
-    -----
-    * When the input is a list of dates, the dates are **not** sorted.
-      Use ``autosort = True`` to sort the dates by chronological order.
-    * If `start_date` is a :class:`Date` object and `freq` is None,
-      the frequency of the output is ``start_date.freq``.
-
-
-    Returns
-    -------
-    output : :class:`DateArray` object.
-
-    """
-    freq = check_freq(freq)
-    # Case #1: we have a list ...................
-    if dlist is not None:
-        # Already a DateArray....................
-        if isinstance(dlist, DateArray):
-            if (freq != _c.FR_UND) and (dlist.freq != check_freq(freq)):
-                # Convert to the new frequency
-                dlist = dlist.asfreq()
-            else:
-                # Take a view so that we don't propagate modifications....
-                # ... in _cachedinfo.
-                dlist = dlist.view()
-            if autosort:
-                dlist.sort_chronologically()
-            return dlist
-        # Make sure it's a sequence, else that's a start_date
-        if hasattr(dlist, '__len__') and not isinstance(dlist, basestring):
-            dlist = _listparser(dlist, freq=freq)
-            if autosort:
-                dlist.sort_chronologically()
-            return dlist
-        elif start_date is not None:
-            if end_date is not None:
-                dmsg = "What starting date should be used ? '%s' or '%s' ?"
-                raise DateError, dmsg % (dlist, start_date)
-            else:
-                (start_date, end_date) = (dlist, start_date)
-        else:
-            start_date = dlist
-    # Case #2: we have a starting date ..........
-    if start_date is None:
-        if length == 0:
-            return DateArray([], freq=freq)
-        raise InsufficientDateError
-    if not isinstance(start_date, Date):
-        try:
-            start_date = Date(freq, start_date)
-        except:
-            dmsg = "Starting date should be a valid Date instance! "
-            dmsg += "(got '%s' instead)" % type(start_date)
-            raise DateError, dmsg
-    # Check if we have an end_date
-    if end_date is None:
-        if length is None:
-            length = 1
-    else:
-        try:
-            end_date = Date(start_date.freq, end_date)
-        except:
-            raise DateError, "Ending date should be a valid Date instance!"
-        # Make sure end_date is after start_date
-        if (end_date < start_date):
-            (start_date, end_date) = (end_date, start_date)
-        length = int(end_date - start_date) + 1
-    #
-    dlist = np.arange(length, dtype=np.int)
-    dlist += start_date.value
-    if freq == _c.FR_UND:
-        freq = start_date.freq
-    # Transform the dates and set the cache
-    dates = dlist.view(DateArray)
-    dates.freq = freq
-    dates._cachedinfo.update(ischrono=True, chronidx=np.array([], dtype=int))
-    return dates
-
-
-
-#####---------------------------------------------------------------------------
-#---- --- Definition of functions from the corresponding methods ---
-#####---------------------------------------------------------------------------
-class _frommethod(object):
-    """
-    Defines functions from existing MaskedArray methods.
-    :ivar _methodname (String): Name of the method to transform.
-    """
-    def __init__(self, methodname):
-        self._methodname = methodname
-        self.__doc__ = self.getdoc()
-    #
-    def getdoc(self):
-        "Returns the doc of the function (from the doc of the method)."
-        try:
-            return getattr(DateArray, self._methodname).__doc__
-        except AttributeError:
-            return "???"
-    #
-    def __call__(self, caller, *args, **params):
-        if hasattr(caller, self._methodname):
-            method = getattr(caller, self._methodname)
-            # If method is not callable, it's a property, and don't call it
-            if hasattr(method, '__call__'):
-                return method.__call__(*args, **params)
-            return method
-        method = getattr(np.asarray(caller), self._methodname)
-        try:
-            return method(*args, **params)
-        except SystemError:
-            method = getattr(np, self._methodname)
-            return method(caller, *args, **params)
-
-#............................
-weekday = _frommethod('weekday')
-week = _frommethod('week')
-day_of_year = _frommethod('day_of_year')
-year = _frommethod('year')
-quarter = _frommethod('quarter')
-month = _frommethod('month')
-day = _frommethod('day')
-hour = _frommethod('hour')
-minute = _frommethod('minute')
-second = _frommethod('second')
-
-
-def period_break(dates, period):
-    """
-    Returns the indices where the given period changes.
-
-    Parameters
-    ----------
-    dates : DateArray
-        Array of dates to monitor.
-    period : string
-        Name of the period to monitor.
-    """
-    current = getattr(dates, period)
-    previous = getattr(dates - 1, period)
-    return (current - previous).nonzero()[0]
-
-
-def convert_to_float(datearray, ofreq):
-    """
-    Convert a :class:`~scikits.timeseries.DateArray` object from a ndarray
-    of integers to a ndarray of float at a lower frequency.
-
-    Parameters
-    ----------
-    datearray : DateArray
-        Input :class:`~scikits.timeseries.DateArray` to convert.
-    ofreq : var
-        Valid frequency specifier.
-
-    Notes
-    -----
-    This function is currently restricted to conversion between annual (``'A'``),
-    quarterly (``'Q'``), monthly (``'M'``) and daily (``'D'``) frequencies only.
-    """
-    if not isinstance(datearray, DateArray):
-        raise TypeError("The input should be a valid DateArray instance !"\
-                        " (got '%s' instead)" % type(datearray))
-    errmsg = "Not implemented for the frequencies ('%s', '%s')"
-    #
-    freqdict = dict([(f, check_freq(f)) for f in ('A', 'Q', 'M', 'D')])
-    ifreq = datearray.freq
-    ofreq = check_freq(ofreq)
-    errmsg = "Not implemented for the frequencies ('%s', '%s')" % \
-             (check_freq_str(ifreq), check_freq_str(ofreq))
-    if ifreq < ofreq:
-        output = datearray.asfreq(ofreq).tovalue().astype(float)
-    elif ifreq == ofreq:
-        output = datearray.tovalue().astype(float)
-    # Quarterly.........
-    elif (ifreq >= freqdict['Q']) and (ifreq < freqdict['M']):
-        if (ofreq >= freqdict['A']) and (ofreq < freqdict['Q']):
-            output = datearray.years.astype(float) + (datearray.quarters - 1.) / 4.
-    # Monthly...........
-    elif ifreq == freqdict['M']:
-        #... to annual
-        if (ofreq >= freqdict['A']) and (ofreq < freqdict['Q']):
-            output = datearray.years.astype(float) + (datearray.months - 1) / 12.
-        else:
-            raise NotImplementedError(errmsg)
-    # Daily ............
-    elif ifreq == freqdict['D']:
-        # ... to annual
-        if (ofreq >= freqdict['A']) and (ofreq < freqdict['Q']):
-            output = datearray.asfreq('A')
-            output = output.tovalue().astype(float) + \
-                     (datearray.yeardays - 1.) / output.yeardays.astype(float)
-        # ... to quarterly
-        elif (ofreq >= freqdict['Q']) and (ofreq < freqdict['M']):
-            raise NotImplementedError
-        # ... to monthly
-        elif ofreq == freqdict['M']:
-            output = datearray.asfreq('M')
-            output = output.tovalue().astype(float) + \
-                     (datearray.days - 1.) / output.days.astype(float)
-        # ... to other
-        else:
-            raise NotImplementedError(errmsg)
-    # Less than daily
-    elif ifreq > freqdict['D']:
-        raise NotImplementedError(errmsg)
-    else:
-        raise NotImplementedError(errmsg)
-    return output
-DateArray.tofloat = convert_to_float
-
diff --git a/pandas/timeseries/trecords.py b/pandas/timeseries/trecords.py
deleted file mode 100644
index 02a9b9e49..000000000
--- a/pandas/timeseries/trecords.py
+++ /dev/null
@@ -1,501 +0,0 @@
-# pylint: disable-msg=W0201, W0212
-"""
-Support for multi-variable time series, through masked record arrays.
-
-Individual fields can be accessed as keys or attributes.
-
-:author: Pierre GF Gerard-Marchant & Matt Knox
-:contact: pierregm_at_uga_dot_edu - mattknox_ca_at_hotmail_dot_com
-:version: $Id$
-"""
-__author__ = "Pierre GF Gerard-Marchant & Matt Knox ($Author$)"
-__revision__ = "$Revision$"
-__date__ = '$Date$'
-
-
-import sys
-
-import numpy as np
-from numpy import bool_, complex_, float_, int_, str_, object_, \
-    ndarray, chararray, recarray
-import numpy.core.numerictypes as ntypes
-import numpy.core.umath as umath
-from numpy.core.records import find_duplicate, format_parser, record, \
-    fromarrays as recfromarrays
-
-import numpy.ma as ma
-from numpy.ma import MaskedArray, MAError, \
-     default_fill_value, masked_print_option, masked, nomask, \
-     getmask, getmaskarray, make_mask, make_mask_none, mask_or, filled
-
-import numpy.ma.mrecords
-from numpy.ma.mrecords import _checknames, \
-     _guessvartypes, openfile, MaskedRecords, mrecarray, addfield, \
-     fromrecords as mrecfromrecords, fromarrays as mrecfromarrays
-
-from tseries import TimeSeries, TimeSeriesCompatibilityError, \
-    time_series, _getdatalength, nodates, get_varshape
-from tdates import Date, DateArray, date_array
-from extras import tsfromtxt
-
-_byteorderconv = numpy.core.records._byteorderconv
-_typestr = ntypes._typestr
-
-reserved_fields = numpy.ma.mrecords.reserved_fields + ['_dates']
-
-import warnings
-
-__all__ = [
-'TimeSeriesRecords', 'time_records',
-'fromarrays', 'fromrecords', 'fromtextfile',
-]
-
-def _getformats(data):
-    """
-    Returns the formats of each array of arraylist as a comma-separated string.
-    """
-    if isinstance(data, record):
-        return ",".join([desc[1] for desc in data.dtype.descr])
-
-    formats = ''
-    for obj in data:
-        obj = np.asarray(obj)
-        formats += _typestr[obj.dtype.type]
-        if issubclass(obj.dtype.type, ntypes.flexible):
-            formats += `obj.itemsize`
-        formats += ','
-    return formats[:-1]
-
-
-def _getdates(dates=None, newdates=None, length=None, freq=None,
-              start_date=None):
-    """
-    Determines new dates (private function not meant to be used).
-    """
-    if dates is None:
-        if newdates is not None:
-            if not hasattr(newdates, 'freq'):
-                newdates = date_array(dlist=newdates, freq=freq)
-        else:
-            newdates = date_array(start_date=start_date, length=length,
-                                  freq=freq)
-    elif not hasattr(dates, 'freq'):
-        newdates = date_array(dlist=dates, freq=freq)
-    else:
-        newdates = dates
-    return newdates
-
-
-class TimeSeriesRecords(TimeSeries, MaskedRecords, object):
-    """
-    MaskedRecords with support for time-indexing.
-
-    Fields can be retrieved either as indices (using the indexing scheme
-    based on `__getitem__`) or as attributes (using `__getattribute__`).
-
-    The type of the output of `__getitem__` is variable:
-    
-    field
-       returns a :class:`TimeSeries` object.
-    single record, no masked fields
-        returns a ``numpy.void`` object
-    single record with at least one masked field
-        returns a :class:`MaskedRecords` object.
-    slice
-        return a :class:`TimeSeriesRecords`.
-    """
-    def __new__(cls, shape, dtype=None, buf=None, offset=0, strides=None,
-                formats=None, names=None, titles=None,
-                byteorder=None, aligned=False,
-                mask=nomask, hard_mask=False, fill_value=None, keep_mask=True,
-                copy=False,
-                dates=None, freq='U', start_date=None, observed=None,
-                **options):
-        _data = mrecarray.__new__(cls, shape, dtype=dtype, buf=buf, offset=offset,
-                                  strides=strides, formats=formats,
-                                  byteorder=byteorder, aligned=aligned,
-                                  mask=mask, hard_mask=hard_mask, copy=copy,
-                                  keep_mask=keep_mask, fill_value=fill_value,
-                                  )
-        #
-        newdates = _getdates(dates, length=len(_data),
-                             start_date=start_date, freq=freq)
-        _data._dates = newdates
-        _data._observed = observed
-        #
-        return _data
-
-    def __array_finalize__(self, obj):
-        self.__dict__.update(_varshape=getattr(obj, '_varshape', ()),
-                             _dates=getattr(obj, '_dates', DateArray([])),
-                             _observed=getattr(obj, '_observed', None),
-                             _optinfo=getattr(obj, '_optinfo', {}))
-        MaskedRecords.__array_finalize__(self, obj)
-        return
-
-
-    def _getdata(self):
-        "Returns the data as a recarray."
-        return ndarray.view(self, recarray)
-    _data = property(fget=_getdata)
-
-    def _getseries(self):
-        "Returns the data as a MaskedRecord array."
-        return MaskedArray.view(self, mrecarray)
-    _series = property(fget=_getseries)
-
-
-    def __getattribute__(self, attr):
-        getattribute = MaskedRecords.__getattribute__
-        _dict = getattribute(self, '__dict__')
-        if attr == '_dict':
-            return _dict
-        _names = ndarray.__getattribute__(self, 'dtype').names
-        if attr in (_names or []):
-            obj = getattribute(self, attr).view(TimeSeries)
-            obj._dates = _dict['_dates']
-            return obj
-        return getattribute(self, attr)
-
-
-    def __setattr__(self, attr, value):
-        if attr in ['_dates', 'dates']:
-            self.__setdates__(value)
-        elif attr == 'shape':
-            if self._varshape:
-                err_msg = "Reshaping a nV/nD series is not implemented yet !"
-                raise NotImplementedError(err_msg)
-        return MaskedRecords.__setattr__(self, attr, value)
-
-    #......................................................
-    def __getitem__(self, indx):
-        """Returns all the fields sharing the same fieldname base.
-    The fieldname base is either `_data` or `_mask`."""
-        _localdict = self.__dict__
-        # We want a field ........
-        if indx in ndarray.__getattribute__(self, 'dtype').names:
-            obj = self._data[indx].view(TimeSeries)
-            obj._dates = _localdict['_dates']
-            obj._mask = make_mask(_localdict['_mask'][indx])
-            return obj
-        # We want some elements ..
-        obj = TimeSeries.__getitem__(self, indx)
-        if isinstance(obj, MaskedArray) and not isinstance(obj, TimeSeries):
-            obj = ndarray.view(obj, MaskedRecords)
-        return obj
-
-
-    def __setslice__(self, i, j, value):
-        """Sets the slice described by [i,j] to `value`."""
-        MaskedRecords.__setitem__(self, slice(i, j), value)
-        return
-
-    #......................................................
-    def __str__(self):
-        """x.__str__() <==> str(x)
-    Calculates the string representation, using masked for fill if it is enabled.
-    Otherwise, fills with fill value.
-        """
-        if self.size > 1:
-            mstr = ["(%s)" % ",".join([str(i) for i in s])
-                    for s in zip(*[getattr(self, f)._series
-                                   for f in self.dtype.names])]
-            return "[%s]" % ", ".join(mstr)
-        else:
-            mstr = ["%s" % ",".join([str(i) for i in s])
-                    for s in zip([getattr(self, f)._series
-                                  for f in self.dtype.names])]
-            return "(%s)" % ", ".join(mstr)
-
-    def __repr__(self):
-        """x.__repr__() <==> repr(x)
-    Calculates the repr representation, using masked for fill if it is enabled.
-    Otherwise fill with fill value.
-        """
-        _names = self.dtype.names
-        _dates = self._dates
-        if np.size(_dates) > 2 and self._dates.is_valid():
-            timestr = "[%s ... %s]" % (str(_dates[0]), str(_dates[-1]))
-        else:
-            timestr = str(_dates)
-        fmt = "%%%is : %%s" % (max([len(n) for n in _names]) + 4,)
-        reprstr = [fmt % (f, getattr(self, f)) for f in self.dtype.names]
-        reprstr.insert(0, 'TimeSeriesRecords(')
-        reprstr.extend([fmt % ('dates', timestr),
-                        fmt % ('    fill_value', self.fill_value),
-                         '               )'])
-        return str("\n".join(reprstr))
-
-
-    def copy(self):
-        "Returns a copy of the argument."
-        copied = MaskedRecords.copy(self)
-        copied._dates = self._dates.copy()
-        return copied
-
-
-    def convert(self, freq, func=None, position='END', *args, **kwargs):
-        """
-    Converts a series to another frequency.
-
-    Parameters
-    ----------
-    series : TimeSeries
-        the series to convert. Skip this parameter if you are calling this as
-        a method of the TimeSeries object instead of the module function.
-    freq : freq_spec
-        Frequency to convert the TimeSeries to. Accepts any valid frequency
-        specification (string or integer)
-    func : {None,function}, optional
-        When converting to a lower frequency, `func` is a function that acts on
-        one date's worth of data. `func` should handle masked values appropriately.
-        If `func` is None, then each entry of the resulting series is the group
-        of data points that fall into the date at the lower frequency.
-        For example, if converting from monthly to daily and you wanted each
-        data point in the resulting series to be the average value for each
-        month, you could specify numpy.ma.average for the 'func' parameter.
-    position : {'END', 'START'}, optional
-        When converting to a higher frequency, position is 'START' or 'END'
-        and determines where the data point is in each period. For example, if
-        going from monthly to daily, and position is 'END', then each data
-        point is placed at the end of the month.
-    *args : {extra arguments for func parameter}, optional
-        if a func is specified that requires additional parameters, specify
-        them here.
-    **kwargs : {extra keyword arguments for func parameter}, optional
-        if a func is specified that requires additional keyword parameters,
-        specify them here.
-
-        """
-        kwargs.update(func=func, position=position)
-        field_names = self.dtype.names
-        by_field = [self[f].convert(freq, **kwargs) for f in field_names]
-        output = fromarrays(by_field,
-                            dates=by_field[0].dates,
-                            names=field_names)
-        output.fill_value = self._fill_value
-        return output
-trecarray = TimeSeriesRecords
-
-
-#####---------------------------------------------------------------------------
-#---- --- Constructors ---
-#####---------------------------------------------------------------------------
-
-def time_records(data, dates=None, start_date=None, freq=None, mask=nomask,
-                dtype=None, copy=False, fill_value=None, keep_mask=True,
-                hard_mask=False):
-    """
-    Creates a TimeSeriesRecords object.
-
-    Parameters
-    ----------
-    data : array_like
-        Data portion of the array. Any data that is valid for constructing a
-        MaskedArray can be used here. May also be a TimeSeries object.
-    dates : {None, DateArray}, optional
-        A sequence of dates corresponding to each entry.
-        If None, the dates will be constructed as a DateArray with the same
-        length as ``data``, starting at ``start_date`` with frequency ``freq``.
-    start_date : {Date}, optional
-        Date corresponding to the first entry of the data (index 0).
-        This parameter must be a valid Date object, and is mandatory if ``dates``
-        is None and if ``data`` has a length greater or equal to 1.
-    freq : {freq_spec}, optional
-        A valid frequency specification, as a string or an integer.
-        This parameter is mandatory if ``dates`` is None.
-    mask : {nomask, sequence}, optional
-        Mask.  Must be convertible to an array of booleans with
-        the same shape as data: True indicates a masked (eg.,
-        invalid) data.
-    dtype : {dtype}, optional
-        Data type of the output.
-        If dtype is None, the type of the data argument (`data.dtype`) is used.
-        If dtype is not None and different from `data.dtype`, a copy is performed.
-    copy : {False, True}, optional
-        Whether to copy the input data (True), or to use a reference instead.
-        Note: data are NOT copied by default.
-    fill_value : {var}, optional
-        Value used to fill in the masked values when necessary.
-        If None, a default based on the datatype is used.
-    keep_mask : {True, boolean}, optional
-        Whether to combine mask with the mask of the input data,
-        if any (True), or to use only mask for the output (False).
-    hard_mask : {False, boolean}, optional
-        Whether to use a hard mask or not.
-        With a hard mask, masked values cannot be unmasked.
-
-    Notes
-    -----
-    * All other parameters that are accepted by the :func:`numpy.ma.array`
-      function in the :mod:`numpy.ma` module are also accepted by this function.
-    * The date portion of the time series must be specified in one of the
-      following ways:
-
-       * specify a TimeSeries object for the ``data`` parameter.
-       * pass a DateArray for the ``dates`` parameter.
-       * specify a start_date (a continuous DateArray will be automatically
-         constructed for the dates portion).
-       * specify just a frequency (for TimeSeries of size zero).
-
-    """
-    series = time_series(data, dates=dates, start_date=start_date, freq=freq,
-                          mask=mask, dtype=dtype, copy=copy,
-                          fill_value=fill_value, keep_mask=keep_mask,
-                          hard_mask=hard_mask)
-    return series.view(TimeSeriesRecords)
-
-#!!!: * The docstrings of the following functions need some serious work ;)
-#!!!: * We should try to have a list of TimeSeries sufficient to build a record...
-#!!!:   without having to precise a list of dates...
-#!!!:   > check the compatibility of dates
-#!!!:   > try to adjust endpoints if needed
-#!!!:   > if one of the series is not a TimeSeries, keep going.
-
-def fromarrays(arraylist, dates=None, start_date=None, freq='U',
-               fill_value=None, autosort=True,
-               dtype=None, shape=None, formats=None,
-               names=None, titles=None, aligned=False, byteorder=None,):
-    """
-    Creates a mrecarray from a (flat) list of masked arrays.
-
-    Parameters
-    ----------
-    arraylist : array_like
-        A list of (masked) arrays. Each element of the sequence is first converted
-        to a masked array if needed. If a 2D array is passed as argument, it is
-        processed line by line
-    dates : {DateArray}, optional
-        Array of dates corresponding to each entry.
-        If None, a DateArray is constructed from `start_date` and the length
-        of the arrays in the input list.
-    start_date : {Date}, optional
-        First date of the output.
-        This parameter is inly needed if `dates` is None.
-    freq : {var}, optional
-        Frequency of the DateArray
-    fill_value : {var}, optional
-        Value used to fill in the masked values when necessary.
-        If None, a default based on the datatype is used.
-    autosort : {True, False}, optional
-        Whether the records should be sorted chronologically.
-
-    See Also
-    --------
-    numpy.core.records.fromarrays : equivalent function for ndarrays
-        The docstring of this function describes the additional optional
-        input parameters.
-    
-
-    Notes
-    -----
-    * Lists of tuples should be preferred over lists of lists as inputs 
-      for faster processing.
-    """
-    _array = mrecfromarrays(arraylist, dtype=dtype, shape=shape, formats=formats,
-                            names=names, titles=titles, aligned=aligned,
-                            byteorder=byteorder, fill_value=fill_value)
-    _dates = _getdates(dates, length=len(_array), start_date=start_date,
-                       freq=freq)
-#    if _dates._unsorted is not None:
-#        idx = _dates._unsorted
-#        _array = _array[idx]
-#        _dates._unsorted = None
-    result = _array.view(trecarray)
-    result._dates = _dates
-    if autosort:
-        result.sort_chronologically()
-    return result
-
-
-#..............................................................................
-def fromrecords(reclist, dates=None, freq=None, start_date=None,
-                fill_value=None, mask=nomask, autosort=True,
-                dtype=None, shape=None, formats=None, names=None,
-                titles=None, aligned=False, byteorder=None):
-    """
-    Creates a TimeSeriesRecords from a list of records.
-
-    The data in the same field can be heterogeneous, they will be promoted
-    to the highest data type.  This method is intended for creating
-    smaller record arrays.  If used to create large array without formats
-    defined, it can be slow.
-
-    If formats is None, then this will auto-detect formats. Use a list of
-    tuples rather than a list of lists for faster processing.
-
-
-    Parameters
-    ----------
-    reclist : array_like
-        A list of records. Each element of the sequence is first converted
-        to a masked array if needed. If a 2D array is passed as argument, it is
-        processed line by line
-    dates : {DateArray}, optional
-        Array of dates corresponding to each entry.
-        If None, a DateArray is constructed from `start_date` and the length
-        of the arrays in the input list.
-    freq : {var}, optional
-        Frequency of the DateArray
-    start_date : {Date}, optional
-        First date of the output.
-        This parameter is inly needed if `dates` is None.
-    fill_value : {var}, optional
-        Value used to fill in the masked values when necessary.
-        If None, a default based on the datatype is used.
-    autosort : {True, False}, optional
-        Whether the records should be sorted chronologically.
-        
-
-    See Also
-    --------
-    numpy.core.records.fromrecords : equivalent function for ndarrays
-
-
-    """
-    _data = mrecfromrecords(reclist, dtype=dtype, shape=shape, formats=formats,
-                            names=names, titles=titles, aligned=aligned,
-                            byteorder=byteorder, mask=mask)
-    _dtype = _data.dtype
-    # Check the names for a '_dates' .................
-    newdates = None
-    _names = list(_dtype.names)
-    reserved = [n for n in _names if n.lower() in ['dates', '_dates']]
-    if len(reserved) > 0:
-        newdates = _data[reserved[-1]]
-        [_names.remove(n) for n in reserved]
-        _dtype = np.dtype([t for t in _dtype.descr \
-                                    if t[0] not in reserved ])
-        _data = mrecfromarrays([_data[n] for n in _names], dtype=_dtype)
-    #
-    if dates is None:
-        dates = getattr(reclist, '_dates', None)
-    _dates = _getdates(dates=dates, newdates=newdates, length=len(_data),
-                       freq=freq, start_date=start_date)
-    #
-    result = _data.view(trecarray)
-    result._dates = _dates
-    if autosort:
-        result.sort_chronologically()
-    return result
-
-
-
-def fromtextfile(fname, delimitor=None, commentchar='#', missingchar='',
-                 dates_column=None, varnames=None, vartypes=None,
-                 dates=None, freq=None, skiprows=0):
-    """
-    Deprecated function: please use tsfromtxt instead.
-    """
-    msg = "This function is deprecated.\nPlease use `tsfromtxt` instead."
-    warnings.warn(msg, DeprecationWarning)
-    # Split the names by comma first, then per character
-    if isinstance(varnames, basestring):
-        varnames = varnames.split(",")
-        if len(varnames) == 1:
-            varnames = zip(*varnames[0])[0]
-    return tsfromtxt(fname, dtype=vartypes, names=(varnames or True), freq=freq,
-                     datecols=dates_column, skiprows=skiprows,
-                     delimiter=delimitor, comments=commentchar,
-                     missing=missingchar, asrecarray=True)
-
diff --git a/pandas/timeseries/tseries.py b/pandas/timeseries/tseries.py
deleted file mode 100644
index ce26509a1..000000000
--- a/pandas/timeseries/tseries.py
+++ /dev/null
@@ -1,2458 +0,0 @@
-"""
-The :class:`TimeSeries` class provides a base for the definition of time series.
-A time series is defined here as the combination of two arrays:
-
-- an array storing the time information
-  (as a :class:`~scikits.timeseries.tdates.DateArray` instance);
-- an array storing the data (as a :class:`MaskedArray` instance.)
-
-These two classes were liberally adapted from :class:`MaskedArray` class.
-
-
-:author: Pierre GF Gerard-Marchant & Matt Knox
-:contact: pierregm_at_uga_dot_edu - mattknox_ca_at_hotmail_dot_com
-"""
-
-#!!!: * Allow different lengths for data and dates to handle 2D data more easily
-#!!!:    In that case, just make sure that the data is (n,rows,cols) where n is the nb of dates
-#!!!: * Add some kind of marker telling whether we are 1D or nD:
-#!!!:    That could be done by checking the ratio series.size/series._dates.size
-#!!!: * Disable some of the tests on date compatibility if we are nD
-#!!!: * Adapt reshaping to preserve the first dimension: that goes for squeeze
-
-__author__ = "Pierre GF Gerard-Marchant & Matt Knox"
-__revision__ = "$Revision$"
-__date__ = '$Date$'
-
-import sys
-import warnings
-
-import numpy as np
-from numpy import bool_, complex_, float_, int_, object_, dtype, \
-    ndarray, recarray
-import numpy.core.umath as umath
-from numpy.core.records import fromarrays as recfromarrays
-
-from numpy import ma
-from numpy.ma import MaskedArray, MAError, masked, nomask, \
-    filled, getmask, getmaskarray, hsplit, make_mask_none, mask_or, make_mask, \
-    masked_array
-
-import tdates
-from tdates import \
-    DateError, FrequencyDateError, InsufficientDateError, Date, DateArray, \
-    date_array, now, check_freq, check_freq_str, nodates
-
-import const as _c
-import pandas._skts
-
-__all__ = ['TimeSeries', 'TimeSeriesCompatibilityError', 'TimeSeriesError',
-           'adjust_endpoints', 'align_series', 'align_with', 'aligned',
-           'asrecords',
-           'compressed', 'concatenate', 'convert',
-           'day', 'day_of_year',
-           'empty_like',
-           'fill_missing_dates', 'find_duplicated_dates', 'first_unmasked_val',
-           'flatten',
-           'hour',
-           'last_unmasked_val',
-           'minute', 'month',
-           'pct', 'pct_log', 'pct_symmetric',
-           'quarter',
-           'remove_duplicated_dates',
-           'second', 'split', 'stack',
-           'time_series', 'tofile', 'tshift', 'masked', 'nomask',
-           'week', 'weekday',
-           'year',
-           ]
-
-
-def _unmasked_val(a, kind, axis=None):
-    "helper function for first_unmasked_val and last_unmasked_val"
-    if axis is None or a.ndim == 1:
-        a = a.ravel()
-        m = getmask(a)
-        if m is nomask or not np.any(m):
-            if kind == 0:
-                indx = 0
-            else:
-                indx = -1
-        else:
-            indx = np.flatnonzero(~m)[[0, -1]][kind]
-    else:
-        m = ma.getmaskarray(a)
-        indx = ma.array(np.indices(a.shape), mask=np.asarray([m] * a.ndim))
-        if kind == 0:
-            indx = tuple([indx[i].min(axis=axis).filled(0)
-                          for i in range(a.ndim)])
-        else:
-            indx = tuple([indx[i].max(axis=axis).filled(0)
-                          for i in range(a.ndim)])
-    return a[indx]
-
-def first_unmasked_val(a, axis=None):
-    """
-    Retrieve the first unmasked value along the given axis in a MaskedArray.
-
-    Parameters
-    ----------
-    a : MaskedArray
-        Input MaskedArray (or a subclass of).
-    axis : int, optional
-        Axis along which to perform the operation.
-        If None, applies to a flattened version of the array.
-
-    Returns
-    -------
-    val : {singleton of type marray.dtype}
-        First unmasked value in a.
-        If all values in a are masked, returns the numpy.ma.masked constant.
-    """
-    return _unmasked_val(a, 0, axis=axis)
-
-
-def last_unmasked_val(a, axis=None):
-    """
-    Retrieve the last unmasked value along the given axis in a MaskedArray.
-
-    Parameters
-    ----------
-    a : MaskedArray
-        Input MaskedArray (or a subclass of).
-    axis : int, optional
-        Axis along which to perform the operation.
-        If None, applies to a flattened version of the array.
-
-    Returns
-    -------
-    val : {singleton of type marray.dtype}
-        Last unmasked value in a.
-        If all values in a are masked, returns the numpy.ma.masked constant.
-    """
-    return _unmasked_val(a, 1, axis=axis)
-
-#### -------------------------------------------------------------------------
-#--- ... TimeSeriesError class ...
-#### -------------------------------------------------------------------------
-class TimeSeriesError(Exception):
-    "Class for TS related errors."
-    def __init__ (self, value=None):
-        "Creates an exception."
-        self.value = value
-    def __str__(self):
-        "Calculates the string representation."
-        return str(self.value)
-    __repr__ = __str__
-
-
-class TimeSeriesCompatibilityError(TimeSeriesError):
-    """
-    Defines the exception raised when series are incompatible.
-    Incompatibility can arise from:
-
-    * Inconsistent frequency;
-    * Inconsistent starting dates;
-    * Inconsistent size and/or shape.
-
-    """
-    def __init__(self, mode, first, second):
-        if mode == 'freq':
-            msg = "Incompatible time steps! (%s <> %s)"
-        elif mode == 'start_date':
-            msg = "Incompatible starting dates! (%s <> %s)"
-        elif mode in ('size', 'shape'):
-            msg = "Incompatible sizes! (%s <> %s)"
-        elif mode == 'order':
-            msg = "The series must be sorted in chronological order !"
-        else:
-            msg = "Incompatibility !  (%s <> %s)"
-        msg = msg % (first, second)
-        TimeSeriesError.__init__(self, msg)
-
-#???: Should we go crazy and add some new exceptions ?
-#???: TimeSeriesShapeCompatibilityError
-#???: TimeSeriesStepCompatibilityError
-
-
-def _timeseriescompat(a, b, raise_error=True):
-    """
-    Checks the date compatibility of two TimeSeries object.
-    Returns True if everything's fine, or raises an exception.
-    """
-    #!!!: We need to use _varshape to simplify the analysis
-    # Check the frequency ..............
-    (afreq, bfreq) = (getattr(a, 'freq', None), getattr(b, 'freq', None))
-    if afreq != bfreq:
-        if raise_error:
-            raise TimeSeriesCompatibilityError('freq', afreq, bfreq)
-        return False
-    # Make sure a.freq is not None
-    if afreq is None:
-        return True
-    # Make sure that the series are sorted in chronological order
-    if (not a.is_chronological()) or (not b.is_chronological()):
-        if raise_error:
-            raise TimeSeriesCompatiblityError('sort', None, None)
-        return False
-    # Check the starting dates ..........
-    (astart, bstart) = (getattr(a, 'start_date'), getattr(b, 'start_date'))
-    if astart != bstart:
-        if raise_error:
-            raise TimeSeriesCompatibilityError('start_date', astart, bstart)
-        return False
-    # Check the time steps ..............
-    asteps = getattr(a, '_dates', a).get_steps()
-    bsteps = getattr(b, '_dates', b).get_steps()
-    step_diff = (asteps != bsteps)
-    if (step_diff is True) or \
-       (hasattr(step_diff, "any") and step_diff.any()):
-        if raise_error:
-            raise TimeSeriesCompatibilityError('time_steps', asteps, bsteps)
-        return False
-    elif a.shape != b.shape:
-        if raise_error:
-            raise TimeSeriesCompatibilityError('size', "1: %s" % str(a.shape),
-                                                       "2: %s" % str(b.shape))
-        return False
-    return True
-
-def _timeseriescompat_multiple(*series):
-    """
-    Checks the date compatibility of multiple TimeSeries objects.
-    Returns True if everything's fine, or raises an exception. Unlike
-    the binary version, all items must be TimeSeries objects.
-    """
-
-    defsteps = series[0]._dates.get_steps()
-
-    def _check_steps(ser):
-        _defsteps = s._dates.get_steps()
-        _ds_comp = (_defsteps != defsteps)
-        if not hasattr(_ds_comp, "any") or _ds_comp.any():
-            return True
-        else:
-            return False
-
-    (freqs, start_dates, steps, shapes) = \
-                                zip(*[(s.freq,
-                                       s.start_date,
-                                       _check_steps(s),
-                                       s.shape) for s in series])
-    # Check the frequencies ................
-    freqset = set(freqs)
-    if len(set(freqs)) > 1:
-        err_items = tuple(freqset)
-        raise TimeSeriesCompatibilityError('freq', err_items[0], err_items[1])
-    # Check the strting dates ..............
-    startset = set(start_dates)
-    if len(startset) > 1:
-        err_items = tuple(startset)
-        raise TimeSeriesCompatibilityError('start_dates',
-                                           err_items[0], err_items[1])
-    # Check the shapes .....................
-    shapeset = set(shapes)
-    if len(shapeset) > 1:
-        err_items = tuple(shapeset)
-        raise TimeSeriesCompatibilityError('size',
-                                           "1: %s" % str(err_items[0]),
-                                           "2: %s" % str(err_items[1]))
-    # Check the steps ......................
-    if max(steps) == True:
-        bad_index = [x for (x, val) in enumerate(steps) if val][0]
-        raise TimeSeriesCompatibilityError('time_steps',
-                                           defsteps,
-                                           series[bad_index]._dates.get_steps())
-    return True
-
-
-def get_varshape(data, dates):
-    """
-    Checks the compatibility of dates and data.
-
-    Parameters
-    ----------
-    data : array-like
-        Array of data
-    dates : Date, DateArray
-        Sequence of dates
-
-    Returns
-    -------
-    varshape : tuple
-        A tuple indicating the shape of the data at any date.
-
-    Raises
-    ------
-    A :exc:`TimeSeriesCompatibilityError` exception is raised if something goes
-    wrong.
-
-    """
-
-    dshape = data.shape
-    dates = np.array(dates, copy=False, ndmin=1)
-    tshape = dates.shape
-    err_args = ('shape', "data: %s" % str(dshape), "dates: %s" % str(tshape))
-    # Same size: all is well
-    #???: The (not dates.size) is introduced to deal with masked
-    if (not dates.size):
-        return ()
-    if (dates.size == data.size):
-        if (dates.ndim > 1) or (data.ndim < 2):
-            return ()
-#    if (dates.size == data.size):
-#        if (dates.ndim > 1) or (data.ndim == 1):
-#            return ()
-    # More dates than data: not good
-    if (dates.size > data.size) or (data.ndim == 1):
-        raise TimeSeriesCompatibilityError(*err_args)
-    #....................
-    dcumulshape = np.cumprod(dshape).tolist()
-    try:
-        k = dcumulshape.index(dates.size)
-    except ValueError:
-        raise TimeSeriesCompatibilityError(*err_args)
-    else:
-        return dshape[k + 1:]
-
-
-def _getdatalength(data):
-    "Estimates the length of a series (size/nb of variables)."
-    if np.ndim(data) >= 2:
-        return np.asarray(np.shape(data))[:-1].prod()
-    else:
-        return np.size(data)
-
-def _compare_frequencies(*series):
-    """Compares the frequencies of a sequence of series.
-
-Returns the common frequency, or raises an exception if series have different
-frequencies.
-"""
-    unique_freqs = np.unique([x.freqstr for x in series])
-    try:
-        common_freq = unique_freqs.item()
-    except ValueError:
-        raise TimeSeriesError, \
-            "All series must have same frequency! (got %s instead)" % \
-            unique_freqs
-    return common_freq
-
-
-
-##### ------------------------------------------------------------------------
-##--- ... Time Series ...
-##### ------------------------------------------------------------------------
-_print_templates = dict(desc="""\
-timeseries(
- %(data)s,
-    dates =
- %(time)s,
-    freq  = %(freq)s)
-""",
-                        desc_short="""\
-timeseries(%(data)s,
-   dates = %(time)s,
-   freq  = %(freq)s)
-""",
-                        desc_flx="""\
-timeseries(
- %(data)s,
-   dtype = %(dtype)s,
-   dates =
- %(time)s,
-   freq  = %(freq)s)
-""",
-                        desc_flx_short="""\
-timeseries(%(data)s,
-   dtype = %(dtype)s,
-   dates = %(time)s,
-   freq  = %(freq)s)
-"""
-)
-
-
-
-class _tsmathmethod(object):
-    """
-    Defines a wrapper for arithmetic array methods (add, mul...).
-    When called, returns a new TimeSeries object, with the new series the result
-    of the method applied on the original series. The `_dates` part remains
-    unchanged.
-    """
-    def __init__ (self, methodname):
-        self.__name__ = methodname
-        self.__doc__ = getattr(MaskedArray, methodname).__doc__
-        self.obj = None
-
-    def __get__(self, obj, objtype=None):
-        "Gets the calling object."
-        self.obj = obj
-        return self
-
-    def __call__ (self, other, *args):
-        "Execute the call behavior."
-        instance = self.obj
-        if isinstance(other, TimeSeries):
-            compat = _timeseriescompat(instance, other, raise_error=False)
-        else:
-            compat = True
-        func = getattr(super(TimeSeries, instance), self.__name__)
-        if compat:
-            result = np.array(func(other, *args), subok=True).view(type(instance))
-            result._dates = instance._dates
-        else:
-            other_ = getattr(other, '_series', other)
-            result_ = func(other_, *args)
-            result = getattr(result_, '_series', result_)
-        return result
-
-
-class _tsarraymethod(object):
-    """
-    Defines a wrapper for basic array methods.
-    When called, returns a new TimeSeries object, with the new series the result
-    of the method applied on the original series.
-    If `ondates` is True, the same operation is performed on the `_dates`.
-    If `ondates` is False, the `_dates` part remains unchanged.
-    """
-    def __init__ (self, methodname, ondates=False):
-        self.__name__ = methodname
-        self.__doc__ = getattr(MaskedArray, methodname).__doc__
-        self._ondates = ondates
-        self.obj = None
-
-    def __get__(self, obj, objtype=None):
-        self.obj = obj
-        return self
-
-    def __call__ (self, *args, **kwargs):
-        "Execute the call behavior."
-        _name = self.__name__
-        instance = self.obj
-        # Fallback: if the instance has not been set, use the first argument
-        if instance is None:
-            args = list(args)
-            instance = args.pop(0)
-        _series = ndarray.__getattribute__(instance, '_series')
-        _dates = ndarray.__getattribute__(instance, '_dates')
-        func_series = getattr(_series, _name)
-        result = func_series(*args, **kwargs).view(type(instance))
-        if self._ondates:
-            result._dates = getattr(_dates, _name)(*args, **kwargs)
-        else:
-            result._dates = _dates
-        return result
-
-
-class _tsaxismethod(object):
-    """
-    Defines a wrapper for array methods working on an axis (mean...).
-
-    When called, returns a ndarray, as the result of the method applied on the
-    series.
-    """
-    def __init__ (self, methodname):
-        """abfunc(fillx, filly) must be defined.
-           abinop(x, filly) = x for all x to enable reduce.
-        """
-        self.__name__ = methodname
-        self.__doc__ = getattr(MaskedArray, methodname).__doc__
-        self.obj = None
-
-    def __get__(self, obj, objtype=None):
-        self.obj = obj
-        return self
-
-    def __call__ (self, *args, **params):
-        "Execute the call behavior."
-        instance = self.obj
-        if instance is None:
-            args = list(args)
-            instance = args.pop(0)
-        (_dates, _series) = (instance._dates, instance._series)
-        func = getattr(_series, self.__name__)
-        result = func(*args, **params)
-        if _dates.size != _series.size:
-            axis = params.get('axis', None)
-            if axis is None and len(args):
-                axis = args[0]
-            if axis in [-1, _series.ndim - 1]:
-                result = result.view(type(instance))
-                result._dates = _dates
-        return result
-
-
-
-
-
-
-class TimeSeries(MaskedArray, object):
-    """
-    Base class for the definition of time series.
-
-    Parameters
-    ----------
-    data : {array_like}
-        Data portion of the array.
-        Any data that is valid for constructing a MaskedArray can be used here.
-    dates : {DateArray}
-        A `DateArray` instance.
-    **optional_parameters:
-        All the parameters recognized by `MaskedArray` are also recognized by
-        TimeSeries.
-
-    Notes
-    -----
-    It is recommended to use the :func:`time_series` function for construction,
-    as it is more flexible and convenient.
-
-    See Also
-    --------
-    numpy.ma.MaskedArray
-        ndarray with support for missing data.
-    scikits.timeseries.DateArray
-    """
-
-    __array_priority__ = 20
-
-    def __new__(cls, data, dates, mask=nomask, dtype=None, copy=False,
-                fill_value=None, subok=True, keep_mask=True, hard_mask=False,
-                autosort=True, **options):
-
-        maparms = dict(copy=copy, dtype=dtype, fill_value=fill_value,
-                       subok=subok, keep_mask=keep_mask, hard_mask=hard_mask)
-        _data = MaskedArray.__new__(cls, data, mask=mask, **maparms)
-
-        # Get the data .......................................................
-        if not subok or not isinstance(_data, TimeSeries):
-            _data = _data.view(cls)
-        if _data is masked:
-            assert(np.size(dates) == 1)
-            return _data.view(cls)
-        # Check that the dates and data are compatible in shape.
-        _data._varshape = get_varshape(_data, dates)
-        # Set the dates
-        _data._dates = dates
-        if autosort:
-            _data.sort_chronologically()
-        return _data
-
-    def __array_finalize__(self, obj):
-        self._varshape = getattr(obj, '_varshape', ())
-        MaskedArray.__array_finalize__(self, obj)
-
-    def _update_from(self, obj):
-        _dates = getattr(self, '_dates', nodates)
-        newdates = getattr(obj, '_dates', nodates)
-        # Only update the dates if we don't have any
-        if not getattr(_dates, 'size', 0):
-            self.__setdates__(newdates)
-        MaskedArray._update_from(self, obj)
-
-
-    def view(self, dtype=None, type=None):
-        try:
-            output = super(TimeSeries, self).view(dtype=dtype, type=type)
-        except ValueError:
-            output = super(TimeSeries, self).view(dtype)
-        if isinstance(output, TimeSeries):
-            if output.dtype.fields:
-                output._varshape = ()
-            else:
-                fields = self.dtype.fields
-                if fields:
-                    output._varshape = (len(fields),)
-        return output
-
-
-    def _get_series(self):
-        """
-    Returns a view of the instance as a regular masked array.
-
-    This attribute is read-only.
-        """
-        _mask = self._mask
-        if _mask.ndim == 0 and _mask:
-            return masked
-        return self.view(MaskedArray)
-    series = _series = property(fget=_get_series)
-
-    @property
-    def varshape(self):
-        """
-    Returns the shape of the underlying variables.
-        """
-        return self._varshape
-
-
-    def _index_checker(self, indx):
-        """
-    Private function to process the index.
-        """
-        # Basic index ............
-        if isinstance(indx, int):
-            return (indx, indx, False)
-        _dates = self._dates
-        # String index : field name or date ?
-        if isinstance(indx, basestring):
-            if indx in (self.dtype.names or ()):
-                return (indx, slice(None, None, None), False)
-            try:
-                indx = _dates.date_to_index(Date(_dates.freq, string=indx))
-            except IndexError:
-                # Trap the exception: we need the traceback
-                exc_info = sys.exc_info()
-                msg = "Invalid field or date '%s'" % indx
-                raise IndexError(msg), None, exc_info[2]
-            return (indx, indx, False)
-        # Date or DateArray index ..........
-        if isinstance(indx, (Date, DateArray)):
-            indx = _dates.date_to_index(indx)
-            return (indx, indx, False)
-        # Slice ............................
-        if isinstance(indx, slice):
-            indx = slice(self._slicebound_checker(indx.start),
-                         self._slicebound_checker(indx.stop),
-                         indx.step)
-            return (indx, indx, False)
-        # Tuple index ......................
-        if isinstance(indx, tuple):
-            if not self._varshape:
-                return (indx, indx, False)
-            else:
-                return (indx, indx[0], False)
-        return (indx, indx, True)
-
-
-    def _slicebound_checker(self, bound):
-        "Private functions to check the bounds of a slice"
-        # Integer bound (or None) ..........
-        if bound is None or isinstance(bound, int):
-            return bound
-        # The bound is a date (string or Date)
-        _dates = self._dates
-        if isinstance(bound, str):
-            bound = Date(_dates.freq, string=bound)
-        if not isinstance(bound, Date):
-            raise ValueError(
-                "invalid object used in slice: %s" % repr(bound))
-        if bound.freq != _dates.freq:
-            raise TimeSeriesCompatibilityError('freq',
-                                               _dates.freq, bound.freq)
-        # this allows for slicing with dates outside the end points of the
-        # series and slicing on series with missing dates
-        return np.sum(self._dates < bound)
-
-
-    def __getitem__(self, indx):
-        """x.__getitem__(y) <==> x[y]
-
-    Returns the item described by i. Not a copy.
-        """
-        (sindx, dindx, recheck) = self._index_checker(indx)
-        _data = ndarray.__getattribute__(self, '_data')
-        _mask = ndarray.__getattribute__(self, '_mask')
-        _dates = ndarray.__getattribute__(self, '_dates')
-        try:
-            output = _data.__getitem__(sindx)
-        except IndexError:
-            # We don't need to recheck the index: just raise an exception
-            if not recheck:
-                raise
-            # Maybe the index is a list of Dates ?
-            try:
-                indx = _dates.date_to_index(indx)
-            except (IndexError, ValueError):
-                # Mmh, is it a list of dates as strings ?
-                try:
-                    indx = _dates.date_to_index(date_array(indx,
-                                                           freq=_dates.freq))
-                except (IndexError, ValueError, DateError):
-                    exc_info = sys.exc_info()
-                    msg = "Invalid index or date '%s'" % indx
-                    raise IndexError(msg), None, exc_info[2]
-                else:
-                    output = _data.__getitem__(indx)
-                    sindx = dindx = indx
-            else:
-                output = _data.__getitem__(indx)
-                sindx = dindx = indx
-        # Don't find the date if it's not needed......
-        if not getattr(output, 'ndim', False):
-            # A record ................
-            if isinstance(output, np.void):
-                mask = _mask[sindx]
-                if mask.view((bool, len(mask.dtype))).any():
-                    output = masked_array(output, mask=mask)
-                else:
-                    return output
-            elif _mask is not nomask and _mask[sindx]:
-                return masked
-            return output
-        # Get the date................................
-        newdates = _dates.__getitem__(dindx)
-        if not getattr(newdates, 'shape', 0):
-            # No dates ? Output a MaskedArray
-            newseries = output.view(MaskedArray)
-        else:
-            # Some dates: output a TimeSeries
-            newseries = output.view(type(self))
-            newseries._dates = newdates
-        # Update some info from self (fill_value, _basedict...)
-        MaskedArray._update_from(newseries, self)
-        # Fix the fill_value if we were accessing a field of a flexible array
-        if isinstance(sindx, basestring):
-            _fv = self._fill_value
-            if _fv is not None and not np.isscalar(_fv):
-                 newseries._fill_value = _fv[sindx]
-            newseries._isfield = True
-        # Fix the mask
-        if _mask is not nomask:
-            newseries._mask = _mask[sindx]
-            newseries._sharedmask = True
-        return newseries
-
-
-    def __setitem__(self, indx, value):
-        """x.__setitem__(i, y) <==> x[i]=y
-
-    Sets item described by index. If value is masked, masks those locations.
-        """
-        (sindx, dindx, recheck) = self._index_checker(indx)
-        _dates = ndarray.__getattribute__(self, '_dates')
-        try:
-            MaskedArray.__setitem__(self, sindx, value)
-        except IndexError:
-            # We don't need to recheck the index: just raise an exception
-            if not recheck:
-                raise
-            # Maybe the index is a list of Dates ?
-            try:
-                indx = _dates.date_to_index(indx)
-            except (IndexError, ValueError):
-                # Mmh, is it a list of dates as strings ?
-                try:
-                    indx = _dates.date_to_index(date_array(indx,
-                                                           freq=_dates.freq))
-                except (IndexError, ValueError, DateError):
-                    exc_info = sys.exc_info()
-                    msg = "Invalid index or date '%s'" % indx
-                    raise IndexError(msg), None, exc_info[2]
-                else:
-                    MaskedArray.__setitem__(self, indx, value)
-            else:
-                MaskedArray.__setitem__(self, indx, value)
-
-    def __setattr__(self, attr, value):
-        if attr in ['_dates', 'dates']:
-            return self.__setdates__(value)
-        elif attr == 'shape':
-            if self._varshape:
-                err_msg = "Reshaping a nV/nD series is not implemented yet !"
-                raise NotImplementedError(err_msg)
-            else:
-                self._dates.shape = value
-        return ndarray.__setattr__(self, attr, value)
-
-
-    def __setdates__(self, value):
-        """
-    Sets the dates to `value`.
-        """
-        # Make sure it's a DateArray
-        if not isinstance(value, DateArray):
-            err_msg = "The input dates should be a valid "\
-                      "DateArray object (got %s instead)" % type(value)
-            raise TypeError(err_msg)
-        # Skip if dates is nodates (or empty)\
-        if value is nodates or not getattr(value, 'size', 0):
-            return super(TimeSeries, self).__setattr__('_dates', value)
-        # Make sure it has the proper size
-        tsize = getattr(value, 'size', 1)
-        # Check the _varshape
-        varshape = self._varshape
-        if not varshape:
-            # We may be using the default: retry
-            varshape = self._varshape = get_varshape(self, value)
-        # Get the data length (independently of the nb of variables)
-        dsize = self.size // int(np.prod(varshape))
-        if tsize != dsize:
-            raise TimeSeriesCompatibilityError("size",
-                                               "data: %s" % dsize,
-                                               "dates: %s" % tsize)
-#        # Check whether the dates are already sorted
-#        if not value.is_chronological():
-#            _cached = value._cachedinfo
-#            idx = _cached['chronidx']
-#            _series = self._series
-#            if not varshape:
-#                if self.ndim > 1:
-#                    flatseries = _series.flat
-#                    flatseries[:] = flatseries[idx]
-#                else:
-#                    _series[:] = _series[idx]
-#            else:
-#                inishape = self.shape
-#                _series.shape = tuple([-1,]+list(varshape))
-#                _series[:] = _series[idx]
-#                _series.shape = inishape
-#            _cached['chronidx'] = np.array([], dtype=int)
-#            _cached['ischrono'] = True
-        #
-        if not varshape and (value.shape != self.shape):
-            # The data is 1D
-            value = value.reshape(self.shape)
-        super(TimeSeries, self).__setattr__('_dates', value)
-        return
-
-    dates = property(fget=lambda self:self._dates,
-                     fset=__setdates__)
-
-
-    #
-    def sort_chronologically(self):
-        """
-    Sort the series by chronological order (in place).
-
-    Notes
-    -----
-    This method sorts the series **in place**.
-    To sort the a copy of the series, use the :func:`sort_chronologically`
-    function.
-
-    See Also
-    --------
-    sort_chronologically
-        Equivalent function.
-        """
-        _dates = self._dates
-        _series = self._series
-        if not _dates.is_chronological():
-            _cached = _dates._cachedinfo
-            idx = _cached['chronidx']
-            if not self._varshape:
-                flatseries = _series.flat
-                flatseries[:] = flatseries[idx]
-            else:
-                inishape = self.shape
-                _series.shape = tuple([-1, ] + list(self._varshape))
-                _series[:] = _series[idx]
-                _series.shape = inishape
-            # Sort the dates and reset the cache
-            flatdates = _dates.ravel()
-            flatdates[:] = flatdates[idx]
-            _cached['chronidx'] = np.array([], dtype=int)
-            _cached['ischrono'] = True
-
-
-
-    def __str__(self):
-        """Returns a string representation of self (w/o the dates...)"""
-        return str(self._series)
-
-
-    def __repr__(self):
-        """
-    Calculates the repr representation, using masked for fill if it is
-    enabled. Otherwise fill with fill value.
-    """
-        _dates = self._dates
-        if np.size(self._dates) > 2 and self.is_valid():
-            timestr = "[%s ... %s]" % (str(_dates[0]), str(_dates[-1]))
-        else:
-            timestr = str(_dates)
-        kwargs = {'data': str(self._series), 'time': timestr,
-                  'freq': self.freqstr, 'dtype': self.dtype}
-        names = kwargs['dtype'].names
-        if self.ndim <= 1:
-            if names:
-                return _print_templates['desc_flx_short'] % kwargs
-            return _print_templates['desc_short'] % kwargs
-        if names:
-            return _print_templates['desc_flx'] % kwargs
-        return _print_templates['desc'] % kwargs
-
-    #............................................
-    __add__ = _tsmathmethod('__add__')
-    __radd__ = _tsmathmethod('__add__')
-    __sub__ = _tsmathmethod('__sub__')
-    __rsub__ = _tsmathmethod('__rsub__')
-    __pow__ = _tsmathmethod('__pow__')
-    __mul__ = _tsmathmethod('__mul__')
-    __rmul__ = _tsmathmethod('__mul__')
-    __div__ = _tsmathmethod('__div__')
-    __rdiv__ = _tsmathmethod('__rdiv__')
-    __truediv__ = _tsmathmethod('__truediv__')
-    __rtruediv__ = _tsmathmethod('__rtruediv__')
-    __floordiv__ = _tsmathmethod('__floordiv__')
-    __rfloordiv__ = _tsmathmethod('__rfloordiv__')
-    __eq__ = _tsmathmethod('__eq__')
-    __ne__ = _tsmathmethod('__ne__')
-    __lt__ = _tsmathmethod('__lt__')
-    __le__ = _tsmathmethod('__le__')
-    __gt__ = _tsmathmethod('__gt__')
-    __ge__ = _tsmathmethod('__ge__')
-
-    copy = _tsarraymethod('copy', ondates=True)
-    compress = _tsarraymethod('compress', ondates=True)
-    cumsum = _tsarraymethod('cumsum', ondates=False)
-    cumprod = _tsarraymethod('cumprod', ondates=False)
-    anom = _tsarraymethod('anom', ondates=False)
-
-    sum = _tsaxismethod('sum')
-    prod = _tsaxismethod('prod')
-    mean = _tsaxismethod('mean')
-    var = _tsaxismethod('var')
-    std = _tsaxismethod('std')
-    all = _tsaxismethod('all')
-    any = _tsaxismethod('any')
-
-
-    def ravel(self):
-        """
-    Returns a ravelled view of the instance.
-
-    If the instance corresponds to one variable (e.g., ``self.varshape == ()``),
-    the result is the ravelled view of the input.
-    Otherwise, the result is actually a TimeSeries where the `series` attribute
-    is a reshaped view of the input and where the `dates` attribute is
-    a ravelled view of the input `dates` attribute.
-
-    Examples
-    --------
-    >>> start_date = ts.Date('M', '2001-01')
-    >>> dates = ts.date_array(start_date=start_date, length=4)
-    >>> series = ts.time_series([[1, 2], [3, 4]], dates=dates)
-    >>> series
-    timeseries(
-     [[1 2]
-     [3 4]],
-        dates =
-     [[Jan-2001 Feb-2001] ... [Mar-2001 Apr-2001]],
-        freq  = M)
-    >>> series.ravel()
-    timeseries([1 2 3 4],
-       dates = [Jan-2001 ... Apr-2001],
-       freq  = M)
-    >>> series = ts.time_series([[1, 2], [3, 4]], start_date=start_date)
-    >>> series
-    timeseries(
-     [[1 2]
-     [3 4]],
-        dates =
-     [Jan-2001 Feb-2001],
-        freq  = M)
-    >>> series.ravel()
-    timeseries(
-     [[1 2]
-     [3 4]],
-        dates =
-     [Jan-2001 Feb-2001],
-        freq  = M)
-        """
-        _varshape = self._varshape
-        if _varshape:
-            newshape = tuple([-1] + [np.prod(_varshape), ])
-            result = MaskedArray.reshape(self, *newshape)
-        else:
-            result = MaskedArray.ravel(self)
-        result._dates = self._dates.ravel()
-        return result
-
-
-    def reshape(self, *newshape, **kwargs):
-        """
-    Returns a time series containing the data of a, but with a new shape.
-
-    The result is a view to the original array; if this is not possible,
-    a ValueError is raised.
-
-    Parameters
-    ----------
-    shape : shape tuple or int
-       The new shape should be compatible with the original shape. If an
-       integer, then the result will be a 1D array of that length.
-    order : {'C', 'F'}, optional
-        Determines whether the array data should be viewed as in C
-        (row-major) order or FORTRAN (column-major) order.
-
-    Returns
-    -------
-    reshaped_array : array
-        A new view to the timeseries.
-
-    Warnings
-    --------
-    The `._dates` part is reshaped, but the order is NOT ensured.
-
-        """
-        kwargs.update(order=kwargs.get('order', 'C'))
-        if self._varshape:
-            try:
-                bkdtype = (self.dtype, self._varshape)
-                _series = self._series.view([('', bkdtype)])
-                result = _series.reshape(*newshape, **kwargs)
-                result = result.view(dtype=bkdtype, type=type(self))
-                result._dates = ndarray.reshape(self._dates, *newshape, **kwargs)
-            except:
-                err_msg = "Reshaping a nV/nD series is not implemented yet !"
-                raise NotImplementedError(err_msg)
-        # 1D series : reshape the dates as well
-        else:
-            result = MaskedArray.reshape(self, *newshape, **kwargs)
-            result._dates = ndarray.reshape(self._dates, *newshape, **kwargs)
-            result._varshape = ()
-        return result
-
-    #.........................................................................
-    def ids (self):
-        """Return the ids of the data, dates and mask areas"""
-        return (id(self._series), id(self.dates),)
-
-    #.........................................................................
-    @property
-    def freq(self):
-        """Returns the corresponding frequency (as an integer)."""
-        return self._dates.freq
-    @property
-    def freqstr(self):
-        """Returns the corresponding frequency (as a string)."""
-        return self._dates.freqstr
-
-    @property
-    def year(self):
-        """Returns the year for each date of the instance."""
-        return self._dates.year
-    years = year
-    @property
-    def qyear(self):
-        """
-    For quarterly frequencies, returns the equivalent of the 'fiscal' year
-    for each date of the instance.
-    For non-quarterly frequencies, returns the year.
-        """
-        return self._dates.qyear
-    @property
-    def quarter(self):
-        """Returns the quarter for each date of the instance."""
-        return self._dates.quarter
-    quarters = quarter
-    @property
-    def month(self):
-        """Returns the month for each date of the instance."""
-        return self._dates.month
-    months = month
-    @property
-    def week(self):
-        """Returns the week for each date in self._dates."""
-        return self._dates.week
-    weeks = week
-    @property
-    def day(self):
-        """Returns the day of month for each date of the instance."""
-        return self._dates.day
-    days = day
-    @property
-    def day_of_week(self):
-        """Returns the day of week for each date of the instance."""
-        return self._dates.weekday
-    weekdays = weekday = day_of_week
-    @property
-    def day_of_year(self):
-        """Returns the day of year for each date of the instance."""
-        return self._dates.day_of_year
-    yeardays = day_of_year
-    @property
-    def hour(self):
-        """Returns the hour for each date in self._dates."""
-        return self._dates.hour
-    hours = hour
-    @property
-    def minute(self):
-        """Returns the minute for each date in self._dates."""
-        return self._dates.minute
-    minutes = minute
-    @property
-    def second(self):
-        """Returns the second for each date in self._dates."""
-        return self._dates.second
-    seconds = second
-
-    @property
-    def start_date(self):
-        """Returns the first date of the series."""
-        _dates = self._dates
-        dsize = _dates.size
-        if dsize == 0:
-            return None
-        elif dsize == 1:
-            return _dates[0]
-        else:
-            return Date(self.freq, _dates.flat[0])
-
-    @property
-    def end_date(self):
-        """Returns the last date of the series."""
-        _dates = self._dates
-        dsize = _dates.size
-        if dsize == 0:
-            return None
-        elif dsize == 1:
-            return _dates[-1]
-        else:
-            return Date(self.freq, _dates.flat[-1])
-
-    def is_valid(self):
-        """Returns whether the series has no duplicate/missing dates."""
-        return self._dates.is_valid()
-
-    def isvalid(self):
-        """Deprecated name: use '.is_valid' instead."""
-        return self._dates.isvalid()
-
-    def has_missing_dates(self):
-        """Returns whether there's a date gap in the series."""
-        return self._dates.has_missing_dates()
-
-    def is_full(self):
-        """Returns whether there's no date gap in the series."""
-        return self._dates.is_full()
-
-    def isfull(self):
-        """Deprecated name: use '.is_full' instead."""
-        return self._dates.isfull()
-
-    def has_duplicated_dates(self):
-        """Returns whether there are duplicated dates in the series."""
-        return self._dates.has_duplicated_dates()
-
-    def get_steps(self):
-        """
-    Returns the time steps between consecutive dates, in the same unit as
-    the frequency of the instance.
-        """
-        return self._dates.get_steps()
-
-    def is_chronological(self):
-        """Returns whether the series is in chronological order."""
-        return self._dates.is_chronological()
-
-    def date_to_index(self, date):
-        """Returns the index corresponding to a given date, as an integer."""
-        return self._dates.date_to_index(date)
-
-    #.....................................................
-    def asfreq(self, freq, relation="END"):
-        """
-    Converts the dates portion of the TimeSeries to another frequency.
-
-    The resulting TimeSeries will have the same shape and dimensions
-    as the original series (unlike the :meth:`convert` method).
-
-    Parameters
-    ----------
-    freq : {freq_spec}
-    relation : {'END', 'START'} (optional)
-
-    Returns
-    -------
-    A new TimeSeries with the :attr:`.dates` :class:`DateArray` at the
-    specified frequency (the :meth`.asfreq` method of the :attr:`.dates`
-    property will be called).
-    The data in the resulting series will be a VIEW of the original series.
-
-    Notes
-    -----
-    The parameters are the exact same as for
-    :meth:`~scikit.timeseries.DateArray.asfreq`. Please see the docstring for
-    that method for details on the parameters and how the actual conversion is
-    performed.
-
-    """
-        if freq is None: return self
-
-        return TimeSeries(self._series,
-                          dates=self._dates.asfreq(freq, relation=relation))
-    #.....................................................
-    def transpose(self, *axes):
-        if self._dates.size == self.size:
-            result = MaskedArray.transpose(self, *axes)
-            result._dates = self._dates.transpose(*axes)
-        else:
-            errmsg = "Operation not permitted on multi-variable series"
-            if (len(axes) == 0) or axes[0] != 0:
-                raise TimeSeriesError, errmsg
-            else:
-                result = MaskedArray.transpose(self, *axes)
-                result._dates = self._dates
-        return result
-    transpose.__doc__ = np.transpose.__doc__
-
-    def split(self):
-        """Split a multi-dimensional series into individual columns."""
-        if self.ndim == 1:
-            return [self]
-        else:
-            n = self.shape[1]
-            arr = hsplit(self, n)[0]
-            return [self.__class__(np.squeeze(a),
-                                   self._dates,
-                                   **_attrib_dict(self)) for a in arr]
-
-    def filled(self, fill_value=None):
-        """
-    Returns an array of the same class as `_data`,  with masked values
-    filled with `fill_value`. Subclassing is preserved.
-
-    Parameters
-    ----------
-    fill_value : {None, singleton of type self.dtype}, optional
-        The value to fill in masked values with.
-        If `fill_value` is None, uses ``self.fill_value``.
-
-    """
-        result = self._series.filled(fill_value=fill_value).view(type(self))
-        result._dates = self._dates
-        return result
-
-
-    def tolist(self):
-        """
-    Returns the dates and data portion of the TimeSeries "zipped" up in
-    a list of standard python objects (eg. datetime, int, etc...).
-
-        """
-        if self.ndim > 0:
-            return zip(self.dates.tolist(), self.series.tolist())
-        else:
-            return self.series.tolist()
-
-    def torecords(self):
-        """
-    Transforms a TimeSeries into a structured array with three fields:.
-
-    * the ``_dates`` field stores the date information;
-    * the ``_data`` field stores the ``_data`` part of the series;
-    * the ``_mask`` field stores the mask.
-
-
-    Returns
-    -------
-    record : ndarray
-        A new flexible-type ndarray with three fields: the first element
-        contains the date (as an integer), the second element contains the
-        corresponding value and the third the corresponding mask boolean.
-        The returned record shape matches the shape of the instance.
-
-        """
-        _varshape = self._varshape
-        if not _varshape:
-            desctype = [('_dates', int),
-                        ('_data', self.dtype),
-                        ('_mask', self.mask.dtype)]
-        else:
-            desctype = [('_dates', int),
-                        ('_data', (self.dtype, _varshape)),
-                        ('_mask', (self.mask.dtype, _varshape))]
-        flat = self.ravel()
-        _dates = np.asarray(flat._dates)
-        if flat.size > 0:
-            result = np.empty(len(_dates), dtype=desctype)
-            result['_dates'] = _dates
-            result['_data'] = flat._data
-            result['_mask'] = flat._mask
-            return result
-        else:
-            return np.array([[], [], []], dtype=desctype,)
-
-    # for backwards compatibility
-    toflex = torecords
-    #......................................................
-    # Pickling
-    def __getstate__(self):
-        """
-
-    Returns the internal state of the TimeSeries, for pickling purposes.
-        """
-    #    raise NotImplementedError,"Please use timeseries.archive/unarchive instead."""
-        state = (1,
-                 self.shape,
-                 self.dtype,
-                 self.flags.fnc,
-                 self._data.tostring(),
-                 getmaskarray(self).tostring(),
-                 self._fill_value,
-                 self._dates.shape,
-                 self._dates.__array__().tostring(),
-                 self.freq,
-                 self._optinfo,
-                 )
-        return state
-    #
-    def __setstate__(self, state):
-        """
-
-    Restores the internal state of the TimeSeries, for pickling purposes.
-    `state` is typically the output of the ``__getstate__`` output, and is a 5-tuple:
-
-        - class name
-        - a tuple giving the shape of the data
-        - a typecode for the data
-        - a binary string for the data
-        - a binary string for the mask.
-        """
-        (ver, shp, typ, isf, raw, msk, flv, dsh, dtm, frq, infodict) = state
-        MaskedArray.__setstate__(self, (ver, shp, typ, isf, raw, msk, flv))
-        _dates = self._dates
-        _dates.__setstate__((ver, dsh, dtype(int_), isf, dtm, frq))
-        _dates.freq = frq
-        _dates._cachedinfo.update(dict(full=None, hasdups=None, steps=None,
-                                       toobj=None, toord=None, tostr=None))
-        # Update the _optinfo dictionary
-        self._optinfo.update(infodict)
-#
-    def __reduce__(self):
-        """Returns a 3-tuple for pickling a MaskedArray."""
-        return (_tsreconstruct,
-                (self.__class__, self._baseclass,
-                 self.shape, self._dates.shape, self.dtype, self._fill_value),
-                self.__getstate__())
-
-def _tsreconstruct(genclass, baseclass, baseshape, dateshape, basetype, fill_value):
-    """Internal function that builds a new TimeSeries from the information stored
-    in a pickle."""
-    #    raise NotImplementedError,"Please use timeseries.archive/unarchive instead."""
-    _series = ndarray.__new__(baseclass, baseshape, basetype)
-    _dates = ndarray.__new__(DateArray, dateshape, int_)
-    _mask = ndarray.__new__(ndarray, baseshape, bool_)
-    return genclass.__new__(genclass, _series, dates=_dates, mask=_mask,
-                            dtype=basetype, fill_value=fill_value)
-
-
-def _attrib_dict(series, exclude=[]):
-    """this function is used for passing through attributes of one
-time series to a new one being created"""
-    result = {'fill_value':series.fill_value}
-    return dict(filter(lambda x: x[0] not in exclude, result.iteritems()))
-
-
-##### --------------------------------------------------------------------------
-##--- ... Additional methods ...
-##### --------------------------------------------------------------------------
-
-def _extrema(self, method, axis=None, fill_value=None):
-    "Private function used by max/min"
-    (_series, _dates) = (self._series, self._dates)
-    func = getattr(_series, method)
-    idx = func(axis, fill_value)
-
-    # 1D series .......................
-    if (_dates.size == _series.size):
-        if axis is None:
-            return self.ravel()[idx]
-        else:
-            return self[idx]
-    # nD series .......................
-    else:
-        if axis is None:
-            idces = np.unravel_index(idx, _series.shape)
-            result = time_series(_series[idces], dates=_dates[idces[0]])
-        else:
-            _shape = _series.shape
-            _dates = np.repeat(_dates, np.prod(_shape[1:])).reshape(_shape)
-            _s = ma.choose(idx, np.rollaxis(_series, axis, 0))
-            _d = ma.choose(idx, np.rollaxis(_dates, axis, 0))
-            result = time_series(_s, dates=_d, freq=_dates.freq)
-        return result
-
-def _max(self, axis=None, fill_value=None):
-    """Return the maximum of self along the given axis.
-    Masked values are filled with fill_value.
-
-    Parameters
-    ----------
-    axis : int, optional
-        Axis along which to perform the operation.
-        If None, applies to a flattened view of the array.
-    fill_value : {var}, optional
-        Value used to fill in the masked values.
-        If None, use the the output of maximum_fill_value().
-    """
-    return _extrema(self, 'argmax', axis, fill_value)
-TimeSeries.max = _max
-
-def _min(self, axis=None, fill_value=None):
-    """Return the minimum of self along the given axis.
-    Masked values are filled with fill_value.
-
-    Parameters
-    ----------
-    axis : int, optional
-        Axis along which to perform the operation.
-        If None, applies to a flattened view of the array.
-    fill_value : {var}, optional
-        Value used to fill in the masked values.
-        If None, use the the output of minimum_fill_value().
-    """
-    return _extrema(self, 'argmin', axis, fill_value)
-TimeSeries.min = _min
-
-
-#.......................................
-
-
-class _tsblockedmethods(object):
-    """Defines a wrapper for array methods that should be temporarily disabled.
-    """
-    def __init__ (self, methodname):
-        """abfunc(fillx, filly) must be defined.
-           abinop(x, filly) = x for all x to enable reduce.
-        """
-        self._name = methodname
-        self.obj = None
-    #
-    def __get__(self, obj, objtype=None):
-        self.obj = obj
-        return self
-    #
-    def __call__ (self, *args, **params):
-        raise NotImplementedError
-
-TimeSeries.swapaxes = _tsarraymethod('swapaxes', ondates=True)
-
-#####---------------------------------------------------------------------------
-#---- --- Definition of functions from the corresponding methods ---
-#####---------------------------------------------------------------------------
-class _frommethod(object):
-    """Defines functions from existing MaskedArray methods.
-:ivar _methodname (String): Name of the method to transform.
-    """
-    def __init__(self, methodname):
-        self.__name__ = methodname
-        self.__doc__ = self.getdoc()
-    def getdoc(self):
-        "Returns the doc of the function (from the doc of the method)."
-        try:
-            return getattr(TimeSeries, self.__name__).__doc__
-        except:
-            return "???"
-    #
-    def __call__ (self, caller, *args, **params):
-        if hasattr(caller, self.__name__):
-            method = getattr(caller, self.__name__)
-            # If method is not callable, it's a property, and don't call it
-            if hasattr(method, '__call__'):
-                return method.__call__(*args, **params)
-            return method
-        method = getattr(np.asarray(caller), self.__name__)
-        try:
-            return method(*args, **params)
-        except SystemError:
-            return getattr(np, self.__name__).__call__(caller, *args, **params)
-#............................
-weekday = _frommethod('weekday')
-day_of_year = _frommethod('day_of_year')
-week = _frommethod('week')
-year = _frommethod('year')
-quarter = _frommethod('quarter')
-month = _frommethod('month')
-day = _frommethod('day')
-hour = _frommethod('hour')
-minute = _frommethod('minute')
-second = _frommethod('second')
-
-split = _frommethod('split')
-
-torecords = toflex = _frommethod('toflex')
-
-#
-##### ---------------------------------------------------------------------------
-#---- ... Additional methods ...
-##### ---------------------------------------------------------------------------
-def tofile(series, fileobject, format=None,
-           separator=" ", linesep='\n', precision=5,
-           suppress_small=False, keep_open=False):
-    """
-    Writes the TimeSeries to a file. The series should be 2D at most.
-
-    Parameters
-    ----------
-    series : TimeSeries
-        The array to write.
-    fileobject
-        An open file object or a string to a valid filename.
-    format : {None, string}, optional
-        Format string for the date.
-        If None, uses the default date format.
-    separator : {string}, optional
-        Separator to write between elements of the array.
-    linesep : {string}, optional
-        Separator to write between rows of array.
-    precision : {integer}, optional
-        Number of digits after the decimal place to write.
-    suppress_small : {boolean}, optional
-        Whether on-zero to round small numbers down to 0.0
-    keep_open : {boolean}, optional
-        Whether to close the file or to return the open file.
-
-    Returns
-    -------
-    file : file object
-        The open file (if ``keep_open`` is non-zero).
-    """
-
-    try:
-        import scipy.io
-    except ImportError:
-        raise ImportError("scipy is required for the tofile function/method")
-
-    (_dates, _data) = (series._dates, series._series)
-    optpars = dict(separator=separator, linesep=linesep, precision=precision,
-                   suppress_small=suppress_small, keep_open=keep_open)
-    if _dates.size == _data.size:
-        # 1D version
-        tmpfiller = ma.empty((_dates.size, 2), dtype=np.object_)
-        _data = _data.reshape(-1)
-        tmpfiller[:, 1:] = ma.atleast_2d(_data).T
-    else:
-        sshape = list(_data.shape)
-        sshape[-1] += 1
-        tmpfiller = ma.empty(sshape, dtype=np.object_)
-        tmpfiller[:, 1:] = _data
-    #
-    if format is None:
-        tmpfiller[:, 0] = _dates.ravel().tostring()
-    else:
-        tmpfiller[:, 0] = [_.strftime(format) for _ in _dates.ravel()]
-    return scipy.io.write_array(fileobject, tmpfiller, **optpars)
-
-
-TimeSeries.tofile = tofile
-
-
-def flatten(series):
-    """
-    Flattens a (multi-) time series to 1D series.
-
-    """
-    shp_ini = series.shape
-    # Already flat time series....
-    if len(shp_ini) == 1:
-        return series
-    # Folded single time series ..
-    newdates = series._dates.ravel()
-    if series._dates.size == series._series.size:
-        newshape = (series._series.size,)
-    else:
-        newshape = (np.asarray(shp_ini[:-1]).prod(), shp_ini[-1])
-    newseries = series._series.reshape(newshape)
-    return time_series(newseries, newdates)
-
-TimeSeries.flatten = flatten
-
-
-def compressed(series):
-    """
-    Suppresses missing values from a time series.
-
-    Returns a :class:`TimeSeries` object.
-
-    """
-    if series._mask is nomask:
-        return series
-    if series.ndim == 1:
-        keeper = ~(series._mask)
-    elif series.ndim == 2:
-        _dates = series._dates
-        _series = series._series
-        # Both dates and data are 2D: ravel first
-        if _dates.ndim == 2:
-            series = series.ravel()
-            keeper = ~(series._mask)
-        # 2D series w/ only one date : return a new series ....
-        elif _dates.size == 1:
-            result = _series.compressed().view(type(series))
-            result._dates = series.dates
-            return result
-        # a 2D series: suppress the rows (dates are in columns)
-        else:
-            keeper = ~(series._mask.any(-1))
-    else:
-        raise NotImplementedError
-    return series[keeper]
-TimeSeries.compressed = compressed
-
-
-##### -------------------------------------------------------------------------
-#---- --- TimeSeries constructor ---
-##### -------------------------------------------------------------------------
-
-def time_series(data, dates=None, start_date=None, length=None, freq=None,
-                mask=nomask, dtype=None, copy=False, fill_value=None,
-                keep_mask=True, hard_mask=False, autosort=True):
-    """
-    Creates a TimeSeries object.
-
-    The ``data`` parameter can be a valid :class:`TimeSeries` object.
-    In that case, the ``dates``, ``start_date`` or ``freq`` parameters are
-    optional: if none of them is given, the dates of the result are the dates of
-    ``data``.
-
-    If ``data`` is not a :class:`TimeSeries`, then ``dates`` must be either
-    ``None`` or an object recognized by the :func:`date_array` function (used
-    internally):
-
-        * an existing :class:`DateArray` object;
-        * a sequence of :class:`Date` objects with the same frequency;
-        * a sequence of :class:`datetime.datetime` objects;
-        * a sequence of dates in string format;
-        * a sequence of integers corresponding to the representation of
-          :class:`Date` objects.
-
-    In any of the last four possibilities, the ``freq`` parameter is mandatory.
-
-    If ``dates`` is ``None``, a continuous :class:`DateArray` is automatically
-    constructed as an array of size ``len(data)`` starting at ``start_date`` and
-    with a frequency ``freq``.
-
-
-    Parameters
-    ----------
-    data : array_like
-        Data portion of the array. Any data that is valid for constructing a
-        :class:`~numpy.ma.MaskedArray` can be used here.
-        :keyword:`data` can also be a :class:`TimeSeries` object.
-    dates : {None, var}, optional
-        A sequence of dates corresponding to each entry.
-    start_date : {Date}, optional
-        Date corresponding to the first entry of the data (index 0).
-        This parameter must be a valid :class:`Date` object, and is mandatory
-        if ``dates`` is None and if ``data`` has a length greater or equal to 1.
-    length : {integer}, optional
-        Length of the dates.
-    freq : {freq_spec}, optional
-        A valid frequency specification, as a string or an integer.
-        This parameter is mandatory if ``dates`` is None.
-        Otherwise, the frequency of the series is set to the frequency
-        of the ``dates`` input.
-
-    Notes
-    -----
-    * All other parameters recognized by the :func:`numpy.ma.array` constructor
-      are also recognized by the function.
-    * If ``data`` is zero-sized, only the ``freq`` parameter is mandatory.
-
-    See Also
-    --------
-    numpy.ma.masked_array
-        Constructor for the :class:`~numpy.ma.MaskedArray` class.
-    scikits.timeseries.date_array
-        Constructor for the :class:`DateArray` class.
-
-    """
-    freq = check_freq(freq)
-
-    if dates is None:
-        _dates = getattr(data, '_dates', None)
-    elif isinstance(dates, (Date, DateArray)):
-        if copy:
-            _dates = date_array(dates, autosort=False).copy()
-        else:
-            _dates = date_array(dates, autosort=False)
-    elif isinstance(dates, (tuple, list, ndarray)):
-        _dates = date_array(dlist=dates, freq=freq, autosort=False)
-    else:
-        _dates = date_array([], freq=freq)
-
-    if _dates is not None:
-        # Make sure _dates has the proper frequency
-        if (freq != _c.FR_UND) and (_dates.freq != freq):
-            _dates = _dates.asfreq(freq)
-    else:
-        dshape = np.shape(data)
-        if len(dshape) > 0:
-            length = length or dshape[0]
-            _dates = date_array(start_date=start_date, freq=freq, length=length)
-        else:
-            _dates = date_array([], freq=freq)
-
-    return TimeSeries(data=data, mask=mask, dates=_dates,
-                      copy=copy, dtype=dtype, subok=True,
-                      fill_value=fill_value, keep_mask=keep_mask,
-                      hard_mask=hard_mask, autosort=autosort)
-
-
-
-
-##### --------------------------------------------------------------------------
-#---- ... Additional functions ...
-##### --------------------------------------------------------------------------
-
-
-def sort_chronologically(series):
-    """
-    Returns a copy of series, sorted chronologically.
-    """
-    series = series.copy()
-    series.sort_chronologically()
-    return series
-
-
-def asrecords(series):
-    "Deprecated version of torecords"
-    warnings.warn("Deprecated function: use torecords instead")
-    return torecords(series)
-
-
-def adjust_endpoints(a, start_date=None, end_date=None, copy=False):
-    """
-    Returns a TimeSeries going from `start_date` to `end_date`.
-
-    Parameters
-    ----------
-    a : TimeSeries
-        TimeSeries object whose dates must be adjusted
-    start_date : Date, optional
-        New starting date. If not specified, the current starting date is used.
-    end_date : Date, optional
-        New ending date. If not specified, the current ending date is used.
-    copy : {False, True}, optional
-        Whether to return a copy of the initial array (:const:`True`)
-        or a reference to the array (:const:`False`), in the case where both
-        the `start_date` and `end_date` both fall into the initial range
-        of dates.
-
-    """
-    # Series validity tests .....................
-    if not isinstance(a, TimeSeries):
-        raise TypeError, "Argument should be a valid TimeSeries object!"
-    if a.freq == 'U':
-        errmsg = "Cannot adjust a series with 'Undefined' frequency."
-        raise TimeSeriesError(errmsg,)
-
-    if not a._dates.is_valid():
-        errmsg = "Cannot adjust a series with missing or duplicated dates."
-        raise TimeSeriesError(errmsg,)
-    # Flatten the series if needed ..............
-    a = a.flatten()
-    shp_flat = a.shape
-    # Dates validity checks .,...................
-    msg = "%s should be a valid Date object! (got %s instead)"
-    if a.dates.size >= 1:
-        (dstart, dend) = a.dates[[0, -1]]
-    else:
-        (dstart, dend) = (None, None)
-    # Skip the empty series case
-    if dstart is None and (start_date is None or end_date is None):
-        errmsg = "Both start_date and end_date must be specified"\
-                 " to adjust endpoints of a zero length series!"
-        raise TimeSeriesError(errmsg,)
-    #....
-    if start_date is None:
-        start_date = dstart
-        start_lag = 0
-    else:
-        if isinstance(start_date, basestring):
-            start_date = Date(a.freq, string=start_date)
-        elif not isinstance(start_date, Date):
-            raise TypeError, msg % ('start_date', type(start_date))
-        if dstart is not None:
-            start_lag = start_date - dstart
-        else:
-            start_lag = start_date
-    #....
-    if end_date is None:
-        end_date = dend
-        end_lag = 0
-    else:
-        if isinstance(end_date, basestring):
-            end_date = Date(a.freq, string=end_date)
-        elif not isinstance(end_date, Date):
-            raise TypeError, msg % ('end_date', type(end_date))
-        if dend is not None:
-            end_lag = end_date - dend
-        else:
-            end_lag = end_date
-    # Check if the new range is included in the old one
-    if start_lag >= 0:
-        if end_lag == 0:
-            if not copy:
-                return a[start_lag:]
-            else:
-                return a[start_lag:].copy()
-        elif end_lag < 0:
-            if not copy:
-                return a[start_lag:end_lag]
-            else:
-                return a[start_lag:end_lag].copy()
-    # Create a new series .......................
-    newdates = date_array(start_date=start_date, end_date=end_date)
-
-    newshape = list(shp_flat)
-    newshape[0] = len(newdates)
-    newshape = tuple(newshape)
-
-    newseries = np.empty(newshape, dtype=a.dtype).view(type(a))
-    #!!!: Here, we may wanna use something else than MaskType
-    newseries.__setmask__(np.ones(newseries.shape, dtype=bool_))
-    newseries._dates = newdates
-    newseries._update_from(a)
-    if dstart is not None:
-        start_date = max(start_date, dstart)
-        end_date = min(end_date, dend) + 1
-        if not copy:
-            newseries[start_date:end_date] = a[start_date:end_date]
-        else:
-            newseries[start_date:end_date] = a[start_date:end_date].copy()
-    return newseries
-TimeSeries.adjust_endpoints = adjust_endpoints
-
-
-
-def align_series(*series, **kwargs):
-    """
-    Aligns several TimeSeries, so that their starting and ending dates match.
-
-    Series are resized and filled with masked values accordingly.
-
-    The resulting series have no missing dates (ie. ``series.is_valid() == True``
-    for each of the resulting series).
-
-    The function accepts two extras parameters:
-    - `start_date` forces the series to start at that given date,
-    - `end_date` forces the series to end at that given date.
-
-    By default, `start_date` and `end_date` are set respectively to the smallest
-    and largest dates of the series.
-    """
-    if len(series) < 2:
-        return series
-    unique_freqs = np.unique([x.freqstr for x in series])
-    common_freq = _compare_frequencies(*series)
-
-    # if any of the series have missing dates, fill them in first
-    filled_series = []
-    for ser in series:
-        if ser.is_valid():
-            filled_series.append(ser)
-        else:
-            filled_series.append(ser.fill_missing_dates())
-
-    start_date = kwargs.pop('start_date',
-                            min([x.start_date for x in filled_series
-                                     if x.start_date is not None]))
-    if isinstance(start_date, str):
-        start_date = Date(common_freq, string=start_date)
-    end_date = kwargs.pop('end_date',
-                          max([x.end_date for x in filled_series
-                                   if x.end_date is not None]))
-    if isinstance(end_date, str):
-        end_date = Date(common_freq, string=end_date)
-
-    return [adjust_endpoints(x, start_date, end_date) for x in filled_series]
-aligned = align_series
-
-
-
-def align_with(*series):
-    """
-    Aligns several TimeSeries to the first of the list, so that their
-    starting and ending dates match.
-
-    The series are resized and padded with masked values accordingly.
-    """
-    if len(series) < 2:
-        return series
-    dates = series[0]._dates[[0, -1]]
-    if len(series) == 2:
-        return adjust_endpoints(series[-1], dates[0], dates[-1])
-    return [adjust_endpoints(x, dates[0], dates[-1]) for x in series[1:]]
-
-
-#....................................................................
-def _convert1d(series, freq, func, position, *args, **kwargs):
-    "helper function for `convert` function"
-    # Check the frequencies ..........................
-    to_freq = check_freq(freq)
-    from_freq = series.freq
-    # Don't do anything if not needed
-    if from_freq == to_freq:
-        return series
-    if from_freq == _c.FR_UND:
-        err_msg = "Cannot convert a series with UNDEFINED frequency."
-        raise TimeSeriesError(err_msg)
-    if to_freq == _c.FR_UND:
-        err_msg = "Cannot convert a series to UNDEFINED frequency."
-        raise TimeSeriesError(err_msg)
-    # Check the validity of the series .....
-    if not series.is_valid():
-        err_msg = "Cannot adjust a series with missing or duplicated dates."
-        raise TimeSeriesError(err_msg)
-
-    # Check the position parameter..........
-    position = position.upper()
-    if position not in ('END', 'START'):
-        err_msg = "Invalid value for position argument: (%s). "\
-                  "Should be in ['END','START']," % str(position)
-        raise ValueError(err_msg)
-
-    start_date = series._dates[0]
-
-    if series.size == 0:
-        return TimeSeries(series, freq=to_freq,
-                          start_date=start_date.asfreq(to_freq))
-
-    data_ = series._series.filled()
-    mask_ = getmaskarray(series)
-
-    if (data_.size // series._dates.size) > 1:
-        raise TimeSeriesError("convert works with 1D data only !")
-
-    cdictresult = pandas._skts.TS_convert(data_, from_freq, to_freq, position,
-                                     int(start_date), mask_)
-    start_date = Date(freq=to_freq, value=cdictresult['startindex'])
-    data_ = masked_array(cdictresult['values'], mask=cdictresult['mask'])
-
-    if data_.ndim == 2:
-        if func is None:
-            newvarshape = data_.shape[1:]
-        else:
-            # Try to use an axis argument
-            try:
-                data_ = func(data_, axis= -1, *args, **kwargs)
-            # Fall back to apply_along_axis (slower)
-            except TypeError:
-                data_ = ma.apply_along_axis(func, -1, data_, *args, **kwargs)
-            newvarshape = ()
-    elif data_.ndim == 1:
-        newvarshape = ()
-
-    newdates = DateArray(np.arange(len(data_)) + start_date, freq=to_freq)
-
-    newseries = data_.view(type(series))
-    newseries._varshape = newvarshape
-    newseries._dates = newdates
-    newseries._update_from(series)
-    return newseries
-
-
-
-def convert(series, freq, func=None, position='END', *args, **kwargs):
-    """
-    Converts a series from one frequency to another, by manipulating both the
-    `data` and `dates` attributes.
-
-    If the input series has any missing dates, it will first be filled in with
-    masked values prior to doing the conversion.
-
-    Parameters
-    ----------
-    series : TimeSeries
-        Series to convert. Skip this parameter if you are calling this as
-        a method of the TimeSeries object instead of the module function.
-    freq : freq_spec
-        Frequency to convert the TimeSeries to. Accepts any valid frequency
-        specification (string or integer)
-    func : function, optional
-        When converting a series to a lower frequency, the :keyword:`func`
-        parameter to perform a calculation on each period of values
-        to aggregate results.
-        For example, when converting a daily series to a monthly series, use
-        :func:`numpy.ma.mean` to get a series of monthly averages.
-        If the first or last value from a period, the functions
-        :func:`~scikits.timeseries.first_unmasked_val` and
-        :func:`~scikits.timeseries.last_unmasked_val` should be used instead.
-        If :keyword:`func` is not given, the output series group the points
-        of the initial series that share the same new date. Thus, if the
-        initial series has a daily frequency and is 1D, the output series is
-        2D.
-    position : {'END', 'START'}, optional
-        When converting a series to a higher frequency, use this parameter to
-        determine where the points should fall in the new period.
-        For example, when converting a monthly series to daily, using
-        position='START' will cause the values to fall on the first day of
-        each month (with all other values being masked).
-    *args : {extra arguments for func parameter}, optional
-        Mandatory parameters of the :keyword:`func` function.
-    **kwargs : {extra keyword arguments for func parameter}, optional
-        Optional keyword parameters of the :keyword:`func` function.
-
-    Returns
-    -------
-    converted_series
-        A new :class:`TimeSeries` at the given frequency, without any missing
-        nor duplicated dates
-
-    """
-    #!!!: Raise some kind of proper exception if the underlying dtype will mess things up
-    #!!!: For example, mean on string array...
-
-    if series.ndim > 2 or series.ndim == 0:
-        raise ValueError(
-            "only series with ndim == 1 or ndim == 2 may be converted")
-
-    if series.has_duplicated_dates():
-        raise TimeSeriesError("The input series must not have duplicated dates!")
-
-    if series.has_missing_dates():
-        # can only convert continuous time series, so fill in missing dates
-        series = fill_missing_dates(series)
-
-    if series.ndim == 1:
-        obj = _convert1d(series, freq, func, position, *args, **kwargs)
-    elif series.ndim == 2:
-        base = _convert1d(series[:, 0], freq, func, position, *args, **kwargs)
-        obj = ma.column_stack([_convert1d(m, freq, func, position,
-                                          *args, **kwargs)._series
-                               for m in series.split()]).view(type(series))
-        obj._dates = base._dates
-        if func is None:
-            shp = obj.shape
-            ncols = base.shape[-1]
-            obj.shape = (shp[0], shp[-1] // ncols, ncols)
-            obj = np.swapaxes(obj, 1, 2)
-
-    return obj
-TimeSeries.convert = convert
-
-
-
-def tshift(series, nper, copy=True):
-    """
-    Returns a series of the same size as `series`, with the same `start_date`
-    and `end_date`, but values shifted by `nper`.
-
-    Parameters
-    ----------
-    series : TimeSeries
-        TimeSeries object to shift. Ignore this parameter if calling this as a
-        method.
-    nper : int
-        Number of periods to shift. Negative numbers shift values to the right,
-        positive to the left.
-    copy : {True, False}, optional
-        copies the data if True, returns a view if False.
-
-    Examples
-    --------
-    >>> series = time_series([0,1,2,3], start_date=Date(freq='A', year=2005))
-    >>> series
-    timeseries(data  = [0 1 2 3],
-               dates = [2005 ... 2008],
-               freq  = A-DEC)
-    >>> tshift(series, -1)
-    timeseries(data  = [-- 0 1 2],
-               dates = [2005 ... 2008],
-               freq  = A-DEC)
-    >>> pct_change = 100 * (series/series.tshift(-1, copy=False) - 1)
-
-    """
-    newdata = masked_array(np.empty(series.shape, dtype=series.dtype),
-                           mask=True)
-    if copy:
-        inidata = series._series.copy()
-    else:
-        inidata = series._series
-    if nper < 0:
-        nper = max(-len(series), nper)
-        newdata[-nper:] = inidata[:nper]
-    elif nper > 0:
-        nper = min(len(series), nper)
-        newdata[:-nper] = inidata[nper:]
-    else:
-        newdata = inidata
-    newseries = newdata.view(type(series))
-    newseries._dates = series._dates
-    newseries._update_from(series)
-    return newseries
-TimeSeries.tshift = tshift
-
-#...............................................................................
-def _get_type_num_double(dtype):
-    """
-    Private used to force dtypes upcasting in certain functions
-    (eg. int -> float in pct function).
-    Adapted from function of the same name in the C source code.
-    """
-    if dtype.num < np.dtype('f').num:
-        return np.dtype('d')
-    return dtype
-
-def _pct_generic(series, nper, pct_func):
-    "helper function for the pct_* functions"
-    _dtype = _get_type_num_double(series.dtype)
-    if _dtype != series.dtype:
-        series = series.astype(_dtype)
-    newdata = masked_array(np.empty(series.shape, dtype=series.dtype),
-                           mask=True)
-    if nper < newdata.size:
-        mseries = series.view(MaskedArray)
-        newdata[nper:] = pct_func(mseries, nper)
-    newseries = newdata.view(type(series))
-    newseries._dates = series._dates
-    newseries._update_from(series)
-    return newseries
-
-def pct(series, nper=1):
-    """
-    Returns the rolling percentage change of the series.
-
-    Parameters
-    ----------
-    series : {TimeSeries}
-        TimeSeries object to to calculate percentage chage for. Ignore this
-        parameter if calling this as a method.
-    nper : {int}
-        Number of periods for percentage change.
-
-    Notes
-    -----
-    Series of integer types will be upcast
-    1.0 == 100% in result
-
-    Examples
-    --------
-    >>> series = ts.time_series(
-    ...     [2.,1.,2.,3.], start_date=ts.Date(freq='A', year=2005))
-    >>> series.pct()
-    timeseries([-- -0.5 1.0 0.5],
-               dates = [2005 ... 2008],
-               freq  = A-DEC)
-    >>> series.pct(2)
-    timeseries([-- -- 0.0 2.0],
-               dates = [2005 ... 2008],
-               freq  = A-DEC)
-
-    """
-    def pct_func(series, nper):
-        return series[nper:] / series[:-nper] - 1
-    return _pct_generic(series, nper, pct_func)
-TimeSeries.pct = pct
-
-def pct_log(series, nper=1):
-    """
-    Returns the rolling log percentage change of the series. This is defined as
-    the log of the ratio of series[T]/series[T-nper]
-
-    Parameters
-    ----------
-    series : {TimeSeries}
-        TimeSeries object to to calculate log percentage chage for. Ignore this
-        parameter if calling this as a method.
-    nper : {int}
-        Number of periods for percentage change.
-
-    Notes
-    -----
-    Series of integer types will be upcast
-    1.0 == 100% in result
-
-    Examples
-    --------
-    >>> series = ts.time_series(
-    ...     [2.,1.,2.,3.], start_date=ts.Date(freq='A', year=2005))
-    >>> series.pct_log()
-    timeseries([-- -0.69314718056 0.69314718056 0.405465108108],
-               dates = [2005 ... 2008],
-               freq  = A-DEC)
-    >>> series.pct_log(2)
-    timeseries([-- -- 0.0 1.09861228867],
-               dates = [2005 ... 2008],
-               freq  = A-DEC)
-
-    """
-    def pct_func(series, nper):
-        return ma.log(series[nper:] / series[:-nper])
-    return _pct_generic(series, nper, pct_func)
-TimeSeries.pct_log = pct_log
-
-def pct_symmetric(series, nper=1):
-    """
-    Returns the rolling symmetric percentage change of the series. This is
-    defined as 2*(series[T] - series[T-nper])/(series[T] - series[T-nper])
-
-    Parameters
-    ----------
-    series : {TimeSeries}
-        TimeSeries object to to calculate symmetric percentage chage for. Ignore
-        this parameter if calling this as a method.
-    nper : {int}
-        Number of periods for percentage change.
-
-    Notes
-    -----
-    Series of integer types will be upcast
-    1.0 == 100% in result
-
-    Examples
-    --------
-    >>> series = ts.time_series(
-    ...     [2.,1.,2.,3.], start_date=ts.Date(freq='A', year=2005))
-    >>> series.pct_symmetric()
-    timeseries([-- -0.666666666667 0.666666666667 0.4],
-               dates = [2005 ... 2008],
-               freq  = A-DEC)
-    >>> series.pct_symmetric(2)
-    timeseries([-- -- 0.0 1.0],
-               dates = [2005 ... 2008],
-               freq  = A-DEC)
-
-    """
-    def pct_func(series, nper):
-        return \
-            2 * (series[nper:] - series[:-nper]) / \
-                (series[nper:] + series[:-nper])
-    return _pct_generic(series, nper, pct_func)
-TimeSeries.pct_symmetric = pct_symmetric
-
-
-
-def fill_missing_dates(data, dates=None, freq=None, fill_value=None):
-    """
-    Finds and fills the missing dates in a time series. The data
-    corresponding to the initially missing dates are masked, or filled to
-    `fill_value`.
-
-    Parameters
-    ----------
-    data : {TimeSeries, ndarray}
-        Initial array of data.
-    dates : {DateArray} (optional)
-        Initial array of dates. Specify this if you are passing a plain ndarray
-        for the data instead of a :class:`TimeSeries`.
-    freq : {freq_spec} (optional)
-        Frequency of result. If not specified, the initial frequency is used.
-    fill_value : {scalar of type data.dtype} (optional)
-        Default value for missing data. If Not specified, the data are just
-        masked.
-
-    """
-    # Check the frequency ........
-    orig_freq = freq
-    freq = check_freq(freq)
-    if orig_freq is not None and freq == _c.FR_UND:
-        freqstr = check_freq_str(freq)
-        raise ValueError, \
-              "Unable to define a proper date resolution (found %s)." % freqstr
-    # Check the dates .............
-    if dates is None:
-        if not isinstance(data, TimeSeries):
-            raise InsufficientDateError
-        dates = data._dates
-    else:
-        if not isinstance(dates, DateArray):
-            dates = DateArray(dates, freq)
-    dflat = dates.asfreq(freq).ravel()
-    if not dflat.has_missing_dates():
-        if isinstance(data, TimeSeries):
-            return data
-        data = data.view(TimeSeries)
-        data._dates = dflat
-        return data
-    # Check the data ..............
-    if isinstance(data, MaskedArray):
-        datad = data._data
-        datam = data._mask
-        if isinstance(data, TimeSeries):
-            datat = type(data)
-            datas = data._varshape
-        else:
-            datat = TimeSeries
-            datas = ()
-    else:
-        datad = np.asarray(data)
-        datam = nomask
-        datat = TimeSeries
-    # Check whether we need to flatten the data
-    if data.ndim > 1:
-        if (not datas):
-            datad.shape = -1
-        elif dflat.size != len(datad):
-            err_msg = "fill_missing_dates is not yet implemented for nD series!"
-            raise NotImplementedError(err_msg)
-    # ...and now, fill it ! ......
-    (tstart, tend) = dflat[[0, -1]]
-    newdates = date_array(start_date=tstart, end_date=tend)
-    (osize, nsize) = (dflat.size, newdates.size)
-    #.............................
-    # Get the steps between consecutive data.
-    delta = dflat.get_steps() - 1
-    gap = delta.nonzero()
-    slcid = np.concatenate(([0, ], np.arange(1, osize)[gap], [osize, ]))
-    oldslc = np.array([slice(i, e)
-                       for (i, e) in np.broadcast(slcid[:-1], slcid[1:])])
-    addidx = delta[gap].astype(int).cumsum()
-    newslc = np.concatenate(([oldslc[0]],
-                             [slice(i + d, e + d) for (i, e, d) in \
-                              np.broadcast(slcid[1:-1], slcid[2:], addidx)]
-                             ))
-    #.............................
-    # Just a quick check
-    vdflat = np.asarray(dflat)
-    vnewdates = np.asarray(newdates)
-    for (osl, nsl) in zip(oldslc, newslc):
-        assert np.equal(vdflat[osl], vnewdates[nsl]).all(), \
-            "Slicing mishap ! Please check %s (old) and %s (new)" % (osl, nsl)
-    #.............................
-    newshape = list(datad.shape)
-    newshape[0] = nsize
-    newdatad = np.empty(newshape, dtype=data.dtype)
-    newdatam = np.ones(newshape, dtype=ma.make_mask_descr(datad.dtype))
-    #....
-    if datam is nomask:
-        for (new, old) in zip(newslc, oldslc):
-            newdatad[new] = datad[old]
-            newdatam[new] = False
-    else:
-        for (new, old) in zip(newslc, oldslc):
-            newdatad[new] = datad[old]
-            newdatam[new] = datam[old]
-    if fill_value is None:
-        fill_value = getattr(data, '_fill_value', None)
-    newdata = ma.masked_array(newdatad, mask=newdatam, fill_value=fill_value)
-    _data = newdata.view(datat)
-    _data._dates = newdates
-    return _data
-TimeSeries.fill_missing_dates = fill_missing_dates
-
-
-
-def find_duplicated_dates(series):
-    """
-    Return a dictionary (duplicated dates <> indices) for the input series.
-
-    The indices are given as a tuple of ndarrays, a la :meth:`nonzero`.
-
-    Parameters
-    ----------
-    series : TimeSeries, DateArray
-        A valid :class:`TimeSeries` or :class:`DateArray` object.
-
-    Examples
-    --------
-    >>> series = time_series(np.arange(10),
-                            dates=[2000, 2001, 2002, 2003, 2003,
-                                   2003, 2004, 2005, 2005, 2006], freq='A')
-    >>> test = find_duplicated_dates(series)
-     {<A-DEC : 2003>: (array([3, 4, 5]),), <A-DEC : 2005>: (array([7, 8]),)}
-    """
-    dates = getattr(series, '_dates', series)
-    steps = dates.get_steps()
-    duplicated_dates = tuple(set(dates[steps == 0]))
-    indices = {}
-    for d in duplicated_dates:
-        indices[d] = (dates == d).nonzero()
-    return indices
-
-
-
-def remove_duplicated_dates(series):
-    """
-    Remove the entries of `series` corresponding to duplicated dates.
-
-    The series is first sorted in chronological order.
-    Only the first occurence of a date is then kept, the others are discarded.
-
-    Parameters
-    ----------
-    series : TimeSeries
-        Time series to process
-    """
-    dates = getattr(series, '_dates', series)
-    steps = np.concatenate(([1, ], dates.get_steps()))
-    if not dates.is_chronological():
-        series = series.copy()
-        series.sort_chronologically()
-        dates = series._dates
-    return series[steps.nonzero()]
-
-
-
-
-def stack(*series):
-    """
-    Performs a column_stack on the data from each series, and the
-    resulting series has the same dates as each individual series. The series
-    must have compatible dates (same starting and ending dates, same frequency).
-
-    Parameters
-    ----------
-    series : the series to be stacked
-    """
-    _timeseriescompat_multiple(*series)
-    return time_series(ma.column_stack(series), series[0]._dates,
-                       **_attrib_dict(series[0]))
-
-
-
-def concatenate(series, axis=0, remove_duplicates=True, fill_missing=False):
-    """
-    Joins series together.
-
-    The series are joined in chronological order.
-    Duplicated dates are handled with the `remove_duplicates` parameter.
-    If `remove_duplicate` is False, duplicated dates are saved.
-    Otherwise, only the first occurence of the date is conserved.
-
-
-    Parameters
-    ----------
-    series : {sequence}
-        Sequence of time series to join
-    axis : {0, None, int}, optional
-        Axis along which to join
-    remove_duplicates : {False, True}, optional
-        Whether to remove duplicated dates.
-    fill_missing : {False, True}, optional
-        Whether to fill the missing dates with missing values.
-
-    Examples
-    --------
-    >>> a = time_series([1,2,3], start_date=now('D'))
-    >>> b = time_series([10,20,30], start_date=now('D')+1)
-    >>> c = concatenate((a,b))
-    >>> c._series
-    masked_array(data = [ 1  2  3 30],
-          mask = False,
-          fill_value=999999)
-
-    """
-    # Get the common frequency, raise an error if incompatibility
-    common_f = _compare_frequencies(*series)
-    # Concatenate the order of series
-    sidx = np.concatenate([np.repeat(i, len(s))
-                           for (i, s) in enumerate(series)], axis=axis)
-    # Concatenate the dates and data
-    ndates = np.concatenate([s._dates for s in series], axis=axis)
-    ndata = ma.concatenate([s._series for s in series], axis=axis)
-    # Resort the data chronologically
-    norder = ndates.argsort(kind='mergesort')
-    ndates = ndates[norder]
-    ndata = ndata[norder]
-    sidx = sidx[norder]
-    #
-    if not remove_duplicates:
-        ndates = date_array(ndates, freq=common_f)
-        result = time_series(ndata, dates=ndates)
-    else:
-        # Find the original dates
-        orig = np.concatenate([[True], (np.diff(ndates) != 0)])
-        result = time_series(ndata.compress(orig, axis=axis),
-                             dates=ndates.compress(orig, axis=axis),
-                             freq=common_f)
-    if fill_missing:
-        result = fill_missing_dates(result)
-    return result
-
-
-
-def empty_like(series):
-    """
-    Returns an empty series with the same dtype, mask and dates as series.
-    """
-    result = np.empty_like(series).view(type(series))
-    result._dates = series._dates
-    result._mask = series._mask.copy()
-    return result
-
-################################################################################
diff --git a/setup.py b/setup.py
index 40c1d78fa..46a40b6fa 100755
--- a/setup.py
+++ b/setup.py
@@ -369,21 +369,12 @@ sandbox_ext = Extension('pandas._sandbox',
                         sources=[srcpath('sandbox', suffix=suffix)],
                         include_dirs=[np.get_include()])
 
-skts_ext = Extension('pandas._skts',
-                     sources= [os.path.join('pandas/src/timeseries', x)
-                               for x in ('c_lib.c',
-                                         'c_dates.c',
-                                         'c_tseries.c',
-                                         'cseries.c')],
-                      include_dirs=[np.get_include(),
-                                    'pandas/src/timeseries'])
-
 cppsandbox_ext = Extension('pandas._cppsandbox',
                            language='c++',
                            sources=[srcpath('cppsandbox', suffix=suffix)],
                            include_dirs=[np.get_include()])
 
-extensions = [tseries_ext, engines_ext, sparse_ext, skts_ext]
+extensions = [tseries_ext, engines_ext, sparse_ext]
 
 if not ISRELEASED:
     extensions.extend([sandbox_ext])
