<html>
<head>
<meta charset="utf-8">
<title>/home/xxm/Desktop/EMSE/dataset/models/official/nlp/bert/tokenization.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE'>SPIECE_UNDERLINE</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint'>validate_case_matches_checkpoint</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode'>convert_to_unicode</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text'>printable_text</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab'>load_vocab</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab'>convert_by_vocab</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids'>convert_tokens_to_ids</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens'>convert_ids_to_tokens</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize'>whitespace_tokenize</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer'>FullTokenizer</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize'>tokenize</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids'>convert_tokens_to_ids</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens'>convert_ids_to_tokens</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer'>BasicTokenizer</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize'>tokenize</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents'>_run_strip_accents</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc'>_run_split_on_punc</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars'>_tokenize_chinese_chars</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char'>_is_chinese_char</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text'>_clean_text</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer'>WordpieceTokenizer</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize'>tokenize</a></li></ul>
</li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace'>_is_whitespace</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control'>_is_control</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation'>_is_punctuation</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text'>preprocess_text</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces'>encode_pieces</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids'>encode_ids</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer'>FullSentencePieceTokenizer</a><ul>
<li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__'>__init__</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize'>tokenize</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids'>convert_tokens_to_ids</a></li><li><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens', xid='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens'>convert_ids_to_tokens</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> # coding=utf-8
<span class='lineno'>   2</span> # Copyright 2019 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   3</span> #
<span class='lineno'>   4</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   5</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   6</span> # You may obtain a copy of the License at
<span class='lineno'>   7</span> #
<span class='lineno'>   8</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   9</span> #
<span class='lineno'>  10</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  11</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  12</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  13</span> # See the License for the specific language governing permissions and
<span class='lineno'>  14</span> # limitations under the License.
<span class='lineno'>  15</span> # ==============================================================================
<span class='lineno'>  16</span> &quot;&quot;&quot;Tokenization classes implementation.
<span class='lineno'>  17</span> 
<span class='lineno'>  18</span> The file is forked from:
<span class='lineno'>  19</span> https://github.com/google-research/bert/blob/master/tokenization.py.
<span class='lineno'>  20</span> &quot;&quot;&quot;
<span class='lineno'>  21</span> 
<span class='lineno'>  22</span> from __future__ import absolute_import
<span class='lineno'>  23</span> from __future__ import division
<span class='lineno'>  24</span> from __future__ import print_function
<span class='lineno'>  25</span> 
<span class='lineno'>  26</span> import collections
<span class='lineno'>  27</span> import re
<span class='lineno'>  28</span> import unicodedata
<span class='lineno'>  29</span> 
<span class='lineno'>  30</span> import six
<span class='lineno'>  31</span> import tensorflow as tf
<span class='lineno'>  32</span> 
<span class='lineno'>  33</span> import sentencepiece as spm
<span class='lineno'>  34</span> 
<span class='lineno'>  35</span> <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE', title='str'>SPIECE_UNDERLINE</a> = &quot;‚ñÅ&quot;
<span class='lineno'>  36</span> 
<span class='lineno'>  37</span> 
<span class='lineno'>  38</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint', title='(?, ?) -> None'>validate_case_matches_checkpoint</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.do_lower_case', title='?'>do_lower_case</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.init_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.init_checkpoint', title='?'>init_checkpoint</a>):
<span class='lineno'>  39</span>   &quot;&quot;&quot;Checks whether the casing config is consistent with the checkpoint name.&quot;&quot;&quot;
<span class='lineno'>  40</span> 
<span class='lineno'>  41</span>   # The casing has to be passed in by the user and there is no explicit check
<span class='lineno'>  42</span>   # as to whether it matches the checkpoint. The casing information probably
<span class='lineno'>  43</span>   # should have been stored in the bert_config.json file, but it&#39;s not, so
<span class='lineno'>  44</span>   # we have to heuristically detect it to validate.
<span class='lineno'>  45</span> 
<span class='lineno'>  46</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.init_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.init_checkpoint', title='?'>init_checkpoint</a>:
<span class='lineno'>  47</span>     return
<span class='lineno'>  48</span> 
<span class='lineno'>  49</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.m', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.m', title='?'>m</a> = re.match(&quot;^.*?([A-Za-z0-9_-]+)/bert_model.ckpt&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.init_checkpoint', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.init_checkpoint', title='?'>init_checkpoint</a>)
<span class='lineno'>  50</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.m', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.m', title='?'>m</a> is None:
<span class='lineno'>  51</span>     return
<span class='lineno'>  52</span> 
<span class='lineno'>  53</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.model_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.model_name', title='?'>model_name</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.m', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.m', title='?'>m</a>.group(1)
<span class='lineno'>  54</span> 
<span class='lineno'>  55</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.lower_models', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.lower_models', title='[str]'>lower_models</a> = [
<span class='lineno'>  56</span>       &quot;uncased_L-24_H-1024_A-16&quot;, &quot;uncased_L-12_H-768_A-12&quot;,
<span class='lineno'>  57</span>       &quot;multilingual_L-12_H-768_A-12&quot;, &quot;chinese_L-12_H-768_A-12&quot;
<span class='lineno'>  58</span>   ]
<span class='lineno'>  59</span> 
<span class='lineno'>  60</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.cased_models', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.cased_models', title='[str]'>cased_models</a> = [
<span class='lineno'>  61</span>       &quot;cased_L-12_H-768_A-12&quot;, &quot;cased_L-24_H-1024_A-16&quot;,
<span class='lineno'>  62</span>       &quot;multi_cased_L-12_H-768_A-12&quot;
<span class='lineno'>  63</span>   ]
<span class='lineno'>  64</span> 
<span class='lineno'>  65</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.is_bad_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.is_bad_config', title='bool'>is_bad_config</a> = False
<span class='lineno'>  66</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.model_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.model_name', title='?'>model_name</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.lower_models', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.lower_models', title='[str]'>lower_models</a> and not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.do_lower_case', title='?'>do_lower_case</a>:
<span class='lineno'>  67</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.is_bad_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.is_bad_config', title='bool'>is_bad_config</a> = True
<span class='lineno'>  68</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.actual_flag', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.actual_flag', title='str'>actual_flag</a> = &quot;False&quot;
<span class='lineno'>  69</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.case_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.case_name', title='str'>case_name</a> = &quot;lowercased&quot;
<span class='lineno'>  70</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.opposite_flag', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.opposite_flag', title='str'>opposite_flag</a> = &quot;True&quot;
<span class='lineno'>  71</span> 
<span class='lineno'>  72</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.model_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.model_name', title='?'>model_name</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.cased_models', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.cased_models', title='[str]'>cased_models</a> and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.do_lower_case', title='?'>do_lower_case</a>:
<span class='lineno'>  73</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.is_bad_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.is_bad_config', title='bool'>is_bad_config</a> = True
<span class='lineno'>  74</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.actual_flag', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.actual_flag', title='str'>actual_flag</a> = &quot;True&quot;
<span class='lineno'>  75</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.case_name', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.case_name', title='str'>case_name</a> = &quot;cased&quot;
<span class='lineno'>  76</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.opposite_flag', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.opposite_flag', title='str'>opposite_flag</a> = &quot;False&quot;
<span class='lineno'>  77</span> 
<span class='lineno'>  78</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.is_bad_config', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.validate_case_matches_checkpoint.is_bad_config', title='bool'>is_bad_config</a>:
<span class='lineno'>  79</span>     raise ValueError(
<span class='lineno'>  80</span>         &quot;You passed in `--do_lower_case=%s` with `--init_checkpoint=%s`. &quot;
<span class='lineno'>  81</span>         &quot;However, `%s` seems to be a %s model, so you &quot;
<span class='lineno'>  82</span>         &quot;should pass in `--do_lower_case=%s` so that the fine-tuning matches &quot;
<span class='lineno'>  83</span>         &quot;how the model was pre-training. If this error is wrong, please &quot;
<span class='lineno'>  84</span>         &quot;just comment out this check.&quot; %
<span class='lineno'>  85</span>         (actual_flag, init_checkpoint, model_name, case_name, opposite_flag))
<span class='lineno'>  86</span> 
<span class='lineno'>  87</span> 
<span class='lineno'>  88</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode', title='? -> {? -> ? | str}'>convert_to_unicode</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='?'>text</a>):
<span class='lineno'>  89</span>   &quot;&quot;&quot;Converts `text` to Unicode (if it&#39;s not already), assuming utf-8 input.&quot;&quot;&quot;
<span class='lineno'>  90</span>   if six.PY3:
<span class='lineno'>  91</span>     if isinstance(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='str'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='?'>text</a></a>, str):
<span class='lineno'>  92</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='str'>text</a>
<span class='lineno'>  93</span>     elif isinstance(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='?'>text</a></a>, bytes):
<span class='lineno'>  94</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='?'>text</a>.decode(&quot;utf-8&quot;, &quot;ignore&quot;)
<span class='lineno'>  95</span>     else:
<span class='lineno'>  96</span>       raise ValueError(&quot;Unsupported string type: %s&quot; % (type(text)))
<span class='lineno'>  97</span>   elif six.PY2:
<span class='lineno'>  98</span>     if isinstance(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='str'>text</a></a>, str):
<span class='lineno'>  99</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='str'>text</a>.decode(&quot;utf-8&quot;, &quot;ignore&quot;)
<span class='lineno'> 100</span>     elif isinstance(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='? -> ?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='?'>text</a></a>, unicode):
<span class='lineno'> 101</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode.text', title='? -> ?'>text</a>
<span class='lineno'> 102</span>     else:
<span class='lineno'> 103</span>       raise ValueError(&quot;Unsupported string type: %s&quot; % (type(text)))
<span class='lineno'> 104</span>   else:
<span class='lineno'> 105</span>     raise ValueError(&quot;Not running on Python2 or Python 3?&quot;)
<span class='lineno'> 106</span> 
<span class='lineno'> 107</span> 
<span class='lineno'> 108</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text', title='str -> str / ? -> str'>printable_text</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='str'>text</a>):
<span class='lineno'> 109</span>   &quot;&quot;&quot;Returns text encoded in a way suitable for print or `tf.logging`.&quot;&quot;&quot;
<span class='lineno'> 110</span> 
<span class='lineno'> 111</span>   # These functions want `str` for both Python2 and Python3, but in one case
<span class='lineno'> 112</span>   # it&#39;s a Unicode string and in the other it&#39;s a byte string.
<span class='lineno'> 113</span>   if six.PY3:
<span class='lineno'> 114</span>     if isinstance(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='str'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='str'>text</a></a>, str):
<span class='lineno'> 115</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='str'>text</a>
<span class='lineno'> 116</span>     elif isinstance(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='str'>text</a></a>, bytes):
<span class='lineno'> 117</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='?'>text</a>.decode(&quot;utf-8&quot;, &quot;ignore&quot;)
<span class='lineno'> 118</span>     else:
<span class='lineno'> 119</span>       raise ValueError(&quot;Unsupported string type: %s&quot; % (type(text)))
<span class='lineno'> 120</span>   elif six.PY2:
<span class='lineno'> 121</span>     if isinstance(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='str'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='str'>text</a></a>, str):
<span class='lineno'> 122</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='str'>text</a>
<span class='lineno'> 123</span>     elif isinstance(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='? -> ?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='str'>text</a></a>, unicode):
<span class='lineno'> 124</span>       return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text.text', title='? -> ?'>text</a>.encode(&quot;utf-8&quot;)
<span class='lineno'> 125</span>     else:
<span class='lineno'> 126</span>       raise ValueError(&quot;Unsupported string type: %s&quot; % (type(text)))
<span class='lineno'> 127</span>   else:
<span class='lineno'> 128</span>     raise ValueError(&quot;Not running on Python2 or Python 3?&quot;)
<span class='lineno'> 129</span> 
<span class='lineno'> 130</span> 
<span class='lineno'> 131</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab', title='? -> None'>load_vocab</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab_file', title='?'>vocab_file</a>):
<span class='lineno'> 132</span>   &quot;&quot;&quot;Loads a vocabulary file into a dictionary.&quot;&quot;&quot;
<span class='lineno'> 133</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab', title='?'>vocab</a> = collections.OrderedDict()
<span class='lineno'> 134</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.index', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.index', title='int'>index</a> = 0
<span class='lineno'> 135</span>   with tf.io.gfile.GFile(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab_file', title='?'>vocab_file</a>, &quot;r&quot;) as <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.reader', title='?'>reader</a>:
<span class='lineno'> 136</span>     while True:
<span class='lineno'> 137</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', title='{? -> ? | str}'>token</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode', title='? -> {? -> ? | str}'>convert_to_unicode</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.reader', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.reader', title='?'>reader</a>.readline())
<span class='lineno'> 138</span>       if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', title='{? -> ? | str}'>token</a>:
<span class='lineno'> 139</span>         break
<span class='lineno'> 140</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', title='?'>token</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', title='{? -> ? | str}'>token</a>.strip()
<span class='lineno'> 141</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab', title='?'>vocab</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.token', title='?'>token</a>] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.index', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.index', title='int'>index</a>
<span class='lineno'> 142</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.index', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.index', title='int'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.index', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.index', title='int'>index</a></a> += 1
<span class='lineno'> 143</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab.vocab', title='?'>vocab</a>
<span class='lineno'> 144</span> 
<span class='lineno'> 145</span> 
<span class='lineno'> 146</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', title='(?, ?) -> [?] / (None, ?) -> [?] / (dict, ?) -> [?]'>convert_by_vocab</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.vocab', title='{None | dict}'>vocab</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.items', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.items', title='?'>items</a>):
<span class='lineno'> 147</span>   &quot;&quot;&quot;Converts a sequence of [tokens|ids] using the vocab.&quot;&quot;&quot;
<span class='lineno'> 148</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.output', title='[?]'>output</a> = []
<span class='lineno'> 149</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.item', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.item', title='?'>item</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.items', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.items', title='?'>items</a>:
<span class='lineno'> 150</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.output', title='[?]'>output</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.vocab', title='{None | dict}'>vocab</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.item', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.item', title='?'>item</a>])
<span class='lineno'> 151</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab.output', title='[?]'>output</a>
<span class='lineno'> 152</span> 
<span class='lineno'> 153</span> 
<span class='lineno'> 154</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids', title='(?, ?) -> [?]'>convert_tokens_to_ids</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids.vocab', title='?'>vocab</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids.tokens', title='?'>tokens</a>):
<span class='lineno'> 155</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', title='(?, ?) -> [?] / (None, ?) -> [?] / (dict, ?) -> [?]'>convert_by_vocab</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids.vocab', title='?'>vocab</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_tokens_to_ids.tokens', title='?'>tokens</a>)
<span class='lineno'> 156</span> 
<span class='lineno'> 157</span> 
<span class='lineno'> 158</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens', title='(?, ?) -> [?]'>convert_ids_to_tokens</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens.inv_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens.inv_vocab', title='?'>inv_vocab</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens.ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens.ids', title='?'>ids</a>):
<span class='lineno'> 159</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', title='(?, ?) -> [?] / (None, ?) -> [?] / (dict, ?) -> [?]'>convert_by_vocab</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens.inv_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens.inv_vocab', title='?'>inv_vocab</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens.ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_ids_to_tokens.ids', title='?'>ids</a>)
<span class='lineno'> 160</span> 
<span class='lineno'> 161</span> 
<span class='lineno'> 162</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize', title='? -> [?] / str -> {[?] | [str]} / {? -> ? | str} -> [?]'>whitespace_tokenize</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', title='{? -> ? | str}'>text</a>):
<span class='lineno'> 163</span>   &quot;&quot;&quot;Runs basic whitespace cleaning and splitting on a piece of text.&quot;&quot;&quot;
<span class='lineno'> 164</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', title='str'>text</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', title='{? -> ? | str}'>text</a>.strip()
<span class='lineno'> 165</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', title='str'>text</a>:
<span class='lineno'> 166</span>     return []
<span class='lineno'> 167</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.tokens', title='[str]'>tokens</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.text', title='str'>text</a>.split()
<span class='lineno'> 168</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize.tokens', title='[str]'>tokens</a>
<span class='lineno'> 169</span> 
<span class='lineno'> 170</span> 
<span class='lineno'> 171</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer', title='<FullTokenizer>'>FullTokenizer</a>(object):
<span class='lineno'> 172</span>   &quot;&quot;&quot;Runs end-to-end tokenziation.&quot;&quot;&quot;
<span class='lineno'> 173</span> 
<span class='lineno'> 174</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', title='FullTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.vocab_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.vocab_file', title='?'>vocab_file</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.do_lower_case', title='bool'>do_lower_case</a>=True, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.split_on_punc', title='bool'>split_on_punc</a>=True):
<span class='lineno'> 175</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', title='FullTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', title='None'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', title='None'>vocab</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.load_vocab', title='? -> None'>load_vocab</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.vocab_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.vocab_file', title='?'>vocab_file</a>)
<span class='lineno'> 176</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', title='FullTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.inv_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.inv_vocab', title='dict'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.inv_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.inv_vocab', title='dict'>inv_vocab</a></a> = {<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.v', title='?'>v</a>: <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.k', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.k', title='?'>k</a> for <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.k', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.k', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.k', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.k', title='?'>k</a></a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.v', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.v', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.v', title='?'>v</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', title='FullTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', title='None'>vocab</a>.items()}
<span class='lineno'> 177</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', title='FullTokenizer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.basic_tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.basic_tokenizer', title='BasicTokenizer'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.basic_tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.basic_tokenizer', title='BasicTokenizer'>basic_tokenizer</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer', title='<BasicTokenizer>'>BasicTokenizer</a>(
<span class='lineno'> 178</span>         do_lower_case=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.do_lower_case', title='bool'>do_lower_case</a>, split_on_punc=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.split_on_punc', title='bool'>split_on_punc</a>)
<span class='lineno'> 179</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', title='FullTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.wordpiece_tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.wordpiece_tokenizer', title='WordpieceTokenizer'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.wordpiece_tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.wordpiece_tokenizer', title='WordpieceTokenizer'>wordpiece_tokenizer</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer', title='<WordpieceTokenizer>'>WordpieceTokenizer</a>(vocab=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.__init__.self', title='FullTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', title='None'>vocab</a>)
<span class='lineno'> 180</span> 
<span class='lineno'> 181</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize', title='(FullTokenizer, ?) -> [str]'>tokenize</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.self', title='FullTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.text', title='?'>text</a>):
<span class='lineno'> 182</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.split_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.split_tokens', title='[str]'>split_tokens</a> = []
<span class='lineno'> 183</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.token', title='?'>token</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.self', title='FullTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.basic_tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.basic_tokenizer', title='BasicTokenizer'>basic_tokenizer</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize', title='(BasicTokenizer, ?) -> {[?] | [str]}'>tokenize</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.text', title='?'>text</a>):
<span class='lineno'> 184</span>       for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.sub_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.sub_token', title='str'>sub_token</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.self', title='FullTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.wordpiece_tokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.wordpiece_tokenizer', title='WordpieceTokenizer'>wordpiece_tokenizer</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize', title='(WordpieceTokenizer, ?) -> [str]'>tokenize</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.token', title='?'>token</a>):
<span class='lineno'> 185</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.split_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.split_tokens', title='[str]'>split_tokens</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.sub_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.sub_token', title='str'>sub_token</a>)
<span class='lineno'> 186</span> 
<span class='lineno'> 187</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.split_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.tokenize.split_tokens', title='[str]'>split_tokens</a>
<span class='lineno'> 188</span> 
<span class='lineno'> 189</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids', title='(FullTokenizer, ?) -> [?]'>convert_tokens_to_ids</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids.self', title='FullTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids.tokens', title='?'>tokens</a>):
<span class='lineno'> 190</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', title='(?, ?) -> [?] / (None, ?) -> [?] / (dict, ?) -> [?]'>convert_by_vocab</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids.self', title='FullTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.vocab', title='None'>vocab</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_tokens_to_ids.tokens', title='?'>tokens</a>)
<span class='lineno'> 191</span> 
<span class='lineno'> 192</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens', title='(FullTokenizer, ?) -> [?]'>convert_ids_to_tokens</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens.self', title='FullTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens.ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens.ids', title='?'>ids</a>):
<span class='lineno'> 193</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_by_vocab', title='(?, ?) -> [?] / (None, ?) -> [?] / (dict, ?) -> [?]'>convert_by_vocab</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens.self', title='FullTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.inv_vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.inv_vocab', title='dict'>inv_vocab</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens.ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullTokenizer.convert_ids_to_tokens.ids', title='?'>ids</a>)
<span class='lineno'> 194</span> 
<span class='lineno'> 195</span> 
<span class='lineno'> 196</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer', title='<BasicTokenizer>'>BasicTokenizer</a>(object):
<span class='lineno'> 197</span>   &quot;&quot;&quot;Runs basic tokenization (punctuation splitting, lower casing, etc.).&quot;&quot;&quot;
<span class='lineno'> 198</span> 
<span class='lineno'> 199</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.self', title='BasicTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.do_lower_case', title='bool'>do_lower_case</a>=True, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.split_on_punc', title='bool'>split_on_punc</a>=True):
<span class='lineno'> 200</span>     &quot;&quot;&quot;Constructs a BasicTokenizer.
<span class='lineno'> 201</span> 
<span class='lineno'> 202</span>     Args:
<span class='lineno'> 203</span>       do_lower_case: Whether to lower case the input.
<span class='lineno'> 204</span>       split_on_punc: Whether to apply split on punctuations. By default BERT
<span class='lineno'> 205</span>         starts a new token for punctuations. This makes detokenization difficult
<span class='lineno'> 206</span>         for tasks like seq2seq decoding.
<span class='lineno'> 207</span>     &quot;&quot;&quot;
<span class='lineno'> 208</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.self', title='BasicTokenizer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.do_lower_case', title='bool'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.do_lower_case', title='bool'>do_lower_case</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.do_lower_case', title='bool'>do_lower_case</a>
<span class='lineno'> 209</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.self', title='BasicTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.split_on_punc', title='bool'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.split_on_punc', title='bool'>split_on_punc</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.__init__.split_on_punc', title='bool'>split_on_punc</a>
<span class='lineno'> 210</span> 
<span class='lineno'> 211</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize', title='(BasicTokenizer, ?) -> {[?] | [str]}'>tokenize</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', title='BasicTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', title='?'>text</a>):
<span class='lineno'> 212</span>     &quot;&quot;&quot;Tokenizes a piece of text.&quot;&quot;&quot;
<span class='lineno'> 213</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', title='{? -> ? | str}'>text</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode', title='? -> {? -> ? | str}'>convert_to_unicode</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', title='?'>text</a>)
<span class='lineno'> 214</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', title='str'>text</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', title='BasicTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text', title='(BasicTokenizer, ?) -> str / (BasicTokenizer, {? -> ? | str}) -> str'>_clean_text</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', title='{? -> ? | str}'>text</a>)
<span class='lineno'> 215</span> 
<span class='lineno'> 216</span>     # This was added on November 1st, 2018 for the multilingual and Chinese
<span class='lineno'> 217</span>     # models. This is also applied to the English models now, but it doesn&#39;t
<span class='lineno'> 218</span>     # matter since the English models were not trained on any Chinese data
<span class='lineno'> 219</span>     # and generally don&#39;t have any Chinese data in them (there are Chinese
<span class='lineno'> 220</span>     # characters in the vocabulary because Wikipedia does have some Chinese
<span class='lineno'> 221</span>     # words in the English Wikipedia.).
<span class='lineno'> 222</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', title='str'>text</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', title='BasicTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars', title='(BasicTokenizer, ?) -> str / (BasicTokenizer, str) -> str'>_tokenize_chinese_chars</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', title='str'>text</a>)
<span class='lineno'> 223</span> 
<span class='lineno'> 224</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.orig_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.orig_tokens', title='{[?] | [str]}'>orig_tokens</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize', title='? -> [?] / str -> {[?] | [str]} / {? -> ? | str} -> [?]'>whitespace_tokenize</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.text', title='str'>text</a>)
<span class='lineno'> 225</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.split_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.split_tokens', title='[str]'>split_tokens</a> = []
<span class='lineno'> 226</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', title='?'>token</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.orig_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.orig_tokens', title='{[?] | [str]}'>orig_tokens</a>:
<span class='lineno'> 227</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', title='BasicTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.do_lower_case', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.do_lower_case', title='bool'>do_lower_case</a>:
<span class='lineno'> 228</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', title='str'>token</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', title='str'>token</a>.lower()
<span class='lineno'> 229</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', title='str'>token</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', title='BasicTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents', title='(BasicTokenizer, str) -> str / (BasicTokenizer, ?) -> str'>_run_strip_accents</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', title='str'>token</a>)
<span class='lineno'> 230</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', title='BasicTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.split_on_punc', title='bool'>split_on_punc</a>:
<span class='lineno'> 231</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.split_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.split_tokens', title='[str]'>split_tokens</a>.extend(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.self', title='BasicTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc', title='(BasicTokenizer, ?) -> [str] / (BasicTokenizer, str) -> [str]'>_run_split_on_punc</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', title='str'>token</a>))
<span class='lineno'> 232</span>       else:
<span class='lineno'> 233</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.split_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.split_tokens', title='[str]'>split_tokens</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.token', title='str'>token</a>)
<span class='lineno'> 234</span> 
<span class='lineno'> 235</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.output_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.output_tokens', title='{[?] | [str]}'>output_tokens</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize', title='? -> [?] / str -> {[?] | [str]} / {? -> ? | str} -> [?]'>whitespace_tokenize</a>(&quot; &quot;.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.split_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.split_tokens', title='[str]'>split_tokens</a>))
<span class='lineno'> 236</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.output_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer.tokenize.output_tokens', title='{[?] | [str]}'>output_tokens</a>
<span class='lineno'> 237</span> 
<span class='lineno'> 238</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents', title='(BasicTokenizer, str) -> str / (BasicTokenizer, ?) -> str'>_run_strip_accents</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.self', title='BasicTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.text', title='str'>text</a>):
<span class='lineno'> 239</span>     &quot;&quot;&quot;Strips accents from a piece of text.&quot;&quot;&quot;
<span class='lineno'> 240</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.text', title='str'>text</a> = unicodedata.normalize(&quot;NFD&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.text', title='str'>text</a>)
<span class='lineno'> 241</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.output', title='[str]'>output</a> = []
<span class='lineno'> 242</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.char', title='str'>char</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.text', title='str'>text</a>:
<span class='lineno'> 243</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.cat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.cat', title='str'>cat</a> = unicodedata.category(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.char', title='str'>char</a>)
<span class='lineno'> 244</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.cat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.cat', title='str'>cat</a> == &quot;Mn&quot;:
<span class='lineno'> 245</span>         continue
<span class='lineno'> 246</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.output', title='[str]'>output</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.char', title='str'>char</a>)
<span class='lineno'> 247</span>     return &quot;&quot;.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_strip_accents.output', title='[str]'>output</a>)
<span class='lineno'> 248</span> 
<span class='lineno'> 249</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc', title='(BasicTokenizer, ?) -> [str] / (BasicTokenizer, str) -> [str]'>_run_split_on_punc</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.self', title='BasicTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.text', title='str'>text</a>):
<span class='lineno'> 250</span>     &quot;&quot;&quot;Splits punctuation on a piece of text.&quot;&quot;&quot;
<span class='lineno'> 251</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.chars', title='list'>chars</a> = list(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.text', title='str'>text</a>)
<span class='lineno'> 252</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', title='int'>i</a> = 0
<span class='lineno'> 253</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.start_new_word', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.start_new_word', title='bool'>start_new_word</a> = True
<span class='lineno'> 254</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', title='[[?]]'>output</a> = []
<span class='lineno'> 255</span>     while <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', title='int'>i</a> &lt; len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.chars', title='list'>chars</a>):
<span class='lineno'> 256</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.char', title='?'>char</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.chars', title='list'>chars</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', title='int'>i</a>]
<span class='lineno'> 257</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation', title='? -> bool'>_is_punctuation</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.char', title='?'>char</a>):
<span class='lineno'> 258</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', title='[[?]]'>output</a>.append([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.char', title='?'>char</a>])
<span class='lineno'> 259</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.start_new_word', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.start_new_word', title='bool'>start_new_word</a> = True
<span class='lineno'> 260</span>       else:
<span class='lineno'> 261</span>         if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.start_new_word', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.start_new_word', title='bool'>start_new_word</a>:
<span class='lineno'> 262</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', title='[[?]]'>output</a>.append([])
<span class='lineno'> 263</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.start_new_word', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.start_new_word', title='bool'>start_new_word</a> = False
<span class='lineno'> 264</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', title='[[?]]'>output</a>[-1].append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.char', title='?'>char</a>)
<span class='lineno'> 265</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', title='int'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.i', title='int'>i</a></a> += 1
<span class='lineno'> 266</span> 
<span class='lineno'> 267</span>     return [&quot;&quot;.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.x', title='[?]'>x</a>) for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.x', title='[?]'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.x', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.x', title='[?]'>x</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._run_split_on_punc.output', title='[[?]]'>output</a>]
<span class='lineno'> 268</span> 
<span class='lineno'> 269</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars', title='(BasicTokenizer, ?) -> str / (BasicTokenizer, str) -> str'>_tokenize_chinese_chars</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.self', title='BasicTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.text', title='str'>text</a>):
<span class='lineno'> 270</span>     &quot;&quot;&quot;Adds whitespace around any CJK character.&quot;&quot;&quot;
<span class='lineno'> 271</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', title='[str]'>output</a> = []
<span class='lineno'> 272</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.char', title='str'>char</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.text', title='str'>text</a>:
<span class='lineno'> 273</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.cp', title='int'>cp</a> = ord(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.char', title='str'>char</a>)
<span class='lineno'> 274</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.self', title='BasicTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char', title='(BasicTokenizer, int) -> bool / (BasicTokenizer, ?) -> bool'>_is_chinese_char</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.cp', title='int'>cp</a>):
<span class='lineno'> 275</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', title='[str]'>output</a>.append(&quot; &quot;)
<span class='lineno'> 276</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', title='[str]'>output</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.char', title='str'>char</a>)
<span class='lineno'> 277</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', title='[str]'>output</a>.append(&quot; &quot;)
<span class='lineno'> 278</span>       else:
<span class='lineno'> 279</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', title='[str]'>output</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.char', title='str'>char</a>)
<span class='lineno'> 280</span>     return &quot;&quot;.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._tokenize_chinese_chars.output', title='[str]'>output</a>)
<span class='lineno'> 281</span> 
<span class='lineno'> 282</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char', title='(BasicTokenizer, int) -> bool / (BasicTokenizer, ?) -> bool'>_is_chinese_char</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.self', title='BasicTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a>):
<span class='lineno'> 283</span>     &quot;&quot;&quot;Checks whether CP is the codepoint of a CJK character.&quot;&quot;&quot;
<span class='lineno'> 284</span>     # This defines a &quot;chinese character&quot; as anything in the CJK Unicode block:
<span class='lineno'> 285</span>     #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)
<span class='lineno'> 286</span>     #
<span class='lineno'> 287</span>     # Note that the CJK Unicode block is NOT all Japanese and Korean characters,
<span class='lineno'> 288</span>     # despite its name. The modern Korean Hangul alphabet is a different block,
<span class='lineno'> 289</span>     # as is Japanese Hiragana and Katakana. Those alphabets are used to write
<span class='lineno'> 290</span>     # space-separated words, so they are not treated specially and handled
<span class='lineno'> 291</span>     # like the all of the other languages.
<span class='lineno'> 292</span>     if ((<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &gt;= 0x4E00 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &lt;= 0x9FFF) or  #
<span class='lineno'> 293</span>         (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &gt;= 0x3400 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &lt;= 0x4DBF) or  #
<span class='lineno'> 294</span>         (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &gt;= 0x20000 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &lt;= 0x2A6DF) or  #
<span class='lineno'> 295</span>         (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &gt;= 0x2A700 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &lt;= 0x2B73F) or  #
<span class='lineno'> 296</span>         (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &gt;= 0x2B740 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &lt;= 0x2B81F) or  #
<span class='lineno'> 297</span>         (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &gt;= 0x2B820 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &lt;= 0x2CEAF) or
<span class='lineno'> 298</span>         (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &gt;= 0xF900 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &lt;= 0xFAFF) or  #
<span class='lineno'> 299</span>         (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &gt;= 0x2F800 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._is_chinese_char.cp', title='int'>cp</a> &lt;= 0x2FA1F)):  #
<span class='lineno'> 300</span>       return True
<span class='lineno'> 301</span> 
<span class='lineno'> 302</span>     return False
<span class='lineno'> 303</span> 
<span class='lineno'> 304</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text', title='(BasicTokenizer, ?) -> str / (BasicTokenizer, {? -> ? | str}) -> str'>_clean_text</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.self', title='BasicTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.text', title='{? -> ? | str}'>text</a>):
<span class='lineno'> 305</span>     &quot;&quot;&quot;Performs invalid character removal and whitespace cleanup on text.&quot;&quot;&quot;
<span class='lineno'> 306</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.output', title='[str]'>output</a> = []
<span class='lineno'> 307</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', title='?'>char</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.text', title='{? -> ? | str}'>text</a>:
<span class='lineno'> 308</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.cp', title='int'>cp</a> = ord(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', title='?'>char</a>)
<span class='lineno'> 309</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.cp', title='int'>cp</a> == 0 or <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.cp', title='int'>cp</a> == 0xfffd or <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control', title='? -> bool'>_is_control</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', title='?'>char</a>):
<span class='lineno'> 310</span>         continue
<span class='lineno'> 311</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace', title='? -> bool'>_is_whitespace</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', title='?'>char</a>):
<span class='lineno'> 312</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.output', title='[str]'>output</a>.append(&quot; &quot;)
<span class='lineno'> 313</span>       else:
<span class='lineno'> 314</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.output', title='[str]'>output</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.char', title='?'>char</a>)
<span class='lineno'> 315</span>     return &quot;&quot;.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.output', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.BasicTokenizer._clean_text.output', title='[str]'>output</a>)
<span class='lineno'> 316</span> 
<span class='lineno'> 317</span> 
<span class='lineno'> 318</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer', title='<WordpieceTokenizer>'>WordpieceTokenizer</a>(object):
<span class='lineno'> 319</span>   &quot;&quot;&quot;Runs WordPiece tokenziation.&quot;&quot;&quot;
<span class='lineno'> 320</span> 
<span class='lineno'> 321</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.self', title='WordpieceTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.vocab', title='?'>vocab</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.unk_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.unk_token', title='str'>unk_token</a>=&quot;[UNK]&quot;, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.max_input_chars_per_word', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.max_input_chars_per_word', title='int'>max_input_chars_per_word</a>=400):
<span class='lineno'> 322</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.self', title='WordpieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.vocab', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.vocab', title='?'>vocab</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.vocab', title='?'>vocab</a>
<span class='lineno'> 323</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.self', title='WordpieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.unk_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.unk_token', title='str'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.unk_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.unk_token', title='str'>unk_token</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.unk_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.unk_token', title='str'>unk_token</a>
<span class='lineno'> 324</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.self', title='WordpieceTokenizer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.max_input_chars_per_word', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.max_input_chars_per_word', title='int'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.max_input_chars_per_word', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.max_input_chars_per_word', title='int'>max_input_chars_per_word</a></a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.max_input_chars_per_word', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.__init__.max_input_chars_per_word', title='int'>max_input_chars_per_word</a>
<span class='lineno'> 325</span> 
<span class='lineno'> 326</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize', title='(WordpieceTokenizer, ?) -> [str]'>tokenize</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', title='WordpieceTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.text', title='?'>text</a>):
<span class='lineno'> 327</span>     &quot;&quot;&quot;Tokenizes a piece of text into its word pieces.
<span class='lineno'> 328</span> 
<span class='lineno'> 329</span>     This uses a greedy longest-match-first algorithm to perform tokenization
<span class='lineno'> 330</span>     using the given vocabulary.
<span class='lineno'> 331</span> 
<span class='lineno'> 332</span>     For example:
<span class='lineno'> 333</span>       input = &quot;unaffable&quot;
<span class='lineno'> 334</span>       output = [&quot;un&quot;, &quot;##aff&quot;, &quot;##able&quot;]
<span class='lineno'> 335</span> 
<span class='lineno'> 336</span>     Args:
<span class='lineno'> 337</span>       text: A single token or whitespace separated tokens. This should have
<span class='lineno'> 338</span>         already been passed through `BasicTokenizer.
<span class='lineno'> 339</span> 
<span class='lineno'> 340</span>     Returns:
<span class='lineno'> 341</span>       A list of wordpiece tokens.
<span class='lineno'> 342</span>     &quot;&quot;&quot;
<span class='lineno'> 343</span> 
<span class='lineno'> 344</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.text', title='{? -> ? | str}'>text</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.convert_to_unicode', title='? -> {? -> ? | str}'>convert_to_unicode</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.text', title='?'>text</a>)
<span class='lineno'> 345</span> 
<span class='lineno'> 346</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', title='[str]'>output_tokens</a> = []
<span class='lineno'> 347</span>     for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.token', title='?'>token</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.whitespace_tokenize', title='? -> [?] / str -> {[?] | [str]} / {? -> ? | str} -> [?]'>whitespace_tokenize</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.text', title='{? -> ? | str}'>text</a>):
<span class='lineno'> 348</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', title='list'>chars</a> = list(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.token', title='?'>token</a>)
<span class='lineno'> 349</span>       if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', title='list'>chars</a>) &gt; <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', title='WordpieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.max_input_chars_per_word', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.max_input_chars_per_word', title='int'>max_input_chars_per_word</a>:
<span class='lineno'> 350</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', title='[str]'>output_tokens</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', title='WordpieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.unk_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.unk_token', title='str'>unk_token</a>)
<span class='lineno'> 351</span>         continue
<span class='lineno'> 352</span> 
<span class='lineno'> 353</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.is_bad', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.is_bad', title='bool'>is_bad</a> = False
<span class='lineno'> 354</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', title='int'>start</a> = 0
<span class='lineno'> 355</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.sub_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.sub_tokens', title='[str]'>sub_tokens</a> = []
<span class='lineno'> 356</span>       while <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', title='int'>start</a> &lt; len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', title='list'>chars</a>):
<span class='lineno'> 357</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', title='int'>end</a> = len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', title='list'>chars</a>)
<span class='lineno'> 358</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.cur_substr', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.cur_substr', title='None'>cur_substr</a> = None
<span class='lineno'> 359</span>         while <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', title='int'>start</a> &lt; <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', title='int'>end</a>:
<span class='lineno'> 360</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', title='str'>substr</a> = &quot;&quot;.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.chars', title='list'>chars</a>[<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', title='int'>start</a>:<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', title='int'>end</a>])
<span class='lineno'> 361</span>           if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', title='int'>start</a> &gt; 0:
<span class='lineno'> 362</span>             <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', title='str'>substr</a> = &quot;##&quot; + <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', title='str'>substr</a>
<span class='lineno'> 363</span>           if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', title='str'>substr</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', title='WordpieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.vocab', title='?'>vocab</a>:
<span class='lineno'> 364</span>             <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.cur_substr', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.cur_substr', title='str'>cur_substr</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.substr', title='str'>substr</a>
<span class='lineno'> 365</span>             break
<span class='lineno'> 366</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', title='int'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', title='int'>end</a></a> -= 1
<span class='lineno'> 367</span>         if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.cur_substr', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.cur_substr', title='str'>cur_substr</a> is None:
<span class='lineno'> 368</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.is_bad', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.is_bad', title='bool'>is_bad</a> = True
<span class='lineno'> 369</span>           break
<span class='lineno'> 370</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.sub_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.sub_tokens', title='[str]'>sub_tokens</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.cur_substr', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.cur_substr', title='str'>cur_substr</a>)
<span class='lineno'> 371</span>         <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.start', title='int'>start</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.end', title='int'>end</a>
<span class='lineno'> 372</span> 
<span class='lineno'> 373</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.is_bad', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.is_bad', title='bool'>is_bad</a>:
<span class='lineno'> 374</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', title='[str]'>output_tokens</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.self', title='WordpieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.unk_token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.unk_token', title='str'>unk_token</a>)
<span class='lineno'> 375</span>       else:
<span class='lineno'> 376</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', title='[str]'>output_tokens</a>.extend(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.sub_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.sub_tokens', title='[str]'>sub_tokens</a>)
<span class='lineno'> 377</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.WordpieceTokenizer.tokenize.output_tokens', title='[str]'>output_tokens</a>
<span class='lineno'> 378</span> 
<span class='lineno'> 379</span> 
<span class='lineno'> 380</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace', title='? -> bool'>_is_whitespace</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', title='?'>char</a>):
<span class='lineno'> 381</span>   &quot;&quot;&quot;Checks whether `chars` is a whitespace character.&quot;&quot;&quot;
<span class='lineno'> 382</span>   # \t, \n, and \r are technically control characters but we treat them
<span class='lineno'> 383</span>   # as whitespace since they are generally considered as such.
<span class='lineno'> 384</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', title='?'>char</a> == &quot; &quot; or <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', title='?'>char</a> == &quot;\t&quot; or <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', title='?'>char</a> == &quot;\n&quot; or <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', title='?'>char</a> == &quot;\r&quot;:
<span class='lineno'> 385</span>     return True
<span class='lineno'> 386</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.cat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.cat', title='str'>cat</a> = unicodedata.category(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.char', title='?'>char</a>)
<span class='lineno'> 387</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.cat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_whitespace.cat', title='str'>cat</a> == &quot;Zs&quot;:
<span class='lineno'> 388</span>     return True
<span class='lineno'> 389</span>   return False
<span class='lineno'> 390</span> 
<span class='lineno'> 391</span> 
<span class='lineno'> 392</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control', title='? -> bool'>_is_control</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', title='?'>char</a>):
<span class='lineno'> 393</span>   &quot;&quot;&quot;Checks whether `chars` is a control character.&quot;&quot;&quot;
<span class='lineno'> 394</span>   # These are technically control characters but we count them as whitespace
<span class='lineno'> 395</span>   # characters.
<span class='lineno'> 396</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', title='?'>char</a> == &quot;\t&quot; or <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', title='?'>char</a> == &quot;\n&quot; or <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', title='?'>char</a> == &quot;\r&quot;:
<span class='lineno'> 397</span>     return False
<span class='lineno'> 398</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.cat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.cat', title='str'>cat</a> = unicodedata.category(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.char', title='?'>char</a>)
<span class='lineno'> 399</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.cat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_control.cat', title='str'>cat</a> in (&quot;Cc&quot;, &quot;Cf&quot;):
<span class='lineno'> 400</span>     return True
<span class='lineno'> 401</span>   return False
<span class='lineno'> 402</span> 
<span class='lineno'> 403</span> 
<span class='lineno'> 404</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation', title='? -> bool'>_is_punctuation</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.char', title='?'>char</a>):
<span class='lineno'> 405</span>   &quot;&quot;&quot;Checks whether `chars` is a punctuation character.&quot;&quot;&quot;
<span class='lineno'> 406</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', title='int'>cp</a> = ord(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.char', title='?'>char</a>)
<span class='lineno'> 407</span>   # We treat all non-letter/number ASCII as punctuation.
<span class='lineno'> 408</span>   # Characters such as &quot;^&quot;, &quot;$&quot;, and &quot;`&quot; are not in the Unicode
<span class='lineno'> 409</span>   # Punctuation class but we treat them as punctuation anyways, for
<span class='lineno'> 410</span>   # consistency.
<span class='lineno'> 411</span>   if ((<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', title='int'>cp</a> &gt;= 33 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', title='int'>cp</a> &lt;= 47) or (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', title='int'>cp</a> &gt;= 58 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', title='int'>cp</a> &lt;= 64) or
<span class='lineno'> 412</span>       (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', title='int'>cp</a> &gt;= 91 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', title='int'>cp</a> &lt;= 96) or (<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', title='int'>cp</a> &gt;= 123 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cp', title='int'>cp</a> &lt;= 126)):
<span class='lineno'> 413</span>     return True
<span class='lineno'> 414</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cat', title='str'>cat</a> = unicodedata.category(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.char', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.char', title='?'>char</a>)
<span class='lineno'> 415</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cat', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization._is_punctuation.cat', title='str'>cat</a>.startswith(&quot;P&quot;):
<span class='lineno'> 416</span>     return True
<span class='lineno'> 417</span>   return False
<span class='lineno'> 418</span> 
<span class='lineno'> 419</span> 
<span class='lineno'> 420</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text', title='(?, bool, bool) -> str'>preprocess_text</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.inputs', title='?'>inputs</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.remove_space', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.remove_space', title='bool'>remove_space</a>=True, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.lower', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.lower', title='bool'>lower</a>=False):
<span class='lineno'> 421</span>   &quot;&quot;&quot;Preprocesses data by removing extra space and normalize data.
<span class='lineno'> 422</span> 
<span class='lineno'> 423</span>   This method is used together with sentence piece tokenizer and is forked from:
<span class='lineno'> 424</span>   https://github.com/google-research/google-research/blob/master/albert/tokenization.py
<span class='lineno'> 425</span> 
<span class='lineno'> 426</span>   Args:
<span class='lineno'> 427</span>     inputs: The input text.
<span class='lineno'> 428</span>     remove_space: Whether to remove the extra space.
<span class='lineno'> 429</span>     lower: Whether to lowercase the text.
<span class='lineno'> 430</span> 
<span class='lineno'> 431</span>   Returns:
<span class='lineno'> 432</span>     The preprocessed text.
<span class='lineno'> 433</span> 
<span class='lineno'> 434</span>   &quot;&quot;&quot;
<span class='lineno'> 435</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='?'>outputs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.inputs', title='?'>inputs</a>
<span class='lineno'> 436</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.remove_space', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.remove_space', title='bool'>remove_space</a>:
<span class='lineno'> 437</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a> = &quot; &quot;.join(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.inputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.inputs', title='?'>inputs</a>.strip().split())
<span class='lineno'> 438</span> 
<span class='lineno'> 439</span>   if six.PY2 and isinstance(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a>, str):
<span class='lineno'> 440</span>     try:
<span class='lineno'> 441</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='?'>outputs</a> = six.ensure_text(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='?'>outputs</a>, &quot;utf-8&quot;)
<span class='lineno'> 442</span>     except UnicodeDecodeError:
<span class='lineno'> 443</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='?'>outputs</a> = six.ensure_text(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a>, &quot;latin-1&quot;)
<span class='lineno'> 444</span> 
<span class='lineno'> 445</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a> = unicodedata.normalize(&quot;NFKD&quot;, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a>)
<span class='lineno'> 446</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a> = &quot;&quot;.join([<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.c', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.c', title='str'>c</a> for <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.c', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.c', title='str'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.c', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.c', title='str'>c</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a> if not unicodedata.combining(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.c', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.c', title='str'>c</a>)])
<span class='lineno'> 447</span>   if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.lower', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.lower', title='bool'>lower</a>:
<span class='lineno'> 448</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a>.lower()
<span class='lineno'> 449</span> 
<span class='lineno'> 450</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.preprocess_text.outputs', title='str'>outputs</a>
<span class='lineno'> 451</span> 
<span class='lineno'> 452</span> 
<span class='lineno'> 453</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces', title='(?, ?, bool) -> [str]'>encode_pieces</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sp_model', title='?'>sp_model</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', title='?'>text</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sample', title='bool'>sample</a>=False):
<span class='lineno'> 454</span>   &quot;&quot;&quot;Segements text into pieces.
<span class='lineno'> 455</span> 
<span class='lineno'> 456</span>   This method is used together with sentence piece tokenizer and is forked from:
<span class='lineno'> 457</span>   https://github.com/google-research/google-research/blob/master/albert/tokenization.py
<span class='lineno'> 458</span> 
<span class='lineno'> 459</span> 
<span class='lineno'> 460</span>   Args:
<span class='lineno'> 461</span>     sp_model: A spm.SentencePieceProcessor object.
<span class='lineno'> 462</span>     text: The input text to be segemented.
<span class='lineno'> 463</span>     sample: Whether to randomly sample a segmentation output or return a
<span class='lineno'> 464</span>       deterministic one.
<span class='lineno'> 465</span> 
<span class='lineno'> 466</span>   Returns:
<span class='lineno'> 467</span>     A list of token pieces.
<span class='lineno'> 468</span>   &quot;&quot;&quot;
<span class='lineno'> 469</span>   if six.PY2 and isinstance(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', title='?'>text</a>, six.text_type):
<span class='lineno'> 470</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', title='?'>text</a> = six.ensure_binary(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', title='?'>text</a>, &quot;utf-8&quot;)
<span class='lineno'> 471</span> 
<span class='lineno'> 472</span>   if not <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sample', title='bool'>sample</a>:
<span class='lineno'> 473</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.pieces', title='?'>pieces</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sp_model', title='?'>sp_model</a>.EncodeAsPieces(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', title='?'>text</a>)
<span class='lineno'> 474</span>   else:
<span class='lineno'> 475</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.pieces', title='?'>pieces</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sp_model', title='?'>sp_model</a>.SampleEncodeAsPieces(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.text', title='?'>text</a>, 64, 0.1)
<span class='lineno'> 476</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.new_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.new_pieces', title='[str]'>new_pieces</a> = []
<span class='lineno'> 477</span>   for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='?'>piece</a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.pieces', title='?'>pieces</a>:
<span class='lineno'> 478</span>     <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='str'>piece</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text', title='str -> str / ? -> str'>printable_text</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='str'>piece</a>)
<span class='lineno'> 479</span>     if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='str'>piece</a>) &gt; 1 and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='str'>piece</a>[-1] == &quot;,&quot; and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='str'>piece</a>[-2].isdigit():
<span class='lineno'> 480</span>       <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', title='?'>cur_pieces</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.sp_model', title='?'>sp_model</a>.EncodeAsPieces(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='str'>piece</a>[:-1].replace(
<span class='lineno'> 481</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE', title='str'>SPIECE_UNDERLINE</a>, &quot;&quot;))
<span class='lineno'> 482</span>       if <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='str'>piece</a>[0] != <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE', title='str'>SPIECE_UNDERLINE</a> and <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', title='?'>cur_pieces</a>[0][0] == <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.SPIECE_UNDERLINE', title='str'>SPIECE_UNDERLINE</a>:
<span class='lineno'> 483</span>         if len(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', title='?'>cur_pieces</a>[0]) == 1:
<span class='lineno'> 484</span>           <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', title='?'>cur_pieces</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', title='?'>cur_pieces</a>[1:]
<span class='lineno'> 485</span>         else:
<span class='lineno'> 486</span>           <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', title='?'>cur_pieces</a>[0] = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', title='?'>cur_pieces</a>[0][1:]
<span class='lineno'> 487</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', title='?'>cur_pieces</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='str'>piece</a>[-1])
<span class='lineno'> 488</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.new_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.new_pieces', title='[str]'>new_pieces</a>.extend(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.cur_pieces', title='?'>cur_pieces</a>)
<span class='lineno'> 489</span>     else:
<span class='lineno'> 490</span>       <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.new_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.new_pieces', title='[str]'>new_pieces</a>.append(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.piece', title='str'>piece</a>)
<span class='lineno'> 491</span> 
<span class='lineno'> 492</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.new_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces.new_pieces', title='[str]'>new_pieces</a>
<span class='lineno'> 493</span> 
<span class='lineno'> 494</span> 
<span class='lineno'> 495</span> def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids', title='(?, ?, bool) -> [?]'>encode_ids</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sp_model', title='?'>sp_model</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.text', title='?'>text</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sample', title='bool'>sample</a>=False):
<span class='lineno'> 496</span>   &quot;&quot;&quot;Segments text and return token ids.
<span class='lineno'> 497</span> 
<span class='lineno'> 498</span>   This method is used together with sentence piece tokenizer and is forked from:
<span class='lineno'> 499</span>   https://github.com/google-research/google-research/blob/master/albert/tokenization.py
<span class='lineno'> 500</span> 
<span class='lineno'> 501</span>   Args:
<span class='lineno'> 502</span>     sp_model: A spm.SentencePieceProcessor object.
<span class='lineno'> 503</span>     text: The input text to be segemented.
<span class='lineno'> 504</span>     sample: Whether to randomly sample a segmentation output or return a
<span class='lineno'> 505</span>       deterministic one.
<span class='lineno'> 506</span> 
<span class='lineno'> 507</span>   Returns:
<span class='lineno'> 508</span>     A list of token ids.
<span class='lineno'> 509</span>   &quot;&quot;&quot;
<span class='lineno'> 510</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.pieces', title='[str]'>pieces</a> = <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces', title='(?, ?, bool) -> [str]'>encode_pieces</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sp_model', title='?'>sp_model</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.text', title='?'>text</a>, sample=<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sample', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sample', title='bool'>sample</a>)
<span class='lineno'> 511</span>   <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.ids', title='[?]'>ids</a> = [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.sp_model', title='?'>sp_model</a>.PieceToId(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.piece', title='str'>piece</a>) for <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.piece', title='str'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.piece', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.piece', title='str'>piece</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.pieces', title='[str]'>pieces</a>]
<span class='lineno'> 512</span>   return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_ids.ids', title='[?]'>ids</a>
<span class='lineno'> 513</span> 
<span class='lineno'> 514</span> 
<span class='lineno'> 515</span> class <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer', title='<FullSentencePieceTokenizer>'>FullSentencePieceTokenizer</a>(object):
<span class='lineno'> 516</span>   &quot;&quot;&quot;Runs end-to-end sentence piece tokenization.
<span class='lineno'> 517</span> 
<span class='lineno'> 518</span>   The interface of this class is intended to keep the same as above
<span class='lineno'> 519</span>   `FullTokenizer` class for easier usage.
<span class='lineno'> 520</span>   &quot;&quot;&quot;
<span class='lineno'> 521</span> 
<span class='lineno'> 522</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__', title='? -> ?'>__init__</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', title='FullSentencePieceTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.sp_model_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.sp_model_file', title='?'>sp_model_file</a>):
<span class='lineno'> 523</span>     &quot;&quot;&quot;Inits FullSentencePieceTokenizer.
<span class='lineno'> 524</span> 
<span class='lineno'> 525</span>     Args:
<span class='lineno'> 526</span>       sp_model_file: The path to the sentence piece model file.
<span class='lineno'> 527</span>     &quot;&quot;&quot;
<span class='lineno'> 528</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', title='FullSentencePieceTokenizer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', title='?'>sp_model</a> = spm.SentencePieceProcessor()
<span class='lineno'> 529</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', title='FullSentencePieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', title='?'>sp_model</a>.Load(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.sp_model_file', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.sp_model_file', title='?'>sp_model_file</a>)
<span class='lineno'> 530</span>     <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', title='FullSentencePieceTokenizer'>self</a>.<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.vocab', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.vocab', title='dict'>vocab</a> = {
<span class='lineno'> 531</span>         <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', title='FullSentencePieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', title='?'>sp_model</a>.IdToPiece(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.i', title='?'>i</a>): <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.i', title='?'>i</a>
<span class='lineno'> 532</span>         for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.i', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.i', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.i', title='?'>i</a></a> in six.moves.range(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.__init__.self', title='FullSentencePieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', title='?'>sp_model</a>.GetPieceSize())
<span class='lineno'> 533</span>     }
<span class='lineno'> 534</span> 
<span class='lineno'> 535</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize', title='(FullSentencePieceTokenizer, ?) -> [str]'>tokenize</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize.self', title='FullSentencePieceTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize.text', title='?'>text</a>):
<span class='lineno'> 536</span>     &quot;&quot;&quot;Tokenizes text into pieces.&quot;&quot;&quot;
<span class='lineno'> 537</span>     return <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.encode_pieces', title='(?, ?, bool) -> [str]'>encode_pieces</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize.self', title='FullSentencePieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', title='?'>sp_model</a>, <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize.text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.tokenize.text', title='?'>text</a>)
<span class='lineno'> 538</span> 
<span class='lineno'> 539</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids', title='(FullSentencePieceTokenizer, ?) -> [?]'>convert_tokens_to_ids</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.self', title='FullSentencePieceTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.tokens', title='?'>tokens</a>):
<span class='lineno'> 540</span>     &quot;&quot;&quot;Converts a list of tokens to a list of ids.&quot;&quot;&quot;
<span class='lineno'> 541</span>     return [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.self', title='FullSentencePieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', title='?'>sp_model</a>.PieceToId(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.printable_text', title='str -> str / ? -> str'>printable_text</a>(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.token', title='?'>token</a>)) for <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.token', title='?'><a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.token', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.token', title='?'>token</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_tokens_to_ids.tokens', title='?'>tokens</a>]
<span class='lineno'> 542</span> 
<span class='lineno'> 543</span>   def <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens', title='(FullSentencePieceTokenizer, ?) -> [?]'>convert_ids_to_tokens</a>(<a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.self', title='FullSentencePieceTokenizer'>self</a>, <a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.ids', title='?'>ids</a>):
<span class='lineno'> 544</span>     &quot;&quot;&quot;Converts a list of ids ot a list of tokens.&quot;&quot;&quot;
<span class='lineno'> 545</span>     return [<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.self', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.self', title='FullSentencePieceTokenizer'>self</a>.<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.sp_model', title='?'>sp_model</a>.IdToPiece(<a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.id_', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.id_', title='?'>id_</a>) for <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.id_', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.id_', title='?'><a name='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.id_', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.id_', title='?'>id_</a></a> in <a href='#.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.ids', xid ='.home.xxm.Desktop.EMSE.dataset.models.official.nlp.bert.tokenization.FullSentencePieceTokenizer.convert_ids_to_tokens.ids', title='?'>ids</a>]
</pre></td></tr></table></body></html>